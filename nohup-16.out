WARNING:tensorflow:From /home/stud/minawoi/miniconda3/envs/conda-venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2024-04-09 15:15:34.104163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-04-09 15:15:34.249418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:8a:00.0
2024-04-09 15:15:34.250627: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-09 15:15:34.254363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-04-09 15:15:34.257315: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-04-09 15:15:34.258550: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-04-09 15:15:34.262348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-04-09 15:15:34.264550: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-04-09 15:15:34.271989: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-04-09 15:15:34.281317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-04-09 15:15:34.281986: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2024-04-09 15:15:34.306116: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199835000 Hz
2024-04-09 15:15:34.310540: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4393bb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-04-09 15:15:34.310616: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-04-09 15:15:34.829537: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1e15e80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-04-09 15:15:34.829598: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-04-09 15:15:34.833150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:8a:00.0
2024-04-09 15:15:34.833281: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-09 15:15:34.833306: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-04-09 15:15:34.833326: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-04-09 15:15:34.833363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-04-09 15:15:34.833382: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-04-09 15:15:34.833401: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-04-09 15:15:34.833421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-04-09 15:15:34.842739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-04-09 15:15:34.842944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-09 15:15:34.847711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-04-09 15:15:34.847782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-04-09 15:15:34.847797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2024-04-09 15:15:34.854708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30593 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0)
WARNING:tensorflow:Output bob missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to bob.
WARNING:tensorflow:Output bob_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to bob_1.
WARNING:tensorflow:Output eve missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to eve.
WARNING:tensorflow:Output eve_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to eve_1.
2024-04-09 15:15:40.532400: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
Train on 512 samples, validate on 512 samples
Epoch 1/512
512/512 - 1s - loss: 0.6050 - val_loss: 0.0025
Epoch 2/512
512/512 - 0s - loss: 0.1546 - val_loss: 5.7691e-04
Epoch 3/512
512/512 - 0s - loss: 0.0372 - val_loss: 1.5742e-04
Epoch 4/512
512/512 - 0s - loss: 0.0115 - val_loss: 7.2325e-05
Epoch 5/512
512/512 - 0s - loss: 0.0063 - val_loss: 5.1283e-05
Epoch 6/512
512/512 - 0s - loss: 0.0046 - val_loss: 3.6806e-05
Epoch 7/512
512/512 - 0s - loss: 0.0032 - val_loss: 2.4297e-05
Epoch 8/512
512/512 - 0s - loss: 0.0020 - val_loss: 1.4441e-05
Epoch 9/512
512/512 - 0s - loss: 0.0012 - val_loss: 7.5616e-06
Epoch 10/512
512/512 - 0s - loss: 5.8073e-04 - val_loss: 3.3872e-06
Epoch 11/512
512/512 - 0s - loss: 2.4572e-04 - val_loss: 1.2477e-06
Epoch 12/512
512/512 - 0s - loss: 8.4499e-05 - val_loss: 3.5843e-07
Epoch 13/512
512/512 - 0s - loss: 2.2417e-05 - val_loss: 8.0559e-08
Epoch 14/512
512/512 - 0s - loss: 1.5083e-05 - val_loss: 1.7758e-06
Epoch 15/512
512/512 - 0s - loss: 0.0028 - val_loss: 4.1760e-05
Epoch 16/512
512/512 - 0s - loss: 0.0016 - val_loss: 1.5534e-06
Epoch 17/512
512/512 - 0s - loss: 1.1489e-04 - val_loss: 1.3091e-06
Epoch 18/512
512/512 - 0s - loss: 3.3467e-04 - val_loss: 1.3383e-05
Epoch 19/512
512/512 - 0s - loss: 0.0023 - val_loss: 1.8522e-05
Epoch 20/512
512/512 - 0s - loss: 0.0010 - val_loss: 4.3945e-06
Epoch 21/512
512/512 - 0s - loss: 4.4846e-04 - val_loss: 6.9846e-06
Epoch 22/512
512/512 - 0s - loss: 0.0011 - val_loss: 1.8584e-05
Epoch 23/512
512/512 - 0s - loss: 0.0015 - val_loss: 9.0290e-06
Epoch 24/512
512/512 - 0s - loss: 7.3235e-04 - val_loss: 6.8378e-06
Epoch 25/512
512/512 - 0s - loss: 8.3232e-04 - val_loss: 1.2413e-05
Epoch 26/512
512/512 - 0s - loss: 0.0013 - val_loss: 1.1870e-05
Epoch 27/512
512/512 - 0s - loss: 9.7960e-04 - val_loss: 8.0604e-06
Epoch 28/512
512/512 - 0s - loss: 8.1462e-04 - val_loss: 9.8201e-06
Epoch 29/512
512/512 - 0s - loss: 0.0011 - val_loss: 1.1486e-05
Epoch 30/512
512/512 - 0s - loss: 0.0010 - val_loss: 9.2374e-06
Epoch 31/512
512/512 - 0s - loss: 8.7017e-04 - val_loss: 9.1072e-06
Epoch 32/512
512/512 - 0s - loss: 9.4038e-04 - val_loss: 1.0400e-05
Epoch 33/512
512/512 - 0s - loss: 0.0010 - val_loss: 9.6583e-06
Epoch 34/512
512/512 - 0s - loss: 9.0581e-04 - val_loss: 8.8647e-06
Epoch 35/512
512/512 - 0s - loss: 8.8997e-04 - val_loss: 9.5022e-06
Epoch 36/512
512/512 - 0s - loss: 9.4629e-04 - val_loss: 9.5173e-06
Epoch 37/512
512/512 - 0s - loss: 9.1144e-04 - val_loss: 8.9152e-06
Epoch 38/512
512/512 - 0s - loss: 8.6603e-04 - val_loss: 9.1916e-06
Epoch 39/512
512/512 - 0s - loss: 9.2019e-04 - val_loss: 9.0852e-06
Epoch 40/512
512/512 - 0s - loss: 8.7411e-04 - val_loss: 8.7616e-06
Epoch 41/512
512/512 - 0s - loss: 8.6661e-04 - val_loss: 8.8631e-06
Epoch 42/512
512/512 - 0s - loss: 8.7121e-04 - val_loss: 8.9817e-06
Epoch 43/512
512/512 - 0s - loss: 8.7143e-04 - val_loss: 8.6864e-06
Epoch 44/512
512/512 - 0s - loss: 8.4364e-04 - val_loss: 8.5524e-06
Epoch 45/512
512/512 - 0s - loss: 8.4388e-04 - val_loss: 8.6207e-06
Epoch 46/512
512/512 - 0s - loss: 8.5120e-04 - val_loss: 8.4695e-06
Epoch 47/512
512/512 - 0s - loss: 8.2538e-04 - val_loss: 8.3535e-06
Epoch 48/512
512/512 - 0s - loss: 8.2504e-04 - val_loss: 8.4636e-06
Epoch 49/512
512/512 - 0s - loss: 8.3261e-04 - val_loss: 8.2705e-06
Epoch 50/512
512/512 - 0s - loss: 8.0380e-04 - val_loss: 8.1622e-06
Epoch 51/512
512/512 - 0s - loss: 8.0469e-04 - val_loss: 8.3921e-06
Epoch 52/512
512/512 - 0s - loss: 8.1895e-04 - val_loss: 8.1620e-06
Epoch 53/512
512/512 - 0s - loss: 7.9244e-04 - val_loss: 7.9731e-06
Epoch 54/512
512/512 - 0s - loss: 7.8554e-04 - val_loss: 8.0099e-06
Epoch 55/512
512/512 - 0s - loss: 7.8346e-04 - val_loss: 8.1754e-06
Epoch 56/512
512/512 - 0s - loss: 7.9293e-04 - val_loss: 8.0045e-06
Epoch 57/512
512/512 - 0s - loss: 7.7653e-04 - val_loss: 7.7146e-06
Epoch 58/512
512/512 - 0s - loss: 7.5871e-04 - val_loss: 7.8207e-06
Epoch 59/512
512/512 - 0s - loss: 7.7499e-04 - val_loss: 7.8059e-06
Epoch 60/512
512/512 - 0s - loss: 7.5863e-04 - val_loss: 7.6811e-06
Epoch 61/512
512/512 - 0s - loss: 7.5396e-04 - val_loss: 7.6956e-06
Epoch 62/512
512/512 - 0s - loss: 7.5463e-04 - val_loss: 7.5565e-06
Epoch 63/512
512/512 - 0s - loss: 7.4415e-04 - val_loss: 7.5072e-06
Epoch 64/512
512/512 - 0s - loss: 7.4205e-04 - val_loss: 7.4703e-06
Epoch 65/512
512/512 - 0s - loss: 7.3623e-04 - val_loss: 7.4624e-06
Epoch 66/512
512/512 - 0s - loss: 7.3086e-04 - val_loss: 7.4703e-06
Epoch 67/512
512/512 - 0s - loss: 7.3352e-04 - val_loss: 7.3683e-06
Epoch 68/512
512/512 - 0s - loss: 7.2359e-04 - val_loss: 7.2420e-06
Epoch 69/512
512/512 - 0s - loss: 7.1582e-04 - val_loss: 7.2507e-06
Epoch 70/512
512/512 - 0s - loss: 7.1596e-04 - val_loss: 7.3062e-06
Epoch 71/512
512/512 - 0s - loss: 7.1949e-04 - val_loss: 7.0889e-06
Epoch 72/512
512/512 - 0s - loss: 6.9763e-04 - val_loss: 7.0777e-06
Epoch 73/512
512/512 - 0s - loss: 6.9928e-04 - val_loss: 7.2324e-06
Epoch 74/512
512/512 - 0s - loss: 7.1772e-04 - val_loss: 6.9164e-06
Epoch 75/512
512/512 - 0s - loss: 6.7910e-04 - val_loss: 6.8744e-06
Epoch 76/512
512/512 - 0s - loss: 6.8641e-04 - val_loss: 7.1130e-06
Epoch 77/512
512/512 - 0s - loss: 7.0063e-04 - val_loss: 6.9997e-06
Epoch 78/512
512/512 - 0s - loss: 6.8686e-04 - val_loss: 6.6672e-06
Epoch 79/512
512/512 - 0s - loss: 6.6410e-04 - val_loss: 6.7454e-06
Epoch 80/512
512/512 - 0s - loss: 6.7482e-04 - val_loss: 7.0656e-06
Epoch 81/512
512/512 - 0s - loss: 6.8986e-04 - val_loss: 6.8071e-06
Epoch 82/512
512/512 - 0s - loss: 6.6080e-04 - val_loss: 6.5780e-06
Epoch 83/512
512/512 - 0s - loss: 6.5726e-04 - val_loss: 6.7018e-06
Epoch 84/512
512/512 - 0s - loss: 6.6385e-04 - val_loss: 6.7931e-06
Epoch 85/512
512/512 - 0s - loss: 6.6881e-04 - val_loss: 6.5588e-06
Epoch 86/512
512/512 - 0s - loss: 6.4355e-04 - val_loss: 6.4828e-06
Epoch 87/512
512/512 - 0s - loss: 6.4805e-04 - val_loss: 6.6464e-06
Epoch 88/512
512/512 - 0s - loss: 6.5609e-04 - val_loss: 6.5339e-06
Epoch 89/512
512/512 - 0s - loss: 6.3693e-04 - val_loss: 6.4860e-06
Epoch 90/512
512/512 - 0s - loss: 6.3975e-04 - val_loss: 6.5263e-06
Epoch 91/512
512/512 - 0s - loss: 6.4132e-04 - val_loss: 6.4367e-06
Epoch 92/512
512/512 - 0s - loss: 6.3275e-04 - val_loss: 6.3007e-06
Epoch 93/512
512/512 - 0s - loss: 6.2876e-04 - val_loss: 6.2669e-06
Epoch 94/512
512/512 - 0s - loss: 6.2084e-04 - val_loss: 6.3194e-06
Epoch 95/512
512/512 - 0s - loss: 6.2962e-04 - val_loss: 6.2580e-06
Epoch 96/512
512/512 - 0s - loss: 6.2041e-04 - val_loss: 6.0981e-06
Epoch 97/512
512/512 - 0s - loss: 6.0212e-04 - val_loss: 6.2869e-06
Epoch 98/512
512/512 - 0s - loss: 6.2594e-04 - val_loss: 6.2681e-06
Epoch 99/512
512/512 - 0s - loss: 6.1211e-04 - val_loss: 5.9856e-06
Epoch 100/512
512/512 - 0s - loss: 5.9531e-04 - val_loss: 6.0061e-06
Epoch 101/512
512/512 - 0s - loss: 6.0368e-04 - val_loss: 6.0682e-06
Epoch 102/512
512/512 - 0s - loss: 6.0006e-04 - val_loss: 6.0408e-06
Epoch 103/512
512/512 - 0s - loss: 5.9045e-04 - val_loss: 6.0969e-06
Epoch 104/512
512/512 - 0s - loss: 6.0008e-04 - val_loss: 5.9872e-06
Epoch 105/512
512/512 - 0s - loss: 5.8994e-04 - val_loss: 5.8280e-06
Epoch 106/512
512/512 - 0s - loss: 5.7520e-04 - val_loss: 5.9399e-06
Epoch 107/512
512/512 - 0s - loss: 5.8867e-04 - val_loss: 5.9465e-06
Epoch 108/512
512/512 - 0s - loss: 5.8816e-04 - val_loss: 5.6272e-06
Epoch 109/512
512/512 - 0s - loss: 5.5450e-04 - val_loss: 5.7935e-06
Epoch 110/512
512/512 - 0s - loss: 5.8239e-04 - val_loss: 5.9252e-06
Epoch 111/512
512/512 - 0s - loss: 5.7994e-04 - val_loss: 5.5626e-06
Epoch 112/512
512/512 - 0s - loss: 5.5411e-04 - val_loss: 5.4372e-06
Epoch 113/512
512/512 - 0s - loss: 5.5451e-04 - val_loss: 5.6485e-06
Epoch 114/512
512/512 - 0s - loss: 5.6996e-04 - val_loss: 5.6062e-06
Epoch 115/512
512/512 - 0s - loss: 5.5142e-04 - val_loss: 5.4636e-06
Epoch 116/512
512/512 - 0s - loss: 5.4574e-04 - val_loss: 5.5486e-06
Epoch 117/512
512/512 - 0s - loss: 5.5240e-04 - val_loss: 5.5418e-06
Epoch 118/512
512/512 - 0s - loss: 5.4647e-04 - val_loss: 5.4630e-06
Epoch 119/512
512/512 - 0s - loss: 5.3863e-04 - val_loss: 5.4113e-06
Epoch 120/512
512/512 - 0s - loss: 5.3899e-04 - val_loss: 5.3791e-06
Epoch 121/512
512/512 - 0s - loss: 5.3404e-04 - val_loss: 5.3370e-06
Epoch 122/512
512/512 - 0s - loss: 5.3439e-04 - val_loss: 5.2490e-06
Epoch 123/512
512/512 - 0s - loss: 5.2094e-04 - val_loss: 5.2645e-06
Epoch 124/512
512/512 - 0s - loss: 5.2618e-04 - val_loss: 5.2847e-06
Epoch 125/512
512/512 - 0s - loss: 5.2449e-04 - val_loss: 5.1469e-06
Epoch 126/512
512/512 - 0s - loss: 5.1264e-04 - val_loss: 5.1098e-06
Epoch 127/512
512/512 - 0s - loss: 5.0861e-04 - val_loss: 5.2448e-06
Epoch 128/512
512/512 - 0s - loss: 5.2198e-04 - val_loss: 5.1221e-06
Epoch 129/512
512/512 - 0s - loss: 5.0148e-04 - val_loss: 4.9757e-06
Epoch 130/512
512/512 - 0s - loss: 4.9885e-04 - val_loss: 5.0466e-06
Epoch 131/512
512/512 - 0s - loss: 5.0335e-04 - val_loss: 5.0151e-06
Epoch 132/512
512/512 - 0s - loss: 4.9512e-04 - val_loss: 4.9479e-06
Epoch 133/512
512/512 - 0s - loss: 4.9312e-04 - val_loss: 4.9191e-06
Epoch 134/512
512/512 - 0s - loss: 4.8776e-04 - val_loss: 4.8943e-06
Epoch 135/512
512/512 - 0s - loss: 4.8630e-04 - val_loss: 4.8676e-06
Epoch 136/512
512/512 - 0s - loss: 4.8255e-04 - val_loss: 4.8150e-06
Epoch 137/512
512/512 - 0s - loss: 4.7911e-04 - val_loss: 4.7174e-06
Epoch 138/512
512/512 - 0s - loss: 4.7083e-04 - val_loss: 4.7440e-06
Epoch 139/512
512/512 - 0s - loss: 4.7377e-04 - val_loss: 4.7579e-06
Epoch 140/512
512/512 - 0s - loss: 4.6829e-04 - val_loss: 4.6936e-06
Epoch 141/512
512/512 - 0s - loss: 4.6593e-04 - val_loss: 4.5839e-06
Epoch 142/512
512/512 - 0s - loss: 4.5940e-04 - val_loss: 4.4953e-06
Epoch 143/512
512/512 - 0s - loss: 4.5197e-04 - val_loss: 4.5701e-06
Epoch 144/512
512/512 - 0s - loss: 4.5737e-04 - val_loss: 4.5835e-06
Epoch 145/512
512/512 - 0s - loss: 4.5224e-04 - val_loss: 4.4528e-06
Epoch 146/512
512/512 - 0s - loss: 4.4276e-04 - val_loss: 4.3849e-06
Epoch 147/512
512/512 - 0s - loss: 4.4037e-04 - val_loss: 4.4397e-06
Epoch 148/512
512/512 - 0s - loss: 4.4206e-04 - val_loss: 4.4493e-06
Epoch 149/512
512/512 - 0s - loss: 4.3950e-04 - val_loss: 4.3108e-06
Epoch 150/512
512/512 - 0s - loss: 4.2687e-04 - val_loss: 4.2690e-06
Epoch 151/512
512/512 - 0s - loss: 4.3001e-04 - val_loss: 4.2468e-06
Epoch 152/512
512/512 - 0s - loss: 4.2441e-04 - val_loss: 4.2051e-06
Epoch 153/512
512/512 - 0s - loss: 4.2009e-04 - val_loss: 4.1865e-06
Epoch 154/512
512/512 - 0s - loss: 4.1793e-04 - val_loss: 4.1568e-06
Epoch 155/512
512/512 - 0s - loss: 4.1335e-04 - val_loss: 4.1479e-06
Epoch 156/512
512/512 - 0s - loss: 4.1398e-04 - val_loss: 4.0371e-06
Epoch 157/512
512/512 - 0s - loss: 4.0240e-04 - val_loss: 3.9757e-06
Epoch 158/512
512/512 - 0s - loss: 4.0082e-04 - val_loss: 4.0398e-06
Epoch 159/512
512/512 - 0s - loss: 4.0432e-04 - val_loss: 4.0134e-06
Epoch 160/512
512/512 - 0s - loss: 3.9873e-04 - val_loss: 3.8344e-06
Epoch 161/512
512/512 - 0s - loss: 3.8378e-04 - val_loss: 3.8720e-06
Epoch 162/512
512/512 - 0s - loss: 3.9278e-04 - val_loss: 3.8921e-06
Epoch 163/512
512/512 - 0s - loss: 3.8731e-04 - val_loss: 3.8043e-06
Epoch 164/512
512/512 - 0s - loss: 3.7656e-04 - val_loss: 3.8070e-06
Epoch 165/512
512/512 - 0s - loss: 3.8319e-04 - val_loss: 3.7297e-06
Epoch 166/512
512/512 - 0s - loss: 3.7338e-04 - val_loss: 3.6547e-06
Epoch 167/512
512/512 - 0s - loss: 3.6703e-04 - val_loss: 3.6803e-06
Epoch 168/512
512/512 - 0s - loss: 3.6793e-04 - val_loss: 3.7305e-06
Epoch 169/512
512/512 - 0s - loss: 3.6534e-04 - val_loss: 3.6800e-06
Epoch 170/512
512/512 - 0s - loss: 3.6482e-04 - val_loss: 3.5200e-06
Epoch 171/512
512/512 - 0s - loss: 3.4924e-04 - val_loss: 3.5086e-06
Epoch 172/512
512/512 - 0s - loss: 3.5454e-04 - val_loss: 3.5457e-06
Epoch 173/512
512/512 - 0s - loss: 3.5416e-04 - val_loss: 3.4491e-06
Epoch 174/512
512/512 - 0s - loss: 3.4405e-04 - val_loss: 3.3718e-06
Epoch 175/512
512/512 - 0s - loss: 3.4011e-04 - val_loss: 3.3871e-06
Epoch 176/512
512/512 - 0s - loss: 3.4257e-04 - val_loss: 3.3312e-06
Epoch 177/512
512/512 - 0s - loss: 3.3136e-04 - val_loss: 3.3314e-06
Epoch 178/512
512/512 - 0s - loss: 3.3667e-04 - val_loss: 3.2666e-06
Epoch 179/512
512/512 - 0s - loss: 3.2372e-04 - val_loss: 3.2348e-06
Epoch 180/512
512/512 - 0s - loss: 3.2623e-04 - val_loss: 3.2722e-06
Epoch 181/512
512/512 - 0s - loss: 3.2359e-04 - val_loss: 3.2234e-06
Epoch 182/512
512/512 - 0s - loss: 3.1779e-04 - val_loss: 3.1746e-06
Epoch 183/512
512/512 - 0s - loss: 3.1673e-04 - val_loss: 3.0985e-06
Epoch 184/512
512/512 - 0s - loss: 3.0889e-04 - val_loss: 3.0750e-06
Epoch 185/512
512/512 - 0s - loss: 3.0937e-04 - val_loss: 3.0675e-06
Epoch 186/512
512/512 - 0s - loss: 3.0452e-04 - val_loss: 3.0220e-06
Epoch 187/512
512/512 - 0s - loss: 3.0242e-04 - val_loss: 2.9795e-06
Epoch 188/512
512/512 - 0s - loss: 2.9702e-04 - val_loss: 2.9390e-06
Epoch 189/512
512/512 - 0s - loss: 2.9430e-04 - val_loss: 2.9301e-06
Epoch 190/512
512/512 - 0s - loss: 2.9309e-04 - val_loss: 2.8765e-06
Epoch 191/512
512/512 - 0s - loss: 2.8719e-04 - val_loss: 2.8446e-06
Epoch 192/512
512/512 - 0s - loss: 2.8409e-04 - val_loss: 2.8311e-06
Epoch 193/512
512/512 - 0s - loss: 2.8172e-04 - val_loss: 2.8150e-06
Epoch 194/512
512/512 - 0s - loss: 2.8011e-04 - val_loss: 2.7571e-06
Epoch 195/512
512/512 - 0s - loss: 2.7525e-04 - val_loss: 2.6863e-06
Epoch 196/512
512/512 - 0s - loss: 2.6985e-04 - val_loss: 2.6861e-06
Epoch 197/512
512/512 - 0s - loss: 2.6810e-04 - val_loss: 2.6948e-06
Epoch 198/512
512/512 - 0s - loss: 2.7072e-04 - val_loss: 2.5895e-06
Epoch 199/512
512/512 - 0s - loss: 2.5845e-04 - val_loss: 2.5292e-06
Epoch 200/512
512/512 - 0s - loss: 2.5774e-04 - val_loss: 2.5606e-06
Epoch 201/512
512/512 - 0s - loss: 2.5701e-04 - val_loss: 2.5620e-06
Epoch 202/512
512/512 - 0s - loss: 2.5534e-04 - val_loss: 2.4843e-06
Epoch 203/512
512/512 - 0s - loss: 2.4801e-04 - val_loss: 2.4288e-06
Epoch 204/512
512/512 - 0s - loss: 2.4478e-04 - val_loss: 2.4762e-06
Epoch 205/512
512/512 - 0s - loss: 2.4884e-04 - val_loss: 2.3944e-06
Epoch 206/512
512/512 - 0s - loss: 2.3835e-04 - val_loss: 2.3190e-06
Epoch 207/512
512/512 - 0s - loss: 2.3425e-04 - val_loss: 2.3770e-06
Epoch 208/512
512/512 - 0s - loss: 2.3934e-04 - val_loss: 2.3416e-06
Epoch 209/512
512/512 - 0s - loss: 2.2989e-04 - val_loss: 2.2841e-06
Epoch 210/512
512/512 - 0s - loss: 2.2911e-04 - val_loss: 2.2436e-06
Epoch 211/512
512/512 - 0s - loss: 2.2544e-04 - val_loss: 2.2179e-06
Epoch 212/512
512/512 - 0s - loss: 2.2159e-04 - val_loss: 2.2256e-06
Epoch 213/512
512/512 - 0s - loss: 2.2279e-04 - val_loss: 2.1837e-06
Epoch 214/512
512/512 - 0s - loss: 2.1743e-04 - val_loss: 2.1123e-06
Epoch 215/512
512/512 - 0s - loss: 2.1255e-04 - val_loss: 2.0817e-06
Epoch 216/512
512/512 - 0s - loss: 2.0900e-04 - val_loss: 2.1300e-06
Epoch 217/512
512/512 - 0s - loss: 2.1439e-04 - val_loss: 2.0645e-06
Epoch 218/512
512/512 - 0s - loss: 2.0228e-04 - val_loss: 2.0053e-06
Epoch 219/512
512/512 - 0s - loss: 2.0281e-04 - val_loss: 2.0129e-06
Epoch 220/512
512/512 - 0s - loss: 2.0023e-04 - val_loss: 2.0070e-06
Epoch 221/512
512/512 - 0s - loss: 2.0049e-04 - val_loss: 1.9345e-06
Epoch 222/512
512/512 - 0s - loss: 1.9184e-04 - val_loss: 1.9091e-06
Epoch 223/512
512/512 - 0s - loss: 1.9245e-04 - val_loss: 1.9242e-06
Epoch 224/512
512/512 - 0s - loss: 1.9270e-04 - val_loss: 1.8497e-06
Epoch 225/512
512/512 - 0s - loss: 1.8345e-04 - val_loss: 1.8183e-06
Epoch 226/512
512/512 - 0s - loss: 1.8434e-04 - val_loss: 1.8514e-06
Epoch 227/512
512/512 - 0s - loss: 1.8493e-04 - val_loss: 1.7655e-06
Epoch 228/512
512/512 - 0s - loss: 1.7699e-04 - val_loss: 1.7152e-06
Epoch 229/512
512/512 - 0s - loss: 1.7385e-04 - val_loss: 1.7728e-06
Epoch 230/512
512/512 - 0s - loss: 1.7660e-04 - val_loss: 1.7595e-06
Epoch 231/512
512/512 - 0s - loss: 1.7378e-04 - val_loss: 1.6585e-06
Epoch 232/512
512/512 - 0s - loss: 1.6573e-04 - val_loss: 1.6251e-06
Epoch 233/512
512/512 - 0s - loss: 1.6516e-04 - val_loss: 1.6709e-06
Epoch 234/512
512/512 - 0s - loss: 1.6702e-04 - val_loss: 1.6413e-06
Epoch 235/512
512/512 - 0s - loss: 1.6210e-04 - val_loss: 1.5523e-06
Epoch 236/512
512/512 - 0s - loss: 1.5616e-04 - val_loss: 1.5579e-06
Epoch 237/512
512/512 - 0s - loss: 1.5832e-04 - val_loss: 1.5652e-06
Epoch 238/512
512/512 - 0s - loss: 1.5599e-04 - val_loss: 1.5038e-06
Epoch 239/512
512/512 - 0s - loss: 1.5021e-04 - val_loss: 1.4809e-06
Epoch 240/512
512/512 - 0s - loss: 1.4938e-04 - val_loss: 1.4940e-06
Epoch 241/512
512/512 - 0s - loss: 1.4850e-04 - val_loss: 1.4722e-06
Epoch 242/512
512/512 - 0s - loss: 1.4578e-04 - val_loss: 1.4247e-06
Epoch 243/512
512/512 - 0s - loss: 1.4286e-04 - val_loss: 1.3766e-06
Epoch 244/512
512/512 - 0s - loss: 1.3890e-04 - val_loss: 1.3815e-06
Epoch 245/512
512/512 - 0s - loss: 1.3920e-04 - val_loss: 1.3853e-06
Epoch 246/512
512/512 - 0s - loss: 1.3818e-04 - val_loss: 1.3244e-06
Epoch 247/512
512/512 - 0s - loss: 1.3135e-04 - val_loss: 1.3200e-06
Epoch 248/512
512/512 - 0s - loss: 1.3226e-04 - val_loss: 1.3352e-06
Epoch 249/512
512/512 - 0s - loss: 1.3320e-04 - val_loss: 1.2607e-06
Epoch 250/512
512/512 - 0s - loss: 1.2414e-04 - val_loss: 1.2426e-06
Epoch 251/512
512/512 - 0s - loss: 1.2716e-04 - val_loss: 1.2341e-06
Epoch 252/512
512/512 - 0s - loss: 1.2289e-04 - val_loss: 1.2108e-06
Epoch 253/512
512/512 - 0s - loss: 1.2214e-04 - val_loss: 1.1910e-06
Epoch 254/512
512/512 - 0s - loss: 1.1846e-04 - val_loss: 1.1845e-06
Epoch 255/512
512/512 - 0s - loss: 1.1849e-04 - val_loss: 1.1609e-06
Epoch 256/512
512/512 - 0s - loss: 1.1552e-04 - val_loss: 1.1183e-06
Epoch 257/512
512/512 - 0s - loss: 1.1249e-04 - val_loss: 1.1147e-06
Epoch 258/512
512/512 - 0s - loss: 1.1207e-04 - val_loss: 1.1080e-06
Epoch 259/512
512/512 - 0s - loss: 1.1003e-04 - val_loss: 1.0879e-06
Epoch 260/512
512/512 - 0s - loss: 1.0736e-04 - val_loss: 1.0726e-06
Epoch 261/512
512/512 - 0s - loss: 1.0679e-04 - val_loss: 1.0396e-06
Epoch 262/512
512/512 - 0s - loss: 1.0406e-04 - val_loss: 1.0104e-06
Epoch 263/512
512/512 - 0s - loss: 1.0156e-04 - val_loss: 1.0042e-06
Epoch 264/512
512/512 - 0s - loss: 1.0193e-04 - val_loss: 9.6618e-07
Epoch 265/512
512/512 - 0s - loss: 9.6683e-05 - val_loss: 9.6094e-07
Epoch 266/512
512/512 - 0s - loss: 9.6717e-05 - val_loss: 9.8282e-07
Epoch 267/512
512/512 - 0s - loss: 9.7680e-05 - val_loss: 9.3086e-07
Epoch 268/512
512/512 - 0s - loss: 9.2033e-05 - val_loss: 8.8980e-07
Epoch 269/512
512/512 - 0s - loss: 9.0976e-05 - val_loss: 8.9740e-07
Epoch 270/512
512/512 - 0s - loss: 8.9778e-05 - val_loss: 9.0622e-07
Epoch 271/512
512/512 - 0s - loss: 9.0008e-05 - val_loss: 8.7179e-07
Epoch 272/512
512/512 - 0s - loss: 8.6278e-05 - val_loss: 8.3547e-07
Epoch 273/512
512/512 - 0s - loss: 8.4069e-05 - val_loss: 8.3334e-07
Epoch 274/512
512/512 - 0s - loss: 8.3818e-05 - val_loss: 8.3673e-07
Epoch 275/512
512/512 - 0s - loss: 8.3365e-05 - val_loss: 7.9247e-07
Epoch 276/512
512/512 - 0s - loss: 7.8782e-05 - val_loss: 7.7724e-07
Epoch 277/512
512/512 - 0s - loss: 7.8456e-05 - val_loss: 7.9249e-07
Epoch 278/512
512/512 - 0s - loss: 7.8815e-05 - val_loss: 7.7196e-07
Epoch 279/512
512/512 - 0s - loss: 7.5827e-05 - val_loss: 7.2811e-07
Epoch 280/512
512/512 - 0s - loss: 7.3076e-05 - val_loss: 7.2602e-07
Epoch 281/512
512/512 - 0s - loss: 7.3184e-05 - val_loss: 7.2703e-07
Epoch 282/512
512/512 - 0s - loss: 7.2890e-05 - val_loss: 6.8133e-07
Epoch 283/512
512/512 - 0s - loss: 6.7746e-05 - val_loss: 6.7932e-07
Epoch 284/512
512/512 - 0s - loss: 6.9352e-05 - val_loss: 6.8831e-07
Epoch 285/512
512/512 - 0s - loss: 6.7302e-05 - val_loss: 6.6965e-07
Epoch 286/512
512/512 - 0s - loss: 6.6334e-05 - val_loss: 6.4638e-07
Epoch 287/512
512/512 - 0s - loss: 6.4182e-05 - val_loss: 6.2694e-07
Epoch 288/512
512/512 - 0s - loss: 6.3278e-05 - val_loss: 6.1210e-07
Epoch 289/512
512/512 - 0s - loss: 6.1579e-05 - val_loss: 6.0335e-07
Epoch 290/512
512/512 - 0s - loss: 6.1295e-05 - val_loss: 5.8436e-07
Epoch 291/512
512/512 - 0s - loss: 5.8228e-05 - val_loss: 5.8112e-07
Epoch 292/512
512/512 - 0s - loss: 5.8963e-05 - val_loss: 5.7626e-07
Epoch 293/512
512/512 - 0s - loss: 5.7376e-05 - val_loss: 5.3781e-07
Epoch 294/512
512/512 - 0s - loss: 5.4536e-05 - val_loss: 5.3665e-07
Epoch 295/512
512/512 - 0s - loss: 5.4779e-05 - val_loss: 5.3868e-07
Epoch 296/512
512/512 - 0s - loss: 5.3757e-05 - val_loss: 5.2037e-07
Epoch 297/512
512/512 - 0s - loss: 5.2153e-05 - val_loss: 5.0279e-07
Epoch 298/512
512/512 - 0s - loss: 5.0531e-05 - val_loss: 4.9950e-07
Epoch 299/512
512/512 - 0s - loss: 4.9949e-05 - val_loss: 4.9824e-07
Epoch 300/512
512/512 - 0s - loss: 4.9284e-05 - val_loss: 4.8312e-07
Epoch 301/512
512/512 - 0s - loss: 4.7737e-05 - val_loss: 4.6525e-07
Epoch 302/512
512/512 - 0s - loss: 4.6461e-05 - val_loss: 4.5550e-07
Epoch 303/512
512/512 - 0s - loss: 4.5530e-05 - val_loss: 4.5138e-07
Epoch 304/512
512/512 - 0s - loss: 4.5266e-05 - val_loss: 4.3225e-07
Epoch 305/512
512/512 - 0s - loss: 4.2517e-05 - val_loss: 4.3390e-07
Epoch 306/512
512/512 - 0s - loss: 4.3564e-05 - val_loss: 4.2780e-07
Epoch 307/512
512/512 - 0s - loss: 4.2052e-05 - val_loss: 3.9842e-07
Epoch 308/512
512/512 - 0s - loss: 3.9975e-05 - val_loss: 3.8886e-07
Epoch 309/512
512/512 - 0s - loss: 3.9373e-05 - val_loss: 4.0074e-07
Epoch 310/512
512/512 - 0s - loss: 4.0128e-05 - val_loss: 3.8354e-07
Epoch 311/512
512/512 - 0s - loss: 3.7744e-05 - val_loss: 3.5531e-07
Epoch 312/512
512/512 - 0s - loss: 3.6196e-05 - val_loss: 3.5883e-07
Epoch 313/512
512/512 - 0s - loss: 3.6654e-05 - val_loss: 3.6083e-07
Epoch 314/512
512/512 - 0s - loss: 3.5841e-05 - val_loss: 3.4191e-07
Epoch 315/512
512/512 - 0s - loss: 3.4249e-05 - val_loss: 3.2854e-07
Epoch 316/512
512/512 - 0s - loss: 3.3062e-05 - val_loss: 3.3469e-07
Epoch 317/512
512/512 - 0s - loss: 3.3706e-05 - val_loss: 3.2755e-07
Epoch 318/512
512/512 - 0s - loss: 3.2641e-05 - val_loss: 2.9895e-07
Epoch 319/512
512/512 - 0s - loss: 2.9780e-05 - val_loss: 3.0087e-07
Epoch 320/512
512/512 - 0s - loss: 3.0901e-05 - val_loss: 3.1645e-07
Epoch 321/512
512/512 - 0s - loss: 3.0961e-05 - val_loss: 2.9246e-07
Epoch 322/512
512/512 - 0s - loss: 2.8248e-05 - val_loss: 2.7716e-07
Epoch 323/512
512/512 - 0s - loss: 2.8217e-05 - val_loss: 2.8164e-07
Epoch 324/512
512/512 - 0s - loss: 2.8103e-05 - val_loss: 2.7508e-07
Epoch 325/512
512/512 - 0s - loss: 2.7170e-05 - val_loss: 2.5900e-07
Epoch 326/512
512/512 - 0s - loss: 2.5810e-05 - val_loss: 2.5714e-07
Epoch 327/512
512/512 - 0s - loss: 2.5828e-05 - val_loss: 2.5550e-07
Epoch 328/512
512/512 - 0s - loss: 2.5307e-05 - val_loss: 2.4485e-07
Epoch 329/512
512/512 - 0s - loss: 2.4158e-05 - val_loss: 2.3419e-07
Epoch 330/512
512/512 - 0s - loss: 2.3701e-05 - val_loss: 2.3248e-07
Epoch 331/512
512/512 - 0s - loss: 2.3186e-05 - val_loss: 2.2863e-07
Epoch 332/512
512/512 - 0s - loss: 2.2902e-05 - val_loss: 2.1778e-07
Epoch 333/512
512/512 - 0s - loss: 2.1637e-05 - val_loss: 2.1264e-07
Epoch 334/512
512/512 - 0s - loss: 2.1382e-05 - val_loss: 2.1181e-07
Epoch 335/512
512/512 - 0s - loss: 2.1278e-05 - val_loss: 2.0073e-07
Epoch 336/512
512/512 - 0s - loss: 1.9846e-05 - val_loss: 1.9690e-07
Epoch 337/512
512/512 - 0s - loss: 1.9985e-05 - val_loss: 1.9593e-07
Epoch 338/512
512/512 - 0s - loss: 1.9332e-05 - val_loss: 1.9168e-07
Epoch 339/512
512/512 - 0s - loss: 1.8916e-05 - val_loss: 1.8209e-07
Epoch 340/512
512/512 - 0s - loss: 1.8237e-05 - val_loss: 1.7348e-07
Epoch 341/512
512/512 - 0s - loss: 1.7454e-05 - val_loss: 1.7412e-07
Epoch 342/512
512/512 - 0s - loss: 1.7628e-05 - val_loss: 1.7153e-07
Epoch 343/512
512/512 - 0s - loss: 1.6987e-05 - val_loss: 1.6037e-07
Epoch 344/512
512/512 - 0s - loss: 1.5857e-05 - val_loss: 1.6166e-07
Epoch 345/512
512/512 - 0s - loss: 1.6409e-05 - val_loss: 1.5985e-07
Epoch 346/512
512/512 - 0s - loss: 1.5740e-05 - val_loss: 1.4607e-07
Epoch 347/512
512/512 - 0s - loss: 1.4415e-05 - val_loss: 1.4776e-07
Epoch 348/512
512/512 - 0s - loss: 1.5180e-05 - val_loss: 1.4739e-07
Epoch 349/512
512/512 - 0s - loss: 1.4486e-05 - val_loss: 1.3502e-07
Epoch 350/512
512/512 - 0s - loss: 1.3370e-05 - val_loss: 1.3478e-07
Epoch 351/512
512/512 - 0s - loss: 1.3696e-05 - val_loss: 1.3714e-07
Epoch 352/512
512/512 - 0s - loss: 1.3607e-05 - val_loss: 1.2569e-07
Epoch 353/512
512/512 - 0s - loss: 1.2337e-05 - val_loss: 1.2145e-07
Epoch 354/512
512/512 - 0s - loss: 1.2283e-05 - val_loss: 1.2674e-07
Epoch 355/512
512/512 - 0s - loss: 1.2558e-05 - val_loss: 1.2083e-07
Epoch 356/512
512/512 - 0s - loss: 1.1784e-05 - val_loss: 1.0900e-07
Epoch 357/512
512/512 - 0s - loss: 1.0925e-05 - val_loss: 1.1067e-07
Epoch 358/512
512/512 - 0s - loss: 1.1307e-05 - val_loss: 1.1342e-07
Epoch 359/512
512/512 - 0s - loss: 1.1112e-05 - val_loss: 1.0353e-07
Epoch 360/512
512/512 - 0s - loss: 1.0188e-05 - val_loss: 9.8286e-08
Epoch 361/512
512/512 - 0s - loss: 9.9993e-06 - val_loss: 1.0276e-07
Epoch 362/512
512/512 - 0s - loss: 1.0236e-05 - val_loss: 9.9309e-08
Epoch 363/512
512/512 - 0s - loss: 9.6165e-06 - val_loss: 9.0928e-08
Epoch 364/512
512/512 - 0s - loss: 9.0971e-06 - val_loss: 9.0685e-08
Epoch 365/512
512/512 - 0s - loss: 9.1805e-06 - val_loss: 9.0460e-08
Epoch 366/512
512/512 - 0s - loss: 8.9327e-06 - val_loss: 8.5212e-08
Epoch 367/512
512/512 - 0s - loss: 8.3569e-06 - val_loss: 8.3475e-08
Epoch 368/512
512/512 - 0s - loss: 8.4837e-06 - val_loss: 8.1562e-08
Epoch 369/512
512/512 - 0s - loss: 8.0276e-06 - val_loss: 7.7622e-08
Epoch 370/512
512/512 - 0s - loss: 7.7478e-06 - val_loss: 7.6607e-08
Epoch 371/512
512/512 - 0s - loss: 7.7157e-06 - val_loss: 7.3994e-08
Epoch 372/512
512/512 - 0s - loss: 7.2899e-06 - val_loss: 7.1924e-08
Epoch 373/512
512/512 - 0s - loss: 7.1526e-06 - val_loss: 7.1630e-08
Epoch 374/512
512/512 - 0s - loss: 7.1139e-06 - val_loss: 6.7645e-08
Epoch 375/512
512/512 - 0s - loss: 6.6754e-06 - val_loss: 6.4130e-08
Epoch 376/512
512/512 - 0s - loss: 6.4811e-06 - val_loss: 6.4011e-08
Epoch 377/512
512/512 - 0s - loss: 6.4490e-06 - val_loss: 6.2229e-08
Epoch 378/512
512/512 - 0s - loss: 6.1243e-06 - val_loss: 5.9762e-08
Epoch 379/512
512/512 - 0s - loss: 6.0200e-06 - val_loss: 5.7835e-08
Epoch 380/512
512/512 - 0s - loss: 5.7545e-06 - val_loss: 5.6878e-08
Epoch 381/512
512/512 - 0s - loss: 5.6757e-06 - val_loss: 5.5232e-08
Epoch 382/512
512/512 - 0s - loss: 5.4749e-06 - val_loss: 5.2917e-08
Epoch 383/512
512/512 - 0s - loss: 5.2675e-06 - val_loss: 5.1711e-08
Epoch 384/512
512/512 - 0s - loss: 5.2563e-06 - val_loss: 4.8457e-08
Epoch 385/512
512/512 - 0s - loss: 4.8359e-06 - val_loss: 4.7474e-08
Epoch 386/512
512/512 - 0s - loss: 4.8262e-06 - val_loss: 4.8639e-08
Epoch 387/512
512/512 - 0s - loss: 4.8430e-06 - val_loss: 4.5596e-08
Epoch 388/512
512/512 - 0s - loss: 4.4509e-06 - val_loss: 4.3234e-08
Epoch 389/512
512/512 - 0s - loss: 4.3751e-06 - val_loss: 4.3681e-08
Epoch 390/512
512/512 - 0s - loss: 4.3332e-06 - val_loss: 4.2594e-08
Epoch 391/512
512/512 - 0s - loss: 4.1653e-06 - val_loss: 3.9882e-08
Epoch 392/512
512/512 - 0s - loss: 3.9725e-06 - val_loss: 3.8448e-08
Epoch 393/512
512/512 - 0s - loss: 3.8803e-06 - val_loss: 3.8405e-08
Epoch 394/512
512/512 - 0s - loss: 3.8317e-06 - val_loss: 3.6492e-08
Epoch 395/512
512/512 - 0s - loss: 3.6099e-06 - val_loss: 3.5257e-08
Epoch 396/512
512/512 - 0s - loss: 3.5787e-06 - val_loss: 3.4259e-08
Epoch 397/512
512/512 - 0s - loss: 3.4296e-06 - val_loss: 3.3099e-08
Epoch 398/512
512/512 - 0s - loss: 3.3350e-06 - val_loss: 3.2018e-08
Epoch 399/512
512/512 - 0s - loss: 3.2318e-06 - val_loss: 3.0711e-08
Epoch 400/512
512/512 - 0s - loss: 3.0920e-06 - val_loss: 3.0461e-08
Epoch 401/512
512/512 - 0s - loss: 3.0440e-06 - val_loss: 2.9943e-08
Epoch 402/512
512/512 - 0s - loss: 2.9569e-06 - val_loss: 2.8634e-08
Epoch 403/512
512/512 - 0s - loss: 2.8306e-06 - val_loss: 2.7326e-08
Epoch 404/512
512/512 - 0s - loss: 2.7441e-06 - val_loss: 2.6944e-08
Epoch 405/512
512/512 - 0s - loss: 2.7040e-06 - val_loss: 2.5736e-08
Epoch 406/512
512/512 - 0s - loss: 2.5686e-06 - val_loss: 2.4512e-08
Epoch 407/512
512/512 - 0s - loss: 2.4476e-06 - val_loss: 2.4832e-08
Epoch 408/512
512/512 - 0s - loss: 2.5202e-06 - val_loss: 2.3621e-08
Epoch 409/512
512/512 - 0s - loss: 2.3278e-06 - val_loss: 2.1798e-08
Epoch 410/512
512/512 - 0s - loss: 2.2105e-06 - val_loss: 2.2025e-08
Epoch 411/512
512/512 - 0s - loss: 2.2421e-06 - val_loss: 2.2011e-08
Epoch 412/512
512/512 - 0s - loss: 2.1506e-06 - val_loss: 2.0695e-08
Epoch 413/512
512/512 - 0s - loss: 2.0496e-06 - val_loss: 1.9731e-08
Epoch 414/512
512/512 - 0s - loss: 1.9964e-06 - val_loss: 1.9112e-08
Epoch 415/512
512/512 - 0s - loss: 1.9090e-06 - val_loss: 1.9107e-08
Epoch 416/512
512/512 - 0s - loss: 1.9147e-06 - val_loss: 1.8461e-08
Epoch 417/512
512/512 - 0s - loss: 1.8044e-06 - val_loss: 1.7426e-08
Epoch 418/512
512/512 - 0s - loss: 1.7320e-06 - val_loss: 1.7221e-08
Epoch 419/512
512/512 - 0s - loss: 1.7342e-06 - val_loss: 1.6485e-08
Epoch 420/512
512/512 - 0s - loss: 1.6253e-06 - val_loss: 1.5745e-08
Epoch 421/512
512/512 - 0s - loss: 1.5914e-06 - val_loss: 1.5432e-08
Epoch 422/512
512/512 - 0s - loss: 1.5332e-06 - val_loss: 1.5314e-08
Epoch 423/512
512/512 - 0s - loss: 1.5127e-06 - val_loss: 1.4710e-08
Epoch 424/512
512/512 - 0s - loss: 1.4673e-06 - val_loss: 1.3493e-08
Epoch 425/512
512/512 - 0s - loss: 1.3396e-06 - val_loss: 1.3403e-08
Epoch 426/512
512/512 - 0s - loss: 1.3685e-06 - val_loss: 1.3739e-08
Epoch 427/512
512/512 - 0s - loss: 1.3549e-06 - val_loss: 1.2519e-08
Epoch 428/512
512/512 - 0s - loss: 1.2267e-06 - val_loss: 1.1808e-08
Epoch 429/512
512/512 - 0s - loss: 1.2212e-06 - val_loss: 1.1934e-08
Epoch 430/512
512/512 - 0s - loss: 1.1948e-06 - val_loss: 1.1652e-08
Epoch 431/512
512/512 - 0s - loss: 1.1590e-06 - val_loss: 1.0998e-08
Epoch 432/512
512/512 - 0s - loss: 1.0956e-06 - val_loss: 1.0626e-08
Epoch 433/512
512/512 - 0s - loss: 1.0847e-06 - val_loss: 1.0212e-08
Epoch 434/512
512/512 - 0s - loss: 1.0248e-06 - val_loss: 9.9520e-09
Epoch 435/512
512/512 - 0s - loss: 9.9334e-07 - val_loss: 1.0155e-08
Epoch 436/512
512/512 - 0s - loss: 1.0046e-06 - val_loss: 9.5201e-09
Epoch 437/512
512/512 - 0s - loss: 9.2979e-07 - val_loss: 8.8243e-09
Epoch 438/512
512/512 - 0s - loss: 8.9099e-07 - val_loss: 8.8914e-09
Epoch 439/512
512/512 - 0s - loss: 8.9006e-07 - val_loss: 8.7633e-09
Epoch 440/512
512/512 - 0s - loss: 8.6420e-07 - val_loss: 8.1775e-09
Epoch 441/512
512/512 - 0s - loss: 8.0943e-07 - val_loss: 7.8332e-09
Epoch 442/512
512/512 - 0s - loss: 7.9634e-07 - val_loss: 7.6737e-09
Epoch 443/512
512/512 - 0s - loss: 7.6606e-07 - val_loss: 7.5439e-09
Epoch 444/512
512/512 - 0s - loss: 7.5073e-07 - val_loss: 7.2803e-09
Epoch 445/512
512/512 - 0s - loss: 7.2356e-07 - val_loss: 6.8345e-09
Epoch 446/512
512/512 - 0s - loss: 6.7861e-07 - val_loss: 6.7882e-09
Epoch 447/512
512/512 - 0s - loss: 6.8302e-07 - val_loss: 6.6917e-09
Epoch 448/512
512/512 - 0s - loss: 6.5789e-07 - val_loss: 6.2771e-09
Epoch 449/512
512/512 - 0s - loss: 6.1958e-07 - val_loss: 6.0509e-09
Epoch 450/512
512/512 - 0s - loss: 6.0980e-07 - val_loss: 5.9419e-09
Epoch 451/512
512/512 - 0s - loss: 5.9338e-07 - val_loss: 5.6809e-09
Epoch 452/512
512/512 - 0s - loss: 5.5958e-07 - val_loss: 5.5644e-09
Epoch 453/512
512/512 - 0s - loss: 5.5409e-07 - val_loss: 5.4227e-09
Epoch 454/512
512/512 - 0s - loss: 5.3363e-07 - val_loss: 5.2018e-09
Epoch 455/512
512/512 - 0s - loss: 5.1297e-07 - val_loss: 4.9851e-09
Epoch 456/512
512/512 - 0s - loss: 4.9795e-07 - val_loss: 4.7297e-09
Epoch 457/512
512/512 - 0s - loss: 4.7506e-07 - val_loss: 4.6038e-09
Epoch 458/512
512/512 - 0s - loss: 4.6476e-07 - val_loss: 4.5837e-09
Epoch 459/512
512/512 - 0s - loss: 4.5633e-07 - val_loss: 4.3400e-09
Epoch 460/512
512/512 - 0s - loss: 4.2611e-07 - val_loss: 4.1653e-09
Epoch 461/512
512/512 - 0s - loss: 4.2045e-07 - val_loss: 4.0990e-09
Epoch 462/512
512/512 - 0s - loss: 4.0896e-07 - val_loss: 3.8752e-09
Epoch 463/512
512/512 - 0s - loss: 3.8517e-07 - val_loss: 3.8038e-09
Epoch 464/512
512/512 - 0s - loss: 3.8210e-07 - val_loss: 3.6921e-09
Epoch 465/512
512/512 - 0s - loss: 3.6649e-07 - val_loss: 3.5217e-09
Epoch 466/512
512/512 - 0s - loss: 3.5032e-07 - val_loss: 3.4160e-09
Epoch 467/512
512/512 - 0s - loss: 3.4214e-07 - val_loss: 3.3478e-09
Epoch 468/512
512/512 - 0s - loss: 3.3256e-07 - val_loss: 3.2114e-09
Epoch 469/512
512/512 - 0s - loss: 3.1933e-07 - val_loss: 3.0421e-09
Epoch 470/512
512/512 - 0s - loss: 3.0017e-07 - val_loss: 3.0605e-09
Epoch 471/512
512/512 - 0s - loss: 3.1151e-07 - val_loss: 2.8703e-09
Epoch 472/512
512/512 - 0s - loss: 2.8400e-07 - val_loss: 2.6450e-09
Epoch 473/512
512/512 - 0s - loss: 2.6704e-07 - val_loss: 2.7230e-09
Epoch 474/512
512/512 - 0s - loss: 2.7836e-07 - val_loss: 2.7081e-09
Epoch 475/512
512/512 - 0s - loss: 2.6421e-07 - val_loss: 2.4248e-09
Epoch 476/512
512/512 - 0s - loss: 2.4074e-07 - val_loss: 2.3809e-09
Epoch 477/512
512/512 - 0s - loss: 2.4518e-07 - val_loss: 2.3896e-09
Epoch 478/512
512/512 - 0s - loss: 2.3711e-07 - val_loss: 2.2647e-09
Epoch 479/512
512/512 - 0s - loss: 2.2461e-07 - val_loss: 2.1739e-09
Epoch 480/512
512/512 - 0s - loss: 2.1893e-07 - val_loss: 2.0977e-09
Epoch 481/512
512/512 - 0s - loss: 2.0921e-07 - val_loss: 2.0663e-09
Epoch 482/512
512/512 - 0s - loss: 2.0706e-07 - val_loss: 1.9909e-09
Epoch 483/512
512/512 - 0s - loss: 1.9873e-07 - val_loss: 1.8559e-09
Epoch 484/512
512/512 - 0s - loss: 1.8623e-07 - val_loss: 1.8072e-09
Epoch 485/512
512/512 - 0s - loss: 1.8478e-07 - val_loss: 1.7952e-09
Epoch 486/512
512/512 - 0s - loss: 1.7899e-07 - val_loss: 1.7312e-09
Epoch 487/512
512/512 - 0s - loss: 1.7076e-07 - val_loss: 1.6665e-09
Epoch 488/512
512/512 - 0s - loss: 1.6550e-07 - val_loss: 1.6208e-09
Epoch 489/512
512/512 - 0s - loss: 1.6113e-07 - val_loss: 1.5561e-09
Epoch 490/512
512/512 - 0s - loss: 1.5330e-07 - val_loss: 1.5151e-09
Epoch 491/512
512/512 - 0s - loss: 1.5206e-07 - val_loss: 1.4406e-09
Epoch 492/512
512/512 - 0s - loss: 1.4236e-07 - val_loss: 1.3811e-09
Epoch 493/512
512/512 - 0s - loss: 1.3847e-07 - val_loss: 1.3699e-09
Epoch 494/512
512/512 - 0s - loss: 1.3763e-07 - val_loss: 1.2929e-09
Epoch 495/512
512/512 - 0s - loss: 1.2885e-07 - val_loss: 1.2312e-09
Epoch 496/512
512/512 - 0s - loss: 1.2387e-07 - val_loss: 1.2127e-09
Epoch 497/512
512/512 - 0s - loss: 1.2245e-07 - val_loss: 1.1876e-09
Epoch 498/512
512/512 - 0s - loss: 1.1862e-07 - val_loss: 1.1197e-09
Epoch 499/512
512/512 - 0s - loss: 1.1157e-07 - val_loss: 1.0732e-09
Epoch 500/512
512/512 - 0s - loss: 1.0815e-07 - val_loss: 1.0774e-09
Epoch 501/512
512/512 - 0s - loss: 1.0866e-07 - val_loss: 1.0235e-09
Epoch 502/512
512/512 - 0s - loss: 1.0075e-07 - val_loss: 9.4773e-10
Epoch 503/512
512/512 - 0s - loss: 9.6127e-08 - val_loss: 9.5663e-10
Epoch 504/512
512/512 - 0s - loss: 9.7012e-08 - val_loss: 9.3123e-10
Epoch 505/512
512/512 - 0s - loss: 9.2242e-08 - val_loss: 8.7398e-10
Epoch 506/512
512/512 - 0s - loss: 8.7541e-08 - val_loss: 8.5218e-10
Epoch 507/512
512/512 - 0s - loss: 8.6086e-08 - val_loss: 8.3238e-10
Epoch 508/512
512/512 - 0s - loss: 8.3447e-08 - val_loss: 7.9236e-10
Epoch 509/512
512/512 - 0s - loss: 7.8848e-08 - val_loss: 7.6445e-10
Epoch 510/512
512/512 - 0s - loss: 7.7361e-08 - val_loss: 7.4625e-10
Epoch 511/512
512/512 - 0s - loss: 7.5253e-08 - val_loss: 7.1204e-10
Epoch 512/512
512/512 - 0s - loss: 7.0858e-08 - val_loss: 6.8965e-10
2024-04-09 15:16:00.393906: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
Train on 512 samples, validate on 512 samples
Epoch 1/512

Epoch 00001: val_loss improved from inf to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.9246e-08 - val_loss: 4.0761e-08
Epoch 2/512

Epoch 00002: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7998e-08 - val_loss: 6.5802e-08
Epoch 3/512

Epoch 00003: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.6651e-08 - val_loss: 7.6406e-08
Epoch 4/512

Epoch 00004: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5185e-08 - val_loss: 4.6737e-08
Epoch 5/512

Epoch 00005: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4311e-08 - val_loss: 4.5328e-08
Epoch 6/512

Epoch 00006: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2612e-08 - val_loss: 6.2784e-08
Epoch 7/512

Epoch 00007: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.3380e-08 - val_loss: 5.4962e-08
Epoch 8/512

Epoch 00008: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9240e-08 - val_loss: 4.1445e-08
Epoch 9/512

Epoch 00009: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2508e-08 - val_loss: 4.6104e-08
Epoch 10/512

Epoch 00010: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0282e-08 - val_loss: 5.2342e-08
Epoch 11/512

Epoch 00011: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0213e-08 - val_loss: 4.3278e-08
Epoch 12/512

Epoch 00012: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.1140e-08 - val_loss: 3.8517e-08
Epoch 13/512

Epoch 00013: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0395e-08 - val_loss: 4.2815e-08
Epoch 14/512

Epoch 00014: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4155e-08 - val_loss: 4.2519e-08
Epoch 15/512

Epoch 00015: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.0769e-08 - val_loss: 3.6493e-08
Epoch 16/512

Epoch 00016: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.6049e-08 - val_loss: 3.5466e-08
Epoch 17/512

Epoch 00017: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6884e-08 - val_loss: 3.7558e-08
Epoch 18/512

Epoch 00018: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.7577e-08 - val_loss: 3.5199e-08
Epoch 19/512

Epoch 00019: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.4200e-08 - val_loss: 3.1919e-08
Epoch 20/512

Epoch 00020: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2157e-08 - val_loss: 3.1923e-08
Epoch 21/512

Epoch 00021: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2612e-08 - val_loss: 3.2117e-08
Epoch 22/512

Epoch 00022: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1844e-08 - val_loss: 2.9923e-08
Epoch 23/512

Epoch 00023: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9530e-08 - val_loss: 2.8213e-08
Epoch 24/512

Epoch 00024: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8475e-08 - val_loss: 2.8021e-08
Epoch 25/512

Epoch 00025: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8279e-08 - val_loss: 2.7407e-08
Epoch 26/512

Epoch 00026: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7225e-08 - val_loss: 2.5817e-08
Epoch 27/512

Epoch 00027: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5680e-08 - val_loss: 2.4711e-08
Epoch 28/512

Epoch 00028: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4908e-08 - val_loss: 2.4442e-08
Epoch 29/512

Epoch 00029: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4570e-08 - val_loss: 2.3666e-08
Epoch 30/512

Epoch 00030: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3498e-08 - val_loss: 2.2348e-08
Epoch 31/512

Epoch 00031: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2303e-08 - val_loss: 2.1577e-08
Epoch 32/512

Epoch 00032: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1724e-08 - val_loss: 2.1192e-08
Epoch 33/512

Epoch 00033: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1248e-08 - val_loss: 2.0446e-08
Epoch 34/512

Epoch 00034: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0331e-08 - val_loss: 1.9466e-08
Epoch 35/512

Epoch 00035: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9459e-08 - val_loss: 1.8844e-08
Epoch 36/512

Epoch 00036: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8940e-08 - val_loss: 1.8406e-08
Epoch 37/512

Epoch 00037: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8393e-08 - val_loss: 1.7684e-08
Epoch 38/512

Epoch 00038: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7656e-08 - val_loss: 1.6934e-08
Epoch 39/512

Epoch 00039: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6955e-08 - val_loss: 1.6414e-08
Epoch 40/512

Epoch 00040: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6436e-08 - val_loss: 1.5909e-08
Epoch 41/512

Epoch 00041: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5957e-08 - val_loss: 1.5390e-08
Epoch 42/512

Epoch 00042: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5344e-08 - val_loss: 1.4749e-08
Epoch 43/512

Epoch 00043: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4781e-08 - val_loss: 1.4275e-08
Epoch 44/512

Epoch 00044: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4317e-08 - val_loss: 1.3823e-08
Epoch 45/512

Epoch 00045: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3834e-08 - val_loss: 1.3384e-08
Epoch 46/512

Epoch 00046: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3386e-08 - val_loss: 1.2901e-08
Epoch 47/512

Epoch 00047: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2873e-08 - val_loss: 1.2388e-08
Epoch 48/512

Epoch 00048: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2422e-08 - val_loss: 1.2078e-08
Epoch 49/512

Epoch 00049: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2095e-08 - val_loss: 1.1681e-08
Epoch 50/512

Epoch 00050: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1681e-08 - val_loss: 1.1217e-08
Epoch 51/512

Epoch 00051: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1198e-08 - val_loss: 1.0845e-08
Epoch 52/512

Epoch 00052: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0875e-08 - val_loss: 1.0502e-08
Epoch 53/512

Epoch 00053: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0493e-08 - val_loss: 1.0123e-08
Epoch 54/512

Epoch 00054: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0167e-08 - val_loss: 9.8671e-09
Epoch 55/512

Epoch 00055: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.8469e-09 - val_loss: 9.4610e-09
Epoch 56/512

Epoch 00056: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.4564e-09 - val_loss: 9.1388e-09
Epoch 57/512

Epoch 00057: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.1619e-09 - val_loss: 8.8887e-09
Epoch 58/512

Epoch 00058: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.9061e-09 - val_loss: 8.6026e-09
Epoch 59/512

Epoch 00059: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.5913e-09 - val_loss: 8.2502e-09
Epoch 60/512

Epoch 00060: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.2259e-09 - val_loss: 7.9738e-09
Epoch 61/512

Epoch 00061: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.0264e-09 - val_loss: 7.8046e-09
Epoch 62/512

Epoch 00062: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.8093e-09 - val_loss: 7.5301e-09
Epoch 63/512

Epoch 00063: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.5298e-09 - val_loss: 7.2731e-09
Epoch 64/512

Epoch 00064: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.2761e-09 - val_loss: 7.0186e-09
Epoch 65/512

Epoch 00065: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.0124e-09 - val_loss: 6.7907e-09
Epoch 66/512

Epoch 00066: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.8287e-09 - val_loss: 6.6342e-09
Epoch 67/512

Epoch 00067: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.6205e-09 - val_loss: 6.3619e-09
Epoch 68/512

Epoch 00068: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.3561e-09 - val_loss: 6.1555e-09
Epoch 69/512

Epoch 00069: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.1858e-09 - val_loss: 5.9945e-09
Epoch 70/512

Epoch 00070: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.9857e-09 - val_loss: 5.7828e-09
Epoch 71/512

Epoch 00071: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.8000e-09 - val_loss: 5.6217e-09
Epoch 72/512

Epoch 00072: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.6241e-09 - val_loss: 5.4578e-09
Epoch 73/512

Epoch 00073: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.4633e-09 - val_loss: 5.2617e-09
Epoch 74/512

Epoch 00074: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.2441e-09 - val_loss: 5.0620e-09
Epoch 75/512

Epoch 00075: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.0662e-09 - val_loss: 4.9361e-09
Epoch 76/512

Epoch 00076: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.9606e-09 - val_loss: 4.8282e-09
Epoch 77/512

Epoch 00077: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.8283e-09 - val_loss: 4.6505e-09
Epoch 78/512

Epoch 00078: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.6593e-09 - val_loss: 4.5038e-09
Epoch 79/512

Epoch 00079: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.5012e-09 - val_loss: 4.3604e-09
Epoch 80/512

Epoch 00080: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.3483e-09 - val_loss: 4.2160e-09
Epoch 81/512

Epoch 00081: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.2395e-09 - val_loss: 4.1475e-09
Epoch 82/512

Epoch 00082: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.1498e-09 - val_loss: 3.9947e-09
Epoch 83/512

Epoch 00083: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.0047e-09 - val_loss: 3.8737e-09
Epoch 84/512

Epoch 00084: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.8692e-09 - val_loss: 3.7391e-09
Epoch 85/512

Epoch 00085: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.7448e-09 - val_loss: 3.6575e-09
Epoch 86/512

Epoch 00086: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.6654e-09 - val_loss: 3.5495e-09
Epoch 87/512

Epoch 00087: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.5772e-09 - val_loss: 3.4629e-09
Epoch 88/512

Epoch 00088: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.4519e-09 - val_loss: 3.3434e-09
Epoch 89/512

Epoch 00089: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3467e-09 - val_loss: 3.2587e-09
Epoch 90/512

Epoch 00090: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.2539e-09 - val_loss: 3.1576e-09
Epoch 91/512

Epoch 00091: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1597e-09 - val_loss: 3.0604e-09
Epoch 92/512

Epoch 00092: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.0729e-09 - val_loss: 2.9951e-09
Epoch 93/512

Epoch 00093: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.0016e-09 - val_loss: 2.9156e-09
Epoch 94/512

Epoch 00094: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9218e-09 - val_loss: 2.8413e-09
Epoch 95/512

Epoch 00095: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8423e-09 - val_loss: 2.7507e-09
Epoch 96/512

Epoch 00096: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7402e-09 - val_loss: 2.6492e-09
Epoch 97/512

Epoch 00097: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6605e-09 - val_loss: 2.5923e-09
Epoch 98/512

Epoch 00098: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5974e-09 - val_loss: 2.5417e-09
Epoch 99/512

Epoch 00099: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5500e-09 - val_loss: 2.4780e-09
Epoch 100/512

Epoch 00100: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4693e-09 - val_loss: 2.4000e-09
Epoch 101/512

Epoch 00101: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3906e-09 - val_loss: 2.3041e-09
Epoch 102/512

Epoch 00102: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3077e-09 - val_loss: 2.2513e-09
Epoch 103/512

Epoch 00103: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2644e-09 - val_loss: 2.2422e-09
Epoch 104/512

Epoch 00104: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2498e-09 - val_loss: 2.1948e-09
Epoch 105/512

Epoch 00105: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1757e-09 - val_loss: 2.0823e-09
Epoch 106/512

Epoch 00106: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0880e-09 - val_loss: 2.0251e-09
Epoch 107/512

Epoch 00107: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0390e-09 - val_loss: 2.0007e-09
Epoch 108/512

Epoch 00108: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0157e-09 - val_loss: 1.9733e-09
Epoch 109/512

Epoch 00109: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9615e-09 - val_loss: 1.8997e-09
Epoch 110/512

Epoch 00110: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8935e-09 - val_loss: 1.8390e-09
Epoch 111/512

Epoch 00111: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8374e-09 - val_loss: 1.8005e-09
Epoch 112/512

Epoch 00112: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8056e-09 - val_loss: 1.7651e-09
Epoch 113/512

Epoch 00113: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7770e-09 - val_loss: 1.7300e-09
Epoch 114/512

Epoch 00114: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7366e-09 - val_loss: 1.6949e-09
Epoch 115/512

Epoch 00115: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6933e-09 - val_loss: 1.6418e-09
Epoch 116/512

Epoch 00116: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6454e-09 - val_loss: 1.6019e-09
Epoch 117/512

Epoch 00117: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6102e-09 - val_loss: 1.5683e-09
Epoch 118/512

Epoch 00118: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5578e-09 - val_loss: 1.5161e-09
Epoch 119/512

Epoch 00119: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5156e-09 - val_loss: 1.4786e-09
Epoch 120/512

Epoch 00120: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4781e-09 - val_loss: 1.4548e-09
Epoch 121/512

Epoch 00121: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4566e-09 - val_loss: 1.4349e-09
Epoch 122/512

Epoch 00122: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4437e-09 - val_loss: 1.4133e-09
Epoch 123/512

Epoch 00123: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4125e-09 - val_loss: 1.3763e-09
Epoch 124/512

Epoch 00124: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3748e-09 - val_loss: 1.3438e-09
Epoch 125/512

Epoch 00125: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3426e-09 - val_loss: 1.3191e-09
Epoch 126/512

Epoch 00126: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3151e-09 - val_loss: 1.2842e-09
Epoch 127/512

Epoch 00127: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2817e-09 - val_loss: 1.2517e-09
Epoch 128/512

Epoch 00128: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2491e-09 - val_loss: 1.2276e-09
Epoch 129/512

Epoch 00129: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2175e-09 - val_loss: 1.1854e-09
Epoch 130/512

Epoch 00130: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1863e-09 - val_loss: 1.1790e-09
Epoch 131/512

Epoch 00131: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1856e-09 - val_loss: 1.1628e-09
Epoch 132/512

Epoch 00132: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1557e-09 - val_loss: 1.1337e-09
Epoch 133/512

Epoch 00133: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1334e-09 - val_loss: 1.1135e-09
Epoch 134/512

Epoch 00134: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1113e-09 - val_loss: 1.0860e-09
Epoch 135/512

Epoch 00135: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0782e-09 - val_loss: 1.0473e-09
Epoch 136/512

Epoch 00136: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0498e-09 - val_loss: 1.0350e-09
Epoch 137/512

Epoch 00137: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0477e-09 - val_loss: 1.0370e-09
Epoch 138/512

Epoch 00138: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0404e-09 - val_loss: 1.0026e-09
Epoch 139/512

Epoch 00139: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.9379e-10 - val_loss: 9.6374e-10
Epoch 140/512

Epoch 00140: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.6379e-10 - val_loss: 9.4831e-10
Epoch 141/512

Epoch 00141: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.5133e-10 - val_loss: 9.3421e-10
Epoch 142/512

Epoch 00142: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.3744e-10 - val_loss: 9.2966e-10
Epoch 143/512

Epoch 00143: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.3141e-10 - val_loss: 9.2282e-10
Epoch 144/512

Epoch 00144: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.2174e-10 - val_loss: 8.9101e-10
Epoch 145/512

Epoch 00145: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.8439e-10 - val_loss: 8.6211e-10
Epoch 146/512

Epoch 00146: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.5722e-10 - val_loss: 8.4457e-10
Epoch 147/512

Epoch 00147: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.4093e-10 - val_loss: 8.2978e-10
Epoch 148/512

Epoch 00148: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.4221e-10 - val_loss: 8.4153e-10
Epoch 149/512

Epoch 00149: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.4481e-10 - val_loss: 8.2491e-10
Epoch 150/512

Epoch 00150: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.2237e-10 - val_loss: 7.9545e-10
Epoch 151/512

Epoch 00151: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.9411e-10 - val_loss: 7.8907e-10
Epoch 152/512

Epoch 00152: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.8986e-10 - val_loss: 7.7924e-10
Epoch 153/512

Epoch 00153: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.7114e-10 - val_loss: 7.4794e-10
Epoch 154/512

Epoch 00154: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.3922e-10 - val_loss: 7.1714e-10
Epoch 155/512

Epoch 00155: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.3005e-10 - val_loss: 7.3490e-10
Epoch 156/512

Epoch 00156: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.4192e-10 - val_loss: 7.2985e-10
Epoch 157/512

Epoch 00157: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.2857e-10 - val_loss: 7.1825e-10
Epoch 158/512

Epoch 00158: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.1684e-10 - val_loss: 7.0630e-10
Epoch 159/512

Epoch 00159: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.0642e-10 - val_loss: 6.9078e-10
Epoch 160/512

Epoch 00160: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.8367e-10 - val_loss: 6.6605e-10
Epoch 161/512

Epoch 00161: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.6927e-10 - val_loss: 6.6608e-10
Epoch 162/512

Epoch 00162: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.6747e-10 - val_loss: 6.4986e-10
Epoch 163/512

Epoch 00163: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.5157e-10 - val_loss: 6.4337e-10
Epoch 164/512

Epoch 00164: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.4070e-10 - val_loss: 6.3392e-10
Epoch 165/512

Epoch 00165: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.3445e-10 - val_loss: 6.2601e-10
Epoch 166/512

Epoch 00166: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.2597e-10 - val_loss: 6.1450e-10
Epoch 167/512

Epoch 00167: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.1452e-10 - val_loss: 5.9528e-10
Epoch 168/512

Epoch 00168: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.9371e-10 - val_loss: 5.8762e-10
Epoch 169/512

Epoch 00169: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.9167e-10 - val_loss: 5.9113e-10
Epoch 170/512

Epoch 00170: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.8892e-10 - val_loss: 5.8147e-10
Epoch 171/512

Epoch 00171: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.8901e-10 - val_loss: 5.7632e-10
Epoch 172/512

Epoch 00172: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.7602e-10 - val_loss: 5.6210e-10
Epoch 173/512

Epoch 00173: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.6159e-10 - val_loss: 5.5540e-10
Epoch 174/512

Epoch 00174: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.5112e-10 - val_loss: 5.4100e-10
Epoch 175/512

Epoch 00175: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4788e-10 - val_loss: 5.4122e-10
Epoch 176/512

Epoch 00176: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.4050e-10 - val_loss: 5.2909e-10
Epoch 177/512

Epoch 00177: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.2675e-10 - val_loss: 5.1774e-10
Epoch 178/512

Epoch 00178: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.1809e-10 - val_loss: 5.1465e-10
Epoch 179/512

Epoch 00179: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.1659e-10 - val_loss: 5.1057e-10
Epoch 180/512

Epoch 00180: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.1126e-10 - val_loss: 5.0182e-10
Epoch 181/512

Epoch 00181: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.0171e-10 - val_loss: 4.9859e-10
Epoch 182/512

Epoch 00182: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.9640e-10 - val_loss: 4.8386e-10
Epoch 183/512

Epoch 00183: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.7778e-10 - val_loss: 4.7096e-10
Epoch 184/512

Epoch 00184: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.7124e-10 - val_loss: 4.7004e-10
Epoch 185/512

Epoch 00185: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7651e-10 - val_loss: 4.8298e-10
Epoch 186/512

Epoch 00186: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8828e-10 - val_loss: 4.8028e-10
Epoch 187/512

Epoch 00187: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.7640e-10 - val_loss: 4.6514e-10
Epoch 188/512

Epoch 00188: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.6297e-10 - val_loss: 4.4986e-10
Epoch 189/512

Epoch 00189: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.5306e-10 - val_loss: 4.4930e-10
Epoch 190/512

Epoch 00190: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.4630e-10 - val_loss: 4.3599e-10
Epoch 191/512

Epoch 00191: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.3573e-10 - val_loss: 4.3111e-10
Epoch 192/512

Epoch 00192: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.3064e-10 - val_loss: 4.1914e-10
Epoch 193/512

Epoch 00193: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2572e-10 - val_loss: 4.3164e-10
Epoch 194/512

Epoch 00194: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2828e-10 - val_loss: 4.1967e-10
Epoch 195/512

Epoch 00195: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.2361e-10 - val_loss: 4.1454e-10
Epoch 196/512

Epoch 00196: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.1712e-10 - val_loss: 4.1448e-10
Epoch 197/512

Epoch 00197: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.1013e-10 - val_loss: 4.0030e-10
Epoch 198/512

Epoch 00198: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.0167e-10 - val_loss: 3.9505e-10
Epoch 199/512

Epoch 00199: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.9845e-10 - val_loss: 3.8989e-10
Epoch 200/512

Epoch 00200: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.8959e-10 - val_loss: 3.8554e-10
Epoch 201/512

Epoch 00201: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.8384e-10 - val_loss: 3.7469e-10
Epoch 202/512

Epoch 00202: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.7412e-10 - val_loss: 3.7322e-10
Epoch 203/512

Epoch 00203: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7628e-10 - val_loss: 3.7744e-10
Epoch 204/512

Epoch 00204: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7722e-10 - val_loss: 3.7438e-10
Epoch 205/512

Epoch 00205: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.7688e-10 - val_loss: 3.7064e-10
Epoch 206/512

Epoch 00206: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.6789e-10 - val_loss: 3.6326e-10
Epoch 207/512

Epoch 00207: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.6272e-10 - val_loss: 3.5840e-10
Epoch 208/512

Epoch 00208: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6270e-10 - val_loss: 3.6399e-10
Epoch 209/512

Epoch 00209: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6298e-10 - val_loss: 3.5844e-10
Epoch 210/512

Epoch 00210: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.5928e-10 - val_loss: 3.5378e-10
Epoch 211/512

Epoch 00211: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.5506e-10 - val_loss: 3.4778e-10
Epoch 212/512

Epoch 00212: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.4766e-10 - val_loss: 3.4388e-10
Epoch 213/512

Epoch 00213: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.4243e-10 - val_loss: 3.3781e-10
Epoch 214/512

Epoch 00214: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4241e-10 - val_loss: 3.3969e-10
Epoch 215/512

Epoch 00215: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4160e-10 - val_loss: 3.3859e-10
Epoch 216/512

Epoch 00216: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3908e-10 - val_loss: 3.3304e-10
Epoch 217/512

Epoch 00217: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3326e-10 - val_loss: 3.2758e-10
Epoch 218/512

Epoch 00218: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.2808e-10 - val_loss: 3.2717e-10
Epoch 219/512

Epoch 00219: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.2648e-10 - val_loss: 3.1838e-10
Epoch 220/512

Epoch 00220: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1328e-10 - val_loss: 3.0848e-10
Epoch 221/512

Epoch 00221: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.0818e-10 - val_loss: 3.0202e-10
Epoch 222/512

Epoch 00222: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.0554e-10 - val_loss: 3.0963e-10
Epoch 223/512

Epoch 00223: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.1454e-10 - val_loss: 3.1406e-10
Epoch 224/512

Epoch 00224: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.1821e-10 - val_loss: 3.1826e-10
Epoch 225/512

Epoch 00225: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.1393e-10 - val_loss: 3.0617e-10
Epoch 226/512

Epoch 00226: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.0373e-10 - val_loss: 2.9782e-10
Epoch 227/512

Epoch 00227: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9676e-10 - val_loss: 2.9244e-10
Epoch 228/512

Epoch 00228: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9069e-10 - val_loss: 2.8730e-10
Epoch 229/512

Epoch 00229: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9047e-10 - val_loss: 2.8965e-10
Epoch 230/512

Epoch 00230: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9398e-10 - val_loss: 2.9730e-10
Epoch 231/512

Epoch 00231: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9705e-10 - val_loss: 2.9950e-10
Epoch 232/512

Epoch 00232: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.0043e-10 - val_loss: 2.9104e-10
Epoch 233/512

Epoch 00233: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8834e-10 - val_loss: 2.8625e-10
Epoch 234/512

Epoch 00234: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8226e-10 - val_loss: 2.7458e-10
Epoch 235/512

Epoch 00235: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7710e-10 - val_loss: 2.7204e-10
Epoch 236/512

Epoch 00236: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7327e-10 - val_loss: 2.7606e-10
Epoch 237/512

Epoch 00237: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7755e-10 - val_loss: 2.7466e-10
Epoch 238/512

Epoch 00238: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7899e-10 - val_loss: 2.8177e-10
Epoch 239/512

Epoch 00239: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7727e-10 - val_loss: 2.7178e-10
Epoch 240/512

Epoch 00240: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7396e-10 - val_loss: 2.6446e-10
Epoch 241/512

Epoch 00241: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6536e-10 - val_loss: 2.6657e-10
Epoch 242/512

Epoch 00242: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6303e-10 - val_loss: 2.5818e-10
Epoch 243/512

Epoch 00243: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6096e-10 - val_loss: 2.5859e-10
Epoch 244/512

Epoch 00244: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5576e-10 - val_loss: 2.5316e-10
Epoch 245/512

Epoch 00245: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5503e-10 - val_loss: 2.5247e-10
Epoch 246/512

Epoch 00246: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5304e-10 - val_loss: 2.5530e-10
Epoch 247/512

Epoch 00247: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5589e-10 - val_loss: 2.5525e-10
Epoch 248/512

Epoch 00248: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5916e-10 - val_loss: 2.5487e-10
Epoch 249/512

Epoch 00249: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5273e-10 - val_loss: 2.5082e-10
Epoch 250/512

Epoch 00250: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5163e-10 - val_loss: 2.4635e-10
Epoch 251/512

Epoch 00251: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4728e-10 - val_loss: 2.5151e-10
Epoch 252/512

Epoch 00252: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4885e-10 - val_loss: 2.4512e-10
Epoch 253/512

Epoch 00253: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4470e-10 - val_loss: 2.4085e-10
Epoch 254/512

Epoch 00254: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3768e-10 - val_loss: 2.3444e-10
Epoch 255/512

Epoch 00255: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3487e-10 - val_loss: 2.3122e-10
Epoch 256/512

Epoch 00256: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3374e-10 - val_loss: 2.3874e-10
Epoch 257/512

Epoch 00257: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3845e-10 - val_loss: 2.3181e-10
Epoch 258/512

Epoch 00258: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3332e-10 - val_loss: 2.3229e-10
Epoch 259/512

Epoch 00259: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3176e-10 - val_loss: 2.3289e-10
Epoch 260/512

Epoch 00260: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3116e-10 - val_loss: 2.2512e-10
Epoch 261/512

Epoch 00261: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2760e-10 - val_loss: 2.3059e-10
Epoch 262/512

Epoch 00262: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3147e-10 - val_loss: 2.2928e-10
Epoch 263/512

Epoch 00263: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3040e-10 - val_loss: 2.2753e-10
Epoch 264/512

Epoch 00264: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2509e-10 - val_loss: 2.2115e-10
Epoch 265/512

Epoch 00265: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1950e-10 - val_loss: 2.1668e-10
Epoch 266/512

Epoch 00266: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1763e-10 - val_loss: 2.1823e-10
Epoch 267/512

Epoch 00267: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1866e-10 - val_loss: 2.1861e-10
Epoch 268/512

Epoch 00268: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1978e-10 - val_loss: 2.1879e-10
Epoch 269/512

Epoch 00269: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2077e-10 - val_loss: 2.1800e-10
Epoch 270/512

Epoch 00270: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1749e-10 - val_loss: 2.1391e-10
Epoch 271/512

Epoch 00271: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1232e-10 - val_loss: 2.1023e-10
Epoch 272/512

Epoch 00272: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0979e-10 - val_loss: 2.0893e-10
Epoch 273/512

Epoch 00273: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0915e-10 - val_loss: 2.1096e-10
Epoch 274/512

Epoch 00274: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1358e-10 - val_loss: 2.1466e-10
Epoch 275/512

Epoch 00275: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1795e-10 - val_loss: 2.1711e-10
Epoch 276/512

Epoch 00276: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1546e-10 - val_loss: 2.0959e-10
Epoch 277/512

Epoch 00277: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1127e-10 - val_loss: 2.0888e-10
Epoch 278/512

Epoch 00278: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0754e-10 - val_loss: 2.0346e-10
Epoch 279/512

Epoch 00279: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0016e-10 - val_loss: 1.9769e-10
Epoch 280/512

Epoch 00280: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9847e-10 - val_loss: 2.0299e-10
Epoch 281/512

Epoch 00281: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0204e-10 - val_loss: 1.9835e-10
Epoch 282/512

Epoch 00282: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9914e-10 - val_loss: 1.9733e-10
Epoch 283/512

Epoch 00283: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9756e-10 - val_loss: 1.9522e-10
Epoch 284/512

Epoch 00284: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9839e-10 - val_loss: 1.9931e-10
Epoch 285/512

Epoch 00285: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9920e-10 - val_loss: 1.9591e-10
Epoch 286/512

Epoch 00286: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9398e-10 - val_loss: 1.9338e-10
Epoch 287/512

Epoch 00287: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9640e-10 - val_loss: 1.9610e-10
Epoch 288/512

Epoch 00288: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9496e-10 - val_loss: 1.9314e-10
Epoch 289/512

Epoch 00289: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9400e-10 - val_loss: 1.9210e-10
Epoch 290/512

Epoch 00290: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9149e-10 - val_loss: 1.9163e-10
Epoch 291/512

Epoch 00291: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9271e-10 - val_loss: 1.8866e-10
Epoch 292/512

Epoch 00292: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8785e-10 - val_loss: 1.8794e-10
Epoch 293/512

Epoch 00293: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8872e-10 - val_loss: 1.8742e-10
Epoch 294/512

Epoch 00294: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8749e-10 - val_loss: 1.8923e-10
Epoch 295/512

Epoch 00295: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8960e-10 - val_loss: 1.8818e-10
Epoch 296/512

Epoch 00296: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8691e-10 - val_loss: 1.8459e-10
Epoch 297/512

Epoch 00297: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8300e-10 - val_loss: 1.8148e-10
Epoch 298/512

Epoch 00298: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8225e-10 - val_loss: 1.8264e-10
Epoch 299/512

Epoch 00299: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8087e-10 - val_loss: 1.8039e-10
Epoch 300/512

Epoch 00300: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8111e-10 - val_loss: 1.7691e-10
Epoch 301/512

Epoch 00301: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7585e-10 - val_loss: 1.7578e-10
Epoch 302/512

Epoch 00302: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7575e-10 - val_loss: 1.7491e-10
Epoch 303/512

Epoch 00303: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7656e-10 - val_loss: 1.7516e-10
Epoch 304/512

Epoch 00304: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7626e-10 - val_loss: 1.7554e-10
Epoch 305/512

Epoch 00305: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7765e-10 - val_loss: 1.7901e-10
Epoch 306/512

Epoch 00306: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7807e-10 - val_loss: 1.7704e-10
Epoch 307/512

Epoch 00307: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7540e-10 - val_loss: 1.7560e-10
Epoch 308/512

Epoch 00308: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7485e-10 - val_loss: 1.7120e-10
Epoch 309/512

Epoch 00309: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7336e-10 - val_loss: 1.7452e-10
Epoch 310/512

Epoch 00310: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7260e-10 - val_loss: 1.6859e-10
Epoch 311/512

Epoch 00311: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6925e-10 - val_loss: 1.6987e-10
Epoch 312/512

Epoch 00312: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6959e-10 - val_loss: 1.7036e-10
Epoch 313/512

Epoch 00313: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7027e-10 - val_loss: 1.6664e-10
Epoch 314/512

Epoch 00314: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6649e-10 - val_loss: 1.6679e-10
Epoch 315/512

Epoch 00315: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6702e-10 - val_loss: 1.6461e-10
Epoch 316/512

Epoch 00316: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6624e-10 - val_loss: 1.6820e-10
Epoch 317/512

Epoch 00317: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6877e-10 - val_loss: 1.6589e-10
Epoch 318/512

Epoch 00318: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6522e-10 - val_loss: 1.6632e-10
Epoch 319/512

Epoch 00319: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6725e-10 - val_loss: 1.6388e-10
Epoch 320/512

Epoch 00320: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6268e-10 - val_loss: 1.6344e-10
Epoch 321/512

Epoch 00321: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6552e-10 - val_loss: 1.6397e-10
Epoch 322/512

Epoch 00322: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6396e-10 - val_loss: 1.6504e-10
Epoch 323/512

Epoch 00323: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6578e-10 - val_loss: 1.6199e-10
Epoch 324/512

Epoch 00324: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6182e-10 - val_loss: 1.6277e-10
Epoch 325/512

Epoch 00325: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6054e-10 - val_loss: 1.5567e-10
Epoch 326/512

Epoch 00326: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5523e-10 - val_loss: 1.5630e-10
Epoch 327/512

Epoch 00327: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5631e-10 - val_loss: 1.5545e-10
Epoch 328/512

Epoch 00328: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5504e-10 - val_loss: 1.5622e-10
Epoch 329/512

Epoch 00329: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5458e-10 - val_loss: 1.5317e-10
Epoch 330/512

Epoch 00330: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5361e-10 - val_loss: 1.5604e-10
Epoch 331/512

Epoch 00331: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5580e-10 - val_loss: 1.5768e-10
Epoch 332/512

Epoch 00332: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6211e-10 - val_loss: 1.6514e-10
Epoch 333/512

Epoch 00333: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6217e-10 - val_loss: 1.5936e-10
Epoch 334/512

Epoch 00334: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6047e-10 - val_loss: 1.6023e-10
Epoch 335/512

Epoch 00335: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5914e-10 - val_loss: 1.5616e-10
Epoch 336/512

Epoch 00336: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5583e-10 - val_loss: 1.5400e-10
Epoch 337/512

Epoch 00337: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5070e-10 - val_loss: 1.4483e-10
Epoch 338/512

Epoch 00338: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4427e-10 - val_loss: 1.4521e-10
Epoch 339/512

Epoch 00339: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4452e-10 - val_loss: 1.4355e-10
Epoch 340/512

Epoch 00340: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4568e-10 - val_loss: 1.5066e-10
Epoch 341/512

Epoch 00341: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4958e-10 - val_loss: 1.5000e-10
Epoch 342/512

Epoch 00342: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5225e-10 - val_loss: 1.5539e-10
Epoch 343/512

Epoch 00343: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5409e-10 - val_loss: 1.5112e-10
Epoch 344/512

Epoch 00344: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4971e-10 - val_loss: 1.5098e-10
Epoch 345/512

Epoch 00345: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5006e-10 - val_loss: 1.4757e-10
Epoch 346/512

Epoch 00346: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4699e-10 - val_loss: 1.4707e-10
Epoch 347/512

Epoch 00347: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4468e-10 - val_loss: 1.4154e-10
Epoch 348/512

Epoch 00348: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4299e-10 - val_loss: 1.4593e-10
Epoch 349/512

Epoch 00349: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4647e-10 - val_loss: 1.4554e-10
Epoch 350/512

Epoch 00350: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4785e-10 - val_loss: 1.5093e-10
Epoch 351/512

Epoch 00351: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4876e-10 - val_loss: 1.4489e-10
Epoch 352/512

Epoch 00352: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4392e-10 - val_loss: 1.4443e-10
Epoch 353/512

Epoch 00353: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4295e-10 - val_loss: 1.4077e-10
Epoch 354/512

Epoch 00354: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4031e-10 - val_loss: 1.4289e-10
Epoch 355/512

Epoch 00355: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4172e-10 - val_loss: 1.3791e-10
Epoch 356/512

Epoch 00356: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3736e-10 - val_loss: 1.3776e-10
Epoch 357/512

Epoch 00357: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3808e-10 - val_loss: 1.3767e-10
Epoch 358/512

Epoch 00358: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3653e-10 - val_loss: 1.3622e-10
Epoch 359/512

Epoch 00359: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3943e-10 - val_loss: 1.4014e-10
Epoch 360/512

Epoch 00360: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4064e-10 - val_loss: 1.4032e-10
Epoch 361/512

Epoch 00361: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4227e-10 - val_loss: 1.4042e-10
Epoch 362/512

Epoch 00362: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4237e-10 - val_loss: 1.4215e-10
Epoch 363/512

Epoch 00363: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4425e-10 - val_loss: 1.4239e-10
Epoch 364/512

Epoch 00364: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4031e-10 - val_loss: 1.3794e-10
Epoch 365/512

Epoch 00365: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3908e-10 - val_loss: 1.3615e-10
Epoch 366/512

Epoch 00366: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3554e-10 - val_loss: 1.3366e-10
Epoch 367/512

Epoch 00367: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3336e-10 - val_loss: 1.3149e-10
Epoch 368/512

Epoch 00368: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3197e-10 - val_loss: 1.3070e-10
Epoch 369/512

Epoch 00369: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3170e-10 - val_loss: 1.3245e-10
Epoch 370/512

Epoch 00370: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3272e-10 - val_loss: 1.3091e-10
Epoch 371/512

Epoch 00371: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3291e-10 - val_loss: 1.3744e-10
Epoch 372/512

Epoch 00372: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3795e-10 - val_loss: 1.3560e-10
Epoch 373/512

Epoch 00373: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3533e-10 - val_loss: 1.3736e-10
Epoch 374/512

Epoch 00374: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3706e-10 - val_loss: 1.3408e-10
Epoch 375/512

Epoch 00375: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3280e-10 - val_loss: 1.3193e-10
Epoch 376/512

Epoch 00376: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3214e-10 - val_loss: 1.2967e-10
Epoch 377/512

Epoch 00377: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3090e-10 - val_loss: 1.3209e-10
Epoch 378/512

Epoch 00378: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3356e-10 - val_loss: 1.3252e-10
Epoch 379/512

Epoch 00379: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3249e-10 - val_loss: 1.3112e-10
Epoch 380/512

Epoch 00380: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3318e-10 - val_loss: 1.3089e-10
Epoch 381/512

Epoch 00381: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2951e-10 - val_loss: 1.2695e-10
Epoch 382/512

Epoch 00382: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2771e-10 - val_loss: 1.2762e-10
Epoch 383/512

Epoch 00383: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2704e-10 - val_loss: 1.2551e-10
Epoch 384/512

Epoch 00384: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2658e-10 - val_loss: 1.2825e-10
Epoch 385/512

Epoch 00385: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2796e-10 - val_loss: 1.2627e-10
Epoch 386/512

Epoch 00386: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2554e-10 - val_loss: 1.2603e-10
Epoch 387/512

Epoch 00387: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2630e-10 - val_loss: 1.2514e-10
Epoch 388/512

Epoch 00388: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2515e-10 - val_loss: 1.2665e-10
Epoch 389/512

Epoch 00389: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2620e-10 - val_loss: 1.2621e-10
Epoch 390/512

Epoch 00390: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2684e-10 - val_loss: 1.2637e-10
Epoch 391/512

Epoch 00391: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2899e-10 - val_loss: 1.2979e-10
Epoch 392/512

Epoch 00392: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2932e-10 - val_loss: 1.2722e-10
Epoch 393/512

Epoch 00393: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2731e-10 - val_loss: 1.2710e-10
Epoch 394/512

Epoch 00394: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2649e-10 - val_loss: 1.2520e-10
Epoch 395/512

Epoch 00395: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2554e-10 - val_loss: 1.2840e-10
Epoch 396/512

Epoch 00396: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2871e-10 - val_loss: 1.2754e-10
Epoch 397/512

Epoch 00397: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2844e-10 - val_loss: 1.2822e-10
Epoch 398/512

Epoch 00398: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2674e-10 - val_loss: 1.2370e-10
Epoch 399/512

Epoch 00399: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2224e-10 - val_loss: 1.2069e-10
Epoch 400/512

Epoch 00400: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2000e-10 - val_loss: 1.1808e-10
Epoch 401/512

Epoch 00401: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1835e-10 - val_loss: 1.1746e-10
Epoch 402/512

Epoch 00402: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1934e-10 - val_loss: 1.1994e-10
Epoch 403/512

Epoch 00403: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2026e-10 - val_loss: 1.2018e-10
Epoch 404/512

Epoch 00404: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2089e-10 - val_loss: 1.2124e-10
Epoch 405/512

Epoch 00405: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2139e-10 - val_loss: 1.2066e-10
Epoch 406/512

Epoch 00406: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2019e-10 - val_loss: 1.2123e-10
Epoch 407/512

Epoch 00407: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2057e-10 - val_loss: 1.1874e-10
Epoch 408/512

Epoch 00408: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1831e-10 - val_loss: 1.1803e-10
Epoch 409/512

Epoch 00409: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1824e-10 - val_loss: 1.1777e-10
Epoch 410/512

Epoch 00410: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1827e-10 - val_loss: 1.1936e-10
Epoch 411/512

Epoch 00411: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2116e-10 - val_loss: 1.2220e-10
Epoch 412/512

Epoch 00412: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2081e-10 - val_loss: 1.1991e-10
Epoch 413/512

Epoch 00413: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1990e-10 - val_loss: 1.2029e-10
Epoch 414/512

Epoch 00414: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2001e-10 - val_loss: 1.1805e-10
Epoch 415/512

Epoch 00415: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1837e-10 - val_loss: 1.1924e-10
Epoch 416/512

Epoch 00416: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2078e-10 - val_loss: 1.2061e-10
Epoch 417/512

Epoch 00417: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1845e-10 - val_loss: 1.1560e-10
Epoch 418/512

Epoch 00418: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1761e-10 - val_loss: 1.1889e-10
Epoch 419/512

Epoch 00419: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1857e-10 - val_loss: 1.1784e-10
Epoch 420/512

Epoch 00420: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1977e-10 - val_loss: 1.2223e-10
Epoch 421/512

Epoch 00421: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2070e-10 - val_loss: 1.1603e-10
Epoch 422/512

Epoch 00422: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1614e-10 - val_loss: 1.1670e-10
Epoch 423/512

Epoch 00423: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1660e-10 - val_loss: 1.1515e-10
Epoch 424/512

Epoch 00424: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1561e-10 - val_loss: 1.1505e-10
Epoch 425/512

Epoch 00425: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1565e-10 - val_loss: 1.1572e-10
Epoch 426/512

Epoch 00426: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1579e-10 - val_loss: 1.1584e-10
Epoch 427/512

Epoch 00427: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1497e-10 - val_loss: 1.1151e-10
Epoch 428/512

Epoch 00428: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1138e-10 - val_loss: 1.1059e-10
Epoch 429/512

Epoch 00429: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0943e-10 - val_loss: 1.0926e-10
Epoch 430/512

Epoch 00430: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0903e-10 - val_loss: 1.0785e-10
Epoch 431/512

Epoch 00431: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0796e-10 - val_loss: 1.0878e-10
Epoch 432/512

Epoch 00432: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1098e-10 - val_loss: 1.1296e-10
Epoch 433/512

Epoch 00433: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1497e-10 - val_loss: 1.1771e-10
Epoch 434/512

Epoch 00434: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1920e-10 - val_loss: 1.2134e-10
Epoch 435/512

Epoch 00435: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1941e-10 - val_loss: 1.1715e-10
Epoch 436/512

Epoch 00436: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1646e-10 - val_loss: 1.1445e-10
Epoch 437/512

Epoch 00437: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1158e-10 - val_loss: 1.0770e-10
Epoch 438/512

Epoch 00438: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0689e-10 - val_loss: 1.0598e-10
Epoch 439/512

Epoch 00439: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0596e-10 - val_loss: 1.0446e-10
Epoch 440/512

Epoch 00440: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0523e-10 - val_loss: 1.0631e-10
Epoch 441/512

Epoch 00441: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0638e-10 - val_loss: 1.0904e-10
Epoch 442/512

Epoch 00442: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1018e-10 - val_loss: 1.1036e-10
Epoch 443/512

Epoch 00443: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1010e-10 - val_loss: 1.0951e-10
Epoch 444/512

Epoch 00444: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1090e-10 - val_loss: 1.1131e-10
Epoch 445/512

Epoch 00445: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1160e-10 - val_loss: 1.1090e-10
Epoch 446/512

Epoch 00446: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1144e-10 - val_loss: 1.1319e-10
Epoch 447/512

Epoch 00447: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1380e-10 - val_loss: 1.1264e-10
Epoch 448/512

Epoch 00448: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1198e-10 - val_loss: 1.0999e-10
Epoch 449/512

Epoch 00449: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0925e-10 - val_loss: 1.0821e-10
Epoch 450/512

Epoch 00450: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0807e-10 - val_loss: 1.0635e-10
Epoch 451/512

Epoch 00451: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0530e-10 - val_loss: 1.0297e-10
Epoch 452/512

Epoch 00452: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0353e-10 - val_loss: 1.0394e-10
Epoch 453/512

Epoch 00453: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0464e-10 - val_loss: 1.0458e-10
Epoch 454/512

Epoch 00454: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0408e-10 - val_loss: 1.0450e-10
Epoch 455/512

Epoch 00455: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0458e-10 - val_loss: 1.0440e-10
Epoch 456/512

Epoch 00456: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0457e-10 - val_loss: 1.0590e-10
Epoch 457/512

Epoch 00457: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0768e-10 - val_loss: 1.0872e-10
Epoch 458/512

Epoch 00458: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0834e-10 - val_loss: 1.0803e-10
Epoch 459/512

Epoch 00459: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0845e-10 - val_loss: 1.0774e-10
Epoch 460/512

Epoch 00460: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0722e-10 - val_loss: 1.0664e-10
Epoch 461/512

Epoch 00461: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0635e-10 - val_loss: 1.0517e-10
Epoch 462/512

Epoch 00462: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0490e-10 - val_loss: 1.0376e-10
Epoch 463/512

Epoch 00463: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0454e-10 - val_loss: 1.0509e-10
Epoch 464/512

Epoch 00464: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0423e-10 - val_loss: 1.0461e-10
Epoch 465/512

Epoch 00465: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0474e-10 - val_loss: 1.0427e-10
Epoch 466/512

Epoch 00466: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0392e-10 - val_loss: 1.0234e-10
Epoch 467/512

Epoch 00467: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0238e-10 - val_loss: 1.0205e-10
Epoch 468/512

Epoch 00468: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0296e-10 - val_loss: 1.0274e-10
Epoch 469/512

Epoch 00469: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0285e-10 - val_loss: 1.0280e-10
Epoch 470/512

Epoch 00470: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0340e-10 - val_loss: 1.0349e-10
Epoch 471/512

Epoch 00471: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0304e-10 - val_loss: 1.0058e-10
Epoch 472/512

Epoch 00472: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0027e-10 - val_loss: 9.9507e-11
Epoch 473/512

Epoch 00473: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0025e-10 - val_loss: 9.9932e-11
Epoch 474/512

Epoch 00474: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.9597e-11 - val_loss: 9.9543e-11
Epoch 475/512

Epoch 00475: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.9638e-11 - val_loss: 9.9952e-11
Epoch 476/512

Epoch 00476: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0194e-10 - val_loss: 1.0293e-10
Epoch 477/512

Epoch 00477: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0285e-10 - val_loss: 1.0198e-10
Epoch 478/512

Epoch 00478: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0235e-10 - val_loss: 1.0258e-10
Epoch 479/512

Epoch 00479: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0148e-10 - val_loss: 1.0153e-10
Epoch 480/512

Epoch 00480: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0240e-10 - val_loss: 1.0292e-10
Epoch 481/512

Epoch 00481: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0292e-10 - val_loss: 1.0483e-10
Epoch 482/512

Epoch 00482: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0548e-10 - val_loss: 1.0366e-10
Epoch 483/512

Epoch 00483: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0388e-10 - val_loss: 1.0239e-10
Epoch 484/512

Epoch 00484: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0228e-10 - val_loss: 9.9724e-11
Epoch 485/512

Epoch 00485: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.9116e-11 - val_loss: 9.6733e-11
Epoch 486/512

Epoch 00486: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.7462e-11 - val_loss: 9.6691e-11
Epoch 487/512

Epoch 00487: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.5650e-11 - val_loss: 9.6288e-11
Epoch 488/512

Epoch 00488: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.7382e-11 - val_loss: 9.7227e-11
Epoch 489/512

Epoch 00489: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.7510e-11 - val_loss: 9.6697e-11
Epoch 490/512

Epoch 00490: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.7405e-11 - val_loss: 9.8659e-11
Epoch 491/512

Epoch 00491: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0007e-10 - val_loss: 9.9967e-11
Epoch 492/512

Epoch 00492: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.9289e-11 - val_loss: 1.0008e-10
Epoch 493/512

Epoch 00493: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0097e-10 - val_loss: 1.0075e-10
Epoch 494/512

Epoch 00494: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0087e-10 - val_loss: 9.8687e-11
Epoch 495/512

Epoch 00495: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.8390e-11 - val_loss: 9.7263e-11
Epoch 496/512

Epoch 00496: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.7559e-11 - val_loss: 9.8039e-11
Epoch 497/512

Epoch 00497: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.8320e-11 - val_loss: 9.7811e-11
Epoch 498/512

Epoch 00498: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.8816e-11 - val_loss: 9.8036e-11
Epoch 499/512

Epoch 00499: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.7725e-11 - val_loss: 9.7442e-11
Epoch 500/512

Epoch 00500: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.6594e-11 - val_loss: 9.5636e-11
Epoch 501/512

Epoch 00501: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.6520e-11 - val_loss: 9.6362e-11
Epoch 502/512

Epoch 00502: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.6190e-11 - val_loss: 9.2985e-11
Epoch 503/512

Epoch 00503: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.2746e-11 - val_loss: 9.4029e-11
Epoch 504/512

Epoch 00504: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.5155e-11 - val_loss: 9.6784e-11
Epoch 505/512

Epoch 00505: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.7331e-11 - val_loss: 9.7424e-11
Epoch 506/512

Epoch 00506: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.7932e-11 - val_loss: 9.8057e-11
Epoch 507/512

Epoch 00507: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.8506e-11 - val_loss: 9.8053e-11
Epoch 508/512

Epoch 00508: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.7463e-11 - val_loss: 9.7699e-11
Epoch 509/512

Epoch 00509: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.6893e-11 - val_loss: 9.5589e-11
Epoch 510/512

Epoch 00510: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.5391e-11 - val_loss: 9.2140e-11
Epoch 511/512

Epoch 00511: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.0488e-11 - val_loss: 9.0148e-11
Epoch 512/512

Epoch 00512: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.1020e-11 - val_loss: 9.2332e-11
Train on 512 samples, validate on 512 samples
Epoch 1/512
512/512 - 1s - loss: 9.7185 - val_loss: 0.2914
Epoch 2/512
512/512 - 0s - loss: 0.1507 - val_loss: 0.1984
Epoch 3/512
512/512 - 0s - loss: 0.1054 - val_loss: 0.1501
Epoch 4/512
512/512 - 0s - loss: 0.0826 - val_loss: 0.1199
Epoch 5/512
512/512 - 0s - loss: 0.0697 - val_loss: 0.1003
Epoch 6/512
512/512 - 0s - loss: 0.0622 - val_loss: 0.0875
Epoch 7/512
512/512 - 0s - loss: 0.0574 - val_loss: 0.0782
Epoch 8/512
512/512 - 0s - loss: 0.0536 - val_loss: 0.0705
Epoch 9/512
512/512 - 0s - loss: 0.0503 - val_loss: 0.0637
Epoch 10/512
512/512 - 0s - loss: 0.0473 - val_loss: 0.0572
Epoch 11/512
512/512 - 0s - loss: 0.0445 - val_loss: 0.0512
Epoch 12/512
512/512 - 0s - loss: 0.0419 - val_loss: 0.0454
Epoch 13/512
512/512 - 0s - loss: 0.0394 - val_loss: 0.0399
Epoch 14/512
512/512 - 0s - loss: 0.0371 - val_loss: 0.0349
Epoch 15/512
512/512 - 0s - loss: 0.0347 - val_loss: 0.0302
Epoch 16/512
512/512 - 0s - loss: 0.0325 - val_loss: 0.0261
Epoch 17/512
512/512 - 0s - loss: 0.0303 - val_loss: 0.0227
Epoch 18/512
512/512 - 0s - loss: 0.0279 - val_loss: 0.0201
Epoch 19/512
512/512 - 0s - loss: 0.0258 - val_loss: 0.0187
Epoch 20/512
512/512 - 0s - loss: 0.0236 - val_loss: 0.0188
Epoch 21/512
512/512 - 0s - loss: 0.0188 - val_loss: 0.0285
Epoch 22/512
512/512 - 0s - loss: 0.0170 - val_loss: 0.0364
Epoch 23/512
512/512 - 0s - loss: 0.0255 - val_loss: 0.0192
Epoch 24/512
512/512 - 0s - loss: 0.0180 - val_loss: 0.0149
Epoch 25/512
512/512 - 0s - loss: 0.0162 - val_loss: 0.0303
Epoch 26/512
512/512 - 0s - loss: 0.0177 - val_loss: 0.0111
Epoch 27/512
512/512 - 0s - loss: 0.0212 - val_loss: 0.2108
Epoch 28/512
512/512 - 0s - loss: 0.0524 - val_loss: 0.0171
Epoch 29/512
512/512 - 0s - loss: 0.0191 - val_loss: 0.0234
Epoch 30/512
512/512 - 0s - loss: 0.0193 - val_loss: 0.0404
Epoch 31/512
512/512 - 0s - loss: 12.2116 - val_loss: 0.0281
Epoch 32/512
512/512 - 0s - loss: 0.0291 - val_loss: 0.0039
Epoch 33/512
512/512 - 0s - loss: 0.0196 - val_loss: 0.0035
Epoch 34/512
512/512 - 0s - loss: 0.0132 - val_loss: 0.0071
Epoch 35/512
512/512 - 0s - loss: 0.0078 - val_loss: 0.0109
Epoch 36/512
512/512 - 0s - loss: 0.0109 - val_loss: 0.0052
Epoch 37/512
512/512 - 0s - loss: 0.0191 - val_loss: 0.0062
Epoch 38/512
512/512 - 0s - loss: 0.0085 - val_loss: 0.0108
Epoch 39/512
512/512 - 0s - loss: 0.0056 - val_loss: 0.0137
Epoch 40/512
512/512 - 0s - loss: 0.0049 - val_loss: 0.0148
Epoch 41/512
512/512 - 0s - loss: 0.0061 - val_loss: 0.0074
Epoch 42/512
512/512 - 0s - loss: 0.0069 - val_loss: 0.0132
Epoch 43/512
512/512 - 0s - loss: 0.0046 - val_loss: 0.0151
Epoch 44/512
512/512 - 0s - loss: 0.0059 - val_loss: 0.0140
Epoch 45/512
512/512 - 0s - loss: 0.0059 - val_loss: 0.0134
Epoch 46/512
512/512 - 0s - loss: 0.0045 - val_loss: 0.0248
Epoch 47/512
512/512 - 0s - loss: 0.0070 - val_loss: 0.0139
Epoch 48/512
512/512 - 0s - loss: 0.0042 - val_loss: 0.0137
Epoch 49/512
512/512 - 0s - loss: 0.0062 - val_loss: 0.0101
Epoch 50/512
512/512 - 0s - loss: 0.0075 - val_loss: 0.0135
Epoch 51/512
512/512 - 0s - loss: 0.0041 - val_loss: 0.0134
Epoch 52/512
512/512 - 0s - loss: 0.0044 - val_loss: 0.0149
Epoch 53/512
512/512 - 0s - loss: 0.0051 - val_loss: 0.0129
Epoch 54/512
512/512 - 0s - loss: 0.0051 - val_loss: 0.0135
Epoch 55/512
512/512 - 0s - loss: 0.0049 - val_loss: 0.0240
Epoch 56/512
512/512 - 0s - loss: 0.0057 - val_loss: 0.0218
Epoch 57/512
512/512 - 0s - loss: 0.0060 - val_loss: 0.0184
Epoch 58/512
512/512 - 0s - loss: 0.0035 - val_loss: 0.0119
Epoch 59/512
512/512 - 0s - loss: 0.0033 - val_loss: 0.0135
Epoch 60/512
512/512 - 0s - loss: 0.0032 - val_loss: 0.0129
Epoch 61/512
512/512 - 0s - loss: 0.0065 - val_loss: 0.0088
Epoch 62/512
512/512 - 0s - loss: 0.0035 - val_loss: 0.0051
Epoch 63/512
512/512 - 0s - loss: 0.0028 - val_loss: 0.0072
Epoch 64/512
512/512 - 0s - loss: 0.0066 - val_loss: 0.2860
Epoch 65/512
512/512 - 0s - loss: 0.0752 - val_loss: 0.0022
Epoch 66/512
512/512 - 0s - loss: 0.0023 - val_loss: 0.0024
Epoch 67/512
512/512 - 0s - loss: 0.0049 - val_loss: 0.0070
Epoch 68/512
512/512 - 0s - loss: 0.0037 - val_loss: 0.0016
Epoch 69/512
512/512 - 0s - loss: 0.0022 - val_loss: 9.2946e-05
Epoch 70/512
512/512 - 0s - loss: 0.0015 - val_loss: 7.6676e-05
Epoch 71/512
512/512 - 0s - loss: 0.0014 - val_loss: 6.5280e-05
Epoch 72/512
512/512 - 0s - loss: 0.0015 - val_loss: 5.3802e-05
Epoch 73/512
512/512 - 0s - loss: 0.0019 - val_loss: 3.0797e-05
Epoch 74/512
512/512 - 0s - loss: 0.0014 - val_loss: 4.5712e-05
Epoch 75/512
512/512 - 0s - loss: 0.0013 - val_loss: 1.6104e-05
Epoch 76/512
512/512 - 0s - loss: 0.0015 - val_loss: 4.1020e-05
Epoch 77/512
512/512 - 0s - loss: 0.0016 - val_loss: 3.8940e-05
Epoch 78/512
512/512 - 0s - loss: 0.0014 - val_loss: 1.8286e-04
Epoch 79/512
512/512 - 0s - loss: 0.0015 - val_loss: 5.9682e-04
Epoch 80/512
512/512 - 0s - loss: 0.0018 - val_loss: 2.6092e-04
Epoch 81/512
512/512 - 0s - loss: 0.0016 - val_loss: 3.2732e-05
Epoch 82/512
512/512 - 0s - loss: 0.0015 - val_loss: 2.7751e-05
Epoch 83/512
512/512 - 0s - loss: 0.0017 - val_loss: 6.2919e-05
Epoch 84/512
512/512 - 0s - loss: 0.0019 - val_loss: 4.4746e-05
Epoch 85/512
512/512 - 0s - loss: 0.0017 - val_loss: 1.3366e-04
Epoch 86/512
512/512 - 0s - loss: 0.0019 - val_loss: 3.4592e-04
Epoch 87/512
512/512 - 0s - loss: 0.0021 - val_loss: 1.6138e-04
Epoch 88/512
512/512 - 0s - loss: 0.0018 - val_loss: 5.1418e-05
Epoch 89/512
512/512 - 0s - loss: 0.0018 - val_loss: 5.2154e-05
Epoch 90/512
512/512 - 0s - loss: 0.0018 - val_loss: 6.4212e-05
Epoch 91/512
512/512 - 0s - loss: 0.0016 - val_loss: 5.1990e-05
Epoch 92/512
512/512 - 0s - loss: 0.0016 - val_loss: 1.8795e-04
Epoch 93/512
512/512 - 0s - loss: 0.0019 - val_loss: 8.1207e-05
Epoch 94/512
512/512 - 0s - loss: 0.0016 - val_loss: 2.0497e-05
Epoch 95/512
512/512 - 0s - loss: 0.0015 - val_loss: 2.2254e-05
Epoch 96/512
512/512 - 0s - loss: 0.0014 - val_loss: 1.6615e-05
Epoch 97/512
512/512 - 0s - loss: 0.0014 - val_loss: 1.0453e-04
Epoch 98/512
512/512 - 0s - loss: 0.0014 - val_loss: 1.8796e-05
Epoch 99/512
512/512 - 0s - loss: 0.0013 - val_loss: 1.6090e-04
Epoch 100/512
512/512 - 0s - loss: 0.0014 - val_loss: 1.3980e-04
Epoch 101/512
512/512 - 0s - loss: 0.0016 - val_loss: 7.1106e-06
Epoch 102/512
512/512 - 0s - loss: 0.0013 - val_loss: 9.3633e-06
Epoch 103/512
512/512 - 0s - loss: 0.0012 - val_loss: 9.8343e-06
Epoch 104/512
512/512 - 0s - loss: 0.0013 - val_loss: 9.0100e-06
Epoch 105/512
512/512 - 0s - loss: 0.0012 - val_loss: 7.8364e-06
Epoch 106/512
512/512 - 0s - loss: 0.0012 - val_loss: 2.2297e-05
Epoch 107/512
512/512 - 0s - loss: 0.0013 - val_loss: 6.1567e-05
Epoch 108/512
512/512 - 0s - loss: 0.0013 - val_loss: 4.5932e-05
Epoch 109/512
512/512 - 0s - loss: 0.0012 - val_loss: 6.9520e-06
Epoch 110/512
512/512 - 0s - loss: 0.0012 - val_loss: 6.5077e-06
Epoch 111/512
512/512 - 0s - loss: 0.0011 - val_loss: 7.2076e-06
Epoch 112/512
512/512 - 0s - loss: 0.0011 - val_loss: 6.4804e-06
Epoch 113/512
512/512 - 0s - loss: 0.0011 - val_loss: 9.5645e-06
Epoch 114/512
512/512 - 0s - loss: 0.0011 - val_loss: 6.6013e-06
Epoch 115/512
512/512 - 0s - loss: 0.0011 - val_loss: 1.0904e-04
Epoch 116/512
512/512 - 0s - loss: 0.0011 - val_loss: 6.6531e-05
Epoch 117/512
512/512 - 0s - loss: 0.0011 - val_loss: 2.6241e-05
Epoch 118/512
512/512 - 0s - loss: 0.0011 - val_loss: 9.5464e-06
Epoch 119/512
512/512 - 0s - loss: 0.0011 - val_loss: 6.7931e-06
Epoch 120/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.2027e-06
Epoch 121/512
512/512 - 0s - loss: 0.0011 - val_loss: 7.0331e-06
Epoch 122/512
512/512 - 0s - loss: 0.0011 - val_loss: 5.9777e-06
Epoch 123/512
512/512 - 0s - loss: 0.0011 - val_loss: 6.1284e-06
Epoch 124/512
512/512 - 0s - loss: 0.0010 - val_loss: 1.3665e-05
Epoch 125/512
512/512 - 0s - loss: 0.0011 - val_loss: 6.0658e-06
Epoch 126/512
512/512 - 0s - loss: 0.0011 - val_loss: 6.8518e-06
Epoch 127/512
512/512 - 0s - loss: 0.0010 - val_loss: 3.8666e-05
Epoch 128/512
512/512 - 0s - loss: 0.0011 - val_loss: 1.4652e-05
Epoch 129/512
512/512 - 0s - loss: 0.0011 - val_loss: 6.0196e-06
Epoch 130/512
512/512 - 0s - loss: 0.0010 - val_loss: 5.9649e-06
Epoch 131/512
512/512 - 0s - loss: 0.0010 - val_loss: 5.9780e-06
Epoch 132/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.0469e-06
Epoch 133/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.1888e-06
Epoch 134/512
512/512 - 0s - loss: 9.9919e-04 - val_loss: 6.8785e-06
Epoch 135/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.4644e-06
Epoch 136/512
512/512 - 0s - loss: 0.0010 - val_loss: 1.2743e-05
Epoch 137/512
512/512 - 0s - loss: 0.0010 - val_loss: 9.1591e-06
Epoch 138/512
512/512 - 0s - loss: 9.9980e-04 - val_loss: 7.2851e-06
Epoch 139/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.4461e-06
Epoch 140/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.2155e-06
Epoch 141/512
512/512 - 0s - loss: 9.8815e-04 - val_loss: 5.9928e-06
Epoch 142/512
512/512 - 0s - loss: 9.9899e-04 - val_loss: 6.1555e-06
Epoch 143/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.1690e-06
Epoch 144/512
512/512 - 0s - loss: 9.9158e-04 - val_loss: 6.5899e-06
Epoch 145/512
512/512 - 0s - loss: 9.8857e-04 - val_loss: 6.1112e-06
Epoch 146/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.0751e-06
Epoch 147/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.0751e-06
Epoch 148/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.0219e-06
Epoch 149/512
512/512 - 0s - loss: 9.8773e-04 - val_loss: 6.1571e-06
Epoch 150/512
512/512 - 0s - loss: 9.9116e-04 - val_loss: 6.9553e-06
Epoch 151/512
512/512 - 0s - loss: 9.9269e-04 - val_loss: 6.3310e-06
Epoch 152/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.0501e-06
Epoch 153/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.0754e-06
Epoch 154/512
512/512 - 0s - loss: 9.9471e-04 - val_loss: 6.0818e-06
Epoch 155/512
512/512 - 0s - loss: 9.6836e-04 - val_loss: 6.0785e-06
Epoch 156/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.0964e-06
Epoch 157/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.0769e-06
Epoch 158/512
512/512 - 0s - loss: 9.4919e-04 - val_loss: 6.0888e-06
Epoch 159/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.0823e-06
Epoch 160/512
512/512 - 0s - loss: 9.9348e-04 - val_loss: 6.0877e-06
Epoch 161/512
512/512 - 0s - loss: 9.7844e-04 - val_loss: 6.2128e-06
Epoch 162/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.1009e-06
Epoch 163/512
512/512 - 0s - loss: 9.7020e-04 - val_loss: 6.1565e-06
Epoch 164/512
512/512 - 0s - loss: 9.7754e-04 - val_loss: 6.1566e-06
Epoch 165/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.1265e-06
Epoch 166/512
512/512 - 0s - loss: 9.6714e-04 - val_loss: 6.1351e-06
Epoch 167/512
512/512 - 0s - loss: 9.7661e-04 - val_loss: 6.1575e-06
Epoch 168/512
512/512 - 0s - loss: 9.9548e-04 - val_loss: 6.1425e-06
Epoch 169/512
512/512 - 0s - loss: 9.8578e-04 - val_loss: 6.1644e-06
Epoch 170/512
512/512 - 0s - loss: 9.7524e-04 - val_loss: 6.1506e-06
Epoch 171/512
512/512 - 0s - loss: 9.8737e-04 - val_loss: 6.1613e-06
Epoch 172/512
512/512 - 0s - loss: 9.8853e-04 - val_loss: 6.1908e-06
Epoch 173/512
512/512 - 0s - loss: 9.8049e-04 - val_loss: 6.1503e-06
Epoch 174/512
512/512 - 0s - loss: 9.6903e-04 - val_loss: 6.1747e-06
Epoch 175/512
512/512 - 0s - loss: 9.8180e-04 - val_loss: 6.1767e-06
Epoch 176/512
512/512 - 0s - loss: 9.7209e-04 - val_loss: 6.1690e-06
Epoch 177/512
512/512 - 0s - loss: 9.8769e-04 - val_loss: 6.1769e-06
Epoch 178/512
512/512 - 0s - loss: 9.8258e-04 - val_loss: 6.2080e-06
Epoch 179/512
512/512 - 0s - loss: 9.7247e-04 - val_loss: 6.2052e-06
Epoch 180/512
512/512 - 0s - loss: 9.8271e-04 - val_loss: 6.1989e-06
Epoch 181/512
512/512 - 0s - loss: 9.7082e-04 - val_loss: 6.2226e-06
Epoch 182/512
512/512 - 0s - loss: 9.9022e-04 - val_loss: 6.1944e-06
Epoch 183/512
512/512 - 0s - loss: 9.7757e-04 - val_loss: 6.1901e-06
Epoch 184/512
512/512 - 0s - loss: 9.6245e-04 - val_loss: 6.2306e-06
Epoch 185/512
512/512 - 0s - loss: 9.8197e-04 - val_loss: 6.2329e-06
Epoch 186/512
512/512 - 0s - loss: 9.8566e-04 - val_loss: 6.2272e-06
Epoch 187/512
512/512 - 0s - loss: 9.7015e-04 - val_loss: 6.2325e-06
Epoch 188/512
512/512 - 0s - loss: 9.7886e-04 - val_loss: 6.2449e-06
Epoch 189/512
512/512 - 0s - loss: 9.8767e-04 - val_loss: 6.2232e-06
Epoch 190/512
512/512 - 0s - loss: 9.5664e-04 - val_loss: 6.2329e-06
Epoch 191/512
512/512 - 0s - loss: 9.6683e-04 - val_loss: 6.2747e-06
Epoch 192/512
512/512 - 0s - loss: 9.9601e-04 - val_loss: 6.2305e-06
Epoch 193/512
512/512 - 0s - loss: 9.6246e-04 - val_loss: 6.2544e-06
Epoch 194/512
512/512 - 0s - loss: 9.6495e-04 - val_loss: 6.2877e-06
Epoch 195/512
512/512 - 0s - loss: 9.7984e-04 - val_loss: 6.2794e-06
Epoch 196/512
512/512 - 0s - loss: 9.7547e-04 - val_loss: 6.2604e-06
Epoch 197/512
512/512 - 0s - loss: 9.6326e-04 - val_loss: 6.2986e-06
Epoch 198/512
512/512 - 0s - loss: 9.8527e-04 - val_loss: 6.2617e-06
Epoch 199/512
512/512 - 0s - loss: 9.4992e-04 - val_loss: 6.2868e-06
Epoch 200/512
512/512 - 0s - loss: 9.7649e-04 - val_loss: 6.2898e-06
Epoch 201/512
512/512 - 0s - loss: 9.6823e-04 - val_loss: 6.2907e-06
Epoch 202/512
512/512 - 0s - loss: 9.8789e-04 - val_loss: 6.2986e-06
Epoch 203/512
512/512 - 0s - loss: 9.6201e-04 - val_loss: 6.3175e-06
Epoch 204/512
512/512 - 0s - loss: 9.6099e-04 - val_loss: 6.3213e-06
Epoch 205/512
512/512 - 0s - loss: 9.7991e-04 - val_loss: 6.2750e-06
Epoch 206/512
512/512 - 0s - loss: 9.6237e-04 - val_loss: 6.3130e-06
Epoch 207/512
512/512 - 0s - loss: 9.5370e-04 - val_loss: 6.3430e-06
Epoch 208/512
512/512 - 0s - loss: 9.8734e-04 - val_loss: 6.3093e-06
Epoch 209/512
512/512 - 0s - loss: 9.5912e-04 - val_loss: 6.3337e-06
Epoch 210/512
512/512 - 0s - loss: 9.5649e-04 - val_loss: 6.3347e-06
Epoch 211/512
512/512 - 0s - loss: 9.9794e-04 - val_loss: 6.3218e-06
Epoch 212/512
512/512 - 0s - loss: 9.5514e-04 - val_loss: 6.3101e-06
Epoch 213/512
512/512 - 0s - loss: 9.3069e-04 - val_loss: 6.3779e-06
Epoch 214/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.3340e-06
Epoch 215/512
512/512 - 0s - loss: 9.6716e-04 - val_loss: 6.3569e-06
Epoch 216/512
512/512 - 0s - loss: 9.3393e-04 - val_loss: 6.3771e-06
Epoch 217/512
512/512 - 0s - loss: 9.6933e-04 - val_loss: 6.3553e-06
Epoch 218/512
512/512 - 0s - loss: 9.7889e-04 - val_loss: 6.3718e-06
Epoch 219/512
512/512 - 0s - loss: 9.5869e-04 - val_loss: 6.3893e-06
Epoch 220/512
512/512 - 0s - loss: 9.5606e-04 - val_loss: 6.3808e-06
Epoch 221/512
512/512 - 0s - loss: 9.8321e-04 - val_loss: 6.3741e-06
Epoch 222/512
512/512 - 0s - loss: 9.5198e-04 - val_loss: 6.3970e-06
Epoch 223/512
512/512 - 0s - loss: 9.5398e-04 - val_loss: 6.3890e-06
Epoch 224/512
512/512 - 0s - loss: 9.6840e-04 - val_loss: 6.3663e-06
Epoch 225/512
512/512 - 0s - loss: 9.5955e-04 - val_loss: 6.4142e-06
Epoch 226/512
512/512 - 0s - loss: 9.5836e-04 - val_loss: 6.4125e-06
Epoch 227/512
512/512 - 0s - loss: 9.6127e-04 - val_loss: 6.3837e-06
Epoch 228/512
512/512 - 0s - loss: 9.5333e-04 - val_loss: 6.4203e-06
Epoch 229/512
512/512 - 0s - loss: 9.7252e-04 - val_loss: 6.4063e-06
Epoch 230/512
512/512 - 0s - loss: 9.4786e-04 - val_loss: 6.4261e-06
Epoch 231/512
512/512 - 0s - loss: 9.5500e-04 - val_loss: 6.4093e-06
Epoch 232/512
512/512 - 0s - loss: 9.7165e-04 - val_loss: 6.4019e-06
Epoch 233/512
512/512 - 0s - loss: 9.5581e-04 - val_loss: 6.4013e-06
Epoch 234/512
512/512 - 0s - loss: 9.2667e-04 - val_loss: 6.4312e-06
Epoch 235/512
512/512 - 0s - loss: 9.8491e-04 - val_loss: 6.4302e-06
Epoch 236/512
512/512 - 0s - loss: 9.6325e-04 - val_loss: 6.4231e-06
Epoch 237/512
512/512 - 0s - loss: 9.1706e-04 - val_loss: 6.4383e-06
Epoch 238/512
512/512 - 0s - loss: 9.7729e-04 - val_loss: 6.4514e-06
Epoch 239/512
512/512 - 0s - loss: 9.6772e-04 - val_loss: 6.4212e-06
Epoch 240/512
512/512 - 0s - loss: 9.1745e-04 - val_loss: 6.4299e-06
Epoch 241/512
512/512 - 0s - loss: 9.6141e-04 - val_loss: 6.4672e-06
Epoch 242/512
512/512 - 0s - loss: 9.7647e-04 - val_loss: 6.4409e-06
Epoch 243/512
512/512 - 0s - loss: 9.2235e-04 - val_loss: 6.4633e-06
Epoch 244/512
512/512 - 0s - loss: 9.4780e-04 - val_loss: 6.4736e-06
Epoch 245/512
512/512 - 0s - loss: 9.6677e-04 - val_loss: 6.4488e-06
Epoch 246/512
512/512 - 0s - loss: 9.1909e-04 - val_loss: 6.4878e-06
Epoch 247/512
512/512 - 0s - loss: 9.4385e-04 - val_loss: 6.5072e-06
Epoch 248/512
512/512 - 0s - loss: 9.6918e-04 - val_loss: 6.4864e-06
Epoch 249/512
512/512 - 0s - loss: 9.5310e-04 - val_loss: 6.4702e-06
Epoch 250/512
512/512 - 0s - loss: 9.2999e-04 - val_loss: 6.4739e-06
Epoch 251/512
512/512 - 0s - loss: 9.5113e-04 - val_loss: 6.5048e-06
Epoch 252/512
512/512 - 0s - loss: 9.6001e-04 - val_loss: 6.4791e-06
Epoch 253/512
512/512 - 0s - loss: 9.2740e-04 - val_loss: 6.5146e-06
Epoch 254/512
512/512 - 0s - loss: 9.5425e-04 - val_loss: 6.4789e-06
Epoch 255/512
512/512 - 0s - loss: 9.2879e-04 - val_loss: 6.5001e-06
Epoch 256/512
512/512 - 0s - loss: 9.4793e-04 - val_loss: 6.5191e-06
Epoch 257/512
512/512 - 0s - loss: 9.5337e-04 - val_loss: 6.5168e-06
Epoch 258/512
512/512 - 0s - loss: 9.1948e-04 - val_loss: 6.5116e-06
Epoch 259/512
512/512 - 0s - loss: 9.3469e-04 - val_loss: 6.5077e-06
Epoch 260/512
512/512 - 0s - loss: 9.4492e-04 - val_loss: 6.5325e-06
Epoch 261/512
512/512 - 0s - loss: 9.3222e-04 - val_loss: 6.5219e-06
Epoch 262/512
512/512 - 0s - loss: 9.4772e-04 - val_loss: 6.4835e-06
Epoch 263/512
512/512 - 0s - loss: 9.3637e-04 - val_loss: 6.5183e-06
Epoch 264/512
512/512 - 0s - loss: 9.3529e-04 - val_loss: 6.5112e-06
Epoch 265/512
512/512 - 0s - loss: 9.1890e-04 - val_loss: 6.5473e-06
Epoch 266/512
512/512 - 0s - loss: 9.4032e-04 - val_loss: 6.5468e-06
Epoch 267/512
512/512 - 0s - loss: 9.3784e-04 - val_loss: 6.5635e-06
Epoch 268/512
512/512 - 0s - loss: 9.1941e-04 - val_loss: 6.5537e-06
Epoch 269/512
512/512 - 0s - loss: 9.2939e-04 - val_loss: 6.5464e-06
Epoch 270/512
512/512 - 0s - loss: 9.2930e-04 - val_loss: 6.5684e-06
Epoch 271/512
512/512 - 0s - loss: 9.1991e-04 - val_loss: 6.5443e-06
Epoch 272/512
512/512 - 0s - loss: 9.3273e-04 - val_loss: 6.5663e-06
Epoch 273/512
512/512 - 0s - loss: 9.2238e-04 - val_loss: 6.5668e-06
Epoch 274/512
512/512 - 0s - loss: 9.3612e-04 - val_loss: 6.5404e-06
Epoch 275/512
512/512 - 0s - loss: 9.1434e-04 - val_loss: 6.5737e-06
Epoch 276/512
512/512 - 0s - loss: 9.1590e-04 - val_loss: 6.5913e-06
Epoch 277/512
512/512 - 0s - loss: 9.3230e-04 - val_loss: 6.5765e-06
Epoch 278/512
512/512 - 0s - loss: 9.2695e-04 - val_loss: 6.5805e-06
Epoch 279/512
512/512 - 0s - loss: 9.0954e-04 - val_loss: 6.5755e-06
Epoch 280/512
512/512 - 0s - loss: 9.1671e-04 - val_loss: 6.5814e-06
Epoch 281/512
512/512 - 0s - loss: 9.1688e-04 - val_loss: 6.5939e-06
Epoch 282/512
512/512 - 0s - loss: 9.1310e-04 - val_loss: 6.6388e-06
Epoch 283/512
512/512 - 0s - loss: 9.2565e-04 - val_loss: 6.5838e-06
Epoch 284/512
512/512 - 0s - loss: 9.0573e-04 - val_loss: 6.6182e-06
Epoch 285/512
512/512 - 0s - loss: 9.1798e-04 - val_loss: 6.6355e-06
Epoch 286/512
512/512 - 0s - loss: 9.1571e-04 - val_loss: 6.6207e-06
Epoch 287/512
512/512 - 0s - loss: 8.9879e-04 - val_loss: 6.6180e-06
Epoch 288/512
512/512 - 0s - loss: 9.1739e-04 - val_loss: 6.6285e-06
Epoch 289/512
512/512 - 0s - loss: 9.2782e-04 - val_loss: 6.6305e-06
Epoch 290/512
512/512 - 0s - loss: 8.8123e-04 - val_loss: 6.6167e-06
Epoch 291/512
512/512 - 0s - loss: 9.0400e-04 - val_loss: 6.6126e-06
Epoch 292/512
512/512 - 0s - loss: 9.3083e-04 - val_loss: 6.6437e-06
Epoch 293/512
512/512 - 0s - loss: 9.0254e-04 - val_loss: 6.6373e-06
Epoch 294/512
512/512 - 0s - loss: 8.8516e-04 - val_loss: 6.6480e-06
Epoch 295/512
512/512 - 0s - loss: 9.0029e-04 - val_loss: 6.6761e-06
Epoch 296/512
512/512 - 0s - loss: 9.1804e-04 - val_loss: 6.6582e-06
Epoch 297/512
512/512 - 0s - loss: 8.9315e-04 - val_loss: 6.6912e-06
Epoch 298/512
512/512 - 0s - loss: 8.7775e-04 - val_loss: 6.7101e-06
Epoch 299/512
512/512 - 0s - loss: 9.0400e-04 - val_loss: 6.6933e-06
Epoch 300/512
512/512 - 0s - loss: 9.1370e-04 - val_loss: 6.7235e-06
Epoch 301/512
512/512 - 0s - loss: 8.7862e-04 - val_loss: 6.7295e-06
Epoch 302/512
512/512 - 0s - loss: 8.9541e-04 - val_loss: 6.6763e-06
Epoch 303/512
512/512 - 0s - loss: 8.9215e-04 - val_loss: 6.6941e-06
Epoch 304/512
512/512 - 0s - loss: 8.8629e-04 - val_loss: 6.7173e-06
Epoch 305/512
512/512 - 0s - loss: 8.9061e-04 - val_loss: 6.7064e-06
Epoch 306/512
512/512 - 0s - loss: 8.8787e-04 - val_loss: 6.7022e-06
Epoch 307/512
512/512 - 0s - loss: 8.7360e-04 - val_loss: 6.6963e-06
Epoch 308/512
512/512 - 0s - loss: 8.7945e-04 - val_loss: 6.7113e-06
Epoch 309/512
512/512 - 0s - loss: 8.8709e-04 - val_loss: 6.7341e-06
Epoch 310/512
512/512 - 0s - loss: 8.9656e-04 - val_loss: 6.7242e-06
Epoch 311/512
512/512 - 0s - loss: 8.5880e-04 - val_loss: 6.7875e-06
Epoch 312/512
512/512 - 0s - loss: 8.8189e-04 - val_loss: 6.7603e-06
Epoch 313/512
512/512 - 0s - loss: 8.8467e-04 - val_loss: 6.7397e-06
Epoch 314/512
512/512 - 0s - loss: 8.7184e-04 - val_loss: 6.7260e-06
Epoch 315/512
512/512 - 0s - loss: 8.6089e-04 - val_loss: 6.7723e-06
Epoch 316/512
512/512 - 0s - loss: 8.8775e-04 - val_loss: 6.7352e-06
Epoch 317/512
512/512 - 0s - loss: 8.7687e-04 - val_loss: 6.7408e-06
Epoch 318/512
512/512 - 0s - loss: 8.6022e-04 - val_loss: 6.7650e-06
Epoch 319/512
512/512 - 0s - loss: 8.6023e-04 - val_loss: 6.7699e-06
Epoch 320/512
512/512 - 0s - loss: 8.8767e-04 - val_loss: 6.7471e-06
Epoch 321/512
512/512 - 0s - loss: 8.5936e-04 - val_loss: 6.7769e-06
Epoch 322/512
512/512 - 0s - loss: 8.4350e-04 - val_loss: 6.7968e-06
Epoch 323/512
512/512 - 0s - loss: 8.7741e-04 - val_loss: 6.7847e-06
Epoch 324/512
512/512 - 0s - loss: 8.7845e-04 - val_loss: 6.7761e-06
Epoch 325/512
512/512 - 0s - loss: 8.3637e-04 - val_loss: 6.7816e-06
Epoch 326/512
512/512 - 0s - loss: 8.3497e-04 - val_loss: 6.7948e-06
Epoch 327/512
512/512 - 0s - loss: 8.9635e-04 - val_loss: 6.7822e-06
Epoch 328/512
512/512 - 0s - loss: 8.6446e-04 - val_loss: 6.8137e-06
Epoch 329/512
512/512 - 0s - loss: 8.2789e-04 - val_loss: 6.8133e-06
Epoch 330/512
512/512 - 0s - loss: 8.6185e-04 - val_loss: 6.7981e-06
Epoch 331/512
512/512 - 0s - loss: 8.5986e-04 - val_loss: 6.8218e-06
Epoch 332/512
512/512 - 0s - loss: 8.4538e-04 - val_loss: 6.8051e-06
Epoch 333/512
512/512 - 0s - loss: 8.4316e-04 - val_loss: 6.8309e-06
Epoch 334/512
512/512 - 0s - loss: 8.4992e-04 - val_loss: 6.8355e-06
Epoch 335/512
512/512 - 0s - loss: 8.3720e-04 - val_loss: 6.8393e-06
Epoch 336/512
512/512 - 0s - loss: 8.4588e-04 - val_loss: 6.8869e-06
Epoch 337/512
512/512 - 0s - loss: 8.6805e-04 - val_loss: 6.8468e-06
Epoch 338/512
512/512 - 0s - loss: 8.2174e-04 - val_loss: 6.8514e-06
Epoch 339/512
512/512 - 0s - loss: 8.4478e-04 - val_loss: 6.8714e-06
Epoch 340/512
512/512 - 0s - loss: 8.5951e-04 - val_loss: 6.8581e-06
Epoch 341/512
512/512 - 0s - loss: 8.1708e-04 - val_loss: 6.8814e-06
Epoch 342/512
512/512 - 0s - loss: 8.2988e-04 - val_loss: 6.8747e-06
Epoch 343/512
512/512 - 0s - loss: 8.7401e-04 - val_loss: 6.8664e-06
Epoch 344/512
512/512 - 0s - loss: 8.1405e-04 - val_loss: 6.8812e-06
Epoch 345/512
512/512 - 0s - loss: 8.2017e-04 - val_loss: 6.8749e-06
Epoch 346/512
512/512 - 0s - loss: 8.6090e-04 - val_loss: 6.9362e-06
Epoch 347/512
512/512 - 0s - loss: 8.3871e-04 - val_loss: 6.8569e-06
Epoch 348/512
512/512 - 0s - loss: 8.1384e-04 - val_loss: 6.9034e-06
Epoch 349/512
512/512 - 0s - loss: 8.3956e-04 - val_loss: 6.9195e-06
Epoch 350/512
512/512 - 0s - loss: 8.3137e-04 - val_loss: 6.9222e-06
Epoch 351/512
512/512 - 0s - loss: 8.2328e-04 - val_loss: 6.9258e-06
Epoch 352/512
512/512 - 0s - loss: 8.3014e-04 - val_loss: 6.9296e-06
Epoch 353/512
512/512 - 0s - loss: 8.2472e-04 - val_loss: 6.9162e-06
Epoch 354/512
512/512 - 0s - loss: 8.2349e-04 - val_loss: 6.9766e-06
Epoch 355/512
512/512 - 0s - loss: 8.2568e-04 - val_loss: 6.9360e-06
Epoch 356/512
512/512 - 0s - loss: 8.0710e-04 - val_loss: 6.9674e-06
Epoch 357/512
512/512 - 0s - loss: 8.2875e-04 - val_loss: 6.9650e-06
Epoch 358/512
512/512 - 0s - loss: 8.3292e-04 - val_loss: 6.9616e-06
Epoch 359/512
512/512 - 0s - loss: 8.2596e-04 - val_loss: 6.9561e-06
Epoch 360/512
512/512 - 0s - loss: 8.0931e-04 - val_loss: 6.9703e-06
Epoch 361/512
512/512 - 0s - loss: 8.1532e-04 - val_loss: 6.9919e-06
Epoch 362/512
512/512 - 0s - loss: 8.2427e-04 - val_loss: 7.0081e-06
Epoch 363/512
512/512 - 0s - loss: 8.3095e-04 - val_loss: 6.9652e-06
Epoch 364/512
512/512 - 0s - loss: 8.0287e-04 - val_loss: 7.0035e-06
Epoch 365/512
512/512 - 0s - loss: 7.8846e-04 - val_loss: 7.0140e-06
Epoch 366/512
512/512 - 0s - loss: 8.1934e-04 - val_loss: 7.0052e-06
Epoch 367/512
512/512 - 0s - loss: 8.3165e-04 - val_loss: 7.0130e-06
Epoch 368/512
512/512 - 0s - loss: 7.9356e-04 - val_loss: 7.0208e-06
Epoch 369/512
512/512 - 0s - loss: 8.1253e-04 - val_loss: 7.0399e-06
Epoch 370/512
512/512 - 0s - loss: 8.2398e-04 - val_loss: 7.0394e-06
Epoch 371/512
512/512 - 0s - loss: 7.9721e-04 - val_loss: 7.0539e-06
Epoch 372/512
512/512 - 0s - loss: 8.1169e-04 - val_loss: 7.0786e-06
Epoch 373/512
512/512 - 0s - loss: 8.1061e-04 - val_loss: 7.0493e-06
Epoch 374/512
512/512 - 0s - loss: 7.8906e-04 - val_loss: 7.0921e-06
Epoch 375/512
512/512 - 0s - loss: 8.0779e-04 - val_loss: 7.0838e-06
Epoch 376/512
512/512 - 0s - loss: 8.2904e-04 - val_loss: 7.0838e-06
Epoch 377/512
512/512 - 0s - loss: 8.0711e-04 - val_loss: 7.0737e-06
Epoch 378/512
512/512 - 0s - loss: 7.7746e-04 - val_loss: 7.0884e-06
Epoch 379/512
512/512 - 0s - loss: 8.0582e-04 - val_loss: 7.0871e-06
Epoch 380/512
512/512 - 0s - loss: 8.1700e-04 - val_loss: 7.1044e-06
Epoch 381/512
512/512 - 0s - loss: 7.8813e-04 - val_loss: 7.1427e-06
Epoch 382/512
512/512 - 0s - loss: 8.0121e-04 - val_loss: 7.1211e-06
Epoch 383/512
512/512 - 0s - loss: 8.1474e-04 - val_loss: 7.1428e-06
Epoch 384/512
512/512 - 0s - loss: 7.9682e-04 - val_loss: 7.1434e-06
Epoch 385/512
512/512 - 0s - loss: 7.8773e-04 - val_loss: 7.1645e-06
Epoch 386/512
512/512 - 0s - loss: 7.9754e-04 - val_loss: 7.1665e-06
Epoch 387/512
512/512 - 0s - loss: 8.0582e-04 - val_loss: 7.1815e-06
Epoch 388/512
512/512 - 0s - loss: 7.8595e-04 - val_loss: 7.2000e-06
Epoch 389/512
512/512 - 0s - loss: 7.9508e-04 - val_loss: 7.2169e-06
Epoch 390/512
512/512 - 0s - loss: 8.0724e-04 - val_loss: 7.1709e-06
Epoch 391/512
512/512 - 0s - loss: 7.9285e-04 - val_loss: 7.2249e-06
Epoch 392/512
512/512 - 0s - loss: 7.7967e-04 - val_loss: 7.2404e-06
Epoch 393/512
512/512 - 0s - loss: 8.0151e-04 - val_loss: 7.2094e-06
Epoch 394/512
512/512 - 0s - loss: 7.9740e-04 - val_loss: 7.2418e-06
Epoch 395/512
512/512 - 0s - loss: 7.9612e-04 - val_loss: 7.2154e-06
Epoch 396/512
512/512 - 0s - loss: 7.8024e-04 - val_loss: 7.2532e-06
Epoch 397/512
512/512 - 0s - loss: 8.0695e-04 - val_loss: 7.2657e-06
Epoch 398/512
512/512 - 0s - loss: 8.0194e-04 - val_loss: 7.2580e-06
Epoch 399/512
512/512 - 0s - loss: 7.8385e-04 - val_loss: 7.2693e-06
Epoch 400/512
512/512 - 0s - loss: 7.9622e-04 - val_loss: 7.2980e-06
Epoch 401/512
512/512 - 0s - loss: 7.8431e-04 - val_loss: 7.2996e-06
Epoch 402/512
512/512 - 0s - loss: 7.8230e-04 - val_loss: 7.2744e-06
Epoch 403/512
512/512 - 0s - loss: 7.8641e-04 - val_loss: 7.2975e-06
Epoch 404/512
512/512 - 0s - loss: 8.0298e-04 - val_loss: 7.2840e-06
Epoch 405/512
512/512 - 0s - loss: 7.8199e-04 - val_loss: 7.3344e-06
Epoch 406/512
512/512 - 0s - loss: 7.8907e-04 - val_loss: 7.3089e-06
Epoch 407/512
512/512 - 0s - loss: 8.0261e-04 - val_loss: 7.3260e-06
Epoch 408/512
512/512 - 0s - loss: 7.8494e-04 - val_loss: 7.3173e-06
Epoch 409/512
512/512 - 0s - loss: 7.6594e-04 - val_loss: 7.3757e-06
Epoch 410/512
512/512 - 0s - loss: 8.0797e-04 - val_loss: 7.3493e-06
Epoch 411/512
512/512 - 0s - loss: 7.9417e-04 - val_loss: 7.3180e-06
Epoch 412/512
512/512 - 0s - loss: 7.6471e-04 - val_loss: 7.3789e-06
Epoch 413/512
512/512 - 0s - loss: 7.8368e-04 - val_loss: 7.3612e-06
Epoch 414/512
512/512 - 0s - loss: 7.9319e-04 - val_loss: 7.4093e-06
Epoch 415/512
512/512 - 0s - loss: 7.7728e-04 - val_loss: 7.4226e-06
Epoch 416/512
512/512 - 0s - loss: 7.9297e-04 - val_loss: 7.4171e-06
Epoch 417/512
512/512 - 0s - loss: 7.9159e-04 - val_loss: 7.4017e-06
Epoch 418/512
512/512 - 0s - loss: 7.8266e-04 - val_loss: 7.4201e-06
Epoch 419/512
512/512 - 0s - loss: 7.8500e-04 - val_loss: 7.4323e-06
Epoch 420/512
512/512 - 0s - loss: 7.8680e-04 - val_loss: 7.4453e-06
Epoch 421/512
512/512 - 0s - loss: 7.7866e-04 - val_loss: 7.4709e-06
Epoch 422/512
512/512 - 0s - loss: 7.9719e-04 - val_loss: 7.4644e-06
Epoch 423/512
512/512 - 0s - loss: 7.8226e-04 - val_loss: 7.4418e-06
Epoch 424/512
512/512 - 0s - loss: 7.7322e-04 - val_loss: 7.4789e-06
Epoch 425/512
512/512 - 0s - loss: 7.7815e-04 - val_loss: 7.5026e-06
Epoch 426/512
512/512 - 0s - loss: 7.8595e-04 - val_loss: 7.4331e-06
Epoch 427/512
512/512 - 0s - loss: 7.7690e-04 - val_loss: 7.5398e-06
Epoch 428/512
512/512 - 0s - loss: 7.8301e-04 - val_loss: 7.5175e-06
Epoch 429/512
512/512 - 0s - loss: 7.8232e-04 - val_loss: 7.4820e-06
Epoch 430/512
512/512 - 0s - loss: 7.8893e-04 - val_loss: 7.5632e-06
Epoch 431/512
512/512 - 0s - loss: 7.8325e-04 - val_loss: 7.5286e-06
Epoch 432/512
512/512 - 0s - loss: 7.6025e-04 - val_loss: 7.5233e-06
Epoch 433/512
512/512 - 0s - loss: 8.1084e-04 - val_loss: 7.5605e-06
Epoch 434/512
512/512 - 0s - loss: 7.6863e-04 - val_loss: 7.5223e-06
Epoch 435/512
512/512 - 0s - loss: 7.7623e-04 - val_loss: 7.5112e-06
Epoch 436/512
512/512 - 0s - loss: 7.6468e-04 - val_loss: 7.5817e-06
Epoch 437/512
512/512 - 0s - loss: 7.9524e-04 - val_loss: 7.6609e-06
Epoch 438/512
512/512 - 0s - loss: 7.8461e-04 - val_loss: 7.6719e-06
Epoch 439/512
512/512 - 0s - loss: 7.5300e-04 - val_loss: 7.4479e-06
Epoch 440/512
512/512 - 0s - loss: 7.8684e-04 - val_loss: 7.6491e-06
Epoch 441/512
512/512 - 0s - loss: 8.0707e-04 - val_loss: 7.6840e-06
Epoch 442/512
512/512 - 0s - loss: 7.5809e-04 - val_loss: 7.6389e-06
Epoch 443/512
512/512 - 0s - loss: 7.6987e-04 - val_loss: 7.5159e-06
Epoch 444/512
512/512 - 0s - loss: 8.0347e-04 - val_loss: 7.6563e-06
Epoch 445/512
512/512 - 0s - loss: 7.6942e-04 - val_loss: 7.7350e-06
Epoch 446/512
512/512 - 0s - loss: 7.7989e-04 - val_loss: 7.7772e-06
Epoch 447/512
512/512 - 0s - loss: 7.6257e-04 - val_loss: 7.8168e-06
Epoch 448/512
512/512 - 0s - loss: 7.6759e-04 - val_loss: 7.7114e-06
Epoch 449/512
512/512 - 0s - loss: 7.9317e-04 - val_loss: 7.5148e-06
Epoch 450/512
512/512 - 0s - loss: 8.0304e-04 - val_loss: 7.6278e-06
Epoch 451/512
512/512 - 0s - loss: 7.5566e-04 - val_loss: 7.7006e-06
Epoch 452/512
512/512 - 0s - loss: 7.8919e-04 - val_loss: 7.6461e-06
Epoch 453/512
512/512 - 0s - loss: 7.8300e-04 - val_loss: 7.5657e-06
Epoch 454/512
512/512 - 0s - loss: 7.7825e-04 - val_loss: 7.6799e-06
Epoch 455/512
512/512 - 0s - loss: 7.8219e-04 - val_loss: 7.7358e-06
Epoch 456/512
512/512 - 0s - loss: 7.7708e-04 - val_loss: 7.7708e-06
Epoch 457/512
512/512 - 0s - loss: 7.6047e-04 - val_loss: 7.8126e-06
Epoch 458/512
512/512 - 0s - loss: 7.7292e-04 - val_loss: 7.8320e-06
Epoch 459/512
512/512 - 0s - loss: 7.8362e-04 - val_loss: 7.5412e-06
Epoch 460/512
512/512 - 0s - loss: 7.9838e-04 - val_loss: 7.6372e-06
Epoch 461/512
512/512 - 0s - loss: 7.7013e-04 - val_loss: 7.6880e-06
Epoch 462/512
512/512 - 0s - loss: 7.6923e-04 - val_loss: 7.6783e-06
Epoch 463/512
512/512 - 0s - loss: 7.7720e-04 - val_loss: 7.6682e-06
Epoch 464/512
512/512 - 0s - loss: 7.9056e-04 - val_loss: 7.6388e-06
Epoch 465/512
512/512 - 0s - loss: 7.6935e-04 - val_loss: 7.7213e-06
Epoch 466/512
512/512 - 0s - loss: 7.7593e-04 - val_loss: 7.7382e-06
Epoch 467/512
512/512 - 0s - loss: 7.8335e-04 - val_loss: 7.6835e-06
Epoch 468/512
512/512 - 0s - loss: 7.8681e-04 - val_loss: 7.6896e-06
Epoch 469/512
512/512 - 0s - loss: 7.5890e-04 - val_loss: 7.8530e-06
Epoch 470/512
512/512 - 0s - loss: 8.0434e-04 - val_loss: 7.9082e-06
Epoch 471/512
512/512 - 0s - loss: 7.7025e-04 - val_loss: 7.7800e-06
Epoch 472/512
512/512 - 0s - loss: 7.6331e-04 - val_loss: 7.6655e-06
Epoch 473/512
512/512 - 0s - loss: 7.7678e-04 - val_loss: 7.7001e-06
Epoch 474/512
512/512 - 0s - loss: 7.8665e-04 - val_loss: 7.7907e-06
Epoch 475/512
512/512 - 0s - loss: 7.7896e-04 - val_loss: 7.8212e-06
Epoch 476/512
512/512 - 0s - loss: 7.6727e-04 - val_loss: 7.8381e-06
Epoch 477/512
512/512 - 0s - loss: 7.7198e-04 - val_loss: 7.9503e-06
Epoch 478/512
512/512 - 0s - loss: 7.6842e-04 - val_loss: 7.7822e-06
Epoch 479/512
512/512 - 0s - loss: 7.8446e-04 - val_loss: 7.6368e-06
Epoch 480/512
512/512 - 0s - loss: 8.0546e-04 - val_loss: 7.7455e-06
Epoch 481/512
512/512 - 0s - loss: 7.6197e-04 - val_loss: 7.7768e-06
Epoch 482/512
512/512 - 0s - loss: 7.5790e-04 - val_loss: 7.7681e-06
Epoch 483/512
512/512 - 0s - loss: 7.9309e-04 - val_loss: 7.6545e-06
Epoch 484/512
512/512 - 0s - loss: 7.8981e-04 - val_loss: 7.7636e-06
Epoch 485/512
512/512 - 0s - loss: 7.6335e-04 - val_loss: 7.8508e-06
Epoch 486/512
512/512 - 0s - loss: 7.7544e-04 - val_loss: 7.9788e-06
Epoch 487/512
512/512 - 0s - loss: 7.6243e-04 - val_loss: 7.8261e-06
Epoch 488/512
512/512 - 0s - loss: 7.6671e-04 - val_loss: 7.6953e-06
Epoch 489/512
512/512 - 0s - loss: 8.1555e-04 - val_loss: 7.7615e-06
Epoch 490/512
512/512 - 0s - loss: 7.6955e-04 - val_loss: 7.8462e-06
Epoch 491/512
512/512 - 0s - loss: 7.6653e-04 - val_loss: 7.9348e-06
Epoch 492/512
512/512 - 0s - loss: 7.9324e-04 - val_loss: 7.9573e-06
Epoch 493/512
512/512 - 0s - loss: 7.7507e-04 - val_loss: 7.8155e-06
Epoch 494/512
512/512 - 0s - loss: 7.6419e-04 - val_loss: 7.6688e-06
Epoch 495/512
512/512 - 0s - loss: 8.0128e-04 - val_loss: 7.7891e-06
Epoch 496/512
512/512 - 0s - loss: 7.7110e-04 - val_loss: 7.8635e-06
Epoch 497/512
512/512 - 0s - loss: 7.6638e-04 - val_loss: 7.9144e-06
Epoch 498/512
512/512 - 0s - loss: 7.9515e-04 - val_loss: 7.9383e-06
Epoch 499/512
512/512 - 0s - loss: 7.5028e-04 - val_loss: 7.7360e-06
Epoch 500/512
512/512 - 0s - loss: 7.7928e-04 - val_loss: 7.7122e-06
Epoch 501/512
512/512 - 0s - loss: 7.9344e-04 - val_loss: 7.8105e-06
Epoch 502/512
512/512 - 0s - loss: 7.7222e-04 - val_loss: 7.8391e-06
Epoch 503/512
512/512 - 0s - loss: 7.6579e-04 - val_loss: 7.8451e-06
Epoch 504/512
512/512 - 0s - loss: 7.8618e-04 - val_loss: 7.7067e-06
Epoch 505/512
512/512 - 0s - loss: 7.7835e-04 - val_loss: 7.8098e-06
Epoch 506/512
512/512 - 0s - loss: 7.7457e-04 - val_loss: 7.9515e-06
Epoch 507/512
512/512 - 0s - loss: 7.9507e-04 - val_loss: 7.9622e-06
Epoch 508/512
512/512 - 0s - loss: 7.5731e-04 - val_loss: 7.8515e-06
Epoch 509/512
512/512 - 0s - loss: 7.6771e-04 - val_loss: 7.7120e-06
Epoch 510/512
512/512 - 0s - loss: 7.9377e-04 - val_loss: 7.7954e-06
Epoch 511/512
512/512 - 0s - loss: 7.7278e-04 - val_loss: 7.8752e-06
Epoch 512/512
512/512 - 0s - loss: 7.7149e-04 - val_loss: 7.9874e-06
Train on 512 samples, validate on 512 samples
Epoch 1/512

Epoch 00001: val_loss improved from inf to 0.00034, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 0.0017 - val_loss: 3.3547e-04
Epoch 2/512

Epoch 00002: val_loss improved from 0.00034 to 0.00005, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.6720e-04 - val_loss: 5.0759e-05
Epoch 3/512

Epoch 00003: val_loss improved from 0.00005 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00001-RMS-16/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1043e-05 - val_loss: 4.0221e-05
Epoch 4/512

Epoch 00004: val_loss did not improve from 0.00004
512/512 - 0s - loss: 9.5215e-05 - val_loss: 3.9682e-04
Epoch 5/512

Epoch 00005: val_loss did not improve from 0.00004
512/512 - 0s - loss: 7.7536e-04 - val_loss: 5.4851e-04
Epoch 6/512

Epoch 00006: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.1901e-04 - val_loss: 1.2076e-04
Epoch 7/512

Epoch 00007: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.2737e-04 - val_loss: 1.9596e-04
Epoch 8/512

Epoch 00008: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.5448e-04 - val_loss: 5.6975e-04
Epoch 9/512

Epoch 00009: val_loss did not improve from 0.00004
512/512 - 0s - loss: 4.9671e-04 - val_loss: 2.8125e-04
Epoch 10/512

Epoch 00010: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3766e-04 - val_loss: 2.1240e-04
Epoch 11/512

Epoch 00011: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7266e-04 - val_loss: 3.8132e-04
Epoch 12/512

Epoch 00012: val_loss did not improve from 0.00004
512/512 - 0s - loss: 4.1821e-04 - val_loss: 3.5852e-04
Epoch 13/512

Epoch 00013: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.1597e-04 - val_loss: 2.5483e-04
Epoch 14/512

Epoch 00014: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7371e-04 - val_loss: 3.1206e-04
Epoch 15/512

Epoch 00015: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.5053e-04 - val_loss: 3.5349e-04
Epoch 16/512

Epoch 00016: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.3863e-04 - val_loss: 2.8828e-04
Epoch 17/512

Epoch 00017: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8986e-04 - val_loss: 2.9150e-04
Epoch 18/512

Epoch 00018: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.1730e-04 - val_loss: 3.2921e-04
Epoch 19/512

Epoch 00019: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.3301e-04 - val_loss: 3.0529e-04
Epoch 20/512

Epoch 00020: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.0352e-04 - val_loss: 2.8964e-04
Epoch 21/512

Epoch 00021: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.0483e-04 - val_loss: 3.1055e-04
Epoch 22/512

Epoch 00022: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.2048e-04 - val_loss: 3.0719e-04
Epoch 23/512

Epoch 00023: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.0839e-04 - val_loss: 2.9314e-04
Epoch 24/512

Epoch 00024: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.0158e-04 - val_loss: 3.0030e-04
Epoch 25/512

Epoch 00025: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.1048e-04 - val_loss: 3.0302e-04
Epoch 26/512

Epoch 00026: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.0712e-04 - val_loss: 2.9412e-04
Epoch 27/512

Epoch 00027: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.0084e-04 - val_loss: 2.9474e-04
Epoch 28/512

Epoch 00028: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.0373e-04 - val_loss: 2.9856e-04
Epoch 29/512

Epoch 00029: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.0445e-04 - val_loss: 2.9483e-04
Epoch 30/512

Epoch 00030: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.0053e-04 - val_loss: 2.9207e-04
Epoch 31/512

Epoch 00031: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.9968e-04 - val_loss: 2.9458e-04
Epoch 32/512

Epoch 00032: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.0044e-04 - val_loss: 2.9309e-04
Epoch 33/512

Epoch 00033: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.9859e-04 - val_loss: 2.9105e-04
Epoch 34/512

Epoch 00034: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.9663e-04 - val_loss: 2.9011e-04
Epoch 35/512

Epoch 00035: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.9713e-04 - val_loss: 2.9184e-04
Epoch 36/512

Epoch 00036: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.9750e-04 - val_loss: 2.9032e-04
Epoch 37/512

Epoch 00037: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.9519e-04 - val_loss: 2.8795e-04
Epoch 38/512

Epoch 00038: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.9454e-04 - val_loss: 2.8916e-04
Epoch 39/512

Epoch 00039: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.9495e-04 - val_loss: 2.8784e-04
Epoch 40/512

Epoch 00040: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.9258e-04 - val_loss: 2.8581e-04
Epoch 41/512

Epoch 00041: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.9204e-04 - val_loss: 2.8789e-04
Epoch 42/512

Epoch 00042: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.9301e-04 - val_loss: 2.8745e-04
Epoch 43/512

Epoch 00043: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.9137e-04 - val_loss: 2.8466e-04
Epoch 44/512

Epoch 00044: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.9040e-04 - val_loss: 2.8532e-04
Epoch 45/512

Epoch 00045: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.9067e-04 - val_loss: 2.8503e-04
Epoch 46/512

Epoch 00046: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8939e-04 - val_loss: 2.8370e-04
Epoch 47/512

Epoch 00047: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8882e-04 - val_loss: 2.8369e-04
Epoch 48/512

Epoch 00048: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8830e-04 - val_loss: 2.8302e-04
Epoch 49/512

Epoch 00049: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8758e-04 - val_loss: 2.8317e-04
Epoch 50/512

Epoch 00050: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8829e-04 - val_loss: 2.8258e-04
Epoch 51/512

Epoch 00051: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8582e-04 - val_loss: 2.8096e-04
Epoch 52/512

Epoch 00052: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8649e-04 - val_loss: 2.8258e-04
Epoch 53/512

Epoch 00053: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8610e-04 - val_loss: 2.7991e-04
Epoch 54/512

Epoch 00054: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8472e-04 - val_loss: 2.7948e-04
Epoch 55/512

Epoch 00055: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8420e-04 - val_loss: 2.8091e-04
Epoch 56/512

Epoch 00056: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8547e-04 - val_loss: 2.7951e-04
Epoch 57/512

Epoch 00057: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8363e-04 - val_loss: 2.7807e-04
Epoch 58/512

Epoch 00058: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8235e-04 - val_loss: 2.7805e-04
Epoch 59/512

Epoch 00059: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8291e-04 - val_loss: 2.7933e-04
Epoch 60/512

Epoch 00060: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8327e-04 - val_loss: 2.7727e-04
Epoch 61/512

Epoch 00061: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8107e-04 - val_loss: 2.7735e-04
Epoch 62/512

Epoch 00062: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8165e-04 - val_loss: 2.7820e-04
Epoch 63/512

Epoch 00063: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8177e-04 - val_loss: 2.7635e-04
Epoch 64/512

Epoch 00064: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7978e-04 - val_loss: 2.7571e-04
Epoch 65/512

Epoch 00065: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7981e-04 - val_loss: 2.7657e-04
Epoch 66/512

Epoch 00066: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.8015e-04 - val_loss: 2.7573e-04
Epoch 67/512

Epoch 00067: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7946e-04 - val_loss: 2.7557e-04
Epoch 68/512

Epoch 00068: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7920e-04 - val_loss: 2.7490e-04
Epoch 69/512

Epoch 00069: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7869e-04 - val_loss: 2.7521e-04
Epoch 70/512

Epoch 00070: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7816e-04 - val_loss: 2.7355e-04
Epoch 71/512

Epoch 00071: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7763e-04 - val_loss: 2.7394e-04
Epoch 72/512

Epoch 00072: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7719e-04 - val_loss: 2.7295e-04
Epoch 73/512

Epoch 00073: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7709e-04 - val_loss: 2.7373e-04
Epoch 74/512

Epoch 00074: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7658e-04 - val_loss: 2.7258e-04
Epoch 75/512

Epoch 00075: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7615e-04 - val_loss: 2.7139e-04
Epoch 76/512

Epoch 00076: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7493e-04 - val_loss: 2.7262e-04
Epoch 77/512

Epoch 00077: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7540e-04 - val_loss: 2.7228e-04
Epoch 78/512

Epoch 00078: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7579e-04 - val_loss: 2.7120e-04
Epoch 79/512

Epoch 00079: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7331e-04 - val_loss: 2.6931e-04
Epoch 80/512

Epoch 00080: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7367e-04 - val_loss: 2.7193e-04
Epoch 81/512

Epoch 00081: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7527e-04 - val_loss: 2.7073e-04
Epoch 82/512

Epoch 00082: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7344e-04 - val_loss: 2.6950e-04
Epoch 83/512

Epoch 00083: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7215e-04 - val_loss: 2.6917e-04
Epoch 84/512

Epoch 00084: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7275e-04 - val_loss: 2.7025e-04
Epoch 85/512

Epoch 00085: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7249e-04 - val_loss: 2.6890e-04
Epoch 86/512

Epoch 00086: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7173e-04 - val_loss: 2.6815e-04
Epoch 87/512

Epoch 00087: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7143e-04 - val_loss: 2.6891e-04
Epoch 88/512

Epoch 00088: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7216e-04 - val_loss: 2.6839e-04
Epoch 89/512

Epoch 00089: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7034e-04 - val_loss: 2.6692e-04
Epoch 90/512

Epoch 00090: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6976e-04 - val_loss: 2.6762e-04
Epoch 91/512

Epoch 00091: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7080e-04 - val_loss: 2.6775e-04
Epoch 92/512

Epoch 00092: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.7059e-04 - val_loss: 2.6636e-04
Epoch 93/512

Epoch 00093: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6895e-04 - val_loss: 2.6486e-04
Epoch 94/512

Epoch 00094: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6816e-04 - val_loss: 2.6615e-04
Epoch 95/512

Epoch 00095: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6949e-04 - val_loss: 2.6682e-04
Epoch 96/512

Epoch 00096: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6895e-04 - val_loss: 2.6429e-04
Epoch 97/512

Epoch 00097: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6675e-04 - val_loss: 2.6412e-04
Epoch 98/512

Epoch 00098: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6778e-04 - val_loss: 2.6575e-04
Epoch 99/512

Epoch 00099: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6805e-04 - val_loss: 2.6425e-04
Epoch 100/512

Epoch 00100: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6650e-04 - val_loss: 2.6300e-04
Epoch 101/512

Epoch 00101: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6615e-04 - val_loss: 2.6433e-04
Epoch 102/512

Epoch 00102: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6667e-04 - val_loss: 2.6366e-04
Epoch 103/512

Epoch 00103: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6614e-04 - val_loss: 2.6406e-04
Epoch 104/512

Epoch 00104: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6635e-04 - val_loss: 2.6261e-04
Epoch 105/512

Epoch 00105: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6421e-04 - val_loss: 2.6140e-04
Epoch 106/512

Epoch 00106: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6457e-04 - val_loss: 2.6233e-04
Epoch 107/512

Epoch 00107: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6507e-04 - val_loss: 2.6328e-04
Epoch 108/512

Epoch 00108: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6491e-04 - val_loss: 2.6154e-04
Epoch 109/512

Epoch 00109: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6334e-04 - val_loss: 2.6056e-04
Epoch 110/512

Epoch 00110: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6346e-04 - val_loss: 2.6162e-04
Epoch 111/512

Epoch 00111: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6370e-04 - val_loss: 2.6133e-04
Epoch 112/512

Epoch 00112: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6336e-04 - val_loss: 2.5988e-04
Epoch 113/512

Epoch 00113: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6197e-04 - val_loss: 2.5958e-04
Epoch 114/512

Epoch 00114: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6231e-04 - val_loss: 2.6111e-04
Epoch 115/512

Epoch 00115: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6275e-04 - val_loss: 2.5935e-04
Epoch 116/512

Epoch 00116: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6061e-04 - val_loss: 2.5822e-04
Epoch 117/512

Epoch 00117: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6142e-04 - val_loss: 2.6017e-04
Epoch 118/512

Epoch 00118: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6260e-04 - val_loss: 2.5895e-04
Epoch 119/512

Epoch 00119: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6014e-04 - val_loss: 2.5661e-04
Epoch 120/512

Epoch 00120: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5952e-04 - val_loss: 2.5870e-04
Epoch 121/512

Epoch 00121: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.6131e-04 - val_loss: 2.5789e-04
Epoch 122/512

Epoch 00122: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5935e-04 - val_loss: 2.5640e-04
Epoch 123/512

Epoch 00123: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5894e-04 - val_loss: 2.5747e-04
Epoch 124/512

Epoch 00124: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5926e-04 - val_loss: 2.5687e-04
Epoch 125/512

Epoch 00125: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5916e-04 - val_loss: 2.5695e-04
Epoch 126/512

Epoch 00126: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5824e-04 - val_loss: 2.5506e-04
Epoch 127/512

Epoch 00127: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5838e-04 - val_loss: 2.5759e-04
Epoch 128/512

Epoch 00128: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5756e-04 - val_loss: 2.5397e-04
Epoch 129/512

Epoch 00129: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5689e-04 - val_loss: 2.5588e-04
Epoch 130/512

Epoch 00130: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5799e-04 - val_loss: 2.5601e-04
Epoch 131/512

Epoch 00131: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5658e-04 - val_loss: 2.5382e-04
Epoch 132/512

Epoch 00132: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5562e-04 - val_loss: 2.5438e-04
Epoch 133/512

Epoch 00133: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5690e-04 - val_loss: 2.5490e-04
Epoch 134/512

Epoch 00134: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5566e-04 - val_loss: 2.5263e-04
Epoch 135/512

Epoch 00135: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5531e-04 - val_loss: 2.5419e-04
Epoch 136/512

Epoch 00136: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5577e-04 - val_loss: 2.5290e-04
Epoch 137/512

Epoch 00137: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5415e-04 - val_loss: 2.5211e-04
Epoch 138/512

Epoch 00138: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5445e-04 - val_loss: 2.5420e-04
Epoch 139/512

Epoch 00139: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5511e-04 - val_loss: 2.5248e-04
Epoch 140/512

Epoch 00140: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5358e-04 - val_loss: 2.5074e-04
Epoch 141/512

Epoch 00141: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5319e-04 - val_loss: 2.5290e-04
Epoch 142/512

Epoch 00142: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5422e-04 - val_loss: 2.5149e-04
Epoch 143/512

Epoch 00143: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5220e-04 - val_loss: 2.5026e-04
Epoch 144/512

Epoch 00144: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5262e-04 - val_loss: 2.5139e-04
Epoch 145/512

Epoch 00145: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5315e-04 - val_loss: 2.5056e-04
Epoch 146/512

Epoch 00146: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5107e-04 - val_loss: 2.4958e-04
Epoch 147/512

Epoch 00147: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5186e-04 - val_loss: 2.5056e-04
Epoch 148/512

Epoch 00148: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5260e-04 - val_loss: 2.4873e-04
Epoch 149/512

Epoch 00149: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4996e-04 - val_loss: 2.4886e-04
Epoch 150/512

Epoch 00150: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5029e-04 - val_loss: 2.4927e-04
Epoch 151/512

Epoch 00151: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5147e-04 - val_loss: 2.5040e-04
Epoch 152/512

Epoch 00152: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.5074e-04 - val_loss: 2.4723e-04
Epoch 153/512

Epoch 00153: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4848e-04 - val_loss: 2.4881e-04
Epoch 154/512

Epoch 00154: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4990e-04 - val_loss: 2.4794e-04
Epoch 155/512

Epoch 00155: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4970e-04 - val_loss: 2.4817e-04
Epoch 156/512

Epoch 00156: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4857e-04 - val_loss: 2.4652e-04
Epoch 157/512

Epoch 00157: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4832e-04 - val_loss: 2.4701e-04
Epoch 158/512

Epoch 00158: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4771e-04 - val_loss: 2.4615e-04
Epoch 159/512

Epoch 00159: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4805e-04 - val_loss: 2.4758e-04
Epoch 160/512

Epoch 00160: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4810e-04 - val_loss: 2.4508e-04
Epoch 161/512

Epoch 00161: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4634e-04 - val_loss: 2.4534e-04
Epoch 162/512

Epoch 00162: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4730e-04 - val_loss: 2.4564e-04
Epoch 163/512

Epoch 00163: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4651e-04 - val_loss: 2.4546e-04
Epoch 164/512

Epoch 00164: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4700e-04 - val_loss: 2.4513e-04
Epoch 165/512

Epoch 00165: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4554e-04 - val_loss: 2.4397e-04
Epoch 166/512

Epoch 00166: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4549e-04 - val_loss: 2.4419e-04
Epoch 167/512

Epoch 00167: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4561e-04 - val_loss: 2.4468e-04
Epoch 168/512

Epoch 00168: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4547e-04 - val_loss: 2.4341e-04
Epoch 169/512

Epoch 00169: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4371e-04 - val_loss: 2.4267e-04
Epoch 170/512

Epoch 00170: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4446e-04 - val_loss: 2.4440e-04
Epoch 171/512

Epoch 00171: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4471e-04 - val_loss: 2.4275e-04
Epoch 172/512

Epoch 00172: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4309e-04 - val_loss: 2.4272e-04
Epoch 173/512

Epoch 00173: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4394e-04 - val_loss: 2.4293e-04
Epoch 174/512

Epoch 00174: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4346e-04 - val_loss: 2.4192e-04
Epoch 175/512

Epoch 00175: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4188e-04 - val_loss: 2.4125e-04
Epoch 176/512

Epoch 00176: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4240e-04 - val_loss: 2.4160e-04
Epoch 177/512

Epoch 00177: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4215e-04 - val_loss: 2.4086e-04
Epoch 178/512

Epoch 00178: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4113e-04 - val_loss: 2.4057e-04
Epoch 179/512

Epoch 00179: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4121e-04 - val_loss: 2.4106e-04
Epoch 180/512

Epoch 00180: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4191e-04 - val_loss: 2.3942e-04
Epoch 181/512

Epoch 00181: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4009e-04 - val_loss: 2.3969e-04
Epoch 182/512

Epoch 00182: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4031e-04 - val_loss: 2.3954e-04
Epoch 183/512

Epoch 00183: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4052e-04 - val_loss: 2.3977e-04
Epoch 184/512

Epoch 00184: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.4034e-04 - val_loss: 2.3803e-04
Epoch 185/512

Epoch 00185: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3892e-04 - val_loss: 2.3888e-04
Epoch 186/512

Epoch 00186: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3882e-04 - val_loss: 2.3713e-04
Epoch 187/512

Epoch 00187: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3799e-04 - val_loss: 2.3792e-04
Epoch 188/512

Epoch 00188: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3938e-04 - val_loss: 2.3885e-04
Epoch 189/512

Epoch 00189: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3865e-04 - val_loss: 2.3619e-04
Epoch 190/512

Epoch 00190: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3678e-04 - val_loss: 2.3738e-04
Epoch 191/512

Epoch 00191: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3800e-04 - val_loss: 2.3693e-04
Epoch 192/512

Epoch 00192: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3704e-04 - val_loss: 2.3592e-04
Epoch 193/512

Epoch 00193: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3658e-04 - val_loss: 2.3702e-04
Epoch 194/512

Epoch 00194: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3701e-04 - val_loss: 2.3498e-04
Epoch 195/512

Epoch 00195: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3546e-04 - val_loss: 2.3556e-04
Epoch 196/512

Epoch 00196: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3589e-04 - val_loss: 2.3482e-04
Epoch 197/512

Epoch 00197: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3583e-04 - val_loss: 2.3555e-04
Epoch 198/512

Epoch 00198: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3522e-04 - val_loss: 2.3404e-04
Epoch 199/512

Epoch 00199: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3411e-04 - val_loss: 2.3430e-04
Epoch 200/512

Epoch 00200: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3503e-04 - val_loss: 2.3488e-04
Epoch 201/512

Epoch 00201: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3456e-04 - val_loss: 2.3298e-04
Epoch 202/512

Epoch 00202: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3318e-04 - val_loss: 2.3270e-04
Epoch 203/512

Epoch 00203: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3321e-04 - val_loss: 2.3321e-04
Epoch 204/512

Epoch 00204: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3336e-04 - val_loss: 2.3263e-04
Epoch 205/512

Epoch 00205: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3236e-04 - val_loss: 2.3247e-04
Epoch 206/512

Epoch 00206: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3258e-04 - val_loss: 2.3206e-04
Epoch 207/512

Epoch 00207: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3215e-04 - val_loss: 2.3196e-04
Epoch 208/512

Epoch 00208: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3202e-04 - val_loss: 2.3141e-04
Epoch 209/512

Epoch 00209: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3101e-04 - val_loss: 2.3059e-04
Epoch 210/512

Epoch 00210: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3109e-04 - val_loss: 2.3147e-04
Epoch 211/512

Epoch 00211: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3121e-04 - val_loss: 2.2971e-04
Epoch 212/512

Epoch 00212: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2977e-04 - val_loss: 2.3016e-04
Epoch 213/512

Epoch 00213: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.3053e-04 - val_loss: 2.2968e-04
Epoch 214/512

Epoch 00214: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2905e-04 - val_loss: 2.2869e-04
Epoch 215/512

Epoch 00215: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2933e-04 - val_loss: 2.2974e-04
Epoch 216/512

Epoch 00216: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2959e-04 - val_loss: 2.2881e-04
Epoch 217/512

Epoch 00217: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2833e-04 - val_loss: 2.2825e-04
Epoch 218/512

Epoch 00218: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2855e-04 - val_loss: 2.2857e-04
Epoch 219/512

Epoch 00219: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2818e-04 - val_loss: 2.2703e-04
Epoch 220/512

Epoch 00220: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2682e-04 - val_loss: 2.2685e-04
Epoch 221/512

Epoch 00221: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2684e-04 - val_loss: 2.2766e-04
Epoch 222/512

Epoch 00222: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2736e-04 - val_loss: 2.2665e-04
Epoch 223/512

Epoch 00223: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2619e-04 - val_loss: 2.2690e-04
Epoch 224/512

Epoch 00224: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2727e-04 - val_loss: 2.2655e-04
Epoch 225/512

Epoch 00225: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2591e-04 - val_loss: 2.2518e-04
Epoch 226/512

Epoch 00226: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2457e-04 - val_loss: 2.2514e-04
Epoch 227/512

Epoch 00227: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2541e-04 - val_loss: 2.2572e-04
Epoch 228/512

Epoch 00228: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2455e-04 - val_loss: 2.2433e-04
Epoch 229/512

Epoch 00229: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2454e-04 - val_loss: 2.2449e-04
Epoch 230/512

Epoch 00230: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2458e-04 - val_loss: 2.2485e-04
Epoch 231/512

Epoch 00231: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2359e-04 - val_loss: 2.2309e-04
Epoch 232/512

Epoch 00232: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2345e-04 - val_loss: 2.2385e-04
Epoch 233/512

Epoch 00233: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2292e-04 - val_loss: 2.2282e-04
Epoch 234/512

Epoch 00234: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2220e-04 - val_loss: 2.2296e-04
Epoch 235/512

Epoch 00235: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2292e-04 - val_loss: 2.2348e-04
Epoch 236/512

Epoch 00236: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2273e-04 - val_loss: 2.2200e-04
Epoch 237/512

Epoch 00237: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2068e-04 - val_loss: 2.2117e-04
Epoch 238/512

Epoch 00238: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2137e-04 - val_loss: 2.2200e-04
Epoch 239/512

Epoch 00239: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2124e-04 - val_loss: 2.2152e-04
Epoch 240/512

Epoch 00240: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2006e-04 - val_loss: 2.1915e-04
Epoch 241/512

Epoch 00241: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1889e-04 - val_loss: 2.2109e-04
Epoch 242/512

Epoch 00242: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.2102e-04 - val_loss: 2.2158e-04
Epoch 243/512

Epoch 00243: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1984e-04 - val_loss: 2.1853e-04
Epoch 244/512

Epoch 00244: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1802e-04 - val_loss: 2.1939e-04
Epoch 245/512

Epoch 00245: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1894e-04 - val_loss: 2.1898e-04
Epoch 246/512

Epoch 00246: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1768e-04 - val_loss: 2.1830e-04
Epoch 247/512

Epoch 00247: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1842e-04 - val_loss: 2.1953e-04
Epoch 248/512

Epoch 00248: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1820e-04 - val_loss: 2.1810e-04
Epoch 249/512

Epoch 00249: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1666e-04 - val_loss: 2.1653e-04
Epoch 250/512

Epoch 00250: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1625e-04 - val_loss: 2.1871e-04
Epoch 251/512

Epoch 00251: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1814e-04 - val_loss: 2.1769e-04
Epoch 252/512

Epoch 00252: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1613e-04 - val_loss: 2.1596e-04
Epoch 253/512

Epoch 00253: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1486e-04 - val_loss: 2.1618e-04
Epoch 254/512

Epoch 00254: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1597e-04 - val_loss: 2.1736e-04
Epoch 255/512

Epoch 00255: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1521e-04 - val_loss: 2.1506e-04
Epoch 256/512

Epoch 00256: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1387e-04 - val_loss: 2.1571e-04
Epoch 257/512

Epoch 00257: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1494e-04 - val_loss: 2.1540e-04
Epoch 258/512

Epoch 00258: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1414e-04 - val_loss: 2.1489e-04
Epoch 259/512

Epoch 00259: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1336e-04 - val_loss: 2.1419e-04
Epoch 260/512

Epoch 00260: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1329e-04 - val_loss: 2.1371e-04
Epoch 261/512

Epoch 00261: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1336e-04 - val_loss: 2.1400e-04
Epoch 262/512

Epoch 00262: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1233e-04 - val_loss: 2.1303e-04
Epoch 263/512

Epoch 00263: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1161e-04 - val_loss: 2.1294e-04
Epoch 264/512

Epoch 00264: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1203e-04 - val_loss: 2.1279e-04
Epoch 265/512

Epoch 00265: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1192e-04 - val_loss: 2.1206e-04
Epoch 266/512

Epoch 00266: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1056e-04 - val_loss: 2.1128e-04
Epoch 267/512

Epoch 00267: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1074e-04 - val_loss: 2.1181e-04
Epoch 268/512

Epoch 00268: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.1103e-04 - val_loss: 2.1127e-04
Epoch 269/512

Epoch 00269: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0915e-04 - val_loss: 2.1008e-04
Epoch 270/512

Epoch 00270: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0960e-04 - val_loss: 2.1200e-04
Epoch 271/512

Epoch 00271: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0992e-04 - val_loss: 2.0978e-04
Epoch 272/512

Epoch 00272: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0821e-04 - val_loss: 2.0874e-04
Epoch 273/512

Epoch 00273: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0745e-04 - val_loss: 2.0954e-04
Epoch 274/512

Epoch 00274: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0855e-04 - val_loss: 2.1069e-04
Epoch 275/512

Epoch 00275: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0863e-04 - val_loss: 2.0846e-04
Epoch 276/512

Epoch 00276: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0699e-04 - val_loss: 2.0784e-04
Epoch 277/512

Epoch 00277: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0690e-04 - val_loss: 2.0849e-04
Epoch 278/512

Epoch 00278: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0715e-04 - val_loss: 2.0733e-04
Epoch 279/512

Epoch 00279: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0583e-04 - val_loss: 2.0772e-04
Epoch 280/512

Epoch 00280: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0573e-04 - val_loss: 2.0714e-04
Epoch 281/512

Epoch 00281: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0510e-04 - val_loss: 2.0701e-04
Epoch 282/512

Epoch 00282: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0601e-04 - val_loss: 2.0770e-04
Epoch 283/512

Epoch 00283: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0533e-04 - val_loss: 2.0514e-04
Epoch 284/512

Epoch 00284: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0356e-04 - val_loss: 2.0552e-04
Epoch 285/512

Epoch 00285: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0421e-04 - val_loss: 2.0573e-04
Epoch 286/512

Epoch 00286: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0364e-04 - val_loss: 2.0437e-04
Epoch 287/512

Epoch 00287: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0309e-04 - val_loss: 2.0554e-04
Epoch 288/512

Epoch 00288: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0373e-04 - val_loss: 2.0415e-04
Epoch 289/512

Epoch 00289: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0278e-04 - val_loss: 2.0418e-04
Epoch 290/512

Epoch 00290: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0184e-04 - val_loss: 2.0309e-04
Epoch 291/512

Epoch 00291: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0124e-04 - val_loss: 2.0358e-04
Epoch 292/512

Epoch 00292: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0161e-04 - val_loss: 2.0360e-04
Epoch 293/512

Epoch 00293: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0171e-04 - val_loss: 2.0262e-04
Epoch 294/512

Epoch 00294: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0043e-04 - val_loss: 2.0219e-04
Epoch 295/512

Epoch 00295: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0039e-04 - val_loss: 2.0181e-04
Epoch 296/512

Epoch 00296: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0024e-04 - val_loss: 2.0247e-04
Epoch 297/512

Epoch 00297: val_loss did not improve from 0.00004
512/512 - 0s - loss: 2.0004e-04 - val_loss: 2.0059e-04
Epoch 298/512

Epoch 00298: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9820e-04 - val_loss: 2.0020e-04
Epoch 299/512

Epoch 00299: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9893e-04 - val_loss: 2.0185e-04
Epoch 300/512

Epoch 00300: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9960e-04 - val_loss: 2.0010e-04
Epoch 301/512

Epoch 00301: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9764e-04 - val_loss: 1.9868e-04
Epoch 302/512

Epoch 00302: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9722e-04 - val_loss: 1.9968e-04
Epoch 303/512

Epoch 00303: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9800e-04 - val_loss: 2.0042e-04
Epoch 304/512

Epoch 00304: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9767e-04 - val_loss: 1.9889e-04
Epoch 305/512

Epoch 00305: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9703e-04 - val_loss: 1.9872e-04
Epoch 306/512

Epoch 00306: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9603e-04 - val_loss: 1.9774e-04
Epoch 307/512

Epoch 00307: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9638e-04 - val_loss: 1.9863e-04
Epoch 308/512

Epoch 00308: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9579e-04 - val_loss: 1.9698e-04
Epoch 309/512

Epoch 00309: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9502e-04 - val_loss: 1.9693e-04
Epoch 310/512

Epoch 00310: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9484e-04 - val_loss: 1.9717e-04
Epoch 311/512

Epoch 00311: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9480e-04 - val_loss: 1.9664e-04
Epoch 312/512

Epoch 00312: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9424e-04 - val_loss: 1.9574e-04
Epoch 313/512

Epoch 00313: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9358e-04 - val_loss: 1.9611e-04
Epoch 314/512

Epoch 00314: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9383e-04 - val_loss: 1.9520e-04
Epoch 315/512

Epoch 00315: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9264e-04 - val_loss: 1.9553e-04
Epoch 316/512

Epoch 00316: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9386e-04 - val_loss: 1.9544e-04
Epoch 317/512

Epoch 00317: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9244e-04 - val_loss: 1.9396e-04
Epoch 318/512

Epoch 00318: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9135e-04 - val_loss: 1.9415e-04
Epoch 319/512

Epoch 00319: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9233e-04 - val_loss: 1.9473e-04
Epoch 320/512

Epoch 00320: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9211e-04 - val_loss: 1.9298e-04
Epoch 321/512

Epoch 00321: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9007e-04 - val_loss: 1.9248e-04
Epoch 322/512

Epoch 00322: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9071e-04 - val_loss: 1.9366e-04
Epoch 323/512

Epoch 00323: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9128e-04 - val_loss: 1.9248e-04
Epoch 324/512

Epoch 00324: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8906e-04 - val_loss: 1.9046e-04
Epoch 325/512

Epoch 00325: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8977e-04 - val_loss: 1.9354e-04
Epoch 326/512

Epoch 00326: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.9050e-04 - val_loss: 1.9158e-04
Epoch 327/512

Epoch 00327: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8834e-04 - val_loss: 1.9003e-04
Epoch 328/512

Epoch 00328: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8756e-04 - val_loss: 1.9161e-04
Epoch 329/512

Epoch 00329: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8967e-04 - val_loss: 1.9176e-04
Epoch 330/512

Epoch 00330: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8754e-04 - val_loss: 1.8857e-04
Epoch 331/512

Epoch 00331: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8699e-04 - val_loss: 1.9004e-04
Epoch 332/512

Epoch 00332: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8758e-04 - val_loss: 1.9010e-04
Epoch 333/512

Epoch 00333: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8724e-04 - val_loss: 1.8874e-04
Epoch 334/512

Epoch 00334: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8597e-04 - val_loss: 1.8870e-04
Epoch 335/512

Epoch 00335: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8667e-04 - val_loss: 1.8913e-04
Epoch 336/512

Epoch 00336: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8570e-04 - val_loss: 1.8805e-04
Epoch 337/512

Epoch 00337: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8512e-04 - val_loss: 1.8807e-04
Epoch 338/512

Epoch 00338: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8593e-04 - val_loss: 1.8809e-04
Epoch 339/512

Epoch 00339: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8467e-04 - val_loss: 1.8619e-04
Epoch 340/512

Epoch 00340: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8440e-04 - val_loss: 1.8808e-04
Epoch 341/512

Epoch 00341: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8419e-04 - val_loss: 1.8607e-04
Epoch 342/512

Epoch 00342: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8337e-04 - val_loss: 1.8618e-04
Epoch 343/512

Epoch 00343: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8387e-04 - val_loss: 1.8735e-04
Epoch 344/512

Epoch 00344: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8376e-04 - val_loss: 1.8490e-04
Epoch 345/512

Epoch 00345: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8169e-04 - val_loss: 1.8479e-04
Epoch 346/512

Epoch 00346: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8268e-04 - val_loss: 1.8604e-04
Epoch 347/512

Epoch 00347: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8226e-04 - val_loss: 1.8444e-04
Epoch 348/512

Epoch 00348: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8192e-04 - val_loss: 1.8441e-04
Epoch 349/512

Epoch 00349: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8122e-04 - val_loss: 1.8410e-04
Epoch 350/512

Epoch 00350: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8170e-04 - val_loss: 1.8400e-04
Epoch 351/512

Epoch 00351: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8063e-04 - val_loss: 1.8340e-04
Epoch 352/512

Epoch 00352: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8024e-04 - val_loss: 1.8270e-04
Epoch 353/512

Epoch 00353: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.8026e-04 - val_loss: 1.8276e-04
Epoch 354/512

Epoch 00354: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7996e-04 - val_loss: 1.8200e-04
Epoch 355/512

Epoch 00355: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7925e-04 - val_loss: 1.8274e-04
Epoch 356/512

Epoch 00356: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7968e-04 - val_loss: 1.8175e-04
Epoch 357/512

Epoch 00357: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7821e-04 - val_loss: 1.8071e-04
Epoch 358/512

Epoch 00358: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7863e-04 - val_loss: 1.8199e-04
Epoch 359/512

Epoch 00359: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7899e-04 - val_loss: 1.8087e-04
Epoch 360/512

Epoch 00360: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7735e-04 - val_loss: 1.7938e-04
Epoch 361/512

Epoch 00361: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7719e-04 - val_loss: 1.8104e-04
Epoch 362/512

Epoch 00362: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7781e-04 - val_loss: 1.8053e-04
Epoch 363/512

Epoch 00363: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7663e-04 - val_loss: 1.7961e-04
Epoch 364/512

Epoch 00364: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7701e-04 - val_loss: 1.7919e-04
Epoch 365/512

Epoch 00365: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7572e-04 - val_loss: 1.7855e-04
Epoch 366/512

Epoch 00366: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7628e-04 - val_loss: 1.7969e-04
Epoch 367/512

Epoch 00367: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7596e-04 - val_loss: 1.7763e-04
Epoch 368/512

Epoch 00368: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7474e-04 - val_loss: 1.7825e-04
Epoch 369/512

Epoch 00369: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7550e-04 - val_loss: 1.7903e-04
Epoch 370/512

Epoch 00370: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7551e-04 - val_loss: 1.7765e-04
Epoch 371/512

Epoch 00371: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7391e-04 - val_loss: 1.7715e-04
Epoch 372/512

Epoch 00372: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7422e-04 - val_loss: 1.7749e-04
Epoch 373/512

Epoch 00373: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7431e-04 - val_loss: 1.7680e-04
Epoch 374/512

Epoch 00374: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7288e-04 - val_loss: 1.7539e-04
Epoch 375/512

Epoch 00375: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7257e-04 - val_loss: 1.7727e-04
Epoch 376/512

Epoch 00376: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7419e-04 - val_loss: 1.7674e-04
Epoch 377/512

Epoch 00377: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7278e-04 - val_loss: 1.7438e-04
Epoch 378/512

Epoch 00378: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7134e-04 - val_loss: 1.7515e-04
Epoch 379/512

Epoch 00379: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7260e-04 - val_loss: 1.7632e-04
Epoch 380/512

Epoch 00380: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7216e-04 - val_loss: 1.7399e-04
Epoch 381/512

Epoch 00381: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7051e-04 - val_loss: 1.7394e-04
Epoch 382/512

Epoch 00382: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7167e-04 - val_loss: 1.7536e-04
Epoch 383/512

Epoch 00383: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7131e-04 - val_loss: 1.7329e-04
Epoch 384/512

Epoch 00384: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7048e-04 - val_loss: 1.7362e-04
Epoch 385/512

Epoch 00385: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7023e-04 - val_loss: 1.7380e-04
Epoch 386/512

Epoch 00386: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6998e-04 - val_loss: 1.7233e-04
Epoch 387/512

Epoch 00387: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6915e-04 - val_loss: 1.7390e-04
Epoch 388/512

Epoch 00388: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.7112e-04 - val_loss: 1.7346e-04
Epoch 389/512

Epoch 00389: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6899e-04 - val_loss: 1.7091e-04
Epoch 390/512

Epoch 00390: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6746e-04 - val_loss: 1.7182e-04
Epoch 391/512

Epoch 00391: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6918e-04 - val_loss: 1.7281e-04
Epoch 392/512

Epoch 00392: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6912e-04 - val_loss: 1.7158e-04
Epoch 393/512

Epoch 00393: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6711e-04 - val_loss: 1.6940e-04
Epoch 394/512

Epoch 00394: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6750e-04 - val_loss: 1.7246e-04
Epoch 395/512

Epoch 00395: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6866e-04 - val_loss: 1.7028e-04
Epoch 396/512

Epoch 00396: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6637e-04 - val_loss: 1.6963e-04
Epoch 397/512

Epoch 00397: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6691e-04 - val_loss: 1.7132e-04
Epoch 398/512

Epoch 00398: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6705e-04 - val_loss: 1.6878e-04
Epoch 399/512

Epoch 00399: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6549e-04 - val_loss: 1.6918e-04
Epoch 400/512

Epoch 00400: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6602e-04 - val_loss: 1.7027e-04
Epoch 401/512

Epoch 00401: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6637e-04 - val_loss: 1.6960e-04
Epoch 402/512

Epoch 00402: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6604e-04 - val_loss: 1.6832e-04
Epoch 403/512

Epoch 00403: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6398e-04 - val_loss: 1.6722e-04
Epoch 404/512

Epoch 00404: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6536e-04 - val_loss: 1.7012e-04
Epoch 405/512

Epoch 00405: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6634e-04 - val_loss: 1.6807e-04
Epoch 406/512

Epoch 00406: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6379e-04 - val_loss: 1.6669e-04
Epoch 407/512

Epoch 00407: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6365e-04 - val_loss: 1.6831e-04
Epoch 408/512

Epoch 00408: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6494e-04 - val_loss: 1.6799e-04
Epoch 409/512

Epoch 00409: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6317e-04 - val_loss: 1.6588e-04
Epoch 410/512

Epoch 00410: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6274e-04 - val_loss: 1.6769e-04
Epoch 411/512

Epoch 00411: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6441e-04 - val_loss: 1.6718e-04
Epoch 412/512

Epoch 00412: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6281e-04 - val_loss: 1.6573e-04
Epoch 413/512

Epoch 00413: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6203e-04 - val_loss: 1.6634e-04
Epoch 414/512

Epoch 00414: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6278e-04 - val_loss: 1.6689e-04
Epoch 415/512

Epoch 00415: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6272e-04 - val_loss: 1.6529e-04
Epoch 416/512

Epoch 00416: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6174e-04 - val_loss: 1.6494e-04
Epoch 417/512

Epoch 00417: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6124e-04 - val_loss: 1.6545e-04
Epoch 418/512

Epoch 00418: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6205e-04 - val_loss: 1.6539e-04
Epoch 419/512

Epoch 00419: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6098e-04 - val_loss: 1.6371e-04
Epoch 420/512

Epoch 00420: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6019e-04 - val_loss: 1.6476e-04
Epoch 421/512

Epoch 00421: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6131e-04 - val_loss: 1.6567e-04
Epoch 422/512

Epoch 00422: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6149e-04 - val_loss: 1.6346e-04
Epoch 423/512

Epoch 00423: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5911e-04 - val_loss: 1.6335e-04
Epoch 424/512

Epoch 00424: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6020e-04 - val_loss: 1.6396e-04
Epoch 425/512

Epoch 00425: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5966e-04 - val_loss: 1.6249e-04
Epoch 426/512

Epoch 00426: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5942e-04 - val_loss: 1.6414e-04
Epoch 427/512

Epoch 00427: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.6009e-04 - val_loss: 1.6268e-04
Epoch 428/512

Epoch 00428: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5828e-04 - val_loss: 1.6153e-04
Epoch 429/512

Epoch 00429: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5875e-04 - val_loss: 1.6392e-04
Epoch 430/512

Epoch 00430: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5973e-04 - val_loss: 1.6269e-04
Epoch 431/512

Epoch 00431: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5847e-04 - val_loss: 1.6150e-04
Epoch 432/512

Epoch 00432: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5723e-04 - val_loss: 1.6153e-04
Epoch 433/512

Epoch 00433: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5829e-04 - val_loss: 1.6268e-04
Epoch 434/512

Epoch 00434: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5835e-04 - val_loss: 1.6150e-04
Epoch 435/512

Epoch 00435: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5718e-04 - val_loss: 1.6047e-04
Epoch 436/512

Epoch 00436: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5663e-04 - val_loss: 1.6031e-04
Epoch 437/512

Epoch 00437: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5707e-04 - val_loss: 1.6188e-04
Epoch 438/512

Epoch 00438: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5696e-04 - val_loss: 1.5983e-04
Epoch 439/512

Epoch 00439: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5673e-04 - val_loss: 1.6104e-04
Epoch 440/512

Epoch 00440: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5687e-04 - val_loss: 1.6063e-04
Epoch 441/512

Epoch 00441: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5629e-04 - val_loss: 1.5900e-04
Epoch 442/512

Epoch 00442: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5518e-04 - val_loss: 1.5958e-04
Epoch 443/512

Epoch 00443: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5600e-04 - val_loss: 1.6028e-04
Epoch 444/512

Epoch 00444: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5582e-04 - val_loss: 1.5919e-04
Epoch 445/512

Epoch 00445: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5542e-04 - val_loss: 1.5912e-04
Epoch 446/512

Epoch 00446: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5479e-04 - val_loss: 1.5844e-04
Epoch 447/512

Epoch 00447: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5497e-04 - val_loss: 1.5970e-04
Epoch 448/512

Epoch 00448: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5552e-04 - val_loss: 1.5817e-04
Epoch 449/512

Epoch 00449: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5393e-04 - val_loss: 1.5766e-04
Epoch 450/512

Epoch 00450: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5426e-04 - val_loss: 1.5865e-04
Epoch 451/512

Epoch 00451: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5522e-04 - val_loss: 1.5892e-04
Epoch 452/512

Epoch 00452: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5393e-04 - val_loss: 1.5651e-04
Epoch 453/512

Epoch 00453: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5233e-04 - val_loss: 1.5693e-04
Epoch 454/512

Epoch 00454: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5343e-04 - val_loss: 1.5899e-04
Epoch 455/512

Epoch 00455: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5441e-04 - val_loss: 1.5650e-04
Epoch 456/512

Epoch 00456: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5231e-04 - val_loss: 1.5642e-04
Epoch 457/512

Epoch 00457: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5292e-04 - val_loss: 1.5729e-04
Epoch 458/512

Epoch 00458: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5357e-04 - val_loss: 1.5670e-04
Epoch 459/512

Epoch 00459: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5190e-04 - val_loss: 1.5462e-04
Epoch 460/512

Epoch 00460: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5172e-04 - val_loss: 1.5698e-04
Epoch 461/512

Epoch 00461: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5301e-04 - val_loss: 1.5611e-04
Epoch 462/512

Epoch 00462: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5181e-04 - val_loss: 1.5544e-04
Epoch 463/512

Epoch 00463: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5216e-04 - val_loss: 1.5627e-04
Epoch 464/512

Epoch 00464: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5153e-04 - val_loss: 1.5446e-04
Epoch 465/512

Epoch 00465: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5057e-04 - val_loss: 1.5574e-04
Epoch 466/512

Epoch 00466: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5195e-04 - val_loss: 1.5619e-04
Epoch 467/512

Epoch 00467: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5133e-04 - val_loss: 1.5422e-04
Epoch 468/512

Epoch 00468: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5004e-04 - val_loss: 1.5450e-04
Epoch 469/512

Epoch 00469: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5070e-04 - val_loss: 1.5486e-04
Epoch 470/512

Epoch 00470: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5054e-04 - val_loss: 1.5429e-04
Epoch 471/512

Epoch 00471: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5072e-04 - val_loss: 1.5443e-04
Epoch 472/512

Epoch 00472: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4994e-04 - val_loss: 1.5346e-04
Epoch 473/512

Epoch 00473: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.5006e-04 - val_loss: 1.5489e-04
Epoch 474/512

Epoch 00474: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4996e-04 - val_loss: 1.5272e-04
Epoch 475/512

Epoch 00475: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4933e-04 - val_loss: 1.5378e-04
Epoch 476/512

Epoch 00476: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4900e-04 - val_loss: 1.5328e-04
Epoch 477/512

Epoch 00477: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4950e-04 - val_loss: 1.5390e-04
Epoch 478/512

Epoch 00478: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4910e-04 - val_loss: 1.5234e-04
Epoch 479/512

Epoch 00479: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4824e-04 - val_loss: 1.5266e-04
Epoch 480/512

Epoch 00480: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4925e-04 - val_loss: 1.5314e-04
Epoch 481/512

Epoch 00481: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4881e-04 - val_loss: 1.5247e-04
Epoch 482/512

Epoch 00482: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4833e-04 - val_loss: 1.5181e-04
Epoch 483/512

Epoch 00483: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4827e-04 - val_loss: 1.5249e-04
Epoch 484/512

Epoch 00484: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4823e-04 - val_loss: 1.5197e-04
Epoch 485/512

Epoch 00485: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4772e-04 - val_loss: 1.5221e-04
Epoch 486/512

Epoch 00486: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4755e-04 - val_loss: 1.5167e-04
Epoch 487/512

Epoch 00487: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4747e-04 - val_loss: 1.5213e-04
Epoch 488/512

Epoch 00488: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4794e-04 - val_loss: 1.5189e-04
Epoch 489/512

Epoch 00489: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4706e-04 - val_loss: 1.5043e-04
Epoch 490/512

Epoch 00490: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4649e-04 - val_loss: 1.5135e-04
Epoch 491/512

Epoch 00491: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4736e-04 - val_loss: 1.5163e-04
Epoch 492/512

Epoch 00492: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4718e-04 - val_loss: 1.5064e-04
Epoch 493/512

Epoch 00493: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4601e-04 - val_loss: 1.5018e-04
Epoch 494/512

Epoch 00494: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4671e-04 - val_loss: 1.5120e-04
Epoch 495/512

Epoch 00495: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4704e-04 - val_loss: 1.5091e-04
Epoch 496/512

Epoch 00496: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4585e-04 - val_loss: 1.4896e-04
Epoch 497/512

Epoch 00497: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4527e-04 - val_loss: 1.5036e-04
Epoch 498/512

Epoch 00498: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4652e-04 - val_loss: 1.4995e-04
Epoch 499/512

Epoch 00499: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4565e-04 - val_loss: 1.4952e-04
Epoch 500/512

Epoch 00500: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4551e-04 - val_loss: 1.4939e-04
Epoch 501/512

Epoch 00501: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4565e-04 - val_loss: 1.4971e-04
Epoch 502/512

Epoch 00502: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4532e-04 - val_loss: 1.4906e-04
Epoch 503/512

Epoch 00503: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4490e-04 - val_loss: 1.4927e-04
Epoch 504/512

Epoch 00504: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4505e-04 - val_loss: 1.4915e-04
Epoch 505/512

Epoch 00505: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4521e-04 - val_loss: 1.4939e-04
Epoch 506/512

Epoch 00506: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4482e-04 - val_loss: 1.4832e-04
Epoch 507/512

Epoch 00507: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4472e-04 - val_loss: 1.4951e-04
Epoch 508/512

Epoch 00508: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4515e-04 - val_loss: 1.4830e-04
Epoch 509/512

Epoch 00509: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4370e-04 - val_loss: 1.4771e-04
Epoch 510/512

Epoch 00510: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4394e-04 - val_loss: 1.4838e-04
Epoch 511/512

Epoch 00511: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4419e-04 - val_loss: 1.4869e-04
Epoch 512/512

Epoch 00512: val_loss did not improve from 0.00004
512/512 - 0s - loss: 1.4423e-04 - val_loss: 1.4853e-04
WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?
WARNING:tensorflow:From /home/stud/minawoi/miniconda3/envs/conda-venv/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?
Epoch   0:   0% | abe: 9.541 | eve: 10.113 | bob: 9.438Epoch   0:   0% | abe: 9.508 | eve: 10.087 | bob: 9.411Epoch   0:   1% | abe: 9.477 | eve: 10.074 | bob: 9.387Epoch   0:   2% | abe: 9.478 | eve: 10.081 | bob: 9.392Epoch   0:   3% | abe: 9.449 | eve: 10.071 | bob: 9.366Epoch   0:   3% | abe: 9.442 | eve: 10.068 | bob: 9.363Epoch   0:   4% | abe: 9.422 | eve: 10.072 | bob: 9.345Epoch   0:   5% | abe: 9.417 | eve: 10.066 | bob: 9.342Epoch   0:   6% | abe: 9.415 | eve: 10.071 | bob: 9.342Epoch   0:   7% | abe: 9.408 | eve: 10.076 | bob: 9.338Epoch   0:   7% | abe: 9.405 | eve: 10.078 | bob: 9.336Epoch   0:   8% | abe: 9.396 | eve: 10.077 | bob: 9.328Epoch   0:   9% | abe: 9.385 | eve: 10.084 | bob: 9.319Epoch   0:  10% | abe: 9.378 | eve: 10.085 | bob: 9.313Epoch   0:  10% | abe: 9.373 | eve: 10.093 | bob: 9.309Epoch   0:  11% | abe: 9.365 | eve: 10.087 | bob: 9.303Epoch   0:  12% | abe: 9.358 | eve: 10.086 | bob: 9.297Epoch   0:  13% | abe: 9.356 | eve: 10.084 | bob: 9.296Epoch   0:  14% | abe: 9.354 | eve: 10.084 | bob: 9.295Epoch   0:  14% | abe: 9.347 | eve: 10.080 | bob: 9.289Epoch   0:  15% | abe: 9.346 | eve: 10.079 | bob: 9.288Epoch   0:  16% | abe: 9.338 | eve: 10.080 | bob: 9.281Epoch   0:  17% | abe: 9.331 | eve: 10.076 | bob: 9.275Epoch   0:  17% | abe: 9.325 | eve: 10.075 | bob: 9.270Epoch   0:  18% | abe: 9.322 | eve: 10.072 | bob: 9.268Epoch   0:  19% | abe: 9.319 | eve: 10.074 | bob: 9.266Epoch   0:  20% | abe: 9.316 | eve: 10.075 | bob: 9.264Epoch   0:  21% | abe: 9.312 | eve: 10.075 | bob: 9.260Epoch   0:  21% | abe: 9.309 | eve: 10.074 | bob: 9.258Epoch   0:  22% | abe: 9.305 | eve: 10.072 | bob: 9.255Epoch   0:  23% | abe: 9.301 | eve: 10.075 | bob: 9.251Epoch   0:  24% | abe: 9.297 | eve: 10.074 | bob: 9.249Epoch   0:  25% | abe: 9.296 | eve: 10.075 | bob: 9.248Epoch   0:  25% | abe: 9.293 | eve: 10.076 | bob: 9.246Epoch   0:  26% | abe: 9.288 | eve: 10.076 | bob: 9.241Epoch   0:  27% | abe: 9.284 | eve: 10.076 | bob: 9.238Epoch   0:  28% | abe: 9.280 | eve: 10.076 | bob: 9.234Epoch   0:  28% | abe: 9.278 | eve: 10.076 | bob: 9.233Epoch   0:  29% | abe: 9.274 | eve: 10.077 | bob: 9.230Epoch   0:  30% | abe: 9.270 | eve: 10.077 | bob: 9.226Epoch   0:  31% | abe: 9.267 | eve: 10.078 | bob: 9.223Epoch   0:  32% | abe: 9.263 | eve: 10.076 | bob: 9.220Epoch   0:  32% | abe: 9.261 | eve: 10.078 | bob: 9.219Epoch   0:  33% | abe: 9.259 | eve: 10.078 | bob: 9.217Epoch   0:  34% | abe: 9.255 | eve: 10.079 | bob: 9.213Epoch   0:  35% | abe: 9.250 | eve: 10.080 | bob: 9.210Epoch   0:  35% | abe: 9.248 | eve: 10.080 | bob: 9.208Epoch   0:  36% | abe: 9.244 | eve: 10.080 | bob: 9.204Epoch   0:  37% | abe: 9.242 | eve: 10.082 | bob: 9.203Epoch   0:  38% | abe: 9.240 | eve: 10.080 | bob: 9.201Epoch   0:  39% | abe: 9.237 | eve: 10.080 | bob: 9.199Epoch   0:  39% | abe: 9.236 | eve: 10.080 | bob: 9.198Epoch   0:  40% | abe: 9.234 | eve: 10.082 | bob: 9.196Epoch   0:  41% | abe: 9.233 | eve: 10.081 | bob: 9.196Epoch   0:  42% | abe: 9.231 | eve: 10.081 | bob: 9.194Epoch   0:  42% | abe: 9.230 | eve: 10.081 | bob: 9.193Epoch   0:  43% | abe: 9.227 | eve: 10.080 | bob: 9.191Epoch   0:  44% | abe: 9.225 | eve: 10.080 | bob: 9.189Epoch   0:  45% | abe: 9.222 | eve: 10.081 | bob: 9.187Epoch   0:  46% | abe: 9.220 | eve: 10.082 | bob: 9.185Epoch   0:  46% | abe: 9.218 | eve: 10.082 | bob: 9.183Epoch   0:  47% | abe: 9.216 | eve: 10.082 | bob: 9.182Epoch   0:  48% | abe: 9.214 | eve: 10.082 | bob: 9.180Epoch   0:  49% | abe: 9.213 | eve: 10.083 | bob: 9.179Epoch   0:  50% | abe: 9.211 | eve: 10.084 | bob: 9.177Epoch   0:  50% | abe: 9.209 | eve: 10.084 | bob: 9.176Epoch   0:  51% | abe: 9.207 | eve: 10.084 | bob: 9.174Epoch   0:  52% | abe: 9.205 | eve: 10.083 | bob: 9.172Epoch   0:  53% | abe: 9.203 | eve: 10.082 | bob: 9.171Epoch   0:  53% | abe: 9.202 | eve: 10.084 | bob: 9.170Epoch   0:  54% | abe: 9.202 | eve: 10.084 | bob: 9.170Epoch   0:  55% | abe: 9.200 | eve: 10.086 | bob: 9.168Epoch   0:  56% | abe: 9.197 | eve: 10.086 | bob: 9.166Epoch   0:  57% | abe: 9.195 | eve: 10.087 | bob: 9.164Epoch   0:  57% | abe: 9.194 | eve: 10.087 | bob: 9.163Epoch   0:  58% | abe: 9.192 | eve: 10.087 | bob: 9.161Epoch   0:  59% | abe: 9.190 | eve: 10.087 | bob: 9.160Epoch   0:  60% | abe: 9.189 | eve: 10.088 | bob: 9.158Epoch   0:  60% | abe: 9.189 | eve: 10.088 | bob: 9.158Epoch   0:  61% | abe: 9.187 | eve: 10.088 | bob: 9.157Epoch   0:  62% | abe: 9.186 | eve: 10.088 | bob: 9.156Epoch   0:  63% | abe: 9.185 | eve: 10.088 | bob: 9.155Epoch   0:  64% | abe: 9.184 | eve: 10.088 | bob: 9.154Epoch   0:  64% | abe: 9.182 | eve: 10.087 | bob: 9.153Epoch   0:  65% | abe: 9.181 | eve: 10.088 | bob: 9.152Epoch   0:  66% | abe: 9.180 | eve: 10.088 | bob: 9.151Epoch   0:  67% | abe: 9.179 | eve: 10.088 | bob: 9.150Epoch   0:  67% | abe: 9.177 | eve: 10.089 | bob: 9.148Epoch   0:  68% | abe: 9.176 | eve: 10.089 | bob: 9.148Epoch   0:  69% | abe: 9.175 | eve: 10.089 | bob: 9.147Epoch   0:  70% | abe: 9.174 | eve: 10.090 | bob: 9.146Epoch   0:  71% | abe: 9.173 | eve: 10.090 | bob: 9.145Epoch   0:  71% | abe: 9.172 | eve: 10.091 | bob: 9.144Epoch   0:  72% | abe: 9.171 | eve: 10.091 | bob: 9.143Epoch   0:  73% | abe: 9.169 | eve: 10.092 | bob: 9.141Epoch   0:  74% | abe: 9.168 | eve: 10.092 | bob: 9.140Epoch   0:  75% | abe: 9.167 | eve: 10.092 | bob: 9.140Epoch   0:  75% | abe: 9.166 | eve: 10.092 | bob: 9.139Epoch   0:  76% | abe: 9.165 | eve: 10.093 | bob: 9.138Epoch   0:  77% | abe: 9.164 | eve: 10.093 | bob: 9.137Epoch   0:  78% | abe: 9.163 | eve: 10.094 | bob: 9.136Epoch   0:  78% | abe: 9.162 | eve: 10.094 | bob: 9.135Epoch   0:  79% | abe: 9.161 | eve: 10.094 | bob: 9.134Epoch   0:  80% | abe: 9.160 | eve: 10.094 | bob: 9.133Epoch   0:  81% | abe: 9.159 | eve: 10.094 | bob: 9.132Epoch   0:  82% | abe: 9.159 | eve: 10.094 | bob: 9.132Epoch   0:  82% | abe: 9.158 | eve: 10.095 | bob: 9.131Epoch   0:  83% | abe: 9.157 | eve: 10.095 | bob: 9.130Epoch   0:  84% | abe: 9.156 | eve: 10.095 | bob: 9.130Epoch   0:  85% | abe: 9.156 | eve: 10.095 | bob: 9.130Epoch   0:  85% | abe: 9.155 | eve: 10.095 | bob: 9.129Epoch   0:  86% | abe: 9.154 | eve: 10.096 | bob: 9.128Epoch   0:  87% | abe: 9.153 | eve: 10.097 | bob: 9.127Epoch   0:  88% | abe: 9.153 | eve: 10.097 | bob: 9.127Epoch   0:  89% | abe: 9.153 | eve: 10.098 | bob: 9.127Epoch   0:  89% | abe: 9.152 | eve: 10.098 | bob: 9.126Epoch   0:  90% | abe: 9.152 | eve: 10.098 | bob: 9.126Epoch   0:  91% | abe: 9.151 | eve: 10.098 | bob: 9.125Epoch   0:  92% | abe: 9.150 | eve: 10.098 | bob: 9.124Epoch   0:  92% | abe: 9.149 | eve: 10.098 | bob: 9.123Epoch   0:  93% | abe: 9.149 | eve: 10.099 | bob: 9.123Epoch   0:  94% | abe: 9.148 | eve: 10.099 | bob: 9.123Epoch   0:  95% | abe: 9.148 | eve: 10.099 | bob: 9.123Epoch   0:  96% | abe: 9.147 | eve: 10.099 | bob: 9.122Epoch   0:  96% | abe: 9.146 | eve: 10.099 | bob: 9.121Epoch   0:  97% | abe: 9.146 | eve: 10.100 | bob: 9.121Epoch   0:  98% | abe: 9.145 | eve: 10.100 | bob: 9.120Epoch   0:  99% | abe: 9.144 | eve: 10.100 | bob: 9.119
New best Bob loss 9.119316133994971 at epoch 0
Epoch   1:   0% | abe: 9.052 | eve: 10.200 | bob: 9.031Epoch   1:   0% | abe: 9.071 | eve: 10.155 | bob: 9.052Epoch   1:   1% | abe: 9.074 | eve: 10.154 | bob: 9.056Epoch   1:   2% | abe: 9.084 | eve: 10.150 | bob: 9.066Epoch   1:   3% | abe: 9.086 | eve: 10.140 | bob: 9.068Epoch   1:   3% | abe: 9.076 | eve: 10.142 | bob: 9.058Epoch   1:   4% | abe: 9.079 | eve: 10.131 | bob: 9.061Epoch   1:   5% | abe: 9.068 | eve: 10.125 | bob: 9.050Epoch   1:   6% | abe: 9.063 | eve: 10.121 | bob: 9.045Epoch   1:   7% | abe: 9.063 | eve: 10.113 | bob: 9.044Epoch   1:   7% | abe: 9.064 | eve: 10.112 | bob: 9.045Epoch   1:   8% | abe: 9.063 | eve: 10.118 | bob: 9.044Epoch   1:   9% | abe: 9.061 | eve: 10.116 | bob: 9.042Epoch   1:  10% | abe: 9.058 | eve: 10.114 | bob: 9.039Epoch   1:  10% | abe: 9.062 | eve: 10.115 | bob: 9.043Epoch   1:  11% | abe: 9.063 | eve: 10.116 | bob: 9.044Epoch   1:  12% | abe: 9.066 | eve: 10.118 | bob: 9.047Epoch   1:  13% | abe: 9.063 | eve: 10.119 | bob: 9.043Epoch   1:  14% | abe: 9.060 | eve: 10.118 | bob: 9.041Epoch   1:  14% | abe: 9.060 | eve: 10.119 | bob: 9.040Epoch   1:  15% | abe: 9.060 | eve: 10.119 | bob: 9.040Epoch   1:  16% | abe: 9.060 | eve: 10.119 | bob: 9.040Epoch   1:  17% | abe: 9.061 | eve: 10.118 | bob: 9.041Epoch   1:  17% | abe: 9.064 | eve: 10.119 | bob: 9.044Epoch   1:  18% | abe: 9.063 | eve: 10.121 | bob: 9.043Epoch   1:  19% | abe: 9.062 | eve: 10.121 | bob: 9.042Epoch   1:  20% | abe: 9.061 | eve: 10.120 | bob: 9.041Epoch   1:  21% | abe: 9.060 | eve: 10.120 | bob: 9.040Epoch   1:  21% | abe: 9.063 | eve: 10.120 | bob: 9.042Epoch   1:  22% | abe: 9.062 | eve: 10.121 | bob: 9.041Epoch   1:  23% | abe: 9.061 | eve: 10.122 | bob: 9.041Epoch   1:  24% | abe: 9.062 | eve: 10.121 | bob: 9.041Epoch   1:  25% | abe: 9.060 | eve: 10.121 | bob: 9.039Epoch   1:  25% | abe: 9.059 | eve: 10.124 | bob: 9.038Epoch   1:  26% | abe: 9.059 | eve: 10.125 | bob: 9.038Epoch   1:  27% | abe: 9.059 | eve: 10.125 | bob: 9.038Epoch   1:  28% | abe: 9.060 | eve: 10.127 | bob: 9.039Epoch   1:  28% | abe: 9.061 | eve: 10.127 | bob: 9.039Epoch   1:  29% | abe: 9.061 | eve: 10.129 | bob: 9.039Epoch   1:  30% | abe: 9.060 | eve: 10.129 | bob: 9.038Epoch   1:  31% | abe: 9.059 | eve: 10.132 | bob: 9.038Epoch   1:  32% | abe: 9.059 | eve: 10.131 | bob: 9.037Epoch   1:  32% | abe: 9.059 | eve: 10.134 | bob: 9.038Epoch   1:  33% | abe: 9.061 | eve: 10.133 | bob: 9.039Epoch   1:  34% | abe: 9.060 | eve: 10.134 | bob: 9.038Epoch   1:  35% | abe: 9.060 | eve: 10.134 | bob: 9.038Epoch   1:  35% | abe: 9.060 | eve: 10.135 | bob: 9.038Epoch   1:  36% | abe: 9.061 | eve: 10.135 | bob: 9.040Epoch   1:  37% | abe: 9.061 | eve: 10.134 | bob: 9.039Epoch   1:  38% | abe: 9.062 | eve: 10.135 | bob: 9.040Epoch   1:  39% | abe: 9.062 | eve: 10.137 | bob: 9.041Epoch   1:  39% | abe: 9.063 | eve: 10.137 | bob: 9.041Epoch   1:  40% | abe: 9.063 | eve: 10.138 | bob: 9.041Epoch   1:  41% | abe: 9.062 | eve: 10.138 | bob: 9.040Epoch   1:  42% | abe: 9.061 | eve: 10.140 | bob: 9.039Epoch   1:  42% | abe: 9.061 | eve: 10.139 | bob: 9.040Epoch   1:  43% | abe: 9.061 | eve: 10.140 | bob: 9.039Epoch   1:  44% | abe: 9.061 | eve: 10.140 | bob: 9.039Epoch   1:  45% | abe: 9.062 | eve: 10.140 | bob: 9.040Epoch   1:  46% | abe: 9.063 | eve: 10.141 | bob: 9.041Epoch   1:  46% | abe: 9.062 | eve: 10.141 | bob: 9.040Epoch   1:  47% | abe: 9.062 | eve: 10.142 | bob: 9.040Epoch   1:  48% | abe: 9.063 | eve: 10.143 | bob: 9.042Epoch   1:  49% | abe: 9.063 | eve: 10.144 | bob: 9.041Epoch   1:  50% | abe: 9.063 | eve: 10.144 | bob: 9.041Epoch   1:  50% | abe: 9.062 | eve: 10.146 | bob: 9.040Epoch   1:  51% | abe: 9.062 | eve: 10.146 | bob: 9.040Epoch   1:  52% | abe: 9.063 | eve: 10.145 | bob: 9.040Epoch   1:  53% | abe: 9.062 | eve: 10.146 | bob: 9.040Epoch   1:  53% | abe: 9.062 | eve: 10.146 | bob: 9.039Epoch   1:  54% | abe: 9.061 | eve: 10.146 | bob: 9.039Epoch   1:  55% | abe: 9.061 | eve: 10.147 | bob: 9.039Epoch   1:  56% | abe: 9.061 | eve: 10.147 | bob: 9.038Epoch   1:  57% | abe: 9.061 | eve: 10.148 | bob: 9.039Epoch   1:  57% | abe: 9.062 | eve: 10.147 | bob: 9.039Epoch   1:  58% | abe: 9.061 | eve: 10.147 | bob: 9.039Epoch   1:  59% | abe: 9.062 | eve: 10.148 | bob: 9.039Epoch   1:  60% | abe: 9.062 | eve: 10.147 | bob: 9.039Epoch   1:  60% | abe: 9.062 | eve: 10.146 | bob: 9.039Epoch   1:  61% | abe: 9.062 | eve: 10.147 | bob: 9.039Epoch   1:  62% | abe: 9.061 | eve: 10.147 | bob: 9.039Epoch   1:  63% | abe: 9.061 | eve: 10.148 | bob: 9.038Epoch   1:  64% | abe: 9.061 | eve: 10.148 | bob: 9.038Epoch   1:  64% | abe: 9.061 | eve: 10.148 | bob: 9.038Epoch   1:  65% | abe: 9.061 | eve: 10.148 | bob: 9.038Epoch   1:  66% | abe: 9.061 | eve: 10.148 | bob: 9.038Epoch   1:  67% | abe: 9.061 | eve: 10.148 | bob: 9.038Epoch   1:  67% | abe: 9.061 | eve: 10.150 | bob: 9.038Epoch   1:  68% | abe: 9.060 | eve: 10.150 | bob: 9.037Epoch   1:  69% | abe: 9.060 | eve: 10.151 | bob: 9.037Epoch   1:  70% | abe: 9.060 | eve: 10.151 | bob: 9.037Epoch   1:  71% | abe: 9.060 | eve: 10.151 | bob: 9.037Epoch   1:  71% | abe: 9.060 | eve: 10.152 | bob: 9.037Epoch   1:  72% | abe: 9.059 | eve: 10.153 | bob: 9.036Epoch   1:  73% | abe: 9.060 | eve: 10.153 | bob: 9.036Epoch   1:  74% | abe: 9.060 | eve: 10.154 | bob: 9.036Epoch   1:  75% | abe: 9.059 | eve: 10.154 | bob: 9.036Epoch   1:  75% | abe: 9.059 | eve: 10.154 | bob: 9.036Epoch   1:  76% | abe: 9.059 | eve: 10.155 | bob: 9.036Epoch   1:  77% | abe: 9.059 | eve: 10.155 | bob: 9.036Epoch   1:  78% | abe: 9.059 | eve: 10.155 | bob: 9.036Epoch   1:  78% | abe: 9.060 | eve: 10.155 | bob: 9.036Epoch   1:  79% | abe: 9.060 | eve: 10.156 | bob: 9.037Epoch   1:  80% | abe: 9.060 | eve: 10.156 | bob: 9.037Epoch   1:  81% | abe: 9.060 | eve: 10.156 | bob: 9.036Epoch   1:  82% | abe: 9.060 | eve: 10.157 | bob: 9.036Epoch   1:  82% | abe: 9.059 | eve: 10.157 | bob: 9.036Epoch   1:  83% | abe: 9.060 | eve: 10.157 | bob: 9.036Epoch   1:  84% | abe: 9.059 | eve: 10.157 | bob: 9.035Epoch   1:  85% | abe: 9.059 | eve: 10.158 | bob: 9.035Epoch   1:  85% | abe: 9.058 | eve: 10.158 | bob: 9.035Epoch   1:  86% | abe: 9.058 | eve: 10.158 | bob: 9.034Epoch   1:  87% | abe: 9.058 | eve: 10.159 | bob: 9.034Epoch   1:  88% | abe: 9.058 | eve: 10.159 | bob: 9.034Epoch   1:  89% | abe: 9.058 | eve: 10.159 | bob: 9.034Epoch   1:  89% | abe: 9.058 | eve: 10.159 | bob: 9.034Epoch   1:  90% | abe: 9.058 | eve: 10.159 | bob: 9.034Epoch   1:  91% | abe: 9.058 | eve: 10.159 | bob: 9.034Epoch   1:  92% | abe: 9.059 | eve: 10.159 | bob: 9.034Epoch   1:  92% | abe: 9.058 | eve: 10.159 | bob: 9.034Epoch   1:  93% | abe: 9.058 | eve: 10.160 | bob: 9.034Epoch   1:  94% | abe: 9.058 | eve: 10.160 | bob: 9.034Epoch   1:  95% | abe: 9.058 | eve: 10.160 | bob: 9.033Epoch   1:  96% | abe: 9.058 | eve: 10.161 | bob: 9.033Epoch   1:  96% | abe: 9.058 | eve: 10.161 | bob: 9.033Epoch   1:  97% | abe: 9.058 | eve: 10.161 | bob: 9.033Epoch   1:  98% | abe: 9.058 | eve: 10.161 | bob: 9.033Epoch   1:  99% | abe: 9.058 | eve: 10.161 | bob: 9.033
New best Bob loss 9.033268201398414 at epoch 1
Epoch   2:   0% | abe: 9.008 | eve: 10.150 | bob: 8.979Epoch   2:   0% | abe: 9.036 | eve: 10.197 | bob: 9.007Epoch   2:   1% | abe: 9.037 | eve: 10.178 | bob: 9.008Epoch   2:   2% | abe: 9.038 | eve: 10.178 | bob: 9.009Epoch   2:   3% | abe: 9.038 | eve: 10.184 | bob: 9.009Epoch   2:   3% | abe: 9.038 | eve: 10.186 | bob: 9.010Epoch   2:   4% | abe: 9.044 | eve: 10.187 | bob: 9.015Epoch   2:   5% | abe: 9.044 | eve: 10.181 | bob: 9.015Epoch   2:   6% | abe: 9.048 | eve: 10.187 | bob: 9.019Epoch   2:   7% | abe: 9.050 | eve: 10.188 | bob: 9.021Epoch   2:   7% | abe: 9.053 | eve: 10.192 | bob: 9.025Epoch   2:   8% | abe: 9.055 | eve: 10.198 | bob: 9.027Epoch   2:   9% | abe: 9.052 | eve: 10.194 | bob: 9.024Epoch   2:  10% | abe: 9.052 | eve: 10.192 | bob: 9.023Epoch   2:  10% | abe: 9.055 | eve: 10.194 | bob: 9.026Epoch   2:  11% | abe: 9.058 | eve: 10.196 | bob: 9.029Epoch   2:  12% | abe: 9.055 | eve: 10.199 | bob: 9.026Epoch   2:  13% | abe: 9.053 | eve: 10.200 | bob: 9.024Epoch   2:  14% | abe: 9.055 | eve: 10.202 | bob: 9.026Epoch   2:  14% | abe: 9.056 | eve: 10.203 | bob: 9.027Epoch   2:  15% | abe: 9.054 | eve: 10.203 | bob: 9.025Epoch   2:  16% | abe: 9.051 | eve: 10.201 | bob: 9.022Epoch   2:  17% | abe: 9.051 | eve: 10.202 | bob: 9.022Epoch   2:  17% | abe: 9.051 | eve: 10.200 | bob: 9.022Epoch   2:  18% | abe: 9.052 | eve: 10.200 | bob: 9.023Epoch   2:  19% | abe: 9.052 | eve: 10.199 | bob: 9.023Epoch   2:  20% | abe: 9.051 | eve: 10.199 | bob: 9.022Epoch   2:  21% | abe: 9.051 | eve: 10.198 | bob: 9.022Epoch   2:  21% | abe: 9.050 | eve: 10.198 | bob: 9.021Epoch   2:  22% | abe: 9.051 | eve: 10.193 | bob: 9.022Epoch   2:  23% | abe: 9.051 | eve: 10.194 | bob: 9.021Epoch   2:  24% | abe: 9.050 | eve: 10.194 | bob: 9.021Epoch   2:  25% | abe: 9.050 | eve: 10.196 | bob: 9.021Epoch   2:  25% | abe: 9.051 | eve: 10.195 | bob: 9.021Epoch   2:  26% | abe: 9.050 | eve: 10.195 | bob: 9.021Epoch   2:  27% | abe: 9.050 | eve: 10.195 | bob: 9.021Epoch   2:  28% | abe: 9.051 | eve: 10.194 | bob: 9.022Epoch   2:  28% | abe: 9.051 | eve: 10.195 | bob: 9.021Epoch   2:  29% | abe: 9.051 | eve: 10.196 | bob: 9.021Epoch   2:  30% | abe: 9.050 | eve: 10.197 | bob: 9.021Epoch   2:  31% | abe: 9.050 | eve: 10.196 | bob: 9.021Epoch   2:  32% | abe: 9.050 | eve: 10.198 | bob: 9.020Epoch   2:  32% | abe: 9.050 | eve: 10.198 | bob: 9.020Epoch   2:  33% | abe: 9.049 | eve: 10.198 | bob: 9.019Epoch   2:  34% | abe: 9.049 | eve: 10.198 | bob: 9.019Epoch   2:  35% | abe: 9.049 | eve: 10.198 | bob: 9.019Epoch   2:  35% | abe: 9.049 | eve: 10.198 | bob: 9.019Epoch   2:  36% | abe: 9.050 | eve: 10.198 | bob: 9.020Epoch   2:  37% | abe: 9.050 | eve: 10.199 | bob: 9.021Epoch   2:  38% | abe: 9.051 | eve: 10.200 | bob: 9.021Epoch   2:  39% | abe: 9.051 | eve: 10.200 | bob: 9.021Epoch   2:  39% | abe: 9.050 | eve: 10.201 | bob: 9.020Epoch   2:  40% | abe: 9.049 | eve: 10.202 | bob: 9.019Epoch   2:  41% | abe: 9.050 | eve: 10.203 | bob: 9.020Epoch   2:  42% | abe: 9.050 | eve: 10.201 | bob: 9.020Epoch   2:  42% | abe: 9.051 | eve: 10.201 | bob: 9.021Epoch   2:  43% | abe: 9.051 | eve: 10.203 | bob: 9.021Epoch   2:  44% | abe: 9.050 | eve: 10.202 | bob: 9.020Epoch   2:  45% | abe: 9.050 | eve: 10.202 | bob: 9.021Epoch   2:  46% | abe: 9.050 | eve: 10.201 | bob: 9.020Epoch   2:  46% | abe: 9.049 | eve: 10.201 | bob: 9.020Epoch   2:  47% | abe: 9.050 | eve: 10.201 | bob: 9.020Epoch   2:  48% | abe: 9.049 | eve: 10.201 | bob: 9.019Epoch   2:  49% | abe: 9.049 | eve: 10.202 | bob: 9.019Epoch   2:  50% | abe: 9.050 | eve: 10.202 | bob: 9.020Epoch   2:  50% | abe: 9.050 | eve: 10.202 | bob: 9.020Epoch   2:  51% | abe: 9.050 | eve: 10.202 | bob: 9.020Epoch   2:  52% | abe: 9.050 | eve: 10.201 | bob: 9.020Epoch   2:  53% | abe: 9.050 | eve: 10.202 | bob: 9.020Epoch   2:  53% | abe: 9.050 | eve: 10.202 | bob: 9.020Epoch   2:  54% | abe: 9.050 | eve: 10.203 | bob: 9.020Epoch   2:  55% | abe: 9.051 | eve: 10.202 | bob: 9.021Epoch   2:  56% | abe: 9.050 | eve: 10.204 | bob: 9.020Epoch   2:  57% | abe: 9.051 | eve: 10.204 | bob: 9.021Epoch   2:  57% | abe: 9.050 | eve: 10.206 | bob: 9.020Epoch   2:  58% | abe: 9.050 | eve: 10.205 | bob: 9.020Epoch   2:  59% | abe: 9.050 | eve: 10.205 | bob: 9.020Epoch   2:  60% | abe: 9.050 | eve: 10.206 | bob: 9.020Epoch   2:  60% | abe: 9.051 | eve: 10.206 | bob: 9.021Epoch   2:  61% | abe: 9.051 | eve: 10.206 | bob: 9.021Epoch   2:  62% | abe: 9.051 | eve: 10.206 | bob: 9.021Epoch   2:  63% | abe: 9.051 | eve: 10.206 | bob: 9.020Epoch   2:  64% | abe: 9.050 | eve: 10.206 | bob: 9.020Epoch   2:  64% | abe: 9.050 | eve: 10.205 | bob: 9.020Epoch   2:  65% | abe: 9.051 | eve: 10.205 | bob: 9.020Epoch   2:  66% | abe: 9.051 | eve: 10.205 | bob: 9.020Epoch   2:  67% | abe: 9.050 | eve: 10.205 | bob: 9.020Epoch   2:  67% | abe: 9.050 | eve: 10.205 | bob: 9.020Epoch   2:  68% | abe: 9.051 | eve: 10.206 | bob: 9.020Epoch   2:  69% | abe: 9.051 | eve: 10.207 | bob: 9.020Epoch   2:  70% | abe: 9.051 | eve: 10.207 | bob: 9.021Epoch   2:  71% | abe: 9.052 | eve: 10.207 | bob: 9.021Epoch   2:  71% | abe: 9.052 | eve: 10.208 | bob: 9.022Epoch   2:  72% | abe: 9.052 | eve: 10.208 | bob: 9.021Epoch   2:  73% | abe: 9.052 | eve: 10.207 | bob: 9.022Epoch   2:  74% | abe: 9.053 | eve: 10.207 | bob: 9.022Epoch   2:  75% | abe: 9.053 | eve: 10.208 | bob: 9.022Epoch   2:  75% | abe: 9.053 | eve: 10.208 | bob: 9.022Epoch   2:  76% | abe: 9.053 | eve: 10.208 | bob: 9.022Epoch   2:  77% | abe: 9.052 | eve: 10.208 | bob: 9.022Epoch   2:  78% | abe: 9.053 | eve: 10.208 | bob: 9.022Epoch   2:  78% | abe: 9.053 | eve: 10.208 | bob: 9.022Epoch   2:  79% | abe: 9.053 | eve: 10.208 | bob: 9.022Epoch   2:  80% | abe: 9.053 | eve: 10.207 | bob: 9.022Epoch   2:  81% | abe: 9.053 | eve: 10.207 | bob: 9.022Epoch   2:  82% | abe: 9.053 | eve: 10.207 | bob: 9.022Epoch   2:  82% | abe: 9.053 | eve: 10.207 | bob: 9.022Epoch   2:  83% | abe: 9.053 | eve: 10.207 | bob: 9.022Epoch   2:  84% | abe: 9.053 | eve: 10.208 | bob: 9.022Epoch   2:  85% | abe: 9.052 | eve: 10.208 | bob: 9.022Epoch   2:  85% | abe: 9.052 | eve: 10.208 | bob: 9.022Epoch   2:  86% | abe: 9.053 | eve: 10.208 | bob: 9.022Epoch   2:  87% | abe: 9.052 | eve: 10.208 | bob: 9.022Epoch   2:  88% | abe: 9.053 | eve: 10.208 | bob: 9.022Epoch   2:  89% | abe: 9.053 | eve: 10.208 | bob: 9.022Epoch   2:  89% | abe: 9.053 | eve: 10.208 | bob: 9.022Epoch   2:  90% | abe: 9.053 | eve: 10.207 | bob: 9.022Epoch   2:  91% | abe: 9.053 | eve: 10.208 | bob: 9.022Epoch   2:  92% | abe: 9.053 | eve: 10.208 | bob: 9.022Epoch   2:  92% | abe: 9.053 | eve: 10.208 | bob: 9.022Epoch   2:  93% | abe: 9.053 | eve: 10.208 | bob: 9.022Epoch   2:  94% | abe: 9.053 | eve: 10.208 | bob: 9.022Epoch   2:  95% | abe: 9.054 | eve: 10.207 | bob: 9.023Epoch   2:  96% | abe: 9.054 | eve: 10.208 | bob: 9.023Epoch   2:  96% | abe: 9.054 | eve: 10.208 | bob: 9.023Epoch   2:  97% | abe: 9.054 | eve: 10.208 | bob: 9.022Epoch   2:  98% | abe: 9.054 | eve: 10.208 | bob: 9.022Epoch   2:  99% | abe: 9.054 | eve: 10.209 | bob: 9.023
New best Bob loss 9.022618858828082 at epoch 2
Epoch   3:   0% | abe: 9.036 | eve: 10.185 | bob: 9.001Epoch   3:   0% | abe: 9.058 | eve: 10.196 | bob: 9.023Epoch   3:   1% | abe: 9.037 | eve: 10.217 | bob: 9.002Epoch   3:   2% | abe: 9.047 | eve: 10.235 | bob: 9.013Epoch   3:   3% | abe: 9.062 | eve: 10.222 | bob: 9.027Epoch   3:   3% | abe: 9.063 | eve: 10.229 | bob: 9.028Epoch   3:   4% | abe: 9.069 | eve: 10.226 | bob: 9.035Epoch   3:   5% | abe: 9.064 | eve: 10.232 | bob: 9.030Epoch   3:   6% | abe: 9.066 | eve: 10.231 | bob: 9.032Epoch   3:   7% | abe: 9.064 | eve: 10.231 | bob: 9.030Epoch   3:   7% | abe: 9.062 | eve: 10.234 | bob: 9.028Epoch   3:   8% | abe: 9.055 | eve: 10.240 | bob: 9.021Epoch   3:   9% | abe: 9.058 | eve: 10.238 | bob: 9.024Epoch   3:  10% | abe: 9.059 | eve: 10.235 | bob: 9.025Epoch   3:  10% | abe: 9.059 | eve: 10.230 | bob: 9.025Epoch   3:  11% | abe: 9.057 | eve: 10.226 | bob: 9.023Epoch   3:  12% | abe: 9.057 | eve: 10.227 | bob: 9.023Epoch   3:  13% | abe: 9.061 | eve: 10.225 | bob: 9.027Epoch   3:  14% | abe: 9.059 | eve: 10.221 | bob: 9.025Epoch   3:  14% | abe: 9.060 | eve: 10.221 | bob: 9.026Epoch   3:  15% | abe: 9.060 | eve: 10.219 | bob: 9.026Epoch   3:  16% | abe: 9.060 | eve: 10.218 | bob: 9.026Epoch   3:  17% | abe: 9.063 | eve: 10.219 | bob: 9.029Epoch   3:  17% | abe: 9.064 | eve: 10.220 | bob: 9.030Epoch   3:  18% | abe: 9.062 | eve: 10.219 | bob: 9.029Epoch   3:  19% | abe: 9.059 | eve: 10.218 | bob: 9.026Epoch   3:  20% | abe: 9.059 | eve: 10.216 | bob: 9.025Epoch   3:  21% | abe: 9.059 | eve: 10.216 | bob: 9.025Epoch   3:  21% | abe: 9.058 | eve: 10.218 | bob: 9.025Epoch   3:  22% | abe: 9.059 | eve: 10.218 | bob: 9.026Epoch   3:  23% | abe: 9.058 | eve: 10.220 | bob: 9.024Epoch   3:  24% | abe: 9.058 | eve: 10.218 | bob: 9.024Epoch   3:  25% | abe: 9.057 | eve: 10.219 | bob: 9.023Epoch   3:  25% | abe: 9.056 | eve: 10.220 | bob: 9.022Epoch   3:  26% | abe: 9.055 | eve: 10.217 | bob: 9.021Epoch   3:  27% | abe: 9.053 | eve: 10.217 | bob: 9.019Epoch   3:  28% | abe: 9.054 | eve: 10.218 | bob: 9.021Epoch   3:  28% | abe: 9.054 | eve: 10.219 | bob: 9.021Epoch   3:  29% | abe: 9.054 | eve: 10.220 | bob: 9.020Epoch   3:  30% | abe: 9.052 | eve: 10.220 | bob: 9.018Epoch   3:  31% | abe: 9.052 | eve: 10.221 | bob: 9.018Epoch   3:  32% | abe: 9.052 | eve: 10.222 | bob: 9.017Epoch   3:  32% | abe: 9.050 | eve: 10.222 | bob: 9.016Epoch   3:  33% | abe: 9.049 | eve: 10.222 | bob: 9.015Epoch   3:  34% | abe: 9.050 | eve: 10.223 | bob: 9.016Epoch   3:  35% | abe: 9.049 | eve: 10.222 | bob: 9.015Epoch   3:  35% | abe: 9.049 | eve: 10.222 | bob: 9.015Epoch   3:  36% | abe: 9.049 | eve: 10.221 | bob: 9.015Epoch   3:  37% | abe: 9.049 | eve: 10.222 | bob: 9.015Epoch   3:  38% | abe: 9.050 | eve: 10.222 | bob: 9.015Epoch   3:  39% | abe: 9.050 | eve: 10.222 | bob: 9.015Epoch   3:  39% | abe: 9.050 | eve: 10.221 | bob: 9.015Epoch   3:  40% | abe: 9.050 | eve: 10.221 | bob: 9.015Epoch   3:  41% | abe: 9.049 | eve: 10.220 | bob: 9.015Epoch   3:  42% | abe: 9.050 | eve: 10.220 | bob: 9.015Epoch   3:  42% | abe: 9.050 | eve: 10.218 | bob: 9.015Epoch   3:  43% | abe: 9.050 | eve: 10.219 | bob: 9.016Epoch   3:  44% | abe: 9.050 | eve: 10.220 | bob: 9.015Epoch   3:  45% | abe: 9.050 | eve: 10.219 | bob: 9.016Epoch   3:  46% | abe: 9.050 | eve: 10.220 | bob: 9.015Epoch   3:  46% | abe: 9.050 | eve: 10.222 | bob: 9.015Epoch   3:  47% | abe: 9.050 | eve: 10.221 | bob: 9.015Epoch   3:  48% | abe: 9.051 | eve: 10.222 | bob: 9.016Epoch   3:  49% | abe: 9.050 | eve: 10.223 | bob: 9.015Epoch   3:  50% | abe: 9.051 | eve: 10.224 | bob: 9.016Epoch   3:  50% | abe: 9.050 | eve: 10.225 | bob: 9.015Epoch   3:  51% | abe: 9.050 | eve: 10.224 | bob: 9.015Epoch   3:  52% | abe: 9.050 | eve: 10.223 | bob: 9.015Epoch   3:  53% | abe: 9.050 | eve: 10.224 | bob: 9.015Epoch   3:  53% | abe: 9.051 | eve: 10.224 | bob: 9.016Epoch   3:  54% | abe: 9.051 | eve: 10.224 | bob: 9.016Epoch   3:  55% | abe: 9.051 | eve: 10.223 | bob: 9.016Epoch   3:  56% | abe: 9.051 | eve: 10.224 | bob: 9.016Epoch   3:  57% | abe: 9.051 | eve: 10.223 | bob: 9.016Epoch   3:  57% | abe: 9.051 | eve: 10.223 | bob: 9.016Epoch   3:  58% | abe: 9.051 | eve: 10.223 | bob: 9.016Epoch   3:  59% | abe: 9.051 | eve: 10.223 | bob: 9.016Epoch   3:  60% | abe: 9.051 | eve: 10.223 | bob: 9.016Epoch   3:  60% | abe: 9.051 | eve: 10.224 | bob: 9.016Epoch   3:  61% | abe: 9.051 | eve: 10.224 | bob: 9.016Epoch   3:  62% | abe: 9.051 | eve: 10.224 | bob: 9.016Epoch   3:  63% | abe: 9.051 | eve: 10.225 | bob: 9.015Epoch   3:  64% | abe: 9.052 | eve: 10.226 | bob: 9.016Epoch   3:  64% | abe: 9.052 | eve: 10.226 | bob: 9.016Epoch   3:  65% | abe: 9.052 | eve: 10.226 | bob: 9.017Epoch   3:  66% | abe: 9.053 | eve: 10.226 | bob: 9.018Epoch   3:  67% | abe: 9.053 | eve: 10.226 | bob: 9.018Epoch   3:  67% | abe: 9.053 | eve: 10.225 | bob: 9.018Epoch   3:  68% | abe: 9.053 | eve: 10.225 | bob: 9.018Epoch   3:  69% | abe: 9.053 | eve: 10.226 | bob: 9.018Epoch   3:  70% | abe: 9.053 | eve: 10.225 | bob: 9.018Epoch   3:  71% | abe: 9.053 | eve: 10.226 | bob: 9.017Epoch   3:  71% | abe: 9.052 | eve: 10.226 | bob: 9.017Epoch   3:  72% | abe: 9.052 | eve: 10.226 | bob: 9.017Epoch   3:  73% | abe: 9.053 | eve: 10.226 | bob: 9.017Epoch   3:  74% | abe: 9.052 | eve: 10.227 | bob: 9.017Epoch   3:  75% | abe: 9.053 | eve: 10.227 | bob: 9.017Epoch   3:  75% | abe: 9.053 | eve: 10.227 | bob: 9.017Epoch   3:  76% | abe: 9.053 | eve: 10.227 | bob: 9.017Epoch   3:  77% | abe: 9.053 | eve: 10.227 | bob: 9.017Epoch   3:  78% | abe: 9.053 | eve: 10.227 | bob: 9.017Epoch   3:  78% | abe: 9.053 | eve: 10.226 | bob: 9.017Epoch   3:  79% | abe: 9.053 | eve: 10.227 | bob: 9.017Epoch   3:  80% | abe: 9.052 | eve: 10.228 | bob: 9.017Epoch   3:  81% | abe: 9.052 | eve: 10.227 | bob: 9.017Epoch   3:  82% | abe: 9.053 | eve: 10.228 | bob: 9.017Epoch   3:  82% | abe: 9.053 | eve: 10.228 | bob: 9.017Epoch   3:  83% | abe: 9.053 | eve: 10.229 | bob: 9.017Epoch   3:  84% | abe: 9.053 | eve: 10.229 | bob: 9.018Epoch   3:  85% | abe: 9.053 | eve: 10.229 | bob: 9.018Epoch   3:  85% | abe: 9.053 | eve: 10.230 | bob: 9.018Epoch   3:  86% | abe: 9.053 | eve: 10.230 | bob: 9.017Epoch   3:  87% | abe: 9.053 | eve: 10.231 | bob: 9.018Epoch   3:  88% | abe: 9.053 | eve: 10.230 | bob: 9.018Epoch   3:  89% | abe: 9.053 | eve: 10.231 | bob: 9.017Epoch   3:  89% | abe: 9.053 | eve: 10.231 | bob: 9.017Epoch   3:  90% | abe: 9.053 | eve: 10.231 | bob: 9.017Epoch   3:  91% | abe: 9.053 | eve: 10.230 | bob: 9.017Epoch   3:  92% | abe: 9.053 | eve: 10.230 | bob: 9.017Epoch   3:  92% | abe: 9.053 | eve: 10.231 | bob: 9.017Epoch   3:  93% | abe: 9.053 | eve: 10.231 | bob: 9.017Epoch   3:  94% | abe: 9.053 | eve: 10.231 | bob: 9.017Epoch   3:  95% | abe: 9.053 | eve: 10.231 | bob: 9.017Epoch   3:  96% | abe: 9.053 | eve: 10.232 | bob: 9.017Epoch   3:  96% | abe: 9.053 | eve: 10.232 | bob: 9.017Epoch   3:  97% | abe: 9.053 | eve: 10.232 | bob: 9.017Epoch   3:  98% | abe: 9.054 | eve: 10.232 | bob: 9.018Epoch   3:  99% | abe: 9.053 | eve: 10.233 | bob: 9.017
New best Bob loss 9.017163042503626 at epoch 3
Epoch   4:   0% | abe: 9.044 | eve: 10.310 | bob: 9.004Epoch   4:   0% | abe: 9.019 | eve: 10.320 | bob: 8.978Epoch   4:   1% | abe: 9.015 | eve: 10.302 | bob: 8.974Epoch   4:   2% | abe: 9.031 | eve: 10.271 | bob: 8.990Epoch   4:   3% | abe: 9.031 | eve: 10.263 | bob: 8.991Epoch   4:   3% | abe: 9.033 | eve: 10.268 | bob: 8.993Epoch   4:   4% | abe: 9.034 | eve: 10.269 | bob: 8.994Epoch   4:   5% | abe: 9.041 | eve: 10.259 | bob: 9.002Epoch   4:   6% | abe: 9.043 | eve: 10.261 | bob: 9.003Epoch   4:   7% | abe: 9.045 | eve: 10.266 | bob: 9.006Epoch   4:   7% | abe: 9.046 | eve: 10.256 | bob: 9.006Epoch   4:   8% | abe: 9.046 | eve: 10.257 | bob: 9.006Epoch   4:   9% | abe: 9.039 | eve: 10.251 | bob: 8.999Epoch   4:  10% | abe: 9.040 | eve: 10.250 | bob: 9.000Epoch   4:  10% | abe: 9.044 | eve: 10.250 | bob: 9.004Epoch   4:  11% | abe: 9.043 | eve: 10.249 | bob: 9.003Epoch   4:  12% | abe: 9.044 | eve: 10.245 | bob: 9.004Epoch   4:  13% | abe: 9.043 | eve: 10.248 | bob: 9.004Epoch   4:  14% | abe: 9.045 | eve: 10.253 | bob: 9.006Epoch   4:  14% | abe: 9.046 | eve: 10.252 | bob: 9.006Epoch   4:  15% | abe: 9.046 | eve: 10.252 | bob: 9.006Epoch   4:  16% | abe: 9.046 | eve: 10.255 | bob: 9.007Epoch   4:  17% | abe: 9.047 | eve: 10.254 | bob: 9.007Epoch   4:  17% | abe: 9.047 | eve: 10.256 | bob: 9.007Epoch   4:  18% | abe: 9.046 | eve: 10.258 | bob: 9.006Epoch   4:  19% | abe: 9.045 | eve: 10.257 | bob: 9.005Epoch   4:  20% | abe: 9.044 | eve: 10.258 | bob: 9.005Epoch   4:  21% | abe: 9.044 | eve: 10.257 | bob: 9.005Epoch   4:  21% | abe: 9.045 | eve: 10.257 | bob: 9.005Epoch   4:  22% | abe: 9.045 | eve: 10.259 | bob: 9.005Epoch   4:  23% | abe: 9.046 | eve: 10.259 | bob: 9.006Epoch   4:  24% | abe: 9.045 | eve: 10.263 | bob: 9.005Epoch   4:  25% | abe: 9.045 | eve: 10.265 | bob: 9.005Epoch   4:  25% | abe: 9.047 | eve: 10.263 | bob: 9.007Epoch   4:  26% | abe: 9.047 | eve: 10.262 | bob: 9.007Epoch   4:  27% | abe: 9.048 | eve: 10.262 | bob: 9.008Epoch   4:  28% | abe: 9.046 | eve: 10.265 | bob: 9.006Epoch   4:  28% | abe: 9.045 | eve: 10.264 | bob: 9.005Epoch   4:  29% | abe: 9.046 | eve: 10.263 | bob: 9.006Epoch   4:  30% | abe: 9.046 | eve: 10.263 | bob: 9.006Epoch   4:  31% | abe: 9.045 | eve: 10.262 | bob: 9.005Epoch   4:  32% | abe: 9.045 | eve: 10.262 | bob: 9.005Epoch   4:  32% | abe: 9.045 | eve: 10.261 | bob: 9.004Epoch   4:  33% | abe: 9.045 | eve: 10.261 | bob: 9.004Epoch   4:  34% | abe: 9.044 | eve: 10.261 | bob: 9.004Epoch   4:  35% | abe: 9.044 | eve: 10.263 | bob: 9.004Epoch   4:  35% | abe: 9.044 | eve: 10.262 | bob: 9.004Epoch   4:  36% | abe: 9.044 | eve: 10.261 | bob: 9.004Epoch   4:  37% | abe: 9.045 | eve: 10.261 | bob: 9.004Epoch   4:  38% | abe: 9.045 | eve: 10.261 | bob: 9.004Epoch   4:  39% | abe: 9.044 | eve: 10.261 | bob: 9.003Epoch   4:  39% | abe: 9.042 | eve: 10.262 | bob: 9.002Epoch   4:  40% | abe: 9.042 | eve: 10.261 | bob: 9.002Epoch   4:  41% | abe: 9.043 | eve: 10.260 | bob: 9.002Epoch   4:  42% | abe: 9.044 | eve: 10.260 | bob: 9.003Epoch   4:  42% | abe: 9.045 | eve: 10.259 | bob: 9.005Epoch   4:  43% | abe: 9.046 | eve: 10.259 | bob: 9.005Epoch   4:  44% | abe: 9.045 | eve: 10.259 | bob: 9.005Epoch   4:  45% | abe: 9.045 | eve: 10.259 | bob: 9.005Epoch   4:  46% | abe: 9.045 | eve: 10.258 | bob: 9.004Epoch   4:  46% | abe: 9.045 | eve: 10.258 | bob: 9.005Epoch   4:  47% | abe: 9.045 | eve: 10.258 | bob: 9.005Epoch   4:  48% | abe: 9.045 | eve: 10.258 | bob: 9.004Epoch   4:  49% | abe: 9.045 | eve: 10.258 | bob: 9.004Epoch   4:  50% | abe: 9.045 | eve: 10.257 | bob: 9.004Epoch   4:  50% | abe: 9.046 | eve: 10.256 | bob: 9.005Epoch   4:  51% | abe: 9.046 | eve: 10.257 | bob: 9.005Epoch   4:  52% | abe: 9.046 | eve: 10.257 | bob: 9.005Epoch   4:  53% | abe: 9.046 | eve: 10.256 | bob: 9.005Epoch   4:  53% | abe: 9.046 | eve: 10.256 | bob: 9.006Epoch   4:  54% | abe: 9.047 | eve: 10.255 | bob: 9.006Epoch   4:  55% | abe: 9.045 | eve: 10.256 | bob: 9.005Epoch   4:  56% | abe: 9.046 | eve: 10.256 | bob: 9.005Epoch   4:  57% | abe: 9.046 | eve: 10.254 | bob: 9.005Epoch   4:  57% | abe: 9.046 | eve: 10.254 | bob: 9.005Epoch   4:  58% | abe: 9.046 | eve: 10.254 | bob: 9.005Epoch   4:  59% | abe: 9.047 | eve: 10.252 | bob: 9.006Epoch   4:  60% | abe: 9.046 | eve: 10.252 | bob: 9.005Epoch   4:  60% | abe: 9.046 | eve: 10.251 | bob: 9.005Epoch   4:  61% | abe: 9.046 | eve: 10.251 | bob: 9.005Epoch   4:  62% | abe: 9.047 | eve: 10.251 | bob: 9.006Epoch   4:  63% | abe: 9.048 | eve: 10.252 | bob: 9.007Epoch   4:  64% | abe: 9.047 | eve: 10.252 | bob: 9.007Epoch   4:  64% | abe: 9.047 | eve: 10.251 | bob: 9.006Epoch   4:  65% | abe: 9.048 | eve: 10.250 | bob: 9.007Epoch   4:  66% | abe: 9.048 | eve: 10.250 | bob: 9.007Epoch   4:  67% | abe: 9.048 | eve: 10.250 | bob: 9.007Epoch   4:  67% | abe: 9.048 | eve: 10.250 | bob: 9.008Epoch   4:  68% | abe: 9.049 | eve: 10.249 | bob: 9.008Epoch   4:  69% | abe: 9.049 | eve: 10.249 | bob: 9.008Epoch   4:  70% | abe: 9.048 | eve: 10.250 | bob: 9.008Epoch   4:  71% | abe: 9.049 | eve: 10.250 | bob: 9.008Epoch   4:  71% | abe: 9.048 | eve: 10.250 | bob: 9.007Epoch   4:  72% | abe: 9.048 | eve: 10.250 | bob: 9.007Epoch   4:  73% | abe: 9.048 | eve: 10.250 | bob: 9.007Epoch   4:  74% | abe: 9.048 | eve: 10.250 | bob: 9.007Epoch   4:  75% | abe: 9.048 | eve: 10.251 | bob: 9.007Epoch   4:  75% | abe: 9.048 | eve: 10.252 | bob: 9.007Epoch   4:  76% | abe: 9.048 | eve: 10.251 | bob: 9.007Epoch   4:  77% | abe: 9.047 | eve: 10.251 | bob: 9.006Epoch   4:  78% | abe: 9.047 | eve: 10.251 | bob: 9.006Epoch   4:  78% | abe: 9.047 | eve: 10.251 | bob: 9.006Epoch   4:  79% | abe: 9.047 | eve: 10.251 | bob: 9.006Epoch   4:  80% | abe: 9.048 | eve: 10.251 | bob: 9.007Epoch   4:  81% | abe: 9.048 | eve: 10.251 | bob: 9.007Epoch   4:  82% | abe: 9.049 | eve: 10.251 | bob: 9.008Epoch   4:  82% | abe: 9.049 | eve: 10.251 | bob: 9.008Epoch   4:  83% | abe: 9.049 | eve: 10.251 | bob: 9.008Epoch   4:  84% | abe: 9.049 | eve: 10.250 | bob: 9.008Epoch   4:  85% | abe: 9.049 | eve: 10.250 | bob: 9.008Epoch   4:  85% | abe: 9.049 | eve: 10.250 | bob: 9.008Epoch   4:  86% | abe: 9.049 | eve: 10.249 | bob: 9.008Epoch   4:  87% | abe: 9.049 | eve: 10.249 | bob: 9.008Epoch   4:  88% | abe: 9.049 | eve: 10.249 | bob: 9.008Epoch   4:  89% | abe: 9.049 | eve: 10.249 | bob: 9.008Epoch   4:  89% | abe: 9.049 | eve: 10.248 | bob: 9.008Epoch   4:  90% | abe: 9.049 | eve: 10.248 | bob: 9.008Epoch   4:  91% | abe: 9.049 | eve: 10.249 | bob: 9.008Epoch   4:  92% | abe: 9.049 | eve: 10.249 | bob: 9.008Epoch   4:  92% | abe: 9.049 | eve: 10.250 | bob: 9.008Epoch   4:  93% | abe: 9.049 | eve: 10.250 | bob: 9.008Epoch   4:  94% | abe: 9.049 | eve: 10.250 | bob: 9.008Epoch   4:  95% | abe: 9.049 | eve: 10.250 | bob: 9.008Epoch   4:  96% | abe: 9.049 | eve: 10.251 | bob: 9.008Epoch   4:  96% | abe: 9.049 | eve: 10.250 | bob: 9.008Epoch   4:  97% | abe: 9.049 | eve: 10.251 | bob: 9.008Epoch   4:  98% | abe: 9.050 | eve: 10.251 | bob: 9.008Epoch   4:  99% | abe: 9.049 | eve: 10.251 | bob: 9.008
New best Bob loss 9.00801138354177 at epoch 4
Epoch   5:   0% | abe: 9.041 | eve: 10.308 | bob: 8.997Epoch   5:   0% | abe: 9.062 | eve: 10.289 | bob: 9.019Epoch   5:   1% | abe: 9.061 | eve: 10.283 | bob: 9.018Epoch   5:   2% | abe: 9.057 | eve: 10.269 | bob: 9.013Epoch   5:   3% | abe: 9.052 | eve: 10.276 | bob: 9.008Epoch   5:   3% | abe: 9.053 | eve: 10.283 | bob: 9.009Epoch   5:   4% | abe: 9.059 | eve: 10.277 | bob: 9.015Epoch   5:   5% | abe: 9.048 | eve: 10.275 | bob: 9.004Epoch   5:   6% | abe: 9.046 | eve: 10.272 | bob: 9.002Epoch   5:   7% | abe: 9.043 | eve: 10.264 | bob: 8.999Epoch   5:   7% | abe: 9.044 | eve: 10.270 | bob: 9.000Epoch   5:   8% | abe: 9.043 | eve: 10.271 | bob: 8.999Epoch   5:   9% | abe: 9.042 | eve: 10.271 | bob: 8.997Epoch   5:  10% | abe: 9.040 | eve: 10.273 | bob: 8.996Epoch   5:  10% | abe: 9.043 | eve: 10.272 | bob: 8.998Epoch   5:  11% | abe: 9.048 | eve: 10.271 | bob: 9.004Epoch   5:  12% | abe: 9.047 | eve: 10.277 | bob: 9.003Epoch   5:  13% | abe: 9.048 | eve: 10.275 | bob: 9.004Epoch   5:  14% | abe: 9.044 | eve: 10.274 | bob: 9.000Epoch   5:  14% | abe: 9.047 | eve: 10.274 | bob: 9.003Epoch   5:  15% | abe: 9.049 | eve: 10.274 | bob: 9.005Epoch   5:  16% | abe: 9.048 | eve: 10.274 | bob: 9.004Epoch   5:  17% | abe: 9.050 | eve: 10.274 | bob: 9.006Epoch   5:  17% | abe: 9.049 | eve: 10.275 | bob: 9.005Epoch   5:  18% | abe: 9.051 | eve: 10.275 | bob: 9.007Epoch   5:  19% | abe: 9.049 | eve: 10.274 | bob: 9.005Epoch   5:  20% | abe: 9.047 | eve: 10.273 | bob: 9.003Epoch   5:  21% | abe: 9.047 | eve: 10.273 | bob: 9.003Epoch   5:  21% | abe: 9.047 | eve: 10.272 | bob: 9.003Epoch   5:  22% | abe: 9.048 | eve: 10.271 | bob: 9.004Epoch   5:  23% | abe: 9.048 | eve: 10.270 | bob: 9.004Epoch   5:  24% | abe: 9.048 | eve: 10.267 | bob: 9.004Epoch   5:  25% | abe: 9.047 | eve: 10.267 | bob: 9.003Epoch   5:  25% | abe: 9.045 | eve: 10.266 | bob: 9.001Epoch   5:  26% | abe: 9.045 | eve: 10.265 | bob: 9.001Epoch   5:  27% | abe: 9.046 | eve: 10.267 | bob: 9.002Epoch   5:  28% | abe: 9.047 | eve: 10.266 | bob: 9.003Epoch   5:  28% | abe: 9.048 | eve: 10.266 | bob: 9.003Epoch   5:  29% | abe: 9.047 | eve: 10.266 | bob: 9.003Epoch   5:  30% | abe: 9.048 | eve: 10.267 | bob: 9.003Epoch   5:  31% | abe: 9.047 | eve: 10.265 | bob: 9.002Epoch   5:  32% | abe: 9.048 | eve: 10.265 | bob: 9.003Epoch   5:  32% | abe: 9.048 | eve: 10.267 | bob: 9.004Epoch   5:  33% | abe: 9.048 | eve: 10.266 | bob: 9.003Epoch   5:  34% | abe: 9.047 | eve: 10.265 | bob: 9.003Epoch   5:  35% | abe: 9.048 | eve: 10.266 | bob: 9.003Epoch   5:  35% | abe: 9.048 | eve: 10.266 | bob: 9.003Epoch   5:  36% | abe: 9.048 | eve: 10.266 | bob: 9.003Epoch   5:  37% | abe: 9.047 | eve: 10.266 | bob: 9.002Epoch   5:  38% | abe: 9.046 | eve: 10.265 | bob: 9.002Epoch   5:  39% | abe: 9.048 | eve: 10.266 | bob: 9.003Epoch   5:  39% | abe: 9.047 | eve: 10.265 | bob: 9.003Epoch   5:  40% | abe: 9.046 | eve: 10.266 | bob: 9.002Epoch   5:  41% | abe: 9.048 | eve: 10.265 | bob: 9.004Epoch   5:  42% | abe: 9.048 | eve: 10.265 | bob: 9.003Epoch   5:  42% | abe: 9.047 | eve: 10.265 | bob: 9.003Epoch   5:  43% | abe: 9.047 | eve: 10.263 | bob: 9.002Epoch   5:  44% | abe: 9.048 | eve: 10.264 | bob: 9.003Epoch   5:  45% | abe: 9.048 | eve: 10.264 | bob: 9.004Epoch   5:  46% | abe: 9.049 | eve: 10.265 | bob: 9.004Epoch   5:  46% | abe: 9.049 | eve: 10.265 | bob: 9.005Epoch   5:  47% | abe: 9.049 | eve: 10.265 | bob: 9.005Epoch   5:  48% | abe: 9.048 | eve: 10.265 | bob: 9.004Epoch   5:  49% | abe: 9.049 | eve: 10.265 | bob: 9.005Epoch   5:  50% | abe: 9.049 | eve: 10.264 | bob: 9.005Epoch   5:  50% | abe: 9.049 | eve: 10.263 | bob: 9.005Epoch   5:  51% | abe: 9.048 | eve: 10.263 | bob: 9.004Epoch   5:  52% | abe: 9.048 | eve: 10.262 | bob: 9.004Epoch   5:  53% | abe: 9.049 | eve: 10.262 | bob: 9.005Epoch   5:  53% | abe: 9.049 | eve: 10.262 | bob: 9.005Epoch   5:  54% | abe: 9.048 | eve: 10.262 | bob: 9.004Epoch   5:  55% | abe: 9.048 | eve: 10.264 | bob: 9.004Epoch   5:  56% | abe: 9.047 | eve: 10.263 | bob: 9.003Epoch   5:  57% | abe: 9.047 | eve: 10.264 | bob: 9.003Epoch   5:  57% | abe: 9.047 | eve: 10.264 | bob: 9.003Epoch   5:  58% | abe: 9.047 | eve: 10.265 | bob: 9.003Epoch   5:  59% | abe: 9.047 | eve: 10.264 | bob: 9.003Epoch   5:  60% | abe: 9.047 | eve: 10.263 | bob: 9.003Epoch   5:  60% | abe: 9.047 | eve: 10.263 | bob: 9.003Epoch   5:  61% | abe: 9.047 | eve: 10.263 | bob: 9.003Epoch   5:  62% | abe: 9.047 | eve: 10.264 | bob: 9.003Epoch   5:  63% | abe: 9.047 | eve: 10.263 | bob: 9.003Epoch   5:  64% | abe: 9.047 | eve: 10.263 | bob: 9.003Epoch   5:  64% | abe: 9.048 | eve: 10.263 | bob: 9.003Epoch   5:  65% | abe: 9.047 | eve: 10.264 | bob: 9.003Epoch   5:  66% | abe: 9.047 | eve: 10.264 | bob: 9.003Epoch   5:  67% | abe: 9.047 | eve: 10.263 | bob: 9.003Epoch   5:  67% | abe: 9.047 | eve: 10.263 | bob: 9.003Epoch   5:  68% | abe: 9.046 | eve: 10.263 | bob: 9.002Epoch   5:  69% | abe: 9.046 | eve: 10.263 | bob: 9.002Epoch   5:  70% | abe: 9.046 | eve: 10.263 | bob: 9.001Epoch   5:  71% | abe: 9.046 | eve: 10.263 | bob: 9.002Epoch   5:  71% | abe: 9.046 | eve: 10.263 | bob: 9.002Epoch   5:  72% | abe: 9.046 | eve: 10.263 | bob: 9.002Epoch   5:  73% | abe: 9.046 | eve: 10.263 | bob: 9.002Epoch   5:  74% | abe: 9.046 | eve: 10.264 | bob: 9.001Epoch   5:  75% | abe: 9.045 | eve: 10.264 | bob: 9.001Epoch   5:  75% | abe: 9.045 | eve: 10.264 | bob: 9.000Epoch   5:  76% | abe: 9.045 | eve: 10.265 | bob: 9.000Epoch   5:  77% | abe: 9.045 | eve: 10.264 | bob: 9.000Epoch   5:  78% | abe: 9.045 | eve: 10.265 | bob: 9.000Epoch   5:  78% | abe: 9.045 | eve: 10.265 | bob: 9.001Epoch   5:  79% | abe: 9.045 | eve: 10.264 | bob: 9.000Epoch   5:  80% | abe: 9.045 | eve: 10.264 | bob: 9.001Epoch   5:  81% | abe: 9.045 | eve: 10.265 | bob: 9.001Epoch   5:  82% | abe: 9.045 | eve: 10.265 | bob: 9.000Epoch   5:  82% | abe: 9.045 | eve: 10.265 | bob: 9.001Epoch   5:  83% | abe: 9.045 | eve: 10.265 | bob: 9.001Epoch   5:  84% | abe: 9.046 | eve: 10.264 | bob: 9.001Epoch   5:  85% | abe: 9.045 | eve: 10.265 | bob: 9.001Epoch   5:  85% | abe: 9.045 | eve: 10.265 | bob: 9.001Epoch   5:  86% | abe: 9.046 | eve: 10.265 | bob: 9.001Epoch   5:  87% | abe: 9.046 | eve: 10.265 | bob: 9.001Epoch   5:  88% | abe: 9.046 | eve: 10.265 | bob: 9.001Epoch   5:  89% | abe: 9.046 | eve: 10.266 | bob: 9.001Epoch   5:  89% | abe: 9.047 | eve: 10.266 | bob: 9.002Epoch   5:  90% | abe: 9.047 | eve: 10.266 | bob: 9.002Epoch   5:  91% | abe: 9.046 | eve: 10.266 | bob: 9.001Epoch   5:  92% | abe: 9.046 | eve: 10.266 | bob: 9.001Epoch   5:  92% | abe: 9.046 | eve: 10.265 | bob: 9.001Epoch   5:  93% | abe: 9.046 | eve: 10.266 | bob: 9.001Epoch   5:  94% | abe: 9.046 | eve: 10.266 | bob: 9.001Epoch   5:  95% | abe: 9.046 | eve: 10.266 | bob: 9.001Epoch   5:  96% | abe: 9.046 | eve: 10.266 | bob: 9.001Epoch   5:  96% | abe: 9.046 | eve: 10.266 | bob: 9.001Epoch   5:  97% | abe: 9.046 | eve: 10.267 | bob: 9.001Epoch   5:  98% | abe: 9.046 | eve: 10.266 | bob: 9.001Epoch   5:  99% | abe: 9.046 | eve: 10.266 | bob: 9.001
New best Bob loss 9.001107054724116 at epoch 5
Epoch   6:   0% | abe: 9.048 | eve: 10.306 | bob: 9.003Epoch   6:   0% | abe: 9.035 | eve: 10.270 | bob: 8.990Epoch   6:   1% | abe: 9.044 | eve: 10.291 | bob: 8.998Epoch   6:   2% | abe: 9.045 | eve: 10.269 | bob: 8.999Epoch   6:   3% | abe: 9.044 | eve: 10.264 | bob: 8.998Epoch   6:   3% | abe: 9.035 | eve: 10.263 | bob: 8.989Epoch   6:   4% | abe: 9.041 | eve: 10.279 | bob: 8.995Epoch   6:   5% | abe: 9.046 | eve: 10.270 | bob: 9.001Epoch   6:   6% | abe: 9.041 | eve: 10.274 | bob: 8.996Epoch   6:   7% | abe: 9.041 | eve: 10.276 | bob: 8.995Epoch   6:   7% | abe: 9.040 | eve: 10.280 | bob: 8.994Epoch   6:   8% | abe: 9.041 | eve: 10.276 | bob: 8.996Epoch   6:   9% | abe: 9.038 | eve: 10.278 | bob: 8.992Epoch   6:  10% | abe: 9.043 | eve: 10.275 | bob: 8.997Epoch   6:  10% | abe: 9.044 | eve: 10.273 | bob: 8.999Epoch   6:  11% | abe: 9.047 | eve: 10.270 | bob: 9.001Epoch   6:  12% | abe: 9.048 | eve: 10.269 | bob: 9.002Epoch   6:  13% | abe: 9.048 | eve: 10.270 | bob: 9.003Epoch   6:  14% | abe: 9.048 | eve: 10.263 | bob: 9.002Epoch   6:  14% | abe: 9.046 | eve: 10.265 | bob: 9.000Epoch   6:  15% | abe: 9.046 | eve: 10.266 | bob: 9.000Epoch   6:  16% | abe: 9.046 | eve: 10.269 | bob: 9.000Epoch   6:  17% | abe: 9.047 | eve: 10.269 | bob: 9.001Epoch   6:  17% | abe: 9.046 | eve: 10.264 | bob: 9.000Epoch   6:  18% | abe: 9.048 | eve: 10.265 | bob: 9.002Epoch   6:  19% | abe: 9.045 | eve: 10.269 | bob: 9.000Epoch   6:  20% | abe: 9.047 | eve: 10.273 | bob: 9.001Epoch   6:  21% | abe: 9.046 | eve: 10.274 | bob: 9.000Epoch   6:  21% | abe: 9.045 | eve: 10.272 | bob: 8.999Epoch   6:  22% | abe: 9.044 | eve: 10.271 | bob: 8.998Epoch   6:  23% | abe: 9.043 | eve: 10.273 | bob: 8.997Epoch   6:  24% | abe: 9.043 | eve: 10.271 | bob: 8.997Epoch   6:  25% | abe: 9.042 | eve: 10.274 | bob: 8.996Epoch   6:  25% | abe: 9.041 | eve: 10.273 | bob: 8.995Epoch   6:  26% | abe: 9.040 | eve: 10.273 | bob: 8.994Epoch   6:  27% | abe: 9.040 | eve: 10.273 | bob: 8.994Epoch   6:  28% | abe: 9.040 | eve: 10.274 | bob: 8.994Epoch   6:  28% | abe: 9.041 | eve: 10.273 | bob: 8.995Epoch   6:  29% | abe: 9.042 | eve: 10.273 | bob: 8.997Epoch   6:  30% | abe: 9.042 | eve: 10.273 | bob: 8.996Epoch   6:  31% | abe: 9.041 | eve: 10.274 | bob: 8.995Epoch   6:  32% | abe: 9.042 | eve: 10.274 | bob: 8.996Epoch   6:  32% | abe: 9.041 | eve: 10.276 | bob: 8.995Epoch   6:  33% | abe: 9.040 | eve: 10.275 | bob: 8.994Epoch   6:  34% | abe: 9.039 | eve: 10.275 | bob: 8.993Epoch   6:  35% | abe: 9.039 | eve: 10.275 | bob: 8.993Epoch   6:  35% | abe: 9.041 | eve: 10.276 | bob: 8.995Epoch   6:  36% | abe: 9.041 | eve: 10.276 | bob: 8.995Epoch   6:  37% | abe: 9.043 | eve: 10.276 | bob: 8.997Epoch   6:  38% | abe: 9.043 | eve: 10.276 | bob: 8.997Epoch   6:  39% | abe: 9.043 | eve: 10.276 | bob: 8.997Epoch   6:  39% | abe: 9.042 | eve: 10.276 | bob: 8.996Epoch   6:  40% | abe: 9.043 | eve: 10.276 | bob: 8.997Epoch   6:  41% | abe: 9.043 | eve: 10.276 | bob: 8.998Epoch   6:  42% | abe: 9.043 | eve: 10.276 | bob: 8.997Epoch   6:  42% | abe: 9.043 | eve: 10.275 | bob: 8.997Epoch   6:  43% | abe: 9.043 | eve: 10.276 | bob: 8.998Epoch   6:  44% | abe: 9.044 | eve: 10.276 | bob: 8.998Epoch   6:  45% | abe: 9.045 | eve: 10.276 | bob: 8.999Epoch   6:  46% | abe: 9.045 | eve: 10.274 | bob: 8.999Epoch   6:  46% | abe: 9.046 | eve: 10.275 | bob: 9.000Epoch   6:  47% | abe: 9.046 | eve: 10.275 | bob: 9.000Epoch   6:  48% | abe: 9.046 | eve: 10.275 | bob: 9.000Epoch   6:  49% | abe: 9.047 | eve: 10.274 | bob: 9.001Epoch   6:  50% | abe: 9.047 | eve: 10.274 | bob: 9.001Epoch   6:  50% | abe: 9.047 | eve: 10.274 | bob: 9.001Epoch   6:  51% | abe: 9.047 | eve: 10.275 | bob: 9.002Epoch   6:  52% | abe: 9.048 | eve: 10.275 | bob: 9.002Epoch   6:  53% | abe: 9.047 | eve: 10.275 | bob: 9.002Epoch   6:  53% | abe: 9.048 | eve: 10.275 | bob: 9.003Epoch   6:  54% | abe: 9.049 | eve: 10.274 | bob: 9.003Epoch   6:  55% | abe: 9.048 | eve: 10.273 | bob: 9.002Epoch   6:  56% | abe: 9.048 | eve: 10.273 | bob: 9.002Epoch   6:  57% | abe: 9.048 | eve: 10.272 | bob: 9.003Epoch   6:  57% | abe: 9.048 | eve: 10.272 | bob: 9.002Epoch   6:  58% | abe: 9.049 | eve: 10.270 | bob: 9.003Epoch   6:  59% | abe: 9.049 | eve: 10.270 | bob: 9.003Epoch   6:  60% | abe: 9.048 | eve: 10.269 | bob: 9.002Epoch   6:  60% | abe: 9.048 | eve: 10.269 | bob: 9.003Epoch   6:  61% | abe: 9.048 | eve: 10.268 | bob: 9.003Epoch   6:  62% | abe: 9.048 | eve: 10.268 | bob: 9.002Epoch   6:  63% | abe: 9.048 | eve: 10.268 | bob: 9.003Epoch   6:  64% | abe: 9.048 | eve: 10.268 | bob: 9.002Epoch   6:  64% | abe: 9.048 | eve: 10.268 | bob: 9.003Epoch   6:  65% | abe: 9.048 | eve: 10.268 | bob: 9.002Epoch   6:  66% | abe: 9.049 | eve: 10.268 | bob: 9.003Epoch   6:  67% | abe: 9.049 | eve: 10.268 | bob: 9.003Epoch   6:  67% | abe: 9.049 | eve: 10.267 | bob: 9.003Epoch   6:  68% | abe: 9.049 | eve: 10.267 | bob: 9.003Epoch   6:  69% | abe: 9.049 | eve: 10.267 | bob: 9.004Epoch   6:  70% | abe: 9.049 | eve: 10.266 | bob: 9.004Epoch   6:  71% | abe: 9.049 | eve: 10.267 | bob: 9.003Epoch   6:  71% | abe: 9.049 | eve: 10.266 | bob: 9.003Epoch   6:  72% | abe: 9.049 | eve: 10.266 | bob: 9.003Epoch   6:  73% | abe: 9.049 | eve: 10.266 | bob: 9.003Epoch   6:  74% | abe: 9.049 | eve: 10.266 | bob: 9.003Epoch   6:  75% | abe: 9.048 | eve: 10.266 | bob: 9.003Epoch   6:  75% | abe: 9.048 | eve: 10.266 | bob: 9.002Epoch   6:  76% | abe: 9.047 | eve: 10.266 | bob: 9.002Epoch   6:  77% | abe: 9.047 | eve: 10.266 | bob: 9.002Epoch   6:  78% | abe: 9.047 | eve: 10.266 | bob: 9.002Epoch   6:  78% | abe: 9.047 | eve: 10.266 | bob: 9.002Epoch   6:  79% | abe: 9.048 | eve: 10.267 | bob: 9.002Epoch   6:  80% | abe: 9.048 | eve: 10.266 | bob: 9.002Epoch   6:  81% | abe: 9.047 | eve: 10.266 | bob: 9.002Epoch   6:  82% | abe: 9.048 | eve: 10.266 | bob: 9.002Epoch   6:  82% | abe: 9.048 | eve: 10.266 | bob: 9.002Epoch   6:  83% | abe: 9.047 | eve: 10.266 | bob: 9.002Epoch   6:  84% | abe: 9.047 | eve: 10.266 | bob: 9.002Epoch   6:  85% | abe: 9.048 | eve: 10.266 | bob: 9.002Epoch   6:  85% | abe: 9.048 | eve: 10.266 | bob: 9.003Epoch   6:  86% | abe: 9.048 | eve: 10.265 | bob: 9.003Epoch   6:  87% | abe: 9.048 | eve: 10.265 | bob: 9.003Epoch   6:  88% | abe: 9.048 | eve: 10.265 | bob: 9.003Epoch   6:  89% | abe: 9.048 | eve: 10.264 | bob: 9.003Epoch   6:  89% | abe: 9.048 | eve: 10.264 | bob: 9.003Epoch   6:  90% | abe: 9.048 | eve: 10.264 | bob: 9.003Epoch   6:  91% | abe: 9.047 | eve: 10.264 | bob: 9.002Epoch   6:  92% | abe: 9.047 | eve: 10.264 | bob: 9.002Epoch   6:  92% | abe: 9.047 | eve: 10.263 | bob: 9.002Epoch   6:  93% | abe: 9.047 | eve: 10.263 | bob: 9.002Epoch   6:  94% | abe: 9.047 | eve: 10.263 | bob: 9.002Epoch   6:  95% | abe: 9.047 | eve: 10.263 | bob: 9.002Epoch   6:  96% | abe: 9.047 | eve: 10.263 | bob: 9.002Epoch   6:  96% | abe: 9.047 | eve: 10.263 | bob: 9.002Epoch   6:  97% | abe: 9.047 | eve: 10.262 | bob: 9.002Epoch   6:  98% | abe: 9.047 | eve: 10.263 | bob: 9.002Epoch   6:  99% | abe: 9.047 | eve: 10.262 | bob: 9.002Epoch   7:   0% | abe: 9.084 | eve: 10.262 | bob: 9.040Epoch   7:   0% | abe: 9.046 | eve: 10.275 | bob: 9.001Epoch   7:   1% | abe: 9.045 | eve: 10.275 | bob: 8.999Epoch   7:   2% | abe: 9.049 | eve: 10.249 | bob: 9.004Epoch   7:   3% | abe: 9.040 | eve: 10.231 | bob: 8.995Epoch   7:   3% | abe: 9.038 | eve: 10.230 | bob: 8.992Epoch   7:   4% | abe: 9.048 | eve: 10.231 | bob: 9.003Epoch   7:   5% | abe: 9.039 | eve: 10.227 | bob: 8.993Epoch   7:   6% | abe: 9.046 | eve: 10.236 | bob: 9.000Epoch   7:   7% | abe: 9.050 | eve: 10.242 | bob: 9.005Epoch   7:   7% | abe: 9.052 | eve: 10.241 | bob: 9.006Epoch   7:   8% | abe: 9.052 | eve: 10.238 | bob: 9.006Epoch   7:   9% | abe: 9.052 | eve: 10.237 | bob: 9.007Epoch   7:  10% | abe: 9.050 | eve: 10.238 | bob: 9.005Epoch   7:  10% | abe: 9.052 | eve: 10.243 | bob: 9.007Epoch   7:  11% | abe: 9.050 | eve: 10.245 | bob: 9.005Epoch   7:  12% | abe: 9.052 | eve: 10.248 | bob: 9.007Epoch   7:  13% | abe: 9.054 | eve: 10.248 | bob: 9.009Epoch   7:  14% | abe: 9.051 | eve: 10.249 | bob: 9.006Epoch   7:  14% | abe: 9.050 | eve: 10.251 | bob: 9.005Epoch   7:  15% | abe: 9.048 | eve: 10.250 | bob: 9.003Epoch   7:  16% | abe: 9.049 | eve: 10.248 | bob: 9.003Epoch   7:  17% | abe: 9.048 | eve: 10.249 | bob: 9.003Epoch   7:  17% | abe: 9.050 | eve: 10.251 | bob: 9.005Epoch   7:  18% | abe: 9.048 | eve: 10.254 | bob: 9.004Epoch   7:  19% | abe: 9.046 | eve: 10.258 | bob: 9.001Epoch   7:  20% | abe: 9.044 | eve: 10.259 | bob: 8.999Epoch   7:  21% | abe: 9.043 | eve: 10.260 | bob: 8.999Epoch   7:  21% | abe: 9.042 | eve: 10.262 | bob: 8.997Epoch   7:  22% | abe: 9.042 | eve: 10.262 | bob: 8.997Epoch   7:  23% | abe: 9.043 | eve: 10.262 | bob: 8.998Epoch   7:  24% | abe: 9.044 | eve: 10.261 | bob: 8.999Epoch   7:  25% | abe: 9.044 | eve: 10.261 | bob: 8.999Epoch   7:  25% | abe: 9.044 | eve: 10.262 | bob: 8.999Epoch   7:  26% | abe: 9.043 | eve: 10.263 | bob: 8.998Epoch   7:  27% | abe: 9.044 | eve: 10.262 | bob: 8.999Epoch   7:  28% | abe: 9.042 | eve: 10.260 | bob: 8.997Epoch   7:  28% | abe: 9.042 | eve: 10.261 | bob: 8.997Epoch   7:  29% | abe: 9.041 | eve: 10.262 | bob: 8.996Epoch   7:  30% | abe: 9.040 | eve: 10.261 | bob: 8.995Epoch   7:  31% | abe: 9.040 | eve: 10.261 | bob: 8.994Epoch   7:  32% | abe: 9.039 | eve: 10.259 | bob: 8.994Epoch   7:  32% | abe: 9.039 | eve: 10.259 | bob: 8.993Epoch   7:  33% | abe: 9.039 | eve: 10.258 | bob: 8.993Epoch   7:  34% | abe: 9.039 | eve: 10.257 | bob: 8.994Epoch   7:  35% | abe: 9.039 | eve: 10.255 | bob: 8.994Epoch   7:  35% | abe: 9.038 | eve: 10.256 | bob: 8.993Epoch   7:  36% | abe: 9.038 | eve: 10.256 | bob: 8.992Epoch   7:  37% | abe: 9.037 | eve: 10.257 | bob: 8.992Epoch   7:  38% | abe: 9.038 | eve: 10.256 | bob: 8.992Epoch   7:  39% | abe: 9.038 | eve: 10.255 | bob: 8.992Epoch   7:  39% | abe: 9.038 | eve: 10.254 | bob: 8.993Epoch   7:  40% | abe: 9.039 | eve: 10.253 | bob: 8.994Epoch   7:  41% | abe: 9.039 | eve: 10.254 | bob: 8.994Epoch   7:  42% | abe: 9.039 | eve: 10.254 | bob: 8.994Epoch   7:  42% | abe: 9.039 | eve: 10.254 | bob: 8.994Epoch   7:  43% | abe: 9.040 | eve: 10.254 | bob: 8.994Epoch   7:  44% | abe: 9.039 | eve: 10.254 | bob: 8.994Epoch   7:  45% | abe: 9.040 | eve: 10.255 | bob: 8.994Epoch   7:  46% | abe: 9.039 | eve: 10.256 | bob: 8.994Epoch   7:  46% | abe: 9.038 | eve: 10.258 | bob: 8.993Epoch   7:  47% | abe: 9.039 | eve: 10.257 | bob: 8.993Epoch   7:  48% | abe: 9.039 | eve: 10.257 | bob: 8.994Epoch   7:  49% | abe: 9.039 | eve: 10.256 | bob: 8.994Epoch   7:  50% | abe: 9.039 | eve: 10.257 | bob: 8.993Epoch   7:  50% | abe: 9.039 | eve: 10.258 | bob: 8.994Epoch   7:  51% | abe: 9.039 | eve: 10.257 | bob: 8.994Epoch   7:  52% | abe: 9.040 | eve: 10.256 | bob: 8.994Epoch   7:  53% | abe: 9.040 | eve: 10.256 | bob: 8.994Epoch   7:  53% | abe: 9.039 | eve: 10.257 | bob: 8.993Epoch   7:  54% | abe: 9.039 | eve: 10.257 | bob: 8.993Epoch   7:  55% | abe: 9.039 | eve: 10.258 | bob: 8.993Epoch   7:  56% | abe: 9.040 | eve: 10.258 | bob: 8.994Epoch   7:  57% | abe: 9.040 | eve: 10.258 | bob: 8.994Epoch   7:  57% | abe: 9.041 | eve: 10.258 | bob: 8.995Epoch   7:  58% | abe: 9.041 | eve: 10.259 | bob: 8.995Epoch   7:  59% | abe: 9.040 | eve: 10.259 | bob: 8.995Epoch   7:  60% | abe: 9.041 | eve: 10.260 | bob: 8.995Epoch   7:  60% | abe: 9.041 | eve: 10.260 | bob: 8.995Epoch   7:  61% | abe: 9.040 | eve: 10.260 | bob: 8.994Epoch   7:  62% | abe: 9.040 | eve: 10.260 | bob: 8.994Epoch   7:  63% | abe: 9.039 | eve: 10.260 | bob: 8.994Epoch   7:  64% | abe: 9.040 | eve: 10.261 | bob: 8.994Epoch   7:  64% | abe: 9.040 | eve: 10.260 | bob: 8.994Epoch   7:  65% | abe: 9.039 | eve: 10.260 | bob: 8.994Epoch   7:  66% | abe: 9.039 | eve: 10.260 | bob: 8.993Epoch   7:  67% | abe: 9.038 | eve: 10.260 | bob: 8.992Epoch   7:  67% | abe: 9.038 | eve: 10.261 | bob: 8.992Epoch   7:  68% | abe: 9.039 | eve: 10.261 | bob: 8.993Epoch   7:  69% | abe: 9.039 | eve: 10.261 | bob: 8.993Epoch   7:  70% | abe: 9.038 | eve: 10.261 | bob: 8.992Epoch   7:  71% | abe: 9.038 | eve: 10.261 | bob: 8.992Epoch   7:  71% | abe: 9.038 | eve: 10.261 | bob: 8.992Epoch   7:  72% | abe: 9.038 | eve: 10.261 | bob: 8.992Epoch   7:  73% | abe: 9.038 | eve: 10.261 | bob: 8.992Epoch   7:  74% | abe: 9.038 | eve: 10.260 | bob: 8.992Epoch   7:  75% | abe: 9.038 | eve: 10.260 | bob: 8.991Epoch   7:  75% | abe: 9.037 | eve: 10.261 | bob: 8.991Epoch   7:  76% | abe: 9.037 | eve: 10.260 | bob: 8.990Epoch   7:  77% | abe: 9.037 | eve: 10.261 | bob: 8.991Epoch   7:  78% | abe: 9.037 | eve: 10.261 | bob: 8.991Epoch   7:  78% | abe: 9.038 | eve: 10.261 | bob: 8.991Epoch   7:  79% | abe: 9.038 | eve: 10.262 | bob: 8.991Epoch   7:  80% | abe: 9.037 | eve: 10.262 | bob: 8.991Epoch   7:  81% | abe: 9.037 | eve: 10.263 | bob: 8.991Epoch   7:  82% | abe: 9.038 | eve: 10.263 | bob: 8.991Epoch   7:  82% | abe: 9.038 | eve: 10.263 | bob: 8.991Epoch   7:  83% | abe: 9.038 | eve: 10.262 | bob: 8.991Epoch   7:  84% | abe: 9.038 | eve: 10.262 | bob: 8.992Epoch   7:  85% | abe: 9.038 | eve: 10.262 | bob: 8.992Epoch   7:  85% | abe: 9.038 | eve: 10.261 | bob: 8.992Epoch   7:  86% | abe: 9.038 | eve: 10.262 | bob: 8.992Epoch   7:  87% | abe: 9.038 | eve: 10.262 | bob: 8.992Epoch   7:  88% | abe: 9.038 | eve: 10.263 | bob: 8.992Epoch   7:  89% | abe: 9.038 | eve: 10.263 | bob: 8.992Epoch   7:  89% | abe: 9.037 | eve: 10.263 | bob: 8.991Epoch   7:  90% | abe: 9.037 | eve: 10.263 | bob: 8.991Epoch   7:  91% | abe: 9.037 | eve: 10.263 | bob: 8.991Epoch   7:  92% | abe: 9.037 | eve: 10.263 | bob: 8.990Epoch   7:  92% | abe: 9.037 | eve: 10.262 | bob: 8.991Epoch   7:  93% | abe: 9.037 | eve: 10.263 | bob: 8.991Epoch   7:  94% | abe: 9.037 | eve: 10.263 | bob: 8.990Epoch   7:  95% | abe: 9.037 | eve: 10.262 | bob: 8.991Epoch   7:  96% | abe: 9.037 | eve: 10.262 | bob: 8.991Epoch   7:  96% | abe: 9.037 | eve: 10.262 | bob: 8.991Epoch   7:  97% | abe: 9.038 | eve: 10.262 | bob: 8.991Epoch   7:  98% | abe: 9.038 | eve: 10.262 | bob: 8.991Epoch   7:  99% | abe: 9.038 | eve: 10.262 | bob: 8.991
New best Bob loss 8.991415887402354 at epoch 7
Epoch   8:   0% | abe: 9.077 | eve: 10.262 | bob: 9.030Epoch   8:   0% | abe: 9.040 | eve: 10.253 | bob: 8.992Epoch   8:   1% | abe: 9.032 | eve: 10.242 | bob: 8.984Epoch   8:   2% | abe: 9.027 | eve: 10.228 | bob: 8.979Epoch   8:   3% | abe: 9.029 | eve: 10.244 | bob: 8.981Epoch   8:   3% | abe: 9.032 | eve: 10.252 | bob: 8.984Epoch   8:   4% | abe: 9.026 | eve: 10.265 | bob: 8.978Epoch   8:   5% | abe: 9.032 | eve: 10.275 | bob: 8.984Epoch   8:   6% | abe: 9.031 | eve: 10.279 | bob: 8.983Epoch   8:   7% | abe: 9.032 | eve: 10.287 | bob: 8.984Epoch   8:   7% | abe: 9.032 | eve: 10.286 | bob: 8.984Epoch   8:   8% | abe: 9.032 | eve: 10.279 | bob: 8.984Epoch   8:   9% | abe: 9.029 | eve: 10.280 | bob: 8.982Epoch   8:  10% | abe: 9.032 | eve: 10.278 | bob: 8.984Epoch   8:  10% | abe: 9.034 | eve: 10.274 | bob: 8.986Epoch   8:  11% | abe: 9.035 | eve: 10.280 | bob: 8.988Epoch   8:  12% | abe: 9.034 | eve: 10.281 | bob: 8.986Epoch   8:  13% | abe: 9.037 | eve: 10.280 | bob: 8.989Epoch   8:  14% | abe: 9.037 | eve: 10.279 | bob: 8.989Epoch   8:  14% | abe: 9.036 | eve: 10.279 | bob: 8.988Epoch   8:  15% | abe: 9.037 | eve: 10.274 | bob: 8.989Epoch   8:  16% | abe: 9.038 | eve: 10.275 | bob: 8.990Epoch   8:  17% | abe: 9.037 | eve: 10.276 | bob: 8.989Epoch   8:  17% | abe: 9.035 | eve: 10.274 | bob: 8.987Epoch   8:  18% | abe: 9.033 | eve: 10.273 | bob: 8.985Epoch   8:  19% | abe: 9.032 | eve: 10.273 | bob: 8.983Epoch   8:  20% | abe: 9.030 | eve: 10.271 | bob: 8.981Epoch   8:  21% | abe: 9.028 | eve: 10.270 | bob: 8.979Epoch   8:  21% | abe: 9.030 | eve: 10.270 | bob: 8.981Epoch   8:  22% | abe: 9.030 | eve: 10.270 | bob: 8.982Epoch   8:  23% | abe: 9.030 | eve: 10.270 | bob: 8.982Epoch   8:  24% | abe: 9.028 | eve: 10.270 | bob: 8.980Epoch   8:  25% | abe: 9.027 | eve: 10.272 | bob: 8.978Epoch   8:  25% | abe: 9.026 | eve: 10.272 | bob: 8.977Epoch   8:  26% | abe: 9.026 | eve: 10.270 | bob: 8.977Epoch   8:  27% | abe: 9.026 | eve: 10.269 | bob: 8.977Epoch   8:  28% | abe: 9.027 | eve: 10.269 | bob: 8.978Epoch   8:  28% | abe: 9.027 | eve: 10.271 | bob: 8.978Epoch   8:  29% | abe: 9.027 | eve: 10.270 | bob: 8.977Epoch   8:  30% | abe: 9.025 | eve: 10.270 | bob: 8.976Epoch   8:  31% | abe: 9.025 | eve: 10.268 | bob: 8.976Epoch   8:  32% | abe: 9.024 | eve: 10.268 | bob: 8.974Epoch   8:  32% | abe: 9.025 | eve: 10.267 | bob: 8.975Epoch   8:  33% | abe: 9.025 | eve: 10.266 | bob: 8.976Epoch   8:  34% | abe: 9.026 | eve: 10.264 | bob: 8.976Epoch   8:  35% | abe: 9.025 | eve: 10.263 | bob: 8.976Epoch   8:  35% | abe: 9.026 | eve: 10.262 | bob: 8.976Epoch   8:  36% | abe: 9.025 | eve: 10.264 | bob: 8.975Epoch   8:  37% | abe: 9.026 | eve: 10.264 | bob: 8.976Epoch   8:  38% | abe: 9.025 | eve: 10.263 | bob: 8.976Epoch   8:  39% | abe: 9.026 | eve: 10.263 | bob: 8.976Epoch   8:  39% | abe: 9.027 | eve: 10.263 | bob: 8.977Epoch   8:  40% | abe: 9.028 | eve: 10.263 | bob: 8.978Epoch   8:  41% | abe: 9.029 | eve: 10.263 | bob: 8.979Epoch   8:  42% | abe: 9.030 | eve: 10.263 | bob: 8.980Epoch   8:  42% | abe: 9.030 | eve: 10.264 | bob: 8.981Epoch   8:  43% | abe: 9.030 | eve: 10.262 | bob: 8.981Epoch   8:  44% | abe: 9.030 | eve: 10.262 | bob: 8.980Epoch   8:  45% | abe: 9.030 | eve: 10.263 | bob: 8.980Epoch   8:  46% | abe: 9.030 | eve: 10.264 | bob: 8.980Epoch   8:  46% | abe: 9.030 | eve: 10.263 | bob: 8.981Epoch   8:  47% | abe: 9.031 | eve: 10.262 | bob: 8.981Epoch   8:  48% | abe: 9.031 | eve: 10.262 | bob: 8.981Epoch   8:  49% | abe: 9.031 | eve: 10.262 | bob: 8.982Epoch   8:  50% | abe: 9.031 | eve: 10.262 | bob: 8.982Epoch   8:  50% | abe: 9.031 | eve: 10.262 | bob: 8.981Epoch   8:  51% | abe: 9.031 | eve: 10.264 | bob: 8.981Epoch   8:  52% | abe: 9.031 | eve: 10.264 | bob: 8.981Epoch   8:  53% | abe: 9.031 | eve: 10.263 | bob: 8.981Epoch   8:  53% | abe: 9.032 | eve: 10.263 | bob: 8.982Epoch   8:  54% | abe: 9.031 | eve: 10.262 | bob: 8.981Epoch   8:  55% | abe: 9.032 | eve: 10.262 | bob: 8.982Epoch   8:  56% | abe: 9.032 | eve: 10.262 | bob: 8.982Epoch   8:  57% | abe: 9.032 | eve: 10.262 | bob: 8.982Epoch   8:  57% | abe: 9.031 | eve: 10.263 | bob: 8.981Epoch   8:  58% | abe: 9.031 | eve: 10.262 | bob: 8.981Epoch   8:  59% | abe: 9.031 | eve: 10.262 | bob: 8.981Epoch   8:  60% | abe: 9.031 | eve: 10.263 | bob: 8.981Epoch   8:  60% | abe: 9.032 | eve: 10.262 | bob: 8.982Epoch   8:  61% | abe: 9.031 | eve: 10.262 | bob: 8.982Epoch   8:  62% | abe: 9.032 | eve: 10.261 | bob: 8.982Epoch   8:  63% | abe: 9.031 | eve: 10.261 | bob: 8.981Epoch   8:  64% | abe: 9.031 | eve: 10.261 | bob: 8.981Epoch   8:  64% | abe: 9.032 | eve: 10.261 | bob: 8.983Epoch   8:  65% | abe: 9.032 | eve: 10.261 | bob: 8.982Epoch   8:  66% | abe: 9.032 | eve: 10.261 | bob: 8.982Epoch   8:  67% | abe: 9.032 | eve: 10.261 | bob: 8.982Epoch   8:  67% | abe: 9.032 | eve: 10.261 | bob: 8.982Epoch   8:  68% | abe: 9.032 | eve: 10.262 | bob: 8.982Epoch   8:  69% | abe: 9.032 | eve: 10.261 | bob: 8.982Epoch   8:  70% | abe: 9.032 | eve: 10.261 | bob: 8.982Epoch   8:  71% | abe: 9.032 | eve: 10.261 | bob: 8.982Epoch   8:  71% | abe: 9.032 | eve: 10.261 | bob: 8.982Epoch   8:  72% | abe: 9.032 | eve: 10.262 | bob: 8.982Epoch   8:  73% | abe: 9.032 | eve: 10.262 | bob: 8.982Epoch   8:  74% | abe: 9.032 | eve: 10.262 | bob: 8.982Epoch   8:  75% | abe: 9.032 | eve: 10.262 | bob: 8.982Epoch   8:  75% | abe: 9.032 | eve: 10.261 | bob: 8.982Epoch   8:  76% | abe: 9.032 | eve: 10.260 | bob: 8.982Epoch   8:  77% | abe: 9.033 | eve: 10.259 | bob: 8.983Epoch   8:  78% | abe: 9.033 | eve: 10.260 | bob: 8.983Epoch   8:  78% | abe: 9.033 | eve: 10.259 | bob: 8.982Epoch   8:  79% | abe: 9.032 | eve: 10.259 | bob: 8.982Epoch   8:  80% | abe: 9.032 | eve: 10.260 | bob: 8.982Epoch   8:  81% | abe: 9.032 | eve: 10.259 | bob: 8.982Epoch   8:  82% | abe: 9.032 | eve: 10.260 | bob: 8.982Epoch   8:  82% | abe: 9.032 | eve: 10.260 | bob: 8.982Epoch   8:  83% | abe: 9.032 | eve: 10.260 | bob: 8.982Epoch   8:  84% | abe: 9.033 | eve: 10.260 | bob: 8.983Epoch   8:  85% | abe: 9.033 | eve: 10.260 | bob: 8.983Epoch   8:  85% | abe: 9.033 | eve: 10.260 | bob: 8.983Epoch   8:  86% | abe: 9.033 | eve: 10.260 | bob: 8.983Epoch   8:  87% | abe: 9.033 | eve: 10.260 | bob: 8.983Epoch   8:  88% | abe: 9.033 | eve: 10.260 | bob: 8.983Epoch   8:  89% | abe: 9.033 | eve: 10.260 | bob: 8.983Epoch   8:  89% | abe: 9.033 | eve: 10.260 | bob: 8.983Epoch   8:  90% | abe: 9.033 | eve: 10.260 | bob: 8.983Epoch   8:  91% | abe: 9.033 | eve: 10.259 | bob: 8.983Epoch   8:  92% | abe: 9.033 | eve: 10.259 | bob: 8.983Epoch   8:  92% | abe: 9.033 | eve: 10.258 | bob: 8.983Epoch   8:  93% | abe: 9.033 | eve: 10.258 | bob: 8.983Epoch   8:  94% | abe: 9.034 | eve: 10.259 | bob: 8.984Epoch   8:  95% | abe: 9.033 | eve: 10.258 | bob: 8.983Epoch   8:  96% | abe: 9.033 | eve: 10.258 | bob: 8.983Epoch   8:  96% | abe: 9.033 | eve: 10.258 | bob: 8.983Epoch   8:  97% | abe: 9.033 | eve: 10.258 | bob: 8.983Epoch   8:  98% | abe: 9.033 | eve: 10.258 | bob: 8.983Epoch   8:  99% | abe: 9.033 | eve: 10.258 | bob: 8.983
New best Bob loss 8.982680412724221 at epoch 8
Epoch   9:   0% | abe: 9.033 | eve: 10.203 | bob: 8.983Epoch   9:   0% | abe: 9.020 | eve: 10.214 | bob: 8.971Epoch   9:   1% | abe: 9.022 | eve: 10.224 | bob: 8.972Epoch   9:   2% | abe: 9.019 | eve: 10.245 | bob: 8.969Epoch   9:   3% | abe: 9.014 | eve: 10.252 | bob: 8.964Epoch   9:   3% | abe: 9.022 | eve: 10.259 | bob: 8.972Epoch   9:   4% | abe: 9.030 | eve: 10.254 | bob: 8.980Epoch   9:   5% | abe: 9.029 | eve: 10.247 | bob: 8.980Epoch   9:   6% | abe: 9.027 | eve: 10.248 | bob: 8.978Epoch   9:   7% | abe: 9.032 | eve: 10.241 | bob: 8.983Epoch   9:   7% | abe: 9.033 | eve: 10.243 | bob: 8.984Epoch   9:   8% | abe: 9.028 | eve: 10.246 | bob: 8.978Epoch   9:   9% | abe: 9.025 | eve: 10.246 | bob: 8.975Epoch   9:  10% | abe: 9.027 | eve: 10.246 | bob: 8.977Epoch   9:  10% | abe: 9.026 | eve: 10.246 | bob: 8.976Epoch   9:  11% | abe: 9.029 | eve: 10.248 | bob: 8.979Epoch   9:  12% | abe: 9.029 | eve: 10.252 | bob: 8.979Epoch   9:  13% | abe: 9.028 | eve: 10.250 | bob: 8.978Epoch   9:  14% | abe: 9.025 | eve: 10.249 | bob: 8.975Epoch   9:  14% | abe: 9.025 | eve: 10.248 | bob: 8.976Epoch   9:  15% | abe: 9.025 | eve: 10.250 | bob: 8.975Epoch   9:  16% | abe: 9.025 | eve: 10.246 | bob: 8.975Epoch   9:  17% | abe: 9.025 | eve: 10.248 | bob: 8.975Epoch   9:  17% | abe: 9.024 | eve: 10.248 | bob: 8.974Epoch   9:  18% | abe: 9.028 | eve: 10.246 | bob: 8.978Epoch   9:  19% | abe: 9.026 | eve: 10.246 | bob: 8.975Epoch   9:  20% | abe: 9.028 | eve: 10.245 | bob: 8.978Epoch   9:  21% | abe: 9.028 | eve: 10.241 | bob: 8.978Epoch   9:  21% | abe: 9.029 | eve: 10.241 | bob: 8.979Epoch   9:  22% | abe: 9.029 | eve: 10.241 | bob: 8.979Epoch   9:  23% | abe: 9.029 | eve: 10.241 | bob: 8.979Epoch   9:  24% | abe: 9.027 | eve: 10.241 | bob: 8.977Epoch   9:  25% | abe: 9.029 | eve: 10.242 | bob: 8.978Epoch   9:  25% | abe: 9.029 | eve: 10.242 | bob: 8.979Epoch   9:  26% | abe: 9.029 | eve: 10.243 | bob: 8.978Epoch   9:  27% | abe: 9.030 | eve: 10.244 | bob: 8.979Epoch   9:  28% | abe: 9.030 | eve: 10.241 | bob: 8.980Epoch   9:  28% | abe: 9.031 | eve: 10.241 | bob: 8.981Epoch   9:  29% | abe: 9.030 | eve: 10.241 | bob: 8.979Epoch   9:  30% | abe: 9.031 | eve: 10.242 | bob: 8.980Epoch   9:  31% | abe: 9.031 | eve: 10.242 | bob: 8.980Epoch   9:  32% | abe: 9.030 | eve: 10.244 | bob: 8.979Epoch   9:  32% | abe: 9.030 | eve: 10.242 | bob: 8.980Epoch   9:  33% | abe: 9.030 | eve: 10.243 | bob: 8.979Epoch   9:  34% | abe: 9.029 | eve: 10.244 | bob: 8.979Epoch   9:  35% | abe: 9.029 | eve: 10.244 | bob: 8.979Epoch   9:  35% | abe: 9.030 | eve: 10.245 | bob: 8.979Epoch   9:  36% | abe: 9.031 | eve: 10.246 | bob: 8.981Epoch   9:  37% | abe: 9.030 | eve: 10.247 | bob: 8.980Epoch   9:  38% | abe: 9.031 | eve: 10.246 | bob: 8.980Epoch   9:  39% | abe: 9.030 | eve: 10.247 | bob: 8.980Epoch   9:  39% | abe: 9.030 | eve: 10.248 | bob: 8.979Epoch   9:  40% | abe: 9.029 | eve: 10.248 | bob: 8.979Epoch   9:  41% | abe: 9.030 | eve: 10.248 | bob: 8.979Epoch   9:  42% | abe: 9.030 | eve: 10.247 | bob: 8.979Epoch   9:  42% | abe: 9.030 | eve: 10.247 | bob: 8.979Epoch   9:  43% | abe: 9.029 | eve: 10.247 | bob: 8.978Epoch   9:  44% | abe: 9.028 | eve: 10.248 | bob: 8.977Epoch   9:  45% | abe: 9.028 | eve: 10.246 | bob: 8.977Epoch   9:  46% | abe: 9.028 | eve: 10.246 | bob: 8.978Epoch   9:  46% | abe: 9.028 | eve: 10.246 | bob: 8.977Epoch   9:  47% | abe: 9.027 | eve: 10.247 | bob: 8.977Epoch   9:  48% | abe: 9.027 | eve: 10.247 | bob: 8.976Epoch   9:  49% | abe: 9.027 | eve: 10.247 | bob: 8.977Epoch   9:  50% | abe: 9.028 | eve: 10.247 | bob: 8.977Epoch   9:  50% | abe: 9.028 | eve: 10.247 | bob: 8.977Epoch   9:  51% | abe: 9.028 | eve: 10.246 | bob: 8.977Epoch   9:  52% | abe: 9.028 | eve: 10.246 | bob: 8.978Epoch   9:  53% | abe: 9.029 | eve: 10.246 | bob: 8.978Epoch   9:  53% | abe: 9.028 | eve: 10.247 | bob: 8.977Epoch   9:  54% | abe: 9.028 | eve: 10.247 | bob: 8.978Epoch   9:  55% | abe: 9.028 | eve: 10.247 | bob: 8.977Epoch   9:  56% | abe: 9.028 | eve: 10.247 | bob: 8.977Epoch   9:  57% | abe: 9.028 | eve: 10.246 | bob: 8.977Epoch   9:  57% | abe: 9.028 | eve: 10.247 | bob: 8.977Epoch   9:  58% | abe: 9.028 | eve: 10.247 | bob: 8.978Epoch   9:  59% | abe: 9.028 | eve: 10.247 | bob: 8.977Epoch   9:  60% | abe: 9.028 | eve: 10.247 | bob: 8.977Epoch   9:  60% | abe: 9.028 | eve: 10.247 | bob: 8.977Epoch   9:  61% | abe: 9.028 | eve: 10.247 | bob: 8.978Epoch   9:  62% | abe: 9.028 | eve: 10.247 | bob: 8.977Epoch   9:  63% | abe: 9.028 | eve: 10.247 | bob: 8.977Epoch   9:  64% | abe: 9.028 | eve: 10.247 | bob: 8.977Epoch   9:  64% | abe: 9.028 | eve: 10.247 | bob: 8.977Epoch   9:  65% | abe: 9.028 | eve: 10.247 | bob: 8.978Epoch   9:  66% | abe: 9.028 | eve: 10.246 | bob: 8.977Epoch   9:  67% | abe: 9.028 | eve: 10.247 | bob: 8.977Epoch   9:  67% | abe: 9.028 | eve: 10.246 | bob: 8.977Epoch   9:  68% | abe: 9.028 | eve: 10.246 | bob: 8.977Epoch   9:  69% | abe: 9.028 | eve: 10.246 | bob: 8.977Epoch   9:  70% | abe: 9.028 | eve: 10.246 | bob: 8.977Epoch   9:  71% | abe: 9.028 | eve: 10.246 | bob: 8.977Epoch   9:  71% | abe: 9.029 | eve: 10.246 | bob: 8.978Epoch   9:  72% | abe: 9.028 | eve: 10.247 | bob: 8.978Epoch   9:  73% | abe: 9.028 | eve: 10.247 | bob: 8.978Epoch   9:  74% | abe: 9.029 | eve: 10.247 | bob: 8.978Epoch   9:  75% | abe: 9.029 | eve: 10.247 | bob: 8.978Epoch   9:  75% | abe: 9.029 | eve: 10.247 | bob: 8.978Epoch   9:  76% | abe: 9.029 | eve: 10.247 | bob: 8.978Epoch   9:  77% | abe: 9.029 | eve: 10.246 | bob: 8.978Epoch   9:  78% | abe: 9.029 | eve: 10.245 | bob: 8.978Epoch   9:  78% | abe: 9.029 | eve: 10.246 | bob: 8.978Epoch   9:  79% | abe: 9.029 | eve: 10.245 | bob: 8.978Epoch   9:  80% | abe: 9.029 | eve: 10.244 | bob: 8.978Epoch   9:  81% | abe: 9.029 | eve: 10.245 | bob: 8.979Epoch   9:  82% | abe: 9.029 | eve: 10.246 | bob: 8.979Epoch   9:  82% | abe: 9.030 | eve: 10.246 | bob: 8.979Epoch   9:  83% | abe: 9.030 | eve: 10.245 | bob: 8.979Epoch   9:  84% | abe: 9.029 | eve: 10.246 | bob: 8.978Epoch   9:  85% | abe: 9.029 | eve: 10.245 | bob: 8.978Epoch   9:  85% | abe: 9.029 | eve: 10.245 | bob: 8.978Epoch   9:  86% | abe: 9.030 | eve: 10.246 | bob: 8.979Epoch   9:  87% | abe: 9.030 | eve: 10.246 | bob: 8.979Epoch   9:  88% | abe: 9.029 | eve: 10.246 | bob: 8.978Epoch   9:  89% | abe: 9.029 | eve: 10.246 | bob: 8.978Epoch   9:  89% | abe: 9.029 | eve: 10.246 | bob: 8.978Epoch   9:  90% | abe: 9.029 | eve: 10.246 | bob: 8.978Epoch   9:  91% | abe: 9.029 | eve: 10.246 | bob: 8.979Epoch   9:  92% | abe: 9.030 | eve: 10.246 | bob: 8.979Epoch   9:  92% | abe: 9.030 | eve: 10.247 | bob: 8.979Epoch   9:  93% | abe: 9.030 | eve: 10.247 | bob: 8.979Epoch   9:  94% | abe: 9.030 | eve: 10.247 | bob: 8.979Epoch   9:  95% | abe: 9.030 | eve: 10.248 | bob: 8.979Epoch   9:  96% | abe: 9.030 | eve: 10.248 | bob: 8.979Epoch   9:  96% | abe: 9.029 | eve: 10.248 | bob: 8.979Epoch   9:  97% | abe: 9.030 | eve: 10.248 | bob: 8.979Epoch   9:  98% | abe: 9.029 | eve: 10.248 | bob: 8.978Epoch   9:  99% | abe: 9.029 | eve: 10.248 | bob: 8.978
New best Bob loss 8.977901043808288 at epoch 9
Epoch  10:   0% | abe: 9.066 | eve: 10.171 | bob: 9.017Epoch  10:   0% | abe: 9.020 | eve: 10.202 | bob: 8.970Epoch  10:   1% | abe: 9.016 | eve: 10.213 | bob: 8.966Epoch  10:   2% | abe: 9.019 | eve: 10.225 | bob: 8.969Epoch  10:   3% | abe: 9.008 | eve: 10.242 | bob: 8.958Epoch  10:   3% | abe: 9.007 | eve: 10.249 | bob: 8.956Epoch  10:   4% | abe: 9.012 | eve: 10.249 | bob: 8.962Epoch  10:   5% | abe: 9.009 | eve: 10.242 | bob: 8.959Epoch  10:   6% | abe: 9.013 | eve: 10.239 | bob: 8.962Epoch  10:   7% | abe: 9.017 | eve: 10.236 | bob: 8.967Epoch  10:   7% | abe: 9.016 | eve: 10.238 | bob: 8.966Epoch  10:   8% | abe: 9.017 | eve: 10.234 | bob: 8.967Epoch  10:   9% | abe: 9.019 | eve: 10.232 | bob: 8.969Epoch  10:  10% | abe: 9.017 | eve: 10.236 | bob: 8.966Epoch  10:  10% | abe: 9.018 | eve: 10.236 | bob: 8.967Epoch  10:  11% | abe: 9.019 | eve: 10.239 | bob: 8.969Epoch  10:  12% | abe: 9.020 | eve: 10.239 | bob: 8.970Epoch  10:  13% | abe: 9.021 | eve: 10.236 | bob: 8.971Epoch  10:  14% | abe: 9.019 | eve: 10.240 | bob: 8.969Epoch  10:  14% | abe: 9.022 | eve: 10.242 | bob: 8.971Epoch  10:  15% | abe: 9.023 | eve: 10.241 | bob: 8.973Epoch  10:  16% | abe: 9.025 | eve: 10.240 | bob: 8.975Epoch  10:  17% | abe: 9.028 | eve: 10.243 | bob: 8.978Epoch  10:  17% | abe: 9.030 | eve: 10.245 | bob: 8.980Epoch  10:  18% | abe: 9.030 | eve: 10.243 | bob: 8.980Epoch  10:  19% | abe: 9.030 | eve: 10.243 | bob: 8.980Epoch  10:  20% | abe: 9.028 | eve: 10.245 | bob: 8.978Epoch  10:  21% | abe: 9.030 | eve: 10.245 | bob: 8.980Epoch  10:  21% | abe: 9.030 | eve: 10.245 | bob: 8.980Epoch  10:  22% | abe: 9.032 | eve: 10.247 | bob: 8.982Epoch  10:  23% | abe: 9.033 | eve: 10.247 | bob: 8.984Epoch  10:  24% | abe: 9.033 | eve: 10.245 | bob: 8.984Epoch  10:  25% | abe: 9.033 | eve: 10.246 | bob: 8.983Epoch  10:  25% | abe: 9.033 | eve: 10.246 | bob: 8.984Epoch  10:  26% | abe: 9.032 | eve: 10.245 | bob: 8.983Epoch  10:  27% | abe: 9.031 | eve: 10.243 | bob: 8.982Epoch  10:  28% | abe: 9.032 | eve: 10.242 | bob: 8.983Epoch  10:  28% | abe: 9.031 | eve: 10.241 | bob: 8.981Epoch  10:  29% | abe: 9.030 | eve: 10.239 | bob: 8.980Epoch  10:  30% | abe: 9.029 | eve: 10.238 | bob: 8.979Epoch  10:  31% | abe: 9.028 | eve: 10.238 | bob: 8.978Epoch  10:  32% | abe: 9.028 | eve: 10.237 | bob: 8.978Epoch  10:  32% | abe: 9.028 | eve: 10.237 | bob: 8.978Epoch  10:  33% | abe: 9.029 | eve: 10.238 | bob: 8.979Epoch  10:  34% | abe: 9.030 | eve: 10.238 | bob: 8.980Epoch  10:  35% | abe: 9.029 | eve: 10.241 | bob: 8.979Epoch  10:  35% | abe: 9.029 | eve: 10.241 | bob: 8.979Epoch  10:  36% | abe: 9.029 | eve: 10.240 | bob: 8.980Epoch  10:  37% | abe: 9.030 | eve: 10.238 | bob: 8.980Epoch  10:  38% | abe: 9.030 | eve: 10.240 | bob: 8.981Epoch  10:  39% | abe: 9.030 | eve: 10.240 | bob: 8.980Epoch  10:  39% | abe: 9.030 | eve: 10.240 | bob: 8.980Epoch  10:  40% | abe: 9.030 | eve: 10.241 | bob: 8.980Epoch  10:  41% | abe: 9.030 | eve: 10.240 | bob: 8.980Epoch  10:  42% | abe: 9.030 | eve: 10.241 | bob: 8.980Epoch  10:  42% | abe: 9.030 | eve: 10.241 | bob: 8.980Epoch  10:  43% | abe: 9.029 | eve: 10.242 | bob: 8.979Epoch  10:  44% | abe: 9.030 | eve: 10.242 | bob: 8.980Epoch  10:  45% | abe: 9.030 | eve: 10.242 | bob: 8.980Epoch  10:  46% | abe: 9.031 | eve: 10.242 | bob: 8.981Epoch  10:  46% | abe: 9.031 | eve: 10.242 | bob: 8.981Epoch  10:  47% | abe: 9.031 | eve: 10.241 | bob: 8.981Epoch  10:  48% | abe: 9.031 | eve: 10.239 | bob: 8.981Epoch  10:  49% | abe: 9.031 | eve: 10.239 | bob: 8.981Epoch  10:  50% | abe: 9.031 | eve: 10.241 | bob: 8.981Epoch  10:  50% | abe: 9.030 | eve: 10.240 | bob: 8.980Epoch  10:  51% | abe: 9.030 | eve: 10.240 | bob: 8.980Epoch  10:  52% | abe: 9.031 | eve: 10.240 | bob: 8.981Epoch  10:  53% | abe: 9.031 | eve: 10.240 | bob: 8.981Epoch  10:  53% | abe: 9.031 | eve: 10.240 | bob: 8.981Epoch  10:  54% | abe: 9.030 | eve: 10.240 | bob: 8.980Epoch  10:  55% | abe: 9.030 | eve: 10.241 | bob: 8.980Epoch  10:  56% | abe: 9.030 | eve: 10.243 | bob: 8.980Epoch  10:  57% | abe: 9.030 | eve: 10.242 | bob: 8.980Epoch  10:  57% | abe: 9.031 | eve: 10.243 | bob: 8.981Epoch  10:  58% | abe: 9.031 | eve: 10.244 | bob: 8.981Epoch  10:  59% | abe: 9.031 | eve: 10.245 | bob: 8.981Epoch  10:  60% | abe: 9.031 | eve: 10.245 | bob: 8.981Epoch  10:  60% | abe: 9.031 | eve: 10.245 | bob: 8.981Epoch  10:  61% | abe: 9.031 | eve: 10.245 | bob: 8.981Epoch  10:  62% | abe: 9.031 | eve: 10.245 | bob: 8.981Epoch  10:  63% | abe: 9.031 | eve: 10.244 | bob: 8.981Epoch  10:  64% | abe: 9.031 | eve: 10.245 | bob: 8.981Epoch  10:  64% | abe: 9.031 | eve: 10.245 | bob: 8.981Epoch  10:  65% | abe: 9.031 | eve: 10.246 | bob: 8.981Epoch  10:  66% | abe: 9.031 | eve: 10.245 | bob: 8.981Epoch  10:  67% | abe: 9.030 | eve: 10.245 | bob: 8.980Epoch  10:  67% | abe: 9.030 | eve: 10.246 | bob: 8.980Epoch  10:  68% | abe: 9.030 | eve: 10.245 | bob: 8.980Epoch  10:  69% | abe: 9.031 | eve: 10.246 | bob: 8.981Epoch  10:  70% | abe: 9.030 | eve: 10.245 | bob: 8.981Epoch  10:  71% | abe: 9.030 | eve: 10.245 | bob: 8.981Epoch  10:  71% | abe: 9.031 | eve: 10.245 | bob: 8.981Epoch  10:  72% | abe: 9.030 | eve: 10.245 | bob: 8.980Epoch  10:  73% | abe: 9.030 | eve: 10.245 | bob: 8.980Epoch  10:  74% | abe: 9.029 | eve: 10.245 | bob: 8.979Epoch  10:  75% | abe: 9.029 | eve: 10.244 | bob: 8.979Epoch  10:  75% | abe: 9.029 | eve: 10.245 | bob: 8.979Epoch  10:  76% | abe: 9.029 | eve: 10.245 | bob: 8.979Epoch  10:  77% | abe: 9.029 | eve: 10.245 | bob: 8.979Epoch  10:  78% | abe: 9.028 | eve: 10.245 | bob: 8.979Epoch  10:  78% | abe: 9.028 | eve: 10.244 | bob: 8.978Epoch  10:  79% | abe: 9.028 | eve: 10.244 | bob: 8.978Epoch  10:  80% | abe: 9.027 | eve: 10.244 | bob: 8.977Epoch  10:  81% | abe: 9.028 | eve: 10.244 | bob: 8.978Epoch  10:  82% | abe: 9.028 | eve: 10.245 | bob: 8.978Epoch  10:  82% | abe: 9.028 | eve: 10.245 | bob: 8.978Epoch  10:  83% | abe: 9.028 | eve: 10.245 | bob: 8.978Epoch  10:  84% | abe: 9.027 | eve: 10.244 | bob: 8.978Epoch  10:  85% | abe: 9.028 | eve: 10.244 | bob: 8.978Epoch  10:  85% | abe: 9.028 | eve: 10.244 | bob: 8.978Epoch  10:  86% | abe: 9.028 | eve: 10.243 | bob: 8.978Epoch  10:  87% | abe: 9.028 | eve: 10.243 | bob: 8.978Epoch  10:  88% | abe: 9.028 | eve: 10.244 | bob: 8.978Epoch  10:  89% | abe: 9.028 | eve: 10.244 | bob: 8.978Epoch  10:  89% | abe: 9.028 | eve: 10.244 | bob: 8.978Epoch  10:  90% | abe: 9.028 | eve: 10.244 | bob: 8.978Epoch  10:  91% | abe: 9.028 | eve: 10.244 | bob: 8.978Epoch  10:  92% | abe: 9.028 | eve: 10.244 | bob: 8.978Epoch  10:  92% | abe: 9.028 | eve: 10.244 | bob: 8.978Epoch  10:  93% | abe: 9.028 | eve: 10.244 | bob: 8.978Epoch  10:  94% | abe: 9.027 | eve: 10.244 | bob: 8.977Epoch  10:  95% | abe: 9.027 | eve: 10.243 | bob: 8.977Epoch  10:  96% | abe: 9.027 | eve: 10.243 | bob: 8.977Epoch  10:  96% | abe: 9.027 | eve: 10.244 | bob: 8.977Epoch  10:  97% | abe: 9.027 | eve: 10.243 | bob: 8.977Epoch  10:  98% | abe: 9.027 | eve: 10.243 | bob: 8.977Epoch  10:  99% | abe: 9.027 | eve: 10.244 | bob: 8.977
New best Bob loss 8.976807194702133 at epoch 10
Epoch  11:   0% | abe: 9.025 | eve: 10.188 | bob: 8.976Epoch  11:   0% | abe: 9.011 | eve: 10.257 | bob: 8.960Epoch  11:   1% | abe: 9.027 | eve: 10.268 | bob: 8.977Epoch  11:   2% | abe: 9.024 | eve: 10.250 | bob: 8.974Epoch  11:   3% | abe: 9.028 | eve: 10.247 | bob: 8.978Epoch  11:   3% | abe: 9.026 | eve: 10.226 | bob: 8.976Epoch  11:   4% | abe: 9.025 | eve: 10.229 | bob: 8.975Epoch  11:   5% | abe: 9.030 | eve: 10.225 | bob: 8.980Epoch  11:   6% | abe: 9.030 | eve: 10.223 | bob: 8.980Epoch  11:   7% | abe: 9.026 | eve: 10.228 | bob: 8.976Epoch  11:   7% | abe: 9.028 | eve: 10.229 | bob: 8.977Epoch  11:   8% | abe: 9.029 | eve: 10.233 | bob: 8.978Epoch  11:   9% | abe: 9.035 | eve: 10.233 | bob: 8.985Epoch  11:  10% | abe: 9.033 | eve: 10.232 | bob: 8.983Epoch  11:  10% | abe: 9.033 | eve: 10.235 | bob: 8.983Epoch  11:  11% | abe: 9.032 | eve: 10.240 | bob: 8.982Epoch  11:  12% | abe: 9.030 | eve: 10.240 | bob: 8.980Epoch  11:  13% | abe: 9.031 | eve: 10.241 | bob: 8.981Epoch  11:  14% | abe: 9.029 | eve: 10.235 | bob: 8.979Epoch  11:  14% | abe: 9.029 | eve: 10.235 | bob: 8.979Epoch  11:  15% | abe: 9.032 | eve: 10.236 | bob: 8.982Epoch  11:  16% | abe: 9.033 | eve: 10.235 | bob: 8.983Epoch  11:  17% | abe: 9.031 | eve: 10.235 | bob: 8.981Epoch  11:  17% | abe: 9.031 | eve: 10.231 | bob: 8.981Epoch  11:  18% | abe: 9.032 | eve: 10.229 | bob: 8.982Epoch  11:  19% | abe: 9.033 | eve: 10.232 | bob: 8.983Epoch  11:  20% | abe: 9.029 | eve: 10.234 | bob: 8.979Epoch  11:  21% | abe: 9.028 | eve: 10.236 | bob: 8.978Epoch  11:  21% | abe: 9.028 | eve: 10.237 | bob: 8.978Epoch  11:  22% | abe: 9.030 | eve: 10.236 | bob: 8.980Epoch  11:  23% | abe: 9.028 | eve: 10.235 | bob: 8.978Epoch  11:  24% | abe: 9.028 | eve: 10.235 | bob: 8.978Epoch  11:  25% | abe: 9.029 | eve: 10.233 | bob: 8.978Epoch  11:  25% | abe: 9.028 | eve: 10.235 | bob: 8.978Epoch  11:  26% | abe: 9.027 | eve: 10.235 | bob: 8.977Epoch  11:  27% | abe: 9.026 | eve: 10.235 | bob: 8.976Epoch  11:  28% | abe: 9.026 | eve: 10.236 | bob: 8.976Epoch  11:  28% | abe: 9.027 | eve: 10.236 | bob: 8.977Epoch  11:  29% | abe: 9.028 | eve: 10.235 | bob: 8.978Epoch  11:  30% | abe: 9.027 | eve: 10.236 | bob: 8.977Epoch  11:  31% | abe: 9.027 | eve: 10.236 | bob: 8.977Epoch  11:  32% | abe: 9.025 | eve: 10.237 | bob: 8.975Epoch  11:  32% | abe: 9.025 | eve: 10.237 | bob: 8.975Epoch  11:  33% | abe: 9.025 | eve: 10.239 | bob: 8.975Epoch  11:  34% | abe: 9.026 | eve: 10.239 | bob: 8.976Epoch  11:  35% | abe: 9.027 | eve: 10.239 | bob: 8.976Epoch  11:  35% | abe: 9.027 | eve: 10.239 | bob: 8.977Epoch  11:  36% | abe: 9.027 | eve: 10.239 | bob: 8.977Epoch  11:  37% | abe: 9.026 | eve: 10.239 | bob: 8.976Epoch  11:  38% | abe: 9.026 | eve: 10.239 | bob: 8.976Epoch  11:  39% | abe: 9.027 | eve: 10.237 | bob: 8.976Epoch  11:  39% | abe: 9.027 | eve: 10.239 | bob: 8.977Epoch  11:  40% | abe: 9.028 | eve: 10.239 | bob: 8.978Epoch  11:  41% | abe: 9.027 | eve: 10.238 | bob: 8.977Epoch  11:  42% | abe: 9.028 | eve: 10.239 | bob: 8.978Epoch  11:  42% | abe: 9.027 | eve: 10.237 | bob: 8.978Epoch  11:  43% | abe: 9.027 | eve: 10.237 | bob: 8.977Epoch  11:  44% | abe: 9.027 | eve: 10.237 | bob: 8.977Epoch  11:  45% | abe: 9.027 | eve: 10.238 | bob: 8.977Epoch  11:  46% | abe: 9.026 | eve: 10.239 | bob: 8.976Epoch  11:  46% | abe: 9.026 | eve: 10.240 | bob: 8.976Epoch  11:  47% | abe: 9.027 | eve: 10.240 | bob: 8.977Epoch  11:  48% | abe: 9.027 | eve: 10.240 | bob: 8.977Epoch  11:  49% | abe: 9.027 | eve: 10.239 | bob: 8.977Epoch  11:  50% | abe: 9.027 | eve: 10.238 | bob: 8.977Epoch  11:  50% | abe: 9.026 | eve: 10.238 | bob: 8.976Epoch  11:  51% | abe: 9.027 | eve: 10.237 | bob: 8.977Epoch  11:  52% | abe: 9.027 | eve: 10.237 | bob: 8.977Epoch  11:  53% | abe: 9.026 | eve: 10.237 | bob: 8.976Epoch  11:  53% | abe: 9.026 | eve: 10.237 | bob: 8.976Epoch  11:  54% | abe: 9.026 | eve: 10.238 | bob: 8.976Epoch  11:  55% | abe: 9.026 | eve: 10.238 | bob: 8.976Epoch  11:  56% | abe: 9.025 | eve: 10.238 | bob: 8.975Epoch  11:  57% | abe: 9.024 | eve: 10.239 | bob: 8.974Epoch  11:  57% | abe: 9.024 | eve: 10.238 | bob: 8.974Epoch  11:  58% | abe: 9.023 | eve: 10.239 | bob: 8.973Epoch  11:  59% | abe: 9.023 | eve: 10.240 | bob: 8.973Epoch  11:  60% | abe: 9.023 | eve: 10.239 | bob: 8.973Epoch  11:  60% | abe: 9.023 | eve: 10.239 | bob: 8.973Epoch  11:  61% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  62% | abe: 9.023 | eve: 10.239 | bob: 8.973Epoch  11:  63% | abe: 9.023 | eve: 10.239 | bob: 8.973Epoch  11:  64% | abe: 9.023 | eve: 10.239 | bob: 8.974Epoch  11:  64% | abe: 9.023 | eve: 10.239 | bob: 8.973Epoch  11:  65% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  66% | abe: 9.023 | eve: 10.239 | bob: 8.973Epoch  11:  67% | abe: 9.022 | eve: 10.239 | bob: 8.972Epoch  11:  67% | abe: 9.022 | eve: 10.238 | bob: 8.972Epoch  11:  68% | abe: 9.022 | eve: 10.238 | bob: 8.972Epoch  11:  69% | abe: 9.022 | eve: 10.238 | bob: 8.972Epoch  11:  70% | abe: 9.022 | eve: 10.238 | bob: 8.972Epoch  11:  71% | abe: 9.022 | eve: 10.238 | bob: 8.972Epoch  11:  71% | abe: 9.022 | eve: 10.238 | bob: 8.972Epoch  11:  72% | abe: 9.022 | eve: 10.237 | bob: 8.972Epoch  11:  73% | abe: 9.022 | eve: 10.238 | bob: 8.972Epoch  11:  74% | abe: 9.023 | eve: 10.237 | bob: 8.973Epoch  11:  75% | abe: 9.023 | eve: 10.237 | bob: 8.973Epoch  11:  75% | abe: 9.023 | eve: 10.237 | bob: 8.973Epoch  11:  76% | abe: 9.023 | eve: 10.237 | bob: 8.973Epoch  11:  77% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  78% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  78% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  79% | abe: 9.023 | eve: 10.239 | bob: 8.973Epoch  11:  80% | abe: 9.023 | eve: 10.239 | bob: 8.973Epoch  11:  81% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  82% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  82% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  83% | abe: 9.023 | eve: 10.237 | bob: 8.973Epoch  11:  84% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  85% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  85% | abe: 9.022 | eve: 10.238 | bob: 8.972Epoch  11:  86% | abe: 9.023 | eve: 10.237 | bob: 8.973Epoch  11:  87% | abe: 9.023 | eve: 10.237 | bob: 8.973Epoch  11:  88% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  89% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  89% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  90% | abe: 9.023 | eve: 10.239 | bob: 8.973Epoch  11:  91% | abe: 9.023 | eve: 10.238 | bob: 8.974Epoch  11:  92% | abe: 9.024 | eve: 10.238 | bob: 8.974Epoch  11:  92% | abe: 9.023 | eve: 10.238 | bob: 8.974Epoch  11:  93% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  94% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  95% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  96% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  96% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  97% | abe: 9.022 | eve: 10.237 | bob: 8.973Epoch  11:  98% | abe: 9.023 | eve: 10.238 | bob: 8.973Epoch  11:  99% | abe: 9.022 | eve: 10.237 | bob: 8.973
New best Bob loss 8.972552947548365 at epoch 11
Epoch  12:   0% | abe: 8.976 | eve: 10.178 | bob: 8.927Epoch  12:   0% | abe: 9.007 | eve: 10.197 | bob: 8.958Epoch  12:   1% | abe: 8.997 | eve: 10.207 | bob: 8.948Epoch  12:   2% | abe: 8.995 | eve: 10.221 | bob: 8.945Epoch  12:   3% | abe: 9.006 | eve: 10.227 | bob: 8.956Epoch  12:   3% | abe: 9.011 | eve: 10.224 | bob: 8.962Epoch  12:   4% | abe: 9.012 | eve: 10.225 | bob: 8.963Epoch  12:   5% | abe: 9.009 | eve: 10.228 | bob: 8.960Epoch  12:   6% | abe: 9.010 | eve: 10.219 | bob: 8.961Epoch  12:   7% | abe: 9.009 | eve: 10.215 | bob: 8.960Epoch  12:   7% | abe: 9.005 | eve: 10.217 | bob: 8.956Epoch  12:   8% | abe: 9.009 | eve: 10.210 | bob: 8.960Epoch  12:   9% | abe: 9.009 | eve: 10.218 | bob: 8.960Epoch  12:  10% | abe: 9.013 | eve: 10.217 | bob: 8.964Epoch  12:  10% | abe: 9.008 | eve: 10.221 | bob: 8.959Epoch  12:  11% | abe: 9.008 | eve: 10.220 | bob: 8.960Epoch  12:  12% | abe: 9.005 | eve: 10.220 | bob: 8.956Epoch  12:  13% | abe: 9.006 | eve: 10.217 | bob: 8.957Epoch  12:  14% | abe: 9.008 | eve: 10.216 | bob: 8.959Epoch  12:  14% | abe: 9.008 | eve: 10.220 | bob: 8.959Epoch  12:  15% | abe: 9.007 | eve: 10.221 | bob: 8.958Epoch  12:  16% | abe: 9.006 | eve: 10.221 | bob: 8.957Epoch  12:  17% | abe: 9.005 | eve: 10.216 | bob: 8.956Epoch  12:  17% | abe: 9.006 | eve: 10.218 | bob: 8.957Epoch  12:  18% | abe: 9.008 | eve: 10.216 | bob: 8.958Epoch  12:  19% | abe: 9.007 | eve: 10.216 | bob: 8.958Epoch  12:  20% | abe: 9.007 | eve: 10.217 | bob: 8.958Epoch  12:  21% | abe: 9.007 | eve: 10.216 | bob: 8.958Epoch  12:  21% | abe: 9.008 | eve: 10.216 | bob: 8.958Epoch  12:  22% | abe: 9.009 | eve: 10.217 | bob: 8.960Epoch  12:  23% | abe: 9.009 | eve: 10.219 | bob: 8.960Epoch  12:  24% | abe: 9.009 | eve: 10.217 | bob: 8.959Epoch  12:  25% | abe: 9.008 | eve: 10.220 | bob: 8.959Epoch  12:  25% | abe: 9.007 | eve: 10.221 | bob: 8.957Epoch  12:  26% | abe: 9.007 | eve: 10.220 | bob: 8.958Epoch  12:  27% | abe: 9.010 | eve: 10.221 | bob: 8.960Epoch  12:  28% | abe: 9.008 | eve: 10.222 | bob: 8.959Epoch  12:  28% | abe: 9.008 | eve: 10.220 | bob: 8.959Epoch  12:  29% | abe: 9.008 | eve: 10.221 | bob: 8.959Epoch  12:  30% | abe: 9.009 | eve: 10.223 | bob: 8.959Epoch  12:  31% | abe: 9.009 | eve: 10.224 | bob: 8.959Epoch  12:  32% | abe: 9.010 | eve: 10.223 | bob: 8.960Epoch  12:  32% | abe: 9.011 | eve: 10.223 | bob: 8.961Epoch  12:  33% | abe: 9.010 | eve: 10.224 | bob: 8.961Epoch  12:  34% | abe: 9.009 | eve: 10.225 | bob: 8.960Epoch  12:  35% | abe: 9.010 | eve: 10.225 | bob: 8.961Epoch  12:  35% | abe: 9.010 | eve: 10.226 | bob: 8.961Epoch  12:  36% | abe: 9.009 | eve: 10.226 | bob: 8.960Epoch  12:  37% | abe: 9.010 | eve: 10.226 | bob: 8.961Epoch  12:  38% | abe: 9.011 | eve: 10.226 | bob: 8.962Epoch  12:  39% | abe: 9.012 | eve: 10.225 | bob: 8.962Epoch  12:  39% | abe: 9.012 | eve: 10.224 | bob: 8.963Epoch  12:  40% | abe: 9.012 | eve: 10.225 | bob: 8.963Epoch  12:  41% | abe: 9.014 | eve: 10.225 | bob: 8.965Epoch  12:  42% | abe: 9.015 | eve: 10.225 | bob: 8.965Epoch  12:  42% | abe: 9.014 | eve: 10.226 | bob: 8.965Epoch  12:  43% | abe: 9.014 | eve: 10.226 | bob: 8.965Epoch  12:  44% | abe: 9.014 | eve: 10.228 | bob: 8.965Epoch  12:  45% | abe: 9.013 | eve: 10.227 | bob: 8.964Epoch  12:  46% | abe: 9.014 | eve: 10.226 | bob: 8.965Epoch  12:  46% | abe: 9.015 | eve: 10.228 | bob: 8.966Epoch  12:  47% | abe: 9.015 | eve: 10.226 | bob: 8.966Epoch  12:  48% | abe: 9.016 | eve: 10.225 | bob: 8.966Epoch  12:  49% | abe: 9.016 | eve: 10.224 | bob: 8.967Epoch  12:  50% | abe: 9.017 | eve: 10.225 | bob: 8.968Epoch  12:  50% | abe: 9.017 | eve: 10.225 | bob: 8.968Epoch  12:  51% | abe: 9.016 | eve: 10.226 | bob: 8.967Epoch  12:  52% | abe: 9.016 | eve: 10.227 | bob: 8.967Epoch  12:  53% | abe: 9.015 | eve: 10.226 | bob: 8.966Epoch  12:  53% | abe: 9.016 | eve: 10.226 | bob: 8.967Epoch  12:  54% | abe: 9.016 | eve: 10.226 | bob: 8.967Epoch  12:  55% | abe: 9.016 | eve: 10.226 | bob: 8.967Epoch  12:  56% | abe: 9.017 | eve: 10.227 | bob: 8.967Epoch  12:  57% | abe: 9.016 | eve: 10.227 | bob: 8.967Epoch  12:  57% | abe: 9.017 | eve: 10.228 | bob: 8.968Epoch  12:  58% | abe: 9.016 | eve: 10.228 | bob: 8.967Epoch  12:  59% | abe: 9.015 | eve: 10.229 | bob: 8.966Epoch  12:  60% | abe: 9.015 | eve: 10.229 | bob: 8.966Epoch  12:  60% | abe: 9.015 | eve: 10.229 | bob: 8.966Epoch  12:  61% | abe: 9.016 | eve: 10.229 | bob: 8.966Epoch  12:  62% | abe: 9.016 | eve: 10.229 | bob: 8.967Epoch  12:  63% | abe: 9.016 | eve: 10.230 | bob: 8.967Epoch  12:  64% | abe: 9.017 | eve: 10.230 | bob: 8.967Epoch  12:  64% | abe: 9.017 | eve: 10.230 | bob: 8.968Epoch  12:  65% | abe: 9.017 | eve: 10.230 | bob: 8.968Epoch  12:  66% | abe: 9.017 | eve: 10.229 | bob: 8.968Epoch  12:  67% | abe: 9.017 | eve: 10.229 | bob: 8.968Epoch  12:  67% | abe: 9.017 | eve: 10.229 | bob: 8.968Epoch  12:  68% | abe: 9.017 | eve: 10.228 | bob: 8.968Epoch  12:  69% | abe: 9.017 | eve: 10.227 | bob: 8.968Epoch  12:  70% | abe: 9.017 | eve: 10.228 | bob: 8.968Epoch  12:  71% | abe: 9.017 | eve: 10.229 | bob: 8.968Epoch  12:  71% | abe: 9.018 | eve: 10.229 | bob: 8.969Epoch  12:  72% | abe: 9.018 | eve: 10.229 | bob: 8.969Epoch  12:  73% | abe: 9.018 | eve: 10.228 | bob: 8.969Epoch  12:  74% | abe: 9.017 | eve: 10.228 | bob: 8.968Epoch  12:  75% | abe: 9.018 | eve: 10.227 | bob: 8.969Epoch  12:  75% | abe: 9.018 | eve: 10.227 | bob: 8.969Epoch  12:  76% | abe: 9.018 | eve: 10.227 | bob: 8.969Epoch  12:  77% | abe: 9.018 | eve: 10.227 | bob: 8.969Epoch  12:  78% | abe: 9.017 | eve: 10.227 | bob: 8.968Epoch  12:  78% | abe: 9.017 | eve: 10.227 | bob: 8.969Epoch  12:  79% | abe: 9.018 | eve: 10.227 | bob: 8.969Epoch  12:  80% | abe: 9.018 | eve: 10.228 | bob: 8.969Epoch  12:  81% | abe: 9.017 | eve: 10.228 | bob: 8.969Epoch  12:  82% | abe: 9.018 | eve: 10.229 | bob: 8.969Epoch  12:  82% | abe: 9.018 | eve: 10.229 | bob: 8.969Epoch  12:  83% | abe: 9.018 | eve: 10.228 | bob: 8.969Epoch  12:  84% | abe: 9.018 | eve: 10.228 | bob: 8.970Epoch  12:  85% | abe: 9.019 | eve: 10.227 | bob: 8.970Epoch  12:  85% | abe: 9.019 | eve: 10.227 | bob: 8.970Epoch  12:  86% | abe: 9.019 | eve: 10.226 | bob: 8.970Epoch  12:  87% | abe: 9.019 | eve: 10.226 | bob: 8.970Epoch  12:  88% | abe: 9.018 | eve: 10.226 | bob: 8.970Epoch  12:  89% | abe: 9.019 | eve: 10.226 | bob: 8.970Epoch  12:  89% | abe: 9.018 | eve: 10.226 | bob: 8.969Epoch  12:  90% | abe: 9.018 | eve: 10.227 | bob: 8.970Epoch  12:  91% | abe: 9.018 | eve: 10.227 | bob: 8.970Epoch  12:  92% | abe: 9.019 | eve: 10.227 | bob: 8.970Epoch  12:  92% | abe: 9.019 | eve: 10.226 | bob: 8.970Epoch  12:  93% | abe: 9.019 | eve: 10.226 | bob: 8.971Epoch  12:  94% | abe: 9.020 | eve: 10.226 | bob: 8.971Epoch  12:  95% | abe: 9.020 | eve: 10.226 | bob: 8.971Epoch  12:  96% | abe: 9.020 | eve: 10.226 | bob: 8.971Epoch  12:  96% | abe: 9.020 | eve: 10.226 | bob: 8.971Epoch  12:  97% | abe: 9.019 | eve: 10.226 | bob: 8.971Epoch  12:  98% | abe: 9.019 | eve: 10.227 | bob: 8.971Epoch  12:  99% | abe: 9.019 | eve: 10.227 | bob: 8.971
New best Bob loss 8.970595425759484 at epoch 12
Epoch  13:   0% | abe: 9.033 | eve: 10.316 | bob: 8.987Epoch  13:   0% | abe: 9.022 | eve: 10.299 | bob: 8.975Epoch  13:   1% | abe: 9.017 | eve: 10.292 | bob: 8.970Epoch  13:   2% | abe: 9.020 | eve: 10.290 | bob: 8.974Epoch  13:   3% | abe: 9.024 | eve: 10.295 | bob: 8.978Epoch  13:   3% | abe: 9.024 | eve: 10.272 | bob: 8.978Epoch  13:   4% | abe: 9.018 | eve: 10.258 | bob: 8.972Epoch  13:   5% | abe: 9.020 | eve: 10.242 | bob: 8.974Epoch  13:   6% | abe: 9.019 | eve: 10.244 | bob: 8.973Epoch  13:   7% | abe: 9.023 | eve: 10.244 | bob: 8.977Epoch  13:   7% | abe: 9.018 | eve: 10.242 | bob: 8.971Epoch  13:   8% | abe: 9.016 | eve: 10.238 | bob: 8.969Epoch  13:   9% | abe: 9.017 | eve: 10.232 | bob: 8.971Epoch  13:  10% | abe: 9.020 | eve: 10.233 | bob: 8.973Epoch  13:  10% | abe: 9.022 | eve: 10.236 | bob: 8.975Epoch  13:  11% | abe: 9.020 | eve: 10.234 | bob: 8.973Epoch  13:  12% | abe: 9.020 | eve: 10.235 | bob: 8.974Epoch  13:  13% | abe: 9.022 | eve: 10.233 | bob: 8.975Epoch  13:  14% | abe: 9.024 | eve: 10.234 | bob: 8.977Epoch  13:  14% | abe: 9.026 | eve: 10.232 | bob: 8.979Epoch  13:  15% | abe: 9.024 | eve: 10.231 | bob: 8.978Epoch  13:  16% | abe: 9.025 | eve: 10.229 | bob: 8.978Epoch  13:  17% | abe: 9.026 | eve: 10.225 | bob: 8.980Epoch  13:  17% | abe: 9.026 | eve: 10.224 | bob: 8.979Epoch  13:  18% | abe: 9.024 | eve: 10.225 | bob: 8.977Epoch  13:  19% | abe: 9.024 | eve: 10.225 | bob: 8.977Epoch  13:  20% | abe: 9.022 | eve: 10.224 | bob: 8.975Epoch  13:  21% | abe: 9.023 | eve: 10.223 | bob: 8.976Epoch  13:  21% | abe: 9.022 | eve: 10.224 | bob: 8.976Epoch  13:  22% | abe: 9.024 | eve: 10.224 | bob: 8.978Epoch  13:  23% | abe: 9.024 | eve: 10.225 | bob: 8.978Epoch  13:  24% | abe: 9.025 | eve: 10.225 | bob: 8.979Epoch  13:  25% | abe: 9.026 | eve: 10.227 | bob: 8.979Epoch  13:  25% | abe: 9.024 | eve: 10.229 | bob: 8.978Epoch  13:  26% | abe: 9.024 | eve: 10.230 | bob: 8.977Epoch  13:  27% | abe: 9.023 | eve: 10.232 | bob: 8.977Epoch  13:  28% | abe: 9.023 | eve: 10.232 | bob: 8.977Epoch  13:  28% | abe: 9.023 | eve: 10.231 | bob: 8.976Epoch  13:  29% | abe: 9.023 | eve: 10.233 | bob: 8.977Epoch  13:  30% | abe: 9.022 | eve: 10.231 | bob: 8.976Epoch  13:  31% | abe: 9.022 | eve: 10.232 | bob: 8.975Epoch  13:  32% | abe: 9.020 | eve: 10.233 | bob: 8.973Epoch  13:  32% | abe: 9.021 | eve: 10.231 | bob: 8.975Epoch  13:  33% | abe: 9.021 | eve: 10.231 | bob: 8.975Epoch  13:  34% | abe: 9.022 | eve: 10.232 | bob: 8.975Epoch  13:  35% | abe: 9.022 | eve: 10.232 | bob: 8.976Epoch  13:  35% | abe: 9.021 | eve: 10.232 | bob: 8.975Epoch  13:  36% | abe: 9.022 | eve: 10.232 | bob: 8.975Epoch  13:  37% | abe: 9.022 | eve: 10.231 | bob: 8.976Epoch  13:  38% | abe: 9.021 | eve: 10.230 | bob: 8.975Epoch  13:  39% | abe: 9.022 | eve: 10.229 | bob: 8.976Epoch  13:  39% | abe: 9.023 | eve: 10.229 | bob: 8.977Epoch  13:  40% | abe: 9.023 | eve: 10.229 | bob: 8.977Epoch  13:  41% | abe: 9.023 | eve: 10.229 | bob: 8.977Epoch  13:  42% | abe: 9.023 | eve: 10.230 | bob: 8.977Epoch  13:  42% | abe: 9.023 | eve: 10.230 | bob: 8.977Epoch  13:  43% | abe: 9.023 | eve: 10.227 | bob: 8.976Epoch  13:  44% | abe: 9.022 | eve: 10.227 | bob: 8.976Epoch  13:  45% | abe: 9.021 | eve: 10.229 | bob: 8.975Epoch  13:  46% | abe: 9.021 | eve: 10.227 | bob: 8.974Epoch  13:  46% | abe: 9.020 | eve: 10.226 | bob: 8.974Epoch  13:  47% | abe: 9.020 | eve: 10.228 | bob: 8.974Epoch  13:  48% | abe: 9.019 | eve: 10.228 | bob: 8.973Epoch  13:  49% | abe: 9.019 | eve: 10.227 | bob: 8.972Epoch  13:  50% | abe: 9.019 | eve: 10.226 | bob: 8.973Epoch  13:  50% | abe: 9.019 | eve: 10.227 | bob: 8.972Epoch  13:  51% | abe: 9.019 | eve: 10.226 | bob: 8.972Epoch  13:  52% | abe: 9.018 | eve: 10.227 | bob: 8.972Epoch  13:  53% | abe: 9.018 | eve: 10.226 | bob: 8.972Epoch  13:  53% | abe: 9.018 | eve: 10.227 | bob: 8.972Epoch  13:  54% | abe: 9.019 | eve: 10.227 | bob: 8.972Epoch  13:  55% | abe: 9.018 | eve: 10.226 | bob: 8.972Epoch  13:  56% | abe: 9.019 | eve: 10.227 | bob: 8.972Epoch  13:  57% | abe: 9.019 | eve: 10.227 | bob: 8.973Epoch  13:  57% | abe: 9.019 | eve: 10.228 | bob: 8.972Epoch  13:  58% | abe: 9.019 | eve: 10.228 | bob: 8.972Epoch  13:  59% | abe: 9.019 | eve: 10.228 | bob: 8.972Epoch  13:  60% | abe: 9.019 | eve: 10.228 | bob: 8.972Epoch  13:  60% | abe: 9.019 | eve: 10.228 | bob: 8.972Epoch  13:  61% | abe: 9.018 | eve: 10.228 | bob: 8.972Epoch  13:  62% | abe: 9.018 | eve: 10.229 | bob: 8.972Epoch  13:  63% | abe: 9.018 | eve: 10.229 | bob: 8.972Epoch  13:  64% | abe: 9.018 | eve: 10.229 | bob: 8.972Epoch  13:  64% | abe: 9.018 | eve: 10.228 | bob: 8.971Epoch  13:  65% | abe: 9.019 | eve: 10.229 | bob: 8.972Epoch  13:  66% | abe: 9.019 | eve: 10.230 | bob: 8.972Epoch  13:  67% | abe: 9.019 | eve: 10.229 | bob: 8.972Epoch  13:  67% | abe: 9.019 | eve: 10.229 | bob: 8.972Epoch  13:  68% | abe: 9.019 | eve: 10.229 | bob: 8.972Epoch  13:  69% | abe: 9.019 | eve: 10.229 | bob: 8.972Epoch  13:  70% | abe: 9.019 | eve: 10.229 | bob: 8.972Epoch  13:  71% | abe: 9.019 | eve: 10.229 | bob: 8.972Epoch  13:  71% | abe: 9.018 | eve: 10.228 | bob: 8.972Epoch  13:  72% | abe: 9.019 | eve: 10.229 | bob: 8.972Epoch  13:  73% | abe: 9.019 | eve: 10.230 | bob: 8.972Epoch  13:  74% | abe: 9.019 | eve: 10.230 | bob: 8.972Epoch  13:  75% | abe: 9.019 | eve: 10.230 | bob: 8.972Epoch  13:  75% | abe: 9.019 | eve: 10.230 | bob: 8.973Epoch  13:  76% | abe: 9.019 | eve: 10.230 | bob: 8.972Epoch  13:  77% | abe: 9.019 | eve: 10.229 | bob: 8.973Epoch  13:  78% | abe: 9.020 | eve: 10.228 | bob: 8.973Epoch  13:  78% | abe: 9.020 | eve: 10.228 | bob: 8.973Epoch  13:  79% | abe: 9.020 | eve: 10.228 | bob: 8.973Epoch  13:  80% | abe: 9.019 | eve: 10.228 | bob: 8.973Epoch  13:  81% | abe: 9.019 | eve: 10.227 | bob: 8.972Epoch  13:  82% | abe: 9.018 | eve: 10.227 | bob: 8.972Epoch  13:  82% | abe: 9.018 | eve: 10.226 | bob: 8.972Epoch  13:  83% | abe: 9.018 | eve: 10.227 | bob: 8.972Epoch  13:  84% | abe: 9.018 | eve: 10.226 | bob: 8.972Epoch  13:  85% | abe: 9.018 | eve: 10.226 | bob: 8.971Epoch  13:  85% | abe: 9.018 | eve: 10.226 | bob: 8.971Epoch  13:  86% | abe: 9.018 | eve: 10.227 | bob: 8.971Epoch  13:  87% | abe: 9.018 | eve: 10.226 | bob: 8.971Epoch  13:  88% | abe: 9.017 | eve: 10.225 | bob: 8.971Epoch  13:  89% | abe: 9.018 | eve: 10.226 | bob: 8.971Epoch  13:  89% | abe: 9.017 | eve: 10.226 | bob: 8.971Epoch  13:  90% | abe: 9.018 | eve: 10.226 | bob: 8.971Epoch  13:  91% | abe: 9.018 | eve: 10.226 | bob: 8.971Epoch  13:  92% | abe: 9.018 | eve: 10.226 | bob: 8.971Epoch  13:  92% | abe: 9.018 | eve: 10.226 | bob: 8.972Epoch  13:  93% | abe: 9.018 | eve: 10.227 | bob: 8.972Epoch  13:  94% | abe: 9.018 | eve: 10.226 | bob: 8.972Epoch  13:  95% | abe: 9.018 | eve: 10.227 | bob: 8.972Epoch  13:  96% | abe: 9.018 | eve: 10.226 | bob: 8.972Epoch  13:  96% | abe: 9.018 | eve: 10.226 | bob: 8.972Epoch  13:  97% | abe: 9.018 | eve: 10.226 | bob: 8.971Epoch  13:  98% | abe: 9.018 | eve: 10.226 | bob: 8.972Epoch  13:  99% | abe: 9.018 | eve: 10.226 | bob: 8.972Epoch  14:   0% | abe: 9.052 | eve: 10.266 | bob: 9.008Epoch  14:   0% | abe: 9.039 | eve: 10.235 | bob: 8.994Epoch  14:   1% | abe: 9.031 | eve: 10.230 | bob: 8.986Epoch  14:   2% | abe: 9.035 | eve: 10.222 | bob: 8.990Epoch  14:   3% | abe: 9.023 | eve: 10.237 | bob: 8.977Epoch  14:   3% | abe: 9.015 | eve: 10.218 | bob: 8.969Epoch  14:   4% | abe: 9.015 | eve: 10.228 | bob: 8.969Epoch  14:   5% | abe: 9.012 | eve: 10.227 | bob: 8.966Epoch  14:   6% | abe: 9.015 | eve: 10.228 | bob: 8.968Epoch  14:   7% | abe: 9.016 | eve: 10.222 | bob: 8.970Epoch  14:   7% | abe: 9.014 | eve: 10.232 | bob: 8.967Epoch  14:   8% | abe: 9.013 | eve: 10.231 | bob: 8.967Epoch  14:   9% | abe: 9.016 | eve: 10.225 | bob: 8.970Epoch  14:  10% | abe: 9.017 | eve: 10.232 | bob: 8.971Epoch  14:  10% | abe: 9.016 | eve: 10.232 | bob: 8.970Epoch  14:  11% | abe: 9.014 | eve: 10.234 | bob: 8.967Epoch  14:  12% | abe: 9.015 | eve: 10.232 | bob: 8.968Epoch  14:  13% | abe: 9.011 | eve: 10.228 | bob: 8.964Epoch  14:  14% | abe: 9.011 | eve: 10.230 | bob: 8.964Epoch  14:  14% | abe: 9.012 | eve: 10.233 | bob: 8.965Epoch  14:  15% | abe: 9.012 | eve: 10.233 | bob: 8.965Epoch  14:  16% | abe: 9.011 | eve: 10.232 | bob: 8.965Epoch  14:  17% | abe: 9.011 | eve: 10.234 | bob: 8.964Epoch  14:  17% | abe: 9.012 | eve: 10.232 | bob: 8.965Epoch  14:  18% | abe: 9.011 | eve: 10.234 | bob: 8.964Epoch  14:  19% | abe: 9.010 | eve: 10.237 | bob: 8.963Epoch  14:  20% | abe: 9.009 | eve: 10.234 | bob: 8.962Epoch  14:  21% | abe: 9.013 | eve: 10.236 | bob: 8.966Epoch  14:  21% | abe: 9.013 | eve: 10.237 | bob: 8.966Epoch  14:  22% | abe: 9.013 | eve: 10.237 | bob: 8.966Epoch  14:  23% | abe: 9.012 | eve: 10.238 | bob: 8.965Epoch  14:  24% | abe: 9.012 | eve: 10.240 | bob: 8.965Epoch  14:  25% | abe: 9.012 | eve: 10.242 | bob: 8.965Epoch  14:  25% | abe: 9.013 | eve: 10.241 | bob: 8.966Epoch  14:  26% | abe: 9.012 | eve: 10.238 | bob: 8.965Epoch  14:  27% | abe: 9.012 | eve: 10.236 | bob: 8.965Epoch  14:  28% | abe: 9.011 | eve: 10.236 | bob: 8.964Epoch  14:  28% | abe: 9.010 | eve: 10.237 | bob: 8.963Epoch  14:  29% | abe: 9.010 | eve: 10.236 | bob: 8.963Epoch  14:  30% | abe: 9.011 | eve: 10.236 | bob: 8.964Epoch  14:  31% | abe: 9.009 | eve: 10.235 | bob: 8.962Epoch  14:  32% | abe: 9.008 | eve: 10.234 | bob: 8.961Epoch  14:  32% | abe: 9.007 | eve: 10.234 | bob: 8.960Epoch  14:  33% | abe: 9.007 | eve: 10.233 | bob: 8.960Epoch  14:  34% | abe: 9.008 | eve: 10.234 | bob: 8.961Epoch  14:  35% | abe: 9.008 | eve: 10.232 | bob: 8.961Epoch  14:  35% | abe: 9.009 | eve: 10.232 | bob: 8.961Epoch  14:  36% | abe: 9.008 | eve: 10.232 | bob: 8.961Epoch  14:  37% | abe: 9.009 | eve: 10.232 | bob: 8.962Epoch  14:  38% | abe: 9.009 | eve: 10.231 | bob: 8.962Epoch  14:  39% | abe: 9.010 | eve: 10.232 | bob: 8.964Epoch  14:  39% | abe: 9.012 | eve: 10.232 | bob: 8.965Epoch  14:  40% | abe: 9.012 | eve: 10.234 | bob: 8.965Epoch  14:  41% | abe: 9.012 | eve: 10.233 | bob: 8.965Epoch  14:  42% | abe: 9.012 | eve: 10.233 | bob: 8.965Epoch  14:  42% | abe: 9.012 | eve: 10.233 | bob: 8.965Epoch  14:  43% | abe: 9.011 | eve: 10.233 | bob: 8.964Epoch  14:  44% | abe: 9.011 | eve: 10.233 | bob: 8.964Epoch  14:  45% | abe: 9.011 | eve: 10.234 | bob: 8.964Epoch  14:  46% | abe: 9.011 | eve: 10.234 | bob: 8.964Epoch  14:  46% | abe: 9.011 | eve: 10.233 | bob: 8.965Epoch  14:  47% | abe: 9.011 | eve: 10.233 | bob: 8.964Epoch  14:  48% | abe: 9.011 | eve: 10.233 | bob: 8.964Epoch  14:  49% | abe: 9.011 | eve: 10.233 | bob: 8.964Epoch  14:  50% | abe: 9.011 | eve: 10.233 | bob: 8.964Epoch  14:  50% | abe: 9.011 | eve: 10.232 | bob: 8.964Epoch  14:  51% | abe: 9.011 | eve: 10.233 | bob: 8.964Epoch  14:  52% | abe: 9.012 | eve: 10.232 | bob: 8.965Epoch  14:  53% | abe: 9.011 | eve: 10.231 | bob: 8.964Epoch  14:  53% | abe: 9.011 | eve: 10.231 | bob: 8.964Epoch  14:  54% | abe: 9.011 | eve: 10.231 | bob: 8.964Epoch  14:  55% | abe: 9.011 | eve: 10.232 | bob: 8.964Epoch  14:  56% | abe: 9.011 | eve: 10.231 | bob: 8.964Epoch  14:  57% | abe: 9.012 | eve: 10.230 | bob: 8.965Epoch  14:  57% | abe: 9.012 | eve: 10.230 | bob: 8.965Epoch  14:  58% | abe: 9.012 | eve: 10.230 | bob: 8.965Epoch  14:  59% | abe: 9.012 | eve: 10.229 | bob: 8.966Epoch  14:  60% | abe: 9.012 | eve: 10.230 | bob: 8.966Epoch  14:  60% | abe: 9.012 | eve: 10.229 | bob: 8.965Epoch  14:  61% | abe: 9.012 | eve: 10.229 | bob: 8.965Epoch  14:  62% | abe: 9.012 | eve: 10.229 | bob: 8.966Epoch  14:  63% | abe: 9.012 | eve: 10.228 | bob: 8.966Epoch  14:  64% | abe: 9.012 | eve: 10.229 | bob: 8.966Epoch  14:  64% | abe: 9.012 | eve: 10.228 | bob: 8.966Epoch  14:  65% | abe: 9.011 | eve: 10.228 | bob: 8.965Epoch  14:  66% | abe: 9.012 | eve: 10.228 | bob: 8.966Epoch  14:  67% | abe: 9.013 | eve: 10.228 | bob: 8.966Epoch  14:  67% | abe: 9.012 | eve: 10.229 | bob: 8.966Epoch  14:  68% | abe: 9.012 | eve: 10.228 | bob: 8.966Epoch  14:  69% | abe: 9.012 | eve: 10.228 | bob: 8.966Epoch  14:  70% | abe: 9.012 | eve: 10.228 | bob: 8.966Epoch  14:  71% | abe: 9.012 | eve: 10.228 | bob: 8.965Epoch  14:  71% | abe: 9.013 | eve: 10.228 | bob: 8.966Epoch  14:  72% | abe: 9.013 | eve: 10.228 | bob: 8.967Epoch  14:  73% | abe: 9.013 | eve: 10.228 | bob: 8.966Epoch  14:  74% | abe: 9.013 | eve: 10.229 | bob: 8.966Epoch  14:  75% | abe: 9.013 | eve: 10.229 | bob: 8.966Epoch  14:  75% | abe: 9.013 | eve: 10.229 | bob: 8.966Epoch  14:  76% | abe: 9.012 | eve: 10.229 | bob: 8.966Epoch  14:  77% | abe: 9.012 | eve: 10.229 | bob: 8.966Epoch  14:  78% | abe: 9.012 | eve: 10.228 | bob: 8.966Epoch  14:  78% | abe: 9.012 | eve: 10.228 | bob: 8.966Epoch  14:  79% | abe: 9.012 | eve: 10.228 | bob: 8.966Epoch  14:  80% | abe: 9.012 | eve: 10.227 | bob: 8.966Epoch  14:  81% | abe: 9.013 | eve: 10.228 | bob: 8.966Epoch  14:  82% | abe: 9.013 | eve: 10.228 | bob: 8.966Epoch  14:  82% | abe: 9.013 | eve: 10.228 | bob: 8.966Epoch  14:  83% | abe: 9.013 | eve: 10.227 | bob: 8.966Epoch  14:  84% | abe: 9.013 | eve: 10.227 | bob: 8.966Epoch  14:  85% | abe: 9.013 | eve: 10.227 | bob: 8.966Epoch  14:  85% | abe: 9.013 | eve: 10.226 | bob: 8.967Epoch  14:  86% | abe: 9.013 | eve: 10.226 | bob: 8.966Epoch  14:  87% | abe: 9.012 | eve: 10.226 | bob: 8.966Epoch  14:  88% | abe: 9.012 | eve: 10.226 | bob: 8.966Epoch  14:  89% | abe: 9.012 | eve: 10.226 | bob: 8.966Epoch  14:  89% | abe: 9.012 | eve: 10.226 | bob: 8.966Epoch  14:  90% | abe: 9.012 | eve: 10.226 | bob: 8.966Epoch  14:  91% | abe: 9.013 | eve: 10.226 | bob: 8.966Epoch  14:  92% | abe: 9.012 | eve: 10.226 | bob: 8.966Epoch  14:  92% | abe: 9.013 | eve: 10.225 | bob: 8.966Epoch  14:  93% | abe: 9.013 | eve: 10.225 | bob: 8.967Epoch  14:  94% | abe: 9.013 | eve: 10.225 | bob: 8.967Epoch  14:  95% | abe: 9.013 | eve: 10.225 | bob: 8.966Epoch  14:  96% | abe: 9.013 | eve: 10.225 | bob: 8.967Epoch  14:  96% | abe: 9.013 | eve: 10.225 | bob: 8.967Epoch  14:  97% | abe: 9.013 | eve: 10.224 | bob: 8.967Epoch  14:  98% | abe: 9.013 | eve: 10.224 | bob: 8.966Epoch  14:  99% | abe: 9.013 | eve: 10.224 | bob: 8.966
New best Bob loss 8.966380169012837 at epoch 14
Epoch  15:   0% | abe: 9.022 | eve: 10.172 | bob: 8.975Epoch  15:   0% | abe: 9.016 | eve: 10.193 | bob: 8.970Epoch  15:   1% | abe: 9.001 | eve: 10.207 | bob: 8.953Epoch  15:   2% | abe: 9.019 | eve: 10.208 | bob: 8.973Epoch  15:   3% | abe: 9.016 | eve: 10.215 | bob: 8.970Epoch  15:   3% | abe: 9.023 | eve: 10.214 | bob: 8.977Epoch  15:   4% | abe: 9.023 | eve: 10.222 | bob: 8.977Epoch  15:   5% | abe: 9.019 | eve: 10.223 | bob: 8.973Epoch  15:   6% | abe: 9.022 | eve: 10.232 | bob: 8.977Epoch  15:   7% | abe: 9.025 | eve: 10.234 | bob: 8.979Epoch  15:   7% | abe: 9.028 | eve: 10.226 | bob: 8.983Epoch  15:   8% | abe: 9.026 | eve: 10.226 | bob: 8.980Epoch  15:   9% | abe: 9.023 | eve: 10.222 | bob: 8.978Epoch  15:  10% | abe: 9.021 | eve: 10.221 | bob: 8.976Epoch  15:  10% | abe: 9.022 | eve: 10.219 | bob: 8.977Epoch  15:  11% | abe: 9.020 | eve: 10.219 | bob: 8.975Epoch  15:  12% | abe: 9.019 | eve: 10.218 | bob: 8.974Epoch  15:  13% | abe: 9.023 | eve: 10.220 | bob: 8.978Epoch  15:  14% | abe: 9.024 | eve: 10.222 | bob: 8.978Epoch  15:  14% | abe: 9.022 | eve: 10.223 | bob: 8.977Epoch  15:  15% | abe: 9.021 | eve: 10.224 | bob: 8.975Epoch  15:  16% | abe: 9.021 | eve: 10.224 | bob: 8.975Epoch  15:  17% | abe: 9.021 | eve: 10.220 | bob: 8.976Epoch  15:  17% | abe: 9.022 | eve: 10.218 | bob: 8.976Epoch  15:  18% | abe: 9.020 | eve: 10.215 | bob: 8.974Epoch  15:  19% | abe: 9.017 | eve: 10.214 | bob: 8.972Epoch  15:  20% | abe: 9.019 | eve: 10.215 | bob: 8.974Epoch  15:  21% | abe: 9.020 | eve: 10.217 | bob: 8.974Epoch  15:  21% | abe: 9.019 | eve: 10.218 | bob: 8.974Epoch  15:  22% | abe: 9.020 | eve: 10.216 | bob: 8.975Epoch  15:  23% | abe: 9.020 | eve: 10.215 | bob: 8.974Epoch  15:  24% | abe: 9.019 | eve: 10.215 | bob: 8.974Epoch  15:  25% | abe: 9.019 | eve: 10.215 | bob: 8.974Epoch  15:  25% | abe: 9.019 | eve: 10.218 | bob: 8.973Epoch  15:  26% | abe: 9.019 | eve: 10.218 | bob: 8.974Epoch  15:  27% | abe: 9.020 | eve: 10.216 | bob: 8.975Epoch  15:  28% | abe: 9.020 | eve: 10.216 | bob: 8.975Epoch  15:  28% | abe: 9.020 | eve: 10.214 | bob: 8.975Epoch  15:  29% | abe: 9.019 | eve: 10.214 | bob: 8.973Epoch  15:  30% | abe: 9.018 | eve: 10.214 | bob: 8.973Epoch  15:  31% | abe: 9.019 | eve: 10.214 | bob: 8.974Epoch  15:  32% | abe: 9.020 | eve: 10.213 | bob: 8.975Epoch  15:  32% | abe: 9.020 | eve: 10.214 | bob: 8.974Epoch  15:  33% | abe: 9.020 | eve: 10.215 | bob: 8.974Epoch  15:  34% | abe: 9.019 | eve: 10.215 | bob: 8.974Epoch  15:  35% | abe: 9.020 | eve: 10.216 | bob: 8.974Epoch  15:  35% | abe: 9.020 | eve: 10.214 | bob: 8.975Epoch  15:  36% | abe: 9.020 | eve: 10.213 | bob: 8.974Epoch  15:  37% | abe: 9.018 | eve: 10.214 | bob: 8.973Epoch  15:  38% | abe: 9.018 | eve: 10.215 | bob: 8.973Epoch  15:  39% | abe: 9.018 | eve: 10.215 | bob: 8.973Epoch  15:  39% | abe: 9.017 | eve: 10.215 | bob: 8.972Epoch  15:  40% | abe: 9.017 | eve: 10.214 | bob: 8.972Epoch  15:  41% | abe: 9.017 | eve: 10.214 | bob: 8.972Epoch  15:  42% | abe: 9.017 | eve: 10.215 | bob: 8.971Epoch  15:  42% | abe: 9.018 | eve: 10.213 | bob: 8.972Epoch  15:  43% | abe: 9.017 | eve: 10.213 | bob: 8.972Epoch  15:  44% | abe: 9.016 | eve: 10.214 | bob: 8.971Epoch  15:  45% | abe: 9.016 | eve: 10.214 | bob: 8.970Epoch  15:  46% | abe: 9.016 | eve: 10.213 | bob: 8.971Epoch  15:  46% | abe: 9.016 | eve: 10.212 | bob: 8.971Epoch  15:  47% | abe: 9.016 | eve: 10.215 | bob: 8.971Epoch  15:  48% | abe: 9.017 | eve: 10.214 | bob: 8.971Epoch  15:  49% | abe: 9.017 | eve: 10.214 | bob: 8.971Epoch  15:  50% | abe: 9.016 | eve: 10.215 | bob: 8.971Epoch  15:  50% | abe: 9.016 | eve: 10.216 | bob: 8.971Epoch  15:  51% | abe: 9.017 | eve: 10.217 | bob: 8.971Epoch  15:  52% | abe: 9.017 | eve: 10.216 | bob: 8.972Epoch  15:  53% | abe: 9.016 | eve: 10.216 | bob: 8.971Epoch  15:  53% | abe: 9.016 | eve: 10.216 | bob: 8.970Epoch  15:  54% | abe: 9.016 | eve: 10.215 | bob: 8.971Epoch  15:  55% | abe: 9.016 | eve: 10.214 | bob: 8.971Epoch  15:  56% | abe: 9.015 | eve: 10.214 | bob: 8.970Epoch  15:  57% | abe: 9.014 | eve: 10.215 | bob: 8.969Epoch  15:  57% | abe: 9.013 | eve: 10.214 | bob: 8.968Epoch  15:  58% | abe: 9.013 | eve: 10.214 | bob: 8.968Epoch  15:  59% | abe: 9.013 | eve: 10.214 | bob: 8.968Epoch  15:  60% | abe: 9.013 | eve: 10.214 | bob: 8.968Epoch  15:  60% | abe: 9.013 | eve: 10.213 | bob: 8.968Epoch  15:  61% | abe: 9.013 | eve: 10.213 | bob: 8.967Epoch  15:  62% | abe: 9.013 | eve: 10.213 | bob: 8.967Epoch  15:  63% | abe: 9.012 | eve: 10.214 | bob: 8.967Epoch  15:  64% | abe: 9.012 | eve: 10.214 | bob: 8.966Epoch  15:  64% | abe: 9.012 | eve: 10.214 | bob: 8.966Epoch  15:  65% | abe: 9.011 | eve: 10.213 | bob: 8.966Epoch  15:  66% | abe: 9.011 | eve: 10.213 | bob: 8.966Epoch  15:  67% | abe: 9.011 | eve: 10.213 | bob: 8.965Epoch  15:  67% | abe: 9.011 | eve: 10.212 | bob: 8.965Epoch  15:  68% | abe: 9.011 | eve: 10.213 | bob: 8.965Epoch  15:  69% | abe: 9.011 | eve: 10.213 | bob: 8.966Epoch  15:  70% | abe: 9.011 | eve: 10.213 | bob: 8.965Epoch  15:  71% | abe: 9.011 | eve: 10.212 | bob: 8.965Epoch  15:  71% | abe: 9.011 | eve: 10.212 | bob: 8.966Epoch  15:  72% | abe: 9.011 | eve: 10.212 | bob: 8.966Epoch  15:  73% | abe: 9.012 | eve: 10.212 | bob: 8.966Epoch  15:  74% | abe: 9.012 | eve: 10.212 | bob: 8.966Epoch  15:  75% | abe: 9.012 | eve: 10.212 | bob: 8.966Epoch  15:  75% | abe: 9.011 | eve: 10.213 | bob: 8.966Epoch  15:  76% | abe: 9.012 | eve: 10.214 | bob: 8.966Epoch  15:  77% | abe: 9.012 | eve: 10.214 | bob: 8.966Epoch  15:  78% | abe: 9.012 | eve: 10.214 | bob: 8.966Epoch  15:  78% | abe: 9.012 | eve: 10.214 | bob: 8.966Epoch  15:  79% | abe: 9.011 | eve: 10.214 | bob: 8.965Epoch  15:  80% | abe: 9.011 | eve: 10.215 | bob: 8.965Epoch  15:  81% | abe: 9.011 | eve: 10.215 | bob: 8.966Epoch  15:  82% | abe: 9.011 | eve: 10.216 | bob: 8.965Epoch  15:  82% | abe: 9.011 | eve: 10.216 | bob: 8.966Epoch  15:  83% | abe: 9.011 | eve: 10.215 | bob: 8.965Epoch  15:  84% | abe: 9.011 | eve: 10.215 | bob: 8.965Epoch  15:  85% | abe: 9.010 | eve: 10.215 | bob: 8.965Epoch  15:  85% | abe: 9.010 | eve: 10.215 | bob: 8.965Epoch  15:  86% | abe: 9.011 | eve: 10.215 | bob: 8.965Epoch  15:  87% | abe: 9.010 | eve: 10.215 | bob: 8.965Epoch  15:  88% | abe: 9.010 | eve: 10.214 | bob: 8.965Epoch  15:  89% | abe: 9.010 | eve: 10.214 | bob: 8.964Epoch  15:  89% | abe: 9.010 | eve: 10.214 | bob: 8.964Epoch  15:  90% | abe: 9.010 | eve: 10.212 | bob: 8.964Epoch  15:  91% | abe: 9.010 | eve: 10.212 | bob: 8.964Epoch  15:  92% | abe: 9.010 | eve: 10.212 | bob: 8.964Epoch  15:  92% | abe: 9.009 | eve: 10.212 | bob: 8.964Epoch  15:  93% | abe: 9.009 | eve: 10.213 | bob: 8.964Epoch  15:  94% | abe: 9.009 | eve: 10.213 | bob: 8.964Epoch  15:  95% | abe: 9.009 | eve: 10.213 | bob: 8.964Epoch  15:  96% | abe: 9.009 | eve: 10.213 | bob: 8.964Epoch  15:  96% | abe: 9.009 | eve: 10.213 | bob: 8.964Epoch  15:  97% | abe: 9.009 | eve: 10.212 | bob: 8.964Epoch  15:  98% | abe: 9.009 | eve: 10.212 | bob: 8.964Epoch  15:  99% | abe: 9.009 | eve: 10.212 | bob: 8.964
New best Bob loss 8.96388113811122 at epoch 15
Epoch  16:   0% | abe: 9.022 | eve: 10.222 | bob: 8.978Epoch  16:   0% | abe: 9.009 | eve: 10.217 | bob: 8.966Epoch  16:   1% | abe: 8.997 | eve: 10.225 | bob: 8.953Epoch  16:   2% | abe: 8.999 | eve: 10.219 | bob: 8.955Epoch  16:   3% | abe: 8.998 | eve: 10.229 | bob: 8.953Epoch  16:   3% | abe: 9.001 | eve: 10.220 | bob: 8.956Epoch  16:   4% | abe: 9.001 | eve: 10.232 | bob: 8.956Epoch  16:   5% | abe: 8.999 | eve: 10.230 | bob: 8.955Epoch  16:   6% | abe: 9.003 | eve: 10.231 | bob: 8.959Epoch  16:   7% | abe: 9.006 | eve: 10.231 | bob: 8.962Epoch  16:   7% | abe: 9.005 | eve: 10.228 | bob: 8.961Epoch  16:   8% | abe: 9.005 | eve: 10.225 | bob: 8.960Epoch  16:   9% | abe: 9.002 | eve: 10.223 | bob: 8.958Epoch  16:  10% | abe: 9.003 | eve: 10.224 | bob: 8.959Epoch  16:  10% | abe: 9.002 | eve: 10.227 | bob: 8.958Epoch  16:  11% | abe: 9.005 | eve: 10.231 | bob: 8.961Epoch  16:  12% | abe: 9.003 | eve: 10.230 | bob: 8.959Epoch  16:  13% | abe: 9.003 | eve: 10.229 | bob: 8.959Epoch  16:  14% | abe: 9.000 | eve: 10.229 | bob: 8.956Epoch  16:  14% | abe: 8.999 | eve: 10.226 | bob: 8.955Epoch  16:  15% | abe: 9.000 | eve: 10.222 | bob: 8.956Epoch  16:  16% | abe: 9.001 | eve: 10.223 | bob: 8.957Epoch  16:  17% | abe: 8.999 | eve: 10.220 | bob: 8.955Epoch  16:  17% | abe: 9.000 | eve: 10.221 | bob: 8.956Epoch  16:  18% | abe: 9.000 | eve: 10.222 | bob: 8.956Epoch  16:  19% | abe: 9.000 | eve: 10.224 | bob: 8.956Epoch  16:  20% | abe: 8.999 | eve: 10.223 | bob: 8.955Epoch  16:  21% | abe: 8.999 | eve: 10.219 | bob: 8.955Epoch  16:  21% | abe: 8.998 | eve: 10.221 | bob: 8.953Epoch  16:  22% | abe: 8.998 | eve: 10.220 | bob: 8.953Epoch  16:  23% | abe: 8.998 | eve: 10.221 | bob: 8.953Epoch  16:  24% | abe: 8.997 | eve: 10.220 | bob: 8.953Epoch  16:  25% | abe: 8.997 | eve: 10.222 | bob: 8.953Epoch  16:  25% | abe: 8.995 | eve: 10.222 | bob: 8.951Epoch  16:  26% | abe: 8.995 | eve: 10.221 | bob: 8.950Epoch  16:  27% | abe: 8.994 | eve: 10.220 | bob: 8.950Epoch  16:  28% | abe: 8.995 | eve: 10.220 | bob: 8.951Epoch  16:  28% | abe: 8.995 | eve: 10.220 | bob: 8.951Epoch  16:  29% | abe: 8.994 | eve: 10.219 | bob: 8.950Epoch  16:  30% | abe: 8.993 | eve: 10.219 | bob: 8.948Epoch  16:  31% | abe: 8.992 | eve: 10.218 | bob: 8.948Epoch  16:  32% | abe: 8.993 | eve: 10.218 | bob: 8.949Epoch  16:  32% | abe: 8.993 | eve: 10.216 | bob: 8.948Epoch  16:  33% | abe: 8.993 | eve: 10.215 | bob: 8.949Epoch  16:  34% | abe: 8.993 | eve: 10.215 | bob: 8.948Epoch  16:  35% | abe: 8.992 | eve: 10.214 | bob: 8.948Epoch  16:  35% | abe: 8.992 | eve: 10.213 | bob: 8.948Epoch  16:  36% | abe: 8.993 | eve: 10.213 | bob: 8.949Epoch  16:  37% | abe: 8.993 | eve: 10.213 | bob: 8.949Epoch  16:  38% | abe: 8.994 | eve: 10.211 | bob: 8.950Epoch  16:  39% | abe: 8.994 | eve: 10.212 | bob: 8.950Epoch  16:  39% | abe: 8.994 | eve: 10.212 | bob: 8.949Epoch  16:  40% | abe: 8.995 | eve: 10.213 | bob: 8.950Epoch  16:  41% | abe: 8.994 | eve: 10.213 | bob: 8.949Epoch  16:  42% | abe: 8.994 | eve: 10.213 | bob: 8.950Epoch  16:  42% | abe: 8.995 | eve: 10.213 | bob: 8.951Epoch  16:  43% | abe: 8.994 | eve: 10.212 | bob: 8.950Epoch  16:  44% | abe: 8.995 | eve: 10.213 | bob: 8.951Epoch  16:  45% | abe: 8.995 | eve: 10.213 | bob: 8.951Epoch  16:  46% | abe: 8.996 | eve: 10.212 | bob: 8.952Epoch  16:  46% | abe: 8.995 | eve: 10.212 | bob: 8.951Epoch  16:  47% | abe: 8.994 | eve: 10.211 | bob: 8.950Epoch  16:  48% | abe: 8.993 | eve: 10.211 | bob: 8.949Epoch  16:  49% | abe: 8.994 | eve: 10.211 | bob: 8.949Epoch  16:  50% | abe: 8.994 | eve: 10.210 | bob: 8.950Epoch  16:  50% | abe: 8.995 | eve: 10.209 | bob: 8.950Epoch  16:  51% | abe: 8.995 | eve: 10.208 | bob: 8.951Epoch  16:  52% | abe: 8.996 | eve: 10.209 | bob: 8.952Epoch  16:  53% | abe: 8.995 | eve: 10.209 | bob: 8.951Epoch  16:  53% | abe: 8.996 | eve: 10.209 | bob: 8.952Epoch  16:  54% | abe: 8.996 | eve: 10.209 | bob: 8.952Epoch  16:  55% | abe: 8.996 | eve: 10.209 | bob: 8.952Epoch  16:  56% | abe: 8.996 | eve: 10.209 | bob: 8.952Epoch  16:  57% | abe: 8.996 | eve: 10.210 | bob: 8.952Epoch  16:  57% | abe: 8.996 | eve: 10.211 | bob: 8.952Epoch  16:  58% | abe: 8.996 | eve: 10.211 | bob: 8.952Epoch  16:  59% | abe: 8.996 | eve: 10.210 | bob: 8.952Epoch  16:  60% | abe: 8.996 | eve: 10.211 | bob: 8.952Epoch  16:  60% | abe: 8.996 | eve: 10.211 | bob: 8.953Epoch  16:  61% | abe: 8.996 | eve: 10.212 | bob: 8.952Epoch  16:  62% | abe: 8.996 | eve: 10.212 | bob: 8.953Epoch  16:  63% | abe: 8.997 | eve: 10.212 | bob: 8.953Epoch  16:  64% | abe: 8.997 | eve: 10.213 | bob: 8.953Epoch  16:  64% | abe: 8.997 | eve: 10.213 | bob: 8.953Epoch  16:  65% | abe: 8.997 | eve: 10.212 | bob: 8.953Epoch  16:  66% | abe: 8.998 | eve: 10.212 | bob: 8.954Epoch  16:  67% | abe: 8.997 | eve: 10.212 | bob: 8.954Epoch  16:  67% | abe: 8.998 | eve: 10.211 | bob: 8.954Epoch  16:  68% | abe: 8.998 | eve: 10.211 | bob: 8.954Epoch  16:  69% | abe: 8.998 | eve: 10.211 | bob: 8.954Epoch  16:  70% | abe: 8.998 | eve: 10.212 | bob: 8.955Epoch  16:  71% | abe: 8.998 | eve: 10.211 | bob: 8.955Epoch  16:  71% | abe: 8.998 | eve: 10.211 | bob: 8.955Epoch  16:  72% | abe: 8.998 | eve: 10.212 | bob: 8.955Epoch  16:  73% | abe: 8.997 | eve: 10.213 | bob: 8.954Epoch  16:  74% | abe: 8.997 | eve: 10.213 | bob: 8.954Epoch  16:  75% | abe: 8.997 | eve: 10.214 | bob: 8.954Epoch  16:  75% | abe: 8.997 | eve: 10.214 | bob: 8.954Epoch  16:  76% | abe: 8.997 | eve: 10.214 | bob: 8.954Epoch  16:  77% | abe: 8.997 | eve: 10.214 | bob: 8.954Epoch  16:  78% | abe: 8.997 | eve: 10.214 | bob: 8.953Epoch  16:  78% | abe: 8.996 | eve: 10.214 | bob: 8.953Epoch  16:  79% | abe: 8.997 | eve: 10.214 | bob: 8.953Epoch  16:  80% | abe: 8.997 | eve: 10.214 | bob: 8.953Epoch  16:  81% | abe: 8.997 | eve: 10.215 | bob: 8.953Epoch  16:  82% | abe: 8.996 | eve: 10.215 | bob: 8.953Epoch  16:  82% | abe: 8.997 | eve: 10.214 | bob: 8.953Epoch  16:  83% | abe: 8.996 | eve: 10.214 | bob: 8.953Epoch  16:  84% | abe: 8.996 | eve: 10.213 | bob: 8.953Epoch  16:  85% | abe: 8.996 | eve: 10.213 | bob: 8.953Epoch  16:  85% | abe: 8.996 | eve: 10.213 | bob: 8.952Epoch  16:  86% | abe: 8.996 | eve: 10.213 | bob: 8.953Epoch  16:  87% | abe: 8.996 | eve: 10.213 | bob: 8.953Epoch  16:  88% | abe: 8.996 | eve: 10.214 | bob: 8.953Epoch  16:  89% | abe: 8.996 | eve: 10.214 | bob: 8.953Epoch  16:  89% | abe: 8.996 | eve: 10.213 | bob: 8.953Epoch  16:  90% | abe: 8.996 | eve: 10.213 | bob: 8.953Epoch  16:  91% | abe: 8.996 | eve: 10.214 | bob: 8.953Epoch  16:  92% | abe: 8.996 | eve: 10.214 | bob: 8.953Epoch  16:  92% | abe: 8.996 | eve: 10.214 | bob: 8.953Epoch  16:  93% | abe: 8.996 | eve: 10.215 | bob: 8.953Epoch  16:  94% | abe: 8.997 | eve: 10.214 | bob: 8.954Epoch  16:  95% | abe: 8.997 | eve: 10.214 | bob: 8.954Epoch  16:  96% | abe: 8.997 | eve: 10.214 | bob: 8.954Epoch  16:  96% | abe: 8.997 | eve: 10.214 | bob: 8.954Epoch  16:  97% | abe: 8.997 | eve: 10.214 | bob: 8.954Epoch  16:  98% | abe: 8.996 | eve: 10.214 | bob: 8.953Epoch  16:  99% | abe: 8.996 | eve: 10.215 | bob: 8.953
New best Bob loss 8.953036770227527 at epoch 16
Epoch  17:   0% | abe: 9.029 | eve: 10.163 | bob: 8.989Epoch  17:   0% | abe: 8.986 | eve: 10.171 | bob: 8.943Epoch  17:   1% | abe: 8.974 | eve: 10.172 | bob: 8.930Epoch  17:   2% | abe: 8.975 | eve: 10.194 | bob: 8.931Epoch  17:   3% | abe: 8.980 | eve: 10.206 | bob: 8.936Epoch  17:   3% | abe: 8.979 | eve: 10.202 | bob: 8.935Epoch  17:   4% | abe: 8.984 | eve: 10.200 | bob: 8.941Epoch  17:   5% | abe: 8.985 | eve: 10.206 | bob: 8.942Epoch  17:   6% | abe: 8.990 | eve: 10.212 | bob: 8.947Epoch  17:   7% | abe: 8.993 | eve: 10.214 | bob: 8.950Epoch  17:   7% | abe: 8.995 | eve: 10.211 | bob: 8.952Epoch  17:   8% | abe: 8.994 | eve: 10.208 | bob: 8.951Epoch  17:   9% | abe: 8.992 | eve: 10.217 | bob: 8.949Epoch  17:  10% | abe: 8.992 | eve: 10.213 | bob: 8.950Epoch  17:  10% | abe: 8.998 | eve: 10.217 | bob: 8.956Epoch  17:  11% | abe: 8.997 | eve: 10.215 | bob: 8.955Epoch  17:  12% | abe: 8.993 | eve: 10.216 | bob: 8.951Epoch  17:  13% | abe: 8.992 | eve: 10.213 | bob: 8.950Epoch  17:  14% | abe: 8.991 | eve: 10.217 | bob: 8.949Epoch  17:  14% | abe: 8.991 | eve: 10.215 | bob: 8.949Epoch  17:  15% | abe: 8.992 | eve: 10.213 | bob: 8.950Epoch  17:  16% | abe: 8.992 | eve: 10.214 | bob: 8.950Epoch  17:  17% | abe: 8.995 | eve: 10.214 | bob: 8.952Epoch  17:  17% | abe: 8.995 | eve: 10.214 | bob: 8.953Epoch  17:  18% | abe: 8.997 | eve: 10.211 | bob: 8.955Epoch  17:  19% | abe: 8.998 | eve: 10.210 | bob: 8.956Epoch  17:  20% | abe: 8.997 | eve: 10.211 | bob: 8.955Epoch  17:  21% | abe: 8.997 | eve: 10.211 | bob: 8.955Epoch  17:  21% | abe: 8.998 | eve: 10.212 | bob: 8.956Epoch  17:  22% | abe: 8.998 | eve: 10.211 | bob: 8.956Epoch  17:  23% | abe: 8.998 | eve: 10.213 | bob: 8.957Epoch  17:  24% | abe: 8.997 | eve: 10.213 | bob: 8.956Epoch  17:  25% | abe: 8.997 | eve: 10.215 | bob: 8.955Epoch  17:  25% | abe: 8.996 | eve: 10.216 | bob: 8.954Epoch  17:  26% | abe: 8.995 | eve: 10.215 | bob: 8.953Epoch  17:  27% | abe: 8.996 | eve: 10.216 | bob: 8.954Epoch  17:  28% | abe: 8.995 | eve: 10.216 | bob: 8.953Epoch  17:  28% | abe: 8.995 | eve: 10.216 | bob: 8.953Epoch  17:  29% | abe: 8.994 | eve: 10.214 | bob: 8.952Epoch  17:  30% | abe: 8.994 | eve: 10.213 | bob: 8.953Epoch  17:  31% | abe: 8.995 | eve: 10.212 | bob: 8.953Epoch  17:  32% | abe: 8.995 | eve: 10.212 | bob: 8.954Epoch  17:  32% | abe: 8.996 | eve: 10.212 | bob: 8.954Epoch  17:  33% | abe: 8.997 | eve: 10.212 | bob: 8.955Epoch  17:  34% | abe: 8.997 | eve: 10.212 | bob: 8.955Epoch  17:  35% | abe: 8.997 | eve: 10.213 | bob: 8.956Epoch  17:  35% | abe: 8.998 | eve: 10.214 | bob: 8.956Epoch  17:  36% | abe: 8.999 | eve: 10.213 | bob: 8.958Epoch  17:  37% | abe: 8.999 | eve: 10.212 | bob: 8.958Epoch  17:  38% | abe: 8.999 | eve: 10.212 | bob: 8.958Epoch  17:  39% | abe: 9.000 | eve: 10.213 | bob: 8.958Epoch  17:  39% | abe: 8.999 | eve: 10.211 | bob: 8.958Epoch  17:  40% | abe: 8.998 | eve: 10.212 | bob: 8.957Epoch  17:  41% | abe: 8.998 | eve: 10.212 | bob: 8.957Epoch  17:  42% | abe: 8.997 | eve: 10.212 | bob: 8.956Epoch  17:  42% | abe: 8.997 | eve: 10.212 | bob: 8.955Epoch  17:  43% | abe: 8.996 | eve: 10.213 | bob: 8.955Epoch  17:  44% | abe: 8.997 | eve: 10.212 | bob: 8.955Epoch  17:  45% | abe: 8.997 | eve: 10.211 | bob: 8.955Epoch  17:  46% | abe: 8.997 | eve: 10.213 | bob: 8.956Epoch  17:  46% | abe: 8.997 | eve: 10.212 | bob: 8.956Epoch  17:  47% | abe: 8.997 | eve: 10.212 | bob: 8.956Epoch  17:  48% | abe: 8.997 | eve: 10.212 | bob: 8.956Epoch  17:  49% | abe: 8.997 | eve: 10.213 | bob: 8.956Epoch  17:  50% | abe: 8.997 | eve: 10.213 | bob: 8.956Epoch  17:  50% | abe: 8.996 | eve: 10.212 | bob: 8.954Epoch  17:  51% | abe: 8.995 | eve: 10.212 | bob: 8.954Epoch  17:  52% | abe: 8.995 | eve: 10.211 | bob: 8.954Epoch  17:  53% | abe: 8.996 | eve: 10.211 | bob: 8.955Epoch  17:  53% | abe: 8.996 | eve: 10.211 | bob: 8.955Epoch  17:  54% | abe: 8.997 | eve: 10.210 | bob: 8.955Epoch  17:  55% | abe: 8.997 | eve: 10.210 | bob: 8.956Epoch  17:  56% | abe: 8.997 | eve: 10.210 | bob: 8.955Epoch  17:  57% | abe: 8.998 | eve: 10.210 | bob: 8.956Epoch  17:  57% | abe: 8.997 | eve: 10.210 | bob: 8.956Epoch  17:  58% | abe: 8.998 | eve: 10.210 | bob: 8.957Epoch  17:  59% | abe: 8.998 | eve: 10.210 | bob: 8.957Epoch  17:  60% | abe: 8.998 | eve: 10.210 | bob: 8.957Epoch  17:  60% | abe: 8.998 | eve: 10.210 | bob: 8.957Epoch  17:  61% | abe: 8.998 | eve: 10.211 | bob: 8.957Epoch  17:  62% | abe: 8.998 | eve: 10.210 | bob: 8.957Epoch  17:  63% | abe: 8.998 | eve: 10.212 | bob: 8.957Epoch  17:  64% | abe: 8.998 | eve: 10.212 | bob: 8.957Epoch  17:  64% | abe: 8.998 | eve: 10.212 | bob: 8.957Epoch  17:  65% | abe: 8.998 | eve: 10.211 | bob: 8.957Epoch  17:  66% | abe: 8.998 | eve: 10.211 | bob: 8.957Epoch  17:  67% | abe: 8.998 | eve: 10.209 | bob: 8.957Epoch  17:  67% | abe: 8.998 | eve: 10.209 | bob: 8.956Epoch  17:  68% | abe: 8.998 | eve: 10.209 | bob: 8.957Epoch  17:  69% | abe: 8.998 | eve: 10.209 | bob: 8.957Epoch  17:  70% | abe: 8.998 | eve: 10.210 | bob: 8.957Epoch  17:  71% | abe: 8.998 | eve: 10.210 | bob: 8.957Epoch  17:  71% | abe: 8.998 | eve: 10.209 | bob: 8.957Epoch  17:  72% | abe: 8.998 | eve: 10.209 | bob: 8.957Epoch  17:  73% | abe: 8.998 | eve: 10.209 | bob: 8.957Epoch  17:  74% | abe: 8.999 | eve: 10.209 | bob: 8.958Epoch  17:  75% | abe: 8.999 | eve: 10.209 | bob: 8.957Epoch  17:  75% | abe: 8.998 | eve: 10.209 | bob: 8.957Epoch  17:  76% | abe: 8.998 | eve: 10.209 | bob: 8.957Epoch  17:  77% | abe: 8.999 | eve: 10.209 | bob: 8.958Epoch  17:  78% | abe: 8.999 | eve: 10.208 | bob: 8.958Epoch  17:  78% | abe: 8.999 | eve: 10.208 | bob: 8.958Epoch  17:  79% | abe: 8.999 | eve: 10.208 | bob: 8.958Epoch  17:  80% | abe: 8.999 | eve: 10.208 | bob: 8.958Epoch  17:  81% | abe: 8.999 | eve: 10.208 | bob: 8.958Epoch  17:  82% | abe: 8.998 | eve: 10.209 | bob: 8.957Epoch  17:  82% | abe: 8.998 | eve: 10.209 | bob: 8.957Epoch  17:  83% | abe: 8.998 | eve: 10.209 | bob: 8.957Epoch  17:  84% | abe: 8.997 | eve: 10.208 | bob: 8.956Epoch  17:  85% | abe: 8.998 | eve: 10.208 | bob: 8.957Epoch  17:  85% | abe: 8.998 | eve: 10.208 | bob: 8.957Epoch  17:  86% | abe: 8.998 | eve: 10.208 | bob: 8.957Epoch  17:  87% | abe: 8.997 | eve: 10.208 | bob: 8.956Epoch  17:  88% | abe: 8.997 | eve: 10.208 | bob: 8.956Epoch  17:  89% | abe: 8.997 | eve: 10.208 | bob: 8.956Epoch  17:  89% | abe: 8.997 | eve: 10.209 | bob: 8.956Epoch  17:  90% | abe: 8.997 | eve: 10.210 | bob: 8.956Epoch  17:  91% | abe: 8.997 | eve: 10.209 | bob: 8.956Epoch  17:  92% | abe: 8.997 | eve: 10.210 | bob: 8.956Epoch  17:  92% | abe: 8.997 | eve: 10.210 | bob: 8.957Epoch  17:  93% | abe: 8.997 | eve: 10.210 | bob: 8.956Epoch  17:  94% | abe: 8.996 | eve: 10.210 | bob: 8.955Epoch  17:  95% | abe: 8.996 | eve: 10.210 | bob: 8.955Epoch  17:  96% | abe: 8.996 | eve: 10.210 | bob: 8.955Epoch  17:  96% | abe: 8.996 | eve: 10.210 | bob: 8.955Epoch  17:  97% | abe: 8.997 | eve: 10.210 | bob: 8.956Epoch  17:  98% | abe: 8.997 | eve: 10.209 | bob: 8.956Epoch  17:  99% | abe: 8.997 | eve: 10.209 | bob: 8.956Epoch  18:   0% | abe: 8.998 | eve: 10.236 | bob: 8.960Epoch  18:   0% | abe: 9.028 | eve: 10.185 | bob: 8.991Epoch  18:   1% | abe: 9.029 | eve: 10.198 | bob: 8.992Epoch  18:   2% | abe: 9.015 | eve: 10.206 | bob: 8.977Epoch  18:   3% | abe: 9.010 | eve: 10.198 | bob: 8.972Epoch  18:   3% | abe: 9.009 | eve: 10.203 | bob: 8.971Epoch  18:   4% | abe: 9.010 | eve: 10.200 | bob: 8.971Epoch  18:   5% | abe: 9.004 | eve: 10.211 | bob: 8.966Epoch  18:   6% | abe: 9.010 | eve: 10.207 | bob: 8.972Epoch  18:   7% | abe: 9.005 | eve: 10.199 | bob: 8.966Epoch  18:   7% | abe: 9.001 | eve: 10.195 | bob: 8.962Epoch  18:   8% | abe: 8.999 | eve: 10.199 | bob: 8.961Epoch  18:   9% | abe: 8.995 | eve: 10.198 | bob: 8.957Epoch  18:  10% | abe: 8.994 | eve: 10.200 | bob: 8.955Epoch  18:  10% | abe: 8.996 | eve: 10.201 | bob: 8.958Epoch  18:  11% | abe: 8.998 | eve: 10.204 | bob: 8.959Epoch  18:  12% | abe: 8.994 | eve: 10.203 | bob: 8.956Epoch  18:  13% | abe: 8.996 | eve: 10.203 | bob: 8.957Epoch  18:  14% | abe: 8.995 | eve: 10.202 | bob: 8.957Epoch  18:  14% | abe: 8.992 | eve: 10.202 | bob: 8.953Epoch  18:  15% | abe: 8.991 | eve: 10.200 | bob: 8.953Epoch  18:  16% | abe: 8.991 | eve: 10.204 | bob: 8.952Epoch  18:  17% | abe: 8.989 | eve: 10.204 | bob: 8.950Epoch  18:  17% | abe: 8.988 | eve: 10.199 | bob: 8.949Epoch  18:  18% | abe: 8.988 | eve: 10.199 | bob: 8.949Epoch  18:  19% | abe: 8.989 | eve: 10.199 | bob: 8.950Epoch  18:  20% | abe: 8.987 | eve: 10.197 | bob: 8.948Epoch  18:  21% | abe: 8.986 | eve: 10.199 | bob: 8.947Epoch  18:  21% | abe: 8.985 | eve: 10.198 | bob: 8.946Epoch  18:  22% | abe: 8.985 | eve: 10.197 | bob: 8.946Epoch  18:  23% | abe: 8.985 | eve: 10.195 | bob: 8.946Epoch  18:  24% | abe: 8.985 | eve: 10.196 | bob: 8.946Epoch  18:  25% | abe: 8.984 | eve: 10.194 | bob: 8.945Epoch  18:  25% | abe: 8.984 | eve: 10.192 | bob: 8.945Epoch  18:  26% | abe: 8.985 | eve: 10.193 | bob: 8.945Epoch  18:  27% | abe: 8.984 | eve: 10.194 | bob: 8.944Epoch  18:  28% | abe: 8.983 | eve: 10.193 | bob: 8.944Epoch  18:  28% | abe: 8.983 | eve: 10.192 | bob: 8.943Epoch  18:  29% | abe: 8.983 | eve: 10.192 | bob: 8.943Epoch  18:  30% | abe: 8.982 | eve: 10.191 | bob: 8.943Epoch  18:  31% | abe: 8.982 | eve: 10.190 | bob: 8.943Epoch  18:  32% | abe: 8.982 | eve: 10.189 | bob: 8.943Epoch  18:  32% | abe: 8.983 | eve: 10.190 | bob: 8.944Epoch  18:  33% | abe: 8.983 | eve: 10.190 | bob: 8.944Epoch  18:  34% | abe: 8.983 | eve: 10.189 | bob: 8.944Epoch  18:  35% | abe: 8.983 | eve: 10.189 | bob: 8.943Epoch  18:  35% | abe: 8.982 | eve: 10.190 | bob: 8.943Epoch  18:  36% | abe: 8.982 | eve: 10.189 | bob: 8.942Epoch  18:  37% | abe: 8.981 | eve: 10.189 | bob: 8.941Epoch  18:  38% | abe: 8.980 | eve: 10.190 | bob: 8.941Epoch  18:  39% | abe: 8.980 | eve: 10.190 | bob: 8.940Epoch  18:  39% | abe: 8.980 | eve: 10.189 | bob: 8.940Epoch  18:  40% | abe: 8.980 | eve: 10.189 | bob: 8.941Epoch  18:  41% | abe: 8.980 | eve: 10.189 | bob: 8.941Epoch  18:  42% | abe: 8.980 | eve: 10.189 | bob: 8.940Epoch  18:  42% | abe: 8.981 | eve: 10.189 | bob: 8.941Epoch  18:  43% | abe: 8.981 | eve: 10.190 | bob: 8.942Epoch  18:  44% | abe: 8.982 | eve: 10.190 | bob: 8.943Epoch  18:  45% | abe: 8.982 | eve: 10.191 | bob: 8.942Epoch  18:  46% | abe: 8.982 | eve: 10.192 | bob: 8.942Epoch  18:  46% | abe: 8.981 | eve: 10.193 | bob: 8.941Epoch  18:  47% | abe: 8.979 | eve: 10.192 | bob: 8.940Epoch  18:  48% | abe: 8.980 | eve: 10.193 | bob: 8.940Epoch  18:  49% | abe: 8.980 | eve: 10.193 | bob: 8.940Epoch  18:  50% | abe: 8.980 | eve: 10.192 | bob: 8.940Epoch  18:  50% | abe: 8.980 | eve: 10.193 | bob: 8.940Epoch  18:  51% | abe: 8.979 | eve: 10.194 | bob: 8.940Epoch  18:  52% | abe: 8.979 | eve: 10.195 | bob: 8.940Epoch  18:  53% | abe: 8.979 | eve: 10.196 | bob: 8.940Epoch  18:  53% | abe: 8.980 | eve: 10.196 | bob: 8.940Epoch  18:  54% | abe: 8.981 | eve: 10.196 | bob: 8.942Epoch  18:  55% | abe: 8.982 | eve: 10.196 | bob: 8.943Epoch  18:  56% | abe: 8.982 | eve: 10.197 | bob: 8.943Epoch  18:  57% | abe: 8.983 | eve: 10.196 | bob: 8.943Epoch  18:  57% | abe: 8.983 | eve: 10.195 | bob: 8.944Epoch  18:  58% | abe: 8.984 | eve: 10.195 | bob: 8.944Epoch  18:  59% | abe: 8.984 | eve: 10.194 | bob: 8.944Epoch  18:  60% | abe: 8.983 | eve: 10.194 | bob: 8.944Epoch  18:  60% | abe: 8.984 | eve: 10.194 | bob: 8.944Epoch  18:  61% | abe: 8.984 | eve: 10.195 | bob: 8.945Epoch  18:  62% | abe: 8.984 | eve: 10.197 | bob: 8.945Epoch  18:  63% | abe: 8.984 | eve: 10.196 | bob: 8.944Epoch  18:  64% | abe: 8.983 | eve: 10.196 | bob: 8.944Epoch  18:  64% | abe: 8.983 | eve: 10.197 | bob: 8.944Epoch  18:  65% | abe: 8.984 | eve: 10.198 | bob: 8.944Epoch  18:  66% | abe: 8.983 | eve: 10.198 | bob: 8.944Epoch  18:  67% | abe: 8.983 | eve: 10.197 | bob: 8.944Epoch  18:  67% | abe: 8.983 | eve: 10.197 | bob: 8.944Epoch  18:  68% | abe: 8.984 | eve: 10.197 | bob: 8.944Epoch  18:  69% | abe: 8.983 | eve: 10.198 | bob: 8.944Epoch  18:  70% | abe: 8.983 | eve: 10.198 | bob: 8.944Epoch  18:  71% | abe: 8.983 | eve: 10.199 | bob: 8.944Epoch  18:  71% | abe: 8.984 | eve: 10.198 | bob: 8.944Epoch  18:  72% | abe: 8.983 | eve: 10.198 | bob: 8.944Epoch  18:  73% | abe: 8.984 | eve: 10.198 | bob: 8.944Epoch  18:  74% | abe: 8.983 | eve: 10.198 | bob: 8.944Epoch  18:  75% | abe: 8.984 | eve: 10.198 | bob: 8.945Epoch  18:  75% | abe: 8.984 | eve: 10.198 | bob: 8.945Epoch  18:  76% | abe: 8.984 | eve: 10.197 | bob: 8.945Epoch  18:  77% | abe: 8.984 | eve: 10.198 | bob: 8.945Epoch  18:  78% | abe: 8.985 | eve: 10.197 | bob: 8.945Epoch  18:  78% | abe: 8.985 | eve: 10.197 | bob: 8.946Epoch  18:  79% | abe: 8.984 | eve: 10.197 | bob: 8.945Epoch  18:  80% | abe: 8.984 | eve: 10.197 | bob: 8.945Epoch  18:  81% | abe: 8.984 | eve: 10.197 | bob: 8.945Epoch  18:  82% | abe: 8.984 | eve: 10.197 | bob: 8.945Epoch  18:  82% | abe: 8.984 | eve: 10.198 | bob: 8.945Epoch  18:  83% | abe: 8.984 | eve: 10.198 | bob: 8.945Epoch  18:  84% | abe: 8.984 | eve: 10.197 | bob: 8.945Epoch  18:  85% | abe: 8.984 | eve: 10.198 | bob: 8.945Epoch  18:  85% | abe: 8.983 | eve: 10.199 | bob: 8.944Epoch  18:  86% | abe: 8.983 | eve: 10.199 | bob: 8.944Epoch  18:  87% | abe: 8.983 | eve: 10.199 | bob: 8.944Epoch  18:  88% | abe: 8.983 | eve: 10.199 | bob: 8.944Epoch  18:  89% | abe: 8.983 | eve: 10.198 | bob: 8.944Epoch  18:  89% | abe: 8.983 | eve: 10.198 | bob: 8.944Epoch  18:  90% | abe: 8.983 | eve: 10.198 | bob: 8.944Epoch  18:  91% | abe: 8.984 | eve: 10.198 | bob: 8.945Epoch  18:  92% | abe: 8.984 | eve: 10.198 | bob: 8.945Epoch  18:  92% | abe: 8.984 | eve: 10.198 | bob: 8.945Epoch  18:  93% | abe: 8.984 | eve: 10.199 | bob: 8.945Epoch  18:  94% | abe: 8.984 | eve: 10.199 | bob: 8.945Epoch  18:  95% | abe: 8.984 | eve: 10.199 | bob: 8.945Epoch  18:  96% | abe: 8.984 | eve: 10.200 | bob: 8.945Epoch  18:  96% | abe: 8.984 | eve: 10.199 | bob: 8.945Epoch  18:  97% | abe: 8.984 | eve: 10.200 | bob: 8.945Epoch  18:  98% | abe: 8.984 | eve: 10.200 | bob: 8.945Epoch  18:  99% | abe: 8.984 | eve: 10.200 | bob: 8.945
New best Bob loss 8.94519865446955 at epoch 18
Epoch  19:   0% | abe: 8.956 | eve: 10.148 | bob: 8.916Epoch  19:   0% | abe: 8.969 | eve: 10.194 | bob: 8.931Epoch  19:   1% | abe: 8.983 | eve: 10.201 | bob: 8.945Epoch  19:   2% | abe: 8.997 | eve: 10.210 | bob: 8.959Epoch  19:   3% | abe: 8.991 | eve: 10.200 | bob: 8.953Epoch  19:   3% | abe: 8.990 | eve: 10.211 | bob: 8.952Epoch  19:   4% | abe: 8.984 | eve: 10.208 | bob: 8.946Epoch  19:   5% | abe: 8.978 | eve: 10.216 | bob: 8.939Epoch  19:   6% | abe: 8.979 | eve: 10.215 | bob: 8.941Epoch  19:   7% | abe: 8.977 | eve: 10.214 | bob: 8.939Epoch  19:   7% | abe: 8.971 | eve: 10.210 | bob: 8.933Epoch  19:   8% | abe: 8.974 | eve: 10.213 | bob: 8.935Epoch  19:   9% | abe: 8.978 | eve: 10.214 | bob: 8.939Epoch  19:  10% | abe: 8.977 | eve: 10.213 | bob: 8.938Epoch  19:  10% | abe: 8.976 | eve: 10.210 | bob: 8.938Epoch  19:  11% | abe: 8.979 | eve: 10.210 | bob: 8.941Epoch  19:  12% | abe: 8.980 | eve: 10.210 | bob: 8.942Epoch  19:  13% | abe: 8.985 | eve: 10.213 | bob: 8.947Epoch  19:  14% | abe: 8.985 | eve: 10.213 | bob: 8.947Epoch  19:  14% | abe: 8.983 | eve: 10.208 | bob: 8.946Epoch  19:  15% | abe: 8.982 | eve: 10.206 | bob: 8.944Epoch  19:  16% | abe: 8.982 | eve: 10.210 | bob: 8.944Epoch  19:  17% | abe: 8.982 | eve: 10.210 | bob: 8.944Epoch  19:  17% | abe: 8.980 | eve: 10.209 | bob: 8.942Epoch  19:  18% | abe: 8.980 | eve: 10.212 | bob: 8.942Epoch  19:  19% | abe: 8.980 | eve: 10.211 | bob: 8.942Epoch  19:  20% | abe: 8.981 | eve: 10.210 | bob: 8.943Epoch  19:  21% | abe: 8.979 | eve: 10.208 | bob: 8.941Epoch  19:  21% | abe: 8.978 | eve: 10.208 | bob: 8.940Epoch  19:  22% | abe: 8.977 | eve: 10.209 | bob: 8.940Epoch  19:  23% | abe: 8.977 | eve: 10.211 | bob: 8.940Epoch  19:  24% | abe: 8.978 | eve: 10.211 | bob: 8.940Epoch  19:  25% | abe: 8.978 | eve: 10.211 | bob: 8.940Epoch  19:  25% | abe: 8.977 | eve: 10.211 | bob: 8.939Epoch  19:  26% | abe: 8.975 | eve: 10.211 | bob: 8.937Epoch  19:  27% | abe: 8.976 | eve: 10.211 | bob: 8.938Epoch  19:  28% | abe: 8.977 | eve: 10.210 | bob: 8.939Epoch  19:  28% | abe: 8.978 | eve: 10.211 | bob: 8.939Epoch  19:  29% | abe: 8.978 | eve: 10.211 | bob: 8.940Epoch  19:  30% | abe: 8.977 | eve: 10.210 | bob: 8.939Epoch  19:  31% | abe: 8.978 | eve: 10.208 | bob: 8.940Epoch  19:  32% | abe: 8.979 | eve: 10.208 | bob: 8.941Epoch  19:  32% | abe: 8.978 | eve: 10.209 | bob: 8.940Epoch  19:  33% | abe: 8.979 | eve: 10.208 | bob: 8.941Epoch  19:  34% | abe: 8.978 | eve: 10.208 | bob: 8.940Epoch  19:  35% | abe: 8.977 | eve: 10.207 | bob: 8.939Epoch  19:  35% | abe: 8.977 | eve: 10.208 | bob: 8.939Epoch  19:  36% | abe: 8.977 | eve: 10.206 | bob: 8.939Epoch  19:  37% | abe: 8.977 | eve: 10.205 | bob: 8.939Epoch  19:  38% | abe: 8.976 | eve: 10.207 | bob: 8.938Epoch  19:  39% | abe: 8.976 | eve: 10.206 | bob: 8.938Epoch  19:  39% | abe: 8.976 | eve: 10.207 | bob: 8.938Epoch  19:  40% | abe: 8.975 | eve: 10.208 | bob: 8.937Epoch  19:  41% | abe: 8.975 | eve: 10.209 | bob: 8.937Epoch  19:  42% | abe: 8.974 | eve: 10.208 | bob: 8.936Epoch  19:  42% | abe: 8.974 | eve: 10.208 | bob: 8.936Epoch  19:  43% | abe: 8.973 | eve: 10.208 | bob: 8.935Epoch  19:  44% | abe: 8.974 | eve: 10.207 | bob: 8.936Epoch  19:  45% | abe: 8.973 | eve: 10.206 | bob: 8.935Epoch  19:  46% | abe: 8.973 | eve: 10.206 | bob: 8.935Epoch  19:  46% | abe: 8.974 | eve: 10.205 | bob: 8.936Epoch  19:  47% | abe: 8.974 | eve: 10.205 | bob: 8.936Epoch  19:  48% | abe: 8.974 | eve: 10.203 | bob: 8.936Epoch  19:  49% | abe: 8.974 | eve: 10.203 | bob: 8.936Epoch  19:  50% | abe: 8.974 | eve: 10.203 | bob: 8.936Epoch  19:  50% | abe: 8.974 | eve: 10.201 | bob: 8.936Epoch  19:  51% | abe: 8.974 | eve: 10.201 | bob: 8.936Epoch  19:  52% | abe: 8.975 | eve: 10.202 | bob: 8.937Epoch  19:  53% | abe: 8.975 | eve: 10.202 | bob: 8.937Epoch  19:  53% | abe: 8.974 | eve: 10.203 | bob: 8.936Epoch  19:  54% | abe: 8.974 | eve: 10.203 | bob: 8.936Epoch  19:  55% | abe: 8.973 | eve: 10.203 | bob: 8.936Epoch  19:  56% | abe: 8.973 | eve: 10.202 | bob: 8.935Epoch  19:  57% | abe: 8.973 | eve: 10.203 | bob: 8.935Epoch  19:  57% | abe: 8.973 | eve: 10.204 | bob: 8.935Epoch  19:  58% | abe: 8.973 | eve: 10.205 | bob: 8.935Epoch  19:  59% | abe: 8.973 | eve: 10.204 | bob: 8.935Epoch  19:  60% | abe: 8.974 | eve: 10.204 | bob: 8.936Epoch  19:  60% | abe: 8.974 | eve: 10.205 | bob: 8.936Epoch  19:  61% | abe: 8.973 | eve: 10.205 | bob: 8.936Epoch  19:  62% | abe: 8.973 | eve: 10.204 | bob: 8.936Epoch  19:  63% | abe: 8.974 | eve: 10.205 | bob: 8.936Epoch  19:  64% | abe: 8.974 | eve: 10.205 | bob: 8.936Epoch  19:  64% | abe: 8.974 | eve: 10.205 | bob: 8.936Epoch  19:  65% | abe: 8.974 | eve: 10.206 | bob: 8.936Epoch  19:  66% | abe: 8.974 | eve: 10.206 | bob: 8.936Epoch  19:  67% | abe: 8.974 | eve: 10.206 | bob: 8.936Epoch  19:  67% | abe: 8.974 | eve: 10.206 | bob: 8.936Epoch  19:  68% | abe: 8.974 | eve: 10.206 | bob: 8.936Epoch  19:  69% | abe: 8.974 | eve: 10.207 | bob: 8.936Epoch  19:  70% | abe: 8.974 | eve: 10.207 | bob: 8.936Epoch  19:  71% | abe: 8.974 | eve: 10.207 | bob: 8.937Epoch  19:  71% | abe: 8.974 | eve: 10.206 | bob: 8.936Epoch  19:  72% | abe: 8.973 | eve: 10.205 | bob: 8.936Epoch  19:  73% | abe: 8.974 | eve: 10.206 | bob: 8.936Epoch  19:  74% | abe: 8.974 | eve: 10.207 | bob: 8.936Epoch  19:  75% | abe: 8.974 | eve: 10.207 | bob: 8.936Epoch  19:  75% | abe: 8.974 | eve: 10.206 | bob: 8.937Epoch  19:  76% | abe: 8.975 | eve: 10.206 | bob: 8.937Epoch  19:  77% | abe: 8.974 | eve: 10.206 | bob: 8.937Epoch  19:  78% | abe: 8.974 | eve: 10.206 | bob: 8.937Epoch  19:  78% | abe: 8.974 | eve: 10.206 | bob: 8.937Epoch  19:  79% | abe: 8.974 | eve: 10.205 | bob: 8.937Epoch  19:  80% | abe: 8.974 | eve: 10.205 | bob: 8.937Epoch  19:  81% | abe: 8.975 | eve: 10.206 | bob: 8.937Epoch  19:  82% | abe: 8.975 | eve: 10.206 | bob: 8.937Epoch  19:  82% | abe: 8.975 | eve: 10.206 | bob: 8.937Epoch  19:  83% | abe: 8.974 | eve: 10.207 | bob: 8.937Epoch  19:  84% | abe: 8.975 | eve: 10.207 | bob: 8.937Epoch  19:  85% | abe: 8.975 | eve: 10.206 | bob: 8.937Epoch  19:  85% | abe: 8.975 | eve: 10.207 | bob: 8.937Epoch  19:  86% | abe: 8.975 | eve: 10.207 | bob: 8.937Epoch  19:  87% | abe: 8.975 | eve: 10.207 | bob: 8.937Epoch  19:  88% | abe: 8.975 | eve: 10.206 | bob: 8.937Epoch  19:  89% | abe: 8.975 | eve: 10.206 | bob: 8.937Epoch  19:  89% | abe: 8.975 | eve: 10.206 | bob: 8.937Epoch  19:  90% | abe: 8.975 | eve: 10.205 | bob: 8.937Epoch  19:  91% | abe: 8.975 | eve: 10.205 | bob: 8.937Epoch  19:  92% | abe: 8.975 | eve: 10.205 | bob: 8.938Epoch  19:  92% | abe: 8.975 | eve: 10.204 | bob: 8.937Epoch  19:  93% | abe: 8.975 | eve: 10.205 | bob: 8.938Epoch  19:  94% | abe: 8.975 | eve: 10.205 | bob: 8.937Epoch  19:  95% | abe: 8.975 | eve: 10.205 | bob: 8.937Epoch  19:  96% | abe: 8.975 | eve: 10.205 | bob: 8.937Epoch  19:  96% | abe: 8.975 | eve: 10.204 | bob: 8.938Epoch  19:  97% | abe: 8.976 | eve: 10.204 | bob: 8.938Epoch  19:  98% | abe: 8.976 | eve: 10.204 | bob: 8.938Epoch  19:  99% | abe: 8.976 | eve: 10.204 | bob: 8.939
New best Bob loss 8.938605588911742 at epoch 19
Epoch  20:   0% | abe: 8.970 | eve: 10.189 | bob: 8.933Epoch  20:   0% | abe: 8.961 | eve: 10.178 | bob: 8.925Epoch  20:   1% | abe: 8.968 | eve: 10.206 | bob: 8.932Epoch  20:   2% | abe: 8.984 | eve: 10.208 | bob: 8.949Epoch  20:   3% | abe: 8.983 | eve: 10.214 | bob: 8.947Epoch  20:   3% | abe: 8.980 | eve: 10.210 | bob: 8.945Epoch  20:   4% | abe: 8.985 | eve: 10.213 | bob: 8.950Epoch  20:   5% | abe: 8.981 | eve: 10.201 | bob: 8.947Epoch  20:   6% | abe: 8.977 | eve: 10.203 | bob: 8.942Epoch  20:   7% | abe: 8.982 | eve: 10.200 | bob: 8.947Epoch  20:   7% | abe: 8.978 | eve: 10.200 | bob: 8.943Epoch  20:   8% | abe: 8.982 | eve: 10.196 | bob: 8.947Epoch  20:   9% | abe: 8.983 | eve: 10.198 | bob: 8.948Epoch  20:  10% | abe: 8.983 | eve: 10.195 | bob: 8.948Epoch  20:  10% | abe: 8.984 | eve: 10.190 | bob: 8.949Epoch  20:  11% | abe: 8.983 | eve: 10.193 | bob: 8.948Epoch  20:  12% | abe: 8.980 | eve: 10.197 | bob: 8.945Epoch  20:  13% | abe: 8.980 | eve: 10.199 | bob: 8.945Epoch  20:  14% | abe: 8.979 | eve: 10.199 | bob: 8.944Epoch  20:  14% | abe: 8.980 | eve: 10.201 | bob: 8.945Epoch  20:  15% | abe: 8.978 | eve: 10.202 | bob: 8.943Epoch  20:  16% | abe: 8.977 | eve: 10.204 | bob: 8.942Epoch  20:  17% | abe: 8.979 | eve: 10.201 | bob: 8.944Epoch  20:  17% | abe: 8.980 | eve: 10.203 | bob: 8.945Epoch  20:  18% | abe: 8.978 | eve: 10.203 | bob: 8.943Epoch  20:  19% | abe: 8.978 | eve: 10.203 | bob: 8.943Epoch  20:  20% | abe: 8.978 | eve: 10.201 | bob: 8.943Epoch  20:  21% | abe: 8.978 | eve: 10.202 | bob: 8.943Epoch  20:  21% | abe: 8.976 | eve: 10.202 | bob: 8.941Epoch  20:  22% | abe: 8.975 | eve: 10.202 | bob: 8.939Epoch  20:  23% | abe: 8.975 | eve: 10.202 | bob: 8.940Epoch  20:  24% | abe: 8.975 | eve: 10.202 | bob: 8.940Epoch  20:  25% | abe: 8.974 | eve: 10.200 | bob: 8.939Epoch  20:  25% | abe: 8.974 | eve: 10.202 | bob: 8.939Epoch  20:  26% | abe: 8.972 | eve: 10.201 | bob: 8.937Epoch  20:  27% | abe: 8.973 | eve: 10.200 | bob: 8.937Epoch  20:  28% | abe: 8.973 | eve: 10.202 | bob: 8.937Epoch  20:  28% | abe: 8.972 | eve: 10.202 | bob: 8.937