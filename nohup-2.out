WARNING:tensorflow:From /home/stud/minawoi/miniconda3/envs/conda-venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2024-04-07 22:03:11.447417: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-04-07 22:03:11.630949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:8a:00.0
2024-04-07 22:03:11.631976: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-07 22:03:11.634645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-04-07 22:03:11.636871: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-04-07 22:03:11.637829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-04-07 22:03:11.640545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-04-07 22:03:11.642724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-04-07 22:03:11.648635: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-04-07 22:03:11.657695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-04-07 22:03:11.658312: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2024-04-07 22:03:11.674752: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199835000 Hz
2024-04-07 22:03:11.678102: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4b0f570 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-04-07 22:03:11.678181: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-04-07 22:03:12.034099: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3bcad00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-04-07 22:03:12.034222: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-04-07 22:03:12.039236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:8a:00.0
2024-04-07 22:03:12.039382: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-07 22:03:12.039421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-04-07 22:03:12.039453: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-04-07 22:03:12.039500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-04-07 22:03:12.039532: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-04-07 22:03:12.039566: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-04-07 22:03:12.039602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-04-07 22:03:12.048542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-04-07 22:03:12.048669: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-07 22:03:12.055067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-04-07 22:03:12.055129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-04-07 22:03:12.055138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2024-04-07 22:03:12.059792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30593 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0)
WARNING:tensorflow:Output bob missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to bob.
WARNING:tensorflow:Output bob_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to bob_1.
WARNING:tensorflow:Output eve missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to eve.
WARNING:tensorflow:Output eve_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to eve_1.
2024-04-07 22:03:16.641285: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
Train on 512 samples, validate on 512 samples
Epoch 1/512
512/512 - 1s - loss: 0.5840 - val_loss: 0.0019
Epoch 2/512
512/512 - 0s - loss: 0.0995 - val_loss: 1.7498e-04
Epoch 3/512
512/512 - 0s - loss: 0.0085 - val_loss: 1.4585e-05
Epoch 4/512
512/512 - 0s - loss: 8.8833e-04 - val_loss: 4.5761e-06
Epoch 5/512
512/512 - 0s - loss: 4.0251e-04 - val_loss: 3.2845e-06
Epoch 6/512
512/512 - 0s - loss: 2.9138e-04 - val_loss: 2.3233e-06
Epoch 7/512
512/512 - 0s - loss: 2.0061e-04 - val_loss: 1.5131e-06
Epoch 8/512
512/512 - 0s - loss: 1.2634e-04 - val_loss: 8.8803e-07
Epoch 9/512
512/512 - 0s - loss: 7.1180e-05 - val_loss: 4.5749e-07
Epoch 10/512
512/512 - 0s - loss: 3.4890e-05 - val_loss: 1.9995e-07
Epoch 11/512
512/512 - 0s - loss: 1.4359e-05 - val_loss: 7.0988e-08
Epoch 12/512
512/512 - 0s - loss: 4.7435e-06 - val_loss: 1.9373e-08
Epoch 13/512
512/512 - 0s - loss: 1.1912e-06 - val_loss: 4.0292e-09
Epoch 14/512
512/512 - 0s - loss: 6.2866e-07 - val_loss: 6.5597e-08
Epoch 15/512
512/512 - 0s - loss: 5.0890e-04 - val_loss: 7.1311e-05
Epoch 16/512
512/512 - 0s - loss: 0.0045 - val_loss: 3.9820e-06
Epoch 17/512
512/512 - 0s - loss: 1.8901e-04 - val_loss: 6.9810e-07
Epoch 18/512
512/512 - 0s - loss: 1.0118e-04 - val_loss: 2.9010e-06
Epoch 19/512
512/512 - 0s - loss: 0.0011 - val_loss: 3.4996e-05
Epoch 20/512
512/512 - 0s - loss: 0.0024 - val_loss: 7.8034e-06
Epoch 21/512
512/512 - 0s - loss: 5.2168e-04 - val_loss: 4.0841e-06
Epoch 22/512
512/512 - 0s - loss: 6.0137e-04 - val_loss: 1.3137e-05
Epoch 23/512
512/512 - 0s - loss: 0.0017 - val_loss: 1.6220e-05
Epoch 24/512
512/512 - 0s - loss: 0.0011 - val_loss: 7.1528e-06
Epoch 25/512
512/512 - 0s - loss: 7.0630e-04 - val_loss: 9.2022e-06
Epoch 26/512
512/512 - 0s - loss: 0.0012 - val_loss: 1.4790e-05
Epoch 27/512
512/512 - 0s - loss: 0.0013 - val_loss: 1.0140e-05
Epoch 28/512
512/512 - 0s - loss: 8.9297e-04 - val_loss: 8.9467e-06
Epoch 29/512
512/512 - 0s - loss: 9.7737e-04 - val_loss: 1.1829e-05
Epoch 30/512
512/512 - 0s - loss: 0.0012 - val_loss: 1.1343e-05
Epoch 31/512
512/512 - 0s - loss: 0.0010 - val_loss: 9.5794e-06
Epoch 32/512
512/512 - 0s - loss: 9.4900e-04 - val_loss: 1.0441e-05
Epoch 33/512
512/512 - 0s - loss: 0.0011 - val_loss: 1.1030e-05
Epoch 34/512
512/512 - 0s - loss: 0.0010 - val_loss: 9.9132e-06
Epoch 35/512
512/512 - 0s - loss: 9.6050e-04 - val_loss: 9.9033e-06
Epoch 36/512
512/512 - 0s - loss: 9.9559e-04 - val_loss: 1.0410e-05
Epoch 37/512
512/512 - 0s - loss: 0.0010 - val_loss: 1.0058e-05
Epoch 38/512
512/512 - 0s - loss: 9.6091e-04 - val_loss: 9.9593e-06
Epoch 39/512
512/512 - 0s - loss: 9.8973e-04 - val_loss: 9.8622e-06
Epoch 40/512
512/512 - 0s - loss: 9.5876e-04 - val_loss: 9.8148e-06
Epoch 41/512
512/512 - 0s - loss: 9.6687e-04 - val_loss: 9.8243e-06
Epoch 42/512
512/512 - 0s - loss: 9.5638e-04 - val_loss: 9.8402e-06
Epoch 43/512
512/512 - 0s - loss: 9.5758e-04 - val_loss: 9.6819e-06
Epoch 44/512
512/512 - 0s - loss: 9.4131e-04 - val_loss: 9.5829e-06
Epoch 45/512
512/512 - 0s - loss: 9.3931e-04 - val_loss: 9.5779e-06
Epoch 46/512
512/512 - 0s - loss: 9.4347e-04 - val_loss: 9.4683e-06
Epoch 47/512
512/512 - 0s - loss: 9.2300e-04 - val_loss: 9.4111e-06
Epoch 48/512
512/512 - 0s - loss: 9.2617e-04 - val_loss: 9.5073e-06
Epoch 49/512
512/512 - 0s - loss: 9.3182e-04 - val_loss: 9.3091e-06
Epoch 50/512
512/512 - 0s - loss: 9.0416e-04 - val_loss: 9.2424e-06
Epoch 51/512
512/512 - 0s - loss: 9.0877e-04 - val_loss: 9.5143e-06
Epoch 52/512
512/512 - 0s - loss: 9.2537e-04 - val_loss: 9.2609e-06
Epoch 53/512
512/512 - 0s - loss: 8.9756e-04 - val_loss: 9.0901e-06
Epoch 54/512
512/512 - 0s - loss: 8.9386e-04 - val_loss: 9.1521e-06
Epoch 55/512
512/512 - 0s - loss: 8.9282e-04 - val_loss: 9.3593e-06
Epoch 56/512
512/512 - 0s - loss: 9.0537e-04 - val_loss: 9.1909e-06
Epoch 57/512
512/512 - 0s - loss: 8.8980e-04 - val_loss: 8.8919e-06
Epoch 58/512
512/512 - 0s - loss: 8.7170e-04 - val_loss: 9.0331e-06
Epoch 59/512
512/512 - 0s - loss: 8.9257e-04 - val_loss: 9.0369e-06
Epoch 60/512
512/512 - 0s - loss: 8.7608e-04 - val_loss: 8.9207e-06
Epoch 61/512
512/512 - 0s - loss: 8.7358e-04 - val_loss: 8.9648e-06
Epoch 62/512
512/512 - 0s - loss: 8.7666e-04 - val_loss: 8.8272e-06
Epoch 63/512
512/512 - 0s - loss: 8.6673e-04 - val_loss: 8.7947e-06
Epoch 64/512
512/512 - 0s - loss: 8.6691e-04 - val_loss: 8.7803e-06
Epoch 65/512
512/512 - 0s - loss: 8.6265e-04 - val_loss: 8.7975e-06
Epoch 66/512
512/512 - 0s - loss: 8.5906e-04 - val_loss: 8.8282e-06
Epoch 67/512
512/512 - 0s - loss: 8.6430e-04 - val_loss: 8.7392e-06
Epoch 68/512
512/512 - 0s - loss: 8.5553e-04 - val_loss: 8.6215e-06
Epoch 69/512
512/512 - 0s - loss: 8.4903e-04 - val_loss: 8.6561e-06
Epoch 70/512
512/512 - 0s - loss: 8.5192e-04 - val_loss: 8.7446e-06
Epoch 71/512
512/512 - 0s - loss: 8.5825e-04 - val_loss: 8.5068e-06
Epoch 72/512
512/512 - 0s - loss: 8.3470e-04 - val_loss: 8.5411e-06
Epoch 73/512
512/512 - 0s - loss: 8.4034e-04 - val_loss: 8.7582e-06
Epoch 74/512
512/512 - 0s - loss: 8.6535e-04 - val_loss: 8.3842e-06
Epoch 75/512
512/512 - 0s - loss: 8.2076e-04 - val_loss: 8.3685e-06
Epoch 76/512
512/512 - 0s - loss: 8.3287e-04 - val_loss: 8.6846e-06
Epoch 77/512
512/512 - 0s - loss: 8.5233e-04 - val_loss: 8.5755e-06
Epoch 78/512
512/512 - 0s - loss: 8.3868e-04 - val_loss: 8.2057e-06
Epoch 79/512
512/512 - 0s - loss: 8.1456e-04 - val_loss: 8.3305e-06
Epoch 80/512
512/512 - 0s - loss: 8.2912e-04 - val_loss: 8.7549e-06
Epoch 81/512
512/512 - 0s - loss: 8.5115e-04 - val_loss: 8.4737e-06
Epoch 82/512
512/512 - 0s - loss: 8.1917e-04 - val_loss: 8.2150e-06
Epoch 83/512
512/512 - 0s - loss: 8.1721e-04 - val_loss: 8.3869e-06
Epoch 84/512
512/512 - 0s - loss: 8.2730e-04 - val_loss: 8.5425e-06
Epoch 85/512
512/512 - 0s - loss: 8.3682e-04 - val_loss: 8.2983e-06
Epoch 86/512
512/512 - 0s - loss: 8.1120e-04 - val_loss: 8.2170e-06
Epoch 87/512
512/512 - 0s - loss: 8.1725e-04 - val_loss: 8.4294e-06
Epoch 88/512
512/512 - 0s - loss: 8.2948e-04 - val_loss: 8.3431e-06
Epoch 89/512
512/512 - 0s - loss: 8.1051e-04 - val_loss: 8.3376e-06
Epoch 90/512
512/512 - 0s - loss: 8.1735e-04 - val_loss: 8.4079e-06
Epoch 91/512
512/512 - 0s - loss: 8.2147e-04 - val_loss: 8.3149e-06
Epoch 92/512
512/512 - 0s - loss: 8.1426e-04 - val_loss: 8.1813e-06
Epoch 93/512
512/512 - 0s - loss: 8.1288e-04 - val_loss: 8.1752e-06
Epoch 94/512
512/512 - 0s - loss: 8.0564e-04 - val_loss: 8.2764e-06
Epoch 95/512
512/512 - 0s - loss: 8.2036e-04 - val_loss: 8.2261e-06
Epoch 96/512
512/512 - 0s - loss: 8.1163e-04 - val_loss: 8.0536e-06
Epoch 97/512
512/512 - 0s - loss: 7.9178e-04 - val_loss: 8.3517e-06
Epoch 98/512
512/512 - 0s - loss: 8.2647e-04 - val_loss: 8.3542e-06
Epoch 99/512
512/512 - 0s - loss: 8.1130e-04 - val_loss: 8.0142e-06
Epoch 100/512
512/512 - 0s - loss: 7.9265e-04 - val_loss: 8.0838e-06
Epoch 101/512
512/512 - 0s - loss: 8.0830e-04 - val_loss: 8.1969e-06
Epoch 102/512
512/512 - 0s - loss: 8.0548e-04 - val_loss: 8.2086e-06
Epoch 103/512
512/512 - 0s - loss: 7.9887e-04 - val_loss: 8.3071e-06
Epoch 104/512
512/512 - 0s - loss: 8.1205e-04 - val_loss: 8.2118e-06
Epoch 105/512
512/512 - 0s - loss: 8.0546e-04 - val_loss: 8.0415e-06
Epoch 106/512
512/512 - 0s - loss: 7.8823e-04 - val_loss: 8.2097e-06
Epoch 107/512
512/512 - 0s - loss: 8.0914e-04 - val_loss: 8.2569e-06
Epoch 108/512
512/512 - 0s - loss: 8.1315e-04 - val_loss: 7.8706e-06
Epoch 109/512
512/512 - 0s - loss: 7.7166e-04 - val_loss: 8.1422e-06
Epoch 110/512
512/512 - 0s - loss: 8.1314e-04 - val_loss: 8.3592e-06
Epoch 111/512
512/512 - 0s - loss: 8.1373e-04 - val_loss: 7.9092e-06
Epoch 112/512
512/512 - 0s - loss: 7.8383e-04 - val_loss: 7.7690e-06
Epoch 113/512
512/512 - 0s - loss: 7.8676e-04 - val_loss: 8.0949e-06
Epoch 114/512
512/512 - 0s - loss: 8.1209e-04 - val_loss: 8.0807e-06
Epoch 115/512
512/512 - 0s - loss: 7.9119e-04 - val_loss: 7.9284e-06
Epoch 116/512
512/512 - 0s - loss: 7.8714e-04 - val_loss: 8.0919e-06
Epoch 117/512
512/512 - 0s - loss: 8.0007e-04 - val_loss: 8.1373e-06
Epoch 118/512
512/512 - 0s - loss: 7.9825e-04 - val_loss: 8.0516e-06
Epoch 119/512
512/512 - 0s - loss: 7.8880e-04 - val_loss: 8.0249e-06
Epoch 120/512
512/512 - 0s - loss: 7.9432e-04 - val_loss: 8.0357e-06
Epoch 121/512
512/512 - 0s - loss: 7.9308e-04 - val_loss: 8.0106e-06
Epoch 122/512
512/512 - 0s - loss: 7.9634e-04 - val_loss: 7.9294e-06
Epoch 123/512
512/512 - 0s - loss: 7.8245e-04 - val_loss: 8.0139e-06
Epoch 124/512
512/512 - 0s - loss: 7.9407e-04 - val_loss: 8.0735e-06
Epoch 125/512
512/512 - 0s - loss: 7.9747e-04 - val_loss: 7.8912e-06
Epoch 126/512
512/512 - 0s - loss: 7.8106e-04 - val_loss: 7.9219e-06
Epoch 127/512
512/512 - 0s - loss: 7.8426e-04 - val_loss: 8.1810e-06
Epoch 128/512
512/512 - 0s - loss: 8.0707e-04 - val_loss: 8.0170e-06
Epoch 129/512
512/512 - 0s - loss: 7.8067e-04 - val_loss: 7.8370e-06
Epoch 130/512
512/512 - 0s - loss: 7.8124e-04 - val_loss: 8.0234e-06
Epoch 131/512
512/512 - 0s - loss: 7.9561e-04 - val_loss: 7.9945e-06
Epoch 132/512
512/512 - 0s - loss: 7.8367e-04 - val_loss: 7.9489e-06
Epoch 133/512
512/512 - 0s - loss: 7.8804e-04 - val_loss: 7.9890e-06
Epoch 134/512
512/512 - 0s - loss: 7.8602e-04 - val_loss: 7.9842e-06
Epoch 135/512
512/512 - 0s - loss: 7.8678e-04 - val_loss: 7.9783e-06
Epoch 136/512
512/512 - 0s - loss: 7.8653e-04 - val_loss: 7.9492e-06
Epoch 137/512
512/512 - 0s - loss: 7.8666e-04 - val_loss: 7.8561e-06
Epoch 138/512
512/512 - 0s - loss: 7.7886e-04 - val_loss: 7.9390e-06
Epoch 139/512
512/512 - 0s - loss: 7.8722e-04 - val_loss: 8.0248e-06
Epoch 140/512
512/512 - 0s - loss: 7.8449e-04 - val_loss: 7.9931e-06
Epoch 141/512
512/512 - 0s - loss: 7.8679e-04 - val_loss: 7.8960e-06
Epoch 142/512
512/512 - 0s - loss: 7.8322e-04 - val_loss: 7.7762e-06
Epoch 143/512
512/512 - 0s - loss: 7.7407e-04 - val_loss: 7.9369e-06
Epoch 144/512
512/512 - 0s - loss: 7.8917e-04 - val_loss: 8.0125e-06
Epoch 145/512
512/512 - 0s - loss: 7.8471e-04 - val_loss: 7.8731e-06
Epoch 146/512
512/512 - 0s - loss: 7.7819e-04 - val_loss: 7.8143e-06
Epoch 147/512
512/512 - 0s - loss: 7.7617e-04 - val_loss: 7.9597e-06
Epoch 148/512
512/512 - 0s - loss: 7.8510e-04 - val_loss: 8.0558e-06
Epoch 149/512
512/512 - 0s - loss: 7.9069e-04 - val_loss: 7.8383e-06
Epoch 150/512
512/512 - 0s - loss: 7.6845e-04 - val_loss: 7.8339e-06
Epoch 151/512
512/512 - 0s - loss: 7.8390e-04 - val_loss: 7.8933e-06
Epoch 152/512
512/512 - 0s - loss: 7.8073e-04 - val_loss: 7.8440e-06
Epoch 153/512
512/512 - 0s - loss: 7.7598e-04 - val_loss: 7.8556e-06
Epoch 154/512
512/512 - 0s - loss: 7.7947e-04 - val_loss: 7.8793e-06
Epoch 155/512
512/512 - 0s - loss: 7.7743e-04 - val_loss: 7.9597e-06
Epoch 156/512
512/512 - 0s - loss: 7.8669e-04 - val_loss: 7.8001e-06
Epoch 157/512
512/512 - 0s - loss: 7.6985e-04 - val_loss: 7.7234e-06
Epoch 158/512
512/512 - 0s - loss: 7.7162e-04 - val_loss: 7.9273e-06
Epoch 159/512
512/512 - 0s - loss: 7.8588e-04 - val_loss: 7.9636e-06
Epoch 160/512
512/512 - 0s - loss: 7.8379e-04 - val_loss: 7.6607e-06
Epoch 161/512
512/512 - 0s - loss: 7.5995e-04 - val_loss: 7.7777e-06
Epoch 162/512
512/512 - 0s - loss: 7.8321e-04 - val_loss: 7.8881e-06
Epoch 163/512
512/512 - 0s - loss: 7.7820e-04 - val_loss: 7.8128e-06
Epoch 164/512
512/512 - 0s - loss: 7.6639e-04 - val_loss: 7.8984e-06
Epoch 165/512
512/512 - 0s - loss: 7.8453e-04 - val_loss: 7.7987e-06
Epoch 166/512
512/512 - 0s - loss: 7.7294e-04 - val_loss: 7.6995e-06
Epoch 167/512
512/512 - 0s - loss: 7.6614e-04 - val_loss: 7.8366e-06
Epoch 168/512
512/512 - 0s - loss: 7.7556e-04 - val_loss: 7.9924e-06
Epoch 169/512
512/512 - 0s - loss: 7.7497e-04 - val_loss: 7.9668e-06
Epoch 170/512
512/512 - 0s - loss: 7.8171e-04 - val_loss: 7.7352e-06
Epoch 171/512
512/512 - 0s - loss: 7.6150e-04 - val_loss: 7.7452e-06
Epoch 172/512
512/512 - 0s - loss: 7.7362e-04 - val_loss: 7.8422e-06
Epoch 173/512
512/512 - 0s - loss: 7.7669e-04 - val_loss: 7.7754e-06
Epoch 174/512
512/512 - 0s - loss: 7.6957e-04 - val_loss: 7.7245e-06
Epoch 175/512
512/512 - 0s - loss: 7.6955e-04 - val_loss: 7.7431e-06
Epoch 176/512
512/512 - 0s - loss: 7.7280e-04 - val_loss: 7.7153e-06
Epoch 177/512
512/512 - 0s - loss: 7.6105e-04 - val_loss: 7.8445e-06
Epoch 178/512
512/512 - 0s - loss: 7.8382e-04 - val_loss: 7.7181e-06
Epoch 179/512
512/512 - 0s - loss: 7.5830e-04 - val_loss: 7.6651e-06
Epoch 180/512
512/512 - 0s - loss: 7.6655e-04 - val_loss: 7.8691e-06
Epoch 181/512
512/512 - 0s - loss: 7.7377e-04 - val_loss: 7.8756e-06
Epoch 182/512
512/512 - 0s - loss: 7.6757e-04 - val_loss: 7.8331e-06
Epoch 183/512
512/512 - 0s - loss: 7.7030e-04 - val_loss: 7.7353e-06
Epoch 184/512
512/512 - 0s - loss: 7.6440e-04 - val_loss: 7.7171e-06
Epoch 185/512
512/512 - 0s - loss: 7.6617e-04 - val_loss: 7.7639e-06
Epoch 186/512
512/512 - 0s - loss: 7.6518e-04 - val_loss: 7.7921e-06
Epoch 187/512
512/512 - 0s - loss: 7.7171e-04 - val_loss: 7.7155e-06
Epoch 188/512
512/512 - 0s - loss: 7.6019e-04 - val_loss: 7.6799e-06
Epoch 189/512
512/512 - 0s - loss: 7.6279e-04 - val_loss: 7.7741e-06
Epoch 190/512
512/512 - 0s - loss: 7.7070e-04 - val_loss: 7.7063e-06
Epoch 191/512
512/512 - 0s - loss: 7.6165e-04 - val_loss: 7.6743e-06
Epoch 192/512
512/512 - 0s - loss: 7.5714e-04 - val_loss: 7.8044e-06
Epoch 193/512
512/512 - 0s - loss: 7.6920e-04 - val_loss: 7.8099e-06
Epoch 194/512
512/512 - 0s - loss: 7.6707e-04 - val_loss: 7.6265e-06
Epoch 195/512
512/512 - 0s - loss: 7.5658e-04 - val_loss: 7.5938e-06
Epoch 196/512
512/512 - 0s - loss: 7.5875e-04 - val_loss: 7.7420e-06
Epoch 197/512
512/512 - 0s - loss: 7.6147e-04 - val_loss: 7.7985e-06
Epoch 198/512
512/512 - 0s - loss: 7.7080e-04 - val_loss: 7.5998e-06
Epoch 199/512
512/512 - 0s - loss: 7.5496e-04 - val_loss: 7.4865e-06
Epoch 200/512
512/512 - 0s - loss: 7.5447e-04 - val_loss: 7.5821e-06
Epoch 201/512
512/512 - 0s - loss: 7.5507e-04 - val_loss: 7.7864e-06
Epoch 202/512
512/512 - 0s - loss: 7.6970e-04 - val_loss: 7.6890e-06
Epoch 203/512
512/512 - 0s - loss: 7.5665e-04 - val_loss: 7.5099e-06
Epoch 204/512
512/512 - 0s - loss: 7.4717e-04 - val_loss: 7.7026e-06
Epoch 205/512
512/512 - 0s - loss: 7.6921e-04 - val_loss: 7.6410e-06
Epoch 206/512
512/512 - 0s - loss: 7.5149e-04 - val_loss: 7.5127e-06
Epoch 207/512
512/512 - 0s - loss: 7.4785e-04 - val_loss: 7.7021e-06
Epoch 208/512
512/512 - 0s - loss: 7.6575e-04 - val_loss: 7.6621e-06
Epoch 209/512
512/512 - 0s - loss: 7.4753e-04 - val_loss: 7.6682e-06
Epoch 210/512
512/512 - 0s - loss: 7.6051e-04 - val_loss: 7.5832e-06
Epoch 211/512
512/512 - 0s - loss: 7.5049e-04 - val_loss: 7.5240e-06
Epoch 212/512
512/512 - 0s - loss: 7.4603e-04 - val_loss: 7.6845e-06
Epoch 213/512
512/512 - 0s - loss: 7.6295e-04 - val_loss: 7.6459e-06
Epoch 214/512
512/512 - 0s - loss: 7.5378e-04 - val_loss: 7.4551e-06
Epoch 215/512
512/512 - 0s - loss: 7.4268e-04 - val_loss: 7.4902e-06
Epoch 216/512
512/512 - 0s - loss: 7.4623e-04 - val_loss: 7.7278e-06
Epoch 217/512
512/512 - 0s - loss: 7.6345e-04 - val_loss: 7.5984e-06
Epoch 218/512
512/512 - 0s - loss: 7.4062e-04 - val_loss: 7.4927e-06
Epoch 219/512
512/512 - 0s - loss: 7.4898e-04 - val_loss: 7.5222e-06
Epoch 220/512
512/512 - 0s - loss: 7.4169e-04 - val_loss: 7.6935e-06
Epoch 221/512
512/512 - 0s - loss: 7.5756e-04 - val_loss: 7.6224e-06
Epoch 222/512
512/512 - 0s - loss: 7.4350e-04 - val_loss: 7.4961e-06
Epoch 223/512
512/512 - 0s - loss: 7.4105e-04 - val_loss: 7.5842e-06
Epoch 224/512
512/512 - 0s - loss: 7.5285e-04 - val_loss: 7.5154e-06
Epoch 225/512
512/512 - 0s - loss: 7.4281e-04 - val_loss: 7.3850e-06
Epoch 226/512
512/512 - 0s - loss: 7.3600e-04 - val_loss: 7.5509e-06
Epoch 227/512
512/512 - 0s - loss: 7.5116e-04 - val_loss: 7.4667e-06
Epoch 228/512
512/512 - 0s - loss: 7.4018e-04 - val_loss: 7.3626e-06
Epoch 229/512
512/512 - 0s - loss: 7.3387e-04 - val_loss: 7.5768e-06
Epoch 230/512
512/512 - 0s - loss: 7.4589e-04 - val_loss: 7.6254e-06
Epoch 231/512
512/512 - 0s - loss: 7.4966e-04 - val_loss: 7.3650e-06
Epoch 232/512
512/512 - 0s - loss: 7.2732e-04 - val_loss: 7.3434e-06
Epoch 233/512
512/512 - 0s - loss: 7.3890e-04 - val_loss: 7.4876e-06
Epoch 234/512
512/512 - 0s - loss: 7.3995e-04 - val_loss: 7.5038e-06
Epoch 235/512
512/512 - 0s - loss: 7.3857e-04 - val_loss: 7.3990e-06
Epoch 236/512
512/512 - 0s - loss: 7.3403e-04 - val_loss: 7.3570e-06
Epoch 237/512
512/512 - 0s - loss: 7.3323e-04 - val_loss: 7.4427e-06
Epoch 238/512
512/512 - 0s - loss: 7.3788e-04 - val_loss: 7.4211e-06
Epoch 239/512
512/512 - 0s - loss: 7.3371e-04 - val_loss: 7.3555e-06
Epoch 240/512
512/512 - 0s - loss: 7.2905e-04 - val_loss: 7.3911e-06
Epoch 241/512
512/512 - 0s - loss: 7.3164e-04 - val_loss: 7.4467e-06
Epoch 242/512
512/512 - 0s - loss: 7.3392e-04 - val_loss: 7.3938e-06
Epoch 243/512
512/512 - 0s - loss: 7.3128e-04 - val_loss: 7.2732e-06
Epoch 244/512
512/512 - 0s - loss: 7.2277e-04 - val_loss: 7.3349e-06
Epoch 245/512
512/512 - 0s - loss: 7.2920e-04 - val_loss: 7.4228e-06
Epoch 246/512
512/512 - 0s - loss: 7.3342e-04 - val_loss: 7.3060e-06
Epoch 247/512
512/512 - 0s - loss: 7.1858e-04 - val_loss: 7.3391e-06
Epoch 248/512
512/512 - 0s - loss: 7.2270e-04 - val_loss: 7.4719e-06
Epoch 249/512
512/512 - 0s - loss: 7.3843e-04 - val_loss: 7.2729e-06
Epoch 250/512
512/512 - 0s - loss: 7.1135e-04 - val_loss: 7.2518e-06
Epoch 251/512
512/512 - 0s - loss: 7.2840e-04 - val_loss: 7.2266e-06
Epoch 252/512
512/512 - 0s - loss: 7.1412e-04 - val_loss: 7.2720e-06
Epoch 253/512
512/512 - 0s - loss: 7.2816e-04 - val_loss: 7.2395e-06
Epoch 254/512
512/512 - 0s - loss: 7.0918e-04 - val_loss: 7.3093e-06
Epoch 255/512
512/512 - 0s - loss: 7.2563e-04 - val_loss: 7.3189e-06
Epoch 256/512
512/512 - 0s - loss: 7.1996e-04 - val_loss: 7.1190e-06
Epoch 257/512
512/512 - 0s - loss: 7.0917e-04 - val_loss: 7.1331e-06
Epoch 258/512
512/512 - 0s - loss: 7.0841e-04 - val_loss: 7.3666e-06
Epoch 259/512
512/512 - 0s - loss: 7.2786e-04 - val_loss: 7.3020e-06
Epoch 260/512
512/512 - 0s - loss: 7.0685e-04 - val_loss: 7.1816e-06
Epoch 261/512
512/512 - 0s - loss: 7.1092e-04 - val_loss: 7.1823e-06
Epoch 262/512
512/512 - 0s - loss: 7.1538e-04 - val_loss: 7.1230e-06
Epoch 263/512
512/512 - 0s - loss: 7.0430e-04 - val_loss: 7.1235e-06
Epoch 264/512
512/512 - 0s - loss: 7.1594e-04 - val_loss: 6.9543e-06
Epoch 265/512
512/512 - 0s - loss: 6.9143e-04 - val_loss: 7.1290e-06
Epoch 266/512
512/512 - 0s - loss: 7.0901e-04 - val_loss: 7.3742e-06
Epoch 267/512
512/512 - 0s - loss: 7.2319e-04 - val_loss: 6.9930e-06
Epoch 268/512
512/512 - 0s - loss: 6.8585e-04 - val_loss: 6.9017e-06
Epoch 269/512
512/512 - 0s - loss: 6.9890e-04 - val_loss: 7.1870e-06
Epoch 270/512
512/512 - 0s - loss: 7.0771e-04 - val_loss: 7.1792e-06
Epoch 271/512
512/512 - 0s - loss: 7.0124e-04 - val_loss: 7.0306e-06
Epoch 272/512
512/512 - 0s - loss: 6.9600e-04 - val_loss: 6.9885e-06
Epoch 273/512
512/512 - 0s - loss: 6.9329e-04 - val_loss: 7.0304e-06
Epoch 274/512
512/512 - 0s - loss: 6.9825e-04 - val_loss: 7.0584e-06
Epoch 275/512
512/512 - 0s - loss: 6.9823e-04 - val_loss: 6.8904e-06
Epoch 276/512
512/512 - 0s - loss: 6.8038e-04 - val_loss: 7.0267e-06
Epoch 277/512
512/512 - 0s - loss: 6.9797e-04 - val_loss: 7.1004e-06
Epoch 278/512
512/512 - 0s - loss: 6.9346e-04 - val_loss: 7.0020e-06
Epoch 279/512
512/512 - 0s - loss: 6.9024e-04 - val_loss: 6.8454e-06
Epoch 280/512
512/512 - 0s - loss: 6.7850e-04 - val_loss: 6.9059e-06
Epoch 281/512
512/512 - 0s - loss: 6.8586e-04 - val_loss: 7.0384e-06
Epoch 282/512
512/512 - 0s - loss: 6.9626e-04 - val_loss: 6.7718e-06
Epoch 283/512
512/512 - 0s - loss: 6.6858e-04 - val_loss: 6.8090e-06
Epoch 284/512
512/512 - 0s - loss: 6.8211e-04 - val_loss: 6.9746e-06
Epoch 285/512
512/512 - 0s - loss: 6.8137e-04 - val_loss: 6.9614e-06
Epoch 286/512
512/512 - 0s - loss: 6.8279e-04 - val_loss: 6.8652e-06
Epoch 287/512
512/512 - 0s - loss: 6.7145e-04 - val_loss: 6.8107e-06
Epoch 288/512
512/512 - 0s - loss: 6.7713e-04 - val_loss: 6.7362e-06
Epoch 289/512
512/512 - 0s - loss: 6.7132e-04 - val_loss: 6.7160e-06
Epoch 290/512
512/512 - 0s - loss: 6.7345e-04 - val_loss: 6.6788e-06
Epoch 291/512
512/512 - 0s - loss: 6.6404e-04 - val_loss: 6.7469e-06
Epoch 292/512
512/512 - 0s - loss: 6.7283e-04 - val_loss: 6.7776e-06
Epoch 293/512
512/512 - 0s - loss: 6.6991e-04 - val_loss: 6.5655e-06
Epoch 294/512
512/512 - 0s - loss: 6.5789e-04 - val_loss: 6.6135e-06
Epoch 295/512
512/512 - 0s - loss: 6.6365e-04 - val_loss: 6.6728e-06
Epoch 296/512
512/512 - 0s - loss: 6.6219e-04 - val_loss: 6.6587e-06
Epoch 297/512
512/512 - 0s - loss: 6.6116e-04 - val_loss: 6.5933e-06
Epoch 298/512
512/512 - 0s - loss: 6.5284e-04 - val_loss: 6.6372e-06
Epoch 299/512
512/512 - 0s - loss: 6.5420e-04 - val_loss: 6.7225e-06
Epoch 300/512
512/512 - 0s - loss: 6.5922e-04 - val_loss: 6.6735e-06
Epoch 301/512
512/512 - 0s - loss: 6.5240e-04 - val_loss: 6.5589e-06
Epoch 302/512
512/512 - 0s - loss: 6.4782e-04 - val_loss: 6.5441e-06
Epoch 303/512
512/512 - 0s - loss: 6.4549e-04 - val_loss: 6.5814e-06
Epoch 304/512
512/512 - 0s - loss: 6.5202e-04 - val_loss: 6.5159e-06
Epoch 305/512
512/512 - 0s - loss: 6.3714e-04 - val_loss: 6.5441e-06
Epoch 306/512
512/512 - 0s - loss: 6.4629e-04 - val_loss: 6.5922e-06
Epoch 307/512
512/512 - 0s - loss: 6.4752e-04 - val_loss: 6.3729e-06
Epoch 308/512
512/512 - 0s - loss: 6.3192e-04 - val_loss: 6.2827e-06
Epoch 309/512
512/512 - 0s - loss: 6.2698e-04 - val_loss: 6.5449e-06
Epoch 310/512
512/512 - 0s - loss: 6.4955e-04 - val_loss: 6.4432e-06
Epoch 311/512
512/512 - 0s - loss: 6.3353e-04 - val_loss: 6.0992e-06
Epoch 312/512
512/512 - 0s - loss: 6.1414e-04 - val_loss: 6.2777e-06
Epoch 313/512
512/512 - 0s - loss: 6.3298e-04 - val_loss: 6.4522e-06
Epoch 314/512
512/512 - 0s - loss: 6.3923e-04 - val_loss: 6.1551e-06
Epoch 315/512
512/512 - 0s - loss: 6.0966e-04 - val_loss: 6.1425e-06
Epoch 316/512
512/512 - 0s - loss: 6.1650e-04 - val_loss: 6.3997e-06
Epoch 317/512
512/512 - 0s - loss: 6.3500e-04 - val_loss: 6.2694e-06
Epoch 318/512
512/512 - 0s - loss: 6.1782e-04 - val_loss: 5.9498e-06
Epoch 319/512
512/512 - 0s - loss: 5.9335e-04 - val_loss: 6.1986e-06
Epoch 320/512
512/512 - 0s - loss: 6.2320e-04 - val_loss: 6.3762e-06
Epoch 321/512
512/512 - 0s - loss: 6.1922e-04 - val_loss: 6.1062e-06
Epoch 322/512
512/512 - 0s - loss: 5.9429e-04 - val_loss: 6.1142e-06
Epoch 323/512
512/512 - 0s - loss: 6.1016e-04 - val_loss: 6.1685e-06
Epoch 324/512
512/512 - 0s - loss: 6.0733e-04 - val_loss: 6.0443e-06
Epoch 325/512
512/512 - 0s - loss: 5.9740e-04 - val_loss: 5.9622e-06
Epoch 326/512
512/512 - 0s - loss: 5.9755e-04 - val_loss: 6.0035e-06
Epoch 327/512
512/512 - 0s - loss: 5.9286e-04 - val_loss: 6.0487e-06
Epoch 328/512
512/512 - 0s - loss: 5.9737e-04 - val_loss: 6.0120e-06
Epoch 329/512
512/512 - 0s - loss: 5.9256e-04 - val_loss: 5.8589e-06
Epoch 330/512
512/512 - 0s - loss: 5.8427e-04 - val_loss: 5.8542e-06
Epoch 331/512
512/512 - 0s - loss: 5.8286e-04 - val_loss: 5.9425e-06
Epoch 332/512
512/512 - 0s - loss: 5.9007e-04 - val_loss: 5.8722e-06
Epoch 333/512
512/512 - 0s - loss: 5.7834e-04 - val_loss: 5.7670e-06
Epoch 334/512
512/512 - 0s - loss: 5.7375e-04 - val_loss: 5.8010e-06
Epoch 335/512
512/512 - 0s - loss: 5.8165e-04 - val_loss: 5.7137e-06
Epoch 336/512
512/512 - 0s - loss: 5.6364e-04 - val_loss: 5.7619e-06
Epoch 337/512
512/512 - 0s - loss: 5.7712e-04 - val_loss: 5.7457e-06
Epoch 338/512
512/512 - 0s - loss: 5.6289e-04 - val_loss: 5.7549e-06
Epoch 339/512
512/512 - 0s - loss: 5.6887e-04 - val_loss: 5.6861e-06
Epoch 340/512
512/512 - 0s - loss: 5.6400e-04 - val_loss: 5.5255e-06
Epoch 341/512
512/512 - 0s - loss: 5.4980e-04 - val_loss: 5.5902e-06
Epoch 342/512
512/512 - 0s - loss: 5.5960e-04 - val_loss: 5.6640e-06
Epoch 343/512
512/512 - 0s - loss: 5.5826e-04 - val_loss: 5.5248e-06
Epoch 344/512
512/512 - 0s - loss: 5.4118e-04 - val_loss: 5.5725e-06
Epoch 345/512
512/512 - 0s - loss: 5.5590e-04 - val_loss: 5.5505e-06
Epoch 346/512
512/512 - 0s - loss: 5.4639e-04 - val_loss: 5.3564e-06
Epoch 347/512
512/512 - 0s - loss: 5.2919e-04 - val_loss: 5.4693e-06
Epoch 348/512
512/512 - 0s - loss: 5.4998e-04 - val_loss: 5.4621e-06
Epoch 349/512
512/512 - 0s - loss: 5.3741e-04 - val_loss: 5.2591e-06
Epoch 350/512
512/512 - 0s - loss: 5.2058e-04 - val_loss: 5.3737e-06
Epoch 351/512
512/512 - 0s - loss: 5.3505e-04 - val_loss: 5.4699e-06
Epoch 352/512
512/512 - 0s - loss: 5.3755e-04 - val_loss: 5.2124e-06
Epoch 353/512
512/512 - 0s - loss: 5.1191e-04 - val_loss: 5.2039e-06
Epoch 354/512
512/512 - 0s - loss: 5.1969e-04 - val_loss: 5.3658e-06
Epoch 355/512
512/512 - 0s - loss: 5.2657e-04 - val_loss: 5.2303e-06
Epoch 356/512
512/512 - 0s - loss: 5.1436e-04 - val_loss: 5.0443e-06
Epoch 357/512
512/512 - 0s - loss: 5.0204e-04 - val_loss: 5.1438e-06
Epoch 358/512
512/512 - 0s - loss: 5.1267e-04 - val_loss: 5.2092e-06
Epoch 359/512
512/512 - 0s - loss: 5.1044e-04 - val_loss: 5.0432e-06
Epoch 360/512
512/512 - 0s - loss: 4.9667e-04 - val_loss: 4.9602e-06
Epoch 361/512
512/512 - 0s - loss: 4.9627e-04 - val_loss: 5.0566e-06
Epoch 362/512
512/512 - 0s - loss: 4.9989e-04 - val_loss: 5.0116e-06
Epoch 363/512
512/512 - 0s - loss: 4.8962e-04 - val_loss: 4.9586e-06
Epoch 364/512
512/512 - 0s - loss: 4.9109e-04 - val_loss: 4.9195e-06
Epoch 365/512
512/512 - 0s - loss: 4.8566e-04 - val_loss: 4.8455e-06
Epoch 366/512
512/512 - 0s - loss: 4.8287e-04 - val_loss: 4.7843e-06
Epoch 367/512
512/512 - 0s - loss: 4.7272e-04 - val_loss: 4.8523e-06
Epoch 368/512
512/512 - 0s - loss: 4.8402e-04 - val_loss: 4.8127e-06
Epoch 369/512
512/512 - 0s - loss: 4.7010e-04 - val_loss: 4.7022e-06
Epoch 370/512
512/512 - 0s - loss: 4.6605e-04 - val_loss: 4.7151e-06
Epoch 371/512
512/512 - 0s - loss: 4.7175e-04 - val_loss: 4.6029e-06
Epoch 372/512
512/512 - 0s - loss: 4.5276e-04 - val_loss: 4.6457e-06
Epoch 373/512
512/512 - 0s - loss: 4.6050e-04 - val_loss: 4.7529e-06
Epoch 374/512
512/512 - 0s - loss: 4.6584e-04 - val_loss: 4.5455e-06
Epoch 375/512
512/512 - 0s - loss: 4.4616e-04 - val_loss: 4.4148e-06
Epoch 376/512
512/512 - 0s - loss: 4.4403e-04 - val_loss: 4.5049e-06
Epoch 377/512
512/512 - 0s - loss: 4.5052e-04 - val_loss: 4.4852e-06
Epoch 378/512
512/512 - 0s - loss: 4.3877e-04 - val_loss: 4.4226e-06
Epoch 379/512
512/512 - 0s - loss: 4.4049e-04 - val_loss: 4.3519e-06
Epoch 380/512
512/512 - 0s - loss: 4.3142e-04 - val_loss: 4.3487e-06
Epoch 381/512
512/512 - 0s - loss: 4.3227e-04 - val_loss: 4.3148e-06
Epoch 382/512
512/512 - 0s - loss: 4.2769e-04 - val_loss: 4.2585e-06
Epoch 383/512
512/512 - 0s - loss: 4.2278e-04 - val_loss: 4.2429e-06
Epoch 384/512
512/512 - 0s - loss: 4.2683e-04 - val_loss: 4.0903e-06
Epoch 385/512
512/512 - 0s - loss: 4.0673e-04 - val_loss: 4.1071e-06
Epoch 386/512
512/512 - 0s - loss: 4.1376e-04 - val_loss: 4.2190e-06
Epoch 387/512
512/512 - 0s - loss: 4.1702e-04 - val_loss: 4.0944e-06
Epoch 388/512
512/512 - 0s - loss: 4.0114e-04 - val_loss: 4.0118e-06
Epoch 389/512
512/512 - 0s - loss: 4.0178e-04 - val_loss: 4.0367e-06
Epoch 390/512
512/512 - 0s - loss: 3.9948e-04 - val_loss: 4.0196e-06
Epoch 391/512
512/512 - 0s - loss: 3.9703e-04 - val_loss: 3.9268e-06
Epoch 392/512
512/512 - 0s - loss: 3.8914e-04 - val_loss: 3.8881e-06
Epoch 393/512
512/512 - 0s - loss: 3.8712e-04 - val_loss: 3.8952e-06
Epoch 394/512
512/512 - 0s - loss: 3.8604e-04 - val_loss: 3.8137e-06
Epoch 395/512
512/512 - 0s - loss: 3.7774e-04 - val_loss: 3.7892e-06
Epoch 396/512
512/512 - 0s - loss: 3.8046e-04 - val_loss: 3.7260e-06
Epoch 397/512
512/512 - 0s - loss: 3.6937e-04 - val_loss: 3.7091e-06
Epoch 398/512
512/512 - 0s - loss: 3.7160e-04 - val_loss: 3.6824e-06
Epoch 399/512
512/512 - 0s - loss: 3.6659e-04 - val_loss: 3.5830e-06
Epoch 400/512
512/512 - 0s - loss: 3.5792e-04 - val_loss: 3.6230e-06
Epoch 401/512
512/512 - 0s - loss: 3.6001e-04 - val_loss: 3.6197e-06
Epoch 402/512
512/512 - 0s - loss: 3.5708e-04 - val_loss: 3.5347e-06
Epoch 403/512
512/512 - 0s - loss: 3.4827e-04 - val_loss: 3.4708e-06
Epoch 404/512
512/512 - 0s - loss: 3.4647e-04 - val_loss: 3.4996e-06
Epoch 405/512
512/512 - 0s - loss: 3.4876e-04 - val_loss: 3.3811e-06
Epoch 406/512
512/512 - 0s - loss: 3.3572e-04 - val_loss: 3.3133e-06
Epoch 407/512
512/512 - 0s - loss: 3.3076e-04 - val_loss: 3.4314e-06
Epoch 408/512
512/512 - 0s - loss: 3.4316e-04 - val_loss: 3.3371e-06
Epoch 409/512
512/512 - 0s - loss: 3.2693e-04 - val_loss: 3.1616e-06
Epoch 410/512
512/512 - 0s - loss: 3.1698e-04 - val_loss: 3.2354e-06
Epoch 411/512
512/512 - 0s - loss: 3.2529e-04 - val_loss: 3.2932e-06
Epoch 412/512
512/512 - 0s - loss: 3.2105e-04 - val_loss: 3.1779e-06
Epoch 413/512
512/512 - 0s - loss: 3.1243e-04 - val_loss: 3.0755e-06
Epoch 414/512
512/512 - 0s - loss: 3.0801e-04 - val_loss: 3.0565e-06
Epoch 415/512
512/512 - 0s - loss: 3.0616e-04 - val_loss: 3.0897e-06
Epoch 416/512
512/512 - 0s - loss: 3.0663e-04 - val_loss: 3.0120e-06
Epoch 417/512
512/512 - 0s - loss: 2.9497e-04 - val_loss: 2.9913e-06
Epoch 418/512
512/512 - 0s - loss: 2.9679e-04 - val_loss: 2.9896e-06
Epoch 419/512
512/512 - 0s - loss: 2.9642e-04 - val_loss: 2.8572e-06
Epoch 420/512
512/512 - 0s - loss: 2.8257e-04 - val_loss: 2.8334e-06
Epoch 421/512
512/512 - 0s - loss: 2.8531e-04 - val_loss: 2.8728e-06
Epoch 422/512
512/512 - 0s - loss: 2.8231e-04 - val_loss: 2.8437e-06
Epoch 423/512
512/512 - 0s - loss: 2.7790e-04 - val_loss: 2.7749e-06
Epoch 424/512
512/512 - 0s - loss: 2.7644e-04 - val_loss: 2.6793e-06
Epoch 425/512
512/512 - 0s - loss: 2.6515e-04 - val_loss: 2.6807e-06
Epoch 426/512
512/512 - 0s - loss: 2.6881e-04 - val_loss: 2.6998e-06
Epoch 427/512
512/512 - 0s - loss: 2.6695e-04 - val_loss: 2.5721e-06
Epoch 428/512
512/512 - 0s - loss: 2.5335e-04 - val_loss: 2.5584e-06
Epoch 429/512
512/512 - 0s - loss: 2.6074e-04 - val_loss: 2.5374e-06
Epoch 430/512
512/512 - 0s - loss: 2.5051e-04 - val_loss: 2.4717e-06
Epoch 431/512
512/512 - 0s - loss: 2.4837e-04 - val_loss: 2.4716e-06
Epoch 432/512
512/512 - 0s - loss: 2.4641e-04 - val_loss: 2.4477e-06
Epoch 433/512
512/512 - 0s - loss: 2.4491e-04 - val_loss: 2.3375e-06
Epoch 434/512
512/512 - 0s - loss: 2.3361e-04 - val_loss: 2.3217e-06
Epoch 435/512
512/512 - 0s - loss: 2.3248e-04 - val_loss: 2.4260e-06
Epoch 436/512
512/512 - 0s - loss: 2.3928e-04 - val_loss: 2.3216e-06
Epoch 437/512
512/512 - 0s - loss: 2.2549e-04 - val_loss: 2.2072e-06
Epoch 438/512
512/512 - 0s - loss: 2.2081e-04 - val_loss: 2.2662e-06
Epoch 439/512
512/512 - 0s - loss: 2.2499e-04 - val_loss: 2.2443e-06
Epoch 440/512
512/512 - 0s - loss: 2.2018e-04 - val_loss: 2.1246e-06
Epoch 441/512
512/512 - 0s - loss: 2.1129e-04 - val_loss: 2.0968e-06
Epoch 442/512
512/512 - 0s - loss: 2.1168e-04 - val_loss: 2.1080e-06
Epoch 443/512
512/512 - 0s - loss: 2.0905e-04 - val_loss: 2.0698e-06
Epoch 444/512
512/512 - 0s - loss: 2.0492e-04 - val_loss: 2.0215e-06
Epoch 445/512
512/512 - 0s - loss: 2.0223e-04 - val_loss: 1.9613e-06
Epoch 446/512
512/512 - 0s - loss: 1.9566e-04 - val_loss: 1.9630e-06
Epoch 447/512
512/512 - 0s - loss: 1.9604e-04 - val_loss: 1.9599e-06
Epoch 448/512
512/512 - 0s - loss: 1.9365e-04 - val_loss: 1.9049e-06
Epoch 449/512
512/512 - 0s - loss: 1.8755e-04 - val_loss: 1.8586e-06
Epoch 450/512
512/512 - 0s - loss: 1.8601e-04 - val_loss: 1.8272e-06
Epoch 451/512
512/512 - 0s - loss: 1.8273e-04 - val_loss: 1.7852e-06
Epoch 452/512
512/512 - 0s - loss: 1.7698e-04 - val_loss: 1.7997e-06
Epoch 453/512
512/512 - 0s - loss: 1.7867e-04 - val_loss: 1.7672e-06
Epoch 454/512
512/512 - 0s - loss: 1.7326e-04 - val_loss: 1.7179e-06
Epoch 455/512
512/512 - 0s - loss: 1.6980e-04 - val_loss: 1.6856e-06
Epoch 456/512
512/512 - 0s - loss: 1.6814e-04 - val_loss: 1.6300e-06
Epoch 457/512
512/512 - 0s - loss: 1.6322e-04 - val_loss: 1.5996e-06
Epoch 458/512
512/512 - 0s - loss: 1.6122e-04 - val_loss: 1.6006e-06
Epoch 459/512
512/512 - 0s - loss: 1.5959e-04 - val_loss: 1.5622e-06
Epoch 460/512
512/512 - 0s - loss: 1.5437e-04 - val_loss: 1.5332e-06
Epoch 461/512
512/512 - 0s - loss: 1.5308e-04 - val_loss: 1.5199e-06
Epoch 462/512
512/512 - 0s - loss: 1.5130e-04 - val_loss: 1.4637e-06
Epoch 463/512
512/512 - 0s - loss: 1.4469e-04 - val_loss: 1.4611e-06
Epoch 464/512
512/512 - 0s - loss: 1.4661e-04 - val_loss: 1.4272e-06
Epoch 465/512
512/512 - 0s - loss: 1.4089e-04 - val_loss: 1.3804e-06
Epoch 466/512
512/512 - 0s - loss: 1.3835e-04 - val_loss: 1.3603e-06
Epoch 467/512
512/512 - 0s - loss: 1.3615e-04 - val_loss: 1.3499e-06
Epoch 468/512
512/512 - 0s - loss: 1.3424e-04 - val_loss: 1.3215e-06
Epoch 469/512
512/512 - 0s - loss: 1.3112e-04 - val_loss: 1.2807e-06
Epoch 470/512
512/512 - 0s - loss: 1.2643e-04 - val_loss: 1.2856e-06
Epoch 471/512
512/512 - 0s - loss: 1.2967e-04 - val_loss: 1.2226e-06
Epoch 472/512
512/512 - 0s - loss: 1.2119e-04 - val_loss: 1.1796e-06
Epoch 473/512
512/512 - 0s - loss: 1.1883e-04 - val_loss: 1.2101e-06
Epoch 474/512
512/512 - 0s - loss: 1.2129e-04 - val_loss: 1.1850e-06
Epoch 475/512
512/512 - 0s - loss: 1.1643e-04 - val_loss: 1.1048e-06
Epoch 476/512
512/512 - 0s - loss: 1.1029e-04 - val_loss: 1.1130e-06
Epoch 477/512
512/512 - 0s - loss: 1.1328e-04 - val_loss: 1.1034e-06
Epoch 478/512
512/512 - 0s - loss: 1.0897e-04 - val_loss: 1.0556e-06
Epoch 479/512
512/512 - 0s - loss: 1.0534e-04 - val_loss: 1.0477e-06
Epoch 480/512
512/512 - 0s - loss: 1.0542e-04 - val_loss: 1.0211e-06
Epoch 481/512
512/512 - 0s - loss: 1.0103e-04 - val_loss: 1.0031e-06
Epoch 482/512
512/512 - 0s - loss: 1.0039e-04 - val_loss: 9.8505e-07
Epoch 483/512
512/512 - 0s - loss: 9.7988e-05 - val_loss: 9.5173e-07
Epoch 484/512
512/512 - 0s - loss: 9.4970e-05 - val_loss: 9.2597e-07
Epoch 485/512
512/512 - 0s - loss: 9.3290e-05 - val_loss: 9.1225e-07
Epoch 486/512
512/512 - 0s - loss: 9.0949e-05 - val_loss: 9.0557e-07
Epoch 487/512
512/512 - 0s - loss: 8.9903e-05 - val_loss: 8.8176e-07
Epoch 488/512
512/512 - 0s - loss: 8.7412e-05 - val_loss: 8.4889e-07
Epoch 489/512
512/512 - 0s - loss: 8.4406e-05 - val_loss: 8.3575e-07
Epoch 490/512
512/512 - 0s - loss: 8.3400e-05 - val_loss: 8.3065e-07
Epoch 491/512
512/512 - 0s - loss: 8.2849e-05 - val_loss: 7.8531e-07
Epoch 492/512
512/512 - 0s - loss: 7.8049e-05 - val_loss: 7.6317e-07
Epoch 493/512
512/512 - 0s - loss: 7.6960e-05 - val_loss: 7.7487e-07
Epoch 494/512
512/512 - 0s - loss: 7.7832e-05 - val_loss: 7.3821e-07
Epoch 495/512
512/512 - 0s - loss: 7.2998e-05 - val_loss: 7.0763e-07
Epoch 496/512
512/512 - 0s - loss: 7.1366e-05 - val_loss: 7.1033e-07
Epoch 497/512
512/512 - 0s - loss: 7.1636e-05 - val_loss: 6.9420e-07
Epoch 498/512
512/512 - 0s - loss: 6.8831e-05 - val_loss: 6.6146e-07
Epoch 499/512
512/512 - 0s - loss: 6.6495e-05 - val_loss: 6.5149e-07
Epoch 500/512
512/512 - 0s - loss: 6.5459e-05 - val_loss: 6.4732e-07
Epoch 501/512
512/512 - 0s - loss: 6.4978e-05 - val_loss: 6.1684e-07
Epoch 502/512
512/512 - 0s - loss: 6.1519e-05 - val_loss: 5.9023e-07
Epoch 503/512
512/512 - 0s - loss: 5.9949e-05 - val_loss: 5.9922e-07
Epoch 504/512
512/512 - 0s - loss: 6.0360e-05 - val_loss: 5.7854e-07
Epoch 505/512
512/512 - 0s - loss: 5.7393e-05 - val_loss: 5.5262e-07
Epoch 506/512
512/512 - 0s - loss: 5.5604e-05 - val_loss: 5.5450e-07
Epoch 507/512
512/512 - 0s - loss: 5.5719e-05 - val_loss: 5.3651e-07
Epoch 508/512
512/512 - 0s - loss: 5.3417e-05 - val_loss: 5.1112e-07
Epoch 509/512
512/512 - 0s - loss: 5.1234e-05 - val_loss: 5.0702e-07
Epoch 510/512
512/512 - 0s - loss: 5.1238e-05 - val_loss: 4.9769e-07
Epoch 511/512
512/512 - 0s - loss: 4.9730e-05 - val_loss: 4.7114e-07
Epoch 512/512
512/512 - 0s - loss: 4.7186e-05 - val_loss: 4.6294e-07
2024-04-07 22:03:35.260088: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
Train on 512 samples, validate on 512 samples
Epoch 1/512

Epoch 00001: val_loss improved from inf to 0.00006, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.5924e-05 - val_loss: 5.8787e-05
Epoch 2/512

Epoch 00002: val_loss improved from 0.00006 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.1857e-05 - val_loss: 3.9372e-05
Epoch 3/512

Epoch 00003: val_loss improved from 0.00004 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.7600e-05 - val_loss: 3.8444e-05
Epoch 4/512

Epoch 00004: val_loss did not improve from 0.00004
512/512 - 0s - loss: 4.3563e-05 - val_loss: 4.9838e-05
Epoch 5/512

Epoch 00005: val_loss did not improve from 0.00004
512/512 - 0s - loss: 4.9273e-05 - val_loss: 4.2866e-05
Epoch 6/512

Epoch 00006: val_loss improved from 0.00004 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.9544e-05 - val_loss: 3.5648e-05
Epoch 7/512

Epoch 00007: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.7414e-05 - val_loss: 4.0711e-05
Epoch 8/512

Epoch 00008: val_loss did not improve from 0.00004
512/512 - 0s - loss: 4.2689e-05 - val_loss: 4.1681e-05
Epoch 9/512

Epoch 00009: val_loss improved from 0.00004 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.9547e-05 - val_loss: 3.5122e-05
Epoch 10/512

Epoch 00010: val_loss improved from 0.00004 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.4868e-05 - val_loss: 3.5032e-05
Epoch 11/512

Epoch 00011: val_loss did not improve from 0.00004
512/512 - 0s - loss: 3.6712e-05 - val_loss: 3.7555e-05
Epoch 12/512

Epoch 00012: val_loss improved from 0.00004 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.7157e-05 - val_loss: 3.4219e-05
Epoch 13/512

Epoch 00013: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3328e-05 - val_loss: 3.1766e-05
Epoch 14/512

Epoch 00014: val_loss did not improve from 0.00003
512/512 - 0s - loss: 3.2586e-05 - val_loss: 3.3055e-05
Epoch 15/512

Epoch 00015: val_loss did not improve from 0.00003
512/512 - 0s - loss: 3.3509e-05 - val_loss: 3.2314e-05
Epoch 16/512

Epoch 00016: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1650e-05 - val_loss: 2.9722e-05
Epoch 17/512

Epoch 00017: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9787e-05 - val_loss: 2.9411e-05
Epoch 18/512

Epoch 00018: val_loss did not improve from 0.00003
512/512 - 0s - loss: 2.9977e-05 - val_loss: 2.9486e-05
Epoch 19/512

Epoch 00019: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9289e-05 - val_loss: 2.7829e-05
Epoch 20/512

Epoch 00020: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7674e-05 - val_loss: 2.6700e-05
Epoch 21/512

Epoch 00021: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7009e-05 - val_loss: 2.6553e-05
Epoch 22/512

Epoch 00022: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6716e-05 - val_loss: 2.5691e-05
Epoch 23/512

Epoch 00023: val_loss improved from 0.00003 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5577e-05 - val_loss: 2.4500e-05
Epoch 24/512

Epoch 00024: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4633e-05 - val_loss: 2.4002e-05
Epoch 25/512

Epoch 00025: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4213e-05 - val_loss: 2.3482e-05
Epoch 26/512

Epoch 00026: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3463e-05 - val_loss: 2.2573e-05
Epoch 27/512

Epoch 00027: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2601e-05 - val_loss: 2.1804e-05
Epoch 28/512

Epoch 00028: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1946e-05 - val_loss: 2.1304e-05
Epoch 29/512

Epoch 00029: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1399e-05 - val_loss: 2.0639e-05
Epoch 30/512

Epoch 00030: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0676e-05 - val_loss: 1.9910e-05
Epoch 31/512

Epoch 00031: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0012e-05 - val_loss: 1.9307e-05
Epoch 32/512

Epoch 00032: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9415e-05 - val_loss: 1.8784e-05
Epoch 33/512

Epoch 00033: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8872e-05 - val_loss: 1.8158e-05
Epoch 34/512

Epoch 00034: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8211e-05 - val_loss: 1.7579e-05
Epoch 35/512

Epoch 00035: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7673e-05 - val_loss: 1.7072e-05
Epoch 36/512

Epoch 00036: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7151e-05 - val_loss: 1.6521e-05
Epoch 37/512

Epoch 00037: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6582e-05 - val_loss: 1.5973e-05
Epoch 38/512

Epoch 00038: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6062e-05 - val_loss: 1.5484e-05
Epoch 39/512

Epoch 00039: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5556e-05 - val_loss: 1.5014e-05
Epoch 40/512

Epoch 00040: val_loss improved from 0.00002 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5098e-05 - val_loss: 1.4508e-05
Epoch 41/512

Epoch 00041: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4570e-05 - val_loss: 1.4032e-05
Epoch 42/512

Epoch 00042: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4116e-05 - val_loss: 1.3623e-05
Epoch 43/512

Epoch 00043: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3695e-05 - val_loss: 1.3176e-05
Epoch 44/512

Epoch 00044: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3241e-05 - val_loss: 1.2716e-05
Epoch 45/512

Epoch 00045: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2788e-05 - val_loss: 1.2311e-05
Epoch 46/512

Epoch 00046: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2395e-05 - val_loss: 1.1950e-05
Epoch 47/512

Epoch 00047: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2025e-05 - val_loss: 1.1521e-05
Epoch 48/512

Epoch 00048: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1570e-05 - val_loss: 1.1138e-05
Epoch 49/512

Epoch 00049: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1237e-05 - val_loss: 1.0795e-05
Epoch 50/512

Epoch 00050: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0863e-05 - val_loss: 1.0419e-05
Epoch 51/512

Epoch 00051: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0489e-05 - val_loss: 1.0066e-05
Epoch 52/512

Epoch 00052: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0149e-05 - val_loss: 9.7536e-06
Epoch 53/512

Epoch 00053: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.8163e-06 - val_loss: 9.4478e-06
Epoch 54/512

Epoch 00054: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.5105e-06 - val_loss: 9.1150e-06
Epoch 55/512

Epoch 00055: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.1692e-06 - val_loss: 8.7888e-06
Epoch 56/512

Epoch 00056: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.8551e-06 - val_loss: 8.5094e-06
Epoch 57/512

Epoch 00057: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.5821e-06 - val_loss: 8.2267e-06
Epoch 58/512

Epoch 00058: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.2830e-06 - val_loss: 7.9472e-06
Epoch 59/512

Epoch 00059: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.0032e-06 - val_loss: 7.6800e-06
Epoch 60/512

Epoch 00060: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.7419e-06 - val_loss: 7.4124e-06
Epoch 61/512

Epoch 00061: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.4683e-06 - val_loss: 7.1533e-06
Epoch 62/512

Epoch 00062: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.2179e-06 - val_loss: 6.9143e-06
Epoch 63/512

Epoch 00063: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.9707e-06 - val_loss: 6.6837e-06
Epoch 64/512

Epoch 00064: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.7435e-06 - val_loss: 6.4414e-06
Epoch 65/512

Epoch 00065: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.4959e-06 - val_loss: 6.2159e-06
Epoch 66/512

Epoch 00066: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.2777e-06 - val_loss: 6.0147e-06
Epoch 67/512

Epoch 00067: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.0676e-06 - val_loss: 5.8073e-06
Epoch 68/512

Epoch 00068: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.8545e-06 - val_loss: 5.5950e-06
Epoch 69/512

Epoch 00069: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.6446e-06 - val_loss: 5.4061e-06
Epoch 70/512

Epoch 00070: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.4539e-06 - val_loss: 5.2276e-06
Epoch 71/512

Epoch 00071: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.2759e-06 - val_loss: 5.0278e-06
Epoch 72/512

Epoch 00072: val_loss improved from 0.00001 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.0705e-06 - val_loss: 4.8461e-06
Epoch 73/512

Epoch 00073: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.8985e-06 - val_loss: 4.6919e-06
Epoch 74/512

Epoch 00074: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.7428e-06 - val_loss: 4.5183e-06
Epoch 75/512

Epoch 00075: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.5548e-06 - val_loss: 4.3495e-06
Epoch 76/512

Epoch 00076: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.3994e-06 - val_loss: 4.2066e-06
Epoch 77/512

Epoch 00077: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.2521e-06 - val_loss: 4.0567e-06
Epoch 78/512

Epoch 00078: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.0934e-06 - val_loss: 3.9054e-06
Epoch 79/512

Epoch 00079: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.9474e-06 - val_loss: 3.7663e-06
Epoch 80/512

Epoch 00080: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.8117e-06 - val_loss: 3.6307e-06
Epoch 81/512

Epoch 00081: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.6719e-06 - val_loss: 3.4989e-06
Epoch 82/512

Epoch 00082: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.5391e-06 - val_loss: 3.3745e-06
Epoch 83/512

Epoch 00083: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.4159e-06 - val_loss: 3.2489e-06
Epoch 84/512

Epoch 00084: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.2870e-06 - val_loss: 3.1346e-06
Epoch 85/512

Epoch 00085: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1730e-06 - val_loss: 3.0204e-06
Epoch 86/512

Epoch 00086: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.0560e-06 - val_loss: 2.9109e-06
Epoch 87/512

Epoch 00087: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9460e-06 - val_loss: 2.8060e-06
Epoch 88/512

Epoch 00088: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8382e-06 - val_loss: 2.7039e-06
Epoch 89/512

Epoch 00089: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7371e-06 - val_loss: 2.6030e-06
Epoch 90/512

Epoch 00090: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6348e-06 - val_loss: 2.5042e-06
Epoch 91/512

Epoch 00091: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5390e-06 - val_loss: 2.4105e-06
Epoch 92/512

Epoch 00092: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4417e-06 - val_loss: 2.3251e-06
Epoch 93/512

Epoch 00093: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3592e-06 - val_loss: 2.2397e-06
Epoch 94/512

Epoch 00094: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2691e-06 - val_loss: 2.1505e-06
Epoch 95/512

Epoch 00095: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1802e-06 - val_loss: 2.0744e-06
Epoch 96/512

Epoch 00096: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1066e-06 - val_loss: 2.0000e-06
Epoch 97/512

Epoch 00097: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0264e-06 - val_loss: 1.9208e-06
Epoch 98/512

Epoch 00098: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9472e-06 - val_loss: 1.8517e-06
Epoch 99/512

Epoch 00099: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8789e-06 - val_loss: 1.7839e-06
Epoch 100/512

Epoch 00100: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8088e-06 - val_loss: 1.7125e-06
Epoch 101/512

Epoch 00101: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7372e-06 - val_loss: 1.6478e-06
Epoch 102/512

Epoch 00102: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6743e-06 - val_loss: 1.5886e-06
Epoch 103/512

Epoch 00103: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6131e-06 - val_loss: 1.5249e-06
Epoch 104/512

Epoch 00104: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5479e-06 - val_loss: 1.4671e-06
Epoch 105/512

Epoch 00105: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4909e-06 - val_loss: 1.4168e-06
Epoch 106/512

Epoch 00106: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4392e-06 - val_loss: 1.3604e-06
Epoch 107/512

Epoch 00107: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3801e-06 - val_loss: 1.3035e-06
Epoch 108/512

Epoch 00108: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3259e-06 - val_loss: 1.2548e-06
Epoch 109/512

Epoch 00109: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2774e-06 - val_loss: 1.2135e-06
Epoch 110/512

Epoch 00110: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2331e-06 - val_loss: 1.1626e-06
Epoch 111/512

Epoch 00111: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1788e-06 - val_loss: 1.1154e-06
Epoch 112/512

Epoch 00112: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1362e-06 - val_loss: 1.0766e-06
Epoch 113/512

Epoch 00113: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0940e-06 - val_loss: 1.0356e-06
Epoch 114/512

Epoch 00114: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0522e-06 - val_loss: 9.9082e-07
Epoch 115/512

Epoch 00115: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0067e-06 - val_loss: 9.5540e-07
Epoch 116/512

Epoch 00116: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.7397e-07 - val_loss: 9.2046e-07
Epoch 117/512

Epoch 00117: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.3533e-07 - val_loss: 8.7869e-07
Epoch 118/512

Epoch 00118: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.9419e-07 - val_loss: 8.4473e-07
Epoch 119/512

Epoch 00119: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.6288e-07 - val_loss: 8.1577e-07
Epoch 120/512

Epoch 00120: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.2963e-07 - val_loss: 7.8397e-07
Epoch 121/512

Epoch 00121: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.9802e-07 - val_loss: 7.5049e-07
Epoch 122/512

Epoch 00122: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.6390e-07 - val_loss: 7.2013e-07
Epoch 123/512

Epoch 00123: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.3532e-07 - val_loss: 6.9452e-07
Epoch 124/512

Epoch 00124: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.0794e-07 - val_loss: 6.6557e-07
Epoch 125/512

Epoch 00125: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.7770e-07 - val_loss: 6.3850e-07
Epoch 126/512

Epoch 00126: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.5181e-07 - val_loss: 6.1481e-07
Epoch 127/512

Epoch 00127: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.2720e-07 - val_loss: 5.9029e-07
Epoch 128/512

Epoch 00128: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.0206e-07 - val_loss: 5.6462e-07
Epoch 129/512

Epoch 00129: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.7573e-07 - val_loss: 5.4372e-07
Epoch 130/512

Epoch 00130: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.5630e-07 - val_loss: 5.2268e-07
Epoch 131/512

Epoch 00131: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.3315e-07 - val_loss: 4.9997e-07
Epoch 132/512

Epoch 00132: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.1018e-07 - val_loss: 4.8003e-07
Epoch 133/512

Epoch 00133: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.9092e-07 - val_loss: 4.6289e-07
Epoch 134/512

Epoch 00134: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.7259e-07 - val_loss: 4.4384e-07
Epoch 135/512

Epoch 00135: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.5242e-07 - val_loss: 4.2460e-07
Epoch 136/512

Epoch 00136: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.3379e-07 - val_loss: 4.0808e-07
Epoch 137/512

Epoch 00137: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.1744e-07 - val_loss: 3.9227e-07
Epoch 138/512

Epoch 00138: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.0072e-07 - val_loss: 3.7538e-07
Epoch 139/512

Epoch 00139: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.8307e-07 - val_loss: 3.5992e-07
Epoch 140/512

Epoch 00140: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.6878e-07 - val_loss: 3.4701e-07
Epoch 141/512

Epoch 00141: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.5478e-07 - val_loss: 3.3061e-07
Epoch 142/512

Epoch 00142: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3795e-07 - val_loss: 3.1703e-07
Epoch 143/512

Epoch 00143: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.2510e-07 - val_loss: 3.0623e-07
Epoch 144/512

Epoch 00144: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1354e-07 - val_loss: 2.9354e-07
Epoch 145/512

Epoch 00145: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9983e-07 - val_loss: 2.7919e-07
Epoch 146/512

Epoch 00146: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8576e-07 - val_loss: 2.6864e-07
Epoch 147/512

Epoch 00147: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7606e-07 - val_loss: 2.5951e-07
Epoch 148/512

Epoch 00148: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6550e-07 - val_loss: 2.4731e-07
Epoch 149/512

Epoch 00149: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5256e-07 - val_loss: 2.3617e-07
Epoch 150/512

Epoch 00150: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4278e-07 - val_loss: 2.2803e-07
Epoch 151/512

Epoch 00151: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3380e-07 - val_loss: 2.1866e-07
Epoch 152/512

Epoch 00152: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2362e-07 - val_loss: 2.0824e-07
Epoch 153/512

Epoch 00153: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1354e-07 - val_loss: 1.9976e-07
Epoch 154/512

Epoch 00154: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0553e-07 - val_loss: 1.9226e-07
Epoch 155/512

Epoch 00155: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9708e-07 - val_loss: 1.8446e-07
Epoch 156/512

Epoch 00156: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8923e-07 - val_loss: 1.7594e-07
Epoch 157/512

Epoch 00157: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8036e-07 - val_loss: 1.6871e-07
Epoch 158/512

Epoch 00158: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7329e-07 - val_loss: 1.6249e-07
Epoch 159/512

Epoch 00159: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6671e-07 - val_loss: 1.5559e-07
Epoch 160/512

Epoch 00160: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5947e-07 - val_loss: 1.4822e-07
Epoch 161/512

Epoch 00161: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5206e-07 - val_loss: 1.4229e-07
Epoch 162/512

Epoch 00162: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4643e-07 - val_loss: 1.3690e-07
Epoch 163/512

Epoch 00163: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4041e-07 - val_loss: 1.3070e-07
Epoch 164/512

Epoch 00164: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3413e-07 - val_loss: 1.2511e-07
Epoch 165/512

Epoch 00165: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2872e-07 - val_loss: 1.1994e-07
Epoch 166/512

Epoch 00166: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2328e-07 - val_loss: 1.1467e-07
Epoch 167/512

Epoch 00167: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1781e-07 - val_loss: 1.1025e-07
Epoch 168/512

Epoch 00168: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1336e-07 - val_loss: 1.0580e-07
Epoch 169/512

Epoch 00169: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0860e-07 - val_loss: 1.0094e-07
Epoch 170/512

Epoch 00170: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0353e-07 - val_loss: 9.6537e-08
Epoch 171/512

Epoch 00171: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.9313e-08 - val_loss: 9.3003e-08
Epoch 172/512

Epoch 00172: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.5562e-08 - val_loss: 8.8805e-08
Epoch 173/512

Epoch 00173: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.1243e-08 - val_loss: 8.4727e-08
Epoch 174/512

Epoch 00174: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.7069e-08 - val_loss: 8.1335e-08
Epoch 175/512

Epoch 00175: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.3829e-08 - val_loss: 7.8173e-08
Epoch 176/512

Epoch 00176: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.0397e-08 - val_loss: 7.4603e-08
Epoch 177/512

Epoch 00177: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.6655e-08 - val_loss: 7.1278e-08
Epoch 178/512

Epoch 00178: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.3348e-08 - val_loss: 6.8631e-08
Epoch 179/512

Epoch 00179: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.0664e-08 - val_loss: 6.5552e-08
Epoch 180/512

Epoch 00180: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.7377e-08 - val_loss: 6.2576e-08
Epoch 181/512

Epoch 00181: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.4350e-08 - val_loss: 5.9894e-08
Epoch 182/512

Epoch 00182: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.1804e-08 - val_loss: 5.7604e-08
Epoch 183/512

Epoch 00183: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.9351e-08 - val_loss: 5.5072e-08
Epoch 184/512

Epoch 00184: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.6639e-08 - val_loss: 5.2685e-08
Epoch 185/512

Epoch 00185: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.4163e-08 - val_loss: 5.0407e-08
Epoch 186/512

Epoch 00186: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.2005e-08 - val_loss: 4.8383e-08
Epoch 187/512

Epoch 00187: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.9826e-08 - val_loss: 4.6220e-08
Epoch 188/512

Epoch 00188: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.7602e-08 - val_loss: 4.4306e-08
Epoch 189/512

Epoch 00189: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.5665e-08 - val_loss: 4.2408e-08
Epoch 190/512

Epoch 00190: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.3721e-08 - val_loss: 4.0687e-08
Epoch 191/512

Epoch 00191: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.1830e-08 - val_loss: 3.8921e-08
Epoch 192/512

Epoch 00192: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.0092e-08 - val_loss: 3.7243e-08
Epoch 193/512

Epoch 00193: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.8296e-08 - val_loss: 3.5661e-08
Epoch 194/512

Epoch 00194: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.6764e-08 - val_loss: 3.4282e-08
Epoch 195/512

Epoch 00195: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.5356e-08 - val_loss: 3.2711e-08
Epoch 196/512

Epoch 00196: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3575e-08 - val_loss: 3.1229e-08
Epoch 197/512

Epoch 00197: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.2236e-08 - val_loss: 3.0223e-08
Epoch 198/512

Epoch 00198: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1154e-08 - val_loss: 2.8845e-08
Epoch 199/512

Epoch 00199: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9606e-08 - val_loss: 2.7425e-08
Epoch 200/512

Epoch 00200: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8208e-08 - val_loss: 2.6294e-08
Epoch 201/512

Epoch 00201: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7214e-08 - val_loss: 2.5454e-08
Epoch 202/512

Epoch 00202: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6227e-08 - val_loss: 2.4281e-08
Epoch 203/512

Epoch 00203: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4975e-08 - val_loss: 2.3135e-08
Epoch 204/512

Epoch 00204: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3786e-08 - val_loss: 2.2164e-08
Epoch 205/512

Epoch 00205: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2939e-08 - val_loss: 2.1465e-08
Epoch 206/512

Epoch 00206: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2082e-08 - val_loss: 2.0488e-08
Epoch 207/512

Epoch 00207: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1056e-08 - val_loss: 1.9518e-08
Epoch 208/512

Epoch 00208: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0142e-08 - val_loss: 1.8755e-08
Epoch 209/512

Epoch 00209: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9343e-08 - val_loss: 1.8079e-08
Epoch 210/512

Epoch 00210: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8670e-08 - val_loss: 1.7343e-08
Epoch 211/512

Epoch 00211: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7817e-08 - val_loss: 1.6478e-08
Epoch 212/512

Epoch 00212: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7002e-08 - val_loss: 1.5871e-08
Epoch 213/512

Epoch 00213: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6386e-08 - val_loss: 1.5340e-08
Epoch 214/512

Epoch 00214: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5795e-08 - val_loss: 1.4694e-08
Epoch 215/512

Epoch 00215: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5105e-08 - val_loss: 1.3987e-08
Epoch 216/512

Epoch 00216: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4393e-08 - val_loss: 1.3431e-08
Epoch 217/512

Epoch 00217: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3840e-08 - val_loss: 1.3004e-08
Epoch 218/512

Epoch 00218: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3438e-08 - val_loss: 1.2562e-08
Epoch 219/512

Epoch 00219: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2890e-08 - val_loss: 1.1919e-08
Epoch 220/512

Epoch 00220: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2237e-08 - val_loss: 1.1382e-08
Epoch 221/512

Epoch 00221: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1745e-08 - val_loss: 1.1047e-08
Epoch 222/512

Epoch 00222: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1388e-08 - val_loss: 1.0618e-08
Epoch 223/512

Epoch 00223: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0909e-08 - val_loss: 1.0137e-08
Epoch 224/512

Epoch 00224: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0425e-08 - val_loss: 9.7434e-09
Epoch 225/512

Epoch 00225: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0055e-08 - val_loss: 9.4554e-09
Epoch 226/512

Epoch 00226: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.7036e-09 - val_loss: 9.0573e-09
Epoch 227/512

Epoch 00227: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.3120e-09 - val_loss: 8.7117e-09
Epoch 228/512

Epoch 00228: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.9591e-09 - val_loss: 8.3534e-09
Epoch 229/512

Epoch 00229: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.6007e-09 - val_loss: 8.0736e-09
Epoch 230/512

Epoch 00230: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.2958e-09 - val_loss: 7.7405e-09
Epoch 231/512

Epoch 00231: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.9700e-09 - val_loss: 7.4600e-09
Epoch 232/512

Epoch 00232: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.6682e-09 - val_loss: 7.1857e-09
Epoch 233/512

Epoch 00233: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.3671e-09 - val_loss: 6.9149e-09
Epoch 234/512

Epoch 00234: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.1190e-09 - val_loss: 6.6632e-09
Epoch 235/512

Epoch 00235: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.8419e-09 - val_loss: 6.4307e-09
Epoch 236/512

Epoch 00236: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.6187e-09 - val_loss: 6.2235e-09
Epoch 237/512

Epoch 00237: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.3817e-09 - val_loss: 5.9706e-09
Epoch 238/512

Epoch 00238: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.1148e-09 - val_loss: 5.7784e-09
Epoch 239/512

Epoch 00239: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.9568e-09 - val_loss: 5.5885e-09
Epoch 240/512

Epoch 00240: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.6975e-09 - val_loss: 5.3034e-09
Epoch 241/512

Epoch 00241: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.4347e-09 - val_loss: 5.1029e-09
Epoch 242/512

Epoch 00242: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.2545e-09 - val_loss: 4.9939e-09
Epoch 243/512

Epoch 00243: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.1380e-09 - val_loss: 4.8789e-09
Epoch 244/512

Epoch 00244: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.0253e-09 - val_loss: 4.7050e-09
Epoch 245/512

Epoch 00245: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.7951e-09 - val_loss: 4.4473e-09
Epoch 246/512

Epoch 00246: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.5320e-09 - val_loss: 4.2656e-09
Epoch 247/512

Epoch 00247: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.4020e-09 - val_loss: 4.2312e-09
Epoch 248/512

Epoch 00248: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.3676e-09 - val_loss: 4.1314e-09
Epoch 249/512

Epoch 00249: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.2174e-09 - val_loss: 3.9479e-09
Epoch 250/512

Epoch 00250: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.0087e-09 - val_loss: 3.7865e-09
Epoch 251/512

Epoch 00251: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.8885e-09 - val_loss: 3.6773e-09
Epoch 252/512

Epoch 00252: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.7634e-09 - val_loss: 3.5813e-09
Epoch 253/512

Epoch 00253: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.6646e-09 - val_loss: 3.4554e-09
Epoch 254/512

Epoch 00254: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.5216e-09 - val_loss: 3.3191e-09
Epoch 255/512

Epoch 00255: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3880e-09 - val_loss: 3.2135e-09
Epoch 256/512

Epoch 00256: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.2929e-09 - val_loss: 3.1265e-09
Epoch 257/512

Epoch 00257: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.2087e-09 - val_loss: 3.0602e-09
Epoch 258/512

Epoch 00258: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1189e-09 - val_loss: 2.9546e-09
Epoch 259/512

Epoch 00259: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.0178e-09 - val_loss: 2.8744e-09
Epoch 260/512

Epoch 00260: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9269e-09 - val_loss: 2.7478e-09
Epoch 261/512

Epoch 00261: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8042e-09 - val_loss: 2.6437e-09
Epoch 262/512

Epoch 00262: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7092e-09 - val_loss: 2.5838e-09
Epoch 263/512

Epoch 00263: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6575e-09 - val_loss: 2.5521e-09
Epoch 264/512

Epoch 00264: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6073e-09 - val_loss: 2.4744e-09
Epoch 265/512

Epoch 00265: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5133e-09 - val_loss: 2.3833e-09
Epoch 266/512

Epoch 00266: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4337e-09 - val_loss: 2.3071e-09
Epoch 267/512

Epoch 00267: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3409e-09 - val_loss: 2.2079e-09
Epoch 268/512

Epoch 00268: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2634e-09 - val_loss: 2.1605e-09
Epoch 269/512

Epoch 00269: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2123e-09 - val_loss: 2.1265e-09
Epoch 270/512

Epoch 00270: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1855e-09 - val_loss: 2.0945e-09
Epoch 271/512

Epoch 00271: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1297e-09 - val_loss: 2.0082e-09
Epoch 272/512

Epoch 00272: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0446e-09 - val_loss: 1.9462e-09
Epoch 273/512

Epoch 00273: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9688e-09 - val_loss: 1.8539e-09
Epoch 274/512

Epoch 00274: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8972e-09 - val_loss: 1.8245e-09
Epoch 275/512

Epoch 00275: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8664e-09 - val_loss: 1.7901e-09
Epoch 276/512

Epoch 00276: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8269e-09 - val_loss: 1.7611e-09
Epoch 277/512

Epoch 00277: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8016e-09 - val_loss: 1.7286e-09
Epoch 278/512

Epoch 00278: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7516e-09 - val_loss: 1.6531e-09
Epoch 279/512

Epoch 00279: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6770e-09 - val_loss: 1.5903e-09
Epoch 280/512

Epoch 00280: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6238e-09 - val_loss: 1.5589e-09
Epoch 281/512

Epoch 00281: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5968e-09 - val_loss: 1.5433e-09
Epoch 282/512

Epoch 00282: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5739e-09 - val_loss: 1.5111e-09
Epoch 283/512

Epoch 00283: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5353e-09 - val_loss: 1.4601e-09
Epoch 284/512

Epoch 00284: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4873e-09 - val_loss: 1.4161e-09
Epoch 285/512

Epoch 00285: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4302e-09 - val_loss: 1.3693e-09
Epoch 286/512

Epoch 00286: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3899e-09 - val_loss: 1.3394e-09
Epoch 287/512

Epoch 00287: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3623e-09 - val_loss: 1.3020e-09
Epoch 288/512

Epoch 00288: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3208e-09 - val_loss: 1.2645e-09
Epoch 289/512

Epoch 00289: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2895e-09 - val_loss: 1.2443e-09
Epoch 290/512

Epoch 00290: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2675e-09 - val_loss: 1.2300e-09
Epoch 291/512

Epoch 00291: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2499e-09 - val_loss: 1.2039e-09
Epoch 292/512

Epoch 00292: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2307e-09 - val_loss: 1.1691e-09
Epoch 293/512

Epoch 00293: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1791e-09 - val_loss: 1.1186e-09
Epoch 294/512

Epoch 00294: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1311e-09 - val_loss: 1.0809e-09
Epoch 295/512

Epoch 00295: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1017e-09 - val_loss: 1.0789e-09
Epoch 296/512

Epoch 00296: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1048e-09 - val_loss: 1.0673e-09
Epoch 297/512

Epoch 00297: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0838e-09 - val_loss: 1.0350e-09
Epoch 298/512

Epoch 00298: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0571e-09 - val_loss: 1.0229e-09
Epoch 299/512

Epoch 00299: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0413e-09 - val_loss: 1.0026e-09
Epoch 300/512

Epoch 00300: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0223e-09 - val_loss: 9.8019e-10
Epoch 301/512

Epoch 00301: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.9220e-10 - val_loss: 9.5051e-10
Epoch 302/512

Epoch 00302: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.6864e-10 - val_loss: 9.3119e-10
Epoch 303/512

Epoch 00303: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.5053e-10 - val_loss: 9.2043e-10
Epoch 304/512

Epoch 00304: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.3543e-10 - val_loss: 8.9615e-10
Epoch 305/512

Epoch 00305: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.0787e-10 - val_loss: 8.7014e-10
Epoch 306/512

Epoch 00306: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.8425e-10 - val_loss: 8.5174e-10
Epoch 307/512

Epoch 00307: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.6510e-10 - val_loss: 8.3618e-10
Epoch 308/512

Epoch 00308: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.4860e-10 - val_loss: 8.2116e-10
Epoch 309/512

Epoch 00309: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.3038e-10 - val_loss: 8.0696e-10
Epoch 310/512

Epoch 00310: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.1998e-10 - val_loss: 7.8405e-10
Epoch 311/512

Epoch 00311: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.9541e-10 - val_loss: 7.6392e-10
Epoch 312/512

Epoch 00312: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.7827e-10 - val_loss: 7.5572e-10
Epoch 313/512

Epoch 00313: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.6973e-10 - val_loss: 7.4544e-10
Epoch 314/512

Epoch 00314: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.5960e-10 - val_loss: 7.3515e-10
Epoch 315/512

Epoch 00315: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.4262e-10 - val_loss: 7.1524e-10
Epoch 316/512

Epoch 00316: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.2957e-10 - val_loss: 7.1022e-10
Epoch 317/512

Epoch 00317: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.1668e-10 - val_loss: 6.8929e-10
Epoch 318/512

Epoch 00318: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.9549e-10 - val_loss: 6.6726e-10
Epoch 319/512

Epoch 00319: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.7322e-10 - val_loss: 6.4676e-10
Epoch 320/512

Epoch 00320: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.5337e-10 - val_loss: 6.2898e-10
Epoch 321/512

Epoch 00321: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.4308e-10 - val_loss: 6.3183e-10
Epoch 322/512

Epoch 00322: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.3917e-10 - val_loss: 6.2103e-10
Epoch 323/512

Epoch 00323: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.2834e-10 - val_loss: 6.0436e-10
Epoch 324/512

Epoch 00324: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.1837e-10 - val_loss: 6.0233e-10
Epoch 325/512

Epoch 00325: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.0988e-10 - val_loss: 5.9579e-10
Epoch 326/512

Epoch 00326: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.0323e-10 - val_loss: 5.7633e-10
Epoch 327/512

Epoch 00327: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.8378e-10 - val_loss: 5.6152e-10
Epoch 328/512

Epoch 00328: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.6384e-10 - val_loss: 5.5154e-10
Epoch 329/512

Epoch 00329: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.6157e-10 - val_loss: 5.4584e-10
Epoch 330/512

Epoch 00330: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.5226e-10 - val_loss: 5.4172e-10
Epoch 331/512

Epoch 00331: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.5002e-10 - val_loss: 5.3237e-10
Epoch 332/512

Epoch 00332: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.4007e-10 - val_loss: 5.2602e-10
Epoch 333/512

Epoch 00333: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.3729e-10 - val_loss: 5.1879e-10
Epoch 334/512

Epoch 00334: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.2277e-10 - val_loss: 4.9878e-10
Epoch 335/512

Epoch 00335: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.0174e-10 - val_loss: 4.7759e-10
Epoch 336/512

Epoch 00336: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.8066e-10 - val_loss: 4.6620e-10
Epoch 337/512

Epoch 00337: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7510e-10 - val_loss: 4.7244e-10
Epoch 338/512

Epoch 00338: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8549e-10 - val_loss: 4.7823e-10
Epoch 339/512

Epoch 00339: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8091e-10 - val_loss: 4.6621e-10
Epoch 340/512

Epoch 00340: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.6796e-10 - val_loss: 4.4357e-10
Epoch 341/512

Epoch 00341: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.4850e-10 - val_loss: 4.3593e-10
Epoch 342/512

Epoch 00342: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.3786e-10 - val_loss: 4.1888e-10
Epoch 343/512

Epoch 00343: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.2413e-10 - val_loss: 4.1527e-10
Epoch 344/512

Epoch 00344: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2683e-10 - val_loss: 4.2489e-10
Epoch 345/512

Epoch 00345: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3634e-10 - val_loss: 4.3287e-10
Epoch 346/512

Epoch 00346: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4305e-10 - val_loss: 4.3422e-10
Epoch 347/512

Epoch 00347: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.3256e-10 - val_loss: 4.1105e-10
Epoch 348/512

Epoch 00348: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.1484e-10 - val_loss: 4.0661e-10
Epoch 349/512

Epoch 00349: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.0690e-10 - val_loss: 3.9214e-10
Epoch 350/512

Epoch 00350: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.9433e-10 - val_loss: 3.7939e-10
Epoch 351/512

Epoch 00351: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.8093e-10 - val_loss: 3.7548e-10
Epoch 352/512

Epoch 00352: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.8213e-10 - val_loss: 3.7356e-10
Epoch 353/512

Epoch 00353: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.8035e-10 - val_loss: 3.6990e-10
Epoch 354/512

Epoch 00354: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7693e-10 - val_loss: 3.7452e-10
Epoch 355/512

Epoch 00355: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.7661e-10 - val_loss: 3.6129e-10
Epoch 356/512

Epoch 00356: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.5829e-10 - val_loss: 3.3935e-10
Epoch 357/512

Epoch 00357: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.4026e-10 - val_loss: 3.2827e-10
Epoch 358/512

Epoch 00358: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.2898e-10 - val_loss: 3.2499e-10
Epoch 359/512

Epoch 00359: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3938e-10 - val_loss: 3.3675e-10
Epoch 360/512

Epoch 00360: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4566e-10 - val_loss: 3.5021e-10
Epoch 361/512

Epoch 00361: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5803e-10 - val_loss: 3.5034e-10
Epoch 362/512

Epoch 00362: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4924e-10 - val_loss: 3.3021e-10
Epoch 363/512

Epoch 00363: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3207e-10 - val_loss: 3.1918e-10
Epoch 364/512

Epoch 00364: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1961e-10 - val_loss: 3.1482e-10
Epoch 365/512

Epoch 00365: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1508e-10 - val_loss: 3.0343e-10
Epoch 366/512

Epoch 00366: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.0572e-10 - val_loss: 2.9584e-10
Epoch 367/512

Epoch 00367: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9580e-10 - val_loss: 2.8732e-10
Epoch 368/512

Epoch 00368: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9638e-10 - val_loss: 2.9338e-10
Epoch 369/512

Epoch 00369: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9458e-10 - val_loss: 2.8983e-10
Epoch 370/512

Epoch 00370: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9904e-10 - val_loss: 2.9588e-10
Epoch 371/512

Epoch 00371: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9752e-10 - val_loss: 2.8802e-10
Epoch 372/512

Epoch 00372: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9164e-10 - val_loss: 2.8215e-10
Epoch 373/512

Epoch 00373: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8451e-10 - val_loss: 2.7660e-10
Epoch 374/512

Epoch 00374: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7809e-10 - val_loss: 2.7381e-10
Epoch 375/512

Epoch 00375: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7487e-10 - val_loss: 2.6790e-10
Epoch 376/512

Epoch 00376: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6914e-10 - val_loss: 2.5634e-10
Epoch 377/512

Epoch 00377: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6156e-10 - val_loss: 2.5816e-10
Epoch 378/512

Epoch 00378: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6010e-10 - val_loss: 2.5955e-10
Epoch 379/512

Epoch 00379: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6290e-10 - val_loss: 2.5776e-10
Epoch 380/512

Epoch 00380: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6012e-10 - val_loss: 2.5413e-10
Epoch 381/512

Epoch 00381: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5628e-10 - val_loss: 2.4824e-10
Epoch 382/512

Epoch 00382: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5188e-10 - val_loss: 2.4624e-10
Epoch 383/512

Epoch 00383: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4603e-10 - val_loss: 2.3820e-10
Epoch 384/512

Epoch 00384: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3774e-10 - val_loss: 2.3226e-10
Epoch 385/512

Epoch 00385: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3727e-10 - val_loss: 2.3537e-10
Epoch 386/512

Epoch 00386: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3680e-10 - val_loss: 2.3690e-10
Epoch 387/512

Epoch 00387: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4352e-10 - val_loss: 2.4070e-10
Epoch 388/512

Epoch 00388: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4292e-10 - val_loss: 2.3389e-10
Epoch 389/512

Epoch 00389: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3747e-10 - val_loss: 2.3375e-10
Epoch 390/512

Epoch 00390: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3207e-10 - val_loss: 2.2955e-10
Epoch 391/512

Epoch 00391: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2962e-10 - val_loss: 2.1701e-10
Epoch 392/512

Epoch 00392: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1460e-10 - val_loss: 2.0916e-10
Epoch 393/512

Epoch 00393: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1082e-10 - val_loss: 2.0837e-10
Epoch 394/512

Epoch 00394: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1133e-10 - val_loss: 2.1034e-10
Epoch 395/512

Epoch 00395: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1307e-10 - val_loss: 2.1557e-10
Epoch 396/512

Epoch 00396: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1400e-10 - val_loss: 2.0320e-10
Epoch 397/512

Epoch 00397: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0760e-10 - val_loss: 2.0283e-10
Epoch 398/512

Epoch 00398: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0392e-10 - val_loss: 2.0051e-10
Epoch 399/512

Epoch 00399: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0585e-10 - val_loss: 2.0374e-10
Epoch 400/512

Epoch 00400: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0513e-10 - val_loss: 1.9902e-10
Epoch 401/512

Epoch 00401: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0029e-10 - val_loss: 1.9961e-10
Epoch 402/512

Epoch 00402: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9822e-10 - val_loss: 1.9346e-10
Epoch 403/512

Epoch 00403: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9518e-10 - val_loss: 1.9433e-10
Epoch 404/512

Epoch 00404: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9579e-10 - val_loss: 1.9384e-10
Epoch 405/512

Epoch 00405: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9505e-10 - val_loss: 1.9279e-10
Epoch 406/512

Epoch 00406: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9025e-10 - val_loss: 1.8080e-10
Epoch 407/512

Epoch 00407: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8294e-10 - val_loss: 1.7586e-10
Epoch 408/512

Epoch 00408: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7864e-10 - val_loss: 1.7319e-10
Epoch 409/512

Epoch 00409: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7656e-10 - val_loss: 1.7548e-10
Epoch 410/512

Epoch 00410: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7951e-10 - val_loss: 1.8105e-10
Epoch 411/512

Epoch 00411: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8315e-10 - val_loss: 1.7903e-10
Epoch 412/512

Epoch 00412: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8225e-10 - val_loss: 1.8218e-10
Epoch 413/512

Epoch 00413: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8313e-10 - val_loss: 1.8176e-10
Epoch 414/512

Epoch 00414: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8075e-10 - val_loss: 1.7533e-10
Epoch 415/512

Epoch 00415: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7225e-10 - val_loss: 1.6204e-10
Epoch 416/512

Epoch 00416: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6342e-10 - val_loss: 1.6093e-10
Epoch 417/512

Epoch 00417: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6294e-10 - val_loss: 1.6416e-10
Epoch 418/512

Epoch 00418: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6379e-10 - val_loss: 1.6174e-10
Epoch 419/512

Epoch 00419: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6152e-10 - val_loss: 1.5799e-10
Epoch 420/512

Epoch 00420: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5862e-10 - val_loss: 1.5760e-10
Epoch 421/512

Epoch 00421: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6000e-10 - val_loss: 1.5843e-10
Epoch 422/512

Epoch 00422: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5894e-10 - val_loss: 1.5358e-10
Epoch 423/512

Epoch 00423: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5516e-10 - val_loss: 1.5025e-10
Epoch 424/512

Epoch 00424: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5339e-10 - val_loss: 1.5517e-10
Epoch 425/512

Epoch 00425: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5616e-10 - val_loss: 1.5475e-10
Epoch 426/512

Epoch 00426: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5231e-10 - val_loss: 1.5020e-10
Epoch 427/512

Epoch 00427: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5494e-10 - val_loss: 1.4936e-10
Epoch 428/512

Epoch 00428: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5005e-10 - val_loss: 1.4860e-10
Epoch 429/512

Epoch 00429: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5148e-10 - val_loss: 1.5067e-10
Epoch 430/512

Epoch 00430: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4977e-10 - val_loss: 1.4653e-10
Epoch 431/512

Epoch 00431: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4718e-10 - val_loss: 1.4394e-10
Epoch 432/512

Epoch 00432: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4163e-10 - val_loss: 1.3764e-10
Epoch 433/512

Epoch 00433: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3736e-10 - val_loss: 1.3432e-10
Epoch 434/512

Epoch 00434: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3571e-10 - val_loss: 1.3225e-10
Epoch 435/512

Epoch 00435: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3277e-10 - val_loss: 1.2522e-10
Epoch 436/512

Epoch 00436: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2848e-10 - val_loss: 1.3094e-10
Epoch 437/512

Epoch 00437: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3015e-10 - val_loss: 1.2687e-10
Epoch 438/512

Epoch 00438: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2878e-10 - val_loss: 1.2405e-10
Epoch 439/512

Epoch 00439: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2730e-10 - val_loss: 1.2972e-10
Epoch 440/512

Epoch 00440: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3077e-10 - val_loss: 1.2976e-10
Epoch 441/512

Epoch 00441: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3376e-10 - val_loss: 1.3730e-10
Epoch 442/512

Epoch 00442: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3892e-10 - val_loss: 1.3485e-10
Epoch 443/512

Epoch 00443: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3602e-10 - val_loss: 1.3124e-10
Epoch 444/512

Epoch 00444: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3154e-10 - val_loss: 1.2475e-10
Epoch 445/512

Epoch 00445: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2482e-10 - val_loss: 1.1990e-10
Epoch 446/512

Epoch 00446: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1929e-10 - val_loss: 1.1715e-10
Epoch 447/512

Epoch 00447: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1607e-10 - val_loss: 1.1475e-10
Epoch 448/512

Epoch 00448: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1787e-10 - val_loss: 1.1464e-10
Epoch 449/512

Epoch 00449: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1765e-10 - val_loss: 1.2057e-10
Epoch 450/512

Epoch 00450: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2401e-10 - val_loss: 1.2036e-10
Epoch 451/512

Epoch 00451: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1967e-10 - val_loss: 1.1333e-10
Epoch 452/512

Epoch 00452: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1295e-10 - val_loss: 1.1369e-10
Epoch 453/512

Epoch 00453: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1381e-10 - val_loss: 1.0932e-10
Epoch 454/512

Epoch 00454: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0945e-10 - val_loss: 1.0883e-10
Epoch 455/512

Epoch 00455: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1223e-10 - val_loss: 1.1325e-10
Epoch 456/512

Epoch 00456: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1764e-10 - val_loss: 1.2156e-10
Epoch 457/512

Epoch 00457: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2161e-10 - val_loss: 1.1710e-10
Epoch 458/512

Epoch 00458: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1621e-10 - val_loss: 1.1195e-10
Epoch 459/512

Epoch 00459: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1188e-10 - val_loss: 1.0924e-10
Epoch 460/512

Epoch 00460: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0974e-10 - val_loss: 1.0643e-10
Epoch 461/512

Epoch 00461: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0570e-10 - val_loss: 1.0688e-10
Epoch 462/512

Epoch 00462: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0919e-10 - val_loss: 1.0899e-10
Epoch 463/512

Epoch 00463: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0757e-10 - val_loss: 1.0661e-10
Epoch 464/512

Epoch 00464: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0973e-10 - val_loss: 1.0860e-10
Epoch 465/512

Epoch 00465: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0702e-10 - val_loss: 1.0638e-10
Epoch 466/512

Epoch 00466: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0791e-10 - val_loss: 1.0458e-10
Epoch 467/512

Epoch 00467: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0404e-10 - val_loss: 1.0346e-10
Epoch 468/512

Epoch 00468: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0186e-10 - val_loss: 9.7807e-11
Epoch 469/512

Epoch 00469: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.8945e-11 - val_loss: 9.4298e-11
Epoch 470/512

Epoch 00470: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.5158e-11 - val_loss: 9.4300e-11
Epoch 471/512

Epoch 00471: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.3771e-11 - val_loss: 9.2555e-11
Epoch 472/512

Epoch 00472: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.4905e-11 - val_loss: 9.7490e-11
Epoch 473/512

Epoch 00473: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.8913e-11 - val_loss: 9.4540e-11
Epoch 474/512

Epoch 00474: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.3578e-11 - val_loss: 9.3250e-11
Epoch 475/512

Epoch 00475: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.6434e-11 - val_loss: 9.3941e-11
Epoch 476/512

Epoch 00476: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.3051e-11 - val_loss: 9.2401e-11
Epoch 477/512

Epoch 00477: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.2080e-11 - val_loss: 8.8828e-11
Epoch 478/512

Epoch 00478: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.9246e-11 - val_loss: 8.9407e-11
Epoch 479/512

Epoch 00479: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.9333e-11 - val_loss: 8.8959e-11
Epoch 480/512

Epoch 00480: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.0418e-11 - val_loss: 8.9469e-11
Epoch 481/512

Epoch 00481: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.7692e-11 - val_loss: 8.8073e-11
Epoch 482/512

Epoch 00482: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.0367e-11 - val_loss: 9.1444e-11
Epoch 483/512

Epoch 00483: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.3558e-11 - val_loss: 9.6142e-11
Epoch 484/512

Epoch 00484: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.4832e-11 - val_loss: 9.1544e-11
Epoch 485/512

Epoch 00485: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.1894e-11 - val_loss: 8.8665e-11
Epoch 486/512

Epoch 00486: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.8615e-11 - val_loss: 8.7521e-11
Epoch 487/512

Epoch 00487: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.7931e-11 - val_loss: 8.4705e-11
Epoch 488/512

Epoch 00488: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.5408e-11 - val_loss: 8.5427e-11
Epoch 489/512

Epoch 00489: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.4982e-11 - val_loss: 8.1673e-11
Epoch 490/512

Epoch 00490: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.1872e-11 - val_loss: 8.2590e-11
Epoch 491/512

Epoch 00491: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.4182e-11 - val_loss: 8.1062e-11
Epoch 492/512

Epoch 00492: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.1330e-11 - val_loss: 7.9672e-11
Epoch 493/512

Epoch 00493: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.7444e-11 - val_loss: 7.3776e-11
Epoch 494/512

Epoch 00494: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.5123e-11 - val_loss: 7.6041e-11
Epoch 495/512

Epoch 00495: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.7581e-11 - val_loss: 7.4794e-11
Epoch 496/512

Epoch 00496: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.5058e-11 - val_loss: 7.6754e-11
Epoch 497/512

Epoch 00497: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8804e-11 - val_loss: 7.9603e-11
Epoch 498/512

Epoch 00498: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.7917e-11 - val_loss: 7.7101e-11
Epoch 499/512

Epoch 00499: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.7659e-11 - val_loss: 7.7890e-11
Epoch 500/512

Epoch 00500: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8995e-11 - val_loss: 7.4906e-11
Epoch 501/512

Epoch 00501: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.5341e-11 - val_loss: 7.5710e-11
Epoch 502/512

Epoch 00502: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8164e-11 - val_loss: 7.9334e-11
Epoch 503/512

Epoch 00503: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.6837e-11 - val_loss: 7.3374e-11
Epoch 504/512

Epoch 00504: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.5388e-11 - val_loss: 7.7442e-11
Epoch 505/512

Epoch 00505: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8759e-11 - val_loss: 7.6544e-11
Epoch 506/512

Epoch 00506: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.6670e-11 - val_loss: 7.6221e-11
Epoch 507/512

Epoch 00507: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.6041e-11 - val_loss: 7.3294e-11
Epoch 508/512

Epoch 00508: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.2056e-11 - val_loss: 7.0244e-11
Epoch 509/512

Epoch 00509: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.0701e-11 - val_loss: 6.6560e-11
Epoch 510/512

Epoch 00510: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.7954e-11 - val_loss: 6.9443e-11
Epoch 511/512

Epoch 00511: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.1506e-11 - val_loss: 7.1802e-11
Epoch 512/512

Epoch 00512: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.3375e-11 - val_loss: 7.4662e-11
Train on 512 samples, validate on 512 samples
Epoch 1/512
512/512 - 1s - loss: 0.0402 - val_loss: 0.0091
Epoch 2/512
512/512 - 0s - loss: 0.0212 - val_loss: 0.0059
Epoch 3/512
512/512 - 0s - loss: 0.0163 - val_loss: 0.0036
Epoch 4/512
512/512 - 0s - loss: 0.0113 - val_loss: 0.0015
Epoch 5/512
512/512 - 0s - loss: 0.0064 - val_loss: 5.4869e-04
Epoch 6/512
512/512 - 0s - loss: 0.0039 - val_loss: 3.5236e-04
Epoch 7/512
512/512 - 0s - loss: 0.0024 - val_loss: 4.3196e-04
Epoch 8/512
512/512 - 0s - loss: 0.0018 - val_loss: 4.0518e-04
Epoch 9/512
512/512 - 0s - loss: 0.0013 - val_loss: 3.7162e-04
Epoch 10/512
512/512 - 0s - loss: 0.0010 - val_loss: 3.5811e-04
Epoch 11/512
512/512 - 0s - loss: 7.6939e-04 - val_loss: 3.4557e-04
Epoch 12/512
512/512 - 0s - loss: 5.8181e-04 - val_loss: 3.5115e-04
Epoch 13/512
512/512 - 0s - loss: 4.3509e-04 - val_loss: 3.9196e-04
Epoch 14/512
512/512 - 0s - loss: 3.4561e-04 - val_loss: 6.4456e-04
Epoch 15/512
512/512 - 0s - loss: 3.5004e-04 - val_loss: 5.0225e-04
Epoch 16/512
512/512 - 0s - loss: 2.6409e-04 - val_loss: 4.3981e-04
Epoch 17/512
512/512 - 0s - loss: 2.0137e-04 - val_loss: 3.7191e-04
Epoch 18/512
512/512 - 0s - loss: 1.6722e-04 - val_loss: 3.2479e-04
Epoch 19/512
512/512 - 0s - loss: 1.4353e-04 - val_loss: 2.7115e-04
Epoch 20/512
512/512 - 0s - loss: 1.2077e-04 - val_loss: 2.3016e-04
Epoch 21/512
512/512 - 0s - loss: 1.0893e-04 - val_loss: 1.8536e-04
Epoch 22/512
512/512 - 0s - loss: 9.4778e-05 - val_loss: 1.5221e-04
Epoch 23/512
512/512 - 0s - loss: 8.4429e-05 - val_loss: 1.2881e-04
Epoch 24/512
512/512 - 0s - loss: 7.9983e-05 - val_loss: 1.0715e-04
Epoch 25/512
512/512 - 0s - loss: 7.6272e-05 - val_loss: 8.8485e-05
Epoch 26/512
512/512 - 0s - loss: 6.6487e-05 - val_loss: 7.7327e-05
Epoch 27/512
512/512 - 0s - loss: 6.4413e-05 - val_loss: 7.0524e-05
Epoch 28/512
512/512 - 0s - loss: 6.3129e-05 - val_loss: 6.6038e-05
Epoch 29/512
512/512 - 0s - loss: 5.7221e-05 - val_loss: 6.4301e-05
Epoch 30/512
512/512 - 0s - loss: 5.3614e-05 - val_loss: 6.5235e-05
Epoch 31/512
512/512 - 0s - loss: 5.2840e-05 - val_loss: 6.8717e-05
Epoch 32/512
512/512 - 0s - loss: 4.9796e-05 - val_loss: 7.2467e-05
Epoch 33/512
512/512 - 0s - loss: 4.6304e-05 - val_loss: 7.6589e-05
Epoch 34/512
512/512 - 0s - loss: 4.4545e-05 - val_loss: 8.5691e-05
Epoch 35/512
512/512 - 0s - loss: 4.2934e-05 - val_loss: 9.2471e-05
Epoch 36/512
512/512 - 0s - loss: 3.9632e-05 - val_loss: 9.7887e-05
Epoch 37/512
512/512 - 0s - loss: 3.7536e-05 - val_loss: 1.0707e-04
Epoch 38/512
512/512 - 0s - loss: 3.6773e-05 - val_loss: 1.1995e-04
Epoch 39/512
512/512 - 0s - loss: 3.4036e-05 - val_loss: 1.2606e-04
Epoch 40/512
512/512 - 0s - loss: 3.1236e-05 - val_loss: 1.3476e-04
Epoch 41/512
512/512 - 0s - loss: 3.0076e-05 - val_loss: 1.4432e-04
Epoch 42/512
512/512 - 0s - loss: 2.8328e-05 - val_loss: 1.5323e-04
Epoch 43/512
512/512 - 0s - loss: 2.6220e-05 - val_loss: 1.6030e-04
Epoch 44/512
512/512 - 0s - loss: 2.4565e-05 - val_loss: 1.7018e-04
Epoch 45/512
512/512 - 0s - loss: 2.3260e-05 - val_loss: 1.7803e-04
Epoch 46/512
512/512 - 0s - loss: 2.1219e-05 - val_loss: 1.8075e-04
Epoch 47/512
512/512 - 0s - loss: 1.9643e-05 - val_loss: 1.9071e-04
Epoch 48/512
512/512 - 0s - loss: 1.8630e-05 - val_loss: 1.9569e-04
Epoch 49/512
512/512 - 0s - loss: 1.7013e-05 - val_loss: 1.9908e-04
Epoch 50/512
512/512 - 0s - loss: 1.5753e-05 - val_loss: 2.0438e-04
Epoch 51/512
512/512 - 0s - loss: 1.4778e-05 - val_loss: 2.0414e-04
Epoch 52/512
512/512 - 0s - loss: 1.3427e-05 - val_loss: 2.0513e-04
Epoch 53/512
512/512 - 0s - loss: 1.2384e-05 - val_loss: 2.0484e-04
Epoch 54/512
512/512 - 0s - loss: 1.1537e-05 - val_loss: 2.0682e-04
Epoch 55/512
512/512 - 0s - loss: 1.0700e-05 - val_loss: 2.0546e-04
Epoch 56/512
512/512 - 0s - loss: 9.8482e-06 - val_loss: 2.0143e-04
Epoch 57/512
512/512 - 0s - loss: 9.1529e-06 - val_loss: 2.0085e-04
Epoch 58/512
512/512 - 0s - loss: 8.3793e-06 - val_loss: 1.9575e-04
Epoch 59/512
512/512 - 0s - loss: 7.7208e-06 - val_loss: 1.9504e-04
Epoch 60/512
512/512 - 0s - loss: 7.2700e-06 - val_loss: 1.9361e-04
Epoch 61/512
512/512 - 0s - loss: 6.7757e-06 - val_loss: 1.8845e-04
Epoch 62/512
512/512 - 0s - loss: 6.2024e-06 - val_loss: 1.8394e-04
Epoch 63/512
512/512 - 0s - loss: 5.7587e-06 - val_loss: 1.8111e-04
Epoch 64/512
512/512 - 0s - loss: 5.4353e-06 - val_loss: 1.7605e-04
Epoch 65/512
512/512 - 0s - loss: 5.0231e-06 - val_loss: 1.6911e-04
Epoch 66/512
512/512 - 0s - loss: 4.6742e-06 - val_loss: 1.6470e-04
Epoch 67/512
512/512 - 0s - loss: 4.3732e-06 - val_loss: 1.6105e-04
Epoch 68/512
512/512 - 0s - loss: 4.0886e-06 - val_loss: 1.5469e-04
Epoch 69/512
512/512 - 0s - loss: 3.8282e-06 - val_loss: 1.5428e-04
Epoch 70/512
512/512 - 0s - loss: 3.6149e-06 - val_loss: 1.4734e-04
Epoch 71/512
512/512 - 0s - loss: 3.3784e-06 - val_loss: 1.4494e-04
Epoch 72/512
512/512 - 0s - loss: 3.1805e-06 - val_loss: 1.3771e-04
Epoch 73/512
512/512 - 0s - loss: 2.9730e-06 - val_loss: 1.3349e-04
Epoch 74/512
512/512 - 0s - loss: 2.8052e-06 - val_loss: 1.3152e-04
Epoch 75/512
512/512 - 0s - loss: 2.6707e-06 - val_loss: 1.2864e-04
Epoch 76/512
512/512 - 0s - loss: 2.5249e-06 - val_loss: 1.2279e-04
Epoch 77/512
512/512 - 0s - loss: 2.3730e-06 - val_loss: 1.1719e-04
Epoch 78/512
512/512 - 0s - loss: 2.2544e-06 - val_loss: 1.1709e-04
Epoch 79/512
512/512 - 0s - loss: 2.1495e-06 - val_loss: 1.1479e-04
Epoch 80/512
512/512 - 0s - loss: 2.0324e-06 - val_loss: 1.0792e-04
Epoch 81/512
512/512 - 0s - loss: 1.9261e-06 - val_loss: 1.0316e-04
Epoch 82/512
512/512 - 0s - loss: 1.8354e-06 - val_loss: 1.0026e-04
Epoch 83/512
512/512 - 0s - loss: 1.7625e-06 - val_loss: 1.0303e-04
Epoch 84/512
512/512 - 0s - loss: 1.7119e-06 - val_loss: 9.6580e-05
Epoch 85/512
512/512 - 0s - loss: 1.5922e-06 - val_loss: 9.1651e-05
Epoch 86/512
512/512 - 0s - loss: 1.5225e-06 - val_loss: 9.0246e-05
Epoch 87/512
512/512 - 0s - loss: 1.4693e-06 - val_loss: 9.0124e-05
Epoch 88/512
512/512 - 0s - loss: 1.4331e-06 - val_loss: 8.6616e-05
Epoch 89/512
512/512 - 0s - loss: 1.3509e-06 - val_loss: 7.9642e-05
Epoch 90/512
512/512 - 0s - loss: 1.2936e-06 - val_loss: 7.9145e-05
Epoch 91/512
512/512 - 0s - loss: 1.2574e-06 - val_loss: 8.3393e-05
Epoch 92/512
512/512 - 0s - loss: 1.2345e-06 - val_loss: 7.7483e-05
Epoch 93/512
512/512 - 0s - loss: 1.1673e-06 - val_loss: 7.2720e-05
Epoch 94/512
512/512 - 0s - loss: 1.1188e-06 - val_loss: 7.2066e-05
Epoch 95/512
512/512 - 0s - loss: 1.0909e-06 - val_loss: 7.4626e-05
Epoch 96/512
512/512 - 0s - loss: 1.0596e-06 - val_loss: 6.7674e-05
Epoch 97/512
512/512 - 0s - loss: 1.0155e-06 - val_loss: 6.8007e-05
Epoch 98/512
512/512 - 0s - loss: 9.9110e-07 - val_loss: 6.7301e-05
Epoch 99/512
512/512 - 0s - loss: 9.6361e-07 - val_loss: 6.5647e-05
Epoch 100/512
512/512 - 0s - loss: 9.3310e-07 - val_loss: 6.2011e-05
Epoch 101/512
512/512 - 0s - loss: 8.9882e-07 - val_loss: 6.0085e-05
Epoch 102/512
512/512 - 0s - loss: 8.7324e-07 - val_loss: 5.9395e-05
Epoch 103/512
512/512 - 0s - loss: 8.5557e-07 - val_loss: 6.1926e-05
Epoch 104/512
512/512 - 0s - loss: 8.3837e-07 - val_loss: 5.7523e-05
Epoch 105/512
512/512 - 0s - loss: 8.0666e-07 - val_loss: 5.5389e-05
Epoch 106/512
512/512 - 0s - loss: 7.8467e-07 - val_loss: 5.4707e-05
Epoch 107/512
512/512 - 0s - loss: 7.7040e-07 - val_loss: 5.5483e-05
Epoch 108/512
512/512 - 0s - loss: 7.5240e-07 - val_loss: 5.3792e-05
Epoch 109/512
512/512 - 0s - loss: 7.3343e-07 - val_loss: 5.2078e-05
Epoch 110/512
512/512 - 0s - loss: 7.1305e-07 - val_loss: 4.9866e-05
Epoch 111/512
512/512 - 0s - loss: 6.9643e-07 - val_loss: 4.9679e-05
Epoch 112/512
512/512 - 0s - loss: 6.8305e-07 - val_loss: 4.9893e-05
Epoch 113/512
512/512 - 0s - loss: 6.7396e-07 - val_loss: 4.8818e-05
Epoch 114/512
512/512 - 0s - loss: 6.5217e-07 - val_loss: 4.5643e-05
Epoch 115/512
512/512 - 0s - loss: 6.3884e-07 - val_loss: 4.6676e-05
Epoch 116/512
512/512 - 0s - loss: 6.2572e-07 - val_loss: 4.4976e-05
Epoch 117/512
512/512 - 0s - loss: 6.1369e-07 - val_loss: 4.6346e-05
Epoch 118/512
512/512 - 0s - loss: 6.0301e-07 - val_loss: 4.3743e-05
Epoch 119/512
512/512 - 0s - loss: 5.8920e-07 - val_loss: 4.1740e-05
Epoch 120/512
512/512 - 0s - loss: 5.8215e-07 - val_loss: 4.0329e-05
Epoch 121/512
512/512 - 0s - loss: 5.7107e-07 - val_loss: 4.0102e-05
Epoch 122/512
512/512 - 0s - loss: 5.5842e-07 - val_loss: 3.9801e-05
Epoch 123/512
512/512 - 0s - loss: 5.4797e-07 - val_loss: 3.9882e-05
Epoch 124/512
512/512 - 0s - loss: 5.3841e-07 - val_loss: 3.8505e-05
Epoch 125/512
512/512 - 0s - loss: 5.2918e-07 - val_loss: 3.8575e-05
Epoch 126/512
512/512 - 0s - loss: 5.2014e-07 - val_loss: 3.9069e-05
Epoch 127/512
512/512 - 0s - loss: 5.1162e-07 - val_loss: 3.8497e-05
Epoch 128/512
512/512 - 0s - loss: 5.0453e-07 - val_loss: 3.8496e-05
Epoch 129/512
512/512 - 0s - loss: 4.9814e-07 - val_loss: 3.8533e-05
Epoch 130/512
512/512 - 0s - loss: 4.8851e-07 - val_loss: 3.6943e-05
Epoch 131/512
512/512 - 0s - loss: 4.8031e-07 - val_loss: 3.6242e-05
Epoch 132/512
512/512 - 0s - loss: 4.7287e-07 - val_loss: 3.5398e-05
Epoch 133/512
512/512 - 0s - loss: 4.6638e-07 - val_loss: 3.5833e-05
Epoch 134/512
512/512 - 0s - loss: 4.6077e-07 - val_loss: 3.5376e-05
Epoch 135/512
512/512 - 0s - loss: 4.5278e-07 - val_loss: 3.4546e-05
Epoch 136/512
512/512 - 0s - loss: 4.4613e-07 - val_loss: 3.3655e-05
Epoch 137/512
512/512 - 0s - loss: 4.4060e-07 - val_loss: 3.2233e-05
Epoch 138/512
512/512 - 0s - loss: 4.3462e-07 - val_loss: 3.3150e-05
Epoch 139/512
512/512 - 0s - loss: 4.2816e-07 - val_loss: 3.2507e-05
Epoch 140/512
512/512 - 0s - loss: 4.2252e-07 - val_loss: 3.2517e-05
Epoch 141/512
512/512 - 0s - loss: 4.1702e-07 - val_loss: 3.2521e-05
Epoch 142/512
512/512 - 0s - loss: 4.1223e-07 - val_loss: 3.2496e-05
Epoch 143/512
512/512 - 0s - loss: 4.0847e-07 - val_loss: 3.1877e-05
Epoch 144/512
512/512 - 0s - loss: 4.0149e-07 - val_loss: 3.0364e-05
Epoch 145/512
512/512 - 0s - loss: 3.9691e-07 - val_loss: 3.0055e-05
Epoch 146/512
512/512 - 0s - loss: 3.9236e-07 - val_loss: 2.9763e-05
Epoch 147/512
512/512 - 0s - loss: 3.8735e-07 - val_loss: 2.9456e-05
Epoch 148/512
512/512 - 0s - loss: 3.8256e-07 - val_loss: 2.9068e-05
Epoch 149/512
512/512 - 0s - loss: 3.7809e-07 - val_loss: 2.8978e-05
Epoch 150/512
512/512 - 0s - loss: 3.7374e-07 - val_loss: 2.8678e-05
Epoch 151/512
512/512 - 0s - loss: 3.6978e-07 - val_loss: 2.9861e-05
Epoch 152/512
512/512 - 0s - loss: 3.6696e-07 - val_loss: 2.8838e-05
Epoch 153/512
512/512 - 0s - loss: 3.6143e-07 - val_loss: 2.8049e-05
Epoch 154/512
512/512 - 0s - loss: 3.5765e-07 - val_loss: 2.7680e-05
Epoch 155/512
512/512 - 0s - loss: 3.5372e-07 - val_loss: 2.7426e-05
Epoch 156/512
512/512 - 0s - loss: 3.5006e-07 - val_loss: 2.7917e-05
Epoch 157/512
512/512 - 0s - loss: 3.4688e-07 - val_loss: 2.7782e-05
Epoch 158/512
512/512 - 0s - loss: 3.4283e-07 - val_loss: 2.6737e-05
Epoch 159/512
512/512 - 0s - loss: 3.3928e-07 - val_loss: 2.7039e-05
Epoch 160/512
512/512 - 0s - loss: 3.3598e-07 - val_loss: 2.6663e-05
Epoch 161/512
512/512 - 0s - loss: 3.3272e-07 - val_loss: 2.6970e-05
Epoch 162/512
512/512 - 0s - loss: 3.2978e-07 - val_loss: 2.6009e-05
Epoch 163/512
512/512 - 0s - loss: 3.2612e-07 - val_loss: 2.5619e-05
Epoch 164/512
512/512 - 0s - loss: 3.2303e-07 - val_loss: 2.5649e-05
Epoch 165/512
512/512 - 0s - loss: 3.1999e-07 - val_loss: 2.5129e-05
Epoch 166/512
512/512 - 0s - loss: 3.1698e-07 - val_loss: 2.5002e-05
Epoch 167/512
512/512 - 0s - loss: 3.1406e-07 - val_loss: 2.4858e-05
Epoch 168/512
512/512 - 0s - loss: 3.1146e-07 - val_loss: 2.4217e-05
Epoch 169/512
512/512 - 0s - loss: 3.0843e-07 - val_loss: 2.4516e-05
Epoch 170/512
512/512 - 0s - loss: 3.0605e-07 - val_loss: 2.4854e-05
Epoch 171/512
512/512 - 0s - loss: 3.0301e-07 - val_loss: 2.4373e-05
Epoch 172/512
512/512 - 0s - loss: 3.0071e-07 - val_loss: 2.4220e-05
Epoch 173/512
512/512 - 0s - loss: 2.9785e-07 - val_loss: 2.3463e-05
Epoch 174/512
512/512 - 0s - loss: 2.9520e-07 - val_loss: 2.3540e-05
Epoch 175/512
512/512 - 0s - loss: 2.9277e-07 - val_loss: 2.2971e-05
Epoch 176/512
512/512 - 0s - loss: 2.9075e-07 - val_loss: 2.2935e-05
Epoch 177/512
512/512 - 0s - loss: 2.8789e-07 - val_loss: 2.3026e-05
Epoch 178/512
512/512 - 0s - loss: 2.8580e-07 - val_loss: 2.3422e-05
Epoch 179/512
512/512 - 0s - loss: 2.8347e-07 - val_loss: 2.2994e-05
Epoch 180/512
512/512 - 0s - loss: 2.8098e-07 - val_loss: 2.2426e-05
Epoch 181/512
512/512 - 0s - loss: 2.7892e-07 - val_loss: 2.2311e-05
Epoch 182/512
512/512 - 0s - loss: 2.7685e-07 - val_loss: 2.2852e-05
Epoch 183/512
512/512 - 0s - loss: 2.7450e-07 - val_loss: 2.2251e-05
Epoch 184/512
512/512 - 0s - loss: 2.7271e-07 - val_loss: 2.1463e-05
Epoch 185/512
512/512 - 0s - loss: 2.7053e-07 - val_loss: 2.1590e-05
Epoch 186/512
512/512 - 0s - loss: 2.6818e-07 - val_loss: 2.1572e-05
Epoch 187/512
512/512 - 0s - loss: 2.6621e-07 - val_loss: 2.1901e-05
Epoch 188/512
512/512 - 0s - loss: 2.6476e-07 - val_loss: 2.1824e-05
Epoch 189/512
512/512 - 0s - loss: 2.6231e-07 - val_loss: 2.0884e-05
Epoch 190/512
512/512 - 0s - loss: 2.6043e-07 - val_loss: 2.1407e-05
Epoch 191/512
512/512 - 0s - loss: 2.5858e-07 - val_loss: 2.1341e-05
Epoch 192/512
512/512 - 0s - loss: 2.5691e-07 - val_loss: 2.1057e-05
Epoch 193/512
512/512 - 0s - loss: 2.5493e-07 - val_loss: 2.1114e-05
Epoch 194/512
512/512 - 0s - loss: 2.5335e-07 - val_loss: 2.0673e-05
Epoch 195/512
512/512 - 0s - loss: 2.5138e-07 - val_loss: 2.0100e-05
Epoch 196/512
512/512 - 0s - loss: 2.4965e-07 - val_loss: 2.0300e-05
Epoch 197/512
512/512 - 0s - loss: 2.4822e-07 - val_loss: 2.0568e-05
Epoch 198/512
512/512 - 0s - loss: 2.4635e-07 - val_loss: 1.9860e-05
Epoch 199/512
512/512 - 0s - loss: 2.4466e-07 - val_loss: 2.0271e-05
Epoch 200/512
512/512 - 0s - loss: 2.4296e-07 - val_loss: 1.9562e-05
Epoch 201/512
512/512 - 0s - loss: 2.4150e-07 - val_loss: 1.9358e-05
Epoch 202/512
512/512 - 0s - loss: 2.3994e-07 - val_loss: 1.9844e-05
Epoch 203/512
512/512 - 0s - loss: 2.3829e-07 - val_loss: 1.9456e-05
Epoch 204/512
512/512 - 0s - loss: 2.3686e-07 - val_loss: 1.9164e-05
Epoch 205/512
512/512 - 0s - loss: 2.3524e-07 - val_loss: 1.9338e-05
Epoch 206/512
512/512 - 0s - loss: 2.3375e-07 - val_loss: 1.9170e-05
Epoch 207/512
512/512 - 0s - loss: 2.3241e-07 - val_loss: 1.9242e-05
Epoch 208/512
512/512 - 0s - loss: 2.3100e-07 - val_loss: 1.9086e-05
Epoch 209/512
512/512 - 0s - loss: 2.2950e-07 - val_loss: 1.9110e-05
Epoch 210/512
512/512 - 0s - loss: 2.2817e-07 - val_loss: 1.8476e-05
Epoch 211/512
512/512 - 0s - loss: 2.2660e-07 - val_loss: 1.8903e-05
Epoch 212/512
512/512 - 0s - loss: 2.2536e-07 - val_loss: 1.8630e-05
Epoch 213/512
512/512 - 0s - loss: 2.2398e-07 - val_loss: 1.8287e-05
Epoch 214/512
512/512 - 0s - loss: 2.2267e-07 - val_loss: 1.8256e-05
Epoch 215/512
512/512 - 0s - loss: 2.2139e-07 - val_loss: 1.7945e-05
Epoch 216/512
512/512 - 0s - loss: 2.2005e-07 - val_loss: 1.7936e-05
Epoch 217/512
512/512 - 0s - loss: 2.1883e-07 - val_loss: 1.7906e-05
Epoch 218/512
512/512 - 0s - loss: 2.1754e-07 - val_loss: 1.7755e-05
Epoch 219/512
512/512 - 0s - loss: 2.1633e-07 - val_loss: 1.7612e-05
Epoch 220/512
512/512 - 0s - loss: 2.1508e-07 - val_loss: 1.7894e-05
Epoch 221/512
512/512 - 0s - loss: 2.1390e-07 - val_loss: 1.7666e-05
Epoch 222/512
512/512 - 0s - loss: 2.1267e-07 - val_loss: 1.7362e-05
Epoch 223/512
512/512 - 0s - loss: 2.1153e-07 - val_loss: 1.7426e-05
Epoch 224/512
512/512 - 0s - loss: 2.1035e-07 - val_loss: 1.7296e-05
Epoch 225/512
512/512 - 0s - loss: 2.0928e-07 - val_loss: 1.7276e-05
Epoch 226/512
512/512 - 0s - loss: 2.0808e-07 - val_loss: 1.7361e-05
Epoch 227/512
512/512 - 0s - loss: 2.0697e-07 - val_loss: 1.6870e-05
Epoch 228/512
512/512 - 0s - loss: 2.0600e-07 - val_loss: 1.6823e-05
Epoch 229/512
512/512 - 0s - loss: 2.0480e-07 - val_loss: 1.6996e-05
Epoch 230/512
512/512 - 0s - loss: 2.0374e-07 - val_loss: 1.6792e-05
Epoch 231/512
512/512 - 0s - loss: 2.0265e-07 - val_loss: 1.6547e-05
Epoch 232/512
512/512 - 0s - loss: 2.0171e-07 - val_loss: 1.6515e-05
Epoch 233/512
512/512 - 0s - loss: 2.0057e-07 - val_loss: 1.6845e-05
Epoch 234/512
512/512 - 0s - loss: 1.9972e-07 - val_loss: 1.6822e-05
Epoch 235/512
512/512 - 0s - loss: 1.9876e-07 - val_loss: 1.6635e-05
Epoch 236/512
512/512 - 0s - loss: 1.9755e-07 - val_loss: 1.6536e-05
Epoch 237/512
512/512 - 0s - loss: 1.9657e-07 - val_loss: 1.6069e-05
Epoch 238/512
512/512 - 0s - loss: 1.9581e-07 - val_loss: 1.6036e-05
Epoch 239/512
512/512 - 0s - loss: 1.9464e-07 - val_loss: 1.6201e-05
Epoch 240/512
512/512 - 0s - loss: 1.9365e-07 - val_loss: 1.5997e-05
Epoch 241/512
512/512 - 0s - loss: 1.9287e-07 - val_loss: 1.6244e-05
Epoch 242/512
512/512 - 0s - loss: 1.9183e-07 - val_loss: 1.5915e-05
Epoch 243/512
512/512 - 0s - loss: 1.9089e-07 - val_loss: 1.5642e-05
Epoch 244/512
512/512 - 0s - loss: 1.9001e-07 - val_loss: 1.5620e-05
Epoch 245/512
512/512 - 0s - loss: 1.8906e-07 - val_loss: 1.5756e-05
Epoch 246/512
512/512 - 0s - loss: 1.8819e-07 - val_loss: 1.5467e-05
Epoch 247/512
512/512 - 0s - loss: 1.8758e-07 - val_loss: 1.5285e-05
Epoch 248/512
512/512 - 0s - loss: 1.8668e-07 - val_loss: 1.5201e-05
Epoch 249/512
512/512 - 0s - loss: 1.8568e-07 - val_loss: 1.5369e-05
Epoch 250/512
512/512 - 0s - loss: 1.8471e-07 - val_loss: 1.5342e-05
Epoch 251/512
512/512 - 0s - loss: 1.8388e-07 - val_loss: 1.5347e-05
Epoch 252/512
512/512 - 0s - loss: 1.8307e-07 - val_loss: 1.5499e-05
Epoch 253/512
512/512 - 0s - loss: 1.8220e-07 - val_loss: 1.5147e-05
Epoch 254/512
512/512 - 0s - loss: 1.8152e-07 - val_loss: 1.5385e-05
Epoch 255/512
512/512 - 0s - loss: 1.8083e-07 - val_loss: 1.5136e-05
Epoch 256/512
512/512 - 0s - loss: 1.7978e-07 - val_loss: 1.4952e-05
Epoch 257/512
512/512 - 0s - loss: 1.7906e-07 - val_loss: 1.4796e-05
Epoch 258/512
512/512 - 0s - loss: 1.7829e-07 - val_loss: 1.5051e-05
Epoch 259/512
512/512 - 0s - loss: 1.7750e-07 - val_loss: 1.4940e-05
Epoch 260/512
512/512 - 0s - loss: 1.7684e-07 - val_loss: 1.4777e-05
Epoch 261/512
512/512 - 0s - loss: 1.7600e-07 - val_loss: 1.4686e-05
Epoch 262/512
512/512 - 0s - loss: 1.7547e-07 - val_loss: 1.4538e-05
Epoch 263/512
512/512 - 0s - loss: 1.7444e-07 - val_loss: 1.4800e-05
Epoch 264/512
512/512 - 0s - loss: 1.7372e-07 - val_loss: 1.4469e-05
Epoch 265/512
512/512 - 0s - loss: 1.7296e-07 - val_loss: 1.4629e-05
Epoch 266/512
512/512 - 0s - loss: 1.7226e-07 - val_loss: 1.4426e-05
Epoch 267/512
512/512 - 0s - loss: 1.7152e-07 - val_loss: 1.4396e-05
Epoch 268/512
512/512 - 0s - loss: 1.7085e-07 - val_loss: 1.4426e-05
Epoch 269/512
512/512 - 0s - loss: 1.7016e-07 - val_loss: 1.4542e-05
Epoch 270/512
512/512 - 0s - loss: 1.6946e-07 - val_loss: 1.4245e-05
Epoch 271/512
512/512 - 0s - loss: 1.6874e-07 - val_loss: 1.4201e-05
Epoch 272/512
512/512 - 0s - loss: 1.6813e-07 - val_loss: 1.4089e-05
Epoch 273/512
512/512 - 0s - loss: 1.6740e-07 - val_loss: 1.4040e-05
Epoch 274/512
512/512 - 0s - loss: 1.6673e-07 - val_loss: 1.3946e-05
Epoch 275/512
512/512 - 0s - loss: 1.6608e-07 - val_loss: 1.4030e-05
Epoch 276/512
512/512 - 0s - loss: 1.6543e-07 - val_loss: 1.4012e-05
Epoch 277/512
512/512 - 0s - loss: 1.6484e-07 - val_loss: 1.3957e-05
Epoch 278/512
512/512 - 0s - loss: 1.6412e-07 - val_loss: 1.3738e-05
Epoch 279/512
512/512 - 0s - loss: 1.6351e-07 - val_loss: 1.3821e-05
Epoch 280/512
512/512 - 0s - loss: 1.6289e-07 - val_loss: 1.3721e-05
Epoch 281/512
512/512 - 0s - loss: 1.6223e-07 - val_loss: 1.3592e-05
Epoch 282/512
512/512 - 0s - loss: 1.6160e-07 - val_loss: 1.3542e-05
Epoch 283/512
512/512 - 0s - loss: 1.6099e-07 - val_loss: 1.3739e-05
Epoch 284/512
512/512 - 0s - loss: 1.6048e-07 - val_loss: 1.3565e-05
Epoch 285/512
512/512 - 0s - loss: 1.5980e-07 - val_loss: 1.3412e-05
Epoch 286/512
512/512 - 0s - loss: 1.5919e-07 - val_loss: 1.3517e-05
Epoch 287/512
512/512 - 0s - loss: 1.5861e-07 - val_loss: 1.3066e-05
Epoch 288/512
512/512 - 0s - loss: 1.5806e-07 - val_loss: 1.3367e-05
Epoch 289/512
512/512 - 0s - loss: 1.5749e-07 - val_loss: 1.3490e-05
Epoch 290/512
512/512 - 0s - loss: 1.5687e-07 - val_loss: 1.3144e-05
Epoch 291/512
512/512 - 0s - loss: 1.5629e-07 - val_loss: 1.3309e-05
Epoch 292/512
512/512 - 0s - loss: 1.5574e-07 - val_loss: 1.3197e-05
Epoch 293/512
512/512 - 0s - loss: 1.5513e-07 - val_loss: 1.2950e-05
Epoch 294/512
512/512 - 0s - loss: 1.5459e-07 - val_loss: 1.3200e-05
Epoch 295/512
512/512 - 0s - loss: 1.5407e-07 - val_loss: 1.2893e-05
Epoch 296/512
512/512 - 0s - loss: 1.5354e-07 - val_loss: 1.3142e-05
Epoch 297/512
512/512 - 0s - loss: 1.5305e-07 - val_loss: 1.3116e-05
Epoch 298/512
512/512 - 0s - loss: 1.5241e-07 - val_loss: 1.2918e-05
Epoch 299/512
512/512 - 0s - loss: 1.5188e-07 - val_loss: 1.2835e-05
Epoch 300/512
512/512 - 0s - loss: 1.5134e-07 - val_loss: 1.2834e-05
Epoch 301/512
512/512 - 0s - loss: 1.5082e-07 - val_loss: 1.2773e-05
Epoch 302/512
512/512 - 0s - loss: 1.5035e-07 - val_loss: 1.2559e-05
Epoch 303/512
512/512 - 0s - loss: 1.4979e-07 - val_loss: 1.2601e-05
Epoch 304/512
512/512 - 0s - loss: 1.4929e-07 - val_loss: 1.2693e-05
Epoch 305/512
512/512 - 0s - loss: 1.4877e-07 - val_loss: 1.2645e-05
Epoch 306/512
512/512 - 0s - loss: 1.4829e-07 - val_loss: 1.2498e-05
Epoch 307/512
512/512 - 0s - loss: 1.4777e-07 - val_loss: 1.2512e-05
Epoch 308/512
512/512 - 0s - loss: 1.4726e-07 - val_loss: 1.2381e-05
Epoch 309/512
512/512 - 0s - loss: 1.4690e-07 - val_loss: 1.2339e-05
Epoch 310/512
512/512 - 0s - loss: 1.4641e-07 - val_loss: 1.2464e-05
Epoch 311/512
512/512 - 0s - loss: 1.4580e-07 - val_loss: 1.2378e-05
Epoch 312/512
512/512 - 0s - loss: 1.4537e-07 - val_loss: 1.2270e-05
Epoch 313/512
512/512 - 0s - loss: 1.4484e-07 - val_loss: 1.2313e-05
Epoch 314/512
512/512 - 0s - loss: 1.4438e-07 - val_loss: 1.2247e-05
Epoch 315/512
512/512 - 0s - loss: 1.4392e-07 - val_loss: 1.2244e-05
Epoch 316/512
512/512 - 0s - loss: 1.4343e-07 - val_loss: 1.2277e-05
Epoch 317/512
512/512 - 0s - loss: 1.4301e-07 - val_loss: 1.2132e-05
Epoch 318/512
512/512 - 0s - loss: 1.4260e-07 - val_loss: 1.2027e-05
Epoch 319/512
512/512 - 0s - loss: 1.4209e-07 - val_loss: 1.2155e-05
Epoch 320/512
512/512 - 0s - loss: 1.4169e-07 - val_loss: 1.1907e-05
Epoch 321/512
512/512 - 0s - loss: 1.4120e-07 - val_loss: 1.2008e-05
Epoch 322/512
512/512 - 0s - loss: 1.4072e-07 - val_loss: 1.1939e-05
Epoch 323/512
512/512 - 0s - loss: 1.4027e-07 - val_loss: 1.1908e-05
Epoch 324/512
512/512 - 0s - loss: 1.3985e-07 - val_loss: 1.2054e-05
Epoch 325/512
512/512 - 0s - loss: 1.3952e-07 - val_loss: 1.1734e-05
Epoch 326/512
512/512 - 0s - loss: 1.3904e-07 - val_loss: 1.1719e-05
Epoch 327/512
512/512 - 0s - loss: 1.3859e-07 - val_loss: 1.1741e-05
Epoch 328/512
512/512 - 0s - loss: 1.3816e-07 - val_loss: 1.1731e-05
Epoch 329/512
512/512 - 0s - loss: 1.3770e-07 - val_loss: 1.1636e-05
Epoch 330/512
512/512 - 0s - loss: 1.3734e-07 - val_loss: 1.1703e-05
Epoch 331/512
512/512 - 0s - loss: 1.3688e-07 - val_loss: 1.1627e-05
Epoch 332/512
512/512 - 0s - loss: 1.3646e-07 - val_loss: 1.1557e-05
Epoch 333/512
512/512 - 0s - loss: 1.3615e-07 - val_loss: 1.1456e-05
Epoch 334/512
512/512 - 0s - loss: 1.3561e-07 - val_loss: 1.1653e-05
Epoch 335/512
512/512 - 0s - loss: 1.3532e-07 - val_loss: 1.1407e-05
Epoch 336/512
512/512 - 0s - loss: 1.3483e-07 - val_loss: 1.1549e-05
Epoch 337/512
512/512 - 0s - loss: 1.3448e-07 - val_loss: 1.1272e-05
Epoch 338/512
512/512 - 0s - loss: 1.3409e-07 - val_loss: 1.1428e-05
Epoch 339/512
512/512 - 0s - loss: 1.3364e-07 - val_loss: 1.1423e-05
Epoch 340/512
512/512 - 0s - loss: 1.3325e-07 - val_loss: 1.1363e-05
Epoch 341/512
512/512 - 0s - loss: 1.3287e-07 - val_loss: 1.1182e-05
Epoch 342/512
512/512 - 0s - loss: 1.3250e-07 - val_loss: 1.1366e-05
Epoch 343/512
512/512 - 0s - loss: 1.3213e-07 - val_loss: 1.1139e-05
Epoch 344/512
512/512 - 0s - loss: 1.3173e-07 - val_loss: 1.1241e-05
Epoch 345/512
512/512 - 0s - loss: 1.3135e-07 - val_loss: 1.1321e-05
Epoch 346/512
512/512 - 0s - loss: 1.3106e-07 - val_loss: 1.1046e-05
Epoch 347/512
512/512 - 0s - loss: 1.3062e-07 - val_loss: 1.1153e-05
Epoch 348/512
512/512 - 0s - loss: 1.3030e-07 - val_loss: 1.1100e-05
Epoch 349/512
512/512 - 0s - loss: 1.2988e-07 - val_loss: 1.1016e-05
Epoch 350/512
512/512 - 0s - loss: 1.2950e-07 - val_loss: 1.1171e-05
Epoch 351/512
512/512 - 0s - loss: 1.2915e-07 - val_loss: 1.0999e-05
Epoch 352/512
512/512 - 0s - loss: 1.2887e-07 - val_loss: 1.1073e-05
Epoch 353/512
512/512 - 0s - loss: 1.2851e-07 - val_loss: 1.0882e-05
Epoch 354/512
512/512 - 0s - loss: 1.2819e-07 - val_loss: 1.0787e-05
Epoch 355/512
512/512 - 0s - loss: 1.2773e-07 - val_loss: 1.0817e-05
Epoch 356/512
512/512 - 0s - loss: 1.2739e-07 - val_loss: 1.0850e-05
Epoch 357/512
512/512 - 0s - loss: 1.2702e-07 - val_loss: 1.0849e-05
Epoch 358/512
512/512 - 0s - loss: 1.2667e-07 - val_loss: 1.0815e-05
Epoch 359/512
512/512 - 0s - loss: 1.2633e-07 - val_loss: 1.0781e-05
Epoch 360/512
512/512 - 0s - loss: 1.2600e-07 - val_loss: 1.0755e-05
Epoch 361/512
512/512 - 0s - loss: 1.2568e-07 - val_loss: 1.0834e-05
Epoch 362/512
512/512 - 0s - loss: 1.2535e-07 - val_loss: 1.0824e-05
Epoch 363/512
512/512 - 0s - loss: 1.2499e-07 - val_loss: 1.0709e-05
Epoch 364/512
512/512 - 0s - loss: 1.2465e-07 - val_loss: 1.0749e-05
Epoch 365/512
512/512 - 0s - loss: 1.2433e-07 - val_loss: 1.0655e-05
Epoch 366/512
512/512 - 0s - loss: 1.2405e-07 - val_loss: 1.0563e-05
Epoch 367/512
512/512 - 0s - loss: 1.2368e-07 - val_loss: 1.0606e-05
Epoch 368/512
512/512 - 0s - loss: 1.2337e-07 - val_loss: 1.0630e-05
Epoch 369/512
512/512 - 0s - loss: 1.2303e-07 - val_loss: 1.0461e-05
Epoch 370/512
512/512 - 0s - loss: 1.2271e-07 - val_loss: 1.0516e-05
Epoch 371/512
512/512 - 0s - loss: 1.2240e-07 - val_loss: 1.0382e-05
Epoch 372/512
512/512 - 0s - loss: 1.2208e-07 - val_loss: 1.0456e-05
Epoch 373/512
512/512 - 0s - loss: 1.2176e-07 - val_loss: 1.0408e-05
Epoch 374/512
512/512 - 0s - loss: 1.2146e-07 - val_loss: 1.0320e-05
Epoch 375/512
512/512 - 0s - loss: 1.2114e-07 - val_loss: 1.0471e-05
Epoch 376/512
512/512 - 0s - loss: 1.2085e-07 - val_loss: 1.0276e-05
Epoch 377/512
512/512 - 0s - loss: 1.2054e-07 - val_loss: 1.0310e-05
Epoch 378/512
512/512 - 0s - loss: 1.2022e-07 - val_loss: 1.0193e-05
Epoch 379/512
512/512 - 0s - loss: 1.1996e-07 - val_loss: 1.0226e-05
Epoch 380/512
512/512 - 0s - loss: 1.1967e-07 - val_loss: 1.0245e-05
Epoch 381/512
512/512 - 0s - loss: 1.1936e-07 - val_loss: 1.0333e-05
Epoch 382/512
512/512 - 0s - loss: 1.1903e-07 - val_loss: 1.0124e-05
Epoch 383/512
512/512 - 0s - loss: 1.1872e-07 - val_loss: 1.0294e-05
Epoch 384/512
512/512 - 0s - loss: 1.1845e-07 - val_loss: 1.0073e-05
Epoch 385/512
512/512 - 0s - loss: 1.1818e-07 - val_loss: 1.0213e-05
Epoch 386/512
512/512 - 0s - loss: 1.1787e-07 - val_loss: 1.0023e-05
Epoch 387/512
512/512 - 0s - loss: 1.1760e-07 - val_loss: 1.0098e-05
Epoch 388/512
512/512 - 0s - loss: 1.1730e-07 - val_loss: 1.0126e-05
Epoch 389/512
512/512 - 0s - loss: 1.1702e-07 - val_loss: 1.0055e-05
Epoch 390/512
512/512 - 0s - loss: 1.1674e-07 - val_loss: 1.0080e-05
Epoch 391/512
512/512 - 0s - loss: 1.1645e-07 - val_loss: 1.0058e-05
Epoch 392/512
512/512 - 0s - loss: 1.1619e-07 - val_loss: 9.9438e-06
Epoch 393/512
512/512 - 0s - loss: 1.1593e-07 - val_loss: 1.0052e-05
Epoch 394/512
512/512 - 0s - loss: 1.1565e-07 - val_loss: 9.9570e-06
Epoch 395/512
512/512 - 0s - loss: 1.1537e-07 - val_loss: 9.8563e-06
Epoch 396/512
512/512 - 0s - loss: 1.1507e-07 - val_loss: 9.8457e-06
Epoch 397/512
512/512 - 0s - loss: 1.1478e-07 - val_loss: 9.8109e-06
Epoch 398/512
512/512 - 0s - loss: 1.1454e-07 - val_loss: 9.8132e-06
Epoch 399/512
512/512 - 0s - loss: 1.1426e-07 - val_loss: 9.6891e-06
Epoch 400/512
512/512 - 0s - loss: 1.1398e-07 - val_loss: 9.7818e-06
Epoch 401/512
512/512 - 0s - loss: 1.1375e-07 - val_loss: 9.8051e-06
Epoch 402/512
512/512 - 0s - loss: 1.1346e-07 - val_loss: 9.6755e-06
Epoch 403/512
512/512 - 0s - loss: 1.1319e-07 - val_loss: 9.7568e-06
Epoch 404/512
512/512 - 0s - loss: 1.1294e-07 - val_loss: 9.7421e-06
Epoch 405/512
512/512 - 0s - loss: 1.1268e-07 - val_loss: 9.6622e-06
Epoch 406/512
512/512 - 0s - loss: 1.1241e-07 - val_loss: 9.7041e-06
Epoch 407/512
512/512 - 0s - loss: 1.1215e-07 - val_loss: 9.5923e-06
Epoch 408/512
512/512 - 0s - loss: 1.1189e-07 - val_loss: 9.7001e-06
Epoch 409/512
512/512 - 0s - loss: 1.1165e-07 - val_loss: 9.6609e-06
Epoch 410/512
512/512 - 0s - loss: 1.1138e-07 - val_loss: 9.5319e-06
Epoch 411/512
512/512 - 0s - loss: 1.1114e-07 - val_loss: 9.5837e-06
Epoch 412/512
512/512 - 0s - loss: 1.1090e-07 - val_loss: 9.5742e-06
Epoch 413/512
512/512 - 0s - loss: 1.1072e-07 - val_loss: 9.4687e-06
Epoch 414/512
512/512 - 0s - loss: 1.1040e-07 - val_loss: 9.4452e-06
Epoch 415/512
512/512 - 0s - loss: 1.1015e-07 - val_loss: 9.4323e-06
Epoch 416/512
512/512 - 0s - loss: 1.0992e-07 - val_loss: 9.3286e-06
Epoch 417/512
512/512 - 0s - loss: 1.0970e-07 - val_loss: 9.3793e-06
Epoch 418/512
512/512 - 0s - loss: 1.0941e-07 - val_loss: 9.5577e-06
Epoch 419/512
512/512 - 0s - loss: 1.0921e-07 - val_loss: 9.4160e-06
Epoch 420/512
512/512 - 0s - loss: 1.0894e-07 - val_loss: 9.4446e-06
Epoch 421/512
512/512 - 0s - loss: 1.0871e-07 - val_loss: 9.3808e-06
Epoch 422/512
512/512 - 0s - loss: 1.0847e-07 - val_loss: 9.2712e-06
Epoch 423/512
512/512 - 0s - loss: 1.0823e-07 - val_loss: 9.2914e-06
Epoch 424/512
512/512 - 0s - loss: 1.0799e-07 - val_loss: 9.2320e-06
Epoch 425/512
512/512 - 0s - loss: 1.0775e-07 - val_loss: 9.3326e-06
Epoch 426/512
512/512 - 0s - loss: 1.0757e-07 - val_loss: 9.2676e-06
Epoch 427/512
512/512 - 0s - loss: 1.0730e-07 - val_loss: 9.3140e-06
Epoch 428/512
512/512 - 0s - loss: 1.0707e-07 - val_loss: 9.2575e-06
Epoch 429/512
512/512 - 0s - loss: 1.0683e-07 - val_loss: 9.1488e-06
Epoch 430/512
512/512 - 0s - loss: 1.0661e-07 - val_loss: 9.1318e-06
Epoch 431/512
512/512 - 0s - loss: 1.0643e-07 - val_loss: 9.0350e-06
Epoch 432/512
512/512 - 0s - loss: 1.0616e-07 - val_loss: 9.1540e-06
Epoch 433/512
512/512 - 0s - loss: 1.0593e-07 - val_loss: 9.1531e-06
Epoch 434/512
512/512 - 0s - loss: 1.0575e-07 - val_loss: 9.1457e-06
Epoch 435/512
512/512 - 0s - loss: 1.0549e-07 - val_loss: 9.1274e-06
Epoch 436/512
512/512 - 0s - loss: 1.0527e-07 - val_loss: 9.0573e-06
Epoch 437/512
512/512 - 0s - loss: 1.0506e-07 - val_loss: 9.0482e-06
Epoch 438/512
512/512 - 0s - loss: 1.0485e-07 - val_loss: 8.8791e-06
Epoch 439/512
512/512 - 0s - loss: 1.0462e-07 - val_loss: 9.0812e-06
Epoch 440/512
512/512 - 0s - loss: 1.0440e-07 - val_loss: 9.0331e-06
Epoch 441/512
512/512 - 0s - loss: 1.0419e-07 - val_loss: 8.9585e-06
Epoch 442/512
512/512 - 0s - loss: 1.0400e-07 - val_loss: 9.0006e-06
Epoch 443/512
512/512 - 0s - loss: 1.0378e-07 - val_loss: 8.8617e-06
Epoch 444/512
512/512 - 0s - loss: 1.0363e-07 - val_loss: 9.0734e-06
Epoch 445/512
512/512 - 0s - loss: 1.0336e-07 - val_loss: 8.9736e-06
Epoch 446/512
512/512 - 0s - loss: 1.0316e-07 - val_loss: 8.8664e-06
Epoch 447/512
512/512 - 0s - loss: 1.0293e-07 - val_loss: 8.8543e-06
Epoch 448/512
512/512 - 0s - loss: 1.0272e-07 - val_loss: 8.8648e-06
Epoch 449/512
512/512 - 0s - loss: 1.0252e-07 - val_loss: 8.9097e-06
Epoch 450/512
512/512 - 0s - loss: 1.0235e-07 - val_loss: 8.9241e-06
Epoch 451/512
512/512 - 0s - loss: 1.0216e-07 - val_loss: 8.8879e-06
Epoch 452/512
512/512 - 0s - loss: 1.0193e-07 - val_loss: 8.8730e-06
Epoch 453/512
512/512 - 0s - loss: 1.0170e-07 - val_loss: 8.8112e-06
Epoch 454/512
512/512 - 0s - loss: 1.0150e-07 - val_loss: 8.7578e-06
Epoch 455/512
512/512 - 0s - loss: 1.0136e-07 - val_loss: 8.7217e-06
Epoch 456/512
512/512 - 0s - loss: 1.0110e-07 - val_loss: 8.6900e-06
Epoch 457/512
512/512 - 0s - loss: 1.0092e-07 - val_loss: 8.6491e-06
Epoch 458/512
512/512 - 0s - loss: 1.0069e-07 - val_loss: 8.7748e-06
Epoch 459/512
512/512 - 0s - loss: 1.0055e-07 - val_loss: 8.6636e-06
Epoch 460/512
512/512 - 0s - loss: 1.0033e-07 - val_loss: 8.6809e-06
Epoch 461/512
512/512 - 0s - loss: 1.0015e-07 - val_loss: 8.5904e-06
Epoch 462/512
512/512 - 0s - loss: 9.9917e-08 - val_loss: 8.5863e-06
Epoch 463/512
512/512 - 0s - loss: 9.9722e-08 - val_loss: 8.7451e-06
Epoch 464/512
512/512 - 0s - loss: 9.9564e-08 - val_loss: 8.4811e-06
Epoch 465/512
512/512 - 0s - loss: 9.9344e-08 - val_loss: 8.6968e-06
Epoch 466/512
512/512 - 0s - loss: 9.9168e-08 - val_loss: 8.5350e-06
Epoch 467/512
512/512 - 0s - loss: 9.8999e-08 - val_loss: 8.4647e-06
Epoch 468/512
512/512 - 0s - loss: 9.8803e-08 - val_loss: 8.5952e-06
Epoch 469/512
512/512 - 0s - loss: 9.8585e-08 - val_loss: 8.5619e-06
Epoch 470/512
512/512 - 0s - loss: 9.8403e-08 - val_loss: 8.5123e-06
Epoch 471/512
512/512 - 0s - loss: 9.8220e-08 - val_loss: 8.4655e-06
Epoch 472/512
512/512 - 0s - loss: 9.8020e-08 - val_loss: 8.5110e-06
Epoch 473/512
512/512 - 0s - loss: 9.7863e-08 - val_loss: 8.4571e-06
Epoch 474/512
512/512 - 0s - loss: 9.7666e-08 - val_loss: 8.3897e-06
Epoch 475/512
512/512 - 0s - loss: 9.7474e-08 - val_loss: 8.4530e-06
Epoch 476/512
512/512 - 0s - loss: 9.7289e-08 - val_loss: 8.4462e-06
Epoch 477/512
512/512 - 0s - loss: 9.7108e-08 - val_loss: 8.3858e-06
Epoch 478/512
512/512 - 0s - loss: 9.6931e-08 - val_loss: 8.3841e-06
Epoch 479/512
512/512 - 0s - loss: 9.6761e-08 - val_loss: 8.3123e-06
Epoch 480/512
512/512 - 0s - loss: 9.6598e-08 - val_loss: 8.4171e-06
Epoch 481/512
512/512 - 0s - loss: 9.6418e-08 - val_loss: 8.3956e-06
Epoch 482/512
512/512 - 0s - loss: 9.6216e-08 - val_loss: 8.2662e-06
Epoch 483/512
512/512 - 0s - loss: 9.6045e-08 - val_loss: 8.2806e-06
Epoch 484/512
512/512 - 0s - loss: 9.5878e-08 - val_loss: 8.3342e-06
Epoch 485/512
512/512 - 0s - loss: 9.5719e-08 - val_loss: 8.3218e-06
Epoch 486/512
512/512 - 0s - loss: 9.5528e-08 - val_loss: 8.3016e-06
Epoch 487/512
512/512 - 0s - loss: 9.5357e-08 - val_loss: 8.2913e-06
Epoch 488/512
512/512 - 0s - loss: 9.5188e-08 - val_loss: 8.2424e-06
Epoch 489/512
512/512 - 0s - loss: 9.5002e-08 - val_loss: 8.1932e-06
Epoch 490/512
512/512 - 0s - loss: 9.4848e-08 - val_loss: 8.2206e-06
Epoch 491/512
512/512 - 0s - loss: 9.4671e-08 - val_loss: 8.2207e-06
Epoch 492/512
512/512 - 0s - loss: 9.4516e-08 - val_loss: 8.2326e-06
Epoch 493/512
512/512 - 0s - loss: 9.4372e-08 - val_loss: 8.1967e-06
Epoch 494/512
512/512 - 0s - loss: 9.4171e-08 - val_loss: 8.1374e-06
Epoch 495/512
512/512 - 0s - loss: 9.4046e-08 - val_loss: 8.0896e-06
Epoch 496/512
512/512 - 0s - loss: 9.3824e-08 - val_loss: 8.1140e-06
Epoch 497/512
512/512 - 0s - loss: 9.3656e-08 - val_loss: 8.1720e-06
Epoch 498/512
512/512 - 0s - loss: 9.3493e-08 - val_loss: 8.0516e-06
Epoch 499/512
512/512 - 0s - loss: 9.3348e-08 - val_loss: 8.0115e-06
Epoch 500/512
512/512 - 0s - loss: 9.3181e-08 - val_loss: 8.0851e-06
Epoch 501/512
512/512 - 0s - loss: 9.3000e-08 - val_loss: 8.0448e-06
Epoch 502/512
512/512 - 0s - loss: 9.2863e-08 - val_loss: 8.0750e-06
Epoch 503/512
512/512 - 0s - loss: 9.2711e-08 - val_loss: 7.9201e-06
Epoch 504/512
512/512 - 0s - loss: 9.2530e-08 - val_loss: 8.0004e-06
Epoch 505/512
512/512 - 0s - loss: 9.2372e-08 - val_loss: 7.9690e-06
Epoch 506/512
512/512 - 0s - loss: 9.2207e-08 - val_loss: 7.9578e-06
Epoch 507/512
512/512 - 0s - loss: 9.2041e-08 - val_loss: 7.8875e-06
Epoch 508/512
512/512 - 0s - loss: 9.1891e-08 - val_loss: 8.0319e-06
Epoch 509/512
512/512 - 0s - loss: 9.1727e-08 - val_loss: 7.9150e-06
Epoch 510/512
512/512 - 0s - loss: 9.1570e-08 - val_loss: 7.9338e-06
Epoch 511/512
512/512 - 0s - loss: 9.1430e-08 - val_loss: 7.9831e-06
Epoch 512/512
512/512 - 0s - loss: 9.1271e-08 - val_loss: 7.9948e-06
Train on 512 samples, validate on 512 samples
Epoch 1/512

Epoch 00001: val_loss improved from inf to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0362e-09 - val_loss: 2.6069e-09
Epoch 2/512

Epoch 00002: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.8957e-09 - val_loss: 8.6219e-10
Epoch 3/512

Epoch 00003: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.4189e-10 - val_loss: 2.3654e-10
Epoch 4/512

Epoch 00004: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.0138e-10 - val_loss: 1.7447e-10
Epoch 5/512

Epoch 00005: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.7187e-10 - val_loss: 1.6880e-10
Epoch 6/512

Epoch 00006: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.6751e-10 - val_loss: 1.6536e-10
Epoch 7/512

Epoch 00007: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.6417e-10 - val_loss: 1.6214e-10
Epoch 8/512

Epoch 00008: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.6096e-10 - val_loss: 1.5901e-10
Epoch 9/512

Epoch 00009: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5792e-10 - val_loss: 1.5600e-10
Epoch 10/512

Epoch 00010: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5499e-10 - val_loss: 1.5323e-10
Epoch 11/512

Epoch 00011: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5220e-10 - val_loss: 1.5046e-10
Epoch 12/512

Epoch 00012: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.4953e-10 - val_loss: 1.4788e-10
Epoch 13/512

Epoch 00013: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.4696e-10 - val_loss: 1.4535e-10
Epoch 14/512

Epoch 00014: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.4446e-10 - val_loss: 1.4293e-10
Epoch 15/512

Epoch 00015: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.4209e-10 - val_loss: 1.4065e-10
Epoch 16/512

Epoch 00016: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.3982e-10 - val_loss: 1.3842e-10
Epoch 17/512

Epoch 00017: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.3766e-10 - val_loss: 1.3626e-10
Epoch 18/512

Epoch 00018: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.3554e-10 - val_loss: 1.3431e-10
Epoch 19/512

Epoch 00019: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.3354e-10 - val_loss: 1.3229e-10
Epoch 20/512

Epoch 00020: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.3161e-10 - val_loss: 1.3041e-10
Epoch 21/512

Epoch 00021: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.2972e-10 - val_loss: 1.2857e-10
Epoch 22/512

Epoch 00022: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.2793e-10 - val_loss: 1.2680e-10
Epoch 23/512

Epoch 00023: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.2618e-10 - val_loss: 1.2506e-10
Epoch 24/512

Epoch 00024: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.2450e-10 - val_loss: 1.2344e-10
Epoch 25/512

Epoch 00025: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.2289e-10 - val_loss: 1.2186e-10
Epoch 26/512

Epoch 00026: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.2129e-10 - val_loss: 1.2028e-10
Epoch 27/512

Epoch 00027: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1976e-10 - val_loss: 1.1884e-10
Epoch 28/512

Epoch 00028: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1833e-10 - val_loss: 1.1744e-10
Epoch 29/512

Epoch 00029: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1693e-10 - val_loss: 1.1604e-10
Epoch 30/512

Epoch 00030: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1556e-10 - val_loss: 1.1468e-10
Epoch 31/512

Epoch 00031: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1422e-10 - val_loss: 1.1342e-10
Epoch 32/512

Epoch 00032: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1297e-10 - val_loss: 1.1220e-10
Epoch 33/512

Epoch 00033: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1173e-10 - val_loss: 1.1090e-10
Epoch 34/512

Epoch 00034: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1049e-10 - val_loss: 1.0975e-10
Epoch 35/512

Epoch 00035: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0934e-10 - val_loss: 1.0862e-10
Epoch 36/512

Epoch 00036: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0821e-10 - val_loss: 1.0752e-10
Epoch 37/512

Epoch 00037: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0711e-10 - val_loss: 1.0640e-10
Epoch 38/512

Epoch 00038: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0604e-10 - val_loss: 1.0537e-10
Epoch 39/512

Epoch 00039: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0502e-10 - val_loss: 1.0433e-10
Epoch 40/512

Epoch 00040: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0399e-10 - val_loss: 1.0338e-10
Epoch 41/512

Epoch 00041: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0301e-10 - val_loss: 1.0241e-10
Epoch 42/512

Epoch 00042: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0206e-10 - val_loss: 1.0146e-10
Epoch 43/512

Epoch 00043: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0112e-10 - val_loss: 1.0054e-10
Epoch 44/512

Epoch 00044: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0020e-10 - val_loss: 9.9609e-11
Epoch 45/512

Epoch 00045: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.9315e-11 - val_loss: 9.8720e-11
Epoch 46/512

Epoch 00046: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.8458e-11 - val_loss: 9.7913e-11
Epoch 47/512

Epoch 00047: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.7627e-11 - val_loss: 9.7079e-11
Epoch 48/512

Epoch 00048: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.6802e-11 - val_loss: 9.6294e-11
Epoch 49/512

Epoch 00049: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.6009e-11 - val_loss: 9.5467e-11
Epoch 50/512

Epoch 00050: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.5212e-11 - val_loss: 9.4723e-11
Epoch 51/512

Epoch 00051: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.4472e-11 - val_loss: 9.3934e-11
Epoch 52/512

Epoch 00052: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.3713e-11 - val_loss: 9.3223e-11
Epoch 53/512

Epoch 00053: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.2994e-11 - val_loss: 9.2481e-11
Epoch 54/512

Epoch 00054: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.2263e-11 - val_loss: 9.1803e-11
Epoch 55/512

Epoch 00055: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.1574e-11 - val_loss: 9.1141e-11
Epoch 56/512

Epoch 00056: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.0897e-11 - val_loss: 9.0400e-11
Epoch 57/512

Epoch 00057: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.0198e-11 - val_loss: 8.9793e-11
Epoch 58/512

Epoch 00058: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.9570e-11 - val_loss: 8.9155e-11
Epoch 59/512

Epoch 00059: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.8921e-11 - val_loss: 8.8503e-11
Epoch 60/512

Epoch 00060: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.8303e-11 - val_loss: 8.7862e-11
Epoch 61/512

Epoch 00061: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.7698e-11 - val_loss: 8.7338e-11
Epoch 62/512

Epoch 00062: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.7098e-11 - val_loss: 8.6708e-11
Epoch 63/512

Epoch 00063: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.6506e-11 - val_loss: 8.6132e-11
Epoch 64/512

Epoch 00064: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.5935e-11 - val_loss: 8.5554e-11
Epoch 65/512

Epoch 00065: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.5351e-11 - val_loss: 8.5001e-11
Epoch 66/512

Epoch 00066: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.4820e-11 - val_loss: 8.4404e-11
Epoch 67/512

Epoch 00067: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.4262e-11 - val_loss: 8.3898e-11
Epoch 68/512

Epoch 00068: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.3735e-11 - val_loss: 8.3390e-11
Epoch 69/512

Epoch 00069: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.3194e-11 - val_loss: 8.2889e-11
Epoch 70/512

Epoch 00070: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.2704e-11 - val_loss: 8.2359e-11
Epoch 71/512

Epoch 00071: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.2190e-11 - val_loss: 8.1864e-11
Epoch 72/512

Epoch 00072: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.1709e-11 - val_loss: 8.1393e-11
Epoch 73/512

Epoch 00073: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.1210e-11 - val_loss: 8.0886e-11
Epoch 74/512

Epoch 00074: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.0709e-11 - val_loss: 8.0376e-11
Epoch 75/512

Epoch 00075: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.0229e-11 - val_loss: 7.9902e-11
Epoch 76/512

Epoch 00076: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.9758e-11 - val_loss: 7.9474e-11
Epoch 77/512

Epoch 00077: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.9336e-11 - val_loss: 7.9001e-11
Epoch 78/512

Epoch 00078: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.8863e-11 - val_loss: 7.8563e-11
Epoch 79/512

Epoch 00079: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.8425e-11 - val_loss: 7.8147e-11
Epoch 80/512

Epoch 00080: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.7989e-11 - val_loss: 7.7721e-11
Epoch 81/512

Epoch 00081: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.7580e-11 - val_loss: 7.7302e-11
Epoch 82/512

Epoch 00082: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.7175e-11 - val_loss: 7.6894e-11
Epoch 83/512

Epoch 00083: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.6743e-11 - val_loss: 7.6446e-11
Epoch 84/512

Epoch 00084: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.6326e-11 - val_loss: 7.6061e-11
Epoch 85/512

Epoch 00085: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.5940e-11 - val_loss: 7.5668e-11
Epoch 86/512

Epoch 00086: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.5533e-11 - val_loss: 7.5269e-11
Epoch 87/512

Epoch 00087: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.5178e-11 - val_loss: 7.4914e-11
Epoch 88/512

Epoch 00088: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.4794e-11 - val_loss: 7.4552e-11
Epoch 89/512

Epoch 00089: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.4419e-11 - val_loss: 7.4144e-11
Epoch 90/512

Epoch 00090: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.4037e-11 - val_loss: 7.3756e-11
Epoch 91/512

Epoch 00091: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.3680e-11 - val_loss: 7.3397e-11
Epoch 92/512

Epoch 00092: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.3331e-11 - val_loss: 7.3094e-11
Epoch 93/512

Epoch 00093: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.2954e-11 - val_loss: 7.2718e-11
Epoch 94/512

Epoch 00094: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.2613e-11 - val_loss: 7.2374e-11
Epoch 95/512

Epoch 00095: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.2279e-11 - val_loss: 7.2047e-11
Epoch 96/512

Epoch 00096: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.1934e-11 - val_loss: 7.1712e-11
Epoch 97/512

Epoch 00097: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.1600e-11 - val_loss: 7.1346e-11
Epoch 98/512

Epoch 00098: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.1274e-11 - val_loss: 7.1069e-11
Epoch 99/512

Epoch 00099: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.0948e-11 - val_loss: 7.0761e-11
Epoch 100/512

Epoch 00100: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.0650e-11 - val_loss: 7.0406e-11
Epoch 101/512

Epoch 00101: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.0308e-11 - val_loss: 7.0129e-11
Epoch 102/512

Epoch 00102: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.0024e-11 - val_loss: 6.9821e-11
Epoch 103/512

Epoch 00103: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.9693e-11 - val_loss: 6.9490e-11
Epoch 104/512

Epoch 00104: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.9395e-11 - val_loss: 6.9188e-11
Epoch 105/512

Epoch 00105: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.9100e-11 - val_loss: 6.8889e-11
Epoch 106/512

Epoch 00106: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.8796e-11 - val_loss: 6.8585e-11
Epoch 107/512

Epoch 00107: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.8503e-11 - val_loss: 6.8307e-11
Epoch 108/512

Epoch 00108: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.8223e-11 - val_loss: 6.8019e-11
Epoch 109/512

Epoch 00109: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.7937e-11 - val_loss: 6.7749e-11
Epoch 110/512

Epoch 00110: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.7644e-11 - val_loss: 6.7482e-11
Epoch 111/512

Epoch 00111: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.7381e-11 - val_loss: 6.7171e-11
Epoch 112/512

Epoch 00112: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.7097e-11 - val_loss: 6.6910e-11
Epoch 113/512

Epoch 00113: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.6833e-11 - val_loss: 6.6640e-11
Epoch 114/512

Epoch 00114: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.6562e-11 - val_loss: 6.6358e-11
Epoch 115/512

Epoch 00115: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.6292e-11 - val_loss: 6.6118e-11
Epoch 116/512

Epoch 00116: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.6032e-11 - val_loss: 6.5858e-11
Epoch 117/512

Epoch 00117: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.5773e-11 - val_loss: 6.5601e-11
Epoch 118/512

Epoch 00118: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.5522e-11 - val_loss: 6.5358e-11
Epoch 119/512

Epoch 00119: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.5287e-11 - val_loss: 6.5116e-11
Epoch 120/512

Epoch 00120: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.5047e-11 - val_loss: 6.4823e-11
Epoch 121/512

Epoch 00121: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.4778e-11 - val_loss: 6.4620e-11
Epoch 122/512

Epoch 00122: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.4541e-11 - val_loss: 6.4366e-11
Epoch 123/512

Epoch 00123: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.4304e-11 - val_loss: 6.4114e-11
Epoch 124/512

Epoch 00124: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.4064e-11 - val_loss: 6.3868e-11
Epoch 125/512

Epoch 00125: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.3780e-11 - val_loss: 6.3654e-11
Epoch 126/512

Epoch 00126: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.3556e-11 - val_loss: 6.3397e-11
Epoch 127/512

Epoch 00127: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.3331e-11 - val_loss: 6.3155e-11
Epoch 128/512

Epoch 00128: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.3091e-11 - val_loss: 6.2925e-11
Epoch 129/512

Epoch 00129: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.2863e-11 - val_loss: 6.2721e-11
Epoch 130/512

Epoch 00130: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.2659e-11 - val_loss: 6.2498e-11
Epoch 131/512

Epoch 00131: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.2415e-11 - val_loss: 6.2253e-11
Epoch 132/512

Epoch 00132: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.2210e-11 - val_loss: 6.2054e-11
Epoch 133/512

Epoch 00133: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.2002e-11 - val_loss: 6.1850e-11
Epoch 134/512

Epoch 00134: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.1791e-11 - val_loss: 6.1636e-11
Epoch 135/512

Epoch 00135: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.1572e-11 - val_loss: 6.1418e-11
Epoch 136/512

Epoch 00136: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.1350e-11 - val_loss: 6.1219e-11
Epoch 137/512

Epoch 00137: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.1148e-11 - val_loss: 6.0999e-11
Epoch 138/512

Epoch 00138: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.0952e-11 - val_loss: 6.0792e-11
Epoch 139/512

Epoch 00139: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.0746e-11 - val_loss: 6.0568e-11
Epoch 140/512

Epoch 00140: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.0528e-11 - val_loss: 6.0394e-11
Epoch 141/512

Epoch 00141: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.0347e-11 - val_loss: 6.0183e-11
Epoch 142/512

Epoch 00142: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.0136e-11 - val_loss: 5.9983e-11
Epoch 143/512

Epoch 00143: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.9940e-11 - val_loss: 5.9795e-11
Epoch 144/512

Epoch 00144: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.9757e-11 - val_loss: 5.9630e-11
Epoch 145/512

Epoch 00145: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.9567e-11 - val_loss: 5.9425e-11
Epoch 146/512

Epoch 00146: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.9387e-11 - val_loss: 5.9256e-11
Epoch 147/512

Epoch 00147: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.9196e-11 - val_loss: 5.9065e-11
Epoch 148/512

Epoch 00148: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.8984e-11 - val_loss: 5.8819e-11
Epoch 149/512

Epoch 00149: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.8791e-11 - val_loss: 5.8652e-11
Epoch 150/512

Epoch 00150: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.8605e-11 - val_loss: 5.8449e-11
Epoch 151/512

Epoch 00151: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.8411e-11 - val_loss: 5.8284e-11
Epoch 152/512

Epoch 00152: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.8253e-11 - val_loss: 5.8123e-11
Epoch 153/512

Epoch 00153: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.8084e-11 - val_loss: 5.7961e-11
Epoch 154/512

Epoch 00154: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.7900e-11 - val_loss: 5.7770e-11
Epoch 155/512

Epoch 00155: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.7736e-11 - val_loss: 5.7602e-11
Epoch 156/512

Epoch 00156: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.7562e-11 - val_loss: 5.7438e-11
Epoch 157/512

Epoch 00157: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.7396e-11 - val_loss: 5.7262e-11
Epoch 158/512

Epoch 00158: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.7207e-11 - val_loss: 5.7090e-11
Epoch 159/512

Epoch 00159: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.7050e-11 - val_loss: 5.6918e-11
Epoch 160/512

Epoch 00160: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.6881e-11 - val_loss: 5.6718e-11
Epoch 161/512

Epoch 00161: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.6692e-11 - val_loss: 5.6568e-11
Epoch 162/512

Epoch 00162: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.6525e-11 - val_loss: 5.6400e-11
Epoch 163/512

Epoch 00163: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.6371e-11 - val_loss: 5.6243e-11
Epoch 164/512

Epoch 00164: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.6205e-11 - val_loss: 5.6098e-11
Epoch 165/512

Epoch 00165: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.6059e-11 - val_loss: 5.5955e-11
Epoch 166/512

Epoch 00166: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.5905e-11 - val_loss: 5.5772e-11
Epoch 167/512

Epoch 00167: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.5738e-11 - val_loss: 5.5614e-11
Epoch 168/512

Epoch 00168: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.5592e-11 - val_loss: 5.5489e-11
Epoch 169/512

Epoch 00169: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.5441e-11 - val_loss: 5.5332e-11
Epoch 170/512

Epoch 00170: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.5293e-11 - val_loss: 5.5155e-11
Epoch 171/512

Epoch 00171: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.5123e-11 - val_loss: 5.5017e-11
Epoch 172/512

Epoch 00172: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.4970e-11 - val_loss: 5.4873e-11
Epoch 173/512

Epoch 00173: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.4834e-11 - val_loss: 5.4718e-11
Epoch 174/512

Epoch 00174: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.4677e-11 - val_loss: 5.4556e-11
Epoch 175/512

Epoch 00175: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.4488e-11 - val_loss: 5.4376e-11
Epoch 176/512

Epoch 00176: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.4346e-11 - val_loss: 5.4252e-11
Epoch 177/512

Epoch 00177: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.4204e-11 - val_loss: 5.4066e-11
Epoch 178/512

Epoch 00178: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.4041e-11 - val_loss: 5.3975e-11
Epoch 179/512

Epoch 00179: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.3925e-11 - val_loss: 5.3827e-11
Epoch 180/512

Epoch 00180: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.3791e-11 - val_loss: 5.3680e-11
Epoch 181/512

Epoch 00181: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.3646e-11 - val_loss: 5.3519e-11
Epoch 182/512

Epoch 00182: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.3510e-11 - val_loss: 5.3375e-11
Epoch 183/512

Epoch 00183: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.3367e-11 - val_loss: 5.3250e-11
Epoch 184/512

Epoch 00184: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.3225e-11 - val_loss: 5.3126e-11
Epoch 185/512

Epoch 00185: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.3093e-11 - val_loss: 5.2993e-11
Epoch 186/512

Epoch 00186: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.2956e-11 - val_loss: 5.2874e-11
Epoch 187/512

Epoch 00187: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.2834e-11 - val_loss: 5.2734e-11
Epoch 188/512

Epoch 00188: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.2677e-11 - val_loss: 5.2560e-11
Epoch 189/512

Epoch 00189: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.2537e-11 - val_loss: 5.2441e-11
Epoch 190/512

Epoch 00190: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.2412e-11 - val_loss: 5.2305e-11
Epoch 191/512

Epoch 00191: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.2274e-11 - val_loss: 5.2206e-11
Epoch 192/512

Epoch 00192: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.2155e-11 - val_loss: 5.2045e-11
Epoch 193/512

Epoch 00193: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.2019e-11 - val_loss: 5.1930e-11
Epoch 194/512

Epoch 00194: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.1896e-11 - val_loss: 5.1804e-11
Epoch 195/512

Epoch 00195: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.1771e-11 - val_loss: 5.1665e-11
Epoch 196/512

Epoch 00196: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.1642e-11 - val_loss: 5.1544e-11
Epoch 197/512

Epoch 00197: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.1519e-11 - val_loss: 5.1432e-11
Epoch 198/512

Epoch 00198: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.1407e-11 - val_loss: 5.1313e-11
Epoch 199/512

Epoch 00199: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.1294e-11 - val_loss: 5.1166e-11
Epoch 200/512

Epoch 00200: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.1143e-11 - val_loss: 5.1056e-11
Epoch 201/512

Epoch 00201: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.1027e-11 - val_loss: 5.0913e-11
Epoch 202/512

Epoch 00202: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.0900e-11 - val_loss: 5.0806e-11
Epoch 203/512

Epoch 00203: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.0785e-11 - val_loss: 5.0662e-11
Epoch 204/512

Epoch 00204: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.0651e-11 - val_loss: 5.0573e-11
Epoch 205/512

Epoch 00205: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.0545e-11 - val_loss: 5.0450e-11
Epoch 206/512

Epoch 00206: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.0429e-11 - val_loss: 5.0329e-11
Epoch 207/512

Epoch 00207: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.0305e-11 - val_loss: 5.0188e-11
Epoch 208/512

Epoch 00208: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.0190e-11 - val_loss: 5.0102e-11
Epoch 209/512

Epoch 00209: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.0080e-11 - val_loss: 5.0009e-11
Epoch 210/512

Epoch 00210: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.9970e-11 - val_loss: 4.9879e-11
Epoch 211/512

Epoch 00211: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.9863e-11 - val_loss: 4.9778e-11
Epoch 212/512

Epoch 00212: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.9755e-11 - val_loss: 4.9671e-11
Epoch 213/512

Epoch 00213: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.9646e-11 - val_loss: 4.9553e-11
Epoch 214/512

Epoch 00214: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.9525e-11 - val_loss: 4.9435e-11
Epoch 215/512

Epoch 00215: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.9417e-11 - val_loss: 4.9330e-11
Epoch 216/512

Epoch 00216: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.9284e-11 - val_loss: 4.9206e-11
Epoch 217/512

Epoch 00217: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.9174e-11 - val_loss: 4.9092e-11
Epoch 218/512

Epoch 00218: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.9076e-11 - val_loss: 4.8976e-11
Epoch 219/512

Epoch 00219: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.8962e-11 - val_loss: 4.8872e-11
Epoch 220/512

Epoch 00220: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.8861e-11 - val_loss: 4.8777e-11
Epoch 221/512

Epoch 00221: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.8756e-11 - val_loss: 4.8657e-11
Epoch 222/512

Epoch 00222: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.8659e-11 - val_loss: 4.8546e-11
Epoch 223/512

Epoch 00223: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.8535e-11 - val_loss: 4.8470e-11
Epoch 224/512

Epoch 00224: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.8443e-11 - val_loss: 4.8358e-11
Epoch 225/512

Epoch 00225: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.8336e-11 - val_loss: 4.8237e-11
Epoch 226/512

Epoch 00226: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.8222e-11 - val_loss: 4.8146e-11
Epoch 227/512

Epoch 00227: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.8109e-11 - val_loss: 4.8019e-11
Epoch 228/512

Epoch 00228: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.8008e-11 - val_loss: 4.7903e-11
Epoch 229/512

Epoch 00229: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.7899e-11 - val_loss: 4.7831e-11
Epoch 230/512

Epoch 00230: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.7813e-11 - val_loss: 4.7733e-11
Epoch 231/512

Epoch 00231: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.7701e-11 - val_loss: 4.7620e-11
Epoch 232/512

Epoch 00232: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.7597e-11 - val_loss: 4.7507e-11
Epoch 233/512

Epoch 00233: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.7483e-11 - val_loss: 4.7401e-11
Epoch 234/512

Epoch 00234: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.7388e-11 - val_loss: 4.7322e-11
Epoch 235/512

Epoch 00235: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.7302e-11 - val_loss: 4.7203e-11
Epoch 236/512

Epoch 00236: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.7194e-11 - val_loss: 4.7132e-11
Epoch 237/512

Epoch 00237: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.7102e-11 - val_loss: 4.7031e-11
Epoch 238/512

Epoch 00238: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.7009e-11 - val_loss: 4.6929e-11
Epoch 239/512

Epoch 00239: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.6916e-11 - val_loss: 4.6838e-11
Epoch 240/512

Epoch 00240: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.6825e-11 - val_loss: 4.6760e-11
Epoch 241/512

Epoch 00241: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.6742e-11 - val_loss: 4.6636e-11
Epoch 242/512

Epoch 00242: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.6639e-11 - val_loss: 4.6579e-11
Epoch 243/512

Epoch 00243: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.6542e-11 - val_loss: 4.6462e-11
Epoch 244/512

Epoch 00244: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.6446e-11 - val_loss: 4.6380e-11
Epoch 245/512

Epoch 00245: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.6360e-11 - val_loss: 4.6298e-11
Epoch 246/512

Epoch 00246: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.6284e-11 - val_loss: 4.6200e-11
Epoch 247/512

Epoch 00247: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.6174e-11 - val_loss: 4.6085e-11
Epoch 248/512

Epoch 00248: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.6073e-11 - val_loss: 4.5985e-11
Epoch 249/512

Epoch 00249: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.5977e-11 - val_loss: 4.5905e-11
Epoch 250/512

Epoch 00250: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.5890e-11 - val_loss: 4.5825e-11
Epoch 251/512

Epoch 00251: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.5810e-11 - val_loss: 4.5752e-11
Epoch 252/512

Epoch 00252: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.5718e-11 - val_loss: 4.5641e-11
Epoch 253/512

Epoch 00253: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.5626e-11 - val_loss: 4.5555e-11
Epoch 254/512

Epoch 00254: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.5547e-11 - val_loss: 4.5461e-11
Epoch 255/512

Epoch 00255: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.5459e-11 - val_loss: 4.5392e-11
Epoch 256/512

Epoch 00256: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.5379e-11 - val_loss: 4.5290e-11
Epoch 257/512

Epoch 00257: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.5280e-11 - val_loss: 4.5207e-11
Epoch 258/512

Epoch 00258: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.5197e-11 - val_loss: 4.5125e-11
Epoch 259/512

Epoch 00259: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.5120e-11 - val_loss: 4.5062e-11
Epoch 260/512

Epoch 00260: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.5044e-11 - val_loss: 4.4942e-11
Epoch 261/512

Epoch 00261: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.4943e-11 - val_loss: 4.4883e-11
Epoch 262/512

Epoch 00262: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.4863e-11 - val_loss: 4.4810e-11
Epoch 263/512

Epoch 00263: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.4781e-11 - val_loss: 4.4702e-11
Epoch 264/512

Epoch 00264: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.4690e-11 - val_loss: 4.4629e-11
Epoch 265/512

Epoch 00265: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.4613e-11 - val_loss: 4.4519e-11
Epoch 266/512

Epoch 00266: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.4523e-11 - val_loss: 4.4460e-11
Epoch 267/512

Epoch 00267: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.4444e-11 - val_loss: 4.4359e-11
Epoch 268/512

Epoch 00268: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.4351e-11 - val_loss: 4.4302e-11
Epoch 269/512

Epoch 00269: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.4284e-11 - val_loss: 4.4215e-11
Epoch 270/512

Epoch 00270: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.4206e-11 - val_loss: 4.4127e-11
Epoch 271/512

Epoch 00271: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.4119e-11 - val_loss: 4.4056e-11
Epoch 272/512

Epoch 00272: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.4053e-11 - val_loss: 4.3986e-11
Epoch 273/512

Epoch 00273: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.3963e-11 - val_loss: 4.3873e-11
Epoch 274/512

Epoch 00274: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.3869e-11 - val_loss: 4.3810e-11
Epoch 275/512

Epoch 00275: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.3797e-11 - val_loss: 4.3741e-11
Epoch 276/512

Epoch 00276: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.3705e-11 - val_loss: 4.3611e-11
Epoch 277/512

Epoch 00277: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.3621e-11 - val_loss: 4.3544e-11
Epoch 278/512

Epoch 00278: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.3530e-11 - val_loss: 4.3466e-11
Epoch 279/512

Epoch 00279: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.3469e-11 - val_loss: 4.3393e-11
Epoch 280/512

Epoch 00280: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.3378e-11 - val_loss: 4.3308e-11
Epoch 281/512

Epoch 00281: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.3298e-11 - val_loss: 4.3235e-11
Epoch 282/512

Epoch 00282: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.3224e-11 - val_loss: 4.3168e-11
Epoch 283/512

Epoch 00283: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.3137e-11 - val_loss: 4.3096e-11
Epoch 284/512

Epoch 00284: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.3067e-11 - val_loss: 4.2997e-11
Epoch 285/512

Epoch 00285: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.2992e-11 - val_loss: 4.2931e-11
Epoch 286/512

Epoch 00286: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.2925e-11 - val_loss: 4.2866e-11
Epoch 287/512

Epoch 00287: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.2850e-11 - val_loss: 4.2801e-11
Epoch 288/512

Epoch 00288: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.2783e-11 - val_loss: 4.2707e-11
Epoch 289/512

Epoch 00289: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.2703e-11 - val_loss: 4.2639e-11
Epoch 290/512

Epoch 00290: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.2634e-11 - val_loss: 4.2578e-11
Epoch 291/512

Epoch 00291: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.2564e-11 - val_loss: 4.2499e-11
Epoch 292/512

Epoch 00292: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.2491e-11 - val_loss: 4.2436e-11
Epoch 293/512

Epoch 00293: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.2428e-11 - val_loss: 4.2341e-11
Epoch 294/512

Epoch 00294: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.2346e-11 - val_loss: 4.2278e-11
Epoch 295/512

Epoch 00295: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.2272e-11 - val_loss: 4.2216e-11
Epoch 296/512

Epoch 00296: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.2209e-11 - val_loss: 4.2170e-11
Epoch 297/512

Epoch 00297: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.2146e-11 - val_loss: 4.2078e-11
Epoch 298/512

Epoch 00298: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.2065e-11 - val_loss: 4.2002e-11
Epoch 299/512

Epoch 00299: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1994e-11 - val_loss: 4.1917e-11
Epoch 300/512

Epoch 00300: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1911e-11 - val_loss: 4.1863e-11
Epoch 301/512

Epoch 00301: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1857e-11 - val_loss: 4.1781e-11
Epoch 302/512

Epoch 00302: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1776e-11 - val_loss: 4.1714e-11
Epoch 303/512

Epoch 00303: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1713e-11 - val_loss: 4.1660e-11
Epoch 304/512

Epoch 00304: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1648e-11 - val_loss: 4.1594e-11
Epoch 305/512

Epoch 00305: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1581e-11 - val_loss: 4.1519e-11
Epoch 306/512

Epoch 00306: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1507e-11 - val_loss: 4.1476e-11
Epoch 307/512

Epoch 00307: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1453e-11 - val_loss: 4.1379e-11
Epoch 308/512

Epoch 00308: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1375e-11 - val_loss: 4.1319e-11
Epoch 309/512

Epoch 00309: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1307e-11 - val_loss: 4.1261e-11
Epoch 310/512

Epoch 00310: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1243e-11 - val_loss: 4.1187e-11
Epoch 311/512

Epoch 00311: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1182e-11 - val_loss: 4.1145e-11
Epoch 312/512

Epoch 00312: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1126e-11 - val_loss: 4.1057e-11
Epoch 313/512

Epoch 00313: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1052e-11 - val_loss: 4.0986e-11
Epoch 314/512

Epoch 00314: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0992e-11 - val_loss: 4.0930e-11
Epoch 315/512

Epoch 00315: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0931e-11 - val_loss: 4.0879e-11
Epoch 316/512

Epoch 00316: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0860e-11 - val_loss: 4.0778e-11
Epoch 317/512

Epoch 00317: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0793e-11 - val_loss: 4.0715e-11
Epoch 318/512

Epoch 00318: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0712e-11 - val_loss: 4.0658e-11
Epoch 319/512

Epoch 00319: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0657e-11 - val_loss: 4.0602e-11
Epoch 320/512

Epoch 00320: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0601e-11 - val_loss: 4.0546e-11
Epoch 321/512

Epoch 00321: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0537e-11 - val_loss: 4.0473e-11
Epoch 322/512

Epoch 00322: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0473e-11 - val_loss: 4.0429e-11
Epoch 323/512

Epoch 00323: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0415e-11 - val_loss: 4.0339e-11
Epoch 324/512

Epoch 00324: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0335e-11 - val_loss: 4.0278e-11
Epoch 325/512

Epoch 00325: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0281e-11 - val_loss: 4.0229e-11
Epoch 326/512

Epoch 00326: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0225e-11 - val_loss: 4.0169e-11
Epoch 327/512

Epoch 00327: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0147e-11 - val_loss: 4.0086e-11
Epoch 328/512

Epoch 00328: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0076e-11 - val_loss: 3.9998e-11
Epoch 329/512

Epoch 00329: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0008e-11 - val_loss: 3.9944e-11
Epoch 330/512

Epoch 00330: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9952e-11 - val_loss: 3.9890e-11
Epoch 331/512

Epoch 00331: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9888e-11 - val_loss: 3.9831e-11
Epoch 332/512

Epoch 00332: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9838e-11 - val_loss: 3.9778e-11
Epoch 333/512

Epoch 00333: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9762e-11 - val_loss: 3.9697e-11
Epoch 334/512

Epoch 00334: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9714e-11 - val_loss: 3.9658e-11
Epoch 335/512

Epoch 00335: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9656e-11 - val_loss: 3.9577e-11
Epoch 336/512

Epoch 00336: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9585e-11 - val_loss: 3.9526e-11
Epoch 337/512

Epoch 00337: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9528e-11 - val_loss: 3.9467e-11
Epoch 338/512

Epoch 00338: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9473e-11 - val_loss: 3.9415e-11
Epoch 339/512

Epoch 00339: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9414e-11 - val_loss: 3.9344e-11
Epoch 340/512

Epoch 00340: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9353e-11 - val_loss: 3.9280e-11
Epoch 341/512

Epoch 00341: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9281e-11 - val_loss: 3.9221e-11
Epoch 342/512

Epoch 00342: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9225e-11 - val_loss: 3.9171e-11
Epoch 343/512

Epoch 00343: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9172e-11 - val_loss: 3.9120e-11
Epoch 344/512

Epoch 00344: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9116e-11 - val_loss: 3.9070e-11
Epoch 345/512

Epoch 00345: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9070e-11 - val_loss: 3.9006e-11
Epoch 346/512

Epoch 00346: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9011e-11 - val_loss: 3.8956e-11
Epoch 347/512

Epoch 00347: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8957e-11 - val_loss: 3.8892e-11
Epoch 348/512

Epoch 00348: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8887e-11 - val_loss: 3.8858e-11
Epoch 349/512

Epoch 00349: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8843e-11 - val_loss: 3.8781e-11
Epoch 350/512

Epoch 00350: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8784e-11 - val_loss: 3.8720e-11
Epoch 351/512

Epoch 00351: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8727e-11 - val_loss: 3.8689e-11
Epoch 352/512

Epoch 00352: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8683e-11 - val_loss: 3.8640e-11
Epoch 353/512

Epoch 00353: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8627e-11 - val_loss: 3.8558e-11
Epoch 354/512

Epoch 00354: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8566e-11 - val_loss: 3.8510e-11
Epoch 355/512

Epoch 00355: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8500e-11 - val_loss: 3.8443e-11
Epoch 356/512

Epoch 00356: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8438e-11 - val_loss: 3.8400e-11
Epoch 357/512

Epoch 00357: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8395e-11 - val_loss: 3.8340e-11
Epoch 358/512

Epoch 00358: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8342e-11 - val_loss: 3.8298e-11
Epoch 359/512

Epoch 00359: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8295e-11 - val_loss: 3.8224e-11
Epoch 360/512

Epoch 00360: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8233e-11 - val_loss: 3.8171e-11
Epoch 361/512

Epoch 00361: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8170e-11 - val_loss: 3.8112e-11
Epoch 362/512

Epoch 00362: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8117e-11 - val_loss: 3.8071e-11
Epoch 363/512

Epoch 00363: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8071e-11 - val_loss: 3.8025e-11
Epoch 364/512

Epoch 00364: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8025e-11 - val_loss: 3.7978e-11
Epoch 365/512

Epoch 00365: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7974e-11 - val_loss: 3.7905e-11
Epoch 366/512

Epoch 00366: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7908e-11 - val_loss: 3.7859e-11
Epoch 367/512

Epoch 00367: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7859e-11 - val_loss: 3.7802e-11
Epoch 368/512

Epoch 00368: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7803e-11 - val_loss: 3.7756e-11
Epoch 369/512

Epoch 00369: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7759e-11 - val_loss: 3.7710e-11
Epoch 370/512

Epoch 00370: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7716e-11 - val_loss: 3.7670e-11
Epoch 371/512

Epoch 00371: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7650e-11 - val_loss: 3.7606e-11
Epoch 372/512

Epoch 00372: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7605e-11 - val_loss: 3.7574e-11
Epoch 373/512

Epoch 00373: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7557e-11 - val_loss: 3.7503e-11
Epoch 374/512

Epoch 00374: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7507e-11 - val_loss: 3.7457e-11
Epoch 375/512

Epoch 00375: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7453e-11 - val_loss: 3.7388e-11
Epoch 376/512

Epoch 00376: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7392e-11 - val_loss: 3.7330e-11
Epoch 377/512

Epoch 00377: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7341e-11 - val_loss: 3.7305e-11
Epoch 378/512

Epoch 00378: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7299e-11 - val_loss: 3.7242e-11
Epoch 379/512

Epoch 00379: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7246e-11 - val_loss: 3.7170e-11
Epoch 380/512

Epoch 00380: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7170e-11 - val_loss: 3.7113e-11
Epoch 381/512

Epoch 00381: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7116e-11 - val_loss: 3.7068e-11
Epoch 382/512

Epoch 00382: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7065e-11 - val_loss: 3.7015e-11
Epoch 383/512

Epoch 00383: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7019e-11 - val_loss: 3.6976e-11
Epoch 384/512

Epoch 00384: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6967e-11 - val_loss: 3.6914e-11
Epoch 385/512

Epoch 00385: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6923e-11 - val_loss: 3.6872e-11
Epoch 386/512

Epoch 00386: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6881e-11 - val_loss: 3.6816e-11
Epoch 387/512

Epoch 00387: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6827e-11 - val_loss: 3.6768e-11
Epoch 388/512

Epoch 00388: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6767e-11 - val_loss: 3.6712e-11
Epoch 389/512

Epoch 00389: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6719e-11 - val_loss: 3.6657e-11
Epoch 390/512

Epoch 00390: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6677e-11 - val_loss: 3.6628e-11
Epoch 391/512

Epoch 00391: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6631e-11 - val_loss: 3.6585e-11
Epoch 392/512

Epoch 00392: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6583e-11 - val_loss: 3.6524e-11
Epoch 393/512

Epoch 00393: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6530e-11 - val_loss: 3.6483e-11
Epoch 394/512

Epoch 00394: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6488e-11 - val_loss: 3.6447e-11
Epoch 395/512

Epoch 00395: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6443e-11 - val_loss: 3.6382e-11
Epoch 396/512

Epoch 00396: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6399e-11 - val_loss: 3.6352e-11
Epoch 397/512

Epoch 00397: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6342e-11 - val_loss: 3.6299e-11
Epoch 398/512

Epoch 00398: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6292e-11 - val_loss: 3.6233e-11
Epoch 399/512

Epoch 00399: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6244e-11 - val_loss: 3.6192e-11
Epoch 400/512

Epoch 00400: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6196e-11 - val_loss: 3.6151e-11
Epoch 401/512

Epoch 00401: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6156e-11 - val_loss: 3.6096e-11
Epoch 402/512

Epoch 00402: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6101e-11 - val_loss: 3.6056e-11
Epoch 403/512

Epoch 00403: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6058e-11 - val_loss: 3.5993e-11
Epoch 404/512

Epoch 00404: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6004e-11 - val_loss: 3.5972e-11
Epoch 405/512

Epoch 00405: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5960e-11 - val_loss: 3.5912e-11
Epoch 406/512

Epoch 00406: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5909e-11 - val_loss: 3.5859e-11
Epoch 407/512

Epoch 00407: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5861e-11 - val_loss: 3.5815e-11
Epoch 408/512

Epoch 00408: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5822e-11 - val_loss: 3.5762e-11
Epoch 409/512

Epoch 00409: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5778e-11 - val_loss: 3.5736e-11
Epoch 410/512

Epoch 00410: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5742e-11 - val_loss: 3.5696e-11
Epoch 411/512

Epoch 00411: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5699e-11 - val_loss: 3.5645e-11
Epoch 412/512

Epoch 00412: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5646e-11 - val_loss: 3.5588e-11
Epoch 413/512

Epoch 00413: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5597e-11 - val_loss: 3.5549e-11
Epoch 414/512

Epoch 00414: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5561e-11 - val_loss: 3.5515e-11
Epoch 415/512

Epoch 00415: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5525e-11 - val_loss: 3.5489e-11
Epoch 416/512

Epoch 00416: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5481e-11 - val_loss: 3.5439e-11
Epoch 417/512

Epoch 00417: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5438e-11 - val_loss: 3.5376e-11
Epoch 418/512

Epoch 00418: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5384e-11 - val_loss: 3.5326e-11
Epoch 419/512

Epoch 00419: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5330e-11 - val_loss: 3.5275e-11
Epoch 420/512

Epoch 00420: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5293e-11 - val_loss: 3.5250e-11
Epoch 421/512

Epoch 00421: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5250e-11 - val_loss: 3.5200e-11
Epoch 422/512

Epoch 00422: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5203e-11 - val_loss: 3.5162e-11
Epoch 423/512

Epoch 00423: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5166e-11 - val_loss: 3.5119e-11
Epoch 424/512

Epoch 00424: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5118e-11 - val_loss: 3.5074e-11
Epoch 425/512

Epoch 00425: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5076e-11 - val_loss: 3.5026e-11
Epoch 426/512

Epoch 00426: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5038e-11 - val_loss: 3.4977e-11
Epoch 427/512

Epoch 00427: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4983e-11 - val_loss: 3.4947e-11
Epoch 428/512

Epoch 00428: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4951e-11 - val_loss: 3.4898e-11
Epoch 429/512

Epoch 00429: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4903e-11 - val_loss: 3.4861e-11
Epoch 430/512

Epoch 00430: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4860e-11 - val_loss: 3.4811e-11
Epoch 431/512

Epoch 00431: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4826e-11 - val_loss: 3.4787e-11
Epoch 432/512

Epoch 00432: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4791e-11 - val_loss: 3.4724e-11
Epoch 433/512

Epoch 00433: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4720e-11 - val_loss: 3.4674e-11
Epoch 434/512

Epoch 00434: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4676e-11 - val_loss: 3.4615e-11
Epoch 435/512

Epoch 00435: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4623e-11 - val_loss: 3.4579e-11
Epoch 436/512

Epoch 00436: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4588e-11 - val_loss: 3.4543e-11
Epoch 437/512

Epoch 00437: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4553e-11 - val_loss: 3.4513e-11
Epoch 438/512

Epoch 00438: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4508e-11 - val_loss: 3.4459e-11
Epoch 439/512

Epoch 00439: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4468e-11 - val_loss: 3.4423e-11
Epoch 440/512

Epoch 00440: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4433e-11 - val_loss: 3.4401e-11
Epoch 441/512

Epoch 00441: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4378e-11 - val_loss: 3.4323e-11
Epoch 442/512

Epoch 00442: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4338e-11 - val_loss: 3.4288e-11
Epoch 443/512

Epoch 00443: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4296e-11 - val_loss: 3.4253e-11
Epoch 444/512

Epoch 00444: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4263e-11 - val_loss: 3.4218e-11
Epoch 445/512

Epoch 00445: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4221e-11 - val_loss: 3.4189e-11
Epoch 446/512

Epoch 00446: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4181e-11 - val_loss: 3.4148e-11
Epoch 447/512

Epoch 00447: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4147e-11 - val_loss: 3.4108e-11
Epoch 448/512

Epoch 00448: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4097e-11 - val_loss: 3.4060e-11
Epoch 449/512

Epoch 00449: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4064e-11 - val_loss: 3.4014e-11
Epoch 450/512

Epoch 00450: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4021e-11 - val_loss: 3.3975e-11
Epoch 451/512

Epoch 00451: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3981e-11 - val_loss: 3.3940e-11
Epoch 452/512

Epoch 00452: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3947e-11 - val_loss: 3.3906e-11
Epoch 453/512

Epoch 00453: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3909e-11 - val_loss: 3.3863e-11
Epoch 454/512

Epoch 00454: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3873e-11 - val_loss: 3.3815e-11
Epoch 455/512

Epoch 00455: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3826e-11 - val_loss: 3.3780e-11
Epoch 456/512

Epoch 00456: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3787e-11 - val_loss: 3.3758e-11
Epoch 457/512

Epoch 00457: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3754e-11 - val_loss: 3.3703e-11
Epoch 458/512

Epoch 00458: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3709e-11 - val_loss: 3.3669e-11
Epoch 459/512

Epoch 00459: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3674e-11 - val_loss: 3.3635e-11
Epoch 460/512

Epoch 00460: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3642e-11 - val_loss: 3.3603e-11
Epoch 461/512

Epoch 00461: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3608e-11 - val_loss: 3.3569e-11
Epoch 462/512

Epoch 00462: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3555e-11 - val_loss: 3.3514e-11
Epoch 463/512

Epoch 00463: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3525e-11 - val_loss: 3.3503e-11
Epoch 464/512

Epoch 00464: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3492e-11 - val_loss: 3.3446e-11
Epoch 465/512

Epoch 00465: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3442e-11 - val_loss: 3.3392e-11
Epoch 466/512

Epoch 00466: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3403e-11 - val_loss: 3.3376e-11
Epoch 467/512

Epoch 00467: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3371e-11 - val_loss: 3.3336e-11
Epoch 468/512

Epoch 00468: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3336e-11 - val_loss: 3.3287e-11
Epoch 469/512

Epoch 00469: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3290e-11 - val_loss: 3.3250e-11
Epoch 470/512

Epoch 00470: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3260e-11 - val_loss: 3.3205e-11
Epoch 471/512

Epoch 00471: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3214e-11 - val_loss: 3.3196e-11
Epoch 472/512

Epoch 00472: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3192e-11 - val_loss: 3.3142e-11
Epoch 473/512

Epoch 00473: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3150e-11 - val_loss: 3.3110e-11
Epoch 474/512

Epoch 00474: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3112e-11 - val_loss: 3.3068e-11
Epoch 475/512

Epoch 00475: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3071e-11 - val_loss: 3.3019e-11
Epoch 476/512

Epoch 00476: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3032e-11 - val_loss: 3.2981e-11
Epoch 477/512

Epoch 00477: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2995e-11 - val_loss: 3.2961e-11
Epoch 478/512

Epoch 00478: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2965e-11 - val_loss: 3.2929e-11
Epoch 479/512

Epoch 00479: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2936e-11 - val_loss: 3.2898e-11
Epoch 480/512

Epoch 00480: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2901e-11 - val_loss: 3.2850e-11
Epoch 481/512

Epoch 00481: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2862e-11 - val_loss: 3.2818e-11
Epoch 482/512

Epoch 00482: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2824e-11 - val_loss: 3.2787e-11
Epoch 483/512

Epoch 00483: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2791e-11 - val_loss: 3.2732e-11
Epoch 484/512

Epoch 00484: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2751e-11 - val_loss: 3.2708e-11
Epoch 485/512

Epoch 00485: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2722e-11 - val_loss: 3.2688e-11
Epoch 486/512

Epoch 00486: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2681e-11 - val_loss: 3.2613e-11
Epoch 487/512

Epoch 00487: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2618e-11 - val_loss: 3.2571e-11
Epoch 488/512

Epoch 00488: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2581e-11 - val_loss: 3.2540e-11
Epoch 489/512

Epoch 00489: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2542e-11 - val_loss: 3.2510e-11
Epoch 490/512

Epoch 00490: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2510e-11 - val_loss: 3.2468e-11
Epoch 491/512

Epoch 00491: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2477e-11 - val_loss: 3.2443e-11
Epoch 492/512

Epoch 00492: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2445e-11 - val_loss: 3.2385e-11
Epoch 493/512

Epoch 00493: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2398e-11 - val_loss: 3.2365e-11
Epoch 494/512

Epoch 00494: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2364e-11 - val_loss: 3.2324e-11
Epoch 495/512

Epoch 00495: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2329e-11 - val_loss: 3.2295e-11
Epoch 496/512

Epoch 00496: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2301e-11 - val_loss: 3.2264e-11
Epoch 497/512

Epoch 00497: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2272e-11 - val_loss: 3.2214e-11
Epoch 498/512

Epoch 00498: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2228e-11 - val_loss: 3.2195e-11
Epoch 499/512

Epoch 00499: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2198e-11 - val_loss: 3.2139e-11
Epoch 500/512

Epoch 00500: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2159e-11 - val_loss: 3.2124e-11
Epoch 501/512

Epoch 00501: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2121e-11 - val_loss: 3.2078e-11
Epoch 502/512

Epoch 00502: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2085e-11 - val_loss: 3.2048e-11
Epoch 503/512

Epoch 00503: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2064e-11 - val_loss: 3.2019e-11
Epoch 504/512

Epoch 00504: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2028e-11 - val_loss: 3.1990e-11
Epoch 505/512

Epoch 00505: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.1995e-11 - val_loss: 3.1950e-11
Epoch 506/512

Epoch 00506: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.1962e-11 - val_loss: 3.1926e-11
Epoch 507/512

Epoch 00507: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.1935e-11 - val_loss: 3.1897e-11
Epoch 508/512

Epoch 00508: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.1906e-11 - val_loss: 3.1873e-11
Epoch 509/512

Epoch 00509: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.1862e-11 - val_loss: 3.1817e-11
Epoch 510/512

Epoch 00510: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.1829e-11 - val_loss: 3.1788e-11
Epoch 511/512

Epoch 00511: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.1798e-11 - val_loss: 3.1759e-11
Epoch 512/512

Epoch 00512: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr-00005-2/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.1765e-11 - val_loss: 3.1731e-11
WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?
WARNING:tensorflow:From /home/stud/minawoi/miniconda3/envs/conda-venv/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?
Epoch   0:   0% | abe: 9.089 | eve: 9.012 | bob: 9.041Epoch   0:   0% | abe: 9.113 | eve: 9.019 | bob: 9.065Epoch   0:   1% | abe: 9.107 | eve: 9.019 | bob: 9.057Epoch   0:   2% | abe: 9.098 | eve: 9.015 | bob: 9.047Epoch   0:   3% | abe: 9.099 | eve: 9.015 | bob: 9.048Epoch   0:   3% | abe: 9.095 | eve: 9.014 | bob: 9.044Epoch   0:   4% | abe: 9.097 | eve: 9.012 | bob: 9.047Epoch   0:   5% | abe: 9.094 | eve: 9.010 | bob: 9.043Epoch   0:   6% | abe: 9.090 | eve: 9.007 | bob: 9.038Epoch   0:   7% | abe: 9.090 | eve: 9.003 | bob: 9.038Epoch   0:   7% | abe: 9.089 | eve: 9.002 | bob: 9.036Epoch   0:   8% | abe: 9.091 | eve: 9.000 | bob: 9.038Epoch   0:   9% | abe: 9.091 | eve: 8.999 | bob: 9.038Epoch   0:  10% | abe: 9.089 | eve: 8.997 | bob: 9.036Epoch   0:  10% | abe: 9.090 | eve: 8.993 | bob: 9.037Epoch   0:  11% | abe: 9.090 | eve: 8.995 | bob: 9.036Epoch   0:  12% | abe: 9.090 | eve: 8.995 | bob: 9.036Epoch   0:  13% | abe: 9.088 | eve: 8.996 | bob: 9.034Epoch   0:  14% | abe: 9.087 | eve: 8.997 | bob: 9.032Epoch   0:  14% | abe: 9.088 | eve: 8.998 | bob: 9.033Epoch   0:  15% | abe: 9.088 | eve: 8.998 | bob: 9.032Epoch   0:  16% | abe: 9.087 | eve: 8.998 | bob: 9.031Epoch   0:  17% | abe: 9.086 | eve: 8.999 | bob: 9.029Epoch   0:  17% | abe: 9.087 | eve: 8.999 | bob: 9.030Epoch   0:  18% | abe: 9.086 | eve: 9.001 | bob: 9.028Epoch   0:  19% | abe: 9.084 | eve: 9.001 | bob: 9.027Epoch   0:  20% | abe: 9.083 | eve: 9.001 | bob: 9.025Epoch   0:  21% | abe: 9.084 | eve: 9.001 | bob: 9.026Epoch   0:  21% | abe: 9.084 | eve: 9.002 | bob: 9.026Epoch   0:  22% | abe: 9.084 | eve: 9.004 | bob: 9.025Epoch   0:  23% | abe: 9.084 | eve: 9.003 | bob: 9.025Epoch   0:  24% | abe: 9.084 | eve: 9.003 | bob: 9.024Epoch   0:  25% | abe: 9.083 | eve: 9.003 | bob: 9.023Epoch   0:  25% | abe: 9.082 | eve: 9.002 | bob: 9.023Epoch   0:  26% | abe: 9.083 | eve: 9.003 | bob: 9.023Epoch   0:  27% | abe: 9.082 | eve: 9.003 | bob: 9.022Epoch   0:  28% | abe: 9.082 | eve: 9.003 | bob: 9.022Epoch   0:  28% | abe: 9.082 | eve: 9.004 | bob: 9.022Epoch   0:  29% | abe: 9.082 | eve: 9.003 | bob: 9.022Epoch   0:  30% | abe: 9.083 | eve: 9.004 | bob: 9.023Epoch   0:  31% | abe: 9.083 | eve: 9.004 | bob: 9.023Epoch   0:  32% | abe: 9.083 | eve: 9.004 | bob: 9.023Epoch   0:  32% | abe: 9.082 | eve: 9.003 | bob: 9.022Epoch   0:  33% | abe: 9.082 | eve: 9.003 | bob: 9.021Epoch   0:  34% | abe: 9.082 | eve: 9.003 | bob: 9.022Epoch   0:  35% | abe: 9.082 | eve: 9.002 | bob: 9.022Epoch   0:  35% | abe: 9.083 | eve: 9.002 | bob: 9.022Epoch   0:  36% | abe: 9.083 | eve: 9.001 | bob: 9.022Epoch   0:  37% | abe: 9.083 | eve: 9.001 | bob: 9.022Epoch   0:  38% | abe: 9.083 | eve: 9.001 | bob: 9.022Epoch   0:  39% | abe: 9.083 | eve: 9.000 | bob: 9.022Epoch   0:  39% | abe: 9.082 | eve: 9.000 | bob: 9.022Epoch   0:  40% | abe: 9.082 | eve: 9.000 | bob: 9.022Epoch   0:  41% | abe: 9.082 | eve: 9.000 | bob: 9.021Epoch   0:  42% | abe: 9.082 | eve: 9.000 | bob: 9.021Epoch   0:  42% | abe: 9.082 | eve: 8.999 | bob: 9.021Epoch   0:  43% | abe: 9.082 | eve: 9.000 | bob: 9.021Epoch   0:  44% | abe: 9.082 | eve: 9.000 | bob: 9.021Epoch   0:  45% | abe: 9.081 | eve: 9.000 | bob: 9.021Epoch   0:  46% | abe: 9.082 | eve: 9.000 | bob: 9.021Epoch   0:  46% | abe: 9.082 | eve: 9.000 | bob: 9.022Epoch   0:  47% | abe: 9.081 | eve: 9.000 | bob: 9.021Epoch   0:  48% | abe: 9.081 | eve: 9.000 | bob: 9.021Epoch   0:  49% | abe: 9.081 | eve: 9.000 | bob: 9.021Epoch   0:  50% | abe: 9.081 | eve: 9.000 | bob: 9.021Epoch   0:  50% | abe: 9.081 | eve: 9.000 | bob: 9.021Epoch   0:  51% | abe: 9.081 | eve: 9.000 | bob: 9.022Epoch   0:  52% | abe: 9.081 | eve: 9.000 | bob: 9.021Epoch   0:  53% | abe: 9.081 | eve: 9.001 | bob: 9.021Epoch   0:  53% | abe: 9.081 | eve: 9.000 | bob: 9.021Epoch   0:  54% | abe: 9.081 | eve: 9.000 | bob: 9.021Epoch   0:  55% | abe: 9.081 | eve: 8.999 | bob: 9.021Epoch   0:  56% | abe: 9.081 | eve: 9.000 | bob: 9.021Epoch   0:  57% | abe: 9.081 | eve: 9.000 | bob: 9.022Epoch   0:  57% | abe: 9.081 | eve: 9.000 | bob: 9.022Epoch   0:  58% | abe: 9.081 | eve: 9.000 | bob: 9.022Epoch   0:  59% | abe: 9.081 | eve: 9.000 | bob: 9.022Epoch   0:  60% | abe: 9.082 | eve: 8.999 | bob: 9.022Epoch   0:  60% | abe: 9.082 | eve: 8.999 | bob: 9.022Epoch   0:  61% | abe: 9.082 | eve: 8.999 | bob: 9.022Epoch   0:  62% | abe: 9.082 | eve: 8.999 | bob: 9.022Epoch   0:  63% | abe: 9.082 | eve: 8.999 | bob: 9.022Epoch   0:  64% | abe: 9.082 | eve: 8.999 | bob: 9.022Epoch   0:  64% | abe: 9.081 | eve: 8.999 | bob: 9.021Epoch   0:  65% | abe: 9.081 | eve: 8.999 | bob: 9.021Epoch   0:  66% | abe: 9.081 | eve: 8.999 | bob: 9.021Epoch   0:  67% | abe: 9.081 | eve: 8.999 | bob: 9.021Epoch   0:  67% | abe: 9.080 | eve: 8.999 | bob: 9.020Epoch   0:  68% | abe: 9.080 | eve: 8.999 | bob: 9.020Epoch   0:  69% | abe: 9.080 | eve: 8.999 | bob: 9.020Epoch   0:  70% | abe: 9.079 | eve: 8.999 | bob: 9.020Epoch   0:  71% | abe: 9.079 | eve: 8.999 | bob: 9.020Epoch   0:  71% | abe: 9.079 | eve: 8.998 | bob: 9.020Epoch   0:  72% | abe: 9.079 | eve: 8.998 | bob: 9.020Epoch   0:  73% | abe: 9.080 | eve: 8.998 | bob: 9.020Epoch   0:  74% | abe: 9.079 | eve: 8.998 | bob: 9.020Epoch   0:  75% | abe: 9.079 | eve: 8.998 | bob: 9.020Epoch   0:  75% | abe: 9.079 | eve: 8.998 | bob: 9.020Epoch   0:  76% | abe: 9.079 | eve: 8.998 | bob: 9.020Epoch   0:  77% | abe: 9.079 | eve: 8.997 | bob: 9.019Epoch   0:  78% | abe: 9.079 | eve: 8.997 | bob: 9.019Epoch   0:  78% | abe: 9.078 | eve: 8.997 | bob: 9.019Epoch   0:  79% | abe: 9.078 | eve: 8.997 | bob: 9.019Epoch   0:  80% | abe: 9.078 | eve: 8.998 | bob: 9.019Epoch   0:  81% | abe: 9.078 | eve: 8.998 | bob: 9.019Epoch   0:  82% | abe: 9.078 | eve: 8.998 | bob: 9.018Epoch   0:  82% | abe: 9.077 | eve: 8.998 | bob: 9.018Epoch   0:  83% | abe: 9.077 | eve: 8.998 | bob: 9.018Epoch   0:  84% | abe: 9.077 | eve: 8.998 | bob: 9.017Epoch   0:  85% | abe: 9.076 | eve: 8.998 | bob: 9.017Epoch   0:  85% | abe: 9.076 | eve: 8.998 | bob: 9.017Epoch   0:  86% | abe: 9.076 | eve: 8.998 | bob: 9.017Epoch   0:  87% | abe: 9.076 | eve: 8.998 | bob: 9.017Epoch   0:  88% | abe: 9.076 | eve: 8.998 | bob: 9.016Epoch   0:  89% | abe: 9.076 | eve: 8.997 | bob: 9.016Epoch   0:  89% | abe: 9.076 | eve: 8.997 | bob: 9.016Epoch   0:  90% | abe: 9.075 | eve: 8.997 | bob: 9.016Epoch   0:  91% | abe: 9.075 | eve: 8.997 | bob: 9.016Epoch   0:  92% | abe: 9.075 | eve: 8.997 | bob: 9.016Epoch   0:  92% | abe: 9.075 | eve: 8.997 | bob: 9.016Epoch   0:  93% | abe: 9.075 | eve: 8.997 | bob: 9.015Epoch   0:  94% | abe: 9.074 | eve: 8.997 | bob: 9.015Epoch   0:  95% | abe: 9.074 | eve: 8.997 | bob: 9.015Epoch   0:  96% | abe: 9.074 | eve: 8.998 | bob: 9.015Epoch   0:  96% | abe: 9.074 | eve: 8.998 | bob: 9.014Epoch   0:  97% | abe: 9.074 | eve: 8.998 | bob: 9.015Epoch   0:  98% | abe: 9.073 | eve: 8.998 | bob: 9.015Epoch   0:  99% | abe: 9.074 | eve: 8.998 | bob: 9.015
New best Bob loss 9.014803573145855 at epoch 0
Epoch   1:   0% | abe: 9.115 | eve: 8.952 | bob: 9.060Epoch   1:   0% | abe: 9.080 | eve: 8.982 | bob: 9.027Epoch   1:   1% | abe: 9.056 | eve: 8.979 | bob: 9.002Epoch   1:   2% | abe: 9.047 | eve: 8.983 | bob: 8.991Epoch   1:   3% | abe: 9.045 | eve: 8.989 | bob: 8.989Epoch   1:   3% | abe: 9.049 | eve: 8.986 | bob: 8.992Epoch   1:   4% | abe: 9.049 | eve: 8.992 | bob: 8.993Epoch   1:   5% | abe: 9.053 | eve: 8.992 | bob: 8.995Epoch   1:   6% | abe: 9.053 | eve: 8.996 | bob: 8.995Epoch   1:   7% | abe: 9.057 | eve: 8.999 | bob: 8.998Epoch   1:   7% | abe: 9.059 | eve: 9.000 | bob: 8.999Epoch   1:   8% | abe: 9.056 | eve: 9.002 | bob: 8.995Epoch   1:   9% | abe: 9.056 | eve: 9.003 | bob: 8.995Epoch   1:  10% | abe: 9.055 | eve: 9.004 | bob: 8.992Epoch   1:  10% | abe: 9.050 | eve: 9.006 | bob: 8.987Epoch   1:  11% | abe: 9.050 | eve: 9.006 | bob: 8.986Epoch   1:  12% | abe: 9.048 | eve: 9.005 | bob: 8.983Epoch   1:  13% | abe: 9.050 | eve: 9.005 | bob: 8.984Epoch   1:  14% | abe: 9.050 | eve: 9.006 | bob: 8.984Epoch   1:  14% | abe: 9.053 | eve: 9.007 | bob: 8.986Epoch   1:  15% | abe: 9.053 | eve: 9.007 | bob: 8.985Epoch   1:  16% | abe: 9.053 | eve: 9.008 | bob: 8.985Epoch   1:  17% | abe: 9.054 | eve: 9.009 | bob: 8.985Epoch   1:  17% | abe: 9.054 | eve: 9.008 | bob: 8.984Epoch   1:  18% | abe: 9.054 | eve: 9.007 | bob: 8.983Epoch   1:  19% | abe: 9.055 | eve: 9.007 | bob: 8.984Epoch   1:  20% | abe: 9.056 | eve: 9.007 | bob: 8.984Epoch   1:  21% | abe: 9.058 | eve: 9.007 | bob: 8.985Epoch   1:  21% | abe: 9.058 | eve: 9.007 | bob: 8.984Epoch   1:  22% | abe: 9.059 | eve: 9.005 | bob: 8.984Epoch   1:  23% | abe: 9.059 | eve: 9.006 | bob: 8.984Epoch   1:  24% | abe: 9.058 | eve: 9.007 | bob: 8.982Epoch   1:  25% | abe: 9.059 | eve: 9.007 | bob: 8.983Epoch   1:  25% | abe: 9.059 | eve: 9.007 | bob: 8.982Epoch   1:  26% | abe: 9.059 | eve: 9.006 | bob: 8.982Epoch   1:  27% | abe: 9.058 | eve: 9.006 | bob: 8.981Epoch   1:  28% | abe: 9.058 | eve: 9.005 | bob: 8.979Epoch   1:  28% | abe: 9.058 | eve: 9.005 | bob: 8.979Epoch   1:  29% | abe: 9.058 | eve: 9.004 | bob: 8.979Epoch   1:  30% | abe: 9.058 | eve: 9.004 | bob: 8.979Epoch   1:  31% | abe: 9.057 | eve: 9.003 | bob: 8.978Epoch   1:  32% | abe: 9.058 | eve: 9.003 | bob: 8.978Epoch   1:  32% | abe: 9.057 | eve: 9.002 | bob: 8.977Epoch   1:  33% | abe: 9.057 | eve: 9.003 | bob: 8.976Epoch   1:  34% | abe: 9.057 | eve: 9.003 | bob: 8.977Epoch   1:  35% | abe: 9.057 | eve: 9.002 | bob: 8.977Epoch   1:  35% | abe: 9.057 | eve: 9.001 | bob: 8.976Epoch   1:  36% | abe: 9.057 | eve: 9.002 | bob: 8.976Epoch   1:  37% | abe: 9.057 | eve: 9.002 | bob: 8.976Epoch   1:  38% | abe: 9.057 | eve: 9.002 | bob: 8.976Epoch   1:  39% | abe: 9.056 | eve: 9.001 | bob: 8.976Epoch   1:  39% | abe: 9.056 | eve: 9.001 | bob: 8.976Epoch   1:  40% | abe: 9.056 | eve: 9.000 | bob: 8.976Epoch   1:  41% | abe: 9.056 | eve: 9.001 | bob: 8.976Epoch   1:  42% | abe: 9.056 | eve: 9.000 | bob: 8.977Epoch   1:  42% | abe: 9.056 | eve: 9.001 | bob: 8.977Epoch   1:  43% | abe: 9.056 | eve: 9.001 | bob: 8.978Epoch   1:  44% | abe: 9.056 | eve: 9.001 | bob: 8.978Epoch   1:  45% | abe: 9.056 | eve: 9.002 | bob: 8.978Epoch   1:  46% | abe: 9.055 | eve: 9.001 | bob: 8.977Epoch   1:  46% | abe: 9.055 | eve: 9.001 | bob: 8.978Epoch   1:  47% | abe: 9.055 | eve: 9.000 | bob: 8.978Epoch   1:  48% | abe: 9.055 | eve: 9.000 | bob: 8.978Epoch   1:  49% | abe: 9.054 | eve: 9.000 | bob: 8.978Epoch   1:  50% | abe: 9.054 | eve: 9.000 | bob: 8.978Epoch   1:  50% | abe: 9.054 | eve: 9.000 | bob: 8.979Epoch   1:  51% | abe: 9.054 | eve: 9.000 | bob: 8.979Epoch   1:  52% | abe: 9.054 | eve: 9.000 | bob: 8.979Epoch   1:  53% | abe: 9.053 | eve: 9.000 | bob: 8.978Epoch   1:  53% | abe: 9.052 | eve: 9.000 | bob: 8.978Epoch   1:  54% | abe: 9.052 | eve: 9.000 | bob: 8.978Epoch   1:  55% | abe: 9.051 | eve: 8.999 | bob: 8.977Epoch   1:  56% | abe: 9.051 | eve: 8.999 | bob: 8.977Epoch   1:  57% | abe: 9.051 | eve: 8.999 | bob: 8.977Epoch   1:  57% | abe: 9.051 | eve: 8.999 | bob: 8.977Epoch   1:  58% | abe: 9.051 | eve: 8.999 | bob: 8.978Epoch   1:  59% | abe: 9.051 | eve: 8.999 | bob: 8.977Epoch   1:  60% | abe: 9.051 | eve: 8.999 | bob: 8.977Epoch   1:  60% | abe: 9.050 | eve: 8.999 | bob: 8.977Epoch   1:  61% | abe: 9.050 | eve: 8.999 | bob: 8.977Epoch   1:  62% | abe: 9.050 | eve: 8.999 | bob: 8.978Epoch   1:  63% | abe: 9.050 | eve: 8.999 | bob: 8.978Epoch   1:  64% | abe: 9.050 | eve: 8.999 | bob: 8.977Epoch   1:  64% | abe: 9.050 | eve: 8.999 | bob: 8.978Epoch   1:  65% | abe: 9.050 | eve: 8.999 | bob: 8.977Epoch   1:  66% | abe: 9.050 | eve: 8.999 | bob: 8.977Epoch   1:  67% | abe: 9.050 | eve: 8.999 | bob: 8.977Epoch   1:  67% | abe: 9.050 | eve: 8.999 | bob: 8.976Epoch   1:  68% | abe: 9.049 | eve: 8.999 | bob: 8.976Epoch   1:  69% | abe: 9.049 | eve: 8.998 | bob: 8.976Epoch   1:  70% | abe: 9.049 | eve: 8.998 | bob: 8.975Epoch   1:  71% | abe: 9.049 | eve: 8.999 | bob: 8.975Epoch   1:  71% | abe: 9.049 | eve: 8.999 | bob: 8.975Epoch   1:  72% | abe: 9.048 | eve: 8.999 | bob: 8.974Epoch   1:  73% | abe: 9.048 | eve: 8.999 | bob: 8.974Epoch   1:  74% | abe: 9.048 | eve: 8.998 | bob: 8.973Epoch   1:  75% | abe: 9.048 | eve: 8.999 | bob: 8.973Epoch   1:  75% | abe: 9.048 | eve: 8.999 | bob: 8.973Epoch   1:  76% | abe: 9.048 | eve: 8.999 | bob: 8.973Epoch   1:  77% | abe: 9.047 | eve: 8.998 | bob: 8.972Epoch   1:  78% | abe: 9.048 | eve: 8.999 | bob: 8.973Epoch   1:  78% | abe: 9.048 | eve: 8.999 | bob: 8.972Epoch   1:  79% | abe: 9.047 | eve: 8.999 | bob: 8.972Epoch   1:  80% | abe: 9.047 | eve: 8.999 | bob: 8.972Epoch   1:  81% | abe: 9.046 | eve: 8.999 | bob: 8.971Epoch   1:  82% | abe: 9.046 | eve: 8.999 | bob: 8.971Epoch   1:  82% | abe: 9.046 | eve: 8.999 | bob: 8.971Epoch   1:  83% | abe: 9.046 | eve: 8.999 | bob: 8.971Epoch   1:  84% | abe: 9.046 | eve: 9.000 | bob: 8.971Epoch   1:  85% | abe: 9.046 | eve: 9.000 | bob: 8.972Epoch   1:  85% | abe: 9.046 | eve: 9.000 | bob: 8.972Epoch   1:  86% | abe: 9.046 | eve: 9.000 | bob: 8.971Epoch   1:  87% | abe: 9.046 | eve: 9.000 | bob: 8.972Epoch   1:  88% | abe: 9.046 | eve: 9.000 | bob: 8.971Epoch   1:  89% | abe: 9.045 | eve: 9.000 | bob: 8.971Epoch   1:  89% | abe: 9.045 | eve: 9.000 | bob: 8.971Epoch   1:  90% | abe: 9.045 | eve: 9.000 | bob: 8.970Epoch   1:  91% | abe: 9.045 | eve: 9.000 | bob: 8.970Epoch   1:  92% | abe: 9.044 | eve: 9.000 | bob: 8.970Epoch   1:  92% | abe: 9.044 | eve: 9.001 | bob: 8.969Epoch   1:  93% | abe: 9.044 | eve: 9.000 | bob: 8.969Epoch   1:  94% | abe: 9.044 | eve: 9.000 | bob: 8.969Epoch   1:  95% | abe: 9.044 | eve: 9.000 | bob: 8.969Epoch   1:  96% | abe: 9.043 | eve: 9.000 | bob: 8.969Epoch   1:  96% | abe: 9.043 | eve: 9.000 | bob: 8.969Epoch   1:  97% | abe: 9.043 | eve: 9.000 | bob: 8.969Epoch   1:  98% | abe: 9.043 | eve: 9.000 | bob: 8.968Epoch   1:  99% | abe: 9.043 | eve: 9.000 | bob: 8.968
New best Bob loss 8.96831423351 at epoch 1
Epoch   2:   0% | abe: 9.012 | eve: 9.017 | bob: 8.946Epoch   2:   0% | abe: 9.004 | eve: 9.003 | bob: 8.938Epoch   2:   1% | abe: 9.003 | eve: 9.001 | bob: 8.936Epoch   2:   2% | abe: 9.014 | eve: 9.004 | bob: 8.947Epoch   2:   3% | abe: 9.011 | eve: 8.994 | bob: 8.942Epoch   2:   3% | abe: 9.011 | eve: 8.992 | bob: 8.941Epoch   2:   4% | abe: 9.013 | eve: 8.990 | bob: 8.943Epoch   2:   5% | abe: 9.015 | eve: 8.993 | bob: 8.945Epoch   2:   6% | abe: 9.015 | eve: 8.990 | bob: 8.945Epoch   2:   7% | abe: 9.016 | eve: 8.994 | bob: 8.945Epoch   2:   7% | abe: 9.017 | eve: 8.992 | bob: 8.947Epoch   2:   8% | abe: 9.015 | eve: 8.990 | bob: 8.944Epoch   2:   9% | abe: 9.016 | eve: 8.993 | bob: 8.946Epoch   2:  10% | abe: 9.016 | eve: 8.995 | bob: 8.945Epoch   2:  10% | abe: 9.015 | eve: 8.992 | bob: 8.944Epoch   2:  11% | abe: 9.014 | eve: 8.993 | bob: 8.943Epoch   2:  12% | abe: 9.015 | eve: 8.991 | bob: 8.945Epoch   2:  13% | abe: 9.015 | eve: 8.993 | bob: 8.945Epoch   2:  14% | abe: 9.013 | eve: 8.993 | bob: 8.943Epoch   2:  14% | abe: 9.012 | eve: 8.994 | bob: 8.943Epoch   2:  15% | abe: 9.015 | eve: 8.994 | bob: 8.945Epoch   2:  16% | abe: 9.013 | eve: 8.995 | bob: 8.943Epoch   2:  17% | abe: 9.012 | eve: 8.995 | bob: 8.943Epoch   2:  17% | abe: 9.012 | eve: 8.996 | bob: 8.942Epoch   2:  18% | abe: 9.012 | eve: 8.998 | bob: 8.942Epoch   2:  19% | abe: 9.012 | eve: 8.999 | bob: 8.942Epoch   2:  20% | abe: 9.012 | eve: 8.999 | bob: 8.942Epoch   2:  21% | abe: 9.012 | eve: 9.001 | bob: 8.943Epoch   2:  21% | abe: 9.012 | eve: 9.000 | bob: 8.942Epoch   2:  22% | abe: 9.013 | eve: 9.001 | bob: 8.943Epoch   2:  23% | abe: 9.013 | eve: 9.001 | bob: 8.943Epoch   2:  24% | abe: 9.012 | eve: 9.002 | bob: 8.942Epoch   2:  25% | abe: 9.012 | eve: 9.002 | bob: 8.942Epoch   2:  25% | abe: 9.011 | eve: 9.001 | bob: 8.941Epoch   2:  26% | abe: 9.011 | eve: 9.001 | bob: 8.940Epoch   2:  27% | abe: 9.012 | eve: 9.002 | bob: 8.942Epoch   2:  28% | abe: 9.012 | eve: 9.002 | bob: 8.942Epoch   2:  28% | abe: 9.011 | eve: 9.001 | bob: 8.941Epoch   2:  29% | abe: 9.011 | eve: 9.001 | bob: 8.941Epoch   2:  30% | abe: 9.010 | eve: 9.002 | bob: 8.940Epoch   2:  31% | abe: 9.011 | eve: 9.002 | bob: 8.941Epoch   2:  32% | abe: 9.011 | eve: 9.001 | bob: 8.941Epoch   2:  32% | abe: 9.010 | eve: 9.001 | bob: 8.940Epoch   2:  33% | abe: 9.009 | eve: 9.001 | bob: 8.940Epoch   2:  34% | abe: 9.009 | eve: 9.001 | bob: 8.939Epoch   2:  35% | abe: 9.009 | eve: 9.000 | bob: 8.939Epoch   2:  35% | abe: 9.008 | eve: 9.000 | bob: 8.938Epoch   2:  36% | abe: 9.007 | eve: 9.000 | bob: 8.937Epoch   2:  37% | abe: 9.006 | eve: 9.001 | bob: 8.936Epoch   2:  38% | abe: 9.006 | eve: 9.000 | bob: 8.936Epoch   2:  39% | abe: 9.005 | eve: 9.000 | bob: 8.935Epoch   2:  39% | abe: 9.005 | eve: 9.000 | bob: 8.935Epoch   2:  40% | abe: 9.004 | eve: 8.999 | bob: 8.935Epoch   2:  41% | abe: 9.004 | eve: 8.999 | bob: 8.934Epoch   2:  42% | abe: 9.003 | eve: 9.000 | bob: 8.934Epoch   2:  42% | abe: 9.003 | eve: 9.000 | bob: 8.933Epoch   2:  43% | abe: 9.002 | eve: 8.999 | bob: 8.933Epoch   2:  44% | abe: 9.002 | eve: 8.999 | bob: 8.933Epoch   2:  45% | abe: 9.001 | eve: 9.000 | bob: 8.933Epoch   2:  46% | abe: 9.001 | eve: 9.000 | bob: 8.932Epoch   2:  46% | abe: 9.000 | eve: 9.000 | bob: 8.932Epoch   2:  47% | abe: 9.000 | eve: 9.000 | bob: 8.932Epoch   2:  48% | abe: 9.000 | eve: 9.000 | bob: 8.931Epoch   2:  49% | abe: 8.999 | eve: 8.999 | bob: 8.931Epoch   2:  50% | abe: 8.999 | eve: 9.000 | bob: 8.930Epoch   2:  50% | abe: 8.998 | eve: 9.000 | bob: 8.929Epoch   2:  51% | abe: 8.997 | eve: 9.000 | bob: 8.928Epoch   2:  52% | abe: 8.997 | eve: 9.000 | bob: 8.928Epoch   2:  53% | abe: 8.997 | eve: 8.999 | bob: 8.927Epoch   2:  53% | abe: 8.996 | eve: 8.999 | bob: 8.926Epoch   2:  54% | abe: 8.996 | eve: 8.999 | bob: 8.926Epoch   2:  55% | abe: 8.995 | eve: 8.999 | bob: 8.925Epoch   2:  56% | abe: 8.995 | eve: 8.999 | bob: 8.925Epoch   2:  57% | abe: 8.995 | eve: 8.999 | bob: 8.925Epoch   2:  57% | abe: 8.995 | eve: 8.998 | bob: 8.925Epoch   2:  58% | abe: 8.994 | eve: 8.998 | bob: 8.925Epoch   2:  59% | abe: 8.994 | eve: 8.998 | bob: 8.924Epoch   2:  60% | abe: 8.993 | eve: 8.998 | bob: 8.924Epoch   2:  60% | abe: 8.992 | eve: 8.998 | bob: 8.923Epoch   2:  61% | abe: 8.991 | eve: 8.998 | bob: 8.923Epoch   2:  62% | abe: 8.991 | eve: 8.998 | bob: 8.923Epoch   2:  63% | abe: 8.991 | eve: 8.997 | bob: 8.923Epoch   2:  64% | abe: 8.991 | eve: 8.997 | bob: 8.923Epoch   2:  64% | abe: 8.990 | eve: 8.998 | bob: 8.922Epoch   2:  65% | abe: 8.990 | eve: 8.998 | bob: 8.922Epoch   2:  66% | abe: 8.990 | eve: 8.998 | bob: 8.921Epoch   2:  67% | abe: 8.989 | eve: 8.998 | bob: 8.921Epoch   2:  67% | abe: 8.989 | eve: 8.998 | bob: 8.921Epoch   2:  68% | abe: 8.989 | eve: 8.998 | bob: 8.920Epoch   2:  69% | abe: 8.988 | eve: 8.997 | bob: 8.919Epoch   2:  70% | abe: 8.988 | eve: 8.998 | bob: 8.919Epoch   2:  71% | abe: 8.987 | eve: 8.998 | bob: 8.918Epoch   2:  71% | abe: 8.986 | eve: 8.998 | bob: 8.917Epoch   2:  72% | abe: 8.986 | eve: 8.998 | bob: 8.917Epoch   2:  73% | abe: 8.985 | eve: 8.998 | bob: 8.916Epoch   2:  74% | abe: 8.985 | eve: 8.998 | bob: 8.916Epoch   2:  75% | abe: 8.985 | eve: 8.998 | bob: 8.916Epoch   2:  75% | abe: 8.984 | eve: 8.998 | bob: 8.916Epoch   2:  76% | abe: 8.983 | eve: 8.998 | bob: 8.915Epoch   2:  77% | abe: 8.983 | eve: 8.998 | bob: 8.915Epoch   2:  78% | abe: 8.983 | eve: 8.998 | bob: 8.915Epoch   2:  78% | abe: 8.982 | eve: 8.999 | bob: 8.914Epoch   2:  79% | abe: 8.981 | eve: 8.999 | bob: 8.914Epoch   2:  80% | abe: 8.981 | eve: 8.999 | bob: 8.914Epoch   2:  81% | abe: 8.980 | eve: 9.000 | bob: 8.914Epoch   2:  82% | abe: 8.980 | eve: 8.999 | bob: 8.913Epoch   2:  82% | abe: 8.980 | eve: 9.000 | bob: 8.913Epoch   2:  83% | abe: 8.979 | eve: 9.000 | bob: 8.913Epoch   2:  84% | abe: 8.979 | eve: 8.999 | bob: 8.912Epoch   2:  85% | abe: 8.978 | eve: 8.999 | bob: 8.911Epoch   2:  85% | abe: 8.978 | eve: 8.999 | bob: 8.911Epoch   2:  86% | abe: 8.977 | eve: 8.999 | bob: 8.910Epoch   2:  87% | abe: 8.977 | eve: 8.999 | bob: 8.910Epoch   2:  88% | abe: 8.976 | eve: 8.999 | bob: 8.909Epoch   2:  89% | abe: 8.976 | eve: 9.000 | bob: 8.908Epoch   2:  89% | abe: 8.975 | eve: 9.000 | bob: 8.908Epoch   2:  90% | abe: 8.975 | eve: 8.999 | bob: 8.908Epoch   2:  91% | abe: 8.974 | eve: 8.999 | bob: 8.907Epoch   2:  92% | abe: 8.974 | eve: 8.999 | bob: 8.907Epoch   2:  92% | abe: 8.973 | eve: 8.999 | bob: 8.906Epoch   2:  93% | abe: 8.973 | eve: 8.999 | bob: 8.906Epoch   2:  94% | abe: 8.972 | eve: 9.000 | bob: 8.906Epoch   2:  95% | abe: 8.972 | eve: 9.000 | bob: 8.905Epoch   2:  96% | abe: 8.971 | eve: 9.000 | bob: 8.905Epoch   2:  96% | abe: 8.971 | eve: 9.000 | bob: 8.905Epoch   2:  97% | abe: 8.971 | eve: 9.000 | bob: 8.905Epoch   2:  98% | abe: 8.970 | eve: 9.000 | bob: 8.904Epoch   2:  99% | abe: 8.969 | eve: 9.000 | bob: 8.904
New best Bob loss 8.903656979838843 at epoch 2
Epoch   3:   0% | abe: 8.911 | eve: 9.022 | bob: 8.841Epoch   3:   0% | abe: 8.912 | eve: 9.015 | bob: 8.843Epoch   3:   1% | abe: 8.915 | eve: 9.010 | bob: 8.844Epoch   3:   2% | abe: 8.916 | eve: 9.001 | bob: 8.843Epoch   3:   3% | abe: 8.909 | eve: 9.001 | bob: 8.835Epoch   3:   3% | abe: 8.908 | eve: 9.000 | bob: 8.835Epoch   3:   4% | abe: 8.908 | eve: 8.999 | bob: 8.837Epoch   3:   5% | abe: 8.913 | eve: 9.003 | bob: 8.844Epoch   3:   6% | abe: 8.910 | eve: 9.002 | bob: 8.842Epoch   3:   7% | abe: 8.909 | eve: 9.002 | bob: 8.844Epoch   3:   7% | abe: 8.908 | eve: 9.001 | bob: 8.843Epoch   3:   8% | abe: 8.910 | eve: 9.000 | bob: 8.845Epoch   3:   9% | abe: 8.907 | eve: 9.001 | bob: 8.842Epoch   3:  10% | abe: 8.906 | eve: 9.002 | bob: 8.842Epoch   3:  10% | abe: 8.905 | eve: 9.005 | bob: 8.840Epoch   3:  11% | abe: 8.906 | eve: 9.005 | bob: 8.841Epoch   3:  12% | abe: 8.905 | eve: 9.006 | bob: 8.839Epoch   3:  13% | abe: 8.906 | eve: 9.006 | bob: 8.840Epoch   3:  14% | abe: 8.907 | eve: 9.008 | bob: 8.840Epoch   3:  14% | abe: 8.906 | eve: 9.009 | bob: 8.839Epoch   3:  15% | abe: 8.905 | eve: 9.010 | bob: 8.838Epoch   3:  16% | abe: 8.904 | eve: 9.011 | bob: 8.838Epoch   3:  17% | abe: 8.902 | eve: 9.011 | bob: 8.837Epoch   3:  17% | abe: 8.900 | eve: 9.010 | bob: 8.836Epoch   3:  18% | abe: 8.900 | eve: 9.011 | bob: 8.837Epoch   3:  19% | abe: 8.901 | eve: 9.012 | bob: 8.839Epoch   3:  20% | abe: 8.899 | eve: 9.011 | bob: 8.837Epoch   3:  21% | abe: 8.897 | eve: 9.009 | bob: 8.836Epoch   3:  21% | abe: 8.895 | eve: 9.008 | bob: 8.834Epoch   3:  22% | abe: 8.894 | eve: 9.008 | bob: 8.834Epoch   3:  23% | abe: 8.894 | eve: 9.007 | bob: 8.834Epoch   3:  24% | abe: 8.894 | eve: 9.008 | bob: 8.834Epoch   3:  25% | abe: 8.894 | eve: 9.009 | bob: 8.833Epoch   3:  25% | abe: 8.894 | eve: 9.008 | bob: 8.832Epoch   3:  26% | abe: 8.893 | eve: 9.009 | bob: 8.831Epoch   3:  27% | abe: 8.893 | eve: 9.009 | bob: 8.829Epoch   3:  28% | abe: 8.892 | eve: 9.009 | bob: 8.828Epoch   3:  28% | abe: 8.892 | eve: 9.008 | bob: 8.827Epoch   3:  29% | abe: 8.891 | eve: 9.008 | bob: 8.826Epoch   3:  30% | abe: 8.891 | eve: 9.008 | bob: 8.826Epoch   3:  31% | abe: 8.891 | eve: 9.008 | bob: 8.826Epoch   3:  32% | abe: 8.891 | eve: 9.008 | bob: 8.826Epoch   3:  32% | abe: 8.890 | eve: 9.008 | bob: 8.825Epoch   3:  33% | abe: 8.890 | eve: 9.009 | bob: 8.825Epoch   3:  34% | abe: 8.889 | eve: 9.009 | bob: 8.824Epoch   3:  35% | abe: 8.889 | eve: 9.009 | bob: 8.824Epoch   3:  35% | abe: 8.889 | eve: 9.009 | bob: 8.825Epoch   3:  36% | abe: 8.888 | eve: 9.009 | bob: 8.824Epoch   3:  37% | abe: 8.888 | eve: 9.008 | bob: 8.824Epoch   3:  38% | abe: 8.888 | eve: 9.009 | bob: 8.823Epoch   3:  39% | abe: 8.887 | eve: 9.009 | bob: 8.823Epoch   3:  39% | abe: 8.886 | eve: 9.009 | bob: 8.822Epoch   3:  40% | abe: 8.886 | eve: 9.009 | bob: 8.822Epoch   3:  41% | abe: 8.886 | eve: 9.009 | bob: 8.822Epoch   3:  42% | abe: 8.885 | eve: 9.009 | bob: 8.821Epoch   3:  42% | abe: 8.884 | eve: 9.009 | bob: 8.821Epoch   3:  43% | abe: 8.884 | eve: 9.009 | bob: 8.820Epoch   3:  44% | abe: 8.883 | eve: 9.008 | bob: 8.820Epoch   3:  45% | abe: 8.882 | eve: 9.008 | bob: 8.819Epoch   3:  46% | abe: 8.881 | eve: 9.007 | bob: 8.819Epoch   3:  46% | abe: 8.880 | eve: 9.007 | bob: 8.818Epoch   3:  47% | abe: 8.879 | eve: 9.008 | bob: 8.817Epoch   3:  48% | abe: 8.878 | eve: 9.007 | bob: 8.816Epoch   3:  49% | abe: 8.878 | eve: 9.007 | bob: 8.816Epoch   3:  50% | abe: 8.876 | eve: 9.006 | bob: 8.815Epoch   3:  50% | abe: 8.876 | eve: 9.006 | bob: 8.815Epoch   3:  51% | abe: 8.875 | eve: 9.006 | bob: 8.814Epoch   3:  52% | abe: 8.875 | eve: 9.006 | bob: 8.813Epoch   3:  53% | abe: 8.874 | eve: 9.006 | bob: 8.812Epoch   3:  53% | abe: 8.873 | eve: 9.006 | bob: 8.812Epoch   3:  54% | abe: 8.873 | eve: 9.006 | bob: 8.811Epoch   3:  55% | abe: 8.872 | eve: 9.006 | bob: 8.810Epoch   3:  56% | abe: 8.871 | eve: 9.006 | bob: 8.810Epoch   3:  57% | abe: 8.871 | eve: 9.006 | bob: 8.810Epoch   3:  57% | abe: 8.870 | eve: 9.006 | bob: 8.809Epoch   3:  58% | abe: 8.870 | eve: 9.006 | bob: 8.808Epoch   3:  59% | abe: 8.868 | eve: 9.006 | bob: 8.807Epoch   3:  60% | abe: 8.868 | eve: 9.006 | bob: 8.807Epoch   3:  60% | abe: 8.867 | eve: 9.006 | bob: 8.807Epoch   3:  61% | abe: 8.866 | eve: 9.006 | bob: 8.806Epoch   3:  62% | abe: 8.866 | eve: 9.006 | bob: 8.805Epoch   3:  63% | abe: 8.865 | eve: 9.006 | bob: 8.804Epoch   3:  64% | abe: 8.864 | eve: 9.006 | bob: 8.803Epoch   3:  64% | abe: 8.863 | eve: 9.006 | bob: 8.803Epoch   3:  65% | abe: 8.862 | eve: 9.006 | bob: 8.802Epoch   3:  66% | abe: 8.861 | eve: 9.005 | bob: 8.801Epoch   3:  67% | abe: 8.861 | eve: 9.006 | bob: 8.801Epoch   3:  67% | abe: 8.860 | eve: 9.006 | bob: 8.801Epoch   3:  68% | abe: 8.860 | eve: 9.006 | bob: 8.800Epoch   3:  69% | abe: 8.859 | eve: 9.006 | bob: 8.800Epoch   3:  70% | abe: 8.858 | eve: 9.006 | bob: 8.799Epoch   3:  71% | abe: 8.858 | eve: 9.005 | bob: 8.798Epoch   3:  71% | abe: 8.857 | eve: 9.005 | bob: 8.797Epoch   3:  72% | abe: 8.856 | eve: 9.005 | bob: 8.796Epoch   3:  73% | abe: 8.855 | eve: 9.005 | bob: 8.796Epoch   3:  74% | abe: 8.854 | eve: 9.005 | bob: 8.795Epoch   3:  75% | abe: 8.853 | eve: 9.004 | bob: 8.794Epoch   3:  75% | abe: 8.853 | eve: 9.004 | bob: 8.793Epoch   3:  76% | abe: 8.852 | eve: 9.004 | bob: 8.793Epoch   3:  77% | abe: 8.851 | eve: 9.004 | bob: 8.792Epoch   3:  78% | abe: 8.851 | eve: 9.004 | bob: 8.792Epoch   3:  78% | abe: 8.850 | eve: 9.005 | bob: 8.791Epoch   3:  79% | abe: 8.849 | eve: 9.004 | bob: 8.790Epoch   3:  80% | abe: 8.848 | eve: 9.004 | bob: 8.790Epoch   3:  81% | abe: 8.847 | eve: 9.004 | bob: 8.789Epoch   3:  82% | abe: 8.847 | eve: 9.004 | bob: 8.788Epoch   3:  82% | abe: 8.846 | eve: 9.004 | bob: 8.787Epoch   3:  83% | abe: 8.845 | eve: 9.003 | bob: 8.786Epoch   3:  84% | abe: 8.844 | eve: 9.003 | bob: 8.785Epoch   3:  85% | abe: 8.843 | eve: 9.003 | bob: 8.785Epoch   3:  85% | abe: 8.843 | eve: 9.003 | bob: 8.784Epoch   3:  86% | abe: 8.842 | eve: 9.003 | bob: 8.784Epoch   3:  87% | abe: 8.841 | eve: 9.003 | bob: 8.783Epoch   3:  88% | abe: 8.840 | eve: 9.003 | bob: 8.782Epoch   3:  89% | abe: 8.840 | eve: 9.003 | bob: 8.782Epoch   3:  89% | abe: 8.839 | eve: 9.003 | bob: 8.781Epoch   3:  90% | abe: 8.838 | eve: 9.003 | bob: 8.780Epoch   3:  91% | abe: 8.837 | eve: 9.003 | bob: 8.779Epoch   3:  92% | abe: 8.836 | eve: 9.003 | bob: 8.779Epoch   3:  92% | abe: 8.836 | eve: 9.003 | bob: 8.778Epoch   3:  93% | abe: 8.835 | eve: 9.003 | bob: 8.777Epoch   3:  94% | abe: 8.834 | eve: 9.003 | bob: 8.776Epoch   3:  95% | abe: 8.833 | eve: 9.003 | bob: 8.775Epoch   3:  96% | abe: 8.832 | eve: 9.003 | bob: 8.775Epoch   3:  96% | abe: 8.832 | eve: 9.003 | bob: 8.774Epoch   3:  97% | abe: 8.831 | eve: 9.003 | bob: 8.774Epoch   3:  98% | abe: 8.830 | eve: 9.003 | bob: 8.773Epoch   3:  99% | abe: 8.829 | eve: 9.003 | bob: 8.772
New best Bob loss 8.772136133025924 at epoch 3
Epoch   4:   0% | abe: 8.740 | eve: 8.980 | bob: 8.690Epoch   4:   0% | abe: 8.748 | eve: 8.985 | bob: 8.693Epoch   4:   1% | abe: 8.747 | eve: 8.993 | bob: 8.690Epoch   4:   2% | abe: 8.745 | eve: 8.998 | bob: 8.685Epoch   4:   3% | abe: 8.744 | eve: 9.003 | bob: 8.683Epoch   4:   3% | abe: 8.742 | eve: 8.998 | bob: 8.679Epoch   4:   4% | abe: 8.738 | eve: 9.000 | bob: 8.675Epoch   4:   5% | abe: 8.733 | eve: 9.007 | bob: 8.671Epoch   4:   6% | abe: 8.731 | eve: 9.007 | bob: 8.671Epoch   4:   7% | abe: 8.726 | eve: 9.004 | bob: 8.668Epoch   4:   7% | abe: 8.723 | eve: 9.005 | bob: 8.668Epoch   4:   8% | abe: 8.722 | eve: 9.004 | bob: 8.669Epoch   4:   9% | abe: 8.724 | eve: 9.004 | bob: 8.672Epoch   4:  10% | abe: 8.722 | eve: 9.005 | bob: 8.671Epoch   4:  10% | abe: 8.722 | eve: 9.004 | bob: 8.670Epoch   4:  11% | abe: 8.719 | eve: 9.003 | bob: 8.668Epoch   4:  12% | abe: 8.719 | eve: 9.005 | bob: 8.668Epoch   4:  13% | abe: 8.719 | eve: 9.003 | bob: 8.667Epoch   4:  14% | abe: 8.718 | eve: 9.001 | bob: 8.666Epoch   4:  14% | abe: 8.717 | eve: 9.000 | bob: 8.666Epoch   4:  15% | abe: 8.715 | eve: 9.001 | bob: 8.665Epoch   4:  16% | abe: 8.713 | eve: 9.000 | bob: 8.665Epoch   4:  17% | abe: 8.713 | eve: 9.000 | bob: 8.666Epoch   4:  17% | abe: 8.712 | eve: 8.998 | bob: 8.666Epoch   4:  18% | abe: 8.713 | eve: 8.997 | bob: 8.667Epoch   4:  19% | abe: 8.712 | eve: 8.997 | bob: 8.667Epoch   4:  20% | abe: 8.710 | eve: 8.997 | bob: 8.664Epoch   4:  21% | abe: 8.707 | eve: 8.996 | bob: 8.661Epoch   4:  21% | abe: 8.707 | eve: 8.996 | bob: 8.661Epoch   4:  22% | abe: 8.706 | eve: 8.996 | bob: 8.660Epoch   4:  23% | abe: 8.704 | eve: 8.996 | bob: 8.658Epoch   4:  24% | abe: 8.703 | eve: 8.994 | bob: 8.657Epoch   4:  25% | abe: 8.703 | eve: 8.994 | bob: 8.657Epoch   4:  25% | abe: 8.702 | eve: 8.994 | bob: 8.657Epoch   4:  26% | abe: 8.701 | eve: 8.994 | bob: 8.657Epoch   4:  27% | abe: 8.700 | eve: 8.994 | bob: 8.657Epoch   4:  28% | abe: 8.700 | eve: 8.994 | bob: 8.657Epoch   4:  28% | abe: 8.699 | eve: 8.995 | bob: 8.656Epoch   4:  29% | abe: 8.698 | eve: 8.995 | bob: 8.655Epoch   4:  30% | abe: 8.696 | eve: 8.995 | bob: 8.654Epoch   4:  31% | abe: 8.696 | eve: 8.995 | bob: 8.653Epoch   4:  32% | abe: 8.695 | eve: 8.995 | bob: 8.651Epoch   4:  32% | abe: 8.694 | eve: 8.995 | bob: 8.650Epoch   4:  33% | abe: 8.694 | eve: 8.995 | bob: 8.650Epoch   4:  34% | abe: 8.693 | eve: 8.995 | bob: 8.649Epoch   4:  35% | abe: 8.692 | eve: 8.995 | bob: 8.648Epoch   4:  35% | abe: 8.692 | eve: 8.994 | bob: 8.648Epoch   4:  36% | abe: 8.690 | eve: 8.994 | bob: 8.647Epoch   4:  37% | abe: 8.689 | eve: 8.994 | bob: 8.647Epoch   4:  38% | abe: 8.688 | eve: 8.994 | bob: 8.645Epoch   4:  39% | abe: 8.687 | eve: 8.994 | bob: 8.644Epoch   4:  39% | abe: 8.686 | eve: 8.993 | bob: 8.644Epoch   4:  40% | abe: 8.684 | eve: 8.993 | bob: 8.641Epoch   4:  41% | abe: 8.683 | eve: 8.995 | bob: 8.640Epoch   4:  42% | abe: 8.682 | eve: 8.995 | bob: 8.639Epoch   4:  42% | abe: 8.681 | eve: 8.995 | bob: 8.638Epoch   4:  43% | abe: 8.679 | eve: 8.995 | bob: 8.637Epoch   4:  44% | abe: 8.678 | eve: 8.995 | bob: 8.637Epoch   4:  45% | abe: 8.678 | eve: 8.995 | bob: 8.637Epoch   4:  46% | abe: 8.677 | eve: 8.995 | bob: 8.637Epoch   4:  46% | abe: 8.676 | eve: 8.995 | bob: 8.636Epoch   4:  47% | abe: 8.675 | eve: 8.995 | bob: 8.635Epoch   4:  48% | abe: 8.674 | eve: 8.995 | bob: 8.633Epoch   4:  49% | abe: 8.673 | eve: 8.996 | bob: 8.632Epoch   4:  50% | abe: 8.671 | eve: 8.995 | bob: 8.631Epoch   4:  50% | abe: 8.670 | eve: 8.996 | bob: 8.629Epoch   4:  51% | abe: 8.668 | eve: 8.996 | bob: 8.628Epoch   4:  52% | abe: 8.667 | eve: 8.996 | bob: 8.628Epoch   4:  53% | abe: 8.667 | eve: 8.996 | bob: 8.628Epoch   4:  53% | abe: 8.665 | eve: 8.997 | bob: 8.626Epoch   4:  54% | abe: 8.664 | eve: 8.997 | bob: 8.625Epoch   4:  55% | abe: 8.663 | eve: 8.996 | bob: 8.624Epoch   4:  56% | abe: 8.662 | eve: 8.997 | bob: 8.623Epoch   4:  57% | abe: 8.661 | eve: 8.997 | bob: 8.622Epoch   4:  57% | abe: 8.660 | eve: 8.997 | bob: 8.621Epoch   4:  58% | abe: 8.659 | eve: 8.997 | bob: 8.620Epoch   4:  59% | abe: 8.658 | eve: 8.997 | bob: 8.619Epoch   4:  60% | abe: 8.657 | eve: 8.998 | bob: 8.619Epoch   4:  60% | abe: 8.656 | eve: 8.998 | bob: 8.618Epoch   4:  61% | abe: 8.655 | eve: 8.998 | bob: 8.617Epoch   4:  62% | abe: 8.654 | eve: 8.998 | bob: 8.616Epoch   4:  63% | abe: 8.653 | eve: 8.997 | bob: 8.615Epoch   4:  64% | abe: 8.652 | eve: 8.997 | bob: 8.614Epoch   4:  64% | abe: 8.651 | eve: 8.998 | bob: 8.614Epoch   4:  65% | abe: 8.649 | eve: 8.998 | bob: 8.612Epoch   4:  66% | abe: 8.647 | eve: 8.999 | bob: 8.611Epoch   4:  67% | abe: 8.646 | eve: 8.999 | bob: 8.609Epoch   4:  67% | abe: 8.645 | eve: 8.999 | bob: 8.608Epoch   4:  68% | abe: 8.644 | eve: 8.999 | bob: 8.607Epoch   4:  69% | abe: 8.642 | eve: 9.000 | bob: 8.606Epoch   4:  70% | abe: 8.641 | eve: 8.999 | bob: 8.605Epoch   4:  71% | abe: 8.640 | eve: 8.999 | bob: 8.604Epoch   4:  71% | abe: 8.639 | eve: 9.000 | bob: 8.603Epoch   4:  72% | abe: 8.638 | eve: 9.000 | bob: 8.602Epoch   4:  73% | abe: 8.637 | eve: 8.999 | bob: 8.600Epoch   4:  74% | abe: 8.635 | eve: 8.999 | bob: 8.600Epoch   4:  75% | abe: 8.634 | eve: 8.999 | bob: 8.599Epoch   4:  75% | abe: 8.633 | eve: 8.999 | bob: 8.598Epoch   4:  76% | abe: 8.632 | eve: 8.999 | bob: 8.596Epoch   4:  77% | abe: 8.631 | eve: 9.000 | bob: 8.595Epoch   4:  78% | abe: 8.630 | eve: 8.999 | bob: 8.594Epoch   4:  78% | abe: 8.628 | eve: 8.999 | bob: 8.593Epoch   4:  79% | abe: 8.627 | eve: 8.999 | bob: 8.592Epoch   4:  80% | abe: 8.625 | eve: 8.999 | bob: 8.591Epoch   4:  81% | abe: 8.624 | eve: 8.999 | bob: 8.589Epoch   4:  82% | abe: 8.623 | eve: 8.999 | bob: 8.588Epoch   4:  82% | abe: 8.622 | eve: 9.000 | bob: 8.588Epoch   4:  83% | abe: 8.621 | eve: 9.000 | bob: 8.587Epoch   4:  84% | abe: 8.620 | eve: 8.999 | bob: 8.586Epoch   4:  85% | abe: 8.618 | eve: 8.999 | bob: 8.585Epoch   4:  85% | abe: 8.618 | eve: 8.999 | bob: 8.584Epoch   4:  86% | abe: 8.616 | eve: 9.000 | bob: 8.583Epoch   4:  87% | abe: 8.615 | eve: 9.000 | bob: 8.581Epoch   4:  88% | abe: 8.614 | eve: 9.000 | bob: 8.580Epoch   4:  89% | abe: 8.612 | eve: 9.000 | bob: 8.579Epoch   4:  89% | abe: 8.611 | eve: 9.000 | bob: 8.578Epoch   4:  90% | abe: 8.611 | eve: 9.000 | bob: 8.578Epoch   4:  91% | abe: 8.610 | eve: 9.000 | bob: 8.577Epoch   4:  92% | abe: 8.608 | eve: 9.000 | bob: 8.576Epoch   4:  92% | abe: 8.607 | eve: 8.999 | bob: 8.575Epoch   4:  93% | abe: 8.606 | eve: 8.999 | bob: 8.574Epoch   4:  94% | abe: 8.605 | eve: 8.999 | bob: 8.573Epoch   4:  95% | abe: 8.604 | eve: 8.999 | bob: 8.572Epoch   4:  96% | abe: 8.603 | eve: 8.999 | bob: 8.571Epoch   4:  96% | abe: 8.601 | eve: 8.999 | bob: 8.570Epoch   4:  97% | abe: 8.600 | eve: 9.000 | bob: 8.568Epoch   4:  98% | abe: 8.599 | eve: 8.999 | bob: 8.567Epoch   4:  99% | abe: 8.598 | eve: 9.000 | bob: 8.566
New best Bob loss 8.56623901823582 at epoch 4
Epoch   5:   0% | abe: 8.433 | eve: 8.975 | bob: 8.427Epoch   5:   0% | abe: 8.426 | eve: 8.970 | bob: 8.426Epoch   5:   1% | abe: 8.427 | eve: 8.975 | bob: 8.425Epoch   5:   2% | abe: 8.439 | eve: 8.987 | bob: 8.436Epoch   5:   3% | abe: 8.442 | eve: 8.987 | bob: 8.437Epoch   5:   3% | abe: 8.436 | eve: 8.988 | bob: 8.429Epoch   5:   4% | abe: 8.437 | eve: 8.988 | bob: 8.428Epoch   5:   5% | abe: 8.441 | eve: 8.992 | bob: 8.430Epoch   5:   6% | abe: 8.442 | eve: 8.991 | bob: 8.429Epoch   5:   7% | abe: 8.442 | eve: 8.995 | bob: 8.427Epoch   5:   7% | abe: 8.440 | eve: 8.992 | bob: 8.425Epoch   5:   8% | abe: 8.440 | eve: 8.992 | bob: 8.424Epoch   5:   9% | abe: 8.437 | eve: 8.992 | bob: 8.422Epoch   5:  10% | abe: 8.435 | eve: 8.992 | bob: 8.421Epoch   5:  10% | abe: 8.432 | eve: 8.992 | bob: 8.418Epoch   5:  11% | abe: 8.427 | eve: 8.993 | bob: 8.415Epoch   5:  12% | abe: 8.427 | eve: 8.991 | bob: 8.415Epoch   5:  13% | abe: 8.424 | eve: 8.992 | bob: 8.412Epoch   5:  14% | abe: 8.422 | eve: 8.992 | bob: 8.410Epoch   5:  14% | abe: 8.419 | eve: 8.991 | bob: 8.405Epoch   5:  15% | abe: 8.417 | eve: 8.992 | bob: 8.404Epoch   5:  16% | abe: 8.416 | eve: 8.992 | bob: 8.403Epoch   5:  17% | abe: 8.413 | eve: 8.991 | bob: 8.401Epoch   5:  17% | abe: 8.412 | eve: 8.990 | bob: 8.400Epoch   5:  18% | abe: 8.410 | eve: 8.989 | bob: 8.400Epoch   5:  19% | abe: 8.410 | eve: 8.990 | bob: 8.400Epoch   5:  20% | abe: 8.410 | eve: 8.989 | bob: 8.399Epoch   5:  21% | abe: 8.408 | eve: 8.989 | bob: 8.397Epoch   5:  21% | abe: 8.406 | eve: 8.990 | bob: 8.394Epoch   5:  22% | abe: 8.403 | eve: 8.990 | bob: 8.391Epoch   5:  23% | abe: 8.402 | eve: 8.991 | bob: 8.391Epoch   5:  24% | abe: 8.401 | eve: 8.992 | bob: 8.390Epoch   5:  25% | abe: 8.399 | eve: 8.991 | bob: 8.389Epoch   5:  25% | abe: 8.398 | eve: 8.991 | bob: 8.388Epoch   5:  26% | abe: 8.397 | eve: 8.992 | bob: 8.387Epoch   5:  27% | abe: 8.394 | eve: 8.992 | bob: 8.385Epoch   5:  28% | abe: 8.392 | eve: 8.991 | bob: 8.382Epoch   5:  28% | abe: 8.390 | eve: 8.990 | bob: 8.380Epoch   5:  29% | abe: 8.389 | eve: 8.990 | bob: 8.379Epoch   5:  30% | abe: 8.387 | eve: 8.990 | bob: 8.378Epoch   5:  31% | abe: 8.386 | eve: 8.991 | bob: 8.377Epoch   5:  32% | abe: 8.383 | eve: 8.991 | bob: 8.375Epoch   5:  32% | abe: 8.382 | eve: 8.990 | bob: 8.374Epoch   5:  33% | abe: 8.380 | eve: 8.991 | bob: 8.373Epoch   5:  34% | abe: 8.378 | eve: 8.991 | bob: 8.371Epoch   5:  35% | abe: 8.377 | eve: 8.991 | bob: 8.370Epoch   5:  35% | abe: 8.377 | eve: 8.991 | bob: 8.369Epoch   5:  36% | abe: 8.375 | eve: 8.992 | bob: 8.368Epoch   5:  37% | abe: 8.374 | eve: 8.992 | bob: 8.367Epoch   5:  38% | abe: 8.373 | eve: 8.992 | bob: 8.366Epoch   5:  39% | abe: 8.371 | eve: 8.992 | bob: 8.364Epoch   5:  39% | abe: 8.370 | eve: 8.992 | bob: 8.363Epoch   5:  40% | abe: 8.368 | eve: 8.992 | bob: 8.362Epoch   5:  41% | abe: 8.367 | eve: 8.991 | bob: 8.361Epoch   5:  42% | abe: 8.365 | eve: 8.991 | bob: 8.359Epoch   5:  42% | abe: 8.363 | eve: 8.992 | bob: 8.358Epoch   5:  43% | abe: 8.361 | eve: 8.992 | bob: 8.356Epoch   5:  44% | abe: 8.359 | eve: 8.992 | bob: 8.354Epoch   5:  45% | abe: 8.357 | eve: 8.992 | bob: 8.352Epoch   5:  46% | abe: 8.356 | eve: 8.992 | bob: 8.351Epoch   5:  46% | abe: 8.353 | eve: 8.991 | bob: 8.349Epoch   5:  47% | abe: 8.352 | eve: 8.991 | bob: 8.348Epoch   5:  48% | abe: 8.350 | eve: 8.991 | bob: 8.346Epoch   5:  49% | abe: 8.349 | eve: 8.991 | bob: 8.345Epoch   5:  50% | abe: 8.347 | eve: 8.991 | bob: 8.343Epoch   5:  50% | abe: 8.345 | eve: 8.992 | bob: 8.341Epoch   5:  51% | abe: 8.344 | eve: 8.992 | bob: 8.340Epoch   5:  52% | abe: 8.343 | eve: 8.993 | bob: 8.339Epoch   5:  53% | abe: 8.341 | eve: 8.992 | bob: 8.338Epoch   5:  53% | abe: 8.339 | eve: 8.993 | bob: 8.335Epoch   5:  54% | abe: 8.338 | eve: 8.993 | bob: 8.334Epoch   5:  55% | abe: 8.336 | eve: 8.992 | bob: 8.332Epoch   5:  56% | abe: 8.335 | eve: 8.992 | bob: 8.331Epoch   5:  57% | abe: 8.333 | eve: 8.992 | bob: 8.330Epoch   5:  57% | abe: 8.332 | eve: 8.992 | bob: 8.329Epoch   5:  58% | abe: 8.330 | eve: 8.992 | bob: 8.327Epoch   5:  59% | abe: 8.328 | eve: 8.991 | bob: 8.326Epoch   5:  60% | abe: 8.327 | eve: 8.992 | bob: 8.325Epoch   5:  60% | abe: 8.325 | eve: 8.992 | bob: 8.323Epoch   5:  61% | abe: 8.323 | eve: 8.992 | bob: 8.321Epoch   5:  62% | abe: 8.322 | eve: 8.992 | bob: 8.320Epoch   5:  63% | abe: 8.320 | eve: 8.992 | bob: 8.318Epoch   5:  64% | abe: 8.318 | eve: 8.992 | bob: 8.317Epoch   5:  64% | abe: 8.316 | eve: 8.992 | bob: 8.314Epoch   5:  65% | abe: 8.314 | eve: 8.993 | bob: 8.313Epoch   5:  66% | abe: 8.312 | eve: 8.992 | bob: 8.312Epoch   5:  67% | abe: 8.311 | eve: 8.993 | bob: 8.310Epoch   5:  67% | abe: 8.309 | eve: 8.993 | bob: 8.309Epoch   5:  68% | abe: 8.308 | eve: 8.992 | bob: 8.307Epoch   5:  69% | abe: 8.307 | eve: 8.993 | bob: 8.306Epoch   5:  70% | abe: 8.305 | eve: 8.993 | bob: 8.305Epoch   5:  71% | abe: 8.303 | eve: 8.993 | bob: 8.303Epoch   5:  71% | abe: 8.302 | eve: 8.993 | bob: 8.302Epoch   5:  72% | abe: 8.300 | eve: 8.994 | bob: 8.300Epoch   5:  73% | abe: 8.299 | eve: 8.994 | bob: 8.299Epoch   5:  74% | abe: 8.297 | eve: 8.994 | bob: 8.298Epoch   5:  75% | abe: 8.296 | eve: 8.994 | bob: 8.296Epoch   5:  75% | abe: 8.294 | eve: 8.993 | bob: 8.295Epoch   5:  76% | abe: 8.293 | eve: 8.993 | bob: 8.293Epoch   5:  77% | abe: 8.291 | eve: 8.993 | bob: 8.292Epoch   5:  78% | abe: 8.289 | eve: 8.994 | bob: 8.290Epoch   5:  78% | abe: 8.287 | eve: 8.993 | bob: 8.288Epoch   5:  79% | abe: 8.285 | eve: 8.993 | bob: 8.287Epoch   5:  80% | abe: 8.284 | eve: 8.993 | bob: 8.285Epoch   5:  81% | abe: 8.282 | eve: 8.993 | bob: 8.284Epoch   5:  82% | abe: 8.280 | eve: 8.993 | bob: 8.282Epoch   5:  82% | abe: 8.278 | eve: 8.993 | bob: 8.280Epoch   5:  83% | abe: 8.276 | eve: 8.993 | bob: 8.279Epoch   5:  84% | abe: 8.274 | eve: 8.994 | bob: 8.277Epoch   5:  85% | abe: 8.273 | eve: 8.993 | bob: 8.276Epoch   5:  85% | abe: 8.271 | eve: 8.994 | bob: 8.274Epoch   5:  86% | abe: 8.269 | eve: 8.994 | bob: 8.272Epoch   5:  87% | abe: 8.268 | eve: 8.994 | bob: 8.271Epoch   5:  88% | abe: 8.266 | eve: 8.994 | bob: 8.269Epoch   5:  89% | abe: 8.264 | eve: 8.994 | bob: 8.267Epoch   5:  89% | abe: 8.262 | eve: 8.994 | bob: 8.266Epoch   5:  90% | abe: 8.260 | eve: 8.994 | bob: 8.264Epoch   5:  91% | abe: 8.258 | eve: 8.993 | bob: 8.262Epoch   5:  92% | abe: 8.256 | eve: 8.993 | bob: 8.261Epoch   5:  92% | abe: 8.254 | eve: 8.993 | bob: 8.259Epoch   5:  93% | abe: 8.253 | eve: 8.993 | bob: 8.257Epoch   5:  94% | abe: 8.251 | eve: 8.993 | bob: 8.256Epoch   5:  95% | abe: 8.249 | eve: 8.993 | bob: 8.254Epoch   5:  96% | abe: 8.247 | eve: 8.994 | bob: 8.252Epoch   5:  96% | abe: 8.245 | eve: 8.994 | bob: 8.251Epoch   5:  97% | abe: 8.244 | eve: 8.993 | bob: 8.249Epoch   5:  98% | abe: 8.242 | eve: 8.993 | bob: 8.247Epoch   5:  99% | abe: 8.240 | eve: 8.993 | bob: 8.246
New best Bob loss 8.245969042471188 at epoch 5
Epoch   6:   0% | abe: 7.996 | eve: 9.011 | bob: 8.016Epoch   6:   0% | abe: 8.009 | eve: 9.018 | bob: 8.035Epoch   6:   1% | abe: 8.011 | eve: 8.999 | bob: 8.040Epoch   6:   2% | abe: 8.002 | eve: 9.010 | bob: 8.032Epoch   6:   3% | abe: 7.998 | eve: 9.012 | bob: 8.027Epoch   6:   3% | abe: 7.996 | eve: 9.012 | bob: 8.023Epoch   6:   4% | abe: 7.991 | eve: 9.008 | bob: 8.017Epoch   6:   5% | abe: 7.992 | eve: 9.007 | bob: 8.017Epoch   6:   6% | abe: 7.992 | eve: 9.006 | bob: 8.017Epoch   6:   7% | abe: 7.991 | eve: 9.004 | bob: 8.018Epoch   6:   7% | abe: 7.990 | eve: 9.002 | bob: 8.017Epoch   6:   8% | abe: 7.988 | eve: 9.001 | bob: 8.015Epoch   6:   9% | abe: 7.988 | eve: 9.000 | bob: 8.014Epoch   6:  10% | abe: 7.984 | eve: 9.002 | bob: 8.010Epoch   6:  10% | abe: 7.982 | eve: 9.002 | bob: 8.008Epoch   6:  11% | abe: 7.980 | eve: 9.002 | bob: 8.006Epoch   6:  12% | abe: 7.977 | eve: 9.002 | bob: 8.003Epoch   6:  13% | abe: 7.974 | eve: 9.000 | bob: 8.001Epoch   6:  14% | abe: 7.971 | eve: 9.004 | bob: 7.998Epoch   6:  14% | abe: 7.971 | eve: 9.002 | bob: 7.998Epoch   6:  15% | abe: 7.969 | eve: 9.001 | bob: 7.996Epoch   6:  16% | abe: 7.966 | eve: 9.000 | bob: 7.993Epoch   6:  17% | abe: 7.963 | eve: 9.000 | bob: 7.991Epoch   6:  17% | abe: 7.962 | eve: 9.001 | bob: 7.991Epoch   6:  18% | abe: 7.961 | eve: 9.001 | bob: 7.990Epoch   6:  19% | abe: 7.960 | eve: 8.999 | bob: 7.989Epoch   6:  20% | abe: 7.957 | eve: 8.998 | bob: 7.987Epoch   6:  21% | abe: 7.955 | eve: 8.997 | bob: 7.985Epoch   6:  21% | abe: 7.953 | eve: 8.998 | bob: 7.982Epoch   6:  22% | abe: 7.951 | eve: 8.999 | bob: 7.980Epoch   6:  23% | abe: 7.949 | eve: 8.997 | bob: 7.979Epoch   6:  24% | abe: 7.948 | eve: 8.998 | bob: 7.977Epoch   6:  25% | abe: 7.946 | eve: 8.997 | bob: 7.977Epoch   6:  25% | abe: 7.944 | eve: 8.997 | bob: 7.974Epoch   6:  26% | abe: 7.943 | eve: 8.996 | bob: 7.973Epoch   6:  27% | abe: 7.941 | eve: 8.997 | bob: 7.971Epoch   6:  28% | abe: 7.938 | eve: 8.997 | bob: 7.969Epoch   6:  28% | abe: 7.935 | eve: 8.996 | bob: 7.966Epoch   6:  29% | abe: 7.934 | eve: 8.997 | bob: 7.965Epoch   6:  30% | abe: 7.933 | eve: 8.997 | bob: 7.965Epoch   6:  31% | abe: 7.932 | eve: 8.997 | bob: 7.964Epoch   6:  32% | abe: 7.930 | eve: 8.997 | bob: 7.962Epoch   6:  32% | abe: 7.929 | eve: 8.996 | bob: 7.960Epoch   6:  33% | abe: 7.927 | eve: 8.996 | bob: 7.959Epoch   6:  34% | abe: 7.925 | eve: 8.996 | bob: 7.957Epoch   6:  35% | abe: 7.923 | eve: 8.996 | bob: 7.955Epoch   6:  35% | abe: 7.920 | eve: 8.996 | bob: 7.953Epoch   6:  36% | abe: 7.918 | eve: 8.996 | bob: 7.951Epoch   6:  37% | abe: 7.915 | eve: 8.996 | bob: 7.948Epoch   6:  38% | abe: 7.913 | eve: 8.995 | bob: 7.946Epoch   6:  39% | abe: 7.910 | eve: 8.995 | bob: 7.944Epoch   6:  39% | abe: 7.909 | eve: 8.995 | bob: 7.942Epoch   6:  40% | abe: 7.906 | eve: 8.995 | bob: 7.940Epoch   6:  41% | abe: 7.904 | eve: 8.995 | bob: 7.938Epoch   6:  42% | abe: 7.902 | eve: 8.995 | bob: 7.936Epoch   6:  42% | abe: 7.901 | eve: 8.995 | bob: 7.934Epoch   6:  43% | abe: 7.898 | eve: 8.994 | bob: 7.932Epoch   6:  44% | abe: 7.896 | eve: 8.995 | bob: 7.930Epoch   6:  45% | abe: 7.894 | eve: 8.994 | bob: 7.928Epoch   6:  46% | abe: 7.892 | eve: 8.995 | bob: 7.926Epoch   6:  46% | abe: 7.890 | eve: 8.994 | bob: 7.924Epoch   6:  47% | abe: 7.888 | eve: 8.994 | bob: 7.922Epoch   6:  48% | abe: 7.886 | eve: 8.994 | bob: 7.920Epoch   6:  49% | abe: 7.883 | eve: 8.994 | bob: 7.918Epoch   6:  50% | abe: 7.882 | eve: 8.994 | bob: 7.916Epoch   6:  50% | abe: 7.880 | eve: 8.994 | bob: 7.914Epoch   6:  51% | abe: 7.877 | eve: 8.994 | bob: 7.912Epoch   6:  52% | abe: 7.875 | eve: 8.993 | bob: 7.910Epoch   6:  53% | abe: 7.873 | eve: 8.993 | bob: 7.908Epoch   6:  53% | abe: 7.870 | eve: 8.993 | bob: 7.905Epoch   6:  54% | abe: 7.869 | eve: 8.993 | bob: 7.904Epoch   6:  55% | abe: 7.867 | eve: 8.993 | bob: 7.902Epoch   6:  56% | abe: 7.865 | eve: 8.994 | bob: 7.900Epoch   6:  57% | abe: 7.863 | eve: 8.994 | bob: 7.898Epoch   6:  57% | abe: 7.861 | eve: 8.994 | bob: 7.896Epoch   6:  58% | abe: 7.859 | eve: 8.995 | bob: 7.894Epoch   6:  59% | abe: 7.857 | eve: 8.995 | bob: 7.892Epoch   6:  60% | abe: 7.855 | eve: 8.995 | bob: 7.891Epoch   6:  60% | abe: 7.854 | eve: 8.995 | bob: 7.889Epoch   6:  61% | abe: 7.851 | eve: 8.996 | bob: 7.887Epoch   6:  62% | abe: 7.849 | eve: 8.996 | bob: 7.885Epoch   6:  63% | abe: 7.847 | eve: 8.996 | bob: 7.883Epoch   6:  64% | abe: 7.845 | eve: 8.996 | bob: 7.881Epoch   6:  64% | abe: 7.843 | eve: 8.997 | bob: 7.879Epoch   6:  65% | abe: 7.841 | eve: 8.997 | bob: 7.878Epoch   6:  66% | abe: 7.839 | eve: 8.997 | bob: 7.876Epoch   6:  67% | abe: 7.837 | eve: 8.997 | bob: 7.874Epoch   6:  67% | abe: 7.835 | eve: 8.997 | bob: 7.872Epoch   6:  68% | abe: 7.834 | eve: 8.997 | bob: 7.871Epoch   6:  69% | abe: 7.832 | eve: 8.997 | bob: 7.869Epoch   6:  70% | abe: 7.829 | eve: 8.997 | bob: 7.866Epoch   6:  71% | abe: 7.827 | eve: 8.998 | bob: 7.864Epoch   6:  71% | abe: 7.825 | eve: 8.998 | bob: 7.862Epoch   6:  72% | abe: 7.823 | eve: 8.998 | bob: 7.860Epoch   6:  73% | abe: 7.821 | eve: 8.998 | bob: 7.859Epoch   6:  74% | abe: 7.819 | eve: 8.998 | bob: 7.857Epoch   6:  75% | abe: 7.817 | eve: 8.998 | bob: 7.855Epoch   6:  75% | abe: 7.816 | eve: 8.998 | bob: 7.853Epoch   6:  76% | abe: 7.814 | eve: 8.998 | bob: 7.851Epoch   6:  77% | abe: 7.812 | eve: 8.998 | bob: 7.850Epoch   6:  78% | abe: 7.810 | eve: 8.998 | bob: 7.848Epoch   6:  78% | abe: 7.808 | eve: 8.998 | bob: 7.846Epoch   6:  79% | abe: 7.806 | eve: 8.998 | bob: 7.844Epoch   6:  80% | abe: 7.804 | eve: 8.998 | bob: 7.843Epoch   6:  81% | abe: 7.803 | eve: 8.998 | bob: 7.841Epoch   6:  82% | abe: 7.801 | eve: 8.998 | bob: 7.839Epoch   6:  82% | abe: 7.799 | eve: 8.998 | bob: 7.837Epoch   6:  83% | abe: 7.797 | eve: 8.998 | bob: 7.836Epoch   6:  84% | abe: 7.795 | eve: 8.998 | bob: 7.834Epoch   6:  85% | abe: 7.793 | eve: 8.998 | bob: 7.832Epoch   6:  85% | abe: 7.791 | eve: 8.999 | bob: 7.830Epoch   6:  86% | abe: 7.789 | eve: 8.999 | bob: 7.828Epoch   6:  87% | abe: 7.787 | eve: 8.999 | bob: 7.827Epoch   6:  88% | abe: 7.785 | eve: 8.999 | bob: 7.825Epoch   6:  89% | abe: 7.783 | eve: 8.999 | bob: 7.823Epoch   6:  89% | abe: 7.781 | eve: 8.999 | bob: 7.821Epoch   6:  90% | abe: 7.779 | eve: 8.999 | bob: 7.819Epoch   6:  91% | abe: 7.778 | eve: 8.999 | bob: 7.817Epoch   6:  92% | abe: 7.776 | eve: 8.999 | bob: 7.815Epoch   6:  92% | abe: 7.774 | eve: 8.999 | bob: 7.814Epoch   6:  93% | abe: 7.772 | eve: 9.000 | bob: 7.812Epoch   6:  94% | abe: 7.770 | eve: 8.999 | bob: 7.810Epoch   6:  95% | abe: 7.768 | eve: 8.999 | bob: 7.808Epoch   6:  96% | abe: 7.766 | eve: 8.999 | bob: 7.806Epoch   6:  96% | abe: 7.764 | eve: 8.999 | bob: 7.805Epoch   6:  97% | abe: 7.762 | eve: 8.999 | bob: 7.803Epoch   6:  98% | abe: 7.761 | eve: 8.999 | bob: 7.801Epoch   6:  99% | abe: 7.758 | eve: 8.999 | bob: 7.799
New best Bob loss 7.798796749381609 at epoch 6
Epoch   7:   0% | abe: 7.454 | eve: 9.004 | bob: 7.514Epoch   7:   0% | abe: 7.494 | eve: 9.000 | bob: 7.550Epoch   7:   1% | abe: 7.497 | eve: 9.004 | bob: 7.554Epoch   7:   2% | abe: 7.488 | eve: 9.019 | bob: 7.543Epoch   7:   3% | abe: 7.486 | eve: 9.024 | bob: 7.543Epoch   7:   3% | abe: 7.483 | eve: 9.019 | bob: 7.540Epoch   7:   4% | abe: 7.478 | eve: 9.015 | bob: 7.536Epoch   7:   5% | abe: 7.476 | eve: 9.020 | bob: 7.535Epoch   7:   6% | abe: 7.472 | eve: 9.016 | bob: 7.530Epoch   7:   7% | abe: 7.472 | eve: 9.011 | bob: 7.530Epoch   7:   7% | abe: 7.470 | eve: 9.009 | bob: 7.527Epoch   7:   8% | abe: 7.469 | eve: 9.010 | bob: 7.527Epoch   7:   9% | abe: 7.467 | eve: 9.009 | bob: 7.524Epoch   7:  10% | abe: 7.464 | eve: 9.008 | bob: 7.521Epoch   7:  10% | abe: 7.462 | eve: 9.006 | bob: 7.519Epoch   7:  11% | abe: 7.462 | eve: 9.005 | bob: 7.518Epoch   7:  12% | abe: 7.459 | eve: 9.006 | bob: 7.515Epoch   7:  13% | abe: 7.457 | eve: 9.006 | bob: 7.513Epoch   7:  14% | abe: 7.454 | eve: 9.004 | bob: 7.509Epoch   7:  14% | abe: 7.452 | eve: 9.003 | bob: 7.507Epoch   7:  15% | abe: 7.450 | eve: 9.004 | bob: 7.505Epoch   7:  16% | abe: 7.448 | eve: 9.004 | bob: 7.503Epoch   7:  17% | abe: 7.446 | eve: 9.005 | bob: 7.501Epoch   7:  17% | abe: 7.444 | eve: 9.004 | bob: 7.499Epoch   7:  18% | abe: 7.442 | eve: 9.003 | bob: 7.497Epoch   7:  19% | abe: 7.442 | eve: 9.001 | bob: 7.496Epoch   7:  20% | abe: 7.441 | eve: 9.001 | bob: 7.495Epoch   7:  21% | abe: 7.439 | eve: 9.000 | bob: 7.493Epoch   7:  21% | abe: 7.439 | eve: 8.999 | bob: 7.493Epoch   7:  22% | abe: 7.436 | eve: 8.999 | bob: 7.490Epoch   7:  23% | abe: 7.433 | eve: 8.999 | bob: 7.488Epoch   7:  24% | abe: 7.431 | eve: 8.999 | bob: 7.486Epoch   7:  25% | abe: 7.429 | eve: 8.999 | bob: 7.484Epoch   7:  25% | abe: 7.427 | eve: 8.998 | bob: 7.482Epoch   7:  26% | abe: 7.426 | eve: 8.998 | bob: 7.480Epoch   7:  27% | abe: 7.423 | eve: 8.998 | bob: 7.477Epoch   7:  28% | abe: 7.422 | eve: 8.999 | bob: 7.477Epoch   7:  28% | abe: 7.420 | eve: 8.999 | bob: 7.475Epoch   7:  29% | abe: 7.419 | eve: 8.999 | bob: 7.473Epoch   7:  30% | abe: 7.417 | eve: 8.999 | bob: 7.472Epoch   7:  31% | abe: 7.416 | eve: 8.999 | bob: 7.470Epoch   7:  32% | abe: 7.414 | eve: 9.000 | bob: 7.469Epoch   7:  32% | abe: 7.412 | eve: 8.999 | bob: 7.467Epoch   7:  33% | abe: 7.409 | eve: 8.999 | bob: 7.464Epoch   7:  34% | abe: 7.407 | eve: 8.999 | bob: 7.463Epoch   7:  35% | abe: 7.405 | eve: 9.000 | bob: 7.460Epoch   7:  35% | abe: 7.403 | eve: 9.000 | bob: 7.458Epoch   7:  36% | abe: 7.401 | eve: 9.000 | bob: 7.457Epoch   7:  37% | abe: 7.400 | eve: 8.999 | bob: 7.456Epoch   7:  38% | abe: 7.397 | eve: 9.000 | bob: 7.453Epoch   7:  39% | abe: 7.395 | eve: 9.001 | bob: 7.451Epoch   7:  39% | abe: 7.392 | eve: 9.001 | bob: 7.448Epoch   7:  40% | abe: 7.390 | eve: 9.002 | bob: 7.446Epoch   7:  41% | abe: 7.388 | eve: 9.002 | bob: 7.444Epoch   7:  42% | abe: 7.386 | eve: 9.001 | bob: 7.443Epoch   7:  42% | abe: 7.385 | eve: 9.002 | bob: 7.441Epoch   7:  43% | abe: 7.382 | eve: 9.002 | bob: 7.439Epoch   7:  44% | abe: 7.381 | eve: 9.002 | bob: 7.437Epoch   7:  45% | abe: 7.379 | eve: 9.002 | bob: 7.436Epoch   7:  46% | abe: 7.377 | eve: 9.001 | bob: 7.434Epoch   7:  46% | abe: 7.375 | eve: 9.001 | bob: 7.432Epoch   7:  47% | abe: 7.373 | eve: 9.001 | bob: 7.430Epoch   7:  48% | abe: 7.371 | eve: 9.001 | bob: 7.428Epoch   7:  49% | abe: 7.369 | eve: 9.001 | bob: 7.426Epoch   7:  50% | abe: 7.367 | eve: 9.000 | bob: 7.424Epoch   7:  50% | abe: 7.365 | eve: 8.999 | bob: 7.421Epoch   7:  51% | abe: 7.362 | eve: 9.000 | bob: 7.419Epoch   7:  52% | abe: 7.360 | eve: 8.999 | bob: 7.417Epoch   7:  53% | abe: 7.358 | eve: 8.999 | bob: 7.416Epoch   7:  53% | abe: 7.357 | eve: 8.999 | bob: 7.415Epoch   7:  54% | abe: 7.355 | eve: 8.999 | bob: 7.412Epoch   7:  55% | abe: 7.352 | eve: 8.999 | bob: 7.410Epoch   7:  56% | abe: 7.350 | eve: 8.999 | bob: 7.408Epoch   7:  57% | abe: 7.349 | eve: 8.999 | bob: 7.406Epoch   7:  57% | abe: 7.346 | eve: 8.999 | bob: 7.404Epoch   7:  58% | abe: 7.344 | eve: 8.998 | bob: 7.401Epoch   7:  59% | abe: 7.342 | eve: 8.998 | bob: 7.400Epoch   7:  60% | abe: 7.340 | eve: 8.998 | bob: 7.398Epoch   7:  60% | abe: 7.338 | eve: 8.998 | bob: 7.396Epoch   7:  61% | abe: 7.336 | eve: 8.998 | bob: 7.394Epoch   7:  62% | abe: 7.335 | eve: 8.998 | bob: 7.393Epoch   7:  63% | abe: 7.333 | eve: 8.998 | bob: 7.391Epoch   7:  64% | abe: 7.331 | eve: 8.997 | bob: 7.388Epoch   7:  64% | abe: 7.329 | eve: 8.998 | bob: 7.386Epoch   7:  65% | abe: 7.327 | eve: 8.998 | bob: 7.385Epoch   7:  66% | abe: 7.325 | eve: 8.998 | bob: 7.383Epoch   7:  67% | abe: 7.323 | eve: 8.998 | bob: 7.382Epoch   7:  67% | abe: 7.321 | eve: 8.998 | bob: 7.379Epoch   7:  68% | abe: 7.319 | eve: 8.998 | bob: 7.377Epoch   7:  69% | abe: 7.317 | eve: 8.998 | bob: 7.375Epoch   7:  70% | abe: 7.315 | eve: 8.998 | bob: 7.373Epoch   7:  71% | abe: 7.313 | eve: 8.998 | bob: 7.371Epoch   7:  71% | abe: 7.311 | eve: 8.998 | bob: 7.369Epoch   7:  72% | abe: 7.309 | eve: 8.998 | bob: 7.367Epoch   7:  73% | abe: 7.307 | eve: 8.998 | bob: 7.365Epoch   7:  74% | abe: 7.305 | eve: 8.998 | bob: 7.364Epoch   7:  75% | abe: 7.303 | eve: 8.998 | bob: 7.362Epoch   7:  75% | abe: 7.302 | eve: 8.998 | bob: 7.360Epoch   7:  76% | abe: 7.300 | eve: 8.998 | bob: 7.359Epoch   7:  77% | abe: 7.298 | eve: 8.999 | bob: 7.357Epoch   7:  78% | abe: 7.296 | eve: 8.999 | bob: 7.355Epoch   7:  78% | abe: 7.294 | eve: 8.998 | bob: 7.353Epoch   7:  79% | abe: 7.292 | eve: 8.998 | bob: 7.351Epoch   7:  80% | abe: 7.290 | eve: 8.998 | bob: 7.349Epoch   7:  81% | abe: 7.288 | eve: 8.998 | bob: 7.347Epoch   7:  82% | abe: 7.286 | eve: 8.998 | bob: 7.345Epoch   7:  82% | abe: 7.284 | eve: 8.997 | bob: 7.343Epoch   7:  83% | abe: 7.282 | eve: 8.998 | bob: 7.341Epoch   7:  84% | abe: 7.280 | eve: 8.997 | bob: 7.339Epoch   7:  85% | abe: 7.278 | eve: 8.998 | bob: 7.337Epoch   7:  85% | abe: 7.276 | eve: 8.998 | bob: 7.335Epoch   7:  86% | abe: 7.274 | eve: 8.998 | bob: 7.334Epoch   7:  87% | abe: 7.272 | eve: 8.997 | bob: 7.332Epoch   7:  88% | abe: 7.270 | eve: 8.997 | bob: 7.330Epoch   7:  89% | abe: 7.269 | eve: 8.997 | bob: 7.328Epoch   7:  89% | abe: 7.267 | eve: 8.997 | bob: 7.326Epoch   7:  90% | abe: 7.265 | eve: 8.997 | bob: 7.324Epoch   7:  91% | abe: 7.263 | eve: 8.997 | bob: 7.322Epoch   7:  92% | abe: 7.261 | eve: 8.997 | bob: 7.320Epoch   7:  92% | abe: 7.259 | eve: 8.997 | bob: 7.318Epoch   7:  93% | abe: 7.257 | eve: 8.997 | bob: 7.317Epoch   7:  94% | abe: 7.255 | eve: 8.997 | bob: 7.315Epoch   7:  95% | abe: 7.253 | eve: 8.997 | bob: 7.312Epoch   7:  96% | abe: 7.251 | eve: 8.997 | bob: 7.311Epoch   7:  96% | abe: 7.249 | eve: 8.997 | bob: 7.308Epoch   7:  97% | abe: 7.247 | eve: 8.997 | bob: 7.306Epoch   7:  98% | abe: 7.245 | eve: 8.997 | bob: 7.304Epoch   7:  99% | abe: 7.243 | eve: 8.997 | bob: 7.302
New best Bob loss 7.3024379438487586 at epoch 7
Epoch   8:   0% | abe: 6.939 | eve: 8.997 | bob: 6.999Epoch   8:   0% | abe: 6.969 | eve: 8.999 | bob: 7.022Epoch   8:   1% | abe: 6.984 | eve: 9.005 | bob: 7.038Epoch   8:   2% | abe: 6.987 | eve: 9.016 | bob: 7.045Epoch   8:   3% | abe: 6.982 | eve: 9.012 | bob: 7.041Epoch   8:   3% | abe: 6.980 | eve: 9.007 | bob: 7.040Epoch   8:   4% | abe: 6.978 | eve: 9.002 | bob: 7.036Epoch   8:   5% | abe: 6.978 | eve: 8.999 | bob: 7.036Epoch   8:   6% | abe: 6.978 | eve: 8.999 | bob: 7.037Epoch   8:   7% | abe: 6.977 | eve: 8.992 | bob: 7.037Epoch   8:   7% | abe: 6.976 | eve: 8.994 | bob: 7.037Epoch   8:   8% | abe: 6.974 | eve: 8.993 | bob: 7.036Epoch   8:   9% | abe: 6.974 | eve: 8.992 | bob: 7.035Epoch   8:  10% | abe: 6.970 | eve: 8.992 | bob: 7.031Epoch   8:  10% | abe: 6.967 | eve: 8.993 | bob: 7.029Epoch   8:  11% | abe: 6.965 | eve: 8.991 | bob: 7.027Epoch   8:  12% | abe: 6.963 | eve: 8.988 | bob: 7.026Epoch   8:  13% | abe: 6.959 | eve: 8.988 | bob: 7.022Epoch   8:  14% | abe: 6.956 | eve: 8.989 | bob: 7.020Epoch   8:  14% | abe: 6.955 | eve: 8.989 | bob: 7.018Epoch   8:  15% | abe: 6.954 | eve: 8.992 | bob: 7.017Epoch   8:  16% | abe: 6.951 | eve: 8.992 | bob: 7.015Epoch   8:  17% | abe: 6.950 | eve: 8.991 | bob: 7.014Epoch   8:  17% | abe: 6.949 | eve: 8.991 | bob: 7.012Epoch   8:  18% | abe: 6.948 | eve: 8.992 | bob: 7.011Epoch   8:  19% | abe: 6.946 | eve: 8.993 | bob: 7.009Epoch   8:  20% | abe: 6.944 | eve: 8.994 | bob: 7.008Epoch   8:  21% | abe: 6.943 | eve: 8.994 | bob: 7.006Epoch   8:  21% | abe: 6.940 | eve: 8.995 | bob: 7.004Epoch   8:  22% | abe: 6.937 | eve: 8.995 | bob: 7.001Epoch   8:  23% | abe: 6.936 | eve: 8.995 | bob: 7.000Epoch   8:  24% | abe: 6.935 | eve: 8.995 | bob: 6.999Epoch   8:  25% | abe: 6.933 | eve: 8.995 | bob: 6.997Epoch   8:  25% | abe: 6.931 | eve: 8.996 | bob: 6.995Epoch   8:  26% | abe: 6.929 | eve: 8.996 | bob: 6.993Epoch   8:  27% | abe: 6.927 | eve: 8.996 | bob: 6.990Epoch   8:  28% | abe: 6.924 | eve: 8.996 | bob: 6.988Epoch   8:  28% | abe: 6.923 | eve: 8.995 | bob: 6.987Epoch   8:  29% | abe: 6.921 | eve: 8.995 | bob: 6.985Epoch   8:  30% | abe: 6.920 | eve: 8.995 | bob: 6.983Epoch   8:  31% | abe: 6.917 | eve: 8.996 | bob: 6.981Epoch   8:  32% | abe: 6.916 | eve: 8.996 | bob: 6.979Epoch   8:  32% | abe: 6.914 | eve: 8.997 | bob: 6.977Epoch   8:  33% | abe: 6.912 | eve: 8.996 | bob: 6.975Epoch   8:  34% | abe: 6.910 | eve: 8.997 | bob: 6.973Epoch   8:  35% | abe: 6.908 | eve: 8.997 | bob: 6.971Epoch   8:  35% | abe: 6.906 | eve: 8.997 | bob: 6.969Epoch   8:  36% | abe: 6.904 | eve: 8.996 | bob: 6.968Epoch   8:  37% | abe: 6.902 | eve: 8.996 | bob: 6.966Epoch   8:  38% | abe: 6.900 | eve: 8.996 | bob: 6.963Epoch   8:  39% | abe: 6.898 | eve: 8.996 | bob: 6.962Epoch   8:  39% | abe: 6.896 | eve: 8.996 | bob: 6.960Epoch   8:  40% | abe: 6.894 | eve: 8.996 | bob: 6.958Epoch   8:  41% | abe: 6.892 | eve: 8.996 | bob: 6.956Epoch   8:  42% | abe: 6.890 | eve: 8.996 | bob: 6.954Epoch   8:  42% | abe: 6.889 | eve: 8.996 | bob: 6.953Epoch   8:  43% | abe: 6.887 | eve: 8.997 | bob: 6.951Epoch   8:  44% | abe: 6.886 | eve: 8.997 | bob: 6.950Epoch   8:  45% | abe: 6.884 | eve: 8.996 | bob: 6.948Epoch   8:  46% | abe: 6.883 | eve: 8.996 | bob: 6.947Epoch   8:  46% | abe: 6.881 | eve: 8.997 | bob: 6.945Epoch   8:  47% | abe: 6.878 | eve: 8.997 | bob: 6.943Epoch   8:  48% | abe: 6.876 | eve: 8.997 | bob: 6.941Epoch   8:  49% | abe: 6.875 | eve: 8.997 | bob: 6.939Epoch   8:  50% | abe: 6.873 | eve: 8.997 | bob: 6.937Epoch   8:  50% | abe: 6.872 | eve: 8.997 | bob: 6.936Epoch   8:  51% | abe: 6.870 | eve: 8.997 | bob: 6.934Epoch   8:  52% | abe: 6.868 | eve: 8.997 | bob: 6.932Epoch   8:  53% | abe: 6.866 | eve: 8.997 | bob: 6.931Epoch   8:  53% | abe: 6.865 | eve: 8.997 | bob: 6.929Epoch   8:  54% | abe: 6.863 | eve: 8.997 | bob: 6.928Epoch   8:  55% | abe: 6.861 | eve: 8.997 | bob: 6.926Epoch   8:  56% | abe: 6.859 | eve: 8.997 | bob: 6.924Epoch   8:  57% | abe: 6.858 | eve: 8.997 | bob: 6.922Epoch   8:  57% | abe: 6.856 | eve: 8.997 | bob: 6.921Epoch   8:  58% | abe: 6.855 | eve: 8.997 | bob: 6.919Epoch   8:  59% | abe: 6.853 | eve: 8.998 | bob: 6.917Epoch   8:  60% | abe: 6.851 | eve: 8.997 | bob: 6.915Epoch   8:  60% | abe: 6.849 | eve: 8.997 | bob: 6.913Epoch   8:  61% | abe: 6.847 | eve: 8.997 | bob: 6.911Epoch   8:  62% | abe: 6.845 | eve: 8.998 | bob: 6.909Epoch   8:  63% | abe: 6.844 | eve: 8.998 | bob: 6.908Epoch   8:  64% | abe: 6.842 | eve: 8.998 | bob: 6.906Epoch   8:  64% | abe: 6.840 | eve: 8.998 | bob: 6.904Epoch   8:  65% | abe: 6.838 | eve: 8.998 | bob: 6.902Epoch   8:  66% | abe: 6.837 | eve: 8.998 | bob: 6.901Epoch   8:  67% | abe: 6.835 | eve: 8.998 | bob: 6.898Epoch   8:  67% | abe: 6.833 | eve: 8.997 | bob: 6.896Epoch   8:  68% | abe: 6.831 | eve: 8.997 | bob: 6.894Epoch   8:  69% | abe: 6.830 | eve: 8.997 | bob: 6.893Epoch   8:  70% | abe: 6.827 | eve: 8.997 | bob: 6.891Epoch   8:  71% | abe: 6.825 | eve: 8.997 | bob: 6.889Epoch   8:  71% | abe: 6.824 | eve: 8.998 | bob: 6.887Epoch   8:  72% | abe: 6.822 | eve: 8.997 | bob: 6.885Epoch   8:  73% | abe: 6.820 | eve: 8.997 | bob: 6.883Epoch   8:  74% | abe: 6.818 | eve: 8.997 | bob: 6.881Epoch   8:  75% | abe: 6.817 | eve: 8.997 | bob: 6.880Epoch   8:  75% | abe: 6.815 | eve: 8.998 | bob: 6.878Epoch   8:  76% | abe: 6.813 | eve: 8.998 | bob: 6.876Epoch   8:  77% | abe: 6.811 | eve: 8.998 | bob: 6.874Epoch   8:  78% | abe: 6.809 | eve: 8.998 | bob: 6.872Epoch   8:  78% | abe: 6.807 | eve: 8.998 | bob: 6.870Epoch   8:  79% | abe: 6.805 | eve: 8.998 | bob: 6.868Epoch   8:  80% | abe: 6.804 | eve: 8.998 | bob: 6.866Epoch   8:  81% | abe: 6.802 | eve: 8.998 | bob: 6.865Epoch   8:  82% | abe: 6.800 | eve: 8.998 | bob: 6.863Epoch   8:  82% | abe: 6.798 | eve: 8.998 | bob: 6.861Epoch   8:  83% | abe: 6.796 | eve: 8.998 | bob: 6.859Epoch   8:  84% | abe: 6.794 | eve: 8.998 | bob: 6.857Epoch   8:  85% | abe: 6.793 | eve: 8.998 | bob: 6.855Epoch   8:  85% | abe: 6.791 | eve: 8.998 | bob: 6.854Epoch   8:  86% | abe: 6.789 | eve: 8.998 | bob: 6.852Epoch   8:  87% | abe: 6.787 | eve: 8.998 | bob: 6.850Epoch   8:  88% | abe: 6.785 | eve: 8.998 | bob: 6.848Epoch   8:  89% | abe: 6.784 | eve: 8.998 | bob: 6.846Epoch   8:  89% | abe: 6.782 | eve: 8.998 | bob: 6.845Epoch   8:  90% | abe: 6.781 | eve: 8.998 | bob: 6.843Epoch   8:  91% | abe: 6.779 | eve: 8.999 | bob: 6.841Epoch   8:  92% | abe: 6.777 | eve: 8.999 | bob: 6.839Epoch   8:  92% | abe: 6.775 | eve: 8.999 | bob: 6.837Epoch   8:  93% | abe: 6.773 | eve: 8.999 | bob: 6.835Epoch   8:  94% | abe: 6.772 | eve: 8.999 | bob: 6.834Epoch   8:  95% | abe: 6.770 | eve: 8.999 | bob: 6.832Epoch   8:  96% | abe: 6.769 | eve: 8.999 | bob: 6.831Epoch   8:  96% | abe: 6.767 | eve: 8.999 | bob: 6.829Epoch   8:  97% | abe: 6.765 | eve: 8.999 | bob: 6.827Epoch   8:  98% | abe: 6.764 | eve: 8.999 | bob: 6.825Epoch   8:  99% | abe: 6.762 | eve: 8.999 | bob: 6.824
New best Bob loss 6.823941802547324 at epoch 8
Epoch   9:   0% | abe: 6.551 | eve: 9.002 | bob: 6.615Epoch   9:   0% | abe: 6.540 | eve: 8.998 | bob: 6.598Epoch   9:   1% | abe: 6.547 | eve: 9.003 | bob: 6.605Epoch   9:   2% | abe: 6.544 | eve: 8.987 | bob: 6.603Epoch   9:   3% | abe: 6.543 | eve: 8.987 | bob: 6.600Epoch   9:   3% | abe: 6.532 | eve: 8.981 | bob: 6.591Epoch   9:   4% | abe: 6.523 | eve: 8.985 | bob: 6.583Epoch   9:   5% | abe: 6.521 | eve: 8.985 | bob: 6.580Epoch   9:   6% | abe: 6.520 | eve: 8.988 | bob: 6.579Epoch   9:   7% | abe: 6.519 | eve: 8.991 | bob: 6.577Epoch   9:   7% | abe: 6.518 | eve: 8.994 | bob: 6.576Epoch   9:   8% | abe: 6.518 | eve: 8.991 | bob: 6.576Epoch   9:   9% | abe: 6.518 | eve: 8.992 | bob: 6.577Epoch   9:  10% | abe: 6.516 | eve: 8.993 | bob: 6.575Epoch   9:  10% | abe: 6.515 | eve: 8.994 | bob: 6.574Epoch   9:  11% | abe: 6.512 | eve: 8.993 | bob: 6.571Epoch   9:  12% | abe: 6.511 | eve: 8.993 | bob: 6.570Epoch   9:  13% | abe: 6.510 | eve: 8.993 | bob: 6.570Epoch   9:  14% | abe: 6.510 | eve: 8.993 | bob: 6.570Epoch   9:  14% | abe: 6.507 | eve: 8.993 | bob: 6.567Epoch   9:  15% | abe: 6.507 | eve: 8.993 | bob: 6.566Epoch   9:  16% | abe: 6.505 | eve: 8.996 | bob: 6.564Epoch   9:  17% | abe: 6.503 | eve: 8.996 | bob: 6.562Epoch   9:  17% | abe: 6.502 | eve: 8.996 | bob: 6.561Epoch   9:  18% | abe: 6.498 | eve: 8.998 | bob: 6.558Epoch   9:  19% | abe: 6.497 | eve: 8.998 | bob: 6.558Epoch   9:  20% | abe: 6.495 | eve: 8.998 | bob: 6.555Epoch   9:  21% | abe: 6.494 | eve: 8.998 | bob: 6.554Epoch   9:  21% | abe: 6.491 | eve: 8.998 | bob: 6.551Epoch   9:  22% | abe: 6.490 | eve: 8.997 | bob: 6.549Epoch   9:  23% | abe: 6.488 | eve: 8.998 | bob: 6.548Epoch   9:  24% | abe: 6.487 | eve: 8.998 | bob: 6.546Epoch   9:  25% | abe: 6.485 | eve: 8.999 | bob: 6.545Epoch   9:  25% | abe: 6.483 | eve: 8.998 | bob: 6.543Epoch   9:  26% | abe: 6.482 | eve: 8.999 | bob: 6.542Epoch   9:  27% | abe: 6.480 | eve: 8.998 | bob: 6.540Epoch   9:  28% | abe: 6.478 | eve: 8.999 | bob: 6.538Epoch   9:  28% | abe: 6.477 | eve: 9.000 | bob: 6.536Epoch   9:  29% | abe: 6.477 | eve: 9.000 | bob: 6.535Epoch   9:  30% | abe: 6.475 | eve: 8.999 | bob: 6.533Epoch   9:  31% | abe: 6.473 | eve: 8.999 | bob: 6.532Epoch   9:  32% | abe: 6.472 | eve: 8.998 | bob: 6.530Epoch   9:  32% | abe: 6.470 | eve: 9.000 | bob: 6.528Epoch   9:  33% | abe: 6.467 | eve: 8.999 | bob: 6.526Epoch   9:  34% | abe: 6.465 | eve: 8.998 | bob: 6.524Epoch   9:  35% | abe: 6.464 | eve: 8.997 | bob: 6.522Epoch   9:  35% | abe: 6.462 | eve: 8.997 | bob: 6.520Epoch   9:  36% | abe: 6.460 | eve: 8.997 | bob: 6.518Epoch   9:  37% | abe: 6.459 | eve: 8.996 | bob: 6.517Epoch   9:  38% | abe: 6.457 | eve: 8.997 | bob: 6.515Epoch   9:  39% | abe: 6.456 | eve: 8.996 | bob: 6.514Epoch   9:  39% | abe: 6.454 | eve: 8.996 | bob: 6.512Epoch   9:  40% | abe: 6.453 | eve: 8.997 | bob: 6.510Epoch   9:  41% | abe: 6.452 | eve: 8.996 | bob: 6.509Epoch   9:  42% | abe: 6.450 | eve: 8.997 | bob: 6.508Epoch   9:  42% | abe: 6.448 | eve: 8.996 | bob: 6.506Epoch   9:  43% | abe: 6.447 | eve: 8.996 | bob: 6.504Epoch   9:  44% | abe: 6.446 | eve: 8.996 | bob: 6.503Epoch   9:  45% | abe: 6.444 | eve: 8.997 | bob: 6.501Epoch   9:  46% | abe: 6.443 | eve: 8.997 | bob: 6.500Epoch   9:  46% | abe: 6.441 | eve: 8.997 | bob: 6.498Epoch   9:  47% | abe: 6.440 | eve: 8.996 | bob: 6.497Epoch   9:  48% | abe: 6.438 | eve: 8.996 | bob: 6.495Epoch   9:  49% | abe: 6.436 | eve: 8.996 | bob: 6.493Epoch   9:  50% | abe: 6.434 | eve: 8.995 | bob: 6.491Epoch   9:  50% | abe: 6.433 | eve: 8.996 | bob: 6.489Epoch   9:  51% | abe: 6.431 | eve: 8.996 | bob: 6.488Epoch   9:  52% | abe: 6.429 | eve: 8.996 | bob: 6.486Epoch   9:  53% | abe: 6.428 | eve: 8.996 | bob: 6.484Epoch   9:  53% | abe: 6.426 | eve: 8.997 | bob: 6.482Epoch   9:  54% | abe: 6.424 | eve: 8.997 | bob: 6.480Epoch   9:  55% | abe: 6.423 | eve: 8.997 | bob: 6.479Epoch   9:  56% | abe: 6.421 | eve: 8.997 | bob: 6.477Epoch   9:  57% | abe: 6.419 | eve: 8.998 | bob: 6.475Epoch   9:  57% | abe: 6.417 | eve: 8.997 | bob: 6.473Epoch   9:  58% | abe: 6.415 | eve: 8.998 | bob: 6.471Epoch   9:  59% | abe: 6.414 | eve: 8.998 | bob: 6.470Epoch   9:  60% | abe: 6.412 | eve: 8.998 | bob: 6.468Epoch   9:  60% | abe: 6.411 | eve: 8.998 | bob: 6.466Epoch   9:  61% | abe: 6.409 | eve: 8.998 | bob: 6.465Epoch   9:  62% | abe: 6.408 | eve: 8.998 | bob: 6.463Epoch   9:  63% | abe: 6.406 | eve: 8.998 | bob: 6.461Epoch   9:  64% | abe: 6.404 | eve: 8.998 | bob: 6.460Epoch   9:  64% | abe: 6.403 | eve: 8.998 | bob: 6.458Epoch   9:  65% | abe: 6.401 | eve: 8.999 | bob: 6.456Epoch   9:  66% | abe: 6.400 | eve: 8.999 | bob: 6.455Epoch   9:  67% | abe: 6.398 | eve: 8.999 | bob: 6.453Epoch   9:  67% | abe: 6.396 | eve: 8.999 | bob: 6.451Epoch   9:  68% | abe: 6.395 | eve: 9.000 | bob: 6.450Epoch   9:  69% | abe: 6.393 | eve: 9.000 | bob: 6.448Epoch   9:  70% | abe: 6.392 | eve: 9.000 | bob: 6.447Epoch   9:  71% | abe: 6.390 | eve: 9.000 | bob: 6.445Epoch   9:  71% | abe: 6.389 | eve: 9.000 | bob: 6.443Epoch   9:  72% | abe: 6.387 | eve: 9.000 | bob: 6.442Epoch   9:  73% | abe: 6.386 | eve: 9.000 | bob: 6.440Epoch   9:  74% | abe: 6.384 | eve: 9.000 | bob: 6.439Epoch   9:  75% | abe: 6.382 | eve: 9.000 | bob: 6.437Epoch   9:  75% | abe: 6.381 | eve: 9.000 | bob: 6.436Epoch   9:  76% | abe: 6.379 | eve: 9.000 | bob: 6.434Epoch   9:  77% | abe: 6.378 | eve: 9.001 | bob: 6.432Epoch   9:  78% | abe: 6.376 | eve: 9.001 | bob: 6.431Epoch   9:  78% | abe: 6.375 | eve: 9.001 | bob: 6.429Epoch   9:  79% | abe: 6.373 | eve: 9.001 | bob: 6.427Epoch   9:  80% | abe: 6.372 | eve: 9.001 | bob: 6.426Epoch   9:  81% | abe: 6.370 | eve: 9.000 | bob: 6.424Epoch   9:  82% | abe: 6.368 | eve: 9.000 | bob: 6.422Epoch   9:  82% | abe: 6.366 | eve: 9.000 | bob: 6.420Epoch   9:  83% | abe: 6.365 | eve: 9.000 | bob: 6.419Epoch   9:  84% | abe: 6.363 | eve: 9.000 | bob: 6.417Epoch   9:  85% | abe: 6.362 | eve: 9.000 | bob: 6.415Epoch   9:  85% | abe: 6.360 | eve: 9.000 | bob: 6.414Epoch   9:  86% | abe: 6.358 | eve: 9.000 | bob: 6.412Epoch   9:  87% | abe: 6.357 | eve: 9.000 | bob: 6.410Epoch   9:  88% | abe: 6.356 | eve: 8.999 | bob: 6.409Epoch   9:  89% | abe: 6.354 | eve: 8.999 | bob: 6.408Epoch   9:  89% | abe: 6.353 | eve: 8.999 | bob: 6.406Epoch   9:  90% | abe: 6.351 | eve: 8.999 | bob: 6.405Epoch   9:  91% | abe: 6.349 | eve: 8.999 | bob: 6.403Epoch   9:  92% | abe: 6.348 | eve: 8.999 | bob: 6.401Epoch   9:  92% | abe: 6.346 | eve: 8.999 | bob: 6.399Epoch   9:  93% | abe: 6.345 | eve: 8.999 | bob: 6.398Epoch   9:  94% | abe: 6.343 | eve: 8.999 | bob: 6.396Epoch   9:  95% | abe: 6.342 | eve: 8.999 | bob: 6.395Epoch   9:  96% | abe: 6.340 | eve: 8.998 | bob: 6.393Epoch   9:  96% | abe: 6.339 | eve: 8.998 | bob: 6.392Epoch   9:  97% | abe: 6.337 | eve: 8.998 | bob: 6.390Epoch   9:  98% | abe: 6.336 | eve: 8.999 | bob: 6.389Epoch   9:  99% | abe: 6.335 | eve: 8.998 | bob: 6.387
New best Bob loss 6.3874571573132926 at epoch 9
Epoch  10:   0% | abe: 6.134 | eve: 9.028 | bob: 6.191Epoch  10:   0% | abe: 6.140 | eve: 9.014 | bob: 6.187Epoch  10:   1% | abe: 6.137 | eve: 9.012 | bob: 6.179Epoch  10:   2% | abe: 6.135 | eve: 9.005 | bob: 6.177Epoch  10:   3% | abe: 6.136 | eve: 9.004 | bob: 6.178Epoch  10:   3% | abe: 6.132 | eve: 8.999 | bob: 6.177Epoch  10:   4% | abe: 6.128 | eve: 8.998 | bob: 6.172Epoch  10:   5% | abe: 6.132 | eve: 9.002 | bob: 6.176Epoch  10:   6% | abe: 6.127 | eve: 9.004 | bob: 6.170Epoch  10:   7% | abe: 6.125 | eve: 9.007 | bob: 6.168Epoch  10:   7% | abe: 6.126 | eve: 9.004 | bob: 6.170Epoch  10:   8% | abe: 6.125 | eve: 9.005 | bob: 6.170Epoch  10:   9% | abe: 6.123 | eve: 9.006 | bob: 6.167Epoch  10:  10% | abe: 6.122 | eve: 9.005 | bob: 6.166Epoch  10:  10% | abe: 6.120 | eve: 9.003 | bob: 6.163Epoch  10:  11% | abe: 6.117 | eve: 9.004 | bob: 6.161Epoch  10:  12% | abe: 6.114 | eve: 9.004 | bob: 6.158Epoch  10:  13% | abe: 6.112 | eve: 9.005 | bob: 6.156Epoch  10:  14% | abe: 6.110 | eve: 9.003 | bob: 6.154Epoch  10:  14% | abe: 6.107 | eve: 9.003 | bob: 6.151Epoch  10:  15% | abe: 6.106 | eve: 9.004 | bob: 6.150Epoch  10:  16% | abe: 6.104 | eve: 9.006 | bob: 6.148Epoch  10:  17% | abe: 6.102 | eve: 9.003 | bob: 6.146Epoch  10:  17% | abe: 6.099 | eve: 9.004 | bob: 6.143Epoch  10:  18% | abe: 6.097 | eve: 9.004 | bob: 6.141Epoch  10:  19% | abe: 6.097 | eve: 9.003 | bob: 6.141Epoch  10:  20% | abe: 6.096 | eve: 9.003 | bob: 6.139Epoch  10:  21% | abe: 6.094 | eve: 9.002 | bob: 6.138Epoch  10:  21% | abe: 6.092 | eve: 9.002 | bob: 6.136Epoch  10:  22% | abe: 6.089 | eve: 9.002 | bob: 6.133Epoch  10:  23% | abe: 6.087 | eve: 9.002 | bob: 6.131Epoch  10:  24% | abe: 6.086 | eve: 9.002 | bob: 6.129Epoch  10:  25% | abe: 6.085 | eve: 9.000 | bob: 6.128Epoch  10:  25% | abe: 6.084 | eve: 9.000 | bob: 6.127Epoch  10:  26% | abe: 6.082 | eve: 9.000 | bob: 6.125Epoch  10:  27% | abe: 6.082 | eve: 9.001 | bob: 6.124Epoch  10:  28% | abe: 6.080 | eve: 9.002 | bob: 6.123Epoch  10:  28% | abe: 6.079 | eve: 9.002 | bob: 6.122Epoch  10:  29% | abe: 6.078 | eve: 9.001 | bob: 6.121Epoch  10:  30% | abe: 6.076 | eve: 9.002 | bob: 6.119Epoch  10:  31% | abe: 6.075 | eve: 9.002 | bob: 6.117Epoch  10:  32% | abe: 6.073 | eve: 9.003 | bob: 6.115Epoch  10:  32% | abe: 6.071 | eve: 9.003 | bob: 6.113Epoch  10:  33% | abe: 6.069 | eve: 9.003 | bob: 6.111Epoch  10:  34% | abe: 6.067 | eve: 9.003 | bob: 6.110Epoch  10:  35% | abe: 6.066 | eve: 9.002 | bob: 6.108Epoch  10:  35% | abe: 6.065 | eve: 9.002 | bob: 6.107Epoch  10:  36% | abe: 6.063 | eve: 9.002 | bob: 6.105Epoch  10:  37% | abe: 6.062 | eve: 9.004 | bob: 6.104Epoch  10:  38% | abe: 6.060 | eve: 9.003 | bob: 6.102Epoch  10:  39% | abe: 6.059 | eve: 9.003 | bob: 6.101Epoch  10:  39% | abe: 6.058 | eve: 9.002 | bob: 6.100Epoch  10:  40% | abe: 6.057 | eve: 9.002 | bob: 6.098Epoch  10:  41% | abe: 6.055 | eve: 9.002 | bob: 6.097Epoch  10:  42% | abe: 6.054 | eve: 9.002 | bob: 6.096Epoch  10:  42% | abe: 6.053 | eve: 9.002 | bob: 6.094Epoch  10:  43% | abe: 6.051 | eve: 9.001 | bob: 6.093Epoch  10:  44% | abe: 6.049 | eve: 9.001 | bob: 6.091Epoch  10:  45% | abe: 6.048 | eve: 9.001 | bob: 6.089Epoch  10:  46% | abe: 6.046 | eve: 9.001 | bob: 6.087Epoch  10:  46% | abe: 6.045 | eve: 9.001 | bob: 6.086Epoch  10:  47% | abe: 6.043 | eve: 9.001 | bob: 6.085Epoch  10:  48% | abe: 6.042 | eve: 9.002 | bob: 6.083Epoch  10:  49% | abe: 6.040 | eve: 9.002 | bob: 6.081Epoch  10:  50% | abe: 6.039 | eve: 9.001 | bob: 6.080Epoch  10:  50% | abe: 6.038 | eve: 9.002 | bob: 6.079Epoch  10:  51% | abe: 6.037 | eve: 9.001 | bob: 6.078Epoch  10:  52% | abe: 6.035 | eve: 9.001 | bob: 6.076Epoch  10:  53% | abe: 6.034 | eve: 9.001 | bob: 6.075Epoch  10:  53% | abe: 6.033 | eve: 9.001 | bob: 6.073Epoch  10:  54% | abe: 6.032 | eve: 9.001 | bob: 6.072Epoch  10:  55% | abe: 6.030 | eve: 9.001 | bob: 6.071Epoch  10:  56% | abe: 6.029 | eve: 9.000 | bob: 6.069Epoch  10:  57% | abe: 6.027 | eve: 9.000 | bob: 6.067Epoch  10:  57% | abe: 6.026 | eve: 9.000 | bob: 6.066Epoch  10:  58% | abe: 6.024 | eve: 8.999 | bob: 6.064Epoch  10:  59% | abe: 6.023 | eve: 8.999 | bob: 6.063Epoch  10:  60% | abe: 6.022 | eve: 8.999 | bob: 6.062Epoch  10:  60% | abe: 6.020 | eve: 8.999 | bob: 6.060Epoch  10:  61% | abe: 6.019 | eve: 8.999 | bob: 6.058Epoch  10:  62% | abe: 6.017 | eve: 8.999 | bob: 6.057Epoch  10:  63% | abe: 6.016 | eve: 8.999 | bob: 6.055Epoch  10:  64% | abe: 6.014 | eve: 8.999 | bob: 6.054Epoch  10:  64% | abe: 6.013 | eve: 8.999 | bob: 6.052Epoch  10:  65% | abe: 6.012 | eve: 8.998 | bob: 6.051Epoch  10:  66% | abe: 6.010 | eve: 8.999 | bob: 6.049Epoch  10:  67% | abe: 6.009 | eve: 8.999 | bob: 6.048Epoch  10:  67% | abe: 6.008 | eve: 8.999 | bob: 6.047Epoch  10:  68% | abe: 6.006 | eve: 8.999 | bob: 6.045Epoch  10:  69% | abe: 6.005 | eve: 8.999 | bob: 6.044Epoch  10:  70% | abe: 6.003 | eve: 8.999 | bob: 6.042Epoch  10:  71% | abe: 6.002 | eve: 9.000 | bob: 6.040Epoch  10:  71% | abe: 6.000 | eve: 9.000 | bob: 6.039Epoch  10:  72% | abe: 5.999 | eve: 9.000 | bob: 6.037Epoch  10:  73% | abe: 5.997 | eve: 9.000 | bob: 6.036Epoch  10:  74% | abe: 5.996 | eve: 9.000 | bob: 6.035Epoch  10:  75% | abe: 5.995 | eve: 9.000 | bob: 6.033Epoch  10:  75% | abe: 5.993 | eve: 9.000 | bob: 6.032Epoch  10:  76% | abe: 5.992 | eve: 9.000 | bob: 6.030Epoch  10:  77% | abe: 5.991 | eve: 8.999 | bob: 6.029Epoch  10:  78% | abe: 5.989 | eve: 8.999 | bob: 6.028Epoch  10:  78% | abe: 5.988 | eve: 9.000 | bob: 6.026Epoch  10:  79% | abe: 5.987 | eve: 9.000 | bob: 6.025Epoch  10:  80% | abe: 5.986 | eve: 9.000 | bob: 6.024Epoch  10:  81% | abe: 5.984 | eve: 8.999 | bob: 6.022Epoch  10:  82% | abe: 5.983 | eve: 8.999 | bob: 6.021Epoch  10:  82% | abe: 5.981 | eve: 8.999 | bob: 6.019Epoch  10:  83% | abe: 5.979 | eve: 8.999 | bob: 6.017Epoch  10:  84% | abe: 5.978 | eve: 8.999 | bob: 6.016Epoch  10:  85% | abe: 5.977 | eve: 8.999 | bob: 6.015Epoch  10:  85% | abe: 5.975 | eve: 8.999 | bob: 6.013Epoch  10:  86% | abe: 5.974 | eve: 8.999 | bob: 6.012Epoch  10:  87% | abe: 5.973 | eve: 8.999 | bob: 6.010Epoch  10:  88% | abe: 5.971 | eve: 8.998 | bob: 6.009Epoch  10:  89% | abe: 5.970 | eve: 8.998 | bob: 6.008Epoch  10:  89% | abe: 5.968 | eve: 8.998 | bob: 6.006Epoch  10:  90% | abe: 5.967 | eve: 8.998 | bob: 6.004Epoch  10:  91% | abe: 5.966 | eve: 8.998 | bob: 6.003Epoch  10:  92% | abe: 5.964 | eve: 8.998 | bob: 6.001Epoch  10:  92% | abe: 5.963 | eve: 8.998 | bob: 6.000Epoch  10:  93% | abe: 5.962 | eve: 8.998 | bob: 5.999Epoch  10:  94% | abe: 5.961 | eve: 8.998 | bob: 5.998Epoch  10:  95% | abe: 5.959 | eve: 8.998 | bob: 5.996Epoch  10:  96% | abe: 5.958 | eve: 8.999 | bob: 5.994Epoch  10:  96% | abe: 5.956 | eve: 8.998 | bob: 5.993Epoch  10:  97% | abe: 5.955 | eve: 8.999 | bob: 5.991Epoch  10:  98% | abe: 5.954 | eve: 8.999 | bob: 5.990Epoch  10:  99% | abe: 5.952 | eve: 8.999 | bob: 5.989
New best Bob loss 5.988653088614001 at epoch 10
Epoch  11:   0% | abe: 5.783 | eve: 9.024 | bob: 5.802Epoch  11:   0% | abe: 5.786 | eve: 9.001 | bob: 5.805Epoch  11:   1% | abe: 5.767 | eve: 9.003 | bob: 5.789Epoch  11:   2% | abe: 5.771 | eve: 9.004 | bob: 5.797Epoch  11:   3% | abe: 5.769 | eve: 9.007 | bob: 5.797Epoch  11:   3% | abe: 5.766 | eve: 9.014 | bob: 5.795Epoch  11:   4% | abe: 5.767 | eve: 9.009 | bob: 5.794Epoch  11:   5% | abe: 5.765 | eve: 9.005 | bob: 5.792Epoch  11:   6% | abe: 5.761 | eve: 9.008 | bob: 5.790Epoch  11:   7% | abe: 5.761 | eve: 9.006 | bob: 5.789Epoch  11:   7% | abe: 5.759 | eve: 9.006 | bob: 5.787Epoch  11:   8% | abe: 5.757 | eve: 9.006 | bob: 5.784Epoch  11:   9% | abe: 5.753 | eve: 9.006 | bob: 5.780Epoch  11:  10% | abe: 5.752 | eve: 9.006 | bob: 5.780Epoch  11:  10% | abe: 5.751 | eve: 9.005 | bob: 5.779Epoch  11:  11% | abe: 5.749 | eve: 9.004 | bob: 5.776Epoch  11:  12% | abe: 5.749 | eve: 9.005 | bob: 5.776Epoch  11:  13% | abe: 5.747 | eve: 9.005 | bob: 5.773Epoch  11:  14% | abe: 5.746 | eve: 9.008 | bob: 5.772Epoch  11:  14% | abe: 5.744 | eve: 9.007 | bob: 5.770Epoch  11:  15% | abe: 5.741 | eve: 9.006 | bob: 5.768Epoch  11:  16% | abe: 5.739 | eve: 9.004 | bob: 5.766Epoch  11:  17% | abe: 5.740 | eve: 9.004 | bob: 5.767Epoch  11:  17% | abe: 5.739 | eve: 9.004 | bob: 5.764Epoch  11:  18% | abe: 5.737 | eve: 9.004 | bob: 5.762Epoch  11:  19% | abe: 5.736 | eve: 9.004 | bob: 5.762Epoch  11:  20% | abe: 5.737 | eve: 9.003 | bob: 5.763Epoch  11:  21% | abe: 5.736 | eve: 9.003 | bob: 5.761Epoch  11:  21% | abe: 5.734 | eve: 9.001 | bob: 5.759Epoch  11:  22% | abe: 5.732 | eve: 9.001 | bob: 5.757Epoch  11:  23% | abe: 5.732 | eve: 9.002 | bob: 5.757Epoch  11:  24% | abe: 5.730 | eve: 9.002 | bob: 5.755Epoch  11:  25% | abe: 5.728 | eve: 9.002 | bob: 5.753Epoch  11:  25% | abe: 5.728 | eve: 9.002 | bob: 5.753Epoch  11:  26% | abe: 5.727 | eve: 9.003 | bob: 5.752Epoch  11:  27% | abe: 5.726 | eve: 9.003 | bob: 5.751Epoch  11:  28% | abe: 5.725 | eve: 9.002 | bob: 5.749Epoch  11:  28% | abe: 5.723 | eve: 9.002 | bob: 5.748Epoch  11:  29% | abe: 5.721 | eve: 9.003 | bob: 5.746Epoch  11:  30% | abe: 5.721 | eve: 9.003 | bob: 5.745Epoch  11:  31% | abe: 5.719 | eve: 9.002 | bob: 5.743Epoch  11:  32% | abe: 5.719 | eve: 9.002 | bob: 5.743Epoch  11:  32% | abe: 5.718 | eve: 9.002 | bob: 5.742Epoch  11:  33% | abe: 5.716 | eve: 9.001 | bob: 5.740Epoch  11:  34% | abe: 5.715 | eve: 9.001 | bob: 5.739Epoch  11:  35% | abe: 5.714 | eve: 9.001 | bob: 5.738Epoch  11:  35% | abe: 5.713 | eve: 9.001 | bob: 5.737Epoch  11:  36% | abe: 5.712 | eve: 9.002 | bob: 5.736Epoch  11:  37% | abe: 5.711 | eve: 9.001 | bob: 5.735Epoch  11:  38% | abe: 5.710 | eve: 9.002 | bob: 5.733Epoch  11:  39% | abe: 5.709 | eve: 9.003 | bob: 5.732Epoch  11:  39% | abe: 5.707 | eve: 9.002 | bob: 5.730Epoch  11:  40% | abe: 5.705 | eve: 9.003 | bob: 5.728Epoch  11:  41% | abe: 5.704 | eve: 9.003 | bob: 5.727Epoch  11:  42% | abe: 5.702 | eve: 9.002 | bob: 5.725Epoch  11:  42% | abe: 5.701 | eve: 9.003 | bob: 5.724Epoch  11:  43% | abe: 5.700 | eve: 9.002 | bob: 5.723Epoch  11:  44% | abe: 5.699 | eve: 9.002 | bob: 5.722Epoch  11:  45% | abe: 5.698 | eve: 9.002 | bob: 5.721Epoch  11:  46% | abe: 5.697 | eve: 9.002 | bob: 5.720Epoch  11:  46% | abe: 5.696 | eve: 9.002 | bob: 5.718Epoch  11:  47% | abe: 5.694 | eve: 9.001 | bob: 5.717Epoch  11:  48% | abe: 5.693 | eve: 9.001 | bob: 5.715Epoch  11:  49% | abe: 5.691 | eve: 9.001 | bob: 5.714Epoch  11:  50% | abe: 5.690 | eve: 9.002 | bob: 5.712Epoch  11:  50% | abe: 5.689 | eve: 9.002 | bob: 5.711Epoch  11:  51% | abe: 5.687 | eve: 9.002 | bob: 5.710Epoch  11:  52% | abe: 5.686 | eve: 9.002 | bob: 5.708Epoch  11:  53% | abe: 5.685 | eve: 9.002 | bob: 5.707Epoch  11:  53% | abe: 5.684 | eve: 9.002 | bob: 5.706Epoch  11:  54% | abe: 5.683 | eve: 9.001 | bob: 5.705Epoch  11:  55% | abe: 5.681 | eve: 9.001 | bob: 5.703Epoch  11:  56% | abe: 5.680 | eve: 9.001 | bob: 5.702Epoch  11:  57% | abe: 5.679 | eve: 9.000 | bob: 5.701Epoch  11:  57% | abe: 5.678 | eve: 9.000 | bob: 5.699Epoch  11:  58% | abe: 5.677 | eve: 9.000 | bob: 5.698Epoch  11:  59% | abe: 5.675 | eve: 8.999 | bob: 5.697Epoch  11:  60% | abe: 5.674 | eve: 9.000 | bob: 5.695Epoch  11:  60% | abe: 5.673 | eve: 9.000 | bob: 5.694Epoch  11:  61% | abe: 5.671 | eve: 9.000 | bob: 5.692Epoch  11:  62% | abe: 5.670 | eve: 9.000 | bob: 5.691Epoch  11:  63% | abe: 5.669 | eve: 9.000 | bob: 5.690Epoch  11:  64% | abe: 5.667 | eve: 9.000 | bob: 5.688Epoch  11:  64% | abe: 5.666 | eve: 9.000 | bob: 5.686Epoch  11:  65% | abe: 5.665 | eve: 9.000 | bob: 5.685Epoch  11:  66% | abe: 5.663 | eve: 9.000 | bob: 5.684Epoch  11:  67% | abe: 5.662 | eve: 8.999 | bob: 5.683Epoch  11:  67% | abe: 5.661 | eve: 8.999 | bob: 5.682Epoch  11:  68% | abe: 5.660 | eve: 9.000 | bob: 5.680Epoch  11:  69% | abe: 5.658 | eve: 9.000 | bob: 5.679Epoch  11:  70% | abe: 5.657 | eve: 9.000 | bob: 5.677Epoch  11:  71% | abe: 5.656 | eve: 9.000 | bob: 5.676Epoch  11:  71% | abe: 5.655 | eve: 9.000 | bob: 5.675Epoch  11:  72% | abe: 5.653 | eve: 9.000 | bob: 5.674Epoch  11:  73% | abe: 5.652 | eve: 9.000 | bob: 5.672Epoch  11:  74% | abe: 5.651 | eve: 9.000 | bob: 5.671Epoch  11:  75% | abe: 5.649 | eve: 9.000 | bob: 5.669Epoch  11:  75% | abe: 5.647 | eve: 9.000 | bob: 5.668Epoch  11:  76% | abe: 5.646 | eve: 9.000 | bob: 5.666Epoch  11:  77% | abe: 5.645 | eve: 9.000 | bob: 5.665Epoch  11:  78% | abe: 5.644 | eve: 9.000 | bob: 5.664Epoch  11:  78% | abe: 5.643 | eve: 9.000 | bob: 5.663Epoch  11:  79% | abe: 5.641 | eve: 9.000 | bob: 5.661Epoch  11:  80% | abe: 5.640 | eve: 9.000 | bob: 5.660Epoch  11:  81% | abe: 5.639 | eve: 9.000 | bob: 5.659Epoch  11:  82% | abe: 5.638 | eve: 9.001 | bob: 5.657Epoch  11:  82% | abe: 5.636 | eve: 9.000 | bob: 5.656Epoch  11:  83% | abe: 5.635 | eve: 9.001 | bob: 5.654Epoch  11:  84% | abe: 5.633 | eve: 9.000 | bob: 5.653Epoch  11:  85% | abe: 5.632 | eve: 9.000 | bob: 5.651Epoch  11:  85% | abe: 5.631 | eve: 9.000 | bob: 5.650Epoch  11:  86% | abe: 5.630 | eve: 9.000 | bob: 5.649Epoch  11:  87% | abe: 5.628 | eve: 9.000 | bob: 5.647Epoch  11:  88% | abe: 5.627 | eve: 9.000 | bob: 5.646Epoch  11:  89% | abe: 5.626 | eve: 9.000 | bob: 5.645Epoch  11:  89% | abe: 5.624 | eve: 9.000 | bob: 5.643Epoch  11:  90% | abe: 5.623 | eve: 9.000 | bob: 5.642Epoch  11:  91% | abe: 5.622 | eve: 9.000 | bob: 5.640Epoch  11:  92% | abe: 5.620 | eve: 9.000 | bob: 5.639Epoch  11:  92% | abe: 5.619 | eve: 9.000 | bob: 5.638Epoch  11:  93% | abe: 5.618 | eve: 9.000 | bob: 5.637Epoch  11:  94% | abe: 5.617 | eve: 9.000 | bob: 5.635Epoch  11:  95% | abe: 5.616 | eve: 9.000 | bob: 5.634Epoch  11:  96% | abe: 5.614 | eve: 9.000 | bob: 5.633Epoch  11:  96% | abe: 5.613 | eve: 9.000 | bob: 5.631Epoch  11:  97% | abe: 5.612 | eve: 9.000 | bob: 5.630Epoch  11:  98% | abe: 5.611 | eve: 9.000 | bob: 5.629Epoch  11:  99% | abe: 5.610 | eve: 9.000 | bob: 5.628
New best Bob loss 5.627704955781496 at epoch 11
Epoch  12:   0% | abe: 5.462 | eve: 9.014 | bob: 5.469Epoch  12:   0% | abe: 5.455 | eve: 9.026 | bob: 5.463Epoch  12:   1% | abe: 5.446 | eve: 9.020 | bob: 5.453Epoch  12:   2% | abe: 5.440 | eve: 9.008 | bob: 5.447Epoch  12:   3% | abe: 5.437 | eve: 9.000 | bob: 5.446Epoch  12:   3% | abe: 5.440 | eve: 8.996 | bob: 5.450Epoch  12:   4% | abe: 5.440 | eve: 8.995 | bob: 5.449Epoch  12:   5% | abe: 5.438 | eve: 8.993 | bob: 5.448Epoch  12:   6% | abe: 5.438 | eve: 8.996 | bob: 5.447Epoch  12:   7% | abe: 5.437 | eve: 8.997 | bob: 5.446Epoch  12:   7% | abe: 5.439 | eve: 8.996 | bob: 5.447Epoch  12:   8% | abe: 5.434 | eve: 9.001 | bob: 5.444Epoch  12:   9% | abe: 5.433 | eve: 9.001 | bob: 5.442Epoch  12:  10% | abe: 5.430 | eve: 9.002 | bob: 5.439Epoch  12:  10% | abe: 5.431 | eve: 8.999 | bob: 5.439Epoch  12:  11% | abe: 5.431 | eve: 8.999 | bob: 5.439Epoch  12:  12% | abe: 5.430 | eve: 8.998 | bob: 5.438Epoch  12:  13% | abe: 5.430 | eve: 8.999 | bob: 5.437Epoch  12:  14% | abe: 5.427 | eve: 9.001 | bob: 5.435Epoch  12:  14% | abe: 5.427 | eve: 9.000 | bob: 5.434Epoch  12:  15% | abe: 5.426 | eve: 8.998 | bob: 5.433Epoch  12:  16% | abe: 5.425 | eve: 8.997 | bob: 5.432Epoch  12:  17% | abe: 5.423 | eve: 8.999 | bob: 5.431Epoch  12:  17% | abe: 5.421 | eve: 8.997 | bob: 5.429Epoch  12:  18% | abe: 5.419 | eve: 8.998 | bob: 5.427Epoch  12:  19% | abe: 5.418 | eve: 8.998 | bob: 5.425Epoch  12:  20% | abe: 5.417 | eve: 8.998 | bob: 5.424Epoch  12:  21% | abe: 5.416 | eve: 8.998 | bob: 5.423Epoch  12:  21% | abe: 5.414 | eve: 8.998 | bob: 5.421Epoch  12:  22% | abe: 5.412 | eve: 8.999 | bob: 5.419Epoch  12:  23% | abe: 5.411 | eve: 8.999 | bob: 5.418Epoch  12:  24% | abe: 5.411 | eve: 8.999 | bob: 5.417Epoch  12:  25% | abe: 5.410 | eve: 8.997 | bob: 5.417Epoch  12:  25% | abe: 5.410 | eve: 8.997 | bob: 5.416Epoch  12:  26% | abe: 5.408 | eve: 8.997 | bob: 5.414Epoch  12:  27% | abe: 5.405 | eve: 8.998 | bob: 5.412Epoch  12:  28% | abe: 5.405 | eve: 8.998 | bob: 5.411Epoch  12:  28% | abe: 5.404 | eve: 8.998 | bob: 5.410Epoch  12:  29% | abe: 5.402 | eve: 8.998 | bob: 5.409Epoch  12:  30% | abe: 5.401 | eve: 8.998 | bob: 5.408Epoch  12:  31% | abe: 5.401 | eve: 8.997 | bob: 5.408Epoch  12:  32% | abe: 5.399 | eve: 8.997 | bob: 5.406Epoch  12:  32% | abe: 5.398 | eve: 8.997 | bob: 5.405Epoch  12:  33% | abe: 5.397 | eve: 8.997 | bob: 5.404Epoch  12:  34% | abe: 5.396 | eve: 8.996 | bob: 5.403Epoch  12:  35% | abe: 5.394 | eve: 8.996 | bob: 5.401Epoch  12:  35% | abe: 5.393 | eve: 8.996 | bob: 5.400Epoch  12:  36% | abe: 5.392 | eve: 8.997 | bob: 5.399Epoch  12:  37% | abe: 5.391 | eve: 8.997 | bob: 5.398Epoch  12:  38% | abe: 5.389 | eve: 8.997 | bob: 5.396Epoch  12:  39% | abe: 5.388 | eve: 8.997 | bob: 5.395Epoch  12:  39% | abe: 5.387 | eve: 8.997 | bob: 5.393Epoch  12:  40% | abe: 5.385 | eve: 8.997 | bob: 5.392Epoch  12:  41% | abe: 5.383 | eve: 8.997 | bob: 5.390Epoch  12:  42% | abe: 5.382 | eve: 8.997 | bob: 5.389Epoch  12:  42% | abe: 5.382 | eve: 8.997 | bob: 5.388Epoch  12:  43% | abe: 5.381 | eve: 8.997 | bob: 5.387Epoch  12:  44% | abe: 5.379 | eve: 8.997 | bob: 5.386Epoch  12:  45% | abe: 5.379 | eve: 8.997 | bob: 5.385Epoch  12:  46% | abe: 5.377 | eve: 8.997 | bob: 5.383Epoch  12:  46% | abe: 5.376 | eve: 8.996 | bob: 5.382Epoch  12:  47% | abe: 5.375 | eve: 8.998 | bob: 5.381Epoch  12:  48% | abe: 5.373 | eve: 8.998 | bob: 5.379Epoch  12:  49% | abe: 5.372 | eve: 8.998 | bob: 5.378Epoch  12:  50% | abe: 5.370 | eve: 8.998 | bob: 5.376Epoch  12:  50% | abe: 5.369 | eve: 8.997 | bob: 5.375Epoch  12:  51% | abe: 5.368 | eve: 8.997 | bob: 5.374Epoch  12:  52% | abe: 5.368 | eve: 8.997 | bob: 5.373Epoch  12:  53% | abe: 5.367 | eve: 8.997 | bob: 5.372Epoch  12:  53% | abe: 5.365 | eve: 8.997 | bob: 5.371Epoch  12:  54% | abe: 5.364 | eve: 8.997 | bob: 5.369Epoch  12:  55% | abe: 5.363 | eve: 8.997 | bob: 5.368Epoch  12:  56% | abe: 5.361 | eve: 8.997 | bob: 5.367Epoch  12:  57% | abe: 5.360 | eve: 8.996 | bob: 5.365Epoch  12:  57% | abe: 5.359 | eve: 8.996 | bob: 5.364Epoch  12:  58% | abe: 5.358 | eve: 8.996 | bob: 5.363Epoch  12:  59% | abe: 5.357 | eve: 8.996 | bob: 5.362Epoch  12:  60% | abe: 5.356 | eve: 8.996 | bob: 5.361Epoch  12:  60% | abe: 5.355 | eve: 8.996 | bob: 5.360Epoch  12:  61% | abe: 5.354 | eve: 8.996 | bob: 5.359Epoch  12:  62% | abe: 5.353 | eve: 8.996 | bob: 5.358Epoch  12:  63% | abe: 5.352 | eve: 8.996 | bob: 5.357Epoch  12:  64% | abe: 5.350 | eve: 8.996 | bob: 5.355Epoch  12:  64% | abe: 5.349 | eve: 8.996 | bob: 5.354Epoch  12:  65% | abe: 5.348 | eve: 8.996 | bob: 5.353Epoch  12:  66% | abe: 5.347 | eve: 8.996 | bob: 5.351Epoch  12:  67% | abe: 5.345 | eve: 8.996 | bob: 5.350Epoch  12:  67% | abe: 5.344 | eve: 8.996 | bob: 5.349Epoch  12:  68% | abe: 5.343 | eve: 8.997 | bob: 5.347Epoch  12:  69% | abe: 5.342 | eve: 8.997 | bob: 5.346Epoch  12:  70% | abe: 5.341 | eve: 8.998 | bob: 5.345Epoch  12:  71% | abe: 5.339 | eve: 8.997 | bob: 5.344Epoch  12:  71% | abe: 5.338 | eve: 8.997 | bob: 5.342Epoch  12:  72% | abe: 5.337 | eve: 8.997 | bob: 5.341Epoch  12:  73% | abe: 5.336 | eve: 8.997 | bob: 5.340Epoch  12:  74% | abe: 5.334 | eve: 8.997 | bob: 5.339Epoch  12:  75% | abe: 5.333 | eve: 8.997 | bob: 5.337Epoch  12:  75% | abe: 5.332 | eve: 8.997 | bob: 5.336Epoch  12:  76% | abe: 5.331 | eve: 8.996 | bob: 5.335Epoch  12:  77% | abe: 5.330 | eve: 8.996 | bob: 5.334Epoch  12:  78% | abe: 5.329 | eve: 8.996 | bob: 5.333Epoch  12:  78% | abe: 5.328 | eve: 8.996 | bob: 5.332Epoch  12:  79% | abe: 5.327 | eve: 8.996 | bob: 5.330Epoch  12:  80% | abe: 5.325 | eve: 8.996 | bob: 5.329Epoch  12:  81% | abe: 5.324 | eve: 8.996 | bob: 5.328Epoch  12:  82% | abe: 5.323 | eve: 8.995 | bob: 5.326Epoch  12:  82% | abe: 5.322 | eve: 8.995 | bob: 5.325Epoch  12:  83% | abe: 5.320 | eve: 8.996 | bob: 5.324Epoch  12:  84% | abe: 5.319 | eve: 8.996 | bob: 5.322Epoch  12:  85% | abe: 5.318 | eve: 8.996 | bob: 5.321Epoch  12:  85% | abe: 5.317 | eve: 8.996 | bob: 5.320Epoch  12:  86% | abe: 5.316 | eve: 8.997 | bob: 5.319Epoch  12:  87% | abe: 5.314 | eve: 8.997 | bob: 5.317Epoch  12:  88% | abe: 5.313 | eve: 8.997 | bob: 5.316Epoch  12:  89% | abe: 5.312 | eve: 8.997 | bob: 5.315Epoch  12:  89% | abe: 5.311 | eve: 8.998 | bob: 5.314Epoch  12:  90% | abe: 5.310 | eve: 8.998 | bob: 5.313Epoch  12:  91% | abe: 5.309 | eve: 8.998 | bob: 5.312Epoch  12:  92% | abe: 5.307 | eve: 8.998 | bob: 5.310Epoch  12:  92% | abe: 5.306 | eve: 8.999 | bob: 5.309Epoch  12:  93% | abe: 5.305 | eve: 8.999 | bob: 5.307Epoch  12:  94% | abe: 5.304 | eve: 8.999 | bob: 5.306Epoch  12:  95% | abe: 5.302 | eve: 8.999 | bob: 5.305Epoch  12:  96% | abe: 5.301 | eve: 8.999 | bob: 5.303Epoch  12:  96% | abe: 5.300 | eve: 8.999 | bob: 5.302Epoch  12:  97% | abe: 5.299 | eve: 8.998 | bob: 5.301Epoch  12:  98% | abe: 5.298 | eve: 8.998 | bob: 5.300Epoch  12:  99% | abe: 5.297 | eve: 8.998 | bob: 5.299
New best Bob loss 5.298828570469482 at epoch 12
Epoch  13:   0% | abe: 5.170 | eve: 8.944 | bob: 5.167Epoch  13:   0% | abe: 5.165 | eve: 8.971 | bob: 5.161Epoch  13:   1% | abe: 5.167 | eve: 8.968 | bob: 5.164Epoch  13:   2% | abe: 5.159 | eve: 8.965 | bob: 5.154Epoch  13:   3% | abe: 5.154 | eve: 8.967 | bob: 5.148Epoch  13:   3% | abe: 5.147 | eve: 8.974 | bob: 5.141Epoch  13:   4% | abe: 5.148 | eve: 8.980 | bob: 5.142Epoch  13:   5% | abe: 5.145 | eve: 8.983 | bob: 5.140Epoch  13:   6% | abe: 5.144 | eve: 8.981 | bob: 5.138Epoch  13:   7% | abe: 5.140 | eve: 8.981 | bob: 5.133Epoch  13:   7% | abe: 5.141 | eve: 8.983 | bob: 5.134Epoch  13:   8% | abe: 5.141 | eve: 8.986 | bob: 5.135Epoch  13:   9% | abe: 5.139 | eve: 8.990 | bob: 5.133Epoch  13:  10% | abe: 5.137 | eve: 8.991 | bob: 5.131Epoch  13:  10% | abe: 5.134 | eve: 8.990 | bob: 5.129Epoch  13:  11% | abe: 5.134 | eve: 8.992 | bob: 5.128Epoch  13:  12% | abe: 5.132 | eve: 8.991 | bob: 5.126Epoch  13:  13% | abe: 5.131 | eve: 8.994 | bob: 5.126Epoch  13:  14% | abe: 5.129 | eve: 8.992 | bob: 5.123Epoch  13:  14% | abe: 5.127 | eve: 8.993 | bob: 5.120Epoch  13:  15% | abe: 5.126 | eve: 8.993 | bob: 5.119Epoch  13:  16% | abe: 5.125 | eve: 8.995 | bob: 5.118Epoch  13:  17% | abe: 5.123 | eve: 8.995 | bob: 5.116Epoch  13:  17% | abe: 5.122 | eve: 8.995 | bob: 5.115Epoch  13:  18% | abe: 5.122 | eve: 8.996 | bob: 5.115Epoch  13:  19% | abe: 5.121 | eve: 8.996 | bob: 5.114Epoch  13:  20% | abe: 5.120 | eve: 8.997 | bob: 5.113Epoch  13:  21% | abe: 5.119 | eve: 8.998 | bob: 5.111Epoch  13:  21% | abe: 5.118 | eve: 8.998 | bob: 5.110Epoch  13:  22% | abe: 5.115 | eve: 8.998 | bob: 5.108Epoch  13:  23% | abe: 5.115 | eve: 8.997 | bob: 5.107Epoch  13:  24% | abe: 5.113 | eve: 8.997 | bob: 5.106Epoch  13:  25% | abe: 5.112 | eve: 8.996 | bob: 5.105Epoch  13:  25% | abe: 5.111 | eve: 8.995 | bob: 5.104Epoch  13:  26% | abe: 5.110 | eve: 8.995 | bob: 5.103Epoch  13:  27% | abe: 5.110 | eve: 8.996 | bob: 5.102Epoch  13:  28% | abe: 5.109 | eve: 8.995 | bob: 5.101Epoch  13:  28% | abe: 5.108 | eve: 8.996 | bob: 5.101Epoch  13:  29% | abe: 5.107 | eve: 8.996 | bob: 5.100Epoch  13:  30% | abe: 5.106 | eve: 8.996 | bob: 5.099Epoch  13:  31% | abe: 5.106 | eve: 8.996 | bob: 5.098Epoch  13:  32% | abe: 5.105 | eve: 8.996 | bob: 5.098Epoch  13:  32% | abe: 5.104 | eve: 8.997 | bob: 5.096Epoch  13:  33% | abe: 5.103 | eve: 8.997 | bob: 5.095Epoch  13:  34% | abe: 5.101 | eve: 8.997 | bob: 5.094Epoch  13:  35% | abe: 5.101 | eve: 8.998 | bob: 5.094Epoch  13:  35% | abe: 5.100 | eve: 8.999 | bob: 5.093Epoch  13:  36% | abe: 5.099 | eve: 8.999 | bob: 5.092Epoch  13:  37% | abe: 5.098 | eve: 9.000 | bob: 5.091Epoch  13:  38% | abe: 5.097 | eve: 9.000 | bob: 5.090Epoch  13:  39% | abe: 5.096 | eve: 9.001 | bob: 5.089Epoch  13:  39% | abe: 5.094 | eve: 9.000 | bob: 5.087Epoch  13:  40% | abe: 5.093 | eve: 9.000 | bob: 5.086Epoch  13:  41% | abe: 5.092 | eve: 9.001 | bob: 5.085Epoch  13:  42% | abe: 5.091 | eve: 9.001 | bob: 5.084Epoch  13:  42% | abe: 5.090 | eve: 9.002 | bob: 5.083Epoch  13:  43% | abe: 5.089 | eve: 9.002 | bob: 5.082Epoch  13:  44% | abe: 5.088 | eve: 9.002 | bob: 5.081Epoch  13:  45% | abe: 5.088 | eve: 9.001 | bob: 5.080Epoch  13:  46% | abe: 5.087 | eve: 9.001 | bob: 5.079Epoch  13:  46% | abe: 5.086 | eve: 9.001 | bob: 5.078Epoch  13:  47% | abe: 5.085 | eve: 9.001 | bob: 5.077Epoch  13:  48% | abe: 5.084 | eve: 9.001 | bob: 5.076Epoch  13:  49% | abe: 5.083 | eve: 9.001 | bob: 5.075Epoch  13:  50% | abe: 5.082 | eve: 9.001 | bob: 5.074Epoch  13:  50% | abe: 5.081 | eve: 9.001 | bob: 5.073Epoch  13:  51% | abe: 5.080 | eve: 9.001 | bob: 5.072Epoch  13:  52% | abe: 5.079 | eve: 9.000 | bob: 5.071Epoch  13:  53% | abe: 5.078 | eve: 9.000 | bob: 5.070Epoch  13:  53% | abe: 5.077 | eve: 9.000 | bob: 5.068Epoch  13:  54% | abe: 5.075 | eve: 9.000 | bob: 5.067Epoch  13:  55% | abe: 5.075 | eve: 9.000 | bob: 5.066Epoch  13:  56% | abe: 5.073 | eve: 9.000 | bob: 5.065Epoch  13:  57% | abe: 5.072 | eve: 9.000 | bob: 5.064Epoch  13:  57% | abe: 5.071 | eve: 9.000 | bob: 5.062Epoch  13:  58% | abe: 5.070 | eve: 9.000 | bob: 5.061Epoch  13:  59% | abe: 5.069 | eve: 9.000 | bob: 5.060Epoch  13:  60% | abe: 5.068 | eve: 9.000 | bob: 5.060Epoch  13:  60% | abe: 5.067 | eve: 9.000 | bob: 5.058Epoch  13:  61% | abe: 5.066 | eve: 9.000 | bob: 5.057Epoch  13:  62% | abe: 5.065 | eve: 9.000 | bob: 5.056Epoch  13:  63% | abe: 5.064 | eve: 9.000 | bob: 5.055Epoch  13:  64% | abe: 5.063 | eve: 9.000 | bob: 5.054Epoch  13:  64% | abe: 5.062 | eve: 9.000 | bob: 5.053Epoch  13:  65% | abe: 5.061 | eve: 9.000 | bob: 5.052Epoch  13:  66% | abe: 5.060 | eve: 8.999 | bob: 5.051Epoch  13:  67% | abe: 5.059 | eve: 8.999 | bob: 5.050Epoch  13:  67% | abe: 5.058 | eve: 8.999 | bob: 5.048Epoch  13:  68% | abe: 5.057 | eve: 8.999 | bob: 5.048Epoch  13:  69% | abe: 5.056 | eve: 8.999 | bob: 5.046Epoch  13:  70% | abe: 5.055 | eve: 8.999 | bob: 5.045Epoch  13:  71% | abe: 5.054 | eve: 8.999 | bob: 5.044Epoch  13:  71% | abe: 5.053 | eve: 9.000 | bob: 5.043Epoch  13:  72% | abe: 5.052 | eve: 9.000 | bob: 5.042Epoch  13:  73% | abe: 5.051 | eve: 9.000 | bob: 5.041Epoch  13:  74% | abe: 5.050 | eve: 8.999 | bob: 5.040Epoch  13:  75% | abe: 5.049 | eve: 8.999 | bob: 5.039Epoch  13:  75% | abe: 5.048 | eve: 8.999 | bob: 5.037Epoch  13:  76% | abe: 5.047 | eve: 9.000 | bob: 5.037Epoch  13:  77% | abe: 5.045 | eve: 9.000 | bob: 5.035Epoch  13:  78% | abe: 5.044 | eve: 9.000 | bob: 5.034Epoch  13:  78% | abe: 5.043 | eve: 9.000 | bob: 5.033Epoch  13:  79% | abe: 5.042 | eve: 9.000 | bob: 5.032Epoch  13:  80% | abe: 5.041 | eve: 9.000 | bob: 5.031Epoch  13:  81% | abe: 5.040 | eve: 9.000 | bob: 5.030Epoch  13:  82% | abe: 5.040 | eve: 9.000 | bob: 5.029Epoch  13:  82% | abe: 5.039 | eve: 9.000 | bob: 5.028Epoch  13:  83% | abe: 5.037 | eve: 9.000 | bob: 5.027Epoch  13:  84% | abe: 5.036 | eve: 9.000 | bob: 5.026Epoch  13:  85% | abe: 5.036 | eve: 9.000 | bob: 5.025Epoch  13:  85% | abe: 5.035 | eve: 9.000 | bob: 5.024Epoch  13:  86% | abe: 5.034 | eve: 9.000 | bob: 5.023Epoch  13:  87% | abe: 5.033 | eve: 9.000 | bob: 5.022Epoch  13:  88% | abe: 5.032 | eve: 9.000 | bob: 5.021Epoch  13:  89% | abe: 5.031 | eve: 9.000 | bob: 5.020Epoch  13:  89% | abe: 5.030 | eve: 9.000 | bob: 5.018Epoch  13:  90% | abe: 5.028 | eve: 9.000 | bob: 5.017Epoch  13:  91% | abe: 5.027 | eve: 9.000 | bob: 5.016Epoch  13:  92% | abe: 5.026 | eve: 9.000 | bob: 5.015Epoch  13:  92% | abe: 5.025 | eve: 9.000 | bob: 5.014Epoch  13:  93% | abe: 5.024 | eve: 9.000 | bob: 5.013Epoch  13:  94% | abe: 5.023 | eve: 9.000 | bob: 5.012Epoch  13:  95% | abe: 5.022 | eve: 8.999 | bob: 5.010Epoch  13:  96% | abe: 5.021 | eve: 8.999 | bob: 5.009Epoch  13:  96% | abe: 5.020 | eve: 8.999 | bob: 5.008Epoch  13:  97% | abe: 5.019 | eve: 8.999 | bob: 5.007Epoch  13:  98% | abe: 5.018 | eve: 8.999 | bob: 5.006Epoch  13:  99% | abe: 5.017 | eve: 8.999 | bob: 5.005
New best Bob loss 5.0049815824897905 at epoch 13
Epoch  14:   0% | abe: 4.864 | eve: 8.968 | bob: 4.843Epoch  14:   0% | abe: 4.876 | eve: 9.006 | bob: 4.854Epoch  14:   1% | abe: 4.876 | eve: 9.007 | bob: 4.854Epoch  14:   2% | abe: 4.876 | eve: 9.003 | bob: 4.855Epoch  14:   3% | abe: 4.882 | eve: 8.999 | bob: 4.861Epoch  14:   3% | abe: 4.884 | eve: 8.998 | bob: 4.863Epoch  14:   4% | abe: 4.883 | eve: 8.995 | bob: 4.862Epoch  14:   5% | abe: 4.884 | eve: 8.994 | bob: 4.862Epoch  14:   6% | abe: 4.881 | eve: 8.994 | bob: 4.860Epoch  14:   7% | abe: 4.880 | eve: 8.994 | bob: 4.859Epoch  14:   7% | abe: 4.880 | eve: 8.992 | bob: 4.859Epoch  14:   8% | abe: 4.880 | eve: 8.991 | bob: 4.859Epoch  14:   9% | abe: 4.877 | eve: 8.995 | bob: 4.856Epoch  14:  10% | abe: 4.876 | eve: 8.990 | bob: 4.855Epoch  14:  10% | abe: 4.875 | eve: 8.994 | bob: 4.855Epoch  14:  11% | abe: 4.875 | eve: 8.991 | bob: 4.854Epoch  14:  12% | abe: 4.874 | eve: 8.988 | bob: 4.853Epoch  14:  13% | abe: 4.875 | eve: 8.990 | bob: 4.853Epoch  14:  14% | abe: 4.874 | eve: 8.990 | bob: 4.853Epoch  14:  14% | abe: 4.872 | eve: 8.988 | bob: 4.851Epoch  14:  15% | abe: 4.872 | eve: 8.990 | bob: 4.851Epoch  14:  16% | abe: 4.870 | eve: 8.991 | bob: 4.849Epoch  14:  17% | abe: 4.869 | eve: 8.991 | bob: 4.848Epoch  14:  17% | abe: 4.868 | eve: 8.993 | bob: 4.847Epoch  14:  18% | abe: 4.867 | eve: 8.991 | bob: 4.846Epoch  14:  19% | abe: 4.867 | eve: 8.990 | bob: 4.846Epoch  14:  20% | abe: 4.866 | eve: 8.992 | bob: 4.845Epoch  14:  21% | abe: 4.863 | eve: 8.992 | bob: 4.842Epoch  14:  21% | abe: 4.863 | eve: 8.992 | bob: 4.841Epoch  14:  22% | abe: 4.861 | eve: 8.991 | bob: 4.840Epoch  14:  23% | abe: 4.861 | eve: 8.991 | bob: 4.840Epoch  14:  24% | abe: 4.859 | eve: 8.990 | bob: 4.838Epoch  14:  25% | abe: 4.858 | eve: 8.990 | bob: 4.837Epoch  14:  25% | abe: 4.857 | eve: 8.992 | bob: 4.836Epoch  14:  26% | abe: 4.856 | eve: 8.992 | bob: 4.835Epoch  14:  27% | abe: 4.855 | eve: 8.993 | bob: 4.834Epoch  14:  28% | abe: 4.855 | eve: 8.993 | bob: 4.834Epoch  14:  28% | abe: 4.855 | eve: 8.992 | bob: 4.834Epoch  14:  29% | abe: 4.854 | eve: 8.992 | bob: 4.833Epoch  14:  30% | abe: 4.852 | eve: 8.993 | bob: 4.832Epoch  14:  31% | abe: 4.852 | eve: 8.993 | bob: 4.831Epoch  14:  32% | abe: 4.851 | eve: 8.993 | bob: 4.831Epoch  14:  32% | abe: 4.851 | eve: 8.994 | bob: 4.830Epoch  14:  33% | abe: 4.850 | eve: 8.994 | bob: 4.828Epoch  14:  34% | abe: 4.848 | eve: 8.994 | bob: 4.827Epoch  14:  35% | abe: 4.847 | eve: 8.995 | bob: 4.826Epoch  14:  35% | abe: 4.846 | eve: 8.995 | bob: 4.825Epoch  14:  36% | abe: 4.846 | eve: 8.995 | bob: 4.825Epoch  14:  37% | abe: 4.845 | eve: 8.994 | bob: 4.823Epoch  14:  38% | abe: 4.843 | eve: 8.995 | bob: 4.822Epoch  14:  39% | abe: 4.842 | eve: 8.995 | bob: 4.821Epoch  14:  39% | abe: 4.840 | eve: 8.994 | bob: 4.819Epoch  14:  40% | abe: 4.839 | eve: 8.994 | bob: 4.818Epoch  14:  41% | abe: 4.838 | eve: 8.994 | bob: 4.817Epoch  14:  42% | abe: 4.838 | eve: 8.994 | bob: 4.816Epoch  14:  42% | abe: 4.837 | eve: 8.994 | bob: 4.815Epoch  14:  43% | abe: 4.836 | eve: 8.995 | bob: 4.814Epoch  14:  44% | abe: 4.835 | eve: 8.995 | bob: 4.813Epoch  14:  45% | abe: 4.834 | eve: 8.994 | bob: 4.812Epoch  14:  46% | abe: 4.833 | eve: 8.994 | bob: 4.811Epoch  14:  46% | abe: 4.832 | eve: 8.995 | bob: 4.810Epoch  14:  47% | abe: 4.831 | eve: 8.995 | bob: 4.809Epoch  14:  48% | abe: 4.830 | eve: 8.995 | bob: 4.808Epoch  14:  49% | abe: 4.829 | eve: 8.994 | bob: 4.807Epoch  14:  50% | abe: 4.828 | eve: 8.994 | bob: 4.806Epoch  14:  50% | abe: 4.827 | eve: 8.994 | bob: 4.805Epoch  14:  51% | abe: 4.826 | eve: 8.993 | bob: 4.804Epoch  14:  52% | abe: 4.825 | eve: 8.994 | bob: 4.803Epoch  14:  53% | abe: 4.825 | eve: 8.995 | bob: 4.802Epoch  14:  53% | abe: 4.824 | eve: 8.995 | bob: 4.801Epoch  14:  54% | abe: 4.823 | eve: 8.995 | bob: 4.800Epoch  14:  55% | abe: 4.822 | eve: 8.995 | bob: 4.799Epoch  14:  56% | abe: 4.821 | eve: 8.995 | bob: 4.798Epoch  14:  57% | abe: 4.820 | eve: 8.995 | bob: 4.797Epoch  14:  57% | abe: 4.819 | eve: 8.995 | bob: 4.796Epoch  14:  58% | abe: 4.818 | eve: 8.995 | bob: 4.795Epoch  14:  59% | abe: 4.816 | eve: 8.995 | bob: 4.793Epoch  14:  60% | abe: 4.816 | eve: 8.995 | bob: 4.793Epoch  14:  60% | abe: 4.815 | eve: 8.995 | bob: 4.792Epoch  14:  61% | abe: 4.814 | eve: 8.995 | bob: 4.791Epoch  14:  62% | abe: 4.813 | eve: 8.995 | bob: 4.790Epoch  14:  63% | abe: 4.812 | eve: 8.995 | bob: 4.789Epoch  14:  64% | abe: 4.811 | eve: 8.995 | bob: 4.788Epoch  14:  64% | abe: 4.810 | eve: 8.996 | bob: 4.787Epoch  14:  65% | abe: 4.810 | eve: 8.995 | bob: 4.787Epoch  14:  66% | abe: 4.808 | eve: 8.995 | bob: 4.785Epoch  14:  67% | abe: 4.808 | eve: 8.995 | bob: 4.784Epoch  14:  67% | abe: 4.807 | eve: 8.995 | bob: 4.784Epoch  14:  68% | abe: 4.806 | eve: 8.995 | bob: 4.782Epoch  14:  69% | abe: 4.805 | eve: 8.995 | bob: 4.781Epoch  14:  70% | abe: 4.804 | eve: 8.995 | bob: 4.781Epoch  14:  71% | abe: 4.803 | eve: 8.995 | bob: 4.780Epoch  14:  71% | abe: 4.802 | eve: 8.995 | bob: 4.778Epoch  14:  72% | abe: 4.801 | eve: 8.996 | bob: 4.777Epoch  14:  73% | abe: 4.800 | eve: 8.996 | bob: 4.777Epoch  14:  74% | abe: 4.799 | eve: 8.996 | bob: 4.776Epoch  14:  75% | abe: 4.798 | eve: 8.995 | bob: 4.775Epoch  14:  75% | abe: 4.797 | eve: 8.996 | bob: 4.774Epoch  14:  76% | abe: 4.796 | eve: 8.995 | bob: 4.773Epoch  14:  77% | abe: 4.796 | eve: 8.995 | bob: 4.772Epoch  14:  78% | abe: 4.795 | eve: 8.995 | bob: 4.771Epoch  14:  78% | abe: 4.794 | eve: 8.996 | bob: 4.771Epoch  14:  79% | abe: 4.793 | eve: 8.996 | bob: 4.770Epoch  14:  80% | abe: 4.792 | eve: 8.995 | bob: 4.769Epoch  14:  81% | abe: 4.791 | eve: 8.995 | bob: 4.767Epoch  14:  82% | abe: 4.790 | eve: 8.995 | bob: 4.767Epoch  14:  82% | abe: 4.789 | eve: 8.995 | bob: 4.766Epoch  14:  83% | abe: 4.788 | eve: 8.995 | bob: 4.765Epoch  14:  84% | abe: 4.788 | eve: 8.995 | bob: 4.764Epoch  14:  85% | abe: 4.787 | eve: 8.995 | bob: 4.763Epoch  14:  85% | abe: 4.786 | eve: 8.995 | bob: 4.762Epoch  14:  86% | abe: 4.785 | eve: 8.995 | bob: 4.761Epoch  14:  87% | abe: 4.784 | eve: 8.995 | bob: 4.760Epoch  14:  88% | abe: 4.783 | eve: 8.995 | bob: 4.759Epoch  14:  89% | abe: 4.783 | eve: 8.995 | bob: 4.759Epoch  14:  89% | abe: 4.782 | eve: 8.995 | bob: 4.757Epoch  14:  90% | abe: 4.781 | eve: 8.995 | bob: 4.757Epoch  14:  91% | abe: 4.780 | eve: 8.995 | bob: 4.756Epoch  14:  92% | abe: 4.779 | eve: 8.995 | bob: 4.755Epoch  14:  92% | abe: 4.778 | eve: 8.995 | bob: 4.754Epoch  14:  93% | abe: 4.777 | eve: 8.995 | bob: 4.753Epoch  14:  94% | abe: 4.776 | eve: 8.995 | bob: 4.752Epoch  14:  95% | abe: 4.775 | eve: 8.996 | bob: 4.751Epoch  14:  96% | abe: 4.774 | eve: 8.996 | bob: 4.750Epoch  14:  96% | abe: 4.773 | eve: 8.996 | bob: 4.749Epoch  14:  97% | abe: 4.772 | eve: 8.996 | bob: 4.748Epoch  14:  98% | abe: 4.771 | eve: 8.996 | bob: 4.747Epoch  14:  99% | abe: 4.771 | eve: 8.996 | bob: 4.746
New best Bob loss 4.746093043601263 at epoch 14
Epoch  15:   0% | abe: 4.658 | eve: 8.998 | bob: 4.622Epoch  15:   0% | abe: 4.649 | eve: 8.999 | bob: 4.611Epoch  15:   1% | abe: 4.661 | eve: 9.001 | bob: 4.626Epoch  15:   2% | abe: 4.650 | eve: 8.990 | bob: 4.617Epoch  15:   3% | abe: 4.652 | eve: 8.989 | bob: 4.620Epoch  15:   3% | abe: 4.648 | eve: 8.992 | bob: 4.616Epoch  15:   4% | abe: 4.646 | eve: 8.990 | bob: 4.613Epoch  15:   5% | abe: 4.648 | eve: 8.993 | bob: 4.614Epoch  15:   6% | abe: 4.645 | eve: 8.989 | bob: 4.612Epoch  15:   7% | abe: 4.642 | eve: 8.989 | bob: 4.610Epoch  15:   7% | abe: 4.639 | eve: 8.995 | bob: 4.607Epoch  15:   8% | abe: 4.640 | eve: 9.000 | bob: 4.608Epoch  15:   9% | abe: 4.641 | eve: 8.999 | bob: 4.609Epoch  15:  10% | abe: 4.640 | eve: 8.996 | bob: 4.608Epoch  15:  10% | abe: 4.638 | eve: 8.998 | bob: 4.606Epoch  15:  11% | abe: 4.638 | eve: 8.996 | bob: 4.607Epoch  15:  12% | abe: 4.638 | eve: 8.998 | bob: 4.606Epoch  15:  13% | abe: 4.635 | eve: 8.998 | bob: 4.604Epoch  15:  14% | abe: 4.635 | eve: 8.999 | bob: 4.603Epoch  15:  14% | abe: 4.634 | eve: 8.999 | bob: 4.602Epoch  15:  15% | abe: 4.634 | eve: 8.998 | bob: 4.601Epoch  15:  16% | abe: 4.633 | eve: 8.997 | bob: 4.601Epoch  15:  17% | abe: 4.632 | eve: 9.000 | bob: 4.600Epoch  15:  17% | abe: 4.631 | eve: 9.000 | bob: 4.599Epoch  15:  18% | abe: 4.631 | eve: 9.000 | bob: 4.599Epoch  15:  19% | abe: 4.631 | eve: 9.001 | bob: 4.599Epoch  15:  20% | abe: 4.630 | eve: 9.001 | bob: 4.598Epoch  15:  21% | abe: 4.629 | eve: 9.000 | bob: 4.597Epoch  15:  21% | abe: 4.628 | eve: 9.000 | bob: 4.596Epoch  15:  22% | abe: 4.627 | eve: 9.001 | bob: 4.595Epoch  15:  23% | abe: 4.626 | eve: 9.001 | bob: 4.594Epoch  15:  24% | abe: 4.626 | eve: 9.001 | bob: 4.594Epoch  15:  25% | abe: 4.625 | eve: 9.001 | bob: 4.593Epoch  15:  25% | abe: 4.624 | eve: 8.999 | bob: 4.593Epoch  15:  26% | abe: 4.623 | eve: 8.999 | bob: 4.592Epoch  15:  27% | abe: 4.622 | eve: 9.000 | bob: 4.590Epoch  15:  28% | abe: 4.622 | eve: 9.001 | bob: 4.590Epoch  15:  28% | abe: 4.621 | eve: 9.001 | bob: 4.589Epoch  15:  29% | abe: 4.621 | eve: 9.002 | bob: 4.589Epoch  15:  30% | abe: 4.620 | eve: 9.002 | bob: 4.588Epoch  15:  31% | abe: 4.619 | eve: 9.002 | bob: 4.587Epoch  15:  32% | abe: 4.617 | eve: 9.001 | bob: 4.585Epoch  15:  32% | abe: 4.617 | eve: 9.001 | bob: 4.585Epoch  15:  33% | abe: 4.616 | eve: 9.001 | bob: 4.584Epoch  15:  34% | abe: 4.616 | eve: 9.001 | bob: 4.584Epoch  15:  35% | abe: 4.615 | eve: 9.001 | bob: 4.583Epoch  15:  35% | abe: 4.613 | eve: 9.001 | bob: 4.582Epoch  15:  36% | abe: 4.613 | eve: 9.001 | bob: 4.581Epoch  15:  37% | abe: 4.613 | eve: 9.001 | bob: 4.581Epoch  15:  38% | abe: 4.612 | eve: 9.001 | bob: 4.580Epoch  15:  39% | abe: 4.612 | eve: 9.001 | bob: 4.580Epoch  15:  39% | abe: 4.611 | eve: 9.002 | bob: 4.579Epoch  15:  40% | abe: 4.610 | eve: 9.002 | bob: 4.578Epoch  15:  41% | abe: 4.609 | eve: 9.002 | bob: 4.578Epoch  15:  42% | abe: 4.609 | eve: 9.001 | bob: 4.577Epoch  15:  42% | abe: 4.607 | eve: 9.002 | bob: 4.576Epoch  15:  43% | abe: 4.607 | eve: 9.002 | bob: 4.575Epoch  15:  44% | abe: 4.607 | eve: 9.001 | bob: 4.575Epoch  15:  45% | abe: 4.606 | eve: 9.000 | bob: 4.574Epoch  15:  46% | abe: 4.605 | eve: 9.000 | bob: 4.573Epoch  15:  46% | abe: 4.604 | eve: 9.000 | bob: 4.572Epoch  15:  47% | abe: 4.603 | eve: 8.999 | bob: 4.571Epoch  15:  48% | abe: 4.602 | eve: 8.999 | bob: 4.570Epoch  15:  49% | abe: 4.601 | eve: 8.999 | bob: 4.569Epoch  15:  50% | abe: 4.600 | eve: 8.999 | bob: 4.568Epoch  15:  50% | abe: 4.600 | eve: 8.998 | bob: 4.567Epoch  15:  51% | abe: 4.599 | eve: 8.999 | bob: 4.566Epoch  15:  52% | abe: 4.598 | eve: 8.999 | bob: 4.565Epoch  15:  53% | abe: 4.597 | eve: 8.998 | bob: 4.565Epoch  15:  53% | abe: 4.597 | eve: 8.999 | bob: 4.564Epoch  15:  54% | abe: 4.595 | eve: 8.999 | bob: 4.563Epoch  15:  55% | abe: 4.595 | eve: 9.000 | bob: 4.563Epoch  15:  56% | abe: 4.595 | eve: 9.000 | bob: 4.562Epoch  15:  57% | abe: 4.594 | eve: 8.999 | bob: 4.562Epoch  15:  57% | abe: 4.594 | eve: 8.999 | bob: 4.562Epoch  15:  58% | abe: 4.593 | eve: 9.000 | bob: 4.561Epoch  15:  59% | abe: 4.592 | eve: 8.999 | bob: 4.560Epoch  15:  60% | abe: 4.591 | eve: 9.000 | bob: 4.559Epoch  15:  60% | abe: 4.591 | eve: 9.000 | bob: 4.558Epoch  15:  61% | abe: 4.590 | eve: 9.000 | bob: 4.558Epoch  15:  62% | abe: 4.589 | eve: 9.000 | bob: 4.557Epoch  15:  63% | abe: 4.588 | eve: 9.000 | bob: 4.556Epoch  15:  64% | abe: 4.588 | eve: 9.000 | bob: 4.556Epoch  15:  64% | abe: 4.587 | eve: 9.000 | bob: 4.555Epoch  15:  65% | abe: 4.587 | eve: 9.001 | bob: 4.554Epoch  15:  66% | abe: 4.586 | eve: 9.001 | bob: 4.553Epoch  15:  67% | abe: 4.585 | eve: 9.000 | bob: 4.553Epoch  15:  67% | abe: 4.584 | eve: 9.001 | bob: 4.552Epoch  15:  68% | abe: 4.583 | eve: 9.001 | bob: 4.551Epoch  15:  69% | abe: 4.582 | eve: 9.001 | bob: 4.550Epoch  15:  70% | abe: 4.582 | eve: 9.001 | bob: 4.549Epoch  15:  71% | abe: 4.581 | eve: 9.001 | bob: 4.548Epoch  15:  71% | abe: 4.580 | eve: 9.001 | bob: 4.547Epoch  15:  72% | abe: 4.579 | eve: 9.001 | bob: 4.546Epoch  15:  73% | abe: 4.578 | eve: 9.001 | bob: 4.546Epoch  15:  74% | abe: 4.577 | eve: 9.001 | bob: 4.545Epoch  15:  75% | abe: 4.577 | eve: 9.001 | bob: 4.544Epoch  15:  75% | abe: 4.576 | eve: 9.001 | bob: 4.543Epoch  15:  76% | abe: 4.575 | eve: 9.000 | bob: 4.542Epoch  15:  77% | abe: 4.574 | eve: 9.000 | bob: 4.541Epoch  15:  78% | abe: 4.574 | eve: 9.000 | bob: 4.541Epoch  15:  78% | abe: 4.573 | eve: 9.000 | bob: 4.540Epoch  15:  79% | abe: 4.572 | eve: 9.000 | bob: 4.539Epoch  15:  80% | abe: 4.571 | eve: 9.000 | bob: 4.539Epoch  15:  81% | abe: 4.570 | eve: 9.000 | bob: 4.537Epoch  15:  82% | abe: 4.570 | eve: 8.999 | bob: 4.537Epoch  15:  82% | abe: 4.569 | eve: 8.999 | bob: 4.536Epoch  15:  83% | abe: 4.568 | eve: 8.999 | bob: 4.535Epoch  15:  84% | abe: 4.568 | eve: 8.999 | bob: 4.534Epoch  15:  85% | abe: 4.567 | eve: 9.000 | bob: 4.534Epoch  15:  85% | abe: 4.566 | eve: 9.000 | bob: 4.533Epoch  15:  86% | abe: 4.565 | eve: 9.000 | bob: 4.532Epoch  15:  87% | abe: 4.565 | eve: 9.000 | bob: 4.532Epoch  15:  88% | abe: 4.564 | eve: 9.000 | bob: 4.531Epoch  15:  89% | abe: 4.563 | eve: 9.000 | bob: 4.530Epoch  15:  89% | abe: 4.563 | eve: 9.000 | bob: 4.529Epoch  15:  90% | abe: 4.562 | eve: 9.001 | bob: 4.528Epoch  15:  91% | abe: 4.561 | eve: 9.001 | bob: 4.528Epoch  15:  92% | abe: 4.560 | eve: 9.001 | bob: 4.527Epoch  15:  92% | abe: 4.560 | eve: 9.001 | bob: 4.526Epoch  15:  93% | abe: 4.559 | eve: 9.001 | bob: 4.526Epoch  15:  94% | abe: 4.558 | eve: 9.000 | bob: 4.525Epoch  15:  95% | abe: 4.557 | eve: 9.001 | bob: 4.524Epoch  15:  96% | abe: 4.557 | eve: 9.001 | bob: 4.523Epoch  15:  96% | abe: 4.556 | eve: 9.001 | bob: 4.523Epoch  15:  97% | abe: 4.555 | eve: 9.001 | bob: 4.522Epoch  15:  98% | abe: 4.554 | eve: 9.001 | bob: 4.521Epoch  15:  99% | abe: 4.553 | eve: 9.001 | bob: 4.520
New best Bob loss 4.520156615435326 at epoch 15
Epoch  16:   0% | abe: 4.449 | eve: 9.006 | bob: 4.424Epoch  16:   0% | abe: 4.447 | eve: 9.009 | bob: 4.416Epoch  16:   1% | abe: 4.454 | eve: 9.013 | bob: 4.421Epoch  16:   2% | abe: 4.453 | eve: 9.008 | bob: 4.420Epoch  16:   3% | abe: 4.456 | eve: 9.003 | bob: 4.423Epoch  16:   3% | abe: 4.454 | eve: 9.001 | bob: 4.422Epoch  16:   4% | abe: 4.452 | eve: 9.003 | bob: 4.420Epoch  16:   5% | abe: 4.453 | eve: 9.006 | bob: 4.420Epoch  16:   6% | abe: 4.449 | eve: 9.005 | bob: 4.415Epoch  16:   7% | abe: 4.447 | eve: 9.005 | bob: 4.413Epoch  16:   7% | abe: 4.447 | eve: 9.003 | bob: 4.412Epoch  16:   8% | abe: 4.446 | eve: 9.003 | bob: 4.412Epoch  16:   9% | abe: 4.446 | eve: 9.003 | bob: 4.411Epoch  16:  10% | abe: 4.446 | eve: 9.002 | bob: 4.411Epoch  16:  10% | abe: 4.445 | eve: 9.001 | bob: 4.409Epoch  16:  11% | abe: 4.443 | eve: 8.999 | bob: 4.407Epoch  16:  12% | abe: 4.443 | eve: 8.998 | bob: 4.408Epoch  16:  13% | abe: 4.442 | eve: 8.998 | bob: 4.407Epoch  16:  14% | abe: 4.443 | eve: 8.997 | bob: 4.409Epoch  16:  14% | abe: 4.442 | eve: 8.998 | bob: 4.408Epoch  16:  15% | abe: 4.441 | eve: 8.999 | bob: 4.406Epoch  16:  16% | abe: 4.440 | eve: 8.999 | bob: 4.405Epoch  16:  17% | abe: 4.440 | eve: 9.000 | bob: 4.406Epoch  16:  17% | abe: 4.439 | eve: 8.999 | bob: 4.404Epoch  16:  18% | abe: 4.437 | eve: 8.999 | bob: 4.403Epoch  16:  19% | abe: 4.437 | eve: 8.999 | bob: 4.403Epoch  16:  20% | abe: 4.437 | eve: 9.000 | bob: 4.402Epoch  16:  21% | abe: 4.436 | eve: 9.000 | bob: 4.401Epoch  16:  21% | abe: 4.435 | eve: 8.998 | bob: 4.401Epoch  16:  22% | abe: 4.435 | eve: 8.998 | bob: 4.401Epoch  16:  23% | abe: 4.435 | eve: 8.998 | bob: 4.400Epoch  16:  24% | abe: 4.434 | eve: 8.999 | bob: 4.400Epoch  16:  25% | abe: 4.433 | eve: 8.999 | bob: 4.399Epoch  16:  25% | abe: 4.433 | eve: 8.998 | bob: 4.399Epoch  16:  26% | abe: 4.433 | eve: 8.999 | bob: 4.398Epoch  16:  27% | abe: 4.432 | eve: 8.999 | bob: 4.398Epoch  16:  28% | abe: 4.431 | eve: 8.999 | bob: 4.397Epoch  16:  28% | abe: 4.430 | eve: 8.999 | bob: 4.396Epoch  16:  29% | abe: 4.430 | eve: 9.001 | bob: 4.395Epoch  16:  30% | abe: 4.430 | eve: 9.001 | bob: 4.395Epoch  16:  31% | abe: 4.430 | eve: 9.000 | bob: 4.395Epoch  16:  32% | abe: 4.429 | eve: 9.001 | bob: 4.394Epoch  16:  32% | abe: 4.428 | eve: 9.001 | bob: 4.393Epoch  16:  33% | abe: 4.427 | eve: 9.002 | bob: 4.392Epoch  16:  34% | abe: 4.426 | eve: 9.001 | bob: 4.391Epoch  16:  35% | abe: 4.426 | eve: 9.002 | bob: 4.391Epoch  16:  35% | abe: 4.426 | eve: 9.002 | bob: 4.390Epoch  16:  36% | abe: 4.424 | eve: 9.002 | bob: 4.389Epoch  16:  37% | abe: 4.424 | eve: 9.002 | bob: 4.389Epoch  16:  38% | abe: 4.423 | eve: 9.002 | bob: 4.388Epoch  16:  39% | abe: 4.422 | eve: 9.003 | bob: 4.387Epoch  16:  39% | abe: 4.422 | eve: 9.002 | bob: 4.387Epoch  16:  40% | abe: 4.420 | eve: 9.002 | bob: 4.385Epoch  16:  41% | abe: 4.420 | eve: 9.002 | bob: 4.385Epoch  16:  42% | abe: 4.419 | eve: 9.002 | bob: 4.384Epoch  16:  42% | abe: 4.418 | eve: 9.001 | bob: 4.383Epoch  16:  43% | abe: 4.418 | eve: 9.002 | bob: 4.382Epoch  16:  44% | abe: 4.417 | eve: 9.001 | bob: 4.382Epoch  16:  45% | abe: 4.416 | eve: 9.001 | bob: 4.380Epoch  16:  46% | abe: 4.415 | eve: 9.001 | bob: 4.380Epoch  16:  46% | abe: 4.415 | eve: 9.001 | bob: 4.379Epoch  16:  47% | abe: 4.414 | eve: 9.001 | bob: 4.379Epoch  16:  48% | abe: 4.414 | eve: 9.001 | bob: 4.379Epoch  16:  49% | abe: 4.413 | eve: 9.001 | bob: 4.378Epoch  16:  50% | abe: 4.412 | eve: 9.002 | bob: 4.377Epoch  16:  50% | abe: 4.412 | eve: 9.002 | bob: 4.376Epoch  16:  51% | abe: 4.410 | eve: 9.002 | bob: 4.375Epoch  16:  52% | abe: 4.409 | eve: 9.001 | bob: 4.374Epoch  16:  53% | abe: 4.409 | eve: 9.002 | bob: 4.373Epoch  16:  53% | abe: 4.408 | eve: 9.002 | bob: 4.372Epoch  16:  54% | abe: 4.407 | eve: 9.002 | bob: 4.371Epoch  16:  55% | abe: 4.406 | eve: 9.002 | bob: 4.370Epoch  16:  56% | abe: 4.405 | eve: 9.002 | bob: 4.369Epoch  16:  57% | abe: 4.405 | eve: 9.002 | bob: 4.369Epoch  16:  57% | abe: 4.404 | eve: 9.002 | bob: 4.368Epoch  16:  58% | abe: 4.403 | eve: 9.002 | bob: 4.367Epoch  16:  59% | abe: 4.402 | eve: 9.003 | bob: 4.366Epoch  16:  60% | abe: 4.402 | eve: 9.002 | bob: 4.366Epoch  16:  60% | abe: 4.401 | eve: 9.002 | bob: 4.365Epoch  16:  61% | abe: 4.401 | eve: 9.002 | bob: 4.364Epoch  16:  62% | abe: 4.400 | eve: 9.002 | bob: 4.363Epoch  16:  63% | abe: 4.398 | eve: 9.002 | bob: 4.362Epoch  16:  64% | abe: 4.398 | eve: 9.002 | bob: 4.361Epoch  16:  64% | abe: 4.397 | eve: 9.002 | bob: 4.360Epoch  16:  65% | abe: 4.396 | eve: 9.002 | bob: 4.360Epoch  16:  66% | abe: 4.395 | eve: 9.002 | bob: 4.359Epoch  16:  67% | abe: 4.395 | eve: 9.002 | bob: 4.358Epoch  16:  67% | abe: 4.394 | eve: 9.002 | bob: 4.357Epoch  16:  68% | abe: 4.393 | eve: 9.002 | bob: 4.356Epoch  16:  69% | abe: 4.392 | eve: 9.002 | bob: 4.355Epoch  16:  70% | abe: 4.391 | eve: 9.002 | bob: 4.354Epoch  16:  71% | abe: 4.391 | eve: 9.002 | bob: 4.354Epoch  16:  71% | abe: 4.390 | eve: 9.002 | bob: 4.353Epoch  16:  72% | abe: 4.389 | eve: 9.001 | bob: 4.352Epoch  16:  73% | abe: 4.389 | eve: 9.001 | bob: 4.352Epoch  16:  74% | abe: 4.388 | eve: 9.001 | bob: 4.351Epoch  16:  75% | abe: 4.388 | eve: 9.001 | bob: 4.351Epoch  16:  75% | abe: 4.387 | eve: 9.001 | bob: 4.350Epoch  16:  76% | abe: 4.386 | eve: 9.001 | bob: 4.349Epoch  16:  77% | abe: 4.386 | eve: 9.001 | bob: 4.349Epoch  16:  78% | abe: 4.385 | eve: 9.001 | bob: 4.348Epoch  16:  78% | abe: 4.385 | eve: 9.001 | bob: 4.348Epoch  16:  79% | abe: 4.384 | eve: 9.001 | bob: 4.347Epoch  16:  80% | abe: 4.383 | eve: 9.001 | bob: 4.346Epoch  16:  81% | abe: 4.382 | eve: 9.001 | bob: 4.345Epoch  16:  82% | abe: 4.382 | eve: 9.001 | bob: 4.345Epoch  16:  82% | abe: 4.381 | eve: 9.001 | bob: 4.344Epoch  16:  83% | abe: 4.380 | eve: 9.001 | bob: 4.343Epoch  16:  84% | abe: 4.380 | eve: 9.002 | bob: 4.342Epoch  16:  85% | abe: 4.379 | eve: 9.002 | bob: 4.342Epoch  16:  85% | abe: 4.378 | eve: 9.002 | bob: 4.341Epoch  16:  86% | abe: 4.378 | eve: 9.002 | bob: 4.340Epoch  16:  87% | abe: 4.377 | eve: 9.002 | bob: 4.340Epoch  16:  88% | abe: 4.376 | eve: 9.002 | bob: 4.339Epoch  16:  89% | abe: 4.375 | eve: 9.002 | bob: 4.338Epoch  16:  89% | abe: 4.375 | eve: 9.002 | bob: 4.338Epoch  16:  90% | abe: 4.374 | eve: 9.002 | bob: 4.337Epoch  16:  91% | abe: 4.374 | eve: 9.002 | bob: 4.336Epoch  16:  92% | abe: 4.373 | eve: 9.002 | bob: 4.335Epoch  16:  92% | abe: 4.372 | eve: 9.001 | bob: 4.335Epoch  16:  93% | abe: 4.371 | eve: 9.001 | bob: 4.334Epoch  16:  94% | abe: 4.370 | eve: 9.001 | bob: 4.333Epoch  16:  95% | abe: 4.370 | eve: 9.001 | bob: 4.332Epoch  16:  96% | abe: 4.369 | eve: 9.001 | bob: 4.331Epoch  16:  96% | abe: 4.368 | eve: 9.001 | bob: 4.331Epoch  16:  97% | abe: 4.367 | eve: 9.002 | bob: 4.330Epoch  16:  98% | abe: 4.367 | eve: 9.001 | bob: 4.329Epoch  16:  99% | abe: 4.366 | eve: 9.001 | bob: 4.329
New best Bob loss 4.3287729002023525 at epoch 16
Epoch  17:   0% | abe: 4.255 | eve: 8.998 | bob: 4.211Epoch  17:   0% | abe: 4.275 | eve: 8.983 | bob: 4.233Epoch  17:   1% | abe: 4.281 | eve: 9.006 | bob: 4.240Epoch  17:   2% | abe: 4.283 | eve: 9.003 | bob: 4.244Epoch  17:   3% | abe: 4.279 | eve: 9.001 | bob: 4.239Epoch  17:   3% | abe: 4.280 | eve: 9.005 | bob: 4.239Epoch  17:   4% | abe: 4.276 | eve: 9.008 | bob: 4.236Epoch  17:   5% | abe: 4.275 | eve: 9.004 | bob: 4.236Epoch  17:   6% | abe: 4.273 | eve: 9.005 | bob: 4.234Epoch  17:   7% | abe: 4.271 | eve: 9.005 | bob: 4.231Epoch  17:   7% | abe: 4.269 | eve: 9.003 | bob: 4.230Epoch  17:   8% | abe: 4.269 | eve: 9.006 | bob: 4.230Epoch  17:   9% | abe: 4.270 | eve: 9.004 | bob: 4.231Epoch  17:  10% | abe: 4.269 | eve: 9.005 | bob: 4.230Epoch  17:  10% | abe: 4.265 | eve: 9.002 | bob: 4.226Epoch  17:  11% | abe: 4.265 | eve: 9.003 | bob: 4.226Epoch  17:  12% | abe: 4.266 | eve: 9.001 | bob: 4.227Epoch  17:  13% | abe: 4.266 | eve: 9.001 | bob: 4.227Epoch  17:  14% | abe: 4.266 | eve: 9.000 | bob: 4.228Epoch  17:  14% | abe: 4.265 | eve: 9.002 | bob: 4.226Epoch  17:  15% | abe: 4.264 | eve: 9.003 | bob: 4.225Epoch  17:  16% | abe: 4.263 | eve: 9.002 | bob: 4.224Epoch  17:  17% | abe: 4.261 | eve: 9.002 | bob: 4.223Epoch  17:  17% | abe: 4.260 | eve: 9.001 | bob: 4.222Epoch  17:  18% | abe: 4.259 | eve: 9.002 | bob: 4.220Epoch  17:  19% | abe: 4.257 | eve: 9.002 | bob: 4.219Epoch  17:  20% | abe: 4.257 | eve: 9.002 | bob: 4.219Epoch  17:  21% | abe: 4.257 | eve: 9.001 | bob: 4.218Epoch  17:  21% | abe: 4.256 | eve: 9.001 | bob: 4.218Epoch  17:  22% | abe: 4.255 | eve: 9.001 | bob: 4.216Epoch  17:  23% | abe: 4.254 | eve: 9.000 | bob: 4.216Epoch  17:  24% | abe: 4.254 | eve: 9.000 | bob: 4.216Epoch  17:  25% | abe: 4.253 | eve: 8.999 | bob: 4.215Epoch  17:  25% | abe: 4.253 | eve: 8.999 | bob: 4.215Epoch  17:  26% | abe: 4.253 | eve: 8.999 | bob: 4.215Epoch  17:  27% | abe: 4.252 | eve: 8.999 | bob: 4.214Epoch  17:  28% | abe: 4.252 | eve: 9.000 | bob: 4.214Epoch  17:  28% | abe: 4.252 | eve: 9.000 | bob: 4.213Epoch  17:  29% | abe: 4.251 | eve: 9.001 | bob: 4.213Epoch  17:  30% | abe: 4.250 | eve: 9.002 | bob: 4.212Epoch  17:  31% | abe: 4.250 | eve: 9.002 | bob: 4.211Epoch  17:  32% | abe: 4.248 | eve: 9.002 | bob: 4.210Epoch  17:  32% | abe: 4.248 | eve: 9.003 | bob: 4.209Epoch  17:  33% | abe: 4.246 | eve: 9.002 | bob: 4.208Epoch  17:  34% | abe: 4.246 | eve: 9.002 | bob: 4.207Epoch  17:  35% | abe: 4.245 | eve: 9.001 | bob: 4.206Epoch  17:  35% | abe: 4.244 | eve: 9.001 | bob: 4.206Epoch  17:  36% | abe: 4.242 | eve: 9.000 | bob: 4.204Epoch  17:  37% | abe: 4.242 | eve: 9.000 | bob: 4.203Epoch  17:  38% | abe: 4.241 | eve: 9.000 | bob: 4.203Epoch  17:  39% | abe: 4.240 | eve: 9.001 | bob: 4.202Epoch  17:  39% | abe: 4.239 | eve: 9.001 | bob: 4.201Epoch  17:  40% | abe: 4.240 | eve: 9.001 | bob: 4.201Epoch  17:  41% | abe: 4.239 | eve: 9.000 | bob: 4.201Epoch  17:  42% | abe: 4.239 | eve: 9.000 | bob: 4.201Epoch  17:  42% | abe: 4.239 | eve: 8.999 | bob: 4.200Epoch  17:  43% | abe: 4.238 | eve: 8.999 | bob: 4.200Epoch  17:  44% | abe: 4.237 | eve: 8.999 | bob: 4.199Epoch  17:  45% | abe: 4.237 | eve: 8.999 | bob: 4.198Epoch  17:  46% | abe: 4.236 | eve: 8.998 | bob: 4.197Epoch  17:  46% | abe: 4.235 | eve: 8.998 | bob: 4.197Epoch  17:  47% | abe: 4.235 | eve: 8.999 | bob: 4.196Epoch  17:  48% | abe: 4.234 | eve: 8.998 | bob: 4.196Epoch  17:  49% | abe: 4.233 | eve: 8.997 | bob: 4.195Epoch  17:  50% | abe: 4.233 | eve: 8.997 | bob: 4.194Epoch  17:  50% | abe: 4.233 | eve: 8.998 | bob: 4.194Epoch  17:  51% | abe: 4.232 | eve: 8.998 | bob: 4.194Epoch  17:  52% | abe: 4.232 | eve: 8.998 | bob: 4.193Epoch  17:  53% | abe: 4.231 | eve: 8.999 | bob: 4.192Epoch  17:  53% | abe: 4.230 | eve: 8.999 | bob: 4.192Epoch  17:  54% | abe: 4.229 | eve: 8.999 | bob: 4.191Epoch  17:  55% | abe: 4.228 | eve: 8.999 | bob: 4.190Epoch  17:  56% | abe: 4.228 | eve: 9.000 | bob: 4.189Epoch  17:  57% | abe: 4.227 | eve: 9.000 | bob: 4.188Epoch  17:  57% | abe: 4.226 | eve: 9.000 | bob: 4.187Epoch  17:  58% | abe: 4.225 | eve: 9.000 | bob: 4.186Epoch  17:  59% | abe: 4.225 | eve: 9.000 | bob: 4.186Epoch  17:  60% | abe: 4.224 | eve: 9.000 | bob: 4.185Epoch  17:  60% | abe: 4.223 | eve: 9.000 | bob: 4.184Epoch  17:  61% | abe: 4.223 | eve: 9.000 | bob: 4.184Epoch  17:  62% | abe: 4.222 | eve: 9.000 | bob: 4.183Epoch  17:  63% | abe: 4.221 | eve: 8.999 | bob: 4.182Epoch  17:  64% | abe: 4.220 | eve: 8.999 | bob: 4.182Epoch  17:  64% | abe: 4.220 | eve: 8.999 | bob: 4.181Epoch  17:  65% | abe: 4.219 | eve: 8.999 | bob: 4.180Epoch  17:  66% | abe: 4.219 | eve: 8.999 | bob: 4.180Epoch  17:  67% | abe: 4.218 | eve: 9.000 | bob: 4.179Epoch  17:  67% | abe: 4.217 | eve: 9.000 | bob: 4.179Epoch  17:  68% | abe: 4.217 | eve: 9.000 | bob: 4.178Epoch  17:  69% | abe: 4.216 | eve: 8.999 | bob: 4.177Epoch  17:  70% | abe: 4.216 | eve: 8.999 | bob: 4.177Epoch  17:  71% | abe: 4.215 | eve: 8.999 | bob: 4.176Epoch  17:  71% | abe: 4.214 | eve: 8.999 | bob: 4.176Epoch  17:  72% | abe: 4.213 | eve: 8.999 | bob: 4.175Epoch  17:  73% | abe: 4.213 | eve: 8.999 | bob: 4.174Epoch  17:  74% | abe: 4.212 | eve: 8.999 | bob: 4.173Epoch  17:  75% | abe: 4.211 | eve: 8.999 | bob: 4.173Epoch  17:  75% | abe: 4.211 | eve: 8.999 | bob: 4.172Epoch  17:  76% | abe: 4.210 | eve: 8.999 | bob: 4.171Epoch  17:  77% | abe: 4.209 | eve: 8.999 | bob: 4.170Epoch  17:  78% | abe: 4.209 | eve: 8.999 | bob: 4.170Epoch  17:  78% | abe: 4.208 | eve: 8.999 | bob: 4.169Epoch  17:  79% | abe: 4.207 | eve: 8.999 | bob: 4.169Epoch  17:  80% | abe: 4.207 | eve: 9.000 | bob: 4.168Epoch  17:  81% | abe: 4.206 | eve: 9.000 | bob: 4.167Epoch  17:  82% | abe: 4.206 | eve: 8.999 | bob: 4.167Epoch  17:  82% | abe: 4.205 | eve: 8.999 | bob: 4.167Epoch  17:  83% | abe: 4.205 | eve: 9.000 | bob: 4.166Epoch  17:  84% | abe: 4.205 | eve: 9.000 | bob: 4.166Epoch  17:  85% | abe: 4.204 | eve: 9.000 | bob: 4.165Epoch  17:  85% | abe: 4.203 | eve: 9.000 | bob: 4.164Epoch  17:  86% | abe: 4.202 | eve: 9.000 | bob: 4.164Epoch  17:  87% | abe: 4.202 | eve: 9.000 | bob: 4.163Epoch  17:  88% | abe: 4.201 | eve: 9.000 | bob: 4.162Epoch  17:  89% | abe: 4.201 | eve: 9.000 | bob: 4.162Epoch  17:  89% | abe: 4.200 | eve: 9.000 | bob: 4.161Epoch  17:  90% | abe: 4.200 | eve: 9.000 | bob: 4.161Epoch  17:  91% | abe: 4.199 | eve: 9.000 | bob: 4.160Epoch  17:  92% | abe: 4.198 | eve: 9.000 | bob: 4.159Epoch  17:  92% | abe: 4.198 | eve: 9.000 | bob: 4.159Epoch  17:  93% | abe: 4.197 | eve: 9.000 | bob: 4.158Epoch  17:  94% | abe: 4.197 | eve: 9.000 | bob: 4.158Epoch  17:  95% | abe: 4.196 | eve: 9.000 | bob: 4.157Epoch  17:  96% | abe: 4.196 | eve: 9.000 | bob: 4.157Epoch  17:  96% | abe: 4.195 | eve: 9.000 | bob: 4.156Epoch  17:  97% | abe: 4.194 | eve: 9.000 | bob: 4.155Epoch  17:  98% | abe: 4.194 | eve: 9.000 | bob: 4.155Epoch  17:  99% | abe: 4.193 | eve: 9.000 | bob: 4.154
New best Bob loss 4.154052652204314 at epoch 17
Epoch  18:   0% | abe: 4.105 | eve: 8.988 | bob: 4.064Epoch  18:   0% | abe: 4.094 | eve: 8.996 | bob: 4.051Epoch  18:   1% | abe: 4.099 | eve: 8.996 | bob: 4.059Epoch  18:   2% | abe: 4.104 | eve: 8.993 | bob: 4.065Epoch  18:   3% | abe: 4.102 | eve: 8.987 | bob: 4.065Epoch  18:   3% | abe: 4.102 | eve: 8.992 | bob: 4.065Epoch  18:   4% | abe: 4.101 | eve: 8.992 | bob: 4.063Epoch  18:   5% | abe: 4.104 | eve: 8.991 | bob: 4.065Epoch  18:   6% | abe: 4.100 | eve: 8.991 | bob: 4.061Epoch  18:   7% | abe: 4.101 | eve: 8.995 | bob: 4.063Epoch  18:   7% | abe: 4.102 | eve: 8.996 | bob: 4.064Epoch  18:   8% | abe: 4.103 | eve: 8.994 | bob: 4.064Epoch  18:   9% | abe: 4.104 | eve: 8.999 | bob: 4.066Epoch  18:  10% | abe: 4.104 | eve: 8.998 | bob: 4.066Epoch  18:  10% | abe: 4.103 | eve: 8.994 | bob: 4.065Epoch  18:  11% | abe: 4.101 | eve: 8.993 | bob: 4.063Epoch  18:  12% | abe: 4.103 | eve: 8.994 | bob: 4.065Epoch  18:  13% | abe: 4.102 | eve: 8.994 | bob: 4.063Epoch  18:  14% | abe: 4.101 | eve: 8.996 | bob: 4.063Epoch  18:  14% | abe: 4.102 | eve: 8.997 | bob: 4.064Epoch  18:  15% | abe: 4.102 | eve: 8.997 | bob: 4.065Epoch  18:  16% | abe: 4.102 | eve: 8.997 | bob: 4.065Epoch  18:  17% | abe: 4.102 | eve: 8.997 | bob: 4.065Epoch  18:  17% | abe: 4.102 | eve: 8.999 | bob: 4.065Epoch  18:  18% | abe: 4.101 | eve: 8.998 | bob: 4.065Epoch  18:  19% | abe: 4.100 | eve: 8.998 | bob: 4.063Epoch  18:  20% | abe: 4.101 | eve: 8.999 | bob: 4.063Epoch  18:  21% | abe: 4.101 | eve: 8.999 | bob: 4.064Epoch  18:  21% | abe: 4.101 | eve: 9.000 | bob: 4.064Epoch  18:  22% | abe: 4.100 | eve: 9.002 | bob: 4.063Epoch  18:  23% | abe: 4.099 | eve: 9.003 | bob: 4.062Epoch  18:  24% | abe: 4.099 | eve: 9.003 | bob: 4.061Epoch  18:  25% | abe: 4.099 | eve: 9.004 | bob: 4.061Epoch  18:  25% | abe: 4.098 | eve: 9.005 | bob: 4.061Epoch  18:  26% | abe: 4.097 | eve: 9.004 | bob: 4.060Epoch  18:  27% | abe: 4.097 | eve: 9.003 | bob: 4.060Epoch  18:  28% | abe: 4.097 | eve: 9.003 | bob: 4.060Epoch  18:  28% | abe: 4.097 | eve: 9.003 | bob: 4.060Epoch  18:  29% | abe: 4.096 | eve: 9.003 | bob: 4.059Epoch  18:  30% | abe: 4.096 | eve: 9.004 | bob: 4.059Epoch  18:  31% | abe: 4.095 | eve: 9.005 | bob: 4.058Epoch  18:  32% | abe: 4.095 | eve: 9.004 | bob: 4.057Epoch  18:  32% | abe: 4.094 | eve: 9.004 | bob: 4.056Epoch  18:  33% | abe: 4.093 | eve: 9.003 | bob: 4.055Epoch  18:  34% | abe: 4.092 | eve: 9.003 | bob: 4.055Epoch  18:  35% | abe: 4.092 | eve: 9.003 | bob: 4.055Epoch  18:  35% | abe: 4.092 | eve: 9.003 | bob: 4.054Epoch  18:  36% | abe: 4.092 | eve: 9.003 | bob: 4.054Epoch  18:  37% | abe: 4.091 | eve: 9.003 | bob: 4.054Epoch  18:  38% | abe: 4.091 | eve: 9.002 | bob: 4.054Epoch  18:  39% | abe: 4.091 | eve: 9.001 | bob: 4.054Epoch  18:  39% | abe: 4.090 | eve: 9.002 | bob: 4.053Epoch  18:  40% | abe: 4.090 | eve: 9.002 | bob: 4.052Epoch  18:  41% | abe: 4.089 | eve: 9.003 | bob: 4.052Epoch  18:  42% | abe: 4.089 | eve: 9.002 | bob: 4.051Epoch  18:  42% | abe: 4.088 | eve: 9.002 | bob: 4.050Epoch  18:  43% | abe: 4.087 | eve: 9.002 | bob: 4.049Epoch  18:  44% | abe: 4.086 | eve: 9.002 | bob: 4.048Epoch  18:  45% | abe: 4.085 | eve: 9.001 | bob: 4.048Epoch  18:  46% | abe: 4.084 | eve: 9.001 | bob: 4.047Epoch  18:  46% | abe: 4.084 | eve: 9.001 | bob: 4.047Epoch  18:  47% | abe: 4.084 | eve: 9.000 | bob: 4.047Epoch  18:  48% | abe: 4.083 | eve: 9.000 | bob: 4.046Epoch  18:  49% | abe: 4.082 | eve: 8.999 | bob: 4.045Epoch  18:  50% | abe: 4.082 | eve: 9.000 | bob: 4.045Epoch  18:  50% | abe: 4.081 | eve: 9.000 | bob: 4.044Epoch  18:  51% | abe: 4.081 | eve: 9.000 | bob: 4.044Epoch  18:  52% | abe: 4.080 | eve: 9.000 | bob: 4.043Epoch  18:  53% | abe: 4.080 | eve: 9.000 | bob: 4.042Epoch  18:  53% | abe: 4.079 | eve: 9.000 | bob: 4.042Epoch  18:  54% | abe: 4.078 | eve: 8.999 | bob: 4.041Epoch  18:  55% | abe: 4.077 | eve: 8.999 | bob: 4.039Epoch  18:  56% | abe: 4.076 | eve: 8.999 | bob: 4.039Epoch  18:  57% | abe: 4.075 | eve: 8.999 | bob: 4.038Epoch  18:  57% | abe: 4.074 | eve: 9.000 | bob: 4.037Epoch  18:  58% | abe: 4.073 | eve: 9.000 | bob: 4.036Epoch  18:  59% | abe: 4.073 | eve: 9.001 | bob: 4.035Epoch  18:  60% | abe: 4.072 | eve: 9.001 | bob: 4.035Epoch  18:  60% | abe: 4.071 | eve: 9.001 | bob: 4.034Epoch  18:  61% | abe: 4.071 | eve: 9.001 | bob: 4.033Epoch  18:  62% | abe: 4.070 | eve: 9.000 | bob: 4.033Epoch  18:  63% | abe: 4.070 | eve: 9.000 | bob: 4.032Epoch  18:  64% | abe: 4.069 | eve: 9.001 | bob: 4.032Epoch  18:  64% | abe: 4.069 | eve: 9.001 | bob: 4.031Epoch  18:  65% | abe: 4.068 | eve: 9.001 | bob: 4.031Epoch  18:  66% | abe: 4.068 | eve: 9.001 | bob: 4.030Epoch  18:  67% | abe: 4.067 | eve: 9.002 | bob: 4.030Epoch  18:  67% | abe: 4.067 | eve: 9.002 | bob: 4.029Epoch  18:  68% | abe: 4.066 | eve: 9.002 | bob: 4.028Epoch  18:  69% | abe: 4.065 | eve: 9.002 | bob: 4.028Epoch  18:  70% | abe: 4.065 | eve: 9.002 | bob: 4.027Epoch  18:  71% | abe: 4.064 | eve: 9.001 | bob: 4.027Epoch  18:  71% | abe: 4.063 | eve: 9.002 | bob: 4.026Epoch  18:  72% | abe: 4.063 | eve: 9.002 | bob: 4.025Epoch  18:  73% | abe: 4.062 | eve: 9.002 | bob: 4.024Epoch  18:  74% | abe: 4.061 | eve: 9.001 | bob: 4.024Epoch  18:  75% | abe: 4.060 | eve: 9.001 | bob: 4.023Epoch  18:  75% | abe: 4.060 | eve: 9.002 | bob: 4.022Epoch  18:  76% | abe: 4.059 | eve: 9.001 | bob: 4.022Epoch  18:  77% | abe: 4.059 | eve: 9.001 | bob: 4.021Epoch  18:  78% | abe: 4.058 | eve: 9.002 | bob: 4.021Epoch  18:  78% | abe: 4.057 | eve: 9.002 | bob: 4.020Epoch  18:  79% | abe: 4.057 | eve: 9.002 | bob: 4.019Epoch  18:  80% | abe: 4.056 | eve: 9.002 | bob: 4.019Epoch  18:  81% | abe: 4.056 | eve: 9.002 | bob: 4.018Epoch  18:  82% | abe: 4.055 | eve: 9.002 | bob: 4.018Epoch  18:  82% | abe: 4.055 | eve: 9.002 | bob: 4.017Epoch  18:  83% | abe: 4.054 | eve: 9.002 | bob: 4.017Epoch  18:  84% | abe: 4.054 | eve: 9.002 | bob: 4.016Epoch  18:  85% | abe: 4.053 | eve: 9.002 | bob: 4.015Epoch  18:  85% | abe: 4.053 | eve: 9.002 | bob: 4.015Epoch  18:  86% | abe: 4.052 | eve: 9.001 | bob: 4.014Epoch  18:  87% | abe: 4.051 | eve: 9.001 | bob: 4.013Epoch  18:  88% | abe: 4.051 | eve: 9.001 | bob: 4.013Epoch  18:  89% | abe: 4.050 | eve: 9.002 | bob: 4.012Epoch  18:  89% | abe: 4.050 | eve: 9.001 | bob: 4.012Epoch  18:  90% | abe: 4.049 | eve: 9.002 | bob: 4.011Epoch  18:  91% | abe: 4.048 | eve: 9.002 | bob: 4.010Epoch  18:  92% | abe: 4.047 | eve: 9.002 | bob: 4.010Epoch  18:  92% | abe: 4.047 | eve: 9.001 | bob: 4.009Epoch  18:  93% | abe: 4.046 | eve: 9.001 | bob: 4.009Epoch  18:  94% | abe: 4.046 | eve: 9.001 | bob: 4.008Epoch  18:  95% | abe: 4.045 | eve: 9.001 | bob: 4.007Epoch  18:  96% | abe: 4.045 | eve: 9.001 | bob: 4.007Epoch  18:  96% | abe: 4.044 | eve: 9.001 | bob: 4.006Epoch  18:  97% | abe: 4.043 | eve: 9.001 | bob: 4.006Epoch  18:  98% | abe: 4.043 | eve: 9.001 | bob: 4.005Epoch  18:  99% | abe: 4.042 | eve: 9.001 | bob: 4.004
New best Bob loss 4.004470170921309 at epoch 18
Epoch  19:   0% | abe: 3.985 | eve: 9.010 | bob: 3.949Epoch  19:   0% | abe: 3.973 | eve: 9.011 | bob: 3.934Epoch  19:   1% | abe: 3.966 | eve: 9.000 | bob: 3.928Epoch  19:   2% | abe: 3.957 | eve: 8.994 | bob: 3.917Epoch  19:   3% | abe: 3.960 | eve: 8.995 | bob: 3.920Epoch  19:   3% | abe: 3.960 | eve: 8.989 | bob: 3.920Epoch  19:   4% | abe: 3.963 | eve: 8.994 | bob: 3.923Epoch  19:   5% | abe: 3.966 | eve: 8.995 | bob: 3.927Epoch  19:   6% | abe: 3.965 | eve: 8.998 | bob: 3.926Epoch  19:   7% | abe: 3.965 | eve: 8.998 | bob: 3.927Epoch  19:   7% | abe: 3.968 | eve: 9.000 | bob: 3.928Epoch  19:   8% | abe: 3.967 | eve: 9.002 | bob: 3.927Epoch  19:   9% | abe: 3.964 | eve: 9.001 | bob: 3.925Epoch  19:  10% | abe: 3.965 | eve: 9.001 | bob: 3.925Epoch  19:  10% | abe: 3.964 | eve: 9.002 | bob: 3.924Epoch  19:  11% | abe: 3.962 | eve: 9.001 | bob: 3.923Epoch  19:  12% | abe: 3.961 | eve: 9.002 | bob: 3.922Epoch  19:  13% | abe: 3.958 | eve: 9.001 | bob: 3.919Epoch  19:  14% | abe: 3.958 | eve: 9.000 | bob: 3.919Epoch  19:  14% | abe: 3.958 | eve: 9.003 | bob: 3.920Epoch  19:  15% | abe: 3.958 | eve: 9.004 | bob: 3.920Epoch  19:  16% | abe: 3.958 | eve: 9.003 | bob: 3.920Epoch  19:  17% | abe: 3.957 | eve: 9.003 | bob: 3.920Epoch  19:  17% | abe: 3.958 | eve: 9.003 | bob: 3.920Epoch  19:  18% | abe: 3.957 | eve: 9.000 | bob: 3.920Epoch  19:  19% | abe: 3.956 | eve: 9.000 | bob: 3.919Epoch  19:  20% | abe: 3.955 | eve: 9.001 | bob: 3.917Epoch  19:  21% | abe: 3.956 | eve: 9.001 | bob: 3.917Epoch  19:  21% | abe: 3.955 | eve: 9.000 | bob: 3.917Epoch  19:  22% | abe: 3.955 | eve: 8.999 | bob: 3.917Epoch  19:  23% | abe: 3.954 | eve: 8.999 | bob: 3.916Epoch  19:  24% | abe: 3.953 | eve: 8.999 | bob: 3.915Epoch  19:  25% | abe: 3.953 | eve: 8.998 | bob: 3.915Epoch  19:  25% | abe: 3.952 | eve: 8.999 | bob: 3.915Epoch  19:  26% | abe: 3.953 | eve: 8.999 | bob: 3.915Epoch  19:  27% | abe: 3.951 | eve: 8.999 | bob: 3.914Epoch  19:  28% | abe: 3.950 | eve: 8.998 | bob: 3.913Epoch  19:  28% | abe: 3.950 | eve: 8.997 | bob: 3.912Epoch  19:  29% | abe: 3.949 | eve: 8.997 | bob: 3.912Epoch  19:  30% | abe: 3.949 | eve: 8.997 | bob: 3.912Epoch  19:  31% | abe: 3.948 | eve: 8.997 | bob: 3.911Epoch  19:  32% | abe: 3.947 | eve: 8.996 | bob: 3.910Epoch  19:  32% | abe: 3.947 | eve: 8.996 | bob: 3.909Epoch  19:  33% | abe: 3.946 | eve: 8.996 | bob: 3.908Epoch  19:  34% | abe: 3.945 | eve: 8.996 | bob: 3.908Epoch  19:  35% | abe: 3.946 | eve: 8.996 | bob: 3.908Epoch  19:  35% | abe: 3.945 | eve: 8.997 | bob: 3.908Epoch  19:  36% | abe: 3.945 | eve: 8.997 | bob: 3.907Epoch  19:  37% | abe: 3.944 | eve: 8.997 | bob: 3.907Epoch  19:  38% | abe: 3.944 | eve: 8.997 | bob: 3.907Epoch  19:  39% | abe: 3.943 | eve: 8.998 | bob: 3.906Epoch  19:  39% | abe: 3.943 | eve: 8.998 | bob: 3.906Epoch  19:  40% | abe: 3.943 | eve: 8.998 | bob: 3.905Epoch  19:  41% | abe: 3.942 | eve: 8.997 | bob: 3.905Epoch  19:  42% | abe: 3.942 | eve: 8.997 | bob: 3.905Epoch  19:  42% | abe: 3.942 | eve: 8.997 | bob: 3.904Epoch  19:  43% | abe: 3.941 | eve: 8.997 | bob: 3.904Epoch  19:  44% | abe: 3.941 | eve: 8.997 | bob: 3.903Epoch  19:  45% | abe: 3.940 | eve: 8.997 | bob: 3.903Epoch  19:  46% | abe: 3.940 | eve: 8.998 | bob: 3.903Epoch  19:  46% | abe: 3.939 | eve: 8.999 | bob: 3.902Epoch  19:  47% | abe: 3.938 | eve: 8.999 | bob: 3.901Epoch  19:  48% | abe: 3.938 | eve: 8.999 | bob: 3.901Epoch  19:  49% | abe: 3.937 | eve: 8.999 | bob: 3.900Epoch  19:  50% | abe: 3.937 | eve: 8.999 | bob: 3.900Epoch  19:  50% | abe: 3.936 | eve: 9.000 | bob: 3.899Epoch  19:  51% | abe: 3.936 | eve: 9.000 | bob: 3.899Epoch  19:  52% | abe: 3.935 | eve: 9.000 | bob: 3.898Epoch  19:  53% | abe: 3.934 | eve: 9.000 | bob: 3.897Epoch  19:  53% | abe: 3.934 | eve: 9.000 | bob: 3.897Epoch  19:  54% | abe: 3.933 | eve: 9.000 | bob: 3.896Epoch  19:  55% | abe: 3.933 | eve: 9.000 | bob: 3.896Epoch  19:  56% | abe: 3.933 | eve: 9.000 | bob: 3.896Epoch  19:  57% | abe: 3.932 | eve: 9.000 | bob: 3.895Epoch  19:  57% | abe: 3.932 | eve: 9.000 | bob: 3.895Epoch  19:  58% | abe: 3.931 | eve: 9.000 | bob: 3.895Epoch  19:  59% | abe: 3.931 | eve: 9.001 | bob: 3.894Epoch  19:  60% | abe: 3.930 | eve: 9.001 | bob: 3.893Epoch  19:  60% | abe: 3.929 | eve: 9.000 | bob: 3.893Epoch  19:  61% | abe: 3.929 | eve: 9.000 | bob: 3.892Epoch  19:  62% | abe: 3.928 | eve: 9.001 | bob: 3.892Epoch  19:  63% | abe: 3.927 | eve: 9.000 | bob: 3.891Epoch  19:  64% | abe: 3.927 | eve: 9.001 | bob: 3.890Epoch  19:  64% | abe: 3.926 | eve: 9.001 | bob: 3.890Epoch  19:  65% | abe: 3.926 | eve: 9.000 | bob: 3.889Epoch  19:  66% | abe: 3.925 | eve: 9.000 | bob: 3.889Epoch  19:  67% | abe: 3.925 | eve: 9.000 | bob: 3.888Epoch  19:  67% | abe: 3.924 | eve: 9.000 | bob: 3.887Epoch  19:  68% | abe: 3.923 | eve: 9.000 | bob: 3.887Epoch  19:  69% | abe: 3.923 | eve: 8.999 | bob: 3.886Epoch  19:  70% | abe: 3.923 | eve: 8.999 | bob: 3.886Epoch  19:  71% | abe: 3.922 | eve: 8.999 | bob: 3.885Epoch  19:  71% | abe: 3.922 | eve: 9.000 | bob: 3.885Epoch  19:  72% | abe: 3.921 | eve: 9.000 | bob: 3.885Epoch  19:  73% | abe: 3.920 | eve: 8.999 | bob: 3.884Epoch  19:  74% | abe: 3.920 | eve: 8.999 | bob: 3.884Epoch  19:  75% | abe: 3.920 | eve: 8.999 | bob: 3.883Epoch  19:  75% | abe: 3.919 | eve: 8.999 | bob: 3.882Epoch  19:  76% | abe: 3.918 | eve: 8.999 | bob: 3.881Epoch  19:  77% | abe: 3.918 | eve: 8.999 | bob: 3.881Epoch  19:  78% | abe: 3.917 | eve: 8.999 | bob: 3.881Epoch  19:  78% | abe: 3.917 | eve: 8.999 | bob: 3.880Epoch  19:  79% | abe: 3.916 | eve: 9.000 | bob: 3.880Epoch  19:  80% | abe: 3.915 | eve: 9.000 | bob: 3.879Epoch  19:  81% | abe: 3.915 | eve: 8.999 | bob: 3.878Epoch  19:  82% | abe: 3.914 | eve: 8.999 | bob: 3.878Epoch  19:  82% | abe: 3.914 | eve: 8.999 | bob: 3.877Epoch  19:  83% | abe: 3.913 | eve: 8.999 | bob: 3.877Epoch  19:  84% | abe: 3.912 | eve: 8.999 | bob: 3.876Epoch  19:  85% | abe: 3.912 | eve: 8.999 | bob: 3.875Epoch  19:  85% | abe: 3.911 | eve: 8.999 | bob: 3.875Epoch  19:  86% | abe: 3.911 | eve: 8.998 | bob: 3.874Epoch  19:  87% | abe: 3.910 | eve: 8.999 | bob: 3.874Epoch  19:  88% | abe: 3.910 | eve: 8.999 | bob: 3.873Epoch  19:  89% | abe: 3.909 | eve: 8.999 | bob: 3.873Epoch  19:  89% | abe: 3.909 | eve: 8.999 | bob: 3.872Epoch  19:  90% | abe: 3.908 | eve: 8.999 | bob: 3.872Epoch  19:  91% | abe: 3.908 | eve: 8.999 | bob: 3.871Epoch  19:  92% | abe: 3.907 | eve: 8.999 | bob: 3.871Epoch  19:  92% | abe: 3.907 | eve: 8.999 | bob: 3.870Epoch  19:  93% | abe: 3.906 | eve: 8.999 | bob: 3.870Epoch  19:  94% | abe: 3.906 | eve: 8.999 | bob: 3.869Epoch  19:  95% | abe: 3.905 | eve: 8.999 | bob: 3.869Epoch  19:  96% | abe: 3.904 | eve: 8.999 | bob: 3.868Epoch  19:  96% | abe: 3.903 | eve: 9.000 | bob: 3.867Epoch  19:  97% | abe: 3.903 | eve: 9.000 | bob: 3.866Epoch  19:  98% | abe: 3.902 | eve: 9.000 | bob: 3.866Epoch  19:  99% | abe: 3.902 | eve: 9.000 | bob: 3.865
New best Bob loss 3.8653538174310142 at epoch 19
Epoch  20:   0% | abe: 3.832 | eve: 8.990 | bob: 3.797Epoch  20:   0% | abe: 3.839 | eve: 8.986 | bob: 3.807Epoch  20:   1% | abe: 3.837 | eve: 8.978 | bob: 3.802Epoch  20:   2% | abe: 3.826 | eve: 8.981 | bob: 3.790Epoch  20:   3% | abe: 3.829 | eve: 8.990 | bob: 3.792Epoch  20:   3% | abe: 3.829 | eve: 8.992 | bob: 3.793Epoch  20:   4% | abe: 3.825 | eve: 8.994 | bob: 3.790Epoch  20:   5% | abe: 3.826 | eve: 8.995 | bob: 3.791Epoch  20:   6% | abe: 3.828 | eve: 8.996 | bob: 3.793Epoch  20:   7% | abe: 3.825 | eve: 8.997 | bob: 3.789Epoch  20:   7% | abe: 3.826 | eve: 8.995 | bob: 3.790Epoch  20:   8% | abe: 3.823 | eve: 8.996 | bob: 3.787Epoch  20:   9% | abe: 3.822 | eve: 8.997 | bob: 3.786Epoch  20:  10% | abe: 3.823 | eve: 8.998 | bob: 3.786Epoch  20:  10% | abe: 3.822 | eve: 9.001 | bob: 3.786Epoch  20:  11% | abe: 3.822 | eve: 9.000 | bob: 3.786Epoch  20:  12% | abe: 3.822 | eve: 9.001 | bob: 3.787Epoch  20:  13% | abe: 3.822 | eve: 9.001 | bob: 3.786Epoch  20:  14% | abe: 3.821 | eve: 9.001 | bob: 3.786Epoch  20:  14% | abe: 3.821 | eve: 9.000 | bob: 3.785Epoch  20:  15% | abe: 3.821 | eve: 8.999 | bob: 3.785Epoch  20:  16% | abe: 3.821 | eve: 8.998 | bob: 3.785Epoch  20:  17% | abe: 3.820 | eve: 8.999 | bob: 3.784Epoch  20:  17% | abe: 3.819 | eve: 8.999 | bob: 3.783Epoch  20:  18% | abe: 3.820 | eve: 8.998 | bob: 3.784Epoch  20:  19% | abe: 3.819 | eve: 8.996 | bob: 3.783Epoch  20:  20% | abe: 3.819 | eve: 8.997 | bob: 3.783Epoch  20:  21% | abe: 3.818 | eve: 8.997 | bob: 3.782Epoch  20:  21% | abe: 3.819 | eve: 8.997 | bob: 3.783Epoch  20:  22% | abe: 3.819 | eve: 8.996 | bob: 3.783Epoch  20:  23% | abe: 3.818 | eve: 8.997 | bob: 3.782Epoch  20:  24% | abe: 3.817 | eve: 8.997 | bob: 3.782Epoch  20:  25% | abe: 3.817 | eve: 8.997 | bob: 3.781Epoch  20:  25% | abe: 3.816 | eve: 8.997 | bob: 3.780Epoch  20:  26% | abe: 3.817 | eve: 8.998 | bob: 3.781Epoch  20:  27% | abe: 3.816 | eve: 8.998 | bob: 3.780Epoch  20:  28% | abe: 3.815 | eve: 8.997 | bob: 3.779Epoch  20:  28% | abe: 3.815 | eve: 8.998 | bob: 3.779Epoch  20:  29% | abe: 3.815 | eve: 8.998 | bob: 3.779Epoch  20:  30% | abe: 3.814 | eve: 8.998 | bob: 3.779Epoch  20:  31% | abe: 3.814 | eve: 8.998 | bob: 3.778Epoch  20:  32% | abe: 3.813 | eve: 8.997 | bob: 3.778Epoch  20:  32% | abe: 3.813 | eve: 8.997 | bob: 3.777Epoch  20:  33% | abe: 3.812 | eve: 8.996 | bob: 3.776Epoch  20:  34% | abe: 3.811 | eve: 8.996 | bob: 3.775Epoch  20:  35% | abe: 3.810 | eve: 8.996 | bob: 3.774Epoch  20:  35% | abe: 3.809 | eve: 8.997 | bob: 3.773Epoch  20:  36% | abe: 3.808 | eve: 8.997 | bob: 3.773Epoch  20:  37% | abe: 3.807 | eve: 8.996 | bob: 3.772Epoch  20:  38% | abe: 3.807 | eve: 8.997 | bob: 3.771Epoch  20:  39% | abe: 3.806 | eve: 8.997 | bob: 3.771Epoch  20:  39% | abe: 3.806 | eve: 8.997 | bob: 3.770Epoch  20:  40% | abe: 3.805 | eve: 8.997 | bob: 3.769Epoch  20:  41% | abe: 3.805 | eve: 8.996 | bob: 3.769Epoch  20:  42% | abe: 3.804 | eve: 8.996 | bob: 3.768Epoch  20:  42% | abe: 3.804 | eve: 8.996 | bob: 3.768Epoch  20:  43% | abe: 3.804 | eve: 8.996 | bob: 3.768Epoch  20:  44% | abe: 3.803 | eve: 8.996 | bob: 3.767Epoch  20:  45% | abe: 3.803 | eve: 8.996 | bob: 3.767Epoch  20:  46% | abe: 3.802 | eve: 8.996 | bob: 3.766Epoch  20:  46% | abe: 3.802 | eve: 8.996 | bob: 3.766Epoch  20:  47% | abe: 3.802 | eve: 8.996 | bob: 3.766Epoch  20:  48% | abe: 3.801 | eve: 8.996 | bob: 3.765Epoch  20:  49% | abe: 3.801 | eve: 8.996 | bob: 3.765Epoch  20:  50% | abe: 3.800 | eve: 8.996 | bob: 3.764Epoch  20:  50% | abe: 3.800 | eve: 8.996 | bob: 3.764Epoch  20:  51% | abe: 3.800 | eve: 8.996 | bob: 3.763Epoch  20:  52% | abe: 3.800 | eve: 8.996 | bob: 3.763Epoch  20:  53% | abe: 3.799 | eve: 8.996 | bob: 3.762Epoch  20:  53% | abe: 3.798 | eve: 8.996 | bob: 3.762Epoch  20:  54% | abe: 3.798 | eve: 8.996 | bob: 3.762Epoch  20:  55% | abe: 3.798 | eve: 8.996 | bob: 3.762Epoch  20:  56% | abe: 3.797 | eve: 8.996 | bob: 3.761Epoch  20:  57% | abe: 3.796 | eve: 8.997 | bob: 3.760Epoch  20:  57% | abe: 3.796 | eve: 8.996 | bob: 3.760Epoch  20:  58% | abe: 3.795 | eve: 8.996 | bob: 3.759Epoch  20:  59% | abe: 3.794 | eve: 8.996 | bob: 3.759Epoch  20:  60% | abe: 3.793 | eve: 8.996 | bob: 3.757Epoch  20:  60% | abe: 3.793 | eve: 8.997 | bob: 3.757Epoch  20:  61% | abe: 3.792 | eve: 8.997 | bob: 3.756Epoch  20:  62% | abe: 3.791 | eve: 8.997 | bob: 3.755Epoch  20:  63% | abe: 3.791 | eve: 8.997 | bob: 3.755Epoch  20:  64% | abe: 3.791 | eve: 8.997 | bob: 3.755Epoch  20:  64% | abe: 3.790 | eve: 8.997 | bob: 3.754Epoch  20:  65% | abe: 3.790 | eve: 8.997 | bob: 3.754Epoch  20:  66% | abe: 3.789 | eve: 8.997 | bob: 3.753Epoch  20:  67% | abe: 3.789 | eve: 8.997 | bob: 3.753Epoch  20:  67% | abe: 3.788 | eve: 8.997 | bob: 3.752Epoch  20:  68% | abe: 3.788 | eve: 8.997 | bob: 3.752Epoch  20:  69% | abe: 3.787 | eve: 8.997 | bob: 3.751Epoch  20:  70% | abe: 3.787 | eve: 8.997 | bob: 3.751Epoch  20:  71% | abe: 3.786 | eve: 8.997 | bob: 3.750Epoch  20:  71% | abe: 3.786 | eve: 8.997 | bob: 3.750Epoch  20:  72% | abe: 3.785 | eve: 8.997 | bob: 3.750Epoch  20:  73% | abe: 3.784 | eve: 8.997 | bob: 3.749Epoch  20:  74% | abe: 3.784 | eve: 8.998 | bob: 3.748Epoch  20:  75% | abe: 3.783 | eve: 8.998 | bob: 3.748Epoch  20:  75% | abe: 3.783 | eve: 8.997 | bob: 3.748Epoch  20:  76% | abe: 3.783 | eve: 8.998 | bob: 3.747Epoch  20:  77% | abe: 3.782 | eve: 8.997 | bob: 3.747Epoch  20:  78% | abe: 3.782 | eve: 8.997 | bob: 3.746Epoch  20:  78% | abe: 3.781 | eve: 8.998 | bob: 3.746Epoch  20:  79% | abe: 3.781 | eve: 8.998 | bob: 3.745Epoch  20:  80% | abe: 3.780 | eve: 8.998 | bob: 3.745Epoch  20:  81% | abe: 3.780 | eve: 8.998 | bob: 3.744Epoch  20:  82% | abe: 3.779 | eve: 8.998 | bob: 3.744Epoch  20:  82% | abe: 3.778 | eve: 8.997 | bob: 3.743Epoch  20:  83% | abe: 3.778 | eve: 8.997 | bob: 3.743Epoch  20:  84% | abe: 3.777 | eve: 8.997 | bob: 3.742Epoch  20:  85% | abe: 3.777 | eve: 8.997 | bob: 3.741Epoch  20:  85% | abe: 3.776 | eve: 8.997 | bob: 3.741Epoch  20:  86% | abe: 3.775 | eve: 8.998 | bob: 3.740Epoch  20:  87% | abe: 3.775 | eve: 8.998 | bob: 3.740Epoch  20:  88% | abe: 3.775 | eve: 8.998 | bob: 3.740Epoch  20:  89% | abe: 3.774 | eve: 8.998 | bob: 3.739Epoch  20:  89% | abe: 3.774 | eve: 8.997 | bob: 3.739Epoch  20:  90% | abe: 3.773 | eve: 8.997 | bob: 3.738Epoch  20:  91% | abe: 3.773 | eve: 8.997 | bob: 3.738Epoch  20:  92% | abe: 3.772 | eve: 8.997 | bob: 3.737Epoch  20:  92% | abe: 3.772 | eve: 8.997 | bob: 3.737Epoch  20:  93% | abe: 3.771 | eve: 8.997 | bob: 3.736Epoch  20:  94% | abe: 3.771 | eve: 8.997 | bob: 3.736Epoch  20:  95% | abe: 3.770 | eve: 8.997 | bob: 3.735Epoch  20:  96% | abe: 3.770 | eve: 8.997 | bob: 3.735Epoch  20:  96% | abe: 3.769 | eve: 8.997 | bob: 3.734Epoch  20:  97% | abe: 3.769 | eve: 8.997 | bob: 3.734Epoch  20:  98% | abe: 3.768 | eve: 8.997 | bob: 3.733Epoch  20:  99% | abe: 3.768 | eve: 8.998 | bob: 3.733
New best Bob loss 3.7326337758354384 at epoch 20
Epoch  21:   0% | abe: 3.729 | eve: 8.982 | bob: 3.693Epoch  21:   0% | abe: 3.721 | eve: 9.017 | bob: 3.686Epoch  21:   1% | abe: 3.716 | eve: 9.002 | bob: 3.684Epoch  21:   2% | abe: 3.708 | eve: 9.005 | bob: 3.677Epoch  21:   3% | abe: 3.709 | eve: 9.008 | bob: 3.678Epoch  21:   3% | abe: 3.706 | eve: 9.002 | bob: 3.674Epoch  21:   4% | abe: 3.705 | eve: 9.005 | bob: 3.673Epoch  21:   5% | abe: 3.701 | eve: 9.006 | bob: 3.669Epoch  21:   6% | abe: 3.701 | eve: 9.006 | bob: 3.669Epoch  21:   7% | abe: 3.701 | eve: 9.006 | bob: 3.668Epoch  21:   7% | abe: 3.703 | eve: 9.005 | bob: 3.670Epoch  21:   8% | abe: 3.702 | eve: 9.002 | bob: 3.669Epoch  21:   9% | abe: 3.702 | eve: 9.000 | bob: 3.670Epoch  21:  10% | abe: 3.702 | eve: 8.998 | bob: 3.670Epoch  21:  10% | abe: 3.702 | eve: 8.998 | bob: 3.670Epoch  21:  11% | abe: 3.703 | eve: 8.997 | bob: 3.671Epoch  21:  12% | abe: 3.702 | eve: 8.997 | bob: 3.670Epoch  21:  13% | abe: 3.702 | eve: 8.999 | bob: 3.670Epoch  21:  14% | abe: 3.703 | eve: 9.001 | bob: 3.671Epoch  21:  14% | abe: 3.702 | eve: 9.001 | bob: 3.670Epoch  21:  15% | abe: 3.702 | eve: 9.000 | bob: 3.670Epoch  21:  16% | abe: 3.701 | eve: 9.002 | bob: 3.669Epoch  21:  17% | abe: 3.701 | eve: 9.002 | bob: 3.669Epoch  21:  17% | abe: 3.699 | eve: 9.002 | bob: 3.667Epoch  21:  18% | abe: 3.699 | eve: 9.002 | bob: 3.667Epoch  21:  19% | abe: 3.699 | eve: 9.002 | bob: 3.667Epoch  21:  20% | abe: 3.698 | eve: 9.001 | bob: 3.666Epoch  21:  21% | abe: 3.698 | eve: 9.000 | bob: 3.666Epoch  21:  21% | abe: 3.697 | eve: 9.000 | bob: 3.665Epoch  21:  22% | abe: 3.696 | eve: 9.000 | bob: 3.664Epoch  21:  23% | abe: 3.695 | eve: 9.000 | bob: 3.663Epoch  21:  24% | abe: 3.695 | eve: 9.000 | bob: 3.663Epoch  21:  25% | abe: 3.695 | eve: 8.999 | bob: 3.663Epoch  21:  25% | abe: 3.693 | eve: 8.999 | bob: 3.661Epoch  21:  26% | abe: 3.692 | eve: 8.998 | bob: 3.660Epoch  21:  27% | abe: 3.692 | eve: 8.999 | bob: 3.660Epoch  21:  28% | abe: 3.691 | eve: 9.000 | bob: 3.658Epoch  21:  28% | abe: 3.690 | eve: 9.001 | bob: 3.658Epoch  21:  29% | abe: 3.690 | eve: 9.000 | bob: 3.657Epoch  21:  30% | abe: 3.690 | eve: 9.001 | bob: 3.657Epoch  21:  31% | abe: 3.689 | eve: 9.000 | bob: 3.656Epoch  21:  32% | abe: 3.688 | eve: 9.000 | bob: 3.656Epoch  21:  32% | abe: 3.688 | eve: 9.000 | bob: 3.655Epoch  21:  33% | abe: 3.687 | eve: 9.000 | bob: 3.655Epoch  21:  34% | abe: 3.687 | eve: 9.001 | bob: 3.655Epoch  21:  35% | abe: 3.686 | eve: 9.000 | bob: 3.654Epoch  21:  35% | abe: 3.686 | eve: 9.000 | bob: 3.654Epoch  21:  36% | abe: 3.685 | eve: 9.001 | bob: 3.653Epoch  21:  37% | abe: 3.685 | eve: 9.001 | bob: 3.653Epoch  21:  38% | abe: 3.685 | eve: 9.001 | bob: 3.653Epoch  21:  39% | abe: 3.684 | eve: 9.002 | bob: 3.653Epoch  21:  39% | abe: 3.684 | eve: 9.002 | bob: 3.652Epoch  21:  40% | abe: 3.683 | eve: 9.002 | bob: 3.652Epoch  21:  41% | abe: 3.683 | eve: 9.002 | bob: 3.651Epoch  21:  42% | abe: 3.682 | eve: 9.001 | bob: 3.651Epoch  21:  42% | abe: 3.682 | eve: 9.003 | bob: 3.650Epoch  21:  43% | abe: 3.681 | eve: 9.002 | bob: 3.650Epoch  21:  44% | abe: 3.681 | eve: 9.002 | bob: 3.649Epoch  21:  45% | abe: 3.681 | eve: 9.001 | bob: 3.649Epoch  21:  46% | abe: 3.680 | eve: 9.001 | bob: 3.649Epoch  21:  46% | abe: 3.680 | eve: 9.001 | bob: 3.648Epoch  21:  47% | abe: 3.680 | eve: 9.001 | bob: 3.648Epoch  21:  48% | abe: 3.679 | eve: 9.000 | bob: 3.648Epoch  21:  49% | abe: 3.679 | eve: 9.000 | bob: 3.647Epoch  21:  50% | abe: 3.679 | eve: 9.001 | bob: 3.647Epoch  21:  50% | abe: 3.678 | eve: 9.001 | bob: 3.647Epoch  21:  51% | abe: 3.677 | eve: 9.001 | bob: 3.646Epoch  21:  52% | abe: 3.677 | eve: 9.001 | bob: 3.645Epoch  21:  53% | abe: 3.677 | eve: 9.001 | bob: 3.645Epoch  21:  53% | abe: 3.676 | eve: 9.001 | bob: 3.645Epoch  21:  54% | abe: 3.676 | eve: 9.001 | bob: 3.644Epoch  21:  55% | abe: 3.675 | eve: 9.001 | bob: 3.644Epoch  21:  56% | abe: 3.674 | eve: 9.002 | bob: 3.643Epoch  21:  57% | abe: 3.674 | eve: 9.002 | bob: 3.642Epoch  21:  57% | abe: 3.674 | eve: 9.002 | bob: 3.642Epoch  21:  58% | abe: 3.673 | eve: 9.002 | bob: 3.641Epoch  21:  59% | abe: 3.673 | eve: 9.001 | bob: 3.641Epoch  21:  60% | abe: 3.672 | eve: 9.002 | bob: 3.641Epoch  21:  60% | abe: 3.672 | eve: 9.002 | bob: 3.640Epoch  21:  61% | abe: 3.671 | eve: 9.002 | bob: 3.639Epoch  21:  62% | abe: 3.671 | eve: 9.002 | bob: 3.639Epoch  21:  63% | abe: 3.670 | eve: 9.002 | bob: 3.639Epoch  21:  64% | abe: 3.670 | eve: 9.002 | bob: 3.638Epoch  21:  64% | abe: 3.670 | eve: 9.002 | bob: 3.638Epoch  21:  65% | abe: 3.670 | eve: 9.001 | bob: 3.638Epoch  21:  66% | abe: 3.669 | eve: 9.001 | bob: 3.637Epoch  21:  67% | abe: 3.669 | eve: 9.001 | bob: 3.637Epoch  21:  67% | abe: 3.668 | eve: 9.001 | bob: 3.636Epoch  21:  68% | abe: 3.668 | eve: 9.001 | bob: 3.636Epoch  21:  69% | abe: 3.668 | eve: 9.001 | bob: 3.636Epoch  21:  70% | abe: 3.667 | eve: 9.001 | bob: 3.635Epoch  21:  71% | abe: 3.666 | eve: 9.002 | bob: 3.634Epoch  21:  71% | abe: 3.666 | eve: 9.001 | bob: 3.634Epoch  21:  72% | abe: 3.665 | eve: 9.001 | bob: 3.633Epoch  21:  73% | abe: 3.665 | eve: 9.001 | bob: 3.633Epoch  21:  74% | abe: 3.664 | eve: 9.001 | bob: 3.632Epoch  21:  75% | abe: 3.663 | eve: 9.002 | bob: 3.631Epoch  21:  75% | abe: 3.663 | eve: 9.002 | bob: 3.631Epoch  21:  76% | abe: 3.662 | eve: 9.002 | bob: 3.630Epoch  21:  77% | abe: 3.661 | eve: 9.002 | bob: 3.629Epoch  21:  78% | abe: 3.661 | eve: 9.002 | bob: 3.629Epoch  21:  78% | abe: 3.661 | eve: 9.002 | bob: 3.629Epoch  21:  79% | abe: 3.660 | eve: 9.002 | bob: 3.628Epoch  21:  80% | abe: 3.660 | eve: 9.001 | bob: 3.628Epoch  21:  81% | abe: 3.659 | eve: 9.001 | bob: 3.627Epoch  21:  82% | abe: 3.658 | eve: 9.001 | bob: 3.626Epoch  21:  82% | abe: 3.658 | eve: 9.001 | bob: 3.626Epoch  21:  83% | abe: 3.658 | eve: 9.001 | bob: 3.626Epoch  21:  84% | abe: 3.657 | eve: 9.001 | bob: 3.625Epoch  21:  85% | abe: 3.657 | eve: 9.000 | bob: 3.625Epoch  21:  85% | abe: 3.656 | eve: 9.000 | bob: 3.624Epoch  21:  86% | abe: 3.656 | eve: 9.000 | bob: 3.624Epoch  21:  87% | abe: 3.655 | eve: 9.000 | bob: 3.623Epoch  21:  88% | abe: 3.654 | eve: 9.000 | bob: 3.622Epoch  21:  89% | abe: 3.653 | eve: 9.000 | bob: 3.622Epoch  21:  89% | abe: 3.653 | eve: 9.000 | bob: 3.621Epoch  21:  90% | abe: 3.653 | eve: 9.000 | bob: 3.621Epoch  21:  91% | abe: 3.652 | eve: 9.000 | bob: 3.620Epoch  21:  92% | abe: 3.651 | eve: 9.000 | bob: 3.619Epoch  21:  92% | abe: 3.651 | eve: 9.000 | bob: 3.619Epoch  21:  93% | abe: 3.651 | eve: 9.000 | bob: 3.619Epoch  21:  94% | abe: 3.650 | eve: 9.000 | bob: 3.618Epoch  21:  95% | abe: 3.649 | eve: 9.000 | bob: 3.618Epoch  21:  96% | abe: 3.649 | eve: 9.000 | bob: 3.617Epoch  21:  96% | abe: 3.649 | eve: 9.000 | bob: 3.617Epoch  21:  97% | abe: 3.648 | eve: 9.000 | bob: 3.617Epoch  21:  98% | abe: 3.648 | eve: 9.000 | bob: 3.616Epoch  21:  99% | abe: 3.647 | eve: 9.000 | bob: 3.615
New best Bob loss 3.6154408925101507 at epoch 21
Epoch  22:   0% | abe: 3.585 | eve: 9.017 | bob: 3.555Epoch  22:   0% | abe: 3.583 | eve: 8.993 | bob: 3.550Epoch  22:   1% | abe: 3.575 | eve: 8.989 | bob: 3.542Epoch  22:   2% | abe: 3.574 | eve: 8.997 | bob: 3.541Epoch  22:   3% | abe: 3.578 | eve: 8.994 | bob: 3.544Epoch  22:   3% | abe: 3.578 | eve: 8.994 | bob: 3.543Epoch  22:   4% | abe: 3.574 | eve: 8.996 | bob: 3.538Epoch  22:   5% | abe: 3.578 | eve: 9.002 | bob: 3.543Epoch  22:   6% | abe: 3.578 | eve: 9.001 | bob: 3.544Epoch  22:   7% | abe: 3.579 | eve: 8.999 | bob: 3.546Epoch  22:   7% | abe: 3.579 | eve: 9.000 | bob: 3.546Epoch  22:   8% | abe: 3.577 | eve: 9.001 | bob: 3.543Epoch  22:   9% | abe: 3.578 | eve: 9.001 | bob: 3.545Epoch  22:  10% | abe: 3.580 | eve: 9.000 | bob: 3.547Epoch  22:  10% | abe: 3.580 | eve: 9.000 | bob: 3.547Epoch  22:  11% | abe: 3.579 | eve: 9.000 | bob: 3.546Epoch  22:  12% | abe: 3.579 | eve: 9.002 | bob: 3.545Epoch  22:  13% | abe: 3.577 | eve: 9.002 | bob: 3.544Epoch  22:  14% | abe: 3.577 | eve: 9.000 | bob: 3.543Epoch  22:  14% | abe: 3.577 | eve: 9.000 | bob: 3.543Epoch  22:  15% | abe: 3.577 | eve: 9.000 | bob: 3.543Epoch  22:  16% | abe: 3.577 | eve: 8.998 | bob: 3.544Epoch  22:  17% | abe: 3.577 | eve: 8.998 | bob: 3.544Epoch  22:  17% | abe: 3.576 | eve: 8.998 | bob: 3.542Epoch  22:  18% | abe: 3.575 | eve: 8.998 | bob: 3.542Epoch  22:  19% | abe: 3.576 | eve: 9.000 | bob: 3.543Epoch  22:  20% | abe: 3.575 | eve: 8.999 | bob: 3.542Epoch  22:  21% | abe: 3.574 | eve: 8.999 | bob: 3.542Epoch  22:  21% | abe: 3.574 | eve: 8.996 | bob: 3.542Epoch  22:  22% | abe: 3.574 | eve: 8.996 | bob: 3.541Epoch  22:  23% | abe: 3.572 | eve: 8.997 | bob: 3.540Epoch  22:  24% | abe: 3.571 | eve: 8.997 | bob: 3.539Epoch  22:  25% | abe: 3.571 | eve: 8.996 | bob: 3.538Epoch  22:  25% | abe: 3.570 | eve: 8.997 | bob: 3.538Epoch  22:  26% | abe: 3.570 | eve: 8.997 | bob: 3.538Epoch  22:  27% | abe: 3.571 | eve: 8.996 | bob: 3.538Epoch  22:  28% | abe: 3.571 | eve: 8.997 | bob: 3.539Epoch  22:  28% | abe: 3.570 | eve: 8.997 | bob: 3.538Epoch  22:  29% | abe: 3.570 | eve: 8.996 | bob: 3.538Epoch  22:  30% | abe: 3.569 | eve: 8.997 | bob: 3.537Epoch  22:  31% | abe: 3.569 | eve: 8.997 | bob: 3.537Epoch  22:  32% | abe: 3.568 | eve: 8.997 | bob: 3.536Epoch  22:  32% | abe: 3.567 | eve: 8.998 | bob: 3.535Epoch  22:  33% | abe: 3.567 | eve: 8.999 | bob: 3.535Epoch  22:  34% | abe: 3.566 | eve: 8.998 | bob: 3.534Epoch  22:  35% | abe: 3.566 | eve: 8.998 | bob: 3.533Epoch  22:  35% | abe: 3.565 | eve: 8.998 | bob: 3.533Epoch  22:  36% | abe: 3.564 | eve: 8.998 | bob: 3.532Epoch  22:  37% | abe: 3.564 | eve: 8.998 | bob: 3.532Epoch  22:  38% | abe: 3.564 | eve: 8.998 | bob: 3.532Epoch  22:  39% | abe: 3.563 | eve: 8.998 | bob: 3.532Epoch  22:  39% | abe: 3.562 | eve: 8.998 | bob: 3.531Epoch  22:  40% | abe: 3.562 | eve: 8.998 | bob: 3.530Epoch  22:  41% | abe: 3.561 | eve: 8.998 | bob: 3.530Epoch  22:  42% | abe: 3.561 | eve: 8.997 | bob: 3.529Epoch  22:  42% | abe: 3.560 | eve: 8.998 | bob: 3.528Epoch  22:  43% | abe: 3.559 | eve: 8.998 | bob: 3.528Epoch  22:  44% | abe: 3.559 | eve: 8.997 | bob: 3.527Epoch  22:  45% | abe: 3.558 | eve: 8.996 | bob: 3.526Epoch  22:  46% | abe: 3.558 | eve: 8.996 | bob: 3.526Epoch  22:  46% | abe: 3.557 | eve: 8.996 | bob: 3.526Epoch  22:  47% | abe: 3.557 | eve: 8.996 | bob: 3.526Epoch  22:  48% | abe: 3.557 | eve: 8.997 | bob: 3.525Epoch  22:  49% | abe: 3.556 | eve: 8.997 | bob: 3.525Epoch  22:  50% | abe: 3.555 | eve: 8.996 | bob: 3.524Epoch  22:  50% | abe: 3.555 | eve: 8.996 | bob: 3.524Epoch  22:  51% | abe: 3.554 | eve: 8.996 | bob: 3.523Epoch  22:  52% | abe: 3.554 | eve: 8.997 | bob: 3.523Epoch  22:  53% | abe: 3.554 | eve: 8.997 | bob: 3.523Epoch  22:  53% | abe: 3.553 | eve: 8.998 | bob: 3.523Epoch  22:  54% | abe: 3.553 | eve: 8.998 | bob: 3.523Epoch  22:  55% | abe: 3.553 | eve: 8.998 | bob: 3.522Epoch  22:  56% | abe: 3.552 | eve: 8.997 | bob: 3.521Epoch  22:  57% | abe: 3.552 | eve: 8.998 | bob: 3.521Epoch  22:  57% | abe: 3.551 | eve: 8.998 | bob: 3.521Epoch  22:  58% | abe: 3.551 | eve: 8.998 | bob: 3.521Epoch  22:  59% | abe: 3.551 | eve: 8.998 | bob: 3.520Epoch  22:  60% | abe: 3.551 | eve: 8.998 | bob: 3.520Epoch  22:  60% | abe: 3.550 | eve: 8.998 | bob: 3.520Epoch  22:  61% | abe: 3.549 | eve: 8.998 | bob: 3.519Epoch  22:  62% | abe: 3.549 | eve: 8.998 | bob: 3.519Epoch  22:  63% | abe: 3.549 | eve: 8.999 | bob: 3.518Epoch  22:  64% | abe: 3.548 | eve: 8.999 | bob: 3.518Epoch  22:  64% | abe: 3.548 | eve: 8.999 | bob: 3.517Epoch  22:  65% | abe: 3.547 | eve: 8.999 | bob: 3.517Epoch  22:  66% | abe: 3.547 | eve: 8.999 | bob: 3.517Epoch  22:  67% | abe: 3.547 | eve: 8.998 | bob: 3.517Epoch  22:  67% | abe: 3.546 | eve: 8.999 | bob: 3.516Epoch  22:  68% | abe: 3.546 | eve: 8.999 | bob: 3.516Epoch  22:  69% | abe: 3.545 | eve: 8.998 | bob: 3.515Epoch  22:  70% | abe: 3.545 | eve: 8.998 | bob: 3.515Epoch  22:  71% | abe: 3.545 | eve: 8.998 | bob: 3.515Epoch  22:  71% | abe: 3.544 | eve: 8.998 | bob: 3.514Epoch  22:  72% | abe: 3.544 | eve: 8.998 | bob: 3.514Epoch  22:  73% | abe: 3.543 | eve: 8.998 | bob: 3.513Epoch  22:  74% | abe: 3.542 | eve: 8.998 | bob: 3.512Epoch  22:  75% | abe: 3.542 | eve: 8.998 | bob: 3.512Epoch  22:  75% | abe: 3.541 | eve: 8.998 | bob: 3.511Epoch  22:  76% | abe: 3.540 | eve: 8.997 | bob: 3.510Epoch  22:  77% | abe: 3.540 | eve: 8.997 | bob: 3.510Epoch  22:  78% | abe: 3.539 | eve: 8.998 | bob: 3.509Epoch  22:  78% | abe: 3.539 | eve: 8.997 | bob: 3.509Epoch  22:  79% | abe: 3.538 | eve: 8.997 | bob: 3.508Epoch  22:  80% | abe: 3.538 | eve: 8.997 | bob: 3.508Epoch  22:  81% | abe: 3.537 | eve: 8.997 | bob: 3.507Epoch  22:  82% | abe: 3.536 | eve: 8.997 | bob: 3.507Epoch  22:  82% | abe: 3.536 | eve: 8.997 | bob: 3.506Epoch  22:  83% | abe: 3.536 | eve: 8.997 | bob: 3.506Epoch  22:  84% | abe: 3.535 | eve: 8.997 | bob: 3.506Epoch  22:  85% | abe: 3.535 | eve: 8.997 | bob: 3.505Epoch  22:  85% | abe: 3.534 | eve: 8.997 | bob: 3.504Epoch  22:  86% | abe: 3.534 | eve: 8.997 | bob: 3.504Epoch  22:  87% | abe: 3.533 | eve: 8.997 | bob: 3.504Epoch  22:  88% | abe: 3.533 | eve: 8.997 | bob: 3.503Epoch  22:  89% | abe: 3.532 | eve: 8.997 | bob: 3.503Epoch  22:  89% | abe: 3.532 | eve: 8.997 | bob: 3.502Epoch  22:  90% | abe: 3.532 | eve: 8.997 | bob: 3.502Epoch  22:  91% | abe: 3.531 | eve: 8.997 | bob: 3.502Epoch  22:  92% | abe: 3.531 | eve: 8.997 | bob: 3.501Epoch  22:  92% | abe: 3.530 | eve: 8.997 | bob: 3.501Epoch  22:  93% | abe: 3.530 | eve: 8.997 | bob: 3.500Epoch  22:  94% | abe: 3.529 | eve: 8.997 | bob: 3.500Epoch  22:  95% | abe: 3.529 | eve: 8.997 | bob: 3.499Epoch  22:  96% | abe: 3.528 | eve: 8.997 | bob: 3.499Epoch  22:  96% | abe: 3.528 | eve: 8.997 | bob: 3.498Epoch  22:  97% | abe: 3.527 | eve: 8.997 | bob: 3.498Epoch  22:  98% | abe: 3.527 | eve: 8.997 | bob: 3.498Epoch  22:  99% | abe: 3.527 | eve: 8.997 | bob: 3.497
New best Bob loss 3.497390395538332 at epoch 22
Epoch  23:   0% | abe: 3.485 | eve: 8.971 | bob: 3.449Epoch  23:   0% | abe: 3.474 | eve: 8.999 | bob: 3.438Epoch  23:   1% | abe: 3.466 | eve: 8.995 | bob: 3.429Epoch  23:   2% | abe: 3.457 | eve: 8.991 | bob: 3.422Epoch  23:   3% | abe: 3.458 | eve: 8.996 | bob: 3.423Epoch  23:   3% | abe: 3.458 | eve: 8.994 | bob: 3.424Epoch  23:   4% | abe: 3.455 | eve: 8.995 | bob: 3.422Epoch  23:   5% | abe: 3.455 | eve: 8.996 | bob: 3.423Epoch  23:   6% | abe: 3.455 | eve: 8.999 | bob: 3.424Epoch  23:   7% | abe: 3.455 | eve: 8.999 | bob: 3.425Epoch  23:   7% | abe: 3.456 | eve: 8.999 | bob: 3.426Epoch  23:   8% | abe: 3.458 | eve: 9.000 | bob: 3.428Epoch  23:   9% | abe: 3.457 | eve: 9.000 | bob: 3.427Epoch  23:  10% | abe: 3.457 | eve: 8.997 | bob: 3.427Epoch  23:  10% | abe: 3.457 | eve: 8.996 | bob: 3.428Epoch  23:  11% | abe: 3.456 | eve: 8.995 | bob: 3.427Epoch  23:  12% | abe: 3.456 | eve: 8.995 | bob: 3.427Epoch  23:  13% | abe: 3.456 | eve: 8.994 | bob: 3.427Epoch  23:  14% | abe: 3.456 | eve: 8.994 | bob: 3.426Epoch  23:  14% | abe: 3.455 | eve: 8.993 | bob: 3.425Epoch  23:  15% | abe: 3.457 | eve: 8.991 | bob: 3.426Epoch  23:  16% | abe: 3.457 | eve: 8.992 | bob: 3.426Epoch  23:  17% | abe: 3.456 | eve: 8.993 | bob: 3.426Epoch  23:  17% | abe: 3.458 | eve: 8.992 | bob: 3.428Epoch  23:  18% | abe: 3.457 | eve: 8.994 | bob: 3.427Epoch  23:  19% | abe: 3.456 | eve: 8.993 | bob: 3.426Epoch  23:  20% | abe: 3.455 | eve: 8.993 | bob: 3.425Epoch  23:  21% | abe: 3.455 | eve: 8.994 | bob: 3.426Epoch  23:  21% | abe: 3.455 | eve: 8.995 | bob: 3.425Epoch  23:  22% | abe: 3.454 | eve: 8.995 | bob: 3.426Epoch  23:  23% | abe: 3.453 | eve: 8.996 | bob: 3.425Epoch  23:  24% | abe: 3.453 | eve: 8.996 | bob: 3.424Epoch  23:  25% | abe: 3.452 | eve: 8.997 | bob: 3.423Epoch  23:  25% | abe: 3.451 | eve: 8.996 | bob: 3.423Epoch  23:  26% | abe: 3.451 | eve: 8.997 | bob: 3.423Epoch  23:  27% | abe: 3.451 | eve: 8.996 | bob: 3.423Epoch  23:  28% | abe: 3.451 | eve: 8.995 | bob: 3.424Epoch  23:  28% | abe: 3.451 | eve: 8.995 | bob: 3.423Epoch  23:  29% | abe: 3.450 | eve: 8.995 | bob: 3.422Epoch  23:  30% | abe: 3.449 | eve: 8.995 | bob: 3.422Epoch  23:  31% | abe: 3.448 | eve: 8.995 | bob: 3.420Epoch  23:  32% | abe: 3.447 | eve: 8.995 | bob: 3.420Epoch  23:  32% | abe: 3.447 | eve: 8.995 | bob: 3.420Epoch  23:  33% | abe: 3.446 | eve: 8.996 | bob: 3.419Epoch  23:  34% | abe: 3.446 | eve: 8.996 | bob: 3.420Epoch  23:  35% | abe: 3.445 | eve: 8.996 | bob: 3.419Epoch  23:  35% | abe: 3.445 | eve: 8.997 | bob: 3.419Epoch  23:  36% | abe: 3.444 | eve: 8.997 | bob: 3.418Epoch  23:  37% | abe: 3.444 | eve: 8.997 | bob: 3.418Epoch  23:  38% | abe: 3.443 | eve: 8.997 | bob: 3.418Epoch  23:  39% | abe: 3.443 | eve: 8.997 | bob: 3.418Epoch  23:  39% | abe: 3.443 | eve: 8.997 | bob: 3.418Epoch  23:  40% | abe: 3.443 | eve: 8.996 | bob: 3.417Epoch  23:  41% | abe: 3.442 | eve: 8.997 | bob: 3.417Epoch  23:  42% | abe: 3.442 | eve: 8.996 | bob: 3.417Epoch  23:  42% | abe: 3.441 | eve: 8.996 | bob: 3.417Epoch  23:  43% | abe: 3.441 | eve: 8.997 | bob: 3.416Epoch  23:  44% | abe: 3.440 | eve: 8.996 | bob: 3.416Epoch  23:  45% | abe: 3.440 | eve: 8.996 | bob: 3.415Epoch  23:  46% | abe: 3.439 | eve: 8.996 | bob: 3.415Epoch  23:  46% | abe: 3.439 | eve: 8.996 | bob: 3.415Epoch  23:  47% | abe: 3.438 | eve: 8.996 | bob: 3.415Epoch  23:  48% | abe: 3.438 | eve: 8.997 | bob: 3.414Epoch  23:  49% | abe: 3.437 | eve: 8.997 | bob: 3.414Epoch  23:  50% | abe: 3.437 | eve: 8.997 | bob: 3.414Epoch  23:  50% | abe: 3.437 | eve: 8.997 | bob: 3.414Epoch  23:  51% | abe: 3.436 | eve: 8.997 | bob: 3.413Epoch  23:  52% | abe: 3.436 | eve: 8.997 | bob: 3.413Epoch  23:  53% | abe: 3.435 | eve: 8.998 | bob: 3.413Epoch  23:  53% | abe: 3.435 | eve: 8.998 | bob: 3.413Epoch  23:  54% | abe: 3.434 | eve: 8.998 | bob: 3.412Epoch  23:  55% | abe: 3.434 | eve: 8.998 | bob: 3.412Epoch  23:  56% | abe: 3.434 | eve: 8.998 | bob: 3.412Epoch  23:  57% | abe: 3.434 | eve: 8.998 | bob: 3.412Epoch  23:  57% | abe: 3.434 | eve: 8.998 | bob: 3.412Epoch  23:  58% | abe: 3.433 | eve: 8.998 | bob: 3.412Epoch  23:  59% | abe: 3.433 | eve: 8.998 | bob: 3.412Epoch  23:  60% | abe: 3.433 | eve: 8.998 | bob: 3.412Epoch  23:  60% | abe: 3.432 | eve: 8.998 | bob: 3.411Epoch  23:  61% | abe: 3.431 | eve: 8.998 | bob: 3.410Epoch  23:  62% | abe: 3.431 | eve: 8.998 | bob: 3.411Epoch  23:  63% | abe: 3.431 | eve: 8.997 | bob: 3.410Epoch  23:  64% | abe: 3.430 | eve: 8.997 | bob: 3.410Epoch  23:  64% | abe: 3.430 | eve: 8.997 | bob: 3.410Epoch  23:  65% | abe: 3.429 | eve: 8.997 | bob: 3.409Epoch  23:  66% | abe: 3.429 | eve: 8.997 | bob: 3.409Epoch  23:  67% | abe: 3.429 | eve: 8.997 | bob: 3.409Epoch  23:  67% | abe: 3.428 | eve: 8.997 | bob: 3.409Epoch  23:  68% | abe: 3.428 | eve: 8.998 | bob: 3.408Epoch  23:  69% | abe: 3.427 | eve: 8.997 | bob: 3.408Epoch  23:  70% | abe: 3.427 | eve: 8.998 | bob: 3.408Epoch  23:  71% | abe: 3.426 | eve: 8.998 | bob: 3.407Epoch  23:  71% | abe: 3.426 | eve: 8.997 | bob: 3.407Epoch  23:  72% | abe: 3.425 | eve: 8.997 | bob: 3.407Epoch  23:  73% | abe: 3.425 | eve: 8.997 | bob: 3.406Epoch  23:  74% | abe: 3.424 | eve: 8.997 | bob: 3.406Epoch  23:  75% | abe: 3.424 | eve: 8.997 | bob: 3.406Epoch  23:  75% | abe: 3.423 | eve: 8.997 | bob: 3.405Epoch  23:  76% | abe: 3.423 | eve: 8.997 | bob: 3.405Epoch  23:  77% | abe: 3.423 | eve: 8.997 | bob: 3.405Epoch  23:  78% | abe: 3.422 | eve: 8.997 | bob: 3.405Epoch  23:  78% | abe: 3.422 | eve: 8.997 | bob: 3.405Epoch  23:  79% | abe: 3.422 | eve: 8.997 | bob: 3.405Epoch  23:  80% | abe: 3.421 | eve: 8.997 | bob: 3.404Epoch  23:  81% | abe: 3.421 | eve: 8.997 | bob: 3.404Epoch  23:  82% | abe: 3.420 | eve: 8.997 | bob: 3.404Epoch  23:  82% | abe: 3.420 | eve: 8.997 | bob: 3.404Epoch  23:  83% | abe: 3.420 | eve: 8.997 | bob: 3.404Epoch  23:  84% | abe: 3.419 | eve: 8.997 | bob: 3.403Epoch  23:  85% | abe: 3.419 | eve: 8.997 | bob: 3.403Epoch  23:  85% | abe: 3.419 | eve: 8.997 | bob: 3.403Epoch  23:  86% | abe: 3.418 | eve: 8.996 | bob: 3.403Epoch  23:  87% | abe: 3.418 | eve: 8.997 | bob: 3.403Epoch  23:  88% | abe: 3.418 | eve: 8.997 | bob: 3.402Epoch  23:  89% | abe: 3.417 | eve: 8.997 | bob: 3.402Epoch  23:  89% | abe: 3.417 | eve: 8.997 | bob: 3.402Epoch  23:  90% | abe: 3.416 | eve: 8.997 | bob: 3.402Epoch  23:  91% | abe: 3.416 | eve: 8.997 | bob: 3.401Epoch  23:  92% | abe: 3.415 | eve: 8.997 | bob: 3.401Epoch  23:  92% | abe: 3.415 | eve: 8.997 | bob: 3.401Epoch  23:  93% | abe: 3.414 | eve: 8.997 | bob: 3.401Epoch  23:  94% | abe: 3.414 | eve: 8.997 | bob: 3.400Epoch  23:  95% | abe: 3.413 | eve: 8.997 | bob: 3.400Epoch  23:  96% | abe: 3.413 | eve: 8.996 | bob: 3.399Epoch  23:  96% | abe: 3.412 | eve: 8.996 | bob: 3.399Epoch  23:  97% | abe: 3.412 | eve: 8.997 | bob: 3.399Epoch  23:  98% | abe: 3.411 | eve: 8.997 | bob: 3.398Epoch  23:  99% | abe: 3.411 | eve: 8.997 | bob: 3.398
New best Bob loss 3.3980802624255375 at epoch 23
Epoch  24:   0% | abe: 3.375 | eve: 9.002 | bob: 3.381Epoch  24:   0% | abe: 3.367 | eve: 9.003 | bob: 3.370Epoch  24:   1% | abe: 3.360 | eve: 9.004 | bob: 3.365Epoch  24:   2% | abe: 3.361 | eve: 9.008 | bob: 3.366Epoch  24:   3% | abe: 3.359 | eve: 9.003 | bob: 3.364Epoch  24:   3% | abe: 3.360 | eve: 8.998 | bob: 3.366Epoch  24:   4% | abe: 3.363 | eve: 8.994 | bob: 3.369Epoch  24:   5% | abe: 3.360 | eve: 8.994 | bob: 3.366Epoch  24:   6% | abe: 3.362 | eve: 8.997 | bob: 3.367Epoch  24:   7% | abe: 3.362 | eve: 8.999 | bob: 3.367Epoch  24:   7% | abe: 3.364 | eve: 9.000 | bob: 3.368Epoch  24:   8% | abe: 3.362 | eve: 8.998 | bob: 3.366Epoch  24:   9% | abe: 3.360 | eve: 8.997 | bob: 3.364Epoch  24:  10% | abe: 3.360 | eve: 8.997 | bob: 3.364Epoch  24:  10% | abe: 3.360 | eve: 8.999 | bob: 3.365Epoch  24:  11% | abe: 3.359 | eve: 9.000 | bob: 3.364Epoch  24:  12% | abe: 3.360 | eve: 9.002 | bob: 3.365Epoch  24:  13% | abe: 3.358 | eve: 9.001 | bob: 3.364Epoch  24:  14% | abe: 3.356 | eve: 9.001 | bob: 3.362Epoch  24:  14% | abe: 3.356 | eve: 9.002 | bob: 3.362Epoch  24:  15% | abe: 3.354 | eve: 9.000 | bob: 3.360Epoch  24:  16% | abe: 3.354 | eve: 8.998 | bob: 3.360Epoch  24:  17% | abe: 3.352 | eve: 8.997 | bob: 3.358Epoch  24:  17% | abe: 3.352 | eve: 8.996 | bob: 3.358Epoch  24:  18% | abe: 3.351 | eve: 8.996 | bob: 3.358Epoch  24:  19% | abe: 3.351 | eve: 8.997 | bob: 3.357Epoch  24:  20% | abe: 3.351 | eve: 8.996 | bob: 3.357Epoch  24:  21% | abe: 3.350 | eve: 8.997 | bob: 3.357Epoch  24:  21% | abe: 3.350 | eve: 8.997 | bob: 3.357Epoch  24:  22% | abe: 3.350 | eve: 8.997 | bob: 3.357Epoch  24:  23% | abe: 3.350 | eve: 8.997 | bob: 3.357Epoch  24:  24% | abe: 3.350 | eve: 8.997 | bob: 3.357Epoch  24:  25% | abe: 3.349 | eve: 8.997 | bob: 3.357Epoch  24:  25% | abe: 3.349 | eve: 8.997 | bob: 3.356Epoch  24:  26% | abe: 3.348 | eve: 8.998 | bob: 3.356Epoch  24:  27% | abe: 3.349 | eve: 8.998 | bob: 3.357Epoch  24:  28% | abe: 3.348 | eve: 8.997 | bob: 3.356Epoch  24:  28% | abe: 3.349 | eve: 8.998 | bob: 3.357Epoch  24:  29% | abe: 3.349 | eve: 8.998 | bob: 3.357Epoch  24:  30% | abe: 3.348 | eve: 8.996 | bob: 3.356Epoch  24:  31% | abe: 3.347 | eve: 8.998 | bob: 3.356Epoch  24:  32% | abe: 3.347 | eve: 8.997 | bob: 3.356Epoch  24:  32% | abe: 3.347 | eve: 8.998 | bob: 3.356Epoch  24:  33% | abe: 3.347 | eve: 8.998 | bob: 3.356Epoch  24:  34% | abe: 3.347 | eve: 8.997 | bob: 3.356Epoch  24:  35% | abe: 3.347 | eve: 8.997 | bob: 3.356Epoch  24:  35% | abe: 3.346 | eve: 8.997 | bob: 3.356Epoch  24:  36% | abe: 3.346 | eve: 8.998 | bob: 3.355Epoch  24:  37% | abe: 3.346 | eve: 8.997 | bob: 3.355Epoch  24:  38% | abe: 3.345 | eve: 8.997 | bob: 3.355Epoch  24:  39% | abe: 3.345 | eve: 8.997 | bob: 3.355Epoch  24:  39% | abe: 3.345 | eve: 8.998 | bob: 3.355Epoch  24:  40% | abe: 3.345 | eve: 8.998 | bob: 3.355Epoch  24:  41% | abe: 3.344 | eve: 8.998 | bob: 3.355Epoch  24:  42% | abe: 3.344 | eve: 8.998 | bob: 3.355Epoch  24:  42% | abe: 3.344 | eve: 8.998 | bob: 3.354Epoch  24:  43% | abe: 3.343 | eve: 8.999 | bob: 3.354Epoch  24:  44% | abe: 3.343 | eve: 8.999 | bob: 3.354Epoch  24:  45% | abe: 3.342 | eve: 8.999 | bob: 3.354Epoch  24:  46% | abe: 3.342 | eve: 8.999 | bob: 3.354Epoch  24:  46% | abe: 3.341 | eve: 8.999 | bob: 3.353Epoch  24:  47% | abe: 3.341 | eve: 8.999 | bob: 3.353Epoch  24:  48% | abe: 3.340 | eve: 8.999 | bob: 3.353Epoch  24:  49% | abe: 3.340 | eve: 8.999 | bob: 3.353Epoch  24:  50% | abe: 3.340 | eve: 8.999 | bob: 3.353Epoch  24:  50% | abe: 3.339 | eve: 8.999 | bob: 3.352Epoch  24:  51% | abe: 3.339 | eve: 8.999 | bob: 3.352Epoch  24:  52% | abe: 3.338 | eve: 8.998 | bob: 3.351Epoch  24:  53% | abe: 3.337 | eve: 8.999 | bob: 3.350Epoch  24:  53% | abe: 3.336 | eve: 8.998 | bob: 3.350Epoch  24:  54% | abe: 3.336 | eve: 8.999 | bob: 3.350Epoch  24:  55% | abe: 3.336 | eve: 8.999 | bob: 3.350Epoch  24:  56% | abe: 3.335 | eve: 8.998 | bob: 3.349Epoch  24:  57% | abe: 3.335 | eve: 8.998 | bob: 3.349Epoch  24:  57% | abe: 3.334 | eve: 8.998 | bob: 3.349Epoch  24:  58% | abe: 3.334 | eve: 8.998 | bob: 3.349Epoch  24:  59% | abe: 3.334 | eve: 8.998 | bob: 3.348Epoch  24:  60% | abe: 3.333 | eve: 8.998 | bob: 3.348Epoch  24:  60% | abe: 3.333 | eve: 8.998 | bob: 3.348Epoch  24:  61% | abe: 3.333 | eve: 8.998 | bob: 3.348Epoch  24:  62% | abe: 3.332 | eve: 8.998 | bob: 3.348Epoch  24:  63% | abe: 3.332 | eve: 8.998 | bob: 3.348Epoch  24:  64% | abe: 3.332 | eve: 8.998 | bob: 3.348Epoch  24:  64% | abe: 3.331 | eve: 8.998 | bob: 3.347Epoch  24:  65% | abe: 3.331 | eve: 8.999 | bob: 3.347Epoch  24:  66% | abe: 3.331 | eve: 8.998 | bob: 3.347Epoch  24:  67% | abe: 3.331 | eve: 8.998 | bob: 3.347Epoch  24:  67% | abe: 3.330 | eve: 8.998 | bob: 3.347Epoch  24:  68% | abe: 3.330 | eve: 8.998 | bob: 3.347Epoch  24:  69% | abe: 3.330 | eve: 8.998 | bob: 3.346Epoch  24:  70% | abe: 3.329 | eve: 8.998 | bob: 3.346Epoch  24:  71% | abe: 3.329 | eve: 8.998 | bob: 3.346Epoch  24:  71% | abe: 3.328 | eve: 8.998 | bob: 3.345Epoch  24:  72% | abe: 3.328 | eve: 8.999 | bob: 3.345Epoch  24:  73% | abe: 3.327 | eve: 8.999 | bob: 3.345Epoch  24:  74% | abe: 3.327 | eve: 8.999 | bob: 3.344Epoch  24:  75% | abe: 3.327 | eve: 8.999 | bob: 3.344Epoch  24:  75% | abe: 3.326 | eve: 8.998 | bob: 3.344Epoch  24:  76% | abe: 3.326 | eve: 8.998 | bob: 3.343Epoch  24:  77% | abe: 3.325 | eve: 8.998 | bob: 3.343Epoch  24:  78% | abe: 3.325 | eve: 8.998 | bob: 3.343Epoch  24:  78% | abe: 3.325 | eve: 8.998 | bob: 3.343Epoch  24:  79% | abe: 3.324 | eve: 8.998 | bob: 3.342Epoch  24:  80% | abe: 3.324 | eve: 8.998 | bob: 3.342Epoch  24:  81% | abe: 3.324 | eve: 8.998 | bob: 3.342Epoch  24:  82% | abe: 3.323 | eve: 8.998 | bob: 3.342Epoch  24:  82% | abe: 3.323 | eve: 8.998 | bob: 3.342Epoch  24:  83% | abe: 3.323 | eve: 8.998 | bob: 3.342Epoch  24:  84% | abe: 3.322 | eve: 8.998 | bob: 3.341Epoch  24:  85% | abe: 3.322 | eve: 8.998 | bob: 3.341Epoch  24:  85% | abe: 3.321 | eve: 8.999 | bob: 3.341Epoch  24:  86% | abe: 3.321 | eve: 8.998 | bob: 3.341Epoch  24:  87% | abe: 3.320 | eve: 8.998 | bob: 3.340Epoch  24:  88% | abe: 3.319 | eve: 8.998 | bob: 3.339Epoch  24:  89% | abe: 3.319 | eve: 8.998 | bob: 3.339Epoch  24:  89% | abe: 3.319 | eve: 8.998 | bob: 3.339Epoch  24:  90% | abe: 3.319 | eve: 8.998 | bob: 3.339Epoch  24:  91% | abe: 3.318 | eve: 8.998 | bob: 3.339Epoch  24:  92% | abe: 3.318 | eve: 8.998 | bob: 3.339Epoch  24:  92% | abe: 3.318 | eve: 8.998 | bob: 3.339Epoch  24:  93% | abe: 3.317 | eve: 8.998 | bob: 3.338Epoch  24:  94% | abe: 3.317 | eve: 8.998 | bob: 3.338Epoch  24:  95% | abe: 3.317 | eve: 8.998 | bob: 3.338Epoch  24:  96% | abe: 3.317 | eve: 8.998 | bob: 3.338Epoch  24:  96% | abe: 3.316 | eve: 8.997 | bob: 3.338Epoch  24:  97% | abe: 3.316 | eve: 8.998 | bob: 3.337Epoch  24:  98% | abe: 3.315 | eve: 8.998 | bob: 3.337Epoch  24:  99% | abe: 3.315 | eve: 8.997 | bob: 3.337
New best Bob loss 3.3368502289552 at epoch 24
Epoch  25:   0% | abe: 3.262 | eve: 8.974 | bob: 3.295Epoch  25:   0% | abe: 3.266 | eve: 8.977 | bob: 3.302Epoch  25:   1% | abe: 3.266 | eve: 8.984 | bob: 3.305Epoch  25:   2% | abe: 3.260 | eve: 8.995 | bob: 3.296Epoch  25:   3% | abe: 3.263 | eve: 8.994 | bob: 3.302Epoch  25:   3% | abe: 3.260 | eve: 8.992 | bob: 3.299Epoch  25:   4% | abe: 3.261 | eve: 8.998 | bob: 3.300Epoch  25:   5% | abe: 3.261 | eve: 8.997 | bob: 3.299Epoch  25:   6% | abe: 3.260 | eve: 9.003 | bob: 3.298Epoch  25:   7% | abe: 3.259 | eve: 9.004 | bob: 3.298Epoch  25:   7% | abe: 3.259 | eve: 9.005 | bob: 3.297Epoch  25:   8% | abe: 3.258 | eve: 9.007 | bob: 3.297Epoch  25:   9% | abe: 3.256 | eve: 9.008 | bob: 3.295Epoch  25:  10% | abe: 3.256 | eve: 9.008 | bob: 3.296Epoch  25:  10% | abe: 3.255 | eve: 9.009 | bob: 3.295Epoch  25:  11% | abe: 3.253 | eve: 9.010 | bob: 3.294Epoch  25:  12% | abe: 3.254 | eve: 9.010 | bob: 3.295Epoch  25:  13% | abe: 3.254 | eve: 9.009 | bob: 3.296Epoch  25:  14% | abe: 3.253 | eve: 9.008 | bob: 3.295Epoch  25:  14% | abe: 3.252 | eve: 9.006 | bob: 3.294Epoch  25:  15% | abe: 3.251 | eve: 9.004 | bob: 3.292Epoch  25:  16% | abe: 3.251 | eve: 9.002 | bob: 3.293Epoch  25:  17% | abe: 3.251 | eve: 9.002 | bob: 3.293Epoch  25:  17% | abe: 3.250 | eve: 9.001 | bob: 3.292Epoch  25:  18% | abe: 3.252 | eve: 9.001 | bob: 3.294Epoch  25:  19% | abe: 3.251 | eve: 8.999 | bob: 3.293Epoch  25:  20% | abe: 3.250 | eve: 9.000 | bob: 3.293Epoch  25:  21% | abe: 3.251 | eve: 9.001 | bob: 3.294Epoch  25:  21% | abe: 3.252 | eve: 9.000 | bob: 3.295Epoch  25:  22% | abe: 3.251 | eve: 8.999 | bob: 3.294Epoch  25:  23% | abe: 3.252 | eve: 9.000 | bob: 3.295Epoch  25:  24% | abe: 3.252 | eve: 9.000 | bob: 3.296Epoch  25:  25% | abe: 3.252 | eve: 9.001 | bob: 3.297Epoch  25:  25% | abe: 3.253 | eve: 9.000 | bob: 3.298Epoch  25:  26% | abe: 3.253 | eve: 9.001 | bob: 3.298Epoch  25:  27% | abe: 3.253 | eve: 9.001 | bob: 3.297Epoch  25:  28% | abe: 3.253 | eve: 9.002 | bob: 3.298Epoch  25:  28% | abe: 3.253 | eve: 9.001 | bob: 3.298Epoch  25:  29% | abe: 3.252 | eve: 9.001 | bob: 3.298Epoch  25:  30% | abe: 3.252 | eve: 9.002 | bob: 3.298Epoch  25:  31% | abe: 3.252 | eve: 9.001 | bob: 3.299Epoch  25:  32% | abe: 3.252 | eve: 9.000 | bob: 3.299Epoch  25:  32% | abe: 3.252 | eve: 8.999 | bob: 3.299Epoch  25:  33% | abe: 3.252 | eve: 8.999 | bob: 3.299Epoch  25:  34% | abe: 3.251 | eve: 8.999 | bob: 3.298Epoch  25:  35% | abe: 3.251 | eve: 9.000 | bob: 3.298Epoch  25:  35% | abe: 3.251 | eve: 9.000 | bob: 3.298Epoch  25:  36% | abe: 3.250 | eve: 9.000 | bob: 3.298Epoch  25:  37% | abe: 3.250 | eve: 9.000 | bob: 3.298Epoch  25:  38% | abe: 3.250 | eve: 8.999 | bob: 3.298Epoch  25:  39% | abe: 3.249 | eve: 8.999 | bob: 3.297Epoch  25:  39% | abe: 3.249 | eve: 8.998 | bob: 3.297Epoch  25:  40% | abe: 3.249 | eve: 8.999 | bob: 3.297Epoch  25:  41% | abe: 3.249 | eve: 8.999 | bob: 3.297Epoch  25:  42% | abe: 3.248 | eve: 8.998 | bob: 3.296Epoch  25:  42% | abe: 3.247 | eve: 8.998 | bob: 3.295Epoch  25:  43% | abe: 3.247 | eve: 8.999 | bob: 3.296Epoch  25:  44% | abe: 3.247 | eve: 8.998 | bob: 3.296Epoch  25:  45% | abe: 3.247 | eve: 8.998 | bob: 3.296Epoch  25:  46% | abe: 3.246 | eve: 8.999 | bob: 3.295Epoch  25:  46% | abe: 3.246 | eve: 8.998 | bob: 3.295Epoch  25:  47% | abe: 3.246 | eve: 8.998 | bob: 3.295Epoch  25:  48% | abe: 3.245 | eve: 8.998 | bob: 3.295Epoch  25:  49% | abe: 3.245 | eve: 8.997 | bob: 3.295Epoch  25:  50% | abe: 3.245 | eve: 8.998 | bob: 3.295Epoch  25:  50% | abe: 3.245 | eve: 8.998 | bob: 3.295Epoch  25:  51% | abe: 3.244 | eve: 8.998 | bob: 3.294Epoch  25:  52% | abe: 3.244 | eve: 8.998 | bob: 3.294Epoch  25:  53% | abe: 3.244 | eve: 8.998 | bob: 3.294Epoch  25:  53% | abe: 3.243 | eve: 8.998 | bob: 3.294Epoch  25:  54% | abe: 3.243 | eve: 8.997 | bob: 3.294Epoch  25:  55% | abe: 3.242 | eve: 8.997 | bob: 3.294Epoch  25:  56% | abe: 3.241 | eve: 8.997 | bob: 3.293Epoch  25:  57% | abe: 3.241 | eve: 8.998 | bob: 3.293Epoch  25:  57% | abe: 3.241 | eve: 8.998 | bob: 3.293Epoch  25:  58% | abe: 3.241 | eve: 8.998 | bob: 3.293Epoch  25:  59% | abe: 3.241 | eve: 8.997 | bob: 3.293Epoch  25:  60% | abe: 3.240 | eve: 8.997 | bob: 3.293Epoch  25:  60% | abe: 3.240 | eve: 8.997 | bob: 3.293Epoch  25:  61% | abe: 3.240 | eve: 8.997 | bob: 3.293Epoch  25:  62% | abe: 3.240 | eve: 8.997 | bob: 3.293Epoch  25:  63% | abe: 3.240 | eve: 8.997 | bob: 3.293Epoch  25:  64% | abe: 3.240 | eve: 8.997 | bob: 3.294Epoch  25:  64% | abe: 3.240 | eve: 8.997 | bob: 3.293Epoch  25:  65% | abe: 3.239 | eve: 8.997 | bob: 3.293Epoch  25:  66% | abe: 3.239 | eve: 8.998 | bob: 3.293Epoch  25:  67% | abe: 3.239 | eve: 8.998 | bob: 3.293Epoch  25:  67% | abe: 3.239 | eve: 8.998 | bob: 3.293Epoch  25:  68% | abe: 3.238 | eve: 8.998 | bob: 3.293Epoch  25:  69% | abe: 3.238 | eve: 8.998 | bob: 3.292Epoch  25:  70% | abe: 3.238 | eve: 8.999 | bob: 3.292Epoch  25:  71% | abe: 3.237 | eve: 8.999 | bob: 3.292Epoch  25:  71% | abe: 3.237 | eve: 8.999 | bob: 3.292Epoch  25:  72% | abe: 3.237 | eve: 8.999 | bob: 3.292Epoch  25:  73% | abe: 3.236 | eve: 9.000 | bob: 3.292Epoch  25:  74% | abe: 3.236 | eve: 8.999 | bob: 3.291Epoch  25:  75% | abe: 3.236 | eve: 8.999 | bob: 3.291Epoch  25:  75% | abe: 3.235 | eve: 8.999 | bob: 3.291Epoch  25:  76% | abe: 3.234 | eve: 8.999 | bob: 3.290Epoch  25:  77% | abe: 3.234 | eve: 8.999 | bob: 3.290Epoch  25:  78% | abe: 3.234 | eve: 8.999 | bob: 3.290Epoch  25:  78% | abe: 3.233 | eve: 8.999 | bob: 3.290Epoch  25:  79% | abe: 3.233 | eve: 8.999 | bob: 3.289Epoch  25:  80% | abe: 3.233 | eve: 8.999 | bob: 3.289Epoch  25:  81% | abe: 3.232 | eve: 8.999 | bob: 3.289Epoch  25:  82% | abe: 3.232 | eve: 8.999 | bob: 3.289Epoch  25:  82% | abe: 3.232 | eve: 8.999 | bob: 3.289Epoch  25:  83% | abe: 3.231 | eve: 8.998 | bob: 3.288Epoch  25:  84% | abe: 3.231 | eve: 8.999 | bob: 3.288Epoch  25:  85% | abe: 3.230 | eve: 8.999 | bob: 3.288Epoch  25:  85% | abe: 3.230 | eve: 8.999 | bob: 3.287Epoch  25:  86% | abe: 3.229 | eve: 8.999 | bob: 3.287Epoch  25:  87% | abe: 3.229 | eve: 8.998 | bob: 3.287Epoch  25:  88% | abe: 3.229 | eve: 8.998 | bob: 3.287Epoch  25:  89% | abe: 3.229 | eve: 8.998 | bob: 3.287Epoch  25:  89% | abe: 3.228 | eve: 8.998 | bob: 3.286Epoch  25:  90% | abe: 3.228 | eve: 8.998 | bob: 3.286Epoch  25:  91% | abe: 3.227 | eve: 8.998 | bob: 3.285Epoch  25:  92% | abe: 3.227 | eve: 8.998 | bob: 3.285Epoch  25:  92% | abe: 3.226 | eve: 8.998 | bob: 3.284Epoch  25:  93% | abe: 3.226 | eve: 8.998 | bob: 3.284Epoch  25:  94% | abe: 3.226 | eve: 8.998 | bob: 3.284Epoch  25:  95% | abe: 3.225 | eve: 8.999 | bob: 3.284Epoch  25:  96% | abe: 3.225 | eve: 8.999 | bob: 3.283Epoch  25:  96% | abe: 3.225 | eve: 8.999 | bob: 3.283Epoch  25:  97% | abe: 3.224 | eve: 8.999 | bob: 3.283Epoch  25:  98% | abe: 3.224 | eve: 8.999 | bob: 3.282Epoch  25:  99% | abe: 3.224 | eve: 8.999 | bob: 3.282
New best Bob loss 3.282147867389085 at epoch 25
Epoch  26:   0% | abe: 3.154 | eve: 9.009 | bob: 3.222Epoch  26:   0% | abe: 3.153 | eve: 9.016 | bob: 3.217Epoch  26:   1% | abe: 3.164 | eve: 9.012 | bob: 3.229Epoch  26:   2% | abe: 3.179 | eve: 9.017 | bob: 3.244Epoch  26:   3% | abe: 3.178 | eve: 9.004 | bob: 3.242Epoch  26:   3% | abe: 3.178 | eve: 9.007 | bob: 3.243Epoch  26:   4% | abe: 3.178 | eve: 9.009 | bob: 3.243Epoch  26:   5% | abe: 3.186 | eve: 9.008 | bob: 3.251Epoch  26:   6% | abe: 3.185 | eve: 9.004 | bob: 3.250Epoch  26:   7% | abe: 3.183 | eve: 9.007 | bob: 3.247Epoch  26:   7% | abe: 3.183 | eve: 9.006 | bob: 3.246Epoch  26:   8% | abe: 3.186 | eve: 9.004 | bob: 3.248Epoch  26:   9% | abe: 3.187 | eve: 9.000 | bob: 3.250Epoch  26:  10% | abe: 3.185 | eve: 8.998 | bob: 3.247Epoch  26:  10% | abe: 3.187 | eve: 8.997 | bob: 3.250Epoch  26:  11% | abe: 3.186 | eve: 8.998 | bob: 3.249Epoch  26:  12% | abe: 3.185 | eve: 8.998 | bob: 3.249Epoch  26:  13% | abe: 3.185 | eve: 8.996 | bob: 3.249Epoch  26:  14% | abe: 3.186 | eve: 8.997 | bob: 3.250Epoch  26:  14% | abe: 3.184 | eve: 8.996 | bob: 3.248Epoch  26:  15% | abe: 3.187 | eve: 8.998 | bob: 3.251Epoch  26:  16% | abe: 3.187 | eve: 8.998 | bob: 3.251Epoch  26:  17% | abe: 3.187 | eve: 8.998 | bob: 3.251Epoch  26:  17% | abe: 3.186 | eve: 8.997 | bob: 3.250Epoch  26:  18% | abe: 3.184 | eve: 8.997 | bob: 3.248Epoch  26:  19% | abe: 3.184 | eve: 8.999 | bob: 3.247Epoch  26:  20% | abe: 3.183 | eve: 8.999 | bob: 3.246Epoch  26:  21% | abe: 3.182 | eve: 8.999 | bob: 3.246Epoch  26:  21% | abe: 3.183 | eve: 8.998 | bob: 3.247Epoch  26:  22% | abe: 3.184 | eve: 8.998 | bob: 3.248Epoch  26:  23% | abe: 3.183 | eve: 8.998 | bob: 3.247Epoch  26:  24% | abe: 3.183 | eve: 8.998 | bob: 3.247Epoch  26:  25% | abe: 3.183 | eve: 8.998 | bob: 3.246Epoch  26:  25% | abe: 3.183 | eve: 8.999 | bob: 3.247Epoch  26:  26% | abe: 3.183 | eve: 8.998 | bob: 3.247Epoch  26:  27% | abe: 3.183 | eve: 8.998 | bob: 3.247Epoch  26:  28% | abe: 3.182 | eve: 9.000 | bob: 3.246Epoch  26:  28% | abe: 3.183 | eve: 8.999 | bob: 3.247Epoch  26:  29% | abe: 3.182 | eve: 8.998 | bob: 3.246Epoch  26:  30% | abe: 3.182 | eve: 8.999 | bob: 3.245Epoch  26:  31% | abe: 3.181 | eve: 8.998 | bob: 3.244Epoch  26:  32% | abe: 3.180 | eve: 8.998 | bob: 3.243Epoch  26:  32% | abe: 3.180 | eve: 8.999 | bob: 3.243Epoch  26:  33% | abe: 3.179 | eve: 8.999 | bob: 3.243Epoch  26:  34% | abe: 3.178 | eve: 8.999 | bob: 3.242Epoch  26:  35% | abe: 3.178 | eve: 8.999 | bob: 3.242Epoch  26:  35% | abe: 3.179 | eve: 9.000 | bob: 3.243Epoch  26:  36% | abe: 3.179 | eve: 9.000 | bob: 3.243Epoch  26:  37% | abe: 3.179 | eve: 9.001 | bob: 3.243Epoch  26:  38% | abe: 3.179 | eve: 9.000 | bob: 3.243Epoch  26:  39% | abe: 3.179 | eve: 9.000 | bob: 3.243Epoch  26:  39% | abe: 3.179 | eve: 9.001 | bob: 3.242Epoch  26:  40% | abe: 3.178 | eve: 9.000 | bob: 3.242Epoch  26:  41% | abe: 3.177 | eve: 9.001 | bob: 3.241Epoch  26:  42% | abe: 3.177 | eve: 9.001 | bob: 3.241Epoch  26:  42% | abe: 3.177 | eve: 9.001 | bob: 3.241Epoch  26:  43% | abe: 3.177 | eve: 9.001 | bob: 3.241Epoch  26:  44% | abe: 3.177 | eve: 9.001 | bob: 3.240Epoch  26:  45% | abe: 3.177 | eve: 9.001 | bob: 3.240Epoch  26:  46% | abe: 3.176 | eve: 9.001 | bob: 3.239Epoch  26:  46% | abe: 3.175 | eve: 9.001 | bob: 3.238Epoch  26:  47% | abe: 3.175 | eve: 9.001 | bob: 3.238Epoch  26:  48% | abe: 3.175 | eve: 9.001 | bob: 3.238Epoch  26:  49% | abe: 3.175 | eve: 9.000 | bob: 3.238Epoch  26:  50% | abe: 3.175 | eve: 9.000 | bob: 3.238Epoch  26:  50% | abe: 3.174 | eve: 9.001 | bob: 3.238Epoch  26:  51% | abe: 3.174 | eve: 9.001 | bob: 3.237Epoch  26:  52% | abe: 3.173 | eve: 9.001 | bob: 3.236Epoch  26:  53% | abe: 3.173 | eve: 9.001 | bob: 3.236Epoch  26:  53% | abe: 3.173 | eve: 9.001 | bob: 3.236Epoch  26:  54% | abe: 3.173 | eve: 9.001 | bob: 3.236Epoch  26:  55% | abe: 3.173 | eve: 9.001 | bob: 3.236Epoch  26:  56% | abe: 3.173 | eve: 9.000 | bob: 3.236Epoch  26:  57% | abe: 3.172 | eve: 9.000 | bob: 3.236Epoch  26:  57% | abe: 3.173 | eve: 9.000 | bob: 3.236Epoch  26:  58% | abe: 3.173 | eve: 9.000 | bob: 3.236Epoch  26:  59% | abe: 3.172 | eve: 9.000 | bob: 3.235Epoch  26:  60% | abe: 3.172 | eve: 9.001 | bob: 3.235Epoch  26:  60% | abe: 3.172 | eve: 9.001 | bob: 3.235Epoch  26:  61% | abe: 3.172 | eve: 9.001 | bob: 3.235Epoch  26:  62% | abe: 3.171 | eve: 9.001 | bob: 3.234Epoch  26:  63% | abe: 3.171 | eve: 9.001 | bob: 3.234Epoch  26:  64% | abe: 3.171 | eve: 9.001 | bob: 3.233Epoch  26:  64% | abe: 3.171 | eve: 9.001 | bob: 3.234Epoch  26:  65% | abe: 3.171 | eve: 9.000 | bob: 3.233Epoch  26:  66% | abe: 3.171 | eve: 9.000 | bob: 3.234Epoch  26:  67% | abe: 3.171 | eve: 9.000 | bob: 3.233Epoch  26:  67% | abe: 3.171 | eve: 9.000 | bob: 3.233Epoch  26:  68% | abe: 3.171 | eve: 9.000 | bob: 3.233Epoch  26:  69% | abe: 3.170 | eve: 9.000 | bob: 3.232Epoch  26:  70% | abe: 3.170 | eve: 9.000 | bob: 3.232Epoch  26:  71% | abe: 3.170 | eve: 9.000 | bob: 3.232Epoch  26:  71% | abe: 3.170 | eve: 8.999 | bob: 3.231Epoch  26:  72% | abe: 3.170 | eve: 8.999 | bob: 3.231Epoch  26:  73% | abe: 3.169 | eve: 8.999 | bob: 3.230Epoch  26:  74% | abe: 3.169 | eve: 8.999 | bob: 3.230Epoch  26:  75% | abe: 3.169 | eve: 8.999 | bob: 3.230Epoch  26:  75% | abe: 3.168 | eve: 9.000 | bob: 3.229Epoch  26:  76% | abe: 3.168 | eve: 9.000 | bob: 3.229Epoch  26:  77% | abe: 3.168 | eve: 9.000 | bob: 3.228Epoch  26:  78% | abe: 3.168 | eve: 9.000 | bob: 3.228Epoch  26:  78% | abe: 3.167 | eve: 9.000 | bob: 3.228Epoch  26:  79% | abe: 3.167 | eve: 8.999 | bob: 3.228Epoch  26:  80% | abe: 3.167 | eve: 9.000 | bob: 3.228Epoch  26:  81% | abe: 3.167 | eve: 9.000 | bob: 3.227Epoch  26:  82% | abe: 3.167 | eve: 8.999 | bob: 3.227Epoch  26:  82% | abe: 3.166 | eve: 8.999 | bob: 3.227Epoch  26:  83% | abe: 3.166 | eve: 8.999 | bob: 3.227Epoch  26:  84% | abe: 3.166 | eve: 8.999 | bob: 3.226Epoch  26:  85% | abe: 3.166 | eve: 8.999 | bob: 3.226Epoch  26:  85% | abe: 3.165 | eve: 8.999 | bob: 3.225Epoch  26:  86% | abe: 3.165 | eve: 9.000 | bob: 3.225Epoch  26:  87% | abe: 3.165 | eve: 9.000 | bob: 3.225Epoch  26:  88% | abe: 3.165 | eve: 9.000 | bob: 3.225Epoch  26:  89% | abe: 3.165 | eve: 9.000 | bob: 3.224Epoch  26:  89% | abe: 3.164 | eve: 9.000 | bob: 3.224Epoch  26:  90% | abe: 3.164 | eve: 9.000 | bob: 3.224Epoch  26:  91% | abe: 3.164 | eve: 9.000 | bob: 3.224Epoch  26:  92% | abe: 3.164 | eve: 9.000 | bob: 3.224Epoch  26:  92% | abe: 3.165 | eve: 8.999 | bob: 3.224Epoch  26:  93% | abe: 3.164 | eve: 8.999 | bob: 3.224Epoch  26:  94% | abe: 3.164 | eve: 8.999 | bob: 3.223Epoch  26:  95% | abe: 3.164 | eve: 8.999 | bob: 3.224Epoch  26:  96% | abe: 3.164 | eve: 8.999 | bob: 3.224Epoch  26:  96% | abe: 3.164 | eve: 8.999 | bob: 3.223Epoch  26:  97% | abe: 3.164 | eve: 9.000 | bob: 3.223Epoch  26:  98% | abe: 3.164 | eve: 9.000 | bob: 3.223Epoch  26:  99% | abe: 3.164 | eve: 9.000 | bob: 3.223
New best Bob loss 3.2226625892349148 at epoch 26
Epoch  27:   0% | abe: 3.130 | eve: 8.973 | bob: 3.176Epoch  27:   0% | abe: 3.140 | eve: 8.979 | bob: 3.190Epoch  27:   1% | abe: 3.154 | eve: 8.990 | bob: 3.208Epoch  27:   2% | abe: 3.161 | eve: 8.981 | bob: 3.215Epoch  27:   3% | abe: 3.160 | eve: 8.983 | bob: 3.215Epoch  27:   3% | abe: 3.154 | eve: 8.987 | bob: 3.207Epoch  27:   4% | abe: 3.153 | eve: 8.993 | bob: 3.205Epoch  27:   5% | abe: 3.150 | eve: 8.990 | bob: 3.202Epoch  27:   6% | abe: 3.152 | eve: 8.988 | bob: 3.202Epoch  27:   7% | abe: 3.146 | eve: 8.990 | bob: 3.196Epoch  27:   7% | abe: 3.143 | eve: 8.988 | bob: 3.192Epoch  27:   8% | abe: 3.145 | eve: 8.987 | bob: 3.195Epoch  27:   9% | abe: 3.148 | eve: 8.991 | bob: 3.198Epoch  27:  10% | abe: 3.148 | eve: 8.991 | bob: 3.198Epoch  27:  10% | abe: 3.149 | eve: 8.991 | bob: 3.199Epoch  27:  11% | abe: 3.150 | eve: 8.993 | bob: 3.200Epoch  27:  12% | abe: 3.149 | eve: 8.992 | bob: 3.199Epoch  27:  13% | abe: 3.149 | eve: 8.991 | bob: 3.198Epoch  27:  14% | abe: 3.150 | eve: 8.992 | bob: 3.199Epoch  27:  14% | abe: 3.150 | eve: 8.991 | bob: 3.199Epoch  27:  15% | abe: 3.151 | eve: 8.991 | bob: 3.200Epoch  27:  16% | abe: 3.149 | eve: 8.991 | bob: 3.197Epoch  27:  17% | abe: 3.149 | eve: 8.989 | bob: 3.197Epoch  27:  17% | abe: 3.149 | eve: 8.991 | bob: 3.197Epoch  27:  18% | abe: 3.148 | eve: 8.990 | bob: 3.197Epoch  27:  19% | abe: 3.148 | eve: 8.992 | bob: 3.196Epoch  27:  20% | abe: 3.148 | eve: 8.992 | bob: 3.196Epoch  27:  21% | abe: 3.147 | eve: 8.992 | bob: 3.195Epoch  27:  21% | abe: 3.147 | eve: 8.992 | bob: 3.195Epoch  27:  22% | abe: 3.147 | eve: 8.992 | bob: 3.194Epoch  27:  23% | abe: 3.146 | eve: 8.993 | bob: 3.194Epoch  27:  24% | abe: 3.146 | eve: 8.994 | bob: 3.193Epoch  27:  25% | abe: 3.145 | eve: 8.993 | bob: 3.193Epoch  27:  25% | abe: 3.145 | eve: 8.994 | bob: 3.193Epoch  27:  26% | abe: 3.146 | eve: 8.993 | bob: 3.193Epoch  27:  27% | abe: 3.145 | eve: 8.993 | bob: 3.192Epoch  27:  28% | abe: 3.144 | eve: 8.993 | bob: 3.191Epoch  27:  28% | abe: 3.144 | eve: 8.993 | bob: 3.191Epoch  27:  29% | abe: 3.145 | eve: 8.994 | bob: 3.192Epoch  27:  30% | abe: 3.145 | eve: 8.993 | bob: 3.192Epoch  27:  31% | abe: 3.144 | eve: 8.993 | bob: 3.190Epoch  27:  32% | abe: 3.143 | eve: 8.992 | bob: 3.190Epoch  27:  32% | abe: 3.143 | eve: 8.993 | bob: 3.190Epoch  27:  33% | abe: 3.142 | eve: 8.993 | bob: 3.189Epoch  27:  34% | abe: 3.143 | eve: 8.994 | bob: 3.189Epoch  27:  35% | abe: 3.143 | eve: 8.995 | bob: 3.189Epoch  27:  35% | abe: 3.142 | eve: 8.995 | bob: 3.189Epoch  27:  36% | abe: 3.142 | eve: 8.995 | bob: 3.189Epoch  27:  37% | abe: 3.142 | eve: 8.995 | bob: 3.188Epoch  27:  38% | abe: 3.141 | eve: 8.995 | bob: 3.188Epoch  27:  39% | abe: 3.141 | eve: 8.995 | bob: 3.187Epoch  27:  39% | abe: 3.141 | eve: 8.995 | bob: 3.187Epoch  27:  40% | abe: 3.141 | eve: 8.995 | bob: 3.187Epoch  27:  41% | abe: 3.141 | eve: 8.995 | bob: 3.187Epoch  27:  42% | abe: 3.141 | eve: 8.995 | bob: 3.187Epoch  27:  42% | abe: 3.140 | eve: 8.995 | bob: 3.186Epoch  27:  43% | abe: 3.140 | eve: 8.995 | bob: 3.186Epoch  27:  44% | abe: 3.140 | eve: 8.995 | bob: 3.186Epoch  27:  45% | abe: 3.141 | eve: 8.995 | bob: 3.186Epoch  27:  46% | abe: 3.140 | eve: 8.994 | bob: 3.186Epoch  27:  46% | abe: 3.141 | eve: 8.994 | bob: 3.187Epoch  27:  47% | abe: 3.140 | eve: 8.994 | bob: 3.186Epoch  27:  48% | abe: 3.140 | eve: 8.994 | bob: 3.186Epoch  27:  49% | abe: 3.140 | eve: 8.994 | bob: 3.186Epoch  27:  50% | abe: 3.140 | eve: 8.994 | bob: 3.186Epoch  27:  50% | abe: 3.140 | eve: 8.993 | bob: 3.186Epoch  27:  51% | abe: 3.140 | eve: 8.993 | bob: 3.185Epoch  27:  52% | abe: 3.140 | eve: 8.993 | bob: 3.186Epoch  27:  53% | abe: 3.140 | eve: 8.994 | bob: 3.186Epoch  27:  53% | abe: 3.140 | eve: 8.994 | bob: 3.185Epoch  27:  54% | abe: 3.139 | eve: 8.994 | bob: 3.185Epoch  27:  55% | abe: 3.139 | eve: 8.994 | bob: 3.185Epoch  27:  56% | abe: 3.139 | eve: 8.994 | bob: 3.185Epoch  27:  57% | abe: 3.139 | eve: 8.995 | bob: 3.184Epoch  27:  57% | abe: 3.139 | eve: 8.994 | bob: 3.184Epoch  27:  58% | abe: 3.139 | eve: 8.994 | bob: 3.184Epoch  27:  59% | abe: 3.139 | eve: 8.995 | bob: 3.184Epoch  27:  60% | abe: 3.139 | eve: 8.995 | bob: 3.184Epoch  27:  60% | abe: 3.138 | eve: 8.995 | bob: 3.183Epoch  27:  61% | abe: 3.138 | eve: 8.995 | bob: 3.183Epoch  27:  62% | abe: 3.138 | eve: 8.995 | bob: 3.183Epoch  27:  63% | abe: 3.138 | eve: 8.995 | bob: 3.182Epoch  27:  64% | abe: 3.138 | eve: 8.995 | bob: 3.182Epoch  27:  64% | abe: 3.138 | eve: 8.995 | bob: 3.183Epoch  27:  65% | abe: 3.138 | eve: 8.995 | bob: 3.183Epoch  27:  66% | abe: 3.138 | eve: 8.996 | bob: 3.183Epoch  27:  67% | abe: 3.139 | eve: 8.995 | bob: 3.183Epoch  27:  67% | abe: 3.138 | eve: 8.996 | bob: 3.183Epoch  27:  68% | abe: 3.138 | eve: 8.995 | bob: 3.183Epoch  27:  69% | abe: 3.138 | eve: 8.995 | bob: 3.182Epoch  27:  70% | abe: 3.138 | eve: 8.995 | bob: 3.182Epoch  27:  71% | abe: 3.137 | eve: 8.995 | bob: 3.182Epoch  27:  71% | abe: 3.137 | eve: 8.996 | bob: 3.181Epoch  27:  72% | abe: 3.137 | eve: 8.996 | bob: 3.181Epoch  27:  73% | abe: 3.137 | eve: 8.996 | bob: 3.181Epoch  27:  74% | abe: 3.137 | eve: 8.996 | bob: 3.181Epoch  27:  75% | abe: 3.137 | eve: 8.997 | bob: 3.180Epoch  27:  75% | abe: 3.137 | eve: 8.997 | bob: 3.181Epoch  27:  76% | abe: 3.137 | eve: 8.997 | bob: 3.180Epoch  27:  77% | abe: 3.136 | eve: 8.997 | bob: 3.180Epoch  27:  78% | abe: 3.137 | eve: 8.997 | bob: 3.181Epoch  27:  78% | abe: 3.136 | eve: 8.996 | bob: 3.180Epoch  27:  79% | abe: 3.137 | eve: 8.997 | bob: 3.180Epoch  27:  80% | abe: 3.137 | eve: 8.997 | bob: 3.180Epoch  27:  81% | abe: 3.137 | eve: 8.997 | bob: 3.180Epoch  27:  82% | abe: 3.137 | eve: 8.996 | bob: 3.180Epoch  27:  82% | abe: 3.137 | eve: 8.996 | bob: 3.180Epoch  27:  83% | abe: 3.136 | eve: 8.996 | bob: 3.180Epoch  27:  84% | abe: 3.136 | eve: 8.996 | bob: 3.180Epoch  27:  85% | abe: 3.136 | eve: 8.996 | bob: 3.180Epoch  27:  85% | abe: 3.136 | eve: 8.996 | bob: 3.180Epoch  27:  86% | abe: 3.136 | eve: 8.997 | bob: 3.179Epoch  27:  87% | abe: 3.136 | eve: 8.997 | bob: 3.179Epoch  27:  88% | abe: 3.136 | eve: 8.997 | bob: 3.179Epoch  27:  89% | abe: 3.136 | eve: 8.997 | bob: 3.179Epoch  27:  89% | abe: 3.136 | eve: 8.997 | bob: 3.179Epoch  27:  90% | abe: 3.136 | eve: 8.997 | bob: 3.179Epoch  27:  91% | abe: 3.136 | eve: 8.997 | bob: 3.179Epoch  27:  92% | abe: 3.136 | eve: 8.997 | bob: 3.179Epoch  27:  92% | abe: 3.136 | eve: 8.997 | bob: 3.178Epoch  27:  93% | abe: 3.135 | eve: 8.997 | bob: 3.178Epoch  27:  94% | abe: 3.135 | eve: 8.997 | bob: 3.178Epoch  27:  95% | abe: 3.135 | eve: 8.997 | bob: 3.177Epoch  27:  96% | abe: 3.135 | eve: 8.997 | bob: 3.177Epoch  27:  96% | abe: 3.135 | eve: 8.997 | bob: 3.177Epoch  27:  97% | abe: 3.135 | eve: 8.997 | bob: 3.177Epoch  27:  98% | abe: 3.134 | eve: 8.997 | bob: 3.176Epoch  27:  99% | abe: 3.134 | eve: 8.997 | bob: 3.177
New best Bob loss 3.176511823945134 at epoch 27
Epoch  28:   0% | abe: 3.139 | eve: 8.955 | bob: 3.184Epoch  28:   0% | abe: 3.137 | eve: 8.951 | bob: 3.175Epoch  28:   1% | abe: 3.134 | eve: 8.958 | bob: 3.169Epoch  28:   2% | abe: 3.133 | eve: 8.967 | bob: 3.168Epoch  28:   3% | abe: 3.132 | eve: 8.970 | bob: 3.167Epoch  28:   3% | abe: 3.131 | eve: 8.976 | bob: 3.165Epoch  28:   4% | abe: 3.130 | eve: 8.978 | bob: 3.162Epoch  28:   5% | abe: 3.130 | eve: 8.980 | bob: 3.163Epoch  28:   6% | abe: 3.126 | eve: 8.983 | bob: 3.159Epoch  28:   7% | abe: 3.124 | eve: 8.987 | bob: 3.157Epoch  28:   7% | abe: 3.124 | eve: 8.987 | bob: 3.157Epoch  28:   8% | abe: 3.123 | eve: 8.987 | bob: 3.155Epoch  28:   9% | abe: 3.125 | eve: 8.990 | bob: 3.157Epoch  28:  10% | abe: 3.126 | eve: 8.992 | bob: 3.159Epoch  28:  10% | abe: 3.125 | eve: 8.993 | bob: 3.157Epoch  28:  11% | abe: 3.126 | eve: 8.992 | bob: 3.159Epoch  28:  12% | abe: 3.125 | eve: 8.993 | bob: 3.158Epoch  28:  13% | abe: 3.125 | eve: 8.993 | bob: 3.159Epoch  28:  14% | abe: 3.125 | eve: 8.992 | bob: 3.159Epoch  28:  14% | abe: 3.126 | eve: 8.991 | bob: 3.160Epoch  28:  15% | abe: 3.125 | eve: 8.991 | bob: 3.159Epoch  28:  16% | abe: 3.127 | eve: 8.992 | bob: 3.161Epoch  28:  17% | abe: 3.128 | eve: 8.994 | bob: 3.162Epoch  28:  17% | abe: 3.128 | eve: 8.993 | bob: 3.162Epoch  28:  18% | abe: 3.128 | eve: 8.995 | bob: 3.162Epoch  28:  19% | abe: 3.128 | eve: 8.995 | bob: 3.162Epoch  28:  20% | abe: 3.127 | eve: 8.995 | bob: 3.161Epoch  28:  21% | abe: 3.127 | eve: 8.995 | bob: 3.161Epoch  28:  21% | abe: 3.128 | eve: 8.996 | bob: 3.162Epoch  28:  22% | abe: 3.128 | eve: 8.997 | bob: 3.162Epoch  28:  23% | abe: 3.127 | eve: 8.996 | bob: 3.161Epoch  28:  24% | abe: 3.126 | eve: 8.996 | bob: 3.161Epoch  28:  25% | abe: 3.126 | eve: 8.997 | bob: 3.160Epoch  28:  25% | abe: 3.126 | eve: 8.997 | bob: 3.160Epoch  28:  26% | abe: 3.126 | eve: 8.997 | bob: 3.161Epoch  28:  27% | abe: 3.125 | eve: 8.998 | bob: 3.160Epoch  28:  28% | abe: 3.126 | eve: 8.998 | bob: 3.161Epoch  28:  28% | abe: 3.126 | eve: 8.999 | bob: 3.160Epoch  28:  29% | abe: 3.126 | eve: 8.998 | bob: 3.160Epoch  28:  30% | abe: 3.126 | eve: 8.998 | bob: 3.161Epoch  28:  31% | abe: 3.125 | eve: 8.999 | bob: 3.159Epoch  28:  32% | abe: 3.125 | eve: 8.999 | bob: 3.160Epoch  28:  32% | abe: 3.126 | eve: 8.999 | bob: 3.161Epoch  28:  33% | abe: 3.126 | eve: 8.999 | bob: 3.161Epoch  28:  34% | abe: 3.126 | eve: 8.999 | bob: 3.161Epoch  28:  35% | abe: 3.125 | eve: 8.999 | bob: 3.160Epoch  28:  35% | abe: 3.124 | eve: 8.999 | bob: 3.159Epoch  28:  36% | abe: 3.124 | eve: 8.999 | bob: 3.159Epoch  28:  37% | abe: 3.124 | eve: 9.000 | bob: 3.159Epoch  28:  38% | abe: 3.124 | eve: 8.999 | bob: 3.159Epoch  28:  39% | abe: 3.124 | eve: 9.000 | bob: 3.159Epoch  28:  39% | abe: 3.124 | eve: 8.999 | bob: 3.159Epoch  28:  40% | abe: 3.123 | eve: 8.999 | bob: 3.158Epoch  28:  41% | abe: 3.123 | eve: 9.000 | bob: 3.158Epoch  28:  42% | abe: 3.124 | eve: 9.000 | bob: 3.159Epoch  28:  42% | abe: 3.123 | eve: 9.001 | bob: 3.158Epoch  28:  43% | abe: 3.123 | eve: 9.000 | bob: 3.158Epoch  28:  44% | abe: 3.123 | eve: 8.999 | bob: 3.158Epoch  28:  45% | abe: 3.123 | eve: 8.999 | bob: 3.158Epoch  28:  46% | abe: 3.123 | eve: 8.999 | bob: 3.158Epoch  28:  46% | abe: 3.123 | eve: 8.999 | bob: 3.158Epoch  28:  47% | abe: 3.123 | eve: 9.000 | bob: 3.158Epoch  28:  48% | abe: 3.123 | eve: 8.999 | bob: 3.157Epoch  28:  49% | abe: 3.123 | eve: 9.000 | bob: 3.158Epoch  28:  50% | abe: 3.123 | eve: 9.000 | bob: 3.158Epoch  28:  50% | abe: 3.123 | eve: 9.000 | bob: 3.158Epoch  28:  51% | abe: 3.122 | eve: 9.000 | bob: 3.158Epoch  28:  52% | abe: 3.122 | eve: 9.000 | bob: 3.157Epoch  28:  53% | abe: 3.122 | eve: 9.000 | bob: 3.157Epoch  28:  53% | abe: 3.122 | eve: 9.000 | bob: 3.157Epoch  28:  54% | abe: 3.122 | eve: 8.999 | bob: 3.157Epoch  28:  55% | abe: 3.122 | eve: 8.999 | bob: 3.157Epoch  28:  56% | abe: 3.121 | eve: 9.000 | bob: 3.156Epoch  28:  57% | abe: 3.122 | eve: 8.999 | bob: 3.156Epoch  28:  57% | abe: 3.121 | eve: 8.999 | bob: 3.156Epoch  28:  58% | abe: 3.121 | eve: 8.999 | bob: 3.156Epoch  28:  59% | abe: 3.121 | eve: 8.999 | bob: 3.155Epoch  28:  60% | abe: 3.121 | eve: 8.999 | bob: 3.155Epoch  28:  60% | abe: 3.121 | eve: 8.999 | bob: 3.155Epoch  28:  61% | abe: 3.121 | eve: 8.999 | bob: 3.155Epoch  28:  62% | abe: 3.121 | eve: 8.999 | bob: 3.155Epoch  28:  63% | abe: 3.121 | eve: 9.000 | bob: 3.155Epoch  28:  64% | abe: 3.121 | eve: 8.999 | bob: 3.155Epoch  28:  64% | abe: 3.121 | eve: 8.999 | bob: 3.155Epoch  28:  65% | abe: 3.121 | eve: 8.999 | bob: 3.156Epoch  28:  66% | abe: 3.121 | eve: 8.999 | bob: 3.155Epoch  28:  67% | abe: 3.121 | eve: 8.999 | bob: 3.156Epoch  28:  67% | abe: 3.122 | eve: 8.999 | bob: 3.156Epoch  28:  68% | abe: 3.121 | eve: 8.999 | bob: 3.155Epoch  28:  69% | abe: 3.121 | eve: 8.998 | bob: 3.156Epoch  28:  70% | abe: 3.121 | eve: 8.999 | bob: 3.155Epoch  28:  71% | abe: 3.121 | eve: 8.999 | bob: 3.155Epoch  28:  71% | abe: 3.121 | eve: 8.999 | bob: 3.155Epoch  28:  72% | abe: 3.121 | eve: 8.999 | bob: 3.155Epoch  28:  73% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  74% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  75% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  75% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  76% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  77% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  78% | abe: 3.120 | eve: 8.998 | bob: 3.154Epoch  28:  78% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  79% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  80% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  81% | abe: 3.120 | eve: 8.998 | bob: 3.154Epoch  28:  82% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  82% | abe: 3.120 | eve: 8.998 | bob: 3.154Epoch  28:  83% | abe: 3.120 | eve: 8.998 | bob: 3.154Epoch  28:  84% | abe: 3.120 | eve: 8.998 | bob: 3.154Epoch  28:  85% | abe: 3.120 | eve: 8.998 | bob: 3.154Epoch  28:  85% | abe: 3.120 | eve: 8.998 | bob: 3.154Epoch  28:  86% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  87% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  88% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  89% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  89% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  90% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  91% | abe: 3.120 | eve: 9.000 | bob: 3.154Epoch  28:  92% | abe: 3.120 | eve: 9.000 | bob: 3.154Epoch  28:  92% | abe: 3.120 | eve: 9.000 | bob: 3.154Epoch  28:  93% | abe: 3.120 | eve: 9.000 | bob: 3.154Epoch  28:  94% | abe: 3.120 | eve: 9.000 | bob: 3.154Epoch  28:  95% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  96% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  96% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  97% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  98% | abe: 3.120 | eve: 8.999 | bob: 3.154Epoch  28:  99% | abe: 3.120 | eve: 8.999 | bob: 3.154
New best Bob loss 3.153949513477187 at epoch 28
Epoch  29:   0% | abe: 3.090 | eve: 8.959 | bob: 3.115Epoch  29:   0% | abe: 3.110 | eve: 8.973 | bob: 3.140Epoch  29:   1% | abe: 3.109 | eve: 8.978 | bob: 3.138Epoch  29:   2% | abe: 3.118 | eve: 8.982 | bob: 3.147Epoch  29:   3% | abe: 3.115 | eve: 8.996 | bob: 3.144Epoch  29:   3% | abe: 3.117 | eve: 9.002 | bob: 3.147Epoch  29:   4% | abe: 3.118 | eve: 9.005 | bob: 3.149Epoch  29:   5% | abe: 3.119 | eve: 9.004 | bob: 3.150Epoch  29:   6% | abe: 3.120 | eve: 9.002 | bob: 3.149Epoch  29:   7% | abe: 3.119 | eve: 9.001 | bob: 3.148Epoch  29:   7% | abe: 3.118 | eve: 9.002 | bob: 3.147Epoch  29:   8% | abe: 3.117 | eve: 9.005 | bob: 3.146Epoch  29:   9% | abe: 3.116 | eve: 9.001 | bob: 3.145Epoch  29:  10% | abe: 3.115 | eve: 9.003 | bob: 3.144Epoch  29:  10% | abe: 3.115 | eve: 9.001 | bob: 3.144Epoch  29:  11% | abe: 3.115 | eve: 9.002 | bob: 3.144Epoch  29:  12% | abe: 3.114 | eve: 9.003 | bob: 3.143Epoch  29:  13% | abe: 3.113 | eve: 9.003 | bob: 3.142Epoch  29:  14% | abe: 3.113 | eve: 9.002 | bob: 3.141Epoch  29:  14% | abe: 3.112 | eve: 9.002 | bob: 3.140Epoch  29:  15% | abe: 3.113 | eve: 9.002 | bob: 3.141Epoch  29:  16% | abe: 3.113 | eve: 9.003 | bob: 3.141Epoch  29:  17% | abe: 3.113 | eve: 9.002 | bob: 3.141Epoch  29:  17% | abe: 3.111 | eve: 9.003 | bob: 3.140Epoch  29:  18% | abe: 3.111 | eve: 9.001 | bob: 3.140Epoch  29:  19% | abe: 3.112 | eve: 9.002 | bob: 3.141Epoch  29:  20% | abe: 3.112 | eve: 9.001 | bob: 3.141Epoch  29:  21% | abe: 3.112 | eve: 9.002 | bob: 3.141Epoch  29:  21% | abe: 3.113 | eve: 9.000 | bob: 3.143Epoch  29:  22% | abe: 3.112 | eve: 9.000 | bob: 3.143Epoch  29:  23% | abe: 3.111 | eve: 9.001 | bob: 3.141Epoch  29:  24% | abe: 3.112 | eve: 9.001 | bob: 3.142Epoch  29:  25% | abe: 3.111 | eve: 9.001 | bob: 3.141Epoch  29:  25% | abe: 3.112 | eve: 9.002 | bob: 3.142Epoch  29:  26% | abe: 3.112 | eve: 9.002 | bob: 3.142Epoch  29:  27% | abe: 3.112 | eve: 9.002 | bob: 3.142Epoch  29:  28% | abe: 3.112 | eve: 9.003 | bob: 3.141Epoch  29:  28% | abe: 3.111 | eve: 9.002 | bob: 3.141Epoch  29:  29% | abe: 3.111 | eve: 9.002 | bob: 3.140Epoch  29:  30% | abe: 3.111 | eve: 9.002 | bob: 3.140Epoch  29:  31% | abe: 3.111 | eve: 9.001 | bob: 3.140Epoch  29:  32% | abe: 3.110 | eve: 9.001 | bob: 3.140Epoch  29:  32% | abe: 3.110 | eve: 9.001 | bob: 3.139Epoch  29:  33% | abe: 3.111 | eve: 9.001 | bob: 3.140Epoch  29:  34% | abe: 3.111 | eve: 9.001 | bob: 3.140Epoch  29:  35% | abe: 3.111 | eve: 9.000 | bob: 3.140Epoch  29:  35% | abe: 3.111 | eve: 9.001 | bob: 3.140Epoch  29:  36% | abe: 3.110 | eve: 9.001 | bob: 3.139Epoch  29:  37% | abe: 3.111 | eve: 9.002 | bob: 3.139Epoch  29:  38% | abe: 3.111 | eve: 9.002 | bob: 3.140Epoch  29:  39% | abe: 3.112 | eve: 9.001 | bob: 3.141Epoch  29:  39% | abe: 3.112 | eve: 9.000 | bob: 3.141Epoch  29:  40% | abe: 3.112 | eve: 8.999 | bob: 3.141Epoch  29:  41% | abe: 3.112 | eve: 8.998 | bob: 3.141Epoch  29:  42% | abe: 3.113 | eve: 8.999 | bob: 3.142Epoch  29:  42% | abe: 3.113 | eve: 8.999 | bob: 3.142Epoch  29:  43% | abe: 3.113 | eve: 8.999 | bob: 3.141Epoch  29:  44% | abe: 3.112 | eve: 8.999 | bob: 3.141Epoch  29:  45% | abe: 3.112 | eve: 8.999 | bob: 3.141Epoch  29:  46% | abe: 3.112 | eve: 8.999 | bob: 3.141Epoch  29:  46% | abe: 3.112 | eve: 8.999 | bob: 3.141Epoch  29:  47% | abe: 3.112 | eve: 9.000 | bob: 3.141Epoch  29:  48% | abe: 3.112 | eve: 8.999 | bob: 3.141Epoch  29:  49% | abe: 3.111 | eve: 8.999 | bob: 3.140Epoch  29:  50% | abe: 3.111 | eve: 8.999 | bob: 3.140Epoch  29:  50% | abe: 3.111 | eve: 8.999 | bob: 3.140Epoch  29:  51% | abe: 3.112 | eve: 8.999 | bob: 3.140Epoch  29:  52% | abe: 3.112 | eve: 8.999 | bob: 3.141Epoch  29:  53% | abe: 3.112 | eve: 8.999 | bob: 3.141Epoch  29:  53% | abe: 3.112 | eve: 8.999 | bob: 3.140Epoch  29:  54% | abe: 3.112 | eve: 8.999 | bob: 3.140Epoch  29:  55% | abe: 3.112 | eve: 8.999 | bob: 3.140Epoch  29:  56% | abe: 3.112 | eve: 8.998 | bob: 3.140Epoch  29:  57% | abe: 3.112 | eve: 8.999 | bob: 3.140Epoch  29:  57% | abe: 3.112 | eve: 8.999 | bob: 3.140Epoch  29:  58% | abe: 3.112 | eve: 8.999 | bob: 3.140Epoch  29:  59% | abe: 3.111 | eve: 8.999 | bob: 3.140Epoch  29:  60% | abe: 3.111 | eve: 8.999 | bob: 3.140Epoch  29:  60% | abe: 3.111 | eve: 8.998 | bob: 3.139Epoch  29:  61% | abe: 3.111 | eve: 8.999 | bob: 3.140Epoch  29:  62% | abe: 3.111 | eve: 8.999 | bob: 3.140Epoch  29:  63% | abe: 3.111 | eve: 8.999 | bob: 3.139Epoch  29:  64% | abe: 3.111 | eve: 8.999 | bob: 3.139Epoch  29:  64% | abe: 3.111 | eve: 8.998 | bob: 3.140Epoch  29:  65% | abe: 3.112 | eve: 8.998 | bob: 3.140Epoch  29:  66% | abe: 3.111 | eve: 8.998 | bob: 3.140Epoch  29:  67% | abe: 3.111 | eve: 8.998 | bob: 3.139Epoch  29:  67% | abe: 3.111 | eve: 8.998 | bob: 3.139Epoch  29:  68% | abe: 3.111 | eve: 8.997 | bob: 3.139Epoch  29:  69% | abe: 3.111 | eve: 8.997 | bob: 3.139Epoch  29:  70% | abe: 3.111 | eve: 8.997 | bob: 3.139Epoch  29:  71% | abe: 3.111 | eve: 8.996 | bob: 3.139Epoch  29:  71% | abe: 3.111 | eve: 8.996 | bob: 3.139Epoch  29:  72% | abe: 3.111 | eve: 8.996 | bob: 3.139Epoch  29:  73% | abe: 3.111 | eve: 8.996 | bob: 3.139Epoch  29:  74% | abe: 3.111 | eve: 8.996 | bob: 3.139Epoch  29:  75% | abe: 3.110 | eve: 8.996 | bob: 3.138Epoch  29:  75% | abe: 3.110 | eve: 8.996 | bob: 3.138Epoch  29:  76% | abe: 3.110 | eve: 8.996 | bob: 3.138Epoch  29:  77% | abe: 3.110 | eve: 8.996 | bob: 3.138Epoch  29:  78% | abe: 3.110 | eve: 8.996 | bob: 3.138Epoch  29:  78% | abe: 3.110 | eve: 8.996 | bob: 3.138Epoch  29:  79% | abe: 3.110 | eve: 8.996 | bob: 3.138Epoch  29:  80% | abe: 3.110 | eve: 8.996 | bob: 3.138Epoch  29:  81% | abe: 3.110 | eve: 8.995 | bob: 3.138Epoch  29:  82% | abe: 3.110 | eve: 8.995 | bob: 3.138Epoch  29:  82% | abe: 3.110 | eve: 8.995 | bob: 3.138Epoch  29:  83% | abe: 3.110 | eve: 8.995 | bob: 3.138Epoch  29:  84% | abe: 3.110 | eve: 8.995 | bob: 3.138Epoch  29:  85% | abe: 3.110 | eve: 8.995 | bob: 3.137Epoch  29:  85% | abe: 3.109 | eve: 8.995 | bob: 3.137Epoch  29:  86% | abe: 3.109 | eve: 8.995 | bob: 3.137Epoch  29:  87% | abe: 3.109 | eve: 8.995 | bob: 3.137Epoch  29:  88% | abe: 3.109 | eve: 8.995 | bob: 3.137Epoch  29:  89% | abe: 3.110 | eve: 8.995 | bob: 3.138Epoch  29:  89% | abe: 3.109 | eve: 8.995 | bob: 3.138Epoch  29:  90% | abe: 3.110 | eve: 8.995 | bob: 3.138Epoch  29:  91% | abe: 3.110 | eve: 8.995 | bob: 3.138Epoch  29:  92% | abe: 3.110 | eve: 8.995 | bob: 3.138Epoch  29:  92% | abe: 3.109 | eve: 8.995 | bob: 3.138Epoch  29:  93% | abe: 3.109 | eve: 8.995 | bob: 3.137Epoch  29:  94% | abe: 3.109 | eve: 8.995 | bob: 3.137Epoch  29:  95% | abe: 3.109 | eve: 8.995 | bob: 3.137Epoch  29:  96% | abe: 3.109 | eve: 8.995 | bob: 3.137Epoch  29:  96% | abe: 3.108 | eve: 8.995 | bob: 3.136Epoch  29:  97% | abe: 3.109 | eve: 8.995 | bob: 3.137Epoch  29:  98% | abe: 3.109 | eve: 8.995 | bob: 3.137Epoch  29:  99% | abe: 3.109 | eve: 8.995 | bob: 3.136
New best Bob loss 3.136498838755756 at epoch 29
Epoch  30:   0% | abe: 3.102 | eve: 9.014 | bob: 3.130Epoch  30:   0% | abe: 3.101 | eve: 9.002 | bob: 3.129Epoch  30:   1% | abe: 3.088 | eve: 9.000 | bob: 3.115Epoch  30:   2% | abe: 3.088 | eve: 8.998 | bob: 3.116Epoch  30:   3% | abe: 3.095 | eve: 8.992 | bob: 3.123Epoch  30:   3% | abe: 3.097 | eve: 8.993 | bob: 3.126Epoch  30:   4% | abe: 3.098 | eve: 8.992 | bob: 3.126Epoch  30:   5% | abe: 3.097 | eve: 8.993 | bob: 3.126Epoch  30:   6% | abe: 3.098 | eve: 8.990 | bob: 3.127Epoch  30:   7% | abe: 3.098 | eve: 8.986 | bob: 3.127Epoch  30:   7% | abe: 3.098 | eve: 8.984 | bob: 3.126Epoch  30:   8% | abe: 3.098 | eve: 8.985 | bob: 3.125Epoch  30:   9% | abe: 3.098 | eve: 8.983 | bob: 3.125Epoch  30:  10% | abe: 3.100 | eve: 8.984 | bob: 3.127Epoch  30:  10% | abe: 3.101 | eve: 8.985 | bob: 3.128Epoch  30:  11% | abe: 3.103 | eve: 8.987 | bob: 3.130Epoch  30:  12% | abe: 3.103 | eve: 8.988 | bob: 3.131Epoch  30:  13% | abe: 3.102 | eve: 8.989 | bob: 3.129Epoch  30:  14% | abe: 3.105 | eve: 8.990 | bob: 3.132Epoch  30:  14% | abe: 3.104 | eve: 8.991 | bob: 3.132Epoch  30:  15% | abe: 3.103 | eve: 8.990 | bob: 3.131Epoch  30:  16% | abe: 3.103 | eve: 8.990 | bob: 3.130Epoch  30:  17% | abe: 3.103 | eve: 8.989 | bob: 3.131Epoch  30:  17% | abe: 3.104 | eve: 8.990 | bob: 3.131Epoch  30:  18% | abe: 3.105 | eve: 8.989 | bob: 3.133Epoch  30:  19% | abe: 3.105 | eve: 8.988 | bob: 3.133Epoch  30:  20% | abe: 3.104 | eve: 8.988 | bob: 3.132Epoch  30:  21% | abe: 3.104 | eve: 8.989 | bob: 3.132Epoch  30:  21% | abe: 3.104 | eve: 8.991 | bob: 3.132Epoch  30:  22% | abe: 3.104 | eve: 8.991 | bob: 3.132Epoch  30:  23% | abe: 3.105 | eve: 8.990 | bob: 3.132Epoch  30:  24% | abe: 3.105 | eve: 8.991 | bob: 3.133Epoch  30:  25% | abe: 3.105 | eve: 8.991 | bob: 3.133Epoch  30:  25% | abe: 3.106 | eve: 8.992 | bob: 3.135Epoch  30:  26% | abe: 3.106 | eve: 8.992 | bob: 3.134Epoch  30:  27% | abe: 3.106 | eve: 8.993 | bob: 3.134Epoch  30:  28% | abe: 3.107 | eve: 8.995 | bob: 3.135Epoch  30:  28% | abe: 3.107 | eve: 8.995 | bob: 3.134Epoch  30:  29% | abe: 3.107 | eve: 8.995 | bob: 3.134Epoch  30:  30% | abe: 3.107 | eve: 8.996 | bob: 3.135Epoch  30:  31% | abe: 3.106 | eve: 8.996 | bob: 3.134Epoch  30:  32% | abe: 3.106 | eve: 8.996 | bob: 3.133Epoch  30:  32% | abe: 3.106 | eve: 8.996 | bob: 3.134Epoch  30:  33% | abe: 3.106 | eve: 8.995 | bob: 3.134Epoch  30:  34% | abe: 3.106 | eve: 8.995 | bob: 3.134Epoch  30:  35% | abe: 3.106 | eve: 8.995 | bob: 3.134Epoch  30:  35% | abe: 3.106 | eve: 8.995 | bob: 3.134Epoch  30:  36% | abe: 3.107 | eve: 8.995 | bob: 3.134Epoch  30:  37% | abe: 3.106 | eve: 8.995 | bob: 3.135Epoch  30:  38% | abe: 3.106 | eve: 8.995 | bob: 3.134Epoch  30:  39% | abe: 3.106 | eve: 8.995 | bob: 3.134Epoch  30:  39% | abe: 3.106 | eve: 8.996 | bob: 3.134Epoch  30:  40% | abe: 3.106 | eve: 8.997 | bob: 3.134Epoch  30:  41% | abe: 3.106 | eve: 8.996 | bob: 3.134Epoch  30:  42% | abe: 3.106 | eve: 8.996 | bob: 3.134Epoch  30:  42% | abe: 3.106 | eve: 8.996 | bob: 3.134Epoch  30:  43% | abe: 3.105 | eve: 8.996 | bob: 3.133Epoch  30:  44% | abe: 3.105 | eve: 8.996 | bob: 3.133Epoch  30:  45% | abe: 3.105 | eve: 8.996 | bob: 3.133Epoch  30:  46% | abe: 3.105 | eve: 8.995 | bob: 3.133Epoch  30:  46% | abe: 3.105 | eve: 8.995 | bob: 3.133Epoch  30:  47% | abe: 3.105 | eve: 8.995 | bob: 3.134Epoch  30:  48% | abe: 3.105 | eve: 8.995 | bob: 3.134Epoch  30:  49% | abe: 3.105 | eve: 8.996 | bob: 3.134Epoch  30:  50% | abe: 3.105 | eve: 8.996 | bob: 3.134Epoch  30:  50% | abe: 3.106 | eve: 8.997 | bob: 3.134Epoch  30:  51% | abe: 3.106 | eve: 8.997 | bob: 3.134Epoch  30:  52% | abe: 3.105 | eve: 8.997 | bob: 3.134Epoch  30:  53% | abe: 3.105 | eve: 8.996 | bob: 3.134Epoch  30:  53% | abe: 3.105 | eve: 8.996 | bob: 3.134Epoch  30:  54% | abe: 3.106 | eve: 8.996 | bob: 3.134Epoch  30:  55% | abe: 3.106 | eve: 8.996 | bob: 3.134Epoch  30:  56% | abe: 3.105 | eve: 8.996 | bob: 3.134Epoch  30:  57% | abe: 3.105 | eve: 8.997 | bob: 3.134Epoch  30:  57% | abe: 3.105 | eve: 8.997 | bob: 3.134Epoch  30:  58% | abe: 3.106 | eve: 8.997 | bob: 3.134Epoch  30:  59% | abe: 3.106 | eve: 8.997 | bob: 3.134Epoch  30:  60% | abe: 3.105 | eve: 8.996 | bob: 3.134Epoch  30:  60% | abe: 3.105 | eve: 8.996 | bob: 3.134Epoch  30:  61% | abe: 3.105 | eve: 8.997 | bob: 3.134Epoch  30:  62% | abe: 3.105 | eve: 8.997 | bob: 3.134Epoch  30:  63% | abe: 3.105 | eve: 8.997 | bob: 3.134Epoch  30:  64% | abe: 3.105 | eve: 8.997 | bob: 3.134Epoch  30:  64% | abe: 3.105 | eve: 8.997 | bob: 3.134Epoch  30:  65% | abe: 3.105 | eve: 8.997 | bob: 3.134Epoch  30:  66% | abe: 3.105 | eve: 8.997 | bob: 3.134Epoch  30:  67% | abe: 3.105 | eve: 8.998 | bob: 3.134Epoch  30:  67% | abe: 3.105 | eve: 8.997 | bob: 3.134Epoch  30:  68% | abe: 3.105 | eve: 8.998 | bob: 3.134Epoch  30:  69% | abe: 3.105 | eve: 8.998 | bob: 3.134Epoch  30:  70% | abe: 3.105 | eve: 8.998 | bob: 3.134Epoch  30:  71% | abe: 3.105 | eve: 8.998 | bob: 3.134Epoch  30:  71% | abe: 3.105 | eve: 8.998 | bob: 3.133Epoch  30:  72% | abe: 3.105 | eve: 8.998 | bob: 3.133Epoch  30:  73% | abe: 3.105 | eve: 8.998 | bob: 3.133Epoch  30:  74% | abe: 3.104 | eve: 8.998 | bob: 3.133Epoch  30:  75% | abe: 3.105 | eve: 8.998 | bob: 3.133Epoch  30:  75% | abe: 3.105 | eve: 8.998 | bob: 3.133Epoch  30:  76% | abe: 3.105 | eve: 8.998 | bob: 3.133Epoch  30:  77% | abe: 3.105 | eve: 8.998 | bob: 3.133Epoch  30:  78% | abe: 3.105 | eve: 8.998 | bob: 3.133Epoch  30:  78% | abe: 3.105 | eve: 8.998 | bob: 3.133Epoch  30:  79% | abe: 3.105 | eve: 8.998 | bob: 3.133Epoch  30:  80% | abe: 3.105 | eve: 8.999 | bob: 3.133Epoch  30:  81% | abe: 3.105 | eve: 8.999 | bob: 3.133Epoch  30:  82% | abe: 3.105 | eve: 8.999 | bob: 3.133Epoch  30:  82% | abe: 3.104 | eve: 8.999 | bob: 3.132Epoch  30:  83% | abe: 3.104 | eve: 8.999 | bob: 3.132Epoch  30:  84% | abe: 3.105 | eve: 8.999 | bob: 3.133Epoch  30:  85% | abe: 3.105 | eve: 8.999 | bob: 3.132Epoch  30:  85% | abe: 3.104 | eve: 8.999 | bob: 3.132Epoch  30:  86% | abe: 3.104 | eve: 8.999 | bob: 3.132Epoch  30:  87% | abe: 3.104 | eve: 8.999 | bob: 3.132Epoch  30:  88% | abe: 3.104 | eve: 8.999 | bob: 3.131Epoch  30:  89% | abe: 3.103 | eve: 8.999 | bob: 3.131Epoch  30:  89% | abe: 3.103 | eve: 8.999 | bob: 3.131Epoch  30:  90% | abe: 3.104 | eve: 9.000 | bob: 3.131Epoch  30:  91% | abe: 3.104 | eve: 8.999 | bob: 3.131Epoch  30:  92% | abe: 3.103 | eve: 8.999 | bob: 3.131Epoch  30:  92% | abe: 3.103 | eve: 8.999 | bob: 3.131Epoch  30:  93% | abe: 3.103 | eve: 8.999 | bob: 3.131Epoch  30:  94% | abe: 3.103 | eve: 8.999 | bob: 3.130Epoch  30:  95% | abe: 3.103 | eve: 8.999 | bob: 3.130Epoch  30:  96% | abe: 3.103 | eve: 8.999 | bob: 3.131Epoch  30:  96% | abe: 3.103 | eve: 8.998 | bob: 3.131Epoch  30:  97% | abe: 3.103 | eve: 8.998 | bob: 3.131Epoch  30:  98% | abe: 3.103 | eve: 8.998 | bob: 3.131Epoch  30:  99% | abe: 3.103 | eve: 8.998 | bob: 3.131
New best Bob loss 3.1305756590827514 at epoch 30
Epoch  31:   0% | abe: 3.110 | eve: 8.995 | bob: 3.149Epoch  31:   0% | abe: 3.102 | eve: 9.010 | bob: 3.134Epoch  31:   1% | abe: 3.092 | eve: 9.013 | bob: 3.122Epoch  31:   2% | abe: 3.089 | eve: 9.016 | bob: 3.117Epoch  31:   3% | abe: 3.098 | eve: 9.019 | bob: 3.126Epoch  31:   3% | abe: 3.107 | eve: 9.009 | bob: 3.139Epoch  31:   4% | abe: 3.105 | eve: 9.008 | bob: 3.136Epoch  31:   5% | abe: 3.109 | eve: 9.008 | bob: 3.140Epoch  31:   6% | abe: 3.109 | eve: 9.005 | bob: 3.139Epoch  31:   7% | abe: 3.106 | eve: 9.003 | bob: 3.136Epoch  31:   7% | abe: 3.104 | eve: 9.004 | bob: 3.134Epoch  31:   8% | abe: 3.105 | eve: 9.004 | bob: 3.134Epoch  31:   9% | abe: 3.106 | eve: 9.003 | bob: 3.135Epoch  31:  10% | abe: 3.104 | eve: 9.002 | bob: 3.133Epoch  31:  10% | abe: 3.105 | eve: 8.999 | bob: 3.134Epoch  31:  11% | abe: 3.105 | eve: 9.000 | bob: 3.133Epoch  31:  12% | abe: 3.103 | eve: 9.001 | bob: 3.131Epoch  31:  13% | abe: 3.104 | eve: 9.001 | bob: 3.132Epoch  31:  14% | abe: 3.103 | eve: 9.000 | bob: 3.130Epoch  31:  14% | abe: 3.103 | eve: 9.000 | bob: 3.131Epoch  31:  15% | abe: 3.103 | eve: 9.000 | bob: 3.131Epoch  31:  16% | abe: 3.103 | eve: 8.999 | bob: 3.131Epoch  31:  17% | abe: 3.102 | eve: 8.998 | bob: 3.130Epoch  31:  17% | abe: 3.101 | eve: 8.998 | bob: 3.129Epoch  31:  18% | abe: 3.101 | eve: 8.999 | bob: 3.128Epoch  31:  19% | abe: 3.101 | eve: 8.998 | bob: 3.128Epoch  31:  20% | abe: 3.101 | eve: 9.000 | bob: 3.129Epoch  31:  21% | abe: 3.102 | eve: 9.000 | bob: 3.130Epoch  31:  21% | abe: 3.102 | eve: 9.001 | bob: 3.130Epoch  31:  22% | abe: 3.102 | eve: 9.000 | bob: 3.131Epoch  31:  23% | abe: 3.101 | eve: 8.999 | bob: 3.130Epoch  31:  24% | abe: 3.100 | eve: 8.997 | bob: 3.129Epoch  31:  25% | abe: 3.101 | eve: 8.997 | bob: 3.129Epoch  31:  25% | abe: 3.101 | eve: 8.997 | bob: 3.129Epoch  31:  26% | abe: 3.102 | eve: 8.997 | bob: 3.131Epoch  31:  27% | abe: 3.101 | eve: 8.998 | bob: 3.130Epoch  31:  28% | abe: 3.101 | eve: 8.998 | bob: 3.130Epoch  31:  28% | abe: 3.100 | eve: 8.999 | bob: 3.128Epoch  31:  29% | abe: 3.101 | eve: 8.998 | bob: 3.129Epoch  31:  30% | abe: 3.101 | eve: 9.000 | bob: 3.129Epoch  31:  31% | abe: 3.100 | eve: 8.999 | bob: 3.129Epoch  31:  32% | abe: 3.101 | eve: 8.998 | bob: 3.129Epoch  31:  32% | abe: 3.100 | eve: 8.999 | bob: 3.128Epoch  31:  33% | abe: 3.100 | eve: 8.999 | bob: 3.128Epoch  31:  34% | abe: 3.099 | eve: 8.999 | bob: 3.127Epoch  31:  35% | abe: 3.100 | eve: 8.999 | bob: 3.128Epoch  31:  35% | abe: 3.100 | eve: 8.999 | bob: 3.128Epoch  31:  36% | abe: 3.100 | eve: 8.999 | bob: 3.128Epoch  31:  37% | abe: 3.100 | eve: 8.999 | bob: 3.128Epoch  31:  38% | abe: 3.100 | eve: 9.000 | bob: 3.128Epoch  31:  39% | abe: 3.100 | eve: 9.000 | bob: 3.128Epoch  31:  39% | abe: 3.100 | eve: 9.000 | bob: 3.128Epoch  31:  40% | abe: 3.100 | eve: 9.000 | bob: 3.128Epoch  31:  41% | abe: 3.099 | eve: 9.000 | bob: 3.128Epoch  31:  42% | abe: 3.099 | eve: 8.999 | bob: 3.127Epoch  31:  42% | abe: 3.098 | eve: 9.000 | bob: 3.127Epoch  31:  43% | abe: 3.098 | eve: 8.999 | bob: 3.126Epoch  31:  44% | abe: 3.098 | eve: 8.999 | bob: 3.126Epoch  31:  45% | abe: 3.098 | eve: 8.999 | bob: 3.127Epoch  31:  46% | abe: 3.098 | eve: 8.999 | bob: 3.126Epoch  31:  46% | abe: 3.098 | eve: 8.999 | bob: 3.126Epoch  31:  47% | abe: 3.097 | eve: 8.999 | bob: 3.126Epoch  31:  48% | abe: 3.097 | eve: 8.998 | bob: 3.126Epoch  31:  49% | abe: 3.097 | eve: 8.998 | bob: 3.125Epoch  31:  50% | abe: 3.098 | eve: 8.998 | bob: 3.126Epoch  31:  50% | abe: 3.097 | eve: 8.998 | bob: 3.126Epoch  31:  51% | abe: 3.098 | eve: 8.998 | bob: 3.126Epoch  31:  52% | abe: 3.098 | eve: 8.997 | bob: 3.126Epoch  31:  53% | abe: 3.098 | eve: 8.998 | bob: 3.127Epoch  31:  53% | abe: 3.099 | eve: 8.998 | bob: 3.127Epoch  31:  54% | abe: 3.099 | eve: 8.998 | bob: 3.128Epoch  31:  55% | abe: 3.099 | eve: 8.998 | bob: 3.127Epoch  31:  56% | abe: 3.099 | eve: 8.998 | bob: 3.127Epoch  31:  57% | abe: 3.099 | eve: 8.998 | bob: 3.128Epoch  31:  57% | abe: 3.099 | eve: 8.998 | bob: 3.127Epoch  31:  58% | abe: 3.099 | eve: 8.998 | bob: 3.128Epoch  31:  59% | abe: 3.099 | eve: 8.998 | bob: 3.128Epoch  31:  60% | abe: 3.099 | eve: 8.998 | bob: 3.128Epoch  31:  60% | abe: 3.099 | eve: 8.998 | bob: 3.127Epoch  31:  61% | abe: 3.099 | eve: 8.998 | bob: 3.127Epoch  31:  62% | abe: 3.099 | eve: 8.998 | bob: 3.128Epoch  31:  63% | abe: 3.099 | eve: 8.997 | bob: 3.128Epoch  31:  64% | abe: 3.099 | eve: 8.997 | bob: 3.128Epoch  31:  64% | abe: 3.099 | eve: 8.997 | bob: 3.128Epoch  31:  65% | abe: 3.100 | eve: 8.997 | bob: 3.129Epoch  31:  66% | abe: 3.099 | eve: 8.997 | bob: 3.128Epoch  31:  67% | abe: 3.100 | eve: 8.997 | bob: 3.128Epoch  31:  67% | abe: 3.099 | eve: 8.997 | bob: 3.128Epoch  31:  68% | abe: 3.099 | eve: 8.997 | bob: 3.128Epoch  31:  69% | abe: 3.099 | eve: 8.996 | bob: 3.128Epoch  31:  70% | abe: 3.099 | eve: 8.996 | bob: 3.128Epoch  31:  71% | abe: 3.099 | eve: 8.996 | bob: 3.128Epoch  31:  71% | abe: 3.099 | eve: 8.996 | bob: 3.128Epoch  31:  72% | abe: 3.099 | eve: 8.996 | bob: 3.128Epoch  31:  73% | abe: 3.099 | eve: 8.996 | bob: 3.128Epoch  31:  74% | abe: 3.099 | eve: 8.996 | bob: 3.128Epoch  31:  75% | abe: 3.099 | eve: 8.996 | bob: 3.128Epoch  31:  75% | abe: 3.099 | eve: 8.996 | bob: 3.128Epoch  31:  76% | abe: 3.099 | eve: 8.995 | bob: 3.128Epoch  31:  77% | abe: 3.099 | eve: 8.995 | bob: 3.128Epoch  31:  78% | abe: 3.098 | eve: 8.996 | bob: 3.127Epoch  31:  78% | abe: 3.098 | eve: 8.996 | bob: 3.127Epoch  31:  79% | abe: 3.098 | eve: 8.996 | bob: 3.127Epoch  31:  80% | abe: 3.098 | eve: 8.996 | bob: 3.127Epoch  31:  81% | abe: 3.099 | eve: 8.996 | bob: 3.128Epoch  31:  82% | abe: 3.098 | eve: 8.996 | bob: 3.127Epoch  31:  82% | abe: 3.099 | eve: 8.996 | bob: 3.128Epoch  31:  83% | abe: 3.098 | eve: 8.996 | bob: 3.127Epoch  31:  84% | abe: 3.098 | eve: 8.996 | bob: 3.127Epoch  31:  85% | abe: 3.098 | eve: 8.996 | bob: 3.127Epoch  31:  85% | abe: 3.098 | eve: 8.996 | bob: 3.127Epoch  31:  86% | abe: 3.097 | eve: 8.996 | bob: 3.126Epoch  31:  87% | abe: 3.097 | eve: 8.996 | bob: 3.126Epoch  31:  88% | abe: 3.097 | eve: 8.995 | bob: 3.126Epoch  31:  89% | abe: 3.097 | eve: 8.995 | bob: 3.126Epoch  31:  89% | abe: 3.097 | eve: 8.995 | bob: 3.126Epoch  31:  90% | abe: 3.097 | eve: 8.995 | bob: 3.126Epoch  31:  91% | abe: 3.097 | eve: 8.995 | bob: 3.126Epoch  31:  92% | abe: 3.097 | eve: 8.995 | bob: 3.126Epoch  31:  92% | abe: 3.097 | eve: 8.995 | bob: 3.126Epoch  31:  93% | abe: 3.097 | eve: 8.995 | bob: 3.126Epoch  31:  94% | abe: 3.097 | eve: 8.995 | bob: 3.126Epoch  31:  95% | abe: 3.097 | eve: 8.995 | bob: 3.126Epoch  31:  96% | abe: 3.097 | eve: 8.995 | bob: 3.126Epoch  31:  96% | abe: 3.097 | eve: 8.995 | bob: 3.126Epoch  31:  97% | abe: 3.097 | eve: 8.995 | bob: 3.126Epoch  31:  98% | abe: 3.097 | eve: 8.995 | bob: 3.126Epoch  31:  99% | abe: 3.097 | eve: 8.995 | bob: 3.126
New best Bob loss 3.1258741791980356 at epoch 31
Epoch  32:   0% | abe: 3.077 | eve: 9.007 | bob: 3.108Epoch  32:   0% | abe: 3.083 | eve: 9.002 | bob: 3.115Epoch  32:   1% | abe: 3.086 | eve: 9.006 | bob: 3.118Epoch  32:   2% | abe: 3.091 | eve: 9.000 | bob: 3.124Epoch  32:   3% | abe: 3.091 | eve: 9.001 | bob: 3.122Epoch  32:   3% | abe: 3.093 | eve: 8.996 | bob: 3.124Epoch  32:   4% | abe: 3.093 | eve: 8.990 | bob: 3.123Epoch  32:   5% | abe: 3.095 | eve: 8.991 | bob: 3.123Epoch  32:   6% | abe: 3.094 | eve: 8.990 | bob: 3.122Epoch  32:   7% | abe: 3.098 | eve: 8.988 | bob: 3.126Epoch  32:   7% | abe: 3.097 | eve: 8.986 | bob: 3.127Epoch  32:   8% | abe: 3.098 | eve: 8.990 | bob: 3.127Epoch  32:   9% | abe: 3.097 | eve: 8.990 | bob: 3.126Epoch  32:  10% | abe: 3.097 | eve: 8.991 | bob: 3.125Epoch  32:  10% | abe: 3.097 | eve: 8.991 | bob: 3.125Epoch  32:  11% | abe: 3.097 | eve: 8.990 | bob: 3.126Epoch  32:  12% | abe: 3.098 | eve: 8.989 | bob: 3.126Epoch  32:  13% | abe: 3.097 | eve: 8.989 | bob: 3.125Epoch  32:  14% | abe: 3.098 | eve: 8.990 | bob: 3.126Epoch  32:  14% | abe: 3.099 | eve: 8.990 | bob: 3.127Epoch  32:  15% | abe: 3.098 | eve: 8.991 | bob: 3.126Epoch  32:  16% | abe: 3.099 | eve: 8.992 | bob: 3.127Epoch  32:  17% | abe: 3.100 | eve: 8.992 | bob: 3.129Epoch  32:  17% | abe: 3.102 | eve: 8.991 | bob: 3.131Epoch  32:  18% | abe: 3.100 | eve: 8.993 | bob: 3.129Epoch  32:  19% | abe: 3.100 | eve: 8.993 | bob: 3.129Epoch  32:  20% | abe: 3.100 | eve: 8.993 | bob: 3.130Epoch  32:  21% | abe: 3.099 | eve: 8.993 | bob: 3.128Epoch  32:  21% | abe: 3.099 | eve: 8.993 | bob: 3.128Epoch  32:  22% | abe: 3.098 | eve: 8.993 | bob: 3.127Epoch  32:  23% | abe: 3.098 | eve: 8.992 | bob: 3.126Epoch  32:  24% | abe: 3.097 | eve: 8.992 | bob: 3.126Epoch  32:  25% | abe: 3.097 | eve: 8.993 | bob: 3.126Epoch  32:  25% | abe: 3.097 | eve: 8.992 | bob: 3.125Epoch  32:  26% | abe: 3.096 | eve: 8.993 | bob: 3.124Epoch  32:  27% | abe: 3.097 | eve: 8.993 | bob: 3.125Epoch  32:  28% | abe: 3.095 | eve: 8.992 | bob: 3.124Epoch  32:  28% | abe: 3.095 | eve: 8.993 | bob: 3.124Epoch  32:  29% | abe: 3.096 | eve: 8.994 | bob: 3.124Epoch  32:  30% | abe: 3.097 | eve: 8.993 | bob: 3.125Epoch  32:  31% | abe: 3.096 | eve: 8.993 | bob: 3.125Epoch  32:  32% | abe: 3.096 | eve: 8.993 | bob: 3.125Epoch  32:  32% | abe: 3.096 | eve: 8.993 | bob: 3.124Epoch  32:  33% | abe: 3.096 | eve: 8.993 | bob: 3.124Epoch  32:  34% | abe: 3.096 | eve: 8.993 | bob: 3.124Epoch  32:  35% | abe: 3.096 | eve: 8.993 | bob: 3.125Epoch  32:  35% | abe: 3.096 | eve: 8.993 | bob: 3.125Epoch  32:  36% | abe: 3.096 | eve: 8.992 | bob: 3.124Epoch  32:  37% | abe: 3.095 | eve: 8.992 | bob: 3.124Epoch  32:  38% | abe: 3.094 | eve: 8.992 | bob: 3.123Epoch  32:  39% | abe: 3.094 | eve: 8.992 | bob: 3.122Epoch  32:  39% | abe: 3.094 | eve: 8.991 | bob: 3.122Epoch  32:  40% | abe: 3.093 | eve: 8.992 | bob: 3.122Epoch  32:  41% | abe: 3.093 | eve: 8.991 | bob: 3.122Epoch  32:  42% | abe: 3.093 | eve: 8.992 | bob: 3.122Epoch  32:  42% | abe: 3.093 | eve: 8.992 | bob: 3.122Epoch  32:  43% | abe: 3.093 | eve: 8.993 | bob: 3.121Epoch  32:  44% | abe: 3.093 | eve: 8.993 | bob: 3.122Epoch  32:  45% | abe: 3.093 | eve: 8.993 | bob: 3.122Epoch  32:  46% | abe: 3.093 | eve: 8.993 | bob: 3.122Epoch  32:  46% | abe: 3.092 | eve: 8.993 | bob: 3.121Epoch  32:  47% | abe: 3.093 | eve: 8.993 | bob: 3.122Epoch  32:  48% | abe: 3.093 | eve: 8.993 | bob: 3.122Epoch  32:  49% | abe: 3.093 | eve: 8.993 | bob: 3.122Epoch  32:  50% | abe: 3.093 | eve: 8.993 | bob: 3.122Epoch  32:  50% | abe: 3.092 | eve: 8.993 | bob: 3.122Epoch  32:  51% | abe: 3.092 | eve: 8.993 | bob: 3.122Epoch  32:  52% | abe: 3.092 | eve: 8.993 | bob: 3.121Epoch  32:  53% | abe: 3.092 | eve: 8.993 | bob: 3.121Epoch  32:  53% | abe: 3.092 | eve: 8.993 | bob: 3.121Epoch  32:  54% | abe: 3.091 | eve: 8.993 | bob: 3.120Epoch  32:  55% | abe: 3.092 | eve: 8.992 | bob: 3.121Epoch  32:  56% | abe: 3.092 | eve: 8.992 | bob: 3.121Epoch  32:  57% | abe: 3.092 | eve: 8.993 | bob: 3.121Epoch  32:  57% | abe: 3.092 | eve: 8.993 | bob: 3.121Epoch  32:  58% | abe: 3.092 | eve: 8.992 | bob: 3.121Epoch  32:  59% | abe: 3.092 | eve: 8.993 | bob: 3.121Epoch  32:  60% | abe: 3.092 | eve: 8.992 | bob: 3.121Epoch  32:  60% | abe: 3.092 | eve: 8.992 | bob: 3.121Epoch  32:  61% | abe: 3.092 | eve: 8.992 | bob: 3.121Epoch  32:  62% | abe: 3.091 | eve: 8.992 | bob: 3.120Epoch  32:  63% | abe: 3.091 | eve: 8.992 | bob: 3.120Epoch  32:  64% | abe: 3.091 | eve: 8.992 | bob: 3.120Epoch  32:  64% | abe: 3.091 | eve: 8.992 | bob: 3.120Epoch  32:  65% | abe: 3.091 | eve: 8.991 | bob: 3.120Epoch  32:  66% | abe: 3.091 | eve: 8.992 | bob: 3.120Epoch  32:  67% | abe: 3.091 | eve: 8.991 | bob: 3.119Epoch  32:  67% | abe: 3.091 | eve: 8.992 | bob: 3.119Epoch  32:  68% | abe: 3.091 | eve: 8.992 | bob: 3.119Epoch  32:  69% | abe: 3.091 | eve: 8.992 | bob: 3.119Epoch  32:  70% | abe: 3.091 | eve: 8.992 | bob: 3.119Epoch  32:  71% | abe: 3.091 | eve: 8.991 | bob: 3.119Epoch  32:  71% | abe: 3.091 | eve: 8.992 | bob: 3.119Epoch  32:  72% | abe: 3.091 | eve: 8.992 | bob: 3.119Epoch  32:  73% | abe: 3.090 | eve: 8.992 | bob: 3.119Epoch  32:  74% | abe: 3.090 | eve: 8.991 | bob: 3.119Epoch  32:  75% | abe: 3.090 | eve: 8.991 | bob: 3.119Epoch  32:  75% | abe: 3.090 | eve: 8.991 | bob: 3.119Epoch  32:  76% | abe: 3.090 | eve: 8.992 | bob: 3.119Epoch  32:  77% | abe: 3.090 | eve: 8.991 | bob: 3.119Epoch  32:  78% | abe: 3.090 | eve: 8.992 | bob: 3.119Epoch  32:  78% | abe: 3.090 | eve: 8.991 | bob: 3.119Epoch  32:  79% | abe: 3.090 | eve: 8.991 | bob: 3.119Epoch  32:  80% | abe: 3.090 | eve: 8.991 | bob: 3.119Epoch  32:  81% | abe: 3.090 | eve: 8.991 | bob: 3.119Epoch  32:  82% | abe: 3.090 | eve: 8.991 | bob: 3.119Epoch  32:  82% | abe: 3.090 | eve: 8.991 | bob: 3.119Epoch  32:  83% | abe: 3.090 | eve: 8.991 | bob: 3.119Epoch  32:  84% | abe: 3.090 | eve: 8.991 | bob: 3.119Epoch  32:  85% | abe: 3.090 | eve: 8.991 | bob: 3.119Epoch  32:  85% | abe: 3.090 | eve: 8.991 | bob: 3.119Epoch  32:  86% | abe: 3.090 | eve: 8.991 | bob: 3.119Epoch  32:  87% | abe: 3.090 | eve: 8.991 | bob: 3.119Epoch  32:  88% | abe: 3.090 | eve: 8.991 | bob: 3.118Epoch  32:  89% | abe: 3.090 | eve: 8.991 | bob: 3.118Epoch  32:  89% | abe: 3.090 | eve: 8.991 | bob: 3.119Epoch  32:  90% | abe: 3.090 | eve: 8.991 | bob: 3.118Epoch  32:  91% | abe: 3.090 | eve: 8.991 | bob: 3.118Epoch  32:  92% | abe: 3.090 | eve: 8.991 | bob: 3.118Epoch  32:  92% | abe: 3.090 | eve: 8.991 | bob: 3.118Epoch  32:  93% | abe: 3.090 | eve: 8.991 | bob: 3.118Epoch  32:  94% | abe: 3.090 | eve: 8.991 | bob: 3.118Epoch  32:  95% | abe: 3.090 | eve: 8.991 | bob: 3.118Epoch  32:  96% | abe: 3.090 | eve: 8.991 | bob: 3.118Epoch  32:  96% | abe: 3.090 | eve: 8.991 | bob: 3.118Epoch  32:  97% | abe: 3.090 | eve: 8.991 | bob: 3.118Epoch  32:  98% | abe: 3.090 | eve: 8.991 | bob: 3.118Epoch  32:  99% | abe: 3.090 | eve: 8.992 | bob: 3.118
New best Bob loss 3.1182419196229603 at epoch 32
Epoch  33:   0% | abe: 3.110 | eve: 8.962 | bob: 3.144Epoch  33:   0% | abe: 3.096 | eve: 8.980 | bob: 3.129Epoch  33:   1% | abe: 3.097 | eve: 8.984 | bob: 3.128Epoch  33:   2% | abe: 3.088 | eve: 8.990 | bob: 3.116Epoch  33:   3% | abe: 3.086 | eve: 8.993 | bob: 3.114Epoch  33:   3% | abe: 3.088 | eve: 8.993 | bob: 3.114Epoch  33:   4% | abe: 3.091 | eve: 8.997 | bob: 3.119Epoch  33:   5% | abe: 3.090 | eve: 8.997 | bob: 3.117Epoch  33:   6% | abe: 3.090 | eve: 9.001 | bob: 3.118Epoch  33:   7% | abe: 3.089 | eve: 9.005 | bob: 3.116Epoch  33:   7% | abe: 3.089 | eve: 9.007 | bob: 3.115Epoch  33:   8% | abe: 3.088 | eve: 9.003 | bob: 3.114Epoch  33:   9% | abe: 3.087 | eve: 9.003 | bob: 3.113Epoch  33:  10% | abe: 3.085 | eve: 9.004 | bob: 3.109Epoch  33:  10% | abe: 3.084 | eve: 9.001 | bob: 3.109Epoch  33:  11% | abe: 3.083 | eve: 9.000 | bob: 3.108Epoch  33:  12% | abe: 3.085 | eve: 8.998 | bob: 3.110Epoch  33:  13% | abe: 3.085 | eve: 8.998 | bob: 3.110Epoch  33:  14% | abe: 3.086 | eve: 8.998 | bob: 3.112Epoch  33:  14% | abe: 3.087 | eve: 8.998 | bob: 3.112Epoch  33:  15% | abe: 3.087 | eve: 8.997 | bob: 3.113Epoch  33:  16% | abe: 3.087 | eve: 8.997 | bob: 3.113Epoch  33:  17% | abe: 3.087 | eve: 8.997 | bob: 3.113Epoch  33:  17% | abe: 3.087 | eve: 8.995 | bob: 3.113Epoch  33:  18% | abe: 3.087 | eve: 8.995 | bob: 3.113Epoch  33:  19% | abe: 3.088 | eve: 8.996 | bob: 3.114Epoch  33:  20% | abe: 3.088 | eve: 8.994 | bob: 3.114Epoch  33:  21% | abe: 3.089 | eve: 8.995 | bob: 3.115Epoch  33:  21% | abe: 3.090 | eve: 8.994 | bob: 3.117Epoch  33:  22% | abe: 3.090 | eve: 8.995 | bob: 3.117Epoch  33:  23% | abe: 3.091 | eve: 8.994 | bob: 3.118Epoch  33:  24% | abe: 3.090 | eve: 8.994 | bob: 3.118Epoch  33:  25% | abe: 3.090 | eve: 8.994 | bob: 3.117Epoch  33:  25% | abe: 3.091 | eve: 8.995 | bob: 3.119Epoch  33:  26% | abe: 3.090 | eve: 8.995 | bob: 3.117Epoch  33:  27% | abe: 3.090 | eve: 8.995 | bob: 3.117Epoch  33:  28% | abe: 3.089 | eve: 8.994 | bob: 3.117Epoch  33:  28% | abe: 3.090 | eve: 8.994 | bob: 3.117Epoch  33:  29% | abe: 3.089 | eve: 8.994 | bob: 3.117Epoch  33:  30% | abe: 3.089 | eve: 8.994 | bob: 3.116Epoch  33:  31% | abe: 3.090 | eve: 8.994 | bob: 3.117Epoch  33:  32% | abe: 3.090 | eve: 8.994 | bob: 3.117Epoch  33:  32% | abe: 3.089 | eve: 8.994 | bob: 3.117Epoch  33:  33% | abe: 3.090 | eve: 8.994 | bob: 3.117Epoch  33:  34% | abe: 3.089 | eve: 8.994 | bob: 3.116Epoch  33:  35% | abe: 3.090 | eve: 8.993 | bob: 3.116Epoch  33:  35% | abe: 3.090 | eve: 8.994 | bob: 3.117Epoch  33:  36% | abe: 3.090 | eve: 8.993 | bob: 3.117Epoch  33:  37% | abe: 3.090 | eve: 8.993 | bob: 3.117Epoch  33:  38% | abe: 3.090 | eve: 8.993 | bob: 3.118Epoch  33:  39% | abe: 3.091 | eve: 8.993 | bob: 3.118Epoch  33:  39% | abe: 3.091 | eve: 8.994 | bob: 3.118Epoch  33:  40% | abe: 3.091 | eve: 8.993 | bob: 3.118Epoch  33:  41% | abe: 3.091 | eve: 8.994 | bob: 3.119Epoch  33:  42% | abe: 3.091 | eve: 8.993 | bob: 3.119Epoch  33:  42% | abe: 3.092 | eve: 8.993 | bob: 3.119Epoch  33:  43% | abe: 3.091 | eve: 8.994 | bob: 3.118Epoch  33:  44% | abe: 3.090 | eve: 8.993 | bob: 3.118Epoch  33:  45% | abe: 3.090 | eve: 8.993 | bob: 3.118Epoch  33:  46% | abe: 3.091 | eve: 8.993 | bob: 3.118Epoch  33:  46% | abe: 3.091 | eve: 8.992 | bob: 3.118Epoch  33:  47% | abe: 3.091 | eve: 8.993 | bob: 3.118Epoch  33:  48% | abe: 3.091 | eve: 8.993 | bob: 3.118Epoch  33:  49% | abe: 3.091 | eve: 8.992 | bob: 3.119Epoch  33:  50% | abe: 3.091 | eve: 8.992 | bob: 3.119Epoch  33:  50% | abe: 3.091 | eve: 8.992 | bob: 3.118Epoch  33:  51% | abe: 3.091 | eve: 8.992 | bob: 3.119Epoch  33:  52% | abe: 3.091 | eve: 8.992 | bob: 3.119Epoch  33:  53% | abe: 3.091 | eve: 8.992 | bob: 3.118Epoch  33:  53% | abe: 3.090 | eve: 8.992 | bob: 3.118Epoch  33:  54% | abe: 3.090 | eve: 8.991 | bob: 3.119Epoch  33:  55% | abe: 3.090 | eve: 8.992 | bob: 3.118Epoch  33:  56% | abe: 3.090 | eve: 8.992 | bob: 3.118Epoch  33:  57% | abe: 3.090 | eve: 8.992 | bob: 3.118Epoch  33:  57% | abe: 3.090 | eve: 8.991 | bob: 3.118Epoch  33:  58% | abe: 3.090 | eve: 8.992 | bob: 3.119Epoch  33:  59% | abe: 3.091 | eve: 8.992 | bob: 3.119Epoch  33:  60% | abe: 3.091 | eve: 8.992 | bob: 3.119Epoch  33:  60% | abe: 3.091 | eve: 8.992 | bob: 3.119Epoch  33:  61% | abe: 3.091 | eve: 8.992 | bob: 3.119Epoch  33:  62% | abe: 3.091 | eve: 8.992 | bob: 3.119Epoch  33:  63% | abe: 3.091 | eve: 8.992 | bob: 3.119Epoch  33:  64% | abe: 3.091 | eve: 8.993 | bob: 3.119Epoch  33:  64% | abe: 3.091 | eve: 8.993 | bob: 3.120Epoch  33:  65% | abe: 3.091 | eve: 8.993 | bob: 3.120Epoch  33:  66% | abe: 3.091 | eve: 8.993 | bob: 3.120Epoch  33:  67% | abe: 3.091 | eve: 8.993 | bob: 3.120Epoch  33:  67% | abe: 3.091 | eve: 8.993 | bob: 3.120Epoch  33:  68% | abe: 3.091 | eve: 8.993 | bob: 3.119Epoch  33:  69% | abe: 3.091 | eve: 8.993 | bob: 3.120Epoch  33:  70% | abe: 3.090 | eve: 8.993 | bob: 3.119Epoch  33:  71% | abe: 3.091 | eve: 8.993 | bob: 3.119Epoch  33:  71% | abe: 3.091 | eve: 8.993 | bob: 3.119Epoch  33:  72% | abe: 3.091 | eve: 8.993 | bob: 3.120Epoch  33:  73% | abe: 3.091 | eve: 8.993 | bob: 3.120Epoch  33:  74% | abe: 3.091 | eve: 8.993 | bob: 3.119Epoch  33:  75% | abe: 3.090 | eve: 8.993 | bob: 3.119Epoch  33:  75% | abe: 3.090 | eve: 8.993 | bob: 3.119Epoch  33:  76% | abe: 3.090 | eve: 8.993 | bob: 3.119Epoch  33:  77% | abe: 3.090 | eve: 8.993 | bob: 3.119Epoch  33:  78% | abe: 3.091 | eve: 8.993 | bob: 3.120Epoch  33:  78% | abe: 3.090 | eve: 8.993 | bob: 3.120Epoch  33:  79% | abe: 3.091 | eve: 8.993 | bob: 3.120Epoch  33:  80% | abe: 3.091 | eve: 8.993 | bob: 3.120Epoch  33:  81% | abe: 3.090 | eve: 8.993 | bob: 3.119Epoch  33:  82% | abe: 3.090 | eve: 8.993 | bob: 3.120Epoch  33:  82% | abe: 3.090 | eve: 8.993 | bob: 3.120Epoch  33:  83% | abe: 3.090 | eve: 8.993 | bob: 3.119Epoch  33:  84% | abe: 3.090 | eve: 8.993 | bob: 3.120Epoch  33:  85% | abe: 3.090 | eve: 8.993 | bob: 3.120Epoch  33:  85% | abe: 3.090 | eve: 8.993 | bob: 3.120Epoch  33:  86% | abe: 3.091 | eve: 8.992 | bob: 3.120Epoch  33:  87% | abe: 3.091 | eve: 8.992 | bob: 3.120Epoch  33:  88% | abe: 3.091 | eve: 8.992 | bob: 3.121Epoch  33:  89% | abe: 3.091 | eve: 8.993 | bob: 3.120Epoch  33:  89% | abe: 3.091 | eve: 8.992 | bob: 3.120Epoch  33:  90% | abe: 3.091 | eve: 8.993 | bob: 3.121Epoch  33:  91% | abe: 3.091 | eve: 8.993 | bob: 3.121Epoch  33:  92% | abe: 3.091 | eve: 8.993 | bob: 3.121Epoch  33:  92% | abe: 3.091 | eve: 8.993 | bob: 3.120Epoch  33:  93% | abe: 3.091 | eve: 8.993 | bob: 3.120Epoch  33:  94% | abe: 3.091 | eve: 8.993 | bob: 3.120Epoch  33:  95% | abe: 3.091 | eve: 8.993 | bob: 3.121Epoch  33:  96% | abe: 3.091 | eve: 8.993 | bob: 3.121Epoch  33:  96% | abe: 3.091 | eve: 8.993 | bob: 3.121Epoch  33:  97% | abe: 3.091 | eve: 8.993 | bob: 3.120Epoch  33:  98% | abe: 3.091 | eve: 8.993 | bob: 3.121Epoch  33:  99% | abe: 3.091 | eve: 8.993 | bob: 3.121Epoch  34:   0% | abe: 3.108 | eve: 8.967 | bob: 3.138Epoch  34:   0% | abe: 3.101 | eve: 8.973 | bob: 3.125Epoch  34:   1% | abe: 3.092 | eve: 8.972 | bob: 3.120Epoch  34:   2% | abe: 3.094 | eve: 8.977 | bob: 3.122Epoch  34:   3% | abe: 3.095 | eve: 8.981 | bob: 3.126Epoch  34:   3% | abe: 3.089 | eve: 8.972 | bob: 3.119Epoch  34:   4% | abe: 3.088 | eve: 8.972 | bob: 3.118Epoch  34:   5% | abe: 3.088 | eve: 8.971 | bob: 3.117Epoch  34:   6% | abe: 3.087 | eve: 8.971 | bob: 3.118Epoch  34:   7% | abe: 3.087 | eve: 8.973 | bob: 3.118Epoch  34:   7% | abe: 3.089 | eve: 8.972 | bob: 3.120Epoch  34:   8% | abe: 3.088 | eve: 8.976 | bob: 3.118Epoch  34:   9% | abe: 3.091 | eve: 8.976 | bob: 3.122Epoch  34:  10% | abe: 3.092 | eve: 8.976 | bob: 3.123Epoch  34:  10% | abe: 3.091 | eve: 8.977 | bob: 3.123Epoch  34:  11% | abe: 3.091 | eve: 8.979 | bob: 3.123Epoch  34:  12% | abe: 3.094 | eve: 8.982 | bob: 3.127Epoch  34:  13% | abe: 3.095 | eve: 8.983 | bob: 3.127Epoch  34:  14% | abe: 3.095 | eve: 8.983 | bob: 3.128Epoch  34:  14% | abe: 3.095 | eve: 8.984 | bob: 3.128Epoch  34:  15% | abe: 3.094 | eve: 8.984 | bob: 3.127Epoch  34:  16% | abe: 3.093 | eve: 8.984 | bob: 3.125Epoch  34:  17% | abe: 3.094 | eve: 8.985 | bob: 3.126Epoch  34:  17% | abe: 3.092 | eve: 8.986 | bob: 3.124Epoch  34:  18% | abe: 3.092 | eve: 8.985 | bob: 3.124Epoch  34:  19% | abe: 3.093 | eve: 8.986 | bob: 3.124Epoch  34:  20% | abe: 3.093 | eve: 8.985 | bob: 3.125Epoch  34:  21% | abe: 3.093 | eve: 8.985 | bob: 3.125Epoch  34:  21% | abe: 3.094 | eve: 8.984 | bob: 3.126Epoch  34:  22% | abe: 3.094 | eve: 8.985 | bob: 3.126Epoch  34:  23% | abe: 3.095 | eve: 8.985 | bob: 3.127Epoch  34:  24% | abe: 3.095 | eve: 8.986 | bob: 3.127Epoch  34:  25% | abe: 3.096 | eve: 8.985 | bob: 3.128Epoch  34:  25% | abe: 3.096 | eve: 8.985 | bob: 3.128Epoch  34:  26% | abe: 3.096 | eve: 8.985 | bob: 3.128Epoch  34:  27% | abe: 3.096 | eve: 8.985 | bob: 3.128Epoch  34:  28% | abe: 3.096 | eve: 8.985 | bob: 3.128Epoch  34:  28% | abe: 3.096 | eve: 8.986 | bob: 3.129Epoch  34:  29% | abe: 3.096 | eve: 8.985 | bob: 3.129Epoch  34:  30% | abe: 3.096 | eve: 8.985 | bob: 3.129Epoch  34:  31% | abe: 3.097 | eve: 8.985 | bob: 3.130Epoch  34:  32% | abe: 3.096 | eve: 8.985 | bob: 3.129Epoch  34:  32% | abe: 3.096 | eve: 8.985 | bob: 3.128Epoch  34:  33% | abe: 3.096 | eve: 8.985 | bob: 3.128Epoch  34:  34% | abe: 3.096 | eve: 8.984 | bob: 3.129Epoch  34:  35% | abe: 3.096 | eve: 8.984 | bob: 3.129Epoch  34:  35% | abe: 3.095 | eve: 8.984 | bob: 3.128Epoch  34:  36% | abe: 3.095 | eve: 8.985 | bob: 3.128Epoch  34:  37% | abe: 3.095 | eve: 8.985 | bob: 3.128Epoch  34:  38% | abe: 3.095 | eve: 8.986 | bob: 3.128Epoch  34:  39% | abe: 3.095 | eve: 8.986 | bob: 3.127Epoch  34:  39% | abe: 3.094 | eve: 8.986 | bob: 3.126Epoch  34:  40% | abe: 3.094 | eve: 8.987 | bob: 3.127Epoch  34:  41% | abe: 3.094 | eve: 8.987 | bob: 3.126Epoch  34:  42% | abe: 3.094 | eve: 8.986 | bob: 3.126Epoch  34:  42% | abe: 3.094 | eve: 8.987 | bob: 3.125Epoch  34:  43% | abe: 3.094 | eve: 8.987 | bob: 3.125Epoch  34:  44% | abe: 3.094 | eve: 8.987 | bob: 3.125Epoch  34:  45% | abe: 3.094 | eve: 8.987 | bob: 3.125Epoch  34:  46% | abe: 3.093 | eve: 8.987 | bob: 3.125Epoch  34:  46% | abe: 3.093 | eve: 8.987 | bob: 3.124Epoch  34:  47% | abe: 3.093 | eve: 8.987 | bob: 3.124Epoch  34:  48% | abe: 3.093 | eve: 8.986 | bob: 3.124Epoch  34:  49% | abe: 3.094 | eve: 8.986 | bob: 3.125Epoch  34:  50% | abe: 3.094 | eve: 8.986 | bob: 3.125Epoch  34:  50% | abe: 3.093 | eve: 8.987 | bob: 3.125Epoch  34:  51% | abe: 3.093 | eve: 8.987 | bob: 3.124Epoch  34:  52% | abe: 3.093 | eve: 8.987 | bob: 3.124Epoch  34:  53% | abe: 3.094 | eve: 8.987 | bob: 3.125Epoch  34:  53% | abe: 3.093 | eve: 8.987 | bob: 3.124Epoch  34:  54% | abe: 3.093 | eve: 8.987 | bob: 3.124Epoch  34:  55% | abe: 3.093 | eve: 8.987 | bob: 3.124Epoch  34:  56% | abe: 3.093 | eve: 8.987 | bob: 3.124Epoch  34:  57% | abe: 3.093 | eve: 8.988 | bob: 3.123Epoch  34:  57% | abe: 3.093 | eve: 8.987 | bob: 3.123Epoch  34:  58% | abe: 3.093 | eve: 8.987 | bob: 3.123Epoch  34:  59% | abe: 3.093 | eve: 8.987 | bob: 3.124Epoch  34:  60% | abe: 3.093 | eve: 8.986 | bob: 3.124Epoch  34:  60% | abe: 3.093 | eve: 8.987 | bob: 3.124Epoch  34:  61% | abe: 3.093 | eve: 8.987 | bob: 3.124Epoch  34:  62% | abe: 3.093 | eve: 8.986 | bob: 3.124Epoch  34:  63% | abe: 3.093 | eve: 8.986 | bob: 3.123Epoch  34:  64% | abe: 3.093 | eve: 8.986 | bob: 3.124Epoch  34:  64% | abe: 3.093 | eve: 8.987 | bob: 3.124Epoch  34:  65% | abe: 3.093 | eve: 8.987 | bob: 3.123Epoch  34:  66% | abe: 3.093 | eve: 8.987 | bob: 3.123Epoch  34:  67% | abe: 3.093 | eve: 8.987 | bob: 3.124Epoch  34:  67% | abe: 3.093 | eve: 8.987 | bob: 3.124Epoch  34:  68% | abe: 3.093 | eve: 8.987 | bob: 3.124Epoch  34:  69% | abe: 3.093 | eve: 8.987 | bob: 3.124Epoch  34:  70% | abe: 3.092 | eve: 8.988 | bob: 3.123Epoch  34:  71% | abe: 3.092 | eve: 8.988 | bob: 3.123Epoch  34:  71% | abe: 3.093 | eve: 8.988 | bob: 3.123Epoch  34:  72% | abe: 3.092 | eve: 8.988 | bob: 3.123Epoch  34:  73% | abe: 3.093 | eve: 8.988 | bob: 3.123Epoch  34:  74% | abe: 3.093 | eve: 8.988 | bob: 3.123Epoch  34:  75% | abe: 3.093 | eve: 8.988 | bob: 3.124Epoch  34:  75% | abe: 3.093 | eve: 8.989 | bob: 3.124Epoch  34:  76% | abe: 3.093 | eve: 8.989 | bob: 3.123Epoch  34:  77% | abe: 3.093 | eve: 8.989 | bob: 3.123Epoch  34:  78% | abe: 3.092 | eve: 8.989 | bob: 3.123Epoch  34:  78% | abe: 3.092 | eve: 8.989 | bob: 3.123Epoch  34:  79% | abe: 3.093 | eve: 8.990 | bob: 3.123Epoch  34:  80% | abe: 3.093 | eve: 8.990 | bob: 3.123Epoch  34:  81% | abe: 3.092 | eve: 8.989 | bob: 3.123Epoch  34:  82% | abe: 3.092 | eve: 8.989 | bob: 3.123Epoch  34:  82% | abe: 3.093 | eve: 8.989 | bob: 3.123Epoch  34:  83% | abe: 3.093 | eve: 8.989 | bob: 3.124Epoch  34:  84% | abe: 3.093 | eve: 8.989 | bob: 3.124Epoch  34:  85% | abe: 3.093 | eve: 8.989 | bob: 3.124Epoch  34:  85% | abe: 3.093 | eve: 8.989 | bob: 3.124Epoch  34:  86% | abe: 3.093 | eve: 8.989 | bob: 3.124Epoch  34:  87% | abe: 3.093 | eve: 8.989 | bob: 3.124Epoch  34:  88% | abe: 3.093 | eve: 8.989 | bob: 3.125Epoch  34:  89% | abe: 3.093 | eve: 8.989 | bob: 3.124Epoch  34:  89% | abe: 3.093 | eve: 8.989 | bob: 3.124Epoch  34:  90% | abe: 3.093 | eve: 8.990 | bob: 3.124Epoch  34:  91% | abe: 3.093 | eve: 8.989 | bob: 3.124Epoch  34:  92% | abe: 3.093 | eve: 8.990 | bob: 3.124Epoch  34:  92% | abe: 3.093 | eve: 8.990 | bob: 3.124Epoch  34:  93% | abe: 3.093 | eve: 8.990 | bob: 3.124Epoch  34:  94% | abe: 3.093 | eve: 8.990 | bob: 3.124Epoch  34:  95% | abe: 3.093 | eve: 8.990 | bob: 3.124Epoch  34:  96% | abe: 3.093 | eve: 8.990 | bob: 3.124Epoch  34:  96% | abe: 3.093 | eve: 8.991 | bob: 3.124Epoch  34:  97% | abe: 3.093 | eve: 8.991 | bob: 3.124Epoch  34:  98% | abe: 3.093 | eve: 8.990 | bob: 3.124Epoch  34:  99% | abe: 3.093 | eve: 8.991 | bob: 3.124Epoch  35:   0% | abe: 3.079 | eve: 9.023 | bob: 3.106Epoch  35:   0% | abe: 3.085 | eve: 9.000 | bob: 3.114Epoch  35:   1% | abe: 3.100 | eve: 8.990 | bob: 3.132Epoch  35:   2% | abe: 3.099 | eve: 8.995 | bob: 3.132Epoch  35:   3% | abe: 3.098 | eve: 9.003 | bob: 3.129Epoch  35:   3% | abe: 3.093 | eve: 8.998 | bob: 3.122Epoch  35:   4% | abe: 3.094 | eve: 9.001 | bob: 3.124Epoch  35:   5% | abe: 3.088 | eve: 8.995 | bob: 3.117Epoch  35:   6% | abe: 3.090 | eve: 8.995 | bob: 3.118Epoch  35:   7% | abe: 3.089 | eve: 8.999 | bob: 3.117Epoch  35:   7% | abe: 3.087 | eve: 8.995 | bob: 3.114Epoch  35:   8% | abe: 3.088 | eve: 8.997 | bob: 3.117Epoch  35:   9% | abe: 3.088 | eve: 8.996 | bob: 3.116Epoch  35:  10% | abe: 3.087 | eve: 8.997 | bob: 3.115Epoch  35:  10% | abe: 3.086 | eve: 8.994 | bob: 3.114Epoch  35:  11% | abe: 3.087 | eve: 8.995 | bob: 3.116Epoch  35:  12% | abe: 3.088 | eve: 8.994 | bob: 3.117Epoch  35:  13% | abe: 3.087 | eve: 8.993 | bob: 3.115Epoch  35:  14% | abe: 3.087 | eve: 8.995 | bob: 3.115Epoch  35:  14% | abe: 3.086 | eve: 8.996 | bob: 3.114Epoch  35:  15% | abe: 3.087 | eve: 8.996 | bob: 3.115Epoch  35:  16% | abe: 3.086 | eve: 8.995 | bob: 3.115Epoch  35:  17% | abe: 3.086 | eve: 8.995 | bob: 3.114Epoch  35:  17% | abe: 3.085 | eve: 8.995 | bob: 3.114Epoch  35:  18% | abe: 3.086 | eve: 8.995 | bob: 3.115Epoch  35:  19% | abe: 3.087 | eve: 8.995 | bob: 3.116Epoch  35:  20% | abe: 3.087 | eve: 8.994 | bob: 3.117Epoch  35:  21% | abe: 3.087 | eve: 8.994 | bob: 3.117Epoch  35:  21% | abe: 3.088 | eve: 8.996 | bob: 3.118Epoch  35:  22% | abe: 3.087 | eve: 8.996 | bob: 3.118Epoch  35:  23% | abe: 3.088 | eve: 8.996 | bob: 3.118Epoch  35:  24% | abe: 3.088 | eve: 8.996 | bob: 3.119Epoch  35:  25% | abe: 3.088 | eve: 8.996 | bob: 3.119Epoch  35:  25% | abe: 3.089 | eve: 8.995 | bob: 3.119Epoch  35:  26% | abe: 3.089 | eve: 8.996 | bob: 3.120Epoch  35:  27% | abe: 3.089 | eve: 8.995 | bob: 3.119Epoch  35:  28% | abe: 3.090 | eve: 8.996 | bob: 3.120Epoch  35:  28% | abe: 3.090 | eve: 8.996 | bob: 3.120Epoch  35:  29% | abe: 3.090 | eve: 8.995 | bob: 3.121Epoch  35:  30% | abe: 3.090 | eve: 8.996 | bob: 3.121Epoch  35:  31% | abe: 3.090 | eve: 8.996 | bob: 3.120Epoch  35:  32% | abe: 3.090 | eve: 8.996 | bob: 3.121Epoch  35:  32% | abe: 3.090 | eve: 8.995 | bob: 3.120Epoch  35:  33% | abe: 3.089 | eve: 8.996 | bob: 3.120Epoch  35:  34% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  35:  35% | abe: 3.089 | eve: 8.996 | bob: 3.120Epoch  35:  35% | abe: 3.089 | eve: 8.997 | bob: 3.120Epoch  35:  36% | abe: 3.089 | eve: 8.997 | bob: 3.120Epoch  35:  37% | abe: 3.089 | eve: 8.997 | bob: 3.119Epoch  35:  38% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  39% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  39% | abe: 3.088 | eve: 8.997 | bob: 3.118Epoch  35:  40% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  41% | abe: 3.089 | eve: 8.997 | bob: 3.119Epoch  35:  42% | abe: 3.088 | eve: 8.998 | bob: 3.118Epoch  35:  42% | abe: 3.088 | eve: 8.997 | bob: 3.118Epoch  35:  43% | abe: 3.088 | eve: 8.998 | bob: 3.118Epoch  35:  44% | abe: 3.087 | eve: 8.997 | bob: 3.118Epoch  35:  45% | abe: 3.088 | eve: 8.997 | bob: 3.118Epoch  35:  46% | abe: 3.087 | eve: 8.998 | bob: 3.118Epoch  35:  46% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  47% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  48% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  49% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  50% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  50% | abe: 3.088 | eve: 8.998 | bob: 3.119Epoch  35:  51% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  52% | abe: 3.088 | eve: 8.998 | bob: 3.119Epoch  35:  53% | abe: 3.089 | eve: 8.997 | bob: 3.120Epoch  35:  53% | abe: 3.088 | eve: 8.997 | bob: 3.120Epoch  35:  54% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  55% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  56% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  57% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  57% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  58% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  59% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  60% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  60% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  61% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  62% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  63% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  64% | abe: 3.088 | eve: 8.996 | bob: 3.119Epoch  35:  64% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  65% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  66% | abe: 3.088 | eve: 8.996 | bob: 3.119Epoch  35:  67% | abe: 3.088 | eve: 8.996 | bob: 3.119Epoch  35:  67% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  68% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  69% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  70% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  71% | abe: 3.088 | eve: 8.997 | bob: 3.119Epoch  35:  71% | abe: 3.088 | eve: 8.997 | bob: 3.118Epoch  35:  72% | abe: 3.087 | eve: 8.996 | bob: 3.118Epoch  35:  73% | abe: 3.088 | eve: 8.996 | bob: 3.118Epoch  35:  74% | abe: 3.088 | eve: 8.996 | bob: 3.118Epoch  35:  75% | abe: 3.088 | eve: 8.996 | bob: 3.119Epoch  35:  75% | abe: 3.088 | eve: 8.996 | bob: 3.119Epoch  35:  76% | abe: 3.088 | eve: 8.996 | bob: 3.119Epoch  35:  77% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  35:  78% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  35:  78% | abe: 3.088 | eve: 8.996 | bob: 3.119Epoch  35:  79% | abe: 3.088 | eve: 8.996 | bob: 3.119Epoch  35:  80% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  35:  81% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  35:  82% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  35:  82% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  35:  83% | abe: 3.089 | eve: 8.995 | bob: 3.119Epoch  35:  84% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  35:  85% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  35:  85% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  35:  86% | abe: 3.089 | eve: 8.996 | bob: 3.120Epoch  35:  87% | abe: 3.089 | eve: 8.995 | bob: 3.119Epoch  35:  88% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  35:  89% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  35:  89% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  35:  90% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  35:  91% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  35:  92% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  35:  92% | abe: 3.089 | eve: 8.994 | bob: 3.120Epoch  35:  93% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  35:  94% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  35:  95% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  35:  96% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  35:  96% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  35:  97% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  35:  98% | abe: 3.089 | eve: 8.994 | bob: 3.120Epoch  35:  99% | abe: 3.089 | eve: 8.994 | bob: 3.120Epoch  36:   0% | abe: 3.104 | eve: 8.932 | bob: 3.136Epoch  36:   0% | abe: 3.092 | eve: 8.980 | bob: 3.126Epoch  36:   1% | abe: 3.088 | eve: 8.996 | bob: 3.122Epoch  36:   2% | abe: 3.085 | eve: 8.994 | bob: 3.118Epoch  36:   3% | abe: 3.079 | eve: 8.999 | bob: 3.112Epoch  36:   3% | abe: 3.077 | eve: 9.000 | bob: 3.108Epoch  36:   4% | abe: 3.075 | eve: 9.004 | bob: 3.104Epoch  36:   5% | abe: 3.078 | eve: 8.999 | bob: 3.108Epoch  36:   6% | abe: 3.078 | eve: 8.999 | bob: 3.109Epoch  36:   7% | abe: 3.080 | eve: 8.996 | bob: 3.111Epoch  36:   7% | abe: 3.082 | eve: 8.995 | bob: 3.113Epoch  36:   8% | abe: 3.079 | eve: 8.996 | bob: 3.110Epoch  36:   9% | abe: 3.079 | eve: 9.001 | bob: 3.110Epoch  36:  10% | abe: 3.079 | eve: 9.001 | bob: 3.110Epoch  36:  10% | abe: 3.079 | eve: 9.003 | bob: 3.109Epoch  36:  11% | abe: 3.078 | eve: 9.002 | bob: 3.108Epoch  36:  12% | abe: 3.078 | eve: 9.004 | bob: 3.108Epoch  36:  13% | abe: 3.078 | eve: 9.005 | bob: 3.107Epoch  36:  14% | abe: 3.078 | eve: 9.002 | bob: 3.107Epoch  36:  14% | abe: 3.078 | eve: 9.005 | bob: 3.108Epoch  36:  15% | abe: 3.079 | eve: 9.004 | bob: 3.110Epoch  36:  16% | abe: 3.081 | eve: 9.001 | bob: 3.112Epoch  36:  17% | abe: 3.081 | eve: 9.002 | bob: 3.113Epoch  36:  17% | abe: 3.081 | eve: 9.001 | bob: 3.113Epoch  36:  18% | abe: 3.082 | eve: 9.000 | bob: 3.113Epoch  36:  19% | abe: 3.082 | eve: 9.000 | bob: 3.113Epoch  36:  20% | abe: 3.083 | eve: 9.001 | bob: 3.114Epoch  36:  21% | abe: 3.084 | eve: 9.001 | bob: 3.116Epoch  36:  21% | abe: 3.085 | eve: 9.000 | bob: 3.117Epoch  36:  22% | abe: 3.085 | eve: 9.000 | bob: 3.116Epoch  36:  23% | abe: 3.085 | eve: 8.999 | bob: 3.117Epoch  36:  24% | abe: 3.085 | eve: 8.998 | bob: 3.117Epoch  36:  25% | abe: 3.085 | eve: 8.998 | bob: 3.117Epoch  36:  25% | abe: 3.086 | eve: 8.999 | bob: 3.118Epoch  36:  26% | abe: 3.086 | eve: 8.998 | bob: 3.118Epoch  36:  27% | abe: 3.086 | eve: 8.999 | bob: 3.118Epoch  36:  28% | abe: 3.086 | eve: 8.998 | bob: 3.118Epoch  36:  28% | abe: 3.086 | eve: 8.998 | bob: 3.119Epoch  36:  29% | abe: 3.086 | eve: 8.997 | bob: 3.118Epoch  36:  30% | abe: 3.086 | eve: 8.997 | bob: 3.119Epoch  36:  31% | abe: 3.086 | eve: 8.997 | bob: 3.119Epoch  36:  32% | abe: 3.087 | eve: 8.997 | bob: 3.119Epoch  36:  32% | abe: 3.087 | eve: 8.996 | bob: 3.119Epoch  36:  33% | abe: 3.087 | eve: 8.996 | bob: 3.119Epoch  36:  34% | abe: 3.087 | eve: 8.996 | bob: 3.119Epoch  36:  35% | abe: 3.087 | eve: 8.995 | bob: 3.119Epoch  36:  35% | abe: 3.087 | eve: 8.994 | bob: 3.119Epoch  36:  36% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  36:  37% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  36:  38% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  36:  39% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  36:  39% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  36:  40% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  36:  41% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  36:  42% | abe: 3.087 | eve: 8.993 | bob: 3.118Epoch  36:  42% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  36:  43% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  36:  44% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  36:  45% | abe: 3.087 | eve: 8.993 | bob: 3.118Epoch  36:  46% | abe: 3.087 | eve: 8.993 | bob: 3.119Epoch  36:  46% | abe: 3.087 | eve: 8.994 | bob: 3.119Epoch  36:  47% | abe: 3.088 | eve: 8.994 | bob: 3.120Epoch  36:  48% | abe: 3.087 | eve: 8.994 | bob: 3.119Epoch  36:  49% | abe: 3.087 | eve: 8.995 | bob: 3.119Epoch  36:  50% | abe: 3.087 | eve: 8.995 | bob: 3.118Epoch  36:  50% | abe: 3.087 | eve: 8.995 | bob: 3.119Epoch  36:  51% | abe: 3.087 | eve: 8.995 | bob: 3.119Epoch  36:  52% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  36:  53% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  53% | abe: 3.088 | eve: 8.995 | bob: 3.121Epoch  36:  54% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  36:  55% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  36:  56% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  36:  57% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  36:  57% | abe: 3.089 | eve: 8.996 | bob: 3.121Epoch  36:  58% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  36:  59% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  36:  60% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  36:  60% | abe: 3.088 | eve: 8.995 | bob: 3.121Epoch  36:  61% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  36:  62% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  36:  63% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  36:  64% | abe: 3.088 | eve: 8.995 | bob: 3.121Epoch  36:  64% | abe: 3.088 | eve: 8.995 | bob: 3.121Epoch  36:  65% | abe: 3.088 | eve: 8.995 | bob: 3.121Epoch  36:  66% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  67% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  67% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  68% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  69% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  70% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  71% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  71% | abe: 3.088 | eve: 8.995 | bob: 3.121Epoch  36:  72% | abe: 3.088 | eve: 8.995 | bob: 3.121Epoch  36:  73% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  74% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  75% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  75% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  76% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  77% | abe: 3.087 | eve: 8.995 | bob: 3.120Epoch  36:  78% | abe: 3.087 | eve: 8.995 | bob: 3.119Epoch  36:  78% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  79% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  80% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  81% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  82% | abe: 3.087 | eve: 8.995 | bob: 3.120Epoch  36:  82% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  83% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  36:  84% | abe: 3.087 | eve: 8.995 | bob: 3.120Epoch  36:  85% | abe: 3.087 | eve: 8.995 | bob: 3.120Epoch  36:  85% | abe: 3.087 | eve: 8.995 | bob: 3.119Epoch  36:  86% | abe: 3.087 | eve: 8.995 | bob: 3.120Epoch  36:  87% | abe: 3.087 | eve: 8.995 | bob: 3.119Epoch  36:  88% | abe: 3.087 | eve: 8.995 | bob: 3.119Epoch  36:  89% | abe: 3.087 | eve: 8.995 | bob: 3.119Epoch  36:  89% | abe: 3.087 | eve: 8.995 | bob: 3.119Epoch  36:  90% | abe: 3.087 | eve: 8.995 | bob: 3.119Epoch  36:  91% | abe: 3.087 | eve: 8.995 | bob: 3.119Epoch  36:  92% | abe: 3.087 | eve: 8.996 | bob: 3.118Epoch  36:  92% | abe: 3.087 | eve: 8.996 | bob: 3.118Epoch  36:  93% | abe: 3.087 | eve: 8.995 | bob: 3.118Epoch  36:  94% | abe: 3.086 | eve: 8.995 | bob: 3.118Epoch  36:  95% | abe: 3.086 | eve: 8.996 | bob: 3.118Epoch  36:  96% | abe: 3.086 | eve: 8.996 | bob: 3.118Epoch  36:  96% | abe: 3.086 | eve: 8.996 | bob: 3.118Epoch  36:  97% | abe: 3.086 | eve: 8.996 | bob: 3.118Epoch  36:  98% | abe: 3.087 | eve: 8.996 | bob: 3.118Epoch  36:  99% | abe: 3.087 | eve: 8.996 | bob: 3.118Epoch  37:   0% | abe: 3.104 | eve: 9.029 | bob: 3.140Epoch  37:   0% | abe: 3.092 | eve: 9.006 | bob: 3.127Epoch  37:   1% | abe: 3.094 | eve: 8.997 | bob: 3.129Epoch  37:   2% | abe: 3.092 | eve: 8.985 | bob: 3.127Epoch  37:   3% | abe: 3.092 | eve: 8.983 | bob: 3.125Epoch  37:   3% | abe: 3.092 | eve: 8.983 | bob: 3.126Epoch  37:   4% | abe: 3.095 | eve: 8.979 | bob: 3.131Epoch  37:   5% | abe: 3.093 | eve: 8.984 | bob: 3.129Epoch  37:   6% | abe: 3.092 | eve: 8.985 | bob: 3.128Epoch  37:   7% | abe: 3.091 | eve: 8.985 | bob: 3.126Epoch  37:   7% | abe: 3.089 | eve: 8.984 | bob: 3.124Epoch  37:   8% | abe: 3.090 | eve: 8.984 | bob: 3.124Epoch  37:   9% | abe: 3.090 | eve: 8.984 | bob: 3.124Epoch  37:  10% | abe: 3.089 | eve: 8.984 | bob: 3.123Epoch  37:  10% | abe: 3.089 | eve: 8.984 | bob: 3.123Epoch  37:  11% | abe: 3.090 | eve: 8.988 | bob: 3.123Epoch  37:  12% | abe: 3.089 | eve: 8.987 | bob: 3.123Epoch  37:  13% | abe: 3.088 | eve: 8.987 | bob: 3.122Epoch  37:  14% | abe: 3.088 | eve: 8.986 | bob: 3.121Epoch  37:  14% | abe: 3.087 | eve: 8.987 | bob: 3.120Epoch  37:  15% | abe: 3.087 | eve: 8.989 | bob: 3.119Epoch  37:  16% | abe: 3.088 | eve: 8.991 | bob: 3.119Epoch  37:  17% | abe: 3.088 | eve: 8.991 | bob: 3.120Epoch  37:  17% | abe: 3.088 | eve: 8.992 | bob: 3.121Epoch  37:  18% | abe: 3.089 | eve: 8.992 | bob: 3.122Epoch  37:  19% | abe: 3.090 | eve: 8.992 | bob: 3.123Epoch  37:  20% | abe: 3.091 | eve: 8.994 | bob: 3.124Epoch  37:  21% | abe: 3.091 | eve: 8.993 | bob: 3.124Epoch  37:  21% | abe: 3.092 | eve: 8.994 | bob: 3.125Epoch  37:  22% | abe: 3.093 | eve: 8.994 | bob: 3.126Epoch  37:  23% | abe: 3.092 | eve: 8.995 | bob: 3.125Epoch  37:  24% | abe: 3.092 | eve: 8.994 | bob: 3.125Epoch  37:  25% | abe: 3.092 | eve: 8.995 | bob: 3.125Epoch  37:  25% | abe: 3.092 | eve: 8.994 | bob: 3.126Epoch  37:  26% | abe: 3.091 | eve: 8.995 | bob: 3.124Epoch  37:  27% | abe: 3.092 | eve: 8.995 | bob: 3.125Epoch  37:  28% | abe: 3.092 | eve: 8.994 | bob: 3.125Epoch  37:  28% | abe: 3.091 | eve: 8.994 | bob: 3.124Epoch  37:  29% | abe: 3.091 | eve: 8.995 | bob: 3.124Epoch  37:  30% | abe: 3.090 | eve: 8.994 | bob: 3.123Epoch  37:  31% | abe: 3.090 | eve: 8.994 | bob: 3.123Epoch  37:  32% | abe: 3.089 | eve: 8.993 | bob: 3.122Epoch  37:  32% | abe: 3.089 | eve: 8.993 | bob: 3.122Epoch  37:  33% | abe: 3.089 | eve: 8.993 | bob: 3.122Epoch  37:  34% | abe: 3.089 | eve: 8.993 | bob: 3.121Epoch  37:  35% | abe: 3.089 | eve: 8.994 | bob: 3.121Epoch  37:  35% | abe: 3.090 | eve: 8.994 | bob: 3.122Epoch  37:  36% | abe: 3.090 | eve: 8.994 | bob: 3.122Epoch  37:  37% | abe: 3.090 | eve: 8.994 | bob: 3.123Epoch  37:  38% | abe: 3.089 | eve: 8.994 | bob: 3.121Epoch  37:  39% | abe: 3.089 | eve: 8.994 | bob: 3.122Epoch  37:  39% | abe: 3.090 | eve: 8.994 | bob: 3.122Epoch  37:  40% | abe: 3.089 | eve: 8.994 | bob: 3.122Epoch  37:  41% | abe: 3.089 | eve: 8.994 | bob: 3.122Epoch  37:  42% | abe: 3.089 | eve: 8.993 | bob: 3.121Epoch  37:  42% | abe: 3.089 | eve: 8.993 | bob: 3.121Epoch  37:  43% | abe: 3.089 | eve: 8.993 | bob: 3.121Epoch  37:  44% | abe: 3.089 | eve: 8.993 | bob: 3.121Epoch  37:  45% | abe: 3.089 | eve: 8.993 | bob: 3.122Epoch  37:  46% | abe: 3.089 | eve: 8.993 | bob: 3.122Epoch  37:  46% | abe: 3.089 | eve: 8.994 | bob: 3.121Epoch  37:  47% | abe: 3.089 | eve: 8.993 | bob: 3.121Epoch  37:  48% | abe: 3.089 | eve: 8.993 | bob: 3.121Epoch  37:  49% | abe: 3.088 | eve: 8.994 | bob: 3.120Epoch  37:  50% | abe: 3.089 | eve: 8.994 | bob: 3.121Epoch  37:  50% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  37:  51% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  37:  52% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  37:  53% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  37:  53% | abe: 3.090 | eve: 8.995 | bob: 3.122Epoch  37:  54% | abe: 3.090 | eve: 8.995 | bob: 3.121Epoch  37:  55% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  37:  56% | abe: 3.090 | eve: 8.995 | bob: 3.121Epoch  37:  57% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  37:  57% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  37:  58% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  37:  59% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  37:  60% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  37:  60% | abe: 3.089 | eve: 8.995 | bob: 3.120Epoch  37:  61% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  37:  62% | abe: 3.088 | eve: 8.995 | bob: 3.120Epoch  37:  63% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  37:  64% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  37:  64% | abe: 3.088 | eve: 8.996 | bob: 3.119Epoch  37:  65% | abe: 3.087 | eve: 8.996 | bob: 3.119Epoch  37:  66% | abe: 3.087 | eve: 8.996 | bob: 3.118Epoch  37:  67% | abe: 3.087 | eve: 8.996 | bob: 3.118Epoch  37:  67% | abe: 3.087 | eve: 8.996 | bob: 3.119Epoch  37:  68% | abe: 3.087 | eve: 8.996 | bob: 3.119Epoch  37:  69% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  37:  70% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  37:  71% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  37:  71% | abe: 3.087 | eve: 8.995 | bob: 3.118Epoch  37:  72% | abe: 3.087 | eve: 8.995 | bob: 3.118Epoch  37:  73% | abe: 3.087 | eve: 8.995 | bob: 3.118Epoch  37:  74% | abe: 3.087 | eve: 8.995 | bob: 3.118Epoch  37:  75% | abe: 3.087 | eve: 8.995 | bob: 3.118Epoch  37:  75% | abe: 3.087 | eve: 8.995 | bob: 3.118Epoch  37:  76% | abe: 3.087 | eve: 8.995 | bob: 3.118Epoch  37:  77% | abe: 3.087 | eve: 8.995 | bob: 3.118Epoch  37:  78% | abe: 3.087 | eve: 8.995 | bob: 3.118Epoch  37:  78% | abe: 3.087 | eve: 8.995 | bob: 3.118Epoch  37:  79% | abe: 3.087 | eve: 8.995 | bob: 3.118Epoch  37:  80% | abe: 3.087 | eve: 8.996 | bob: 3.118Epoch  37:  81% | abe: 3.088 | eve: 8.996 | bob: 3.119Epoch  37:  82% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  37:  82% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  37:  83% | abe: 3.088 | eve: 8.996 | bob: 3.120Epoch  37:  84% | abe: 3.088 | eve: 8.996 | bob: 3.120Epoch  37:  85% | abe: 3.088 | eve: 8.996 | bob: 3.120Epoch  37:  85% | abe: 3.088 | eve: 8.996 | bob: 3.119Epoch  37:  86% | abe: 3.088 | eve: 8.996 | bob: 3.120Epoch  37:  87% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  37:  88% | abe: 3.088 | eve: 8.996 | bob: 3.119Epoch  37:  89% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  37:  89% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  37:  90% | abe: 3.087 | eve: 8.995 | bob: 3.119Epoch  37:  91% | abe: 3.087 | eve: 8.995 | bob: 3.119Epoch  37:  92% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  37:  92% | abe: 3.087 | eve: 8.995 | bob: 3.119Epoch  37:  93% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  37:  94% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  37:  95% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  37:  96% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  37:  96% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  37:  97% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  37:  98% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  37:  99% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  38:   0% | abe: 3.081 | eve: 9.006 | bob: 3.109Epoch  38:   0% | abe: 3.079 | eve: 8.982 | bob: 3.113Epoch  38:   1% | abe: 3.072 | eve: 8.984 | bob: 3.103Epoch  38:   2% | abe: 3.078 | eve: 8.995 | bob: 3.110Epoch  38:   3% | abe: 3.076 | eve: 8.994 | bob: 3.108Epoch  38:   3% | abe: 3.079 | eve: 8.992 | bob: 3.111Epoch  38:   4% | abe: 3.082 | eve: 8.994 | bob: 3.113Epoch  38:   5% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:   6% | abe: 3.087 | eve: 8.998 | bob: 3.118Epoch  38:   7% | abe: 3.085 | eve: 8.998 | bob: 3.116Epoch  38:   7% | abe: 3.086 | eve: 8.999 | bob: 3.117Epoch  38:   8% | abe: 3.090 | eve: 8.997 | bob: 3.121Epoch  38:   9% | abe: 3.090 | eve: 8.996 | bob: 3.121Epoch  38:  10% | abe: 3.091 | eve: 8.996 | bob: 3.123Epoch  38:  10% | abe: 3.090 | eve: 8.997 | bob: 3.122Epoch  38:  11% | abe: 3.089 | eve: 8.996 | bob: 3.121Epoch  38:  12% | abe: 3.090 | eve: 8.994 | bob: 3.121Epoch  38:  13% | abe: 3.089 | eve: 8.994 | bob: 3.121Epoch  38:  14% | abe: 3.089 | eve: 8.993 | bob: 3.121Epoch  38:  14% | abe: 3.089 | eve: 8.993 | bob: 3.121Epoch  38:  15% | abe: 3.089 | eve: 8.993 | bob: 3.121Epoch  38:  16% | abe: 3.089 | eve: 8.995 | bob: 3.121Epoch  38:  17% | abe: 3.089 | eve: 8.994 | bob: 3.121Epoch  38:  17% | abe: 3.090 | eve: 8.994 | bob: 3.122Epoch  38:  18% | abe: 3.089 | eve: 8.993 | bob: 3.121Epoch  38:  19% | abe: 3.088 | eve: 8.993 | bob: 3.120Epoch  38:  20% | abe: 3.088 | eve: 8.994 | bob: 3.120Epoch  38:  21% | abe: 3.087 | eve: 8.993 | bob: 3.120Epoch  38:  21% | abe: 3.087 | eve: 8.993 | bob: 3.120Epoch  38:  22% | abe: 3.088 | eve: 8.994 | bob: 3.121Epoch  38:  23% | abe: 3.088 | eve: 8.995 | bob: 3.121Epoch  38:  24% | abe: 3.087 | eve: 8.995 | bob: 3.120Epoch  38:  25% | abe: 3.087 | eve: 8.994 | bob: 3.120Epoch  38:  25% | abe: 3.087 | eve: 8.994 | bob: 3.119Epoch  38:  26% | abe: 3.087 | eve: 8.994 | bob: 3.119Epoch  38:  27% | abe: 3.088 | eve: 8.994 | bob: 3.120Epoch  38:  28% | abe: 3.088 | eve: 8.994 | bob: 3.120Epoch  38:  28% | abe: 3.087 | eve: 8.995 | bob: 3.119Epoch  38:  29% | abe: 3.088 | eve: 8.994 | bob: 3.120Epoch  38:  30% | abe: 3.088 | eve: 8.993 | bob: 3.120Epoch  38:  31% | abe: 3.088 | eve: 8.994 | bob: 3.120Epoch  38:  32% | abe: 3.087 | eve: 8.993 | bob: 3.119Epoch  38:  32% | abe: 3.087 | eve: 8.994 | bob: 3.119Epoch  38:  33% | abe: 3.086 | eve: 8.995 | bob: 3.118Epoch  38:  34% | abe: 3.087 | eve: 8.995 | bob: 3.119Epoch  38:  35% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  38:  35% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  38:  36% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  38:  37% | abe: 3.087 | eve: 8.993 | bob: 3.118Epoch  38:  38% | abe: 3.086 | eve: 8.993 | bob: 3.118Epoch  38:  39% | abe: 3.087 | eve: 8.993 | bob: 3.118Epoch  38:  39% | abe: 3.087 | eve: 8.993 | bob: 3.118Epoch  38:  40% | abe: 3.087 | eve: 8.993 | bob: 3.118Epoch  38:  41% | abe: 3.087 | eve: 8.993 | bob: 3.119Epoch  38:  42% | abe: 3.087 | eve: 8.993 | bob: 3.119Epoch  38:  42% | abe: 3.087 | eve: 8.993 | bob: 3.118Epoch  38:  43% | abe: 3.087 | eve: 8.993 | bob: 3.119Epoch  38:  44% | abe: 3.087 | eve: 8.992 | bob: 3.119Epoch  38:  45% | abe: 3.087 | eve: 8.992 | bob: 3.119Epoch  38:  46% | abe: 3.087 | eve: 8.993 | bob: 3.119Epoch  38:  46% | abe: 3.087 | eve: 8.993 | bob: 3.119Epoch  38:  47% | abe: 3.087 | eve: 8.994 | bob: 3.119Epoch  38:  48% | abe: 3.087 | eve: 8.993 | bob: 3.119Epoch  38:  49% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  50% | abe: 3.086 | eve: 8.993 | bob: 3.118Epoch  38:  50% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  38:  51% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  38:  52% | abe: 3.086 | eve: 8.993 | bob: 3.118Epoch  38:  53% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  53% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  38:  54% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  55% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  38:  56% | abe: 3.086 | eve: 8.995 | bob: 3.118Epoch  38:  57% | abe: 3.086 | eve: 8.995 | bob: 3.117Epoch  38:  57% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  38:  58% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  38:  59% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  38:  60% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  38:  60% | abe: 3.086 | eve: 8.994 | bob: 3.117Epoch  38:  61% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  38:  62% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  38:  63% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  64% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  64% | abe: 3.087 | eve: 8.995 | bob: 3.118Epoch  38:  65% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  66% | abe: 3.087 | eve: 8.994 | bob: 3.119Epoch  38:  67% | abe: 3.087 | eve: 8.994 | bob: 3.119Epoch  38:  67% | abe: 3.087 | eve: 8.994 | bob: 3.119Epoch  38:  68% | abe: 3.087 | eve: 8.995 | bob: 3.119Epoch  38:  69% | abe: 3.087 | eve: 8.995 | bob: 3.118Epoch  38:  70% | abe: 3.086 | eve: 8.995 | bob: 3.118Epoch  38:  71% | abe: 3.086 | eve: 8.995 | bob: 3.118Epoch  38:  71% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  38:  72% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  38:  73% | abe: 3.086 | eve: 8.994 | bob: 3.118Epoch  38:  74% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  75% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  75% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  76% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  77% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  78% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  78% | abe: 3.087 | eve: 8.993 | bob: 3.118Epoch  38:  79% | abe: 3.087 | eve: 8.993 | bob: 3.118Epoch  38:  80% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  81% | abe: 3.087 | eve: 8.994 | bob: 3.119Epoch  38:  82% | abe: 3.088 | eve: 8.994 | bob: 3.119Epoch  38:  82% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  83% | abe: 3.088 | eve: 8.994 | bob: 3.119Epoch  38:  84% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  85% | abe: 3.087 | eve: 8.994 | bob: 3.117Epoch  38:  85% | abe: 3.087 | eve: 8.995 | bob: 3.118Epoch  38:  86% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  87% | abe: 3.087 | eve: 8.994 | bob: 3.117Epoch  38:  88% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  89% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  89% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  90% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  91% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  92% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  92% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  93% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  94% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  95% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  96% | abe: 3.087 | eve: 8.994 | bob: 3.118Epoch  38:  96% | abe: 3.088 | eve: 8.995 | bob: 3.118Epoch  38:  97% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  38:  98% | abe: 3.088 | eve: 8.995 | bob: 3.119Epoch  38:  99% | abe: 3.088 | eve: 8.995 | bob: 3.119
Early stopping: No improvement after 5 epochs since epoch 32. Best Bob loss: 3.1182419196229603
Training complete.
cipher1 + cipher2
[[1.1705092  0.7844775  0.6111376  ... 0.5900069  0.9964231  1.0021354 ]
 [1.0133053  0.8673479  1.060223   ... 0.3541738  1.2097204  0.80534005]
 [0.7375431  1.4035968  0.94973856 ... 0.8126029  0.9400509  1.5134609 ]
 ...
 [0.9040698  0.75628936 1.4487457  ... 1.0233566  0.69488364 0.83019304]
 [1.197789   1.2475963  0.96136993 ... 1.101234   1.0430807  1.2504778 ]
 [0.65095925 0.9882213  1.2616254  ... 1.0999333  0.44885445 1.0073376 ]]
HO addition:
[[1.1710658  0.7848062  0.61144    ... 0.5902982  0.9970369  1.0025365 ]
 [1.0139108  0.8677834  1.0607827  ... 0.3543765  1.2103746  0.8057051 ]
 [0.7378753  1.4043177  0.9502793  ... 0.81307155 0.94044256 1.5141684 ]
 ...
 [0.90463483 0.7565974  1.4494491  ... 1.0238972  0.6952965  0.83054066]
 [1.1983427  1.2481627  0.9619039  ... 1.1017373  1.0436792  1.2511214 ]
 [0.65123796 0.9887864  1.2622672  ... 1.1004292  0.44906175 1.007753  ]]
cipher1 * cipher2
[[0.3388976  0.13084106 0.09336904 ... 0.08701608 0.15791662 0.1929376 ]
 [0.18959922 0.1878919  0.2737732  ... 0.02674477 0.34724206 0.1546696 ]
 [0.12886381 0.48857945 0.1947836  ... 0.13790058 0.1858505  0.56097895]
 ...
 [0.1183155  0.11465015 0.5232508  ... 0.2549003  0.09128889 0.1463656 ]
 [0.3484532  0.3718951  0.21035695 ... 0.291604   0.23023425 0.387443  ]
 [0.09364933 0.20854172 0.39626625 ... 0.28696203 0.04889292 0.20885113]]
HO multiplication
[[0.33887944 0.13083808 0.09332998 ... 0.08697107 0.15792371 0.19294457]
 [0.18960653 0.18789594 0.27377126 ... 0.02661558 0.34721965 0.15466996]
 [0.12885453 0.4885112  0.19478968 ... 0.13789631 0.18585826 0.5608865 ]
 ...
 [0.11831479 0.11464195 0.5231716  ... 0.2549018  0.09126071 0.1463679 ]
 [0.3484314  0.37186518 0.2103626  ... 0.29159808 0.23023841 0.3874094 ]
 [0.09362131 0.20854779 0.39622992 ... 0.2869569  0.04880252 0.20885763]]
HO model Accuracy Percentage Addition: 100.00%
HO model Accuracy Percentage Multiplication: 100.00%
Bob decrypted addition: [[0.         0.05717459 1.         ... 0.4365693  0.15518564 0.20247817]
 [0.3692246  0.         1.         ... 0.         0.5029268  0.78935015]
 [0.         1.         0.51661485 ... 0.13704807 1.         0.        ]
 ...
 [0.         0.87407744 0.         ... 1.         1.         1.        ]
 [1.         0.7834078  1.         ... 0.58713734 0.         1.        ]
 [0.         0.7969246  0.         ... 0.19094253 0.23019797 1.        ]]
Bob decrypted bits addition: [[0 0 1 ... 0 0 0]
 [0 0 1 ... 0 1 1]
 [0 1 1 ... 0 1 0]
 ...
 [0 1 0 ... 1 1 1]
 [1 1 1 ... 1 0 1]
 [0 1 0 ... 0 0 1]]
Number of correctly decrypted bits addition: 3857
Total number of bits addition: 8192
Decryption accuracy addition: 47.08251953125%
Bob decrypted multiplication: [[0.         0.11906779 1.         ... 0.3094281  0.3810796  0.33066052]
 [0.3364236  0.         1.         ... 0.         0.17055887 0.84867036]
 [0.         1.         0.82443434 ... 0.23652405 1.         0.        ]
 ...
 [0.         0.82288826 0.         ... 1.         1.         1.        ]
 [1.         0.9499892  1.         ... 0.28154024 0.         1.        ]
 [0.         0.7363861  0.         ... 0.21474484 0.502317   1.        ]]
Bob decrypted bits multiplication: [[0 0 1 ... 0 0 0]
 [0 0 1 ... 0 0 1]
 [0 1 1 ... 0 1 0]
 ...
 [0 1 0 ... 1 1 1]
 [1 1 1 ... 0 0 1]
 [0 1 0 ... 0 1 1]]
Number of correctly decrypted bits multiplication: 5977
Total number of bits multiplication: 8192
Decryption accuracy multiplication: 72.96142578125%
Eve decrypted addition: [[0.37514567 0.5253257  0.6201467  ... 0.3982503  0.39664406 0.5460317 ]
 [0.3733971  0.5236382  0.6213393  ... 0.40021798 0.39380708 0.5463549 ]
 [0.37681428 0.52444685 0.6200233  ... 0.3982799  0.4057004  0.54781765]
 ...
 [0.37982473 0.5233954  0.62190956 ... 0.39303976 0.40569186 0.5490341 ]
 [0.37337545 0.5224112  0.6235741  ... 0.39787394 0.39558285 0.5467313 ]
 [0.38285398 0.52577424 0.6171113  ... 0.407138   0.40653044 0.54701144]]
Eve decrypted bits addition: [[0 1 1 ... 0 0 1]
 [0 1 1 ... 0 0 1]
 [0 1 1 ... 0 0 1]
 ...
 [0 1 1 ... 0 0 1]
 [0 1 1 ... 0 0 1]
 [0 1 1 ... 0 0 1]]
Number of correctly decrypted bits by Eve addition: 3026
Total number of bits addition: 8192
Decryption accuracy by Eve addition: 36.9384765625%
Eve decrypted mulitplication: [[0.37685528 0.5258107  0.62134266 ... 0.3883742  0.40600365 0.547693  ]
 [0.38004214 0.5238161  0.6228303  ... 0.38881516 0.40494254 0.54954267]
 [0.3795809  0.52317697 0.62192047 ... 0.38942853 0.41360778 0.55117786]
 ...
 [0.38256326 0.5229208  0.623414   ... 0.3866731  0.4089603  0.54964405]
 [0.38213837 0.52265924 0.6244562  ... 0.38807434 0.4056474  0.54736257]
 [0.3819058  0.52381027 0.6226523  ... 0.39092624 0.4110195  0.5498498 ]]
Eve decrypted bits mulitplication: [[0 1 1 ... 0 0 1]
 [0 1 1 ... 0 0 1]
 [0 1 1 ... 0 0 1]
 ...
 [0 1 1 ... 0 0 1]
 [0 1 1 ... 0 0 1]
 [0 1 1 ... 0 0 1]]
Number of correctly decrypted bits by Eve mulitplication: 4125
Total number of bits mulitplication: 8192
Decryption accuracy by Eve mulitplication: 50.35400390625%
Bob decrypted P1: [[0.         1.         1.         ... 0.00348213 1.         0.        ]
 [0.         0.         1.         ... 0.         1.         0.        ]
 [0.         1.         1.         ... 0.01450667 1.         0.        ]
 ...
 [0.         1.         0.         ... 1.         1.         1.        ]
 [1.         0.01609969 1.         ... 0.9980035  0.         1.        ]
 [0.         1.         0.         ... 0.         0.         1.        ]]
Bob decrypted bits P1: [[0 1 1 ... 0 1 0]
 [0 0 1 ... 0 1 0]
 [0 1 1 ... 0 1 0]
 ...
 [0 1 0 ... 1 1 1]
 [1 0 1 ... 1 0 1]
 [0 1 0 ... 0 0 1]]
Number of correctly decrypted bits P1: 8192
Total number of bits P1: 8192
Decryption accuracy P1: 100.0%
Bob decrypted P2: [[0.         0.         1.         ... 1.         0.         0.99897647]
 [1.         0.         1.         ... 0.         0.         1.        ]
 [0.         1.         0.         ... 1.         1.         0.        ]
 ...
 [0.         0.         0.         ... 1.         1.         1.        ]
 [1.         1.         1.         ... 0.         0.         1.        ]
 [0.         0.         0.         ... 1.         1.         1.        ]]
Bob decrypted bits P2: [[0 0 1 ... 1 0 1]
 [1 0 1 ... 0 0 1]
 [0 1 0 ... 1 1 0]
 ...
 [0 0 0 ... 1 1 1]
 [1 1 1 ... 0 0 1]
 [0 0 0 ... 1 1 1]]
Number of correctly decrypted bits P2: 8192
Total number of bits P2: 8192
Decryption accuracy P2: 100.0%
