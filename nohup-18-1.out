WARNING:tensorflow:From /home/stud/minawoi/miniconda3/envs/conda-venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2024-04-09 17:44:51.732711: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-04-09 17:44:51.829672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:86:00.0
2024-04-09 17:44:51.830232: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-09 17:44:51.832690: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-04-09 17:44:51.834979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-04-09 17:44:51.835568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-04-09 17:44:51.838563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-04-09 17:44:51.841155: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-04-09 17:44:51.847609: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-04-09 17:44:51.851657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-04-09 17:44:51.852334: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2024-04-09 17:44:51.872337: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199835000 Hz
2024-04-09 17:44:51.874361: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x44c4550 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-04-09 17:44:51.874416: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-04-09 17:44:52.447567: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3c23e30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-04-09 17:44:52.447665: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-04-09 17:44:52.456018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:86:00.0
2024-04-09 17:44:52.456242: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-09 17:44:52.456298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-04-09 17:44:52.456339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-04-09 17:44:52.456379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-04-09 17:44:52.456416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-04-09 17:44:52.456450: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-04-09 17:44:52.456485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-04-09 17:44:52.462139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-04-09 17:44:52.462821: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-09 17:44:52.466085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-04-09 17:44:52.466147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-04-09 17:44:52.466166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2024-04-09 17:44:52.470799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14144 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0)
WARNING:tensorflow:Output bob missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to bob.
WARNING:tensorflow:Output bob_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to bob_1.
WARNING:tensorflow:Output eve missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to eve.
WARNING:tensorflow:Output eve_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to eve_1.
2024-04-09 17:44:59.008202: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
Train on 512 samples, validate on 512 samples
Epoch 1/512
512/512 - 1s - loss: 0.8240 - val_loss: 0.0051
Epoch 2/512
512/512 - 0s - loss: 0.3113 - val_loss: 0.0010
Epoch 3/512
512/512 - 0s - loss: 0.0634 - val_loss: 2.3629e-04
Epoch 4/512
512/512 - 0s - loss: 0.0170 - val_loss: 1.0771e-04
Epoch 5/512
512/512 - 0s - loss: 0.0094 - val_loss: 7.6191e-05
Epoch 6/512
512/512 - 0s - loss: 0.0067 - val_loss: 5.2568e-05
Epoch 7/512
512/512 - 0s - loss: 0.0045 - val_loss: 3.2838e-05
Epoch 8/512
512/512 - 0s - loss: 0.0027 - val_loss: 1.8111e-05
Epoch 9/512
512/512 - 0s - loss: 0.0014 - val_loss: 8.5414e-06
Epoch 10/512
512/512 - 0s - loss: 6.2863e-04 - val_loss: 3.2953e-06
Epoch 11/512
512/512 - 0s - loss: 2.2569e-04 - val_loss: 9.8122e-07
Epoch 12/512
512/512 - 0s - loss: 6.1659e-05 - val_loss: 2.1014e-07
Epoch 13/512
512/512 - 0s - loss: 1.2237e-05 - val_loss: 5.8773e-08
Epoch 14/512
512/512 - 0s - loss: 8.9082e-05 - val_loss: 1.6093e-05
Epoch 15/512
512/512 - 0s - loss: 0.0062 - val_loss: 1.7329e-05
Epoch 16/512
512/512 - 0s - loss: 7.6691e-04 - val_loss: 1.4629e-06
Epoch 17/512
512/512 - 0s - loss: 1.5108e-04 - val_loss: 2.8035e-06
Epoch 18/512
512/512 - 0s - loss: 9.6995e-04 - val_loss: 3.3899e-05
Epoch 19/512
512/512 - 0s - loss: 0.0037 - val_loss: 1.5309e-05
Epoch 20/512
512/512 - 0s - loss: 0.0010 - val_loss: 6.0342e-06
Epoch 21/512
512/512 - 0s - loss: 7.9709e-04 - val_loss: 1.4169e-05
Epoch 22/512
512/512 - 0s - loss: 0.0022 - val_loss: 2.3223e-05
Epoch 23/512
512/512 - 0s - loss: 0.0019 - val_loss: 1.0689e-05
Epoch 24/512
512/512 - 0s - loss: 0.0010 - val_loss: 1.1115e-05
Epoch 25/512
512/512 - 0s - loss: 0.0015 - val_loss: 1.8652e-05
Epoch 26/512
512/512 - 0s - loss: 0.0019 - val_loss: 1.4384e-05
Epoch 27/512
512/512 - 0s - loss: 0.0013 - val_loss: 1.1547e-05
Epoch 28/512
512/512 - 0s - loss: 0.0013 - val_loss: 1.4928e-05
Epoch 29/512
512/512 - 0s - loss: 0.0016 - val_loss: 1.5019e-05
Epoch 30/512
512/512 - 0s - loss: 0.0015 - val_loss: 1.2426e-05
Epoch 31/512
512/512 - 0s - loss: 0.0013 - val_loss: 1.3325e-05
Epoch 32/512
512/512 - 0s - loss: 0.0015 - val_loss: 1.4326e-05
Epoch 33/512
512/512 - 0s - loss: 0.0015 - val_loss: 1.2848e-05
Epoch 34/512
512/512 - 0s - loss: 0.0013 - val_loss: 1.2517e-05
Epoch 35/512
512/512 - 0s - loss: 0.0014 - val_loss: 1.3293e-05
Epoch 36/512
512/512 - 0s - loss: 0.0014 - val_loss: 1.2811e-05
Epoch 37/512
512/512 - 0s - loss: 0.0013 - val_loss: 1.2245e-05
Epoch 38/512
512/512 - 0s - loss: 0.0013 - val_loss: 1.2838e-05
Epoch 39/512
512/512 - 0s - loss: 0.0014 - val_loss: 1.2306e-05
Epoch 40/512
512/512 - 0s - loss: 0.0013 - val_loss: 1.1951e-05
Epoch 41/512
512/512 - 0s - loss: 0.0013 - val_loss: 1.2221e-05
Epoch 42/512
512/512 - 0s - loss: 0.0013 - val_loss: 1.2177e-05
Epoch 43/512
512/512 - 0s - loss: 0.0013 - val_loss: 1.1717e-05
Epoch 44/512
512/512 - 0s - loss: 0.0012 - val_loss: 1.1646e-05
Epoch 45/512
512/512 - 0s - loss: 0.0012 - val_loss: 1.1698e-05
Epoch 46/512
512/512 - 0s - loss: 0.0012 - val_loss: 1.1414e-05
Epoch 47/512
512/512 - 0s - loss: 0.0012 - val_loss: 1.1302e-05
Epoch 48/512
512/512 - 0s - loss: 0.0012 - val_loss: 1.1359e-05
Epoch 49/512
512/512 - 0s - loss: 0.0012 - val_loss: 1.1054e-05
Epoch 50/512
512/512 - 0s - loss: 0.0011 - val_loss: 1.0955e-05
Epoch 51/512
512/512 - 0s - loss: 0.0011 - val_loss: 1.1224e-05
Epoch 52/512
512/512 - 0s - loss: 0.0012 - val_loss: 1.0848e-05
Epoch 53/512
512/512 - 0s - loss: 0.0011 - val_loss: 1.0564e-05
Epoch 54/512
512/512 - 0s - loss: 0.0011 - val_loss: 1.0630e-05
Epoch 55/512
512/512 - 0s - loss: 0.0011 - val_loss: 1.0760e-05
Epoch 56/512
512/512 - 0s - loss: 0.0011 - val_loss: 1.0560e-05
Epoch 57/512
512/512 - 0s - loss: 0.0011 - val_loss: 1.0152e-05
Epoch 58/512
512/512 - 0s - loss: 0.0010 - val_loss: 1.0275e-05
Epoch 59/512
512/512 - 0s - loss: 0.0011 - val_loss: 1.0189e-05
Epoch 60/512
512/512 - 0s - loss: 0.0010 - val_loss: 1.0027e-05
Epoch 61/512
512/512 - 0s - loss: 0.0010 - val_loss: 9.9867e-06
Epoch 62/512
512/512 - 0s - loss: 0.0010 - val_loss: 9.8241e-06
Epoch 63/512
512/512 - 0s - loss: 0.0010 - val_loss: 9.7517e-06
Epoch 64/512
512/512 - 0s - loss: 0.0010 - val_loss: 9.6328e-06
Epoch 65/512
512/512 - 0s - loss: 9.9069e-04 - val_loss: 9.6090e-06
Epoch 66/512
512/512 - 0s - loss: 9.8375e-04 - val_loss: 9.6337e-06
Epoch 67/512
512/512 - 0s - loss: 9.8508e-04 - val_loss: 9.4478e-06
Epoch 68/512
512/512 - 0s - loss: 9.6650e-04 - val_loss: 9.2778e-06
Epoch 69/512
512/512 - 0s - loss: 9.5537e-04 - val_loss: 9.2904e-06
Epoch 70/512
512/512 - 0s - loss: 9.5334e-04 - val_loss: 9.2810e-06
Epoch 71/512
512/512 - 0s - loss: 9.5185e-04 - val_loss: 9.0172e-06
Epoch 72/512
512/512 - 0s - loss: 9.2332e-04 - val_loss: 9.0130e-06
Epoch 73/512
512/512 - 0s - loss: 9.2288e-04 - val_loss: 9.1918e-06
Epoch 74/512
512/512 - 0s - loss: 9.4475e-04 - val_loss: 8.7419e-06
Epoch 75/512
512/512 - 0s - loss: 8.9075e-04 - val_loss: 8.6804e-06
Epoch 76/512
512/512 - 0s - loss: 8.9902e-04 - val_loss: 8.9853e-06
Epoch 77/512
512/512 - 0s - loss: 9.1627e-04 - val_loss: 8.8030e-06
Epoch 78/512
512/512 - 0s - loss: 8.9438e-04 - val_loss: 8.3867e-06
Epoch 79/512
512/512 - 0s - loss: 8.6457e-04 - val_loss: 8.4948e-06
Epoch 80/512
512/512 - 0s - loss: 8.7707e-04 - val_loss: 8.8671e-06
Epoch 81/512
512/512 - 0s - loss: 8.9386e-04 - val_loss: 8.5295e-06
Epoch 82/512
512/512 - 0s - loss: 8.5466e-04 - val_loss: 8.2432e-06
Epoch 83/512
512/512 - 0s - loss: 8.4967e-04 - val_loss: 8.3866e-06
Epoch 84/512
512/512 - 0s - loss: 8.5583e-04 - val_loss: 8.4906e-06
Epoch 85/512
512/512 - 0s - loss: 8.6036e-04 - val_loss: 8.2123e-06
Epoch 86/512
512/512 - 0s - loss: 8.2993e-04 - val_loss: 8.0897e-06
Epoch 87/512
512/512 - 0s - loss: 8.3159e-04 - val_loss: 8.2508e-06
Epoch 88/512
512/512 - 0s - loss: 8.3987e-04 - val_loss: 8.1408e-06
Epoch 89/512
512/512 - 0s - loss: 8.1676e-04 - val_loss: 8.0960e-06
Epoch 90/512
512/512 - 0s - loss: 8.1964e-04 - val_loss: 8.1370e-06
Epoch 91/512
512/512 - 0s - loss: 8.2082e-04 - val_loss: 8.0125e-06
Epoch 92/512
512/512 - 0s - loss: 8.0847e-04 - val_loss: 7.8291e-06
Epoch 93/512
512/512 - 0s - loss: 8.0224e-04 - val_loss: 7.7902e-06
Epoch 94/512
512/512 - 0s - loss: 7.9209e-04 - val_loss: 7.8790e-06
Epoch 95/512
512/512 - 0s - loss: 8.0473e-04 - val_loss: 7.7903e-06
Epoch 96/512
512/512 - 0s - loss: 7.9063e-04 - val_loss: 7.5788e-06
Epoch 97/512
512/512 - 0s - loss: 7.6711e-04 - val_loss: 7.8331e-06
Epoch 98/512
512/512 - 0s - loss: 7.9842e-04 - val_loss: 7.8046e-06
Epoch 99/512
512/512 - 0s - loss: 7.7997e-04 - val_loss: 7.4529e-06
Epoch 100/512
512/512 - 0s - loss: 7.5859e-04 - val_loss: 7.5025e-06
Epoch 101/512
512/512 - 0s - loss: 7.7090e-04 - val_loss: 7.5737e-06
Epoch 102/512
512/512 - 0s - loss: 7.6402e-04 - val_loss: 7.5452e-06
Epoch 103/512
512/512 - 0s - loss: 7.5461e-04 - val_loss: 7.6214e-06
Epoch 104/512
512/512 - 0s - loss: 7.6457e-04 - val_loss: 7.4975e-06
Epoch 105/512
512/512 - 0s - loss: 7.5449e-04 - val_loss: 7.3003e-06
Epoch 106/512
512/512 - 0s - loss: 7.3452e-04 - val_loss: 7.4334e-06
Epoch 107/512
512/512 - 0s - loss: 7.5217e-04 - val_loss: 7.4613e-06
Epoch 108/512
512/512 - 0s - loss: 7.5297e-04 - val_loss: 7.0730e-06
Epoch 109/512
512/512 - 0s - loss: 7.1060e-04 - val_loss: 7.2913e-06
Epoch 110/512
512/512 - 0s - loss: 7.4636e-04 - val_loss: 7.4530e-06
Epoch 111/512
512/512 - 0s - loss: 7.4381e-04 - val_loss: 7.0300e-06
Epoch 112/512
512/512 - 0s - loss: 7.1295e-04 - val_loss: 6.8757e-06
Epoch 113/512
512/512 - 0s - loss: 7.1310e-04 - val_loss: 7.1485e-06
Epoch 114/512
512/512 - 0s - loss: 7.3438e-04 - val_loss: 7.1044e-06
Epoch 115/512
512/512 - 0s - loss: 7.1129e-04 - val_loss: 6.9388e-06
Epoch 116/512
512/512 - 0s - loss: 7.0481e-04 - val_loss: 7.0623e-06
Epoch 117/512
512/512 - 0s - loss: 7.1441e-04 - val_loss: 7.0792e-06
Epoch 118/512
512/512 - 0s - loss: 7.1020e-04 - val_loss: 6.9733e-06
Epoch 119/512
512/512 - 0s - loss: 6.9786e-04 - val_loss: 6.9161e-06
Epoch 120/512
512/512 - 0s - loss: 7.0060e-04 - val_loss: 6.9214e-06
Epoch 121/512
512/512 - 0s - loss: 6.9770e-04 - val_loss: 6.8640e-06
Epoch 122/512
512/512 - 0s - loss: 6.9697e-04 - val_loss: 6.7604e-06
Epoch 123/512
512/512 - 0s - loss: 6.8140e-04 - val_loss: 6.8107e-06
Epoch 124/512
512/512 - 0s - loss: 6.9034e-04 - val_loss: 6.8588e-06
Epoch 125/512
512/512 - 0s - loss: 6.9074e-04 - val_loss: 6.6642e-06
Epoch 126/512
512/512 - 0s - loss: 6.7270e-04 - val_loss: 6.6554e-06
Epoch 127/512
512/512 - 0s - loss: 6.7288e-04 - val_loss: 6.8644e-06
Epoch 128/512
512/512 - 0s - loss: 6.9144e-04 - val_loss: 6.6958e-06
Epoch 129/512
512/512 - 0s - loss: 6.6479e-04 - val_loss: 6.5209e-06
Epoch 130/512
512/512 - 0s - loss: 6.6304e-04 - val_loss: 6.6512e-06
Epoch 131/512
512/512 - 0s - loss: 6.7257e-04 - val_loss: 6.6119e-06
Epoch 132/512
512/512 - 0s - loss: 6.6069e-04 - val_loss: 6.5464e-06
Epoch 133/512
512/512 - 0s - loss: 6.6130e-04 - val_loss: 6.5465e-06
Epoch 134/512
512/512 - 0s - loss: 6.5639e-04 - val_loss: 6.5198e-06
Epoch 135/512
512/512 - 0s - loss: 6.5501e-04 - val_loss: 6.4970e-06
Epoch 136/512
512/512 - 0s - loss: 6.5267e-04 - val_loss: 6.4522e-06
Epoch 137/512
512/512 - 0s - loss: 6.4966e-04 - val_loss: 6.3423e-06
Epoch 138/512
512/512 - 0s - loss: 6.4055e-04 - val_loss: 6.3974e-06
Epoch 139/512
512/512 - 0s - loss: 6.4587e-04 - val_loss: 6.4347e-06
Epoch 140/512
512/512 - 0s - loss: 6.4036e-04 - val_loss: 6.3823e-06
Epoch 141/512
512/512 - 0s - loss: 6.3931e-04 - val_loss: 6.2670e-06
Epoch 142/512
512/512 - 0s - loss: 6.3333e-04 - val_loss: 6.1640e-06
Epoch 143/512
512/512 - 0s - loss: 6.2488e-04 - val_loss: 6.2727e-06
Epoch 144/512
512/512 - 0s - loss: 6.3392e-04 - val_loss: 6.2971e-06
Epoch 145/512
512/512 - 0s - loss: 6.2759e-04 - val_loss: 6.1656e-06
Epoch 146/512
512/512 - 0s - loss: 6.1942e-04 - val_loss: 6.0964e-06
Epoch 147/512
512/512 - 0s - loss: 6.1611e-04 - val_loss: 6.1856e-06
Epoch 148/512
512/512 - 0s - loss: 6.2046e-04 - val_loss: 6.2265e-06
Epoch 149/512
512/512 - 0s - loss: 6.2109e-04 - val_loss: 6.0402e-06
Epoch 150/512
512/512 - 0s - loss: 6.0261e-04 - val_loss: 6.0173e-06
Epoch 151/512
512/512 - 0s - loss: 6.1145e-04 - val_loss: 6.0226e-06
Epoch 152/512
512/512 - 0s - loss: 6.0562e-04 - val_loss: 5.9680e-06
Epoch 153/512
512/512 - 0s - loss: 5.9987e-04 - val_loss: 5.9544e-06
Epoch 154/512
512/512 - 0s - loss: 6.0018e-04 - val_loss: 5.9546e-06
Epoch 155/512
512/512 - 0s - loss: 5.9654e-04 - val_loss: 5.9733e-06
Epoch 156/512
512/512 - 0s - loss: 5.9948e-04 - val_loss: 5.8249e-06
Epoch 157/512
512/512 - 0s - loss: 5.8423e-04 - val_loss: 5.7596e-06
Epoch 158/512
512/512 - 0s - loss: 5.8416e-04 - val_loss: 5.8813e-06
Epoch 159/512
512/512 - 0s - loss: 5.9178e-04 - val_loss: 5.8686e-06
Epoch 160/512
512/512 - 0s - loss: 5.8644e-04 - val_loss: 5.6282e-06
Epoch 161/512
512/512 - 0s - loss: 5.6655e-04 - val_loss: 5.6952e-06
Epoch 162/512
512/512 - 0s - loss: 5.8157e-04 - val_loss: 5.7492e-06
Epoch 163/512
512/512 - 0s - loss: 5.7554e-04 - val_loss: 5.6596e-06
Epoch 164/512
512/512 - 0s - loss: 5.6283e-04 - val_loss: 5.6899e-06
Epoch 165/512
512/512 - 0s - loss: 5.7386e-04 - val_loss: 5.5945e-06
Epoch 166/512
512/512 - 0s - loss: 5.6302e-04 - val_loss: 5.5087e-06
Epoch 167/512
512/512 - 0s - loss: 5.5520e-04 - val_loss: 5.5638e-06
Epoch 168/512
512/512 - 0s - loss: 5.5855e-04 - val_loss: 5.6589e-06
Epoch 169/512
512/512 - 0s - loss: 5.5667e-04 - val_loss: 5.6169e-06
Epoch 170/512
512/512 - 0s - loss: 5.5851e-04 - val_loss: 5.4091e-06
Epoch 171/512
512/512 - 0s - loss: 5.3939e-04 - val_loss: 5.4043e-06
Epoch 172/512
512/512 - 0s - loss: 5.4731e-04 - val_loss: 5.4582e-06
Epoch 173/512
512/512 - 0s - loss: 5.4729e-04 - val_loss: 5.3599e-06
Epoch 174/512
512/512 - 0s - loss: 5.3724e-04 - val_loss: 5.2898e-06
Epoch 175/512
512/512 - 0s - loss: 5.3445e-04 - val_loss: 5.3016e-06
Epoch 176/512
512/512 - 0s - loss: 5.3641e-04 - val_loss: 5.2445e-06
Epoch 177/512
512/512 - 0s - loss: 5.2353e-04 - val_loss: 5.2909e-06
Epoch 178/512
512/512 - 0s - loss: 5.3567e-04 - val_loss: 5.1932e-06
Epoch 179/512
512/512 - 0s - loss: 5.1635e-04 - val_loss: 5.1509e-06
Epoch 180/512
512/512 - 0s - loss: 5.2097e-04 - val_loss: 5.2436e-06
Epoch 181/512
512/512 - 0s - loss: 5.2079e-04 - val_loss: 5.2054e-06
Epoch 182/512
512/512 - 0s - loss: 5.1380e-04 - val_loss: 5.1519e-06
Epoch 183/512
512/512 - 0s - loss: 5.1345e-04 - val_loss: 5.0551e-06
Epoch 184/512
512/512 - 0s - loss: 5.0526e-04 - val_loss: 5.0316e-06
Epoch 185/512
512/512 - 0s - loss: 5.0595e-04 - val_loss: 5.0353e-06
Epoch 186/512
512/512 - 0s - loss: 5.0129e-04 - val_loss: 5.0094e-06
Epoch 187/512
512/512 - 0s - loss: 5.0177e-04 - val_loss: 4.9450e-06
Epoch 188/512
512/512 - 0s - loss: 4.9299e-04 - val_loss: 4.8976e-06
Epoch 189/512
512/512 - 0s - loss: 4.9113e-04 - val_loss: 4.9166e-06
Epoch 190/512
512/512 - 0s - loss: 4.9273e-04 - val_loss: 4.8543e-06
Epoch 191/512
512/512 - 0s - loss: 4.8500e-04 - val_loss: 4.8130e-06
Epoch 192/512
512/512 - 0s - loss: 4.7996e-04 - val_loss: 4.8357e-06
Epoch 193/512
512/512 - 0s - loss: 4.8175e-04 - val_loss: 4.8298e-06
Epoch 194/512
512/512 - 0s - loss: 4.7996e-04 - val_loss: 4.7154e-06
Epoch 195/512
512/512 - 0s - loss: 4.7154e-04 - val_loss: 4.6405e-06
Epoch 196/512
512/512 - 0s - loss: 4.6757e-04 - val_loss: 4.6935e-06
Epoch 197/512
512/512 - 0s - loss: 4.6737e-04 - val_loss: 4.7149e-06
Epoch 198/512
512/512 - 0s - loss: 4.7145e-04 - val_loss: 4.5496e-06
Epoch 199/512
512/512 - 0s - loss: 4.5547e-04 - val_loss: 4.4711e-06
Epoch 200/512
512/512 - 0s - loss: 4.5576e-04 - val_loss: 4.5301e-06
Epoch 201/512
512/512 - 0s - loss: 4.5420e-04 - val_loss: 4.5757e-06
Epoch 202/512
512/512 - 0s - loss: 4.5630e-04 - val_loss: 4.4836e-06
Epoch 203/512
512/512 - 0s - loss: 4.4660e-04 - val_loss: 4.3871e-06
Epoch 204/512
512/512 - 0s - loss: 4.4078e-04 - val_loss: 4.4743e-06
Epoch 205/512
512/512 - 0s - loss: 4.4986e-04 - val_loss: 4.3799e-06
Epoch 206/512
512/512 - 0s - loss: 4.3518e-04 - val_loss: 4.2760e-06
Epoch 207/512
512/512 - 0s - loss: 4.3048e-04 - val_loss: 4.3835e-06
Epoch 208/512
512/512 - 0s - loss: 4.4053e-04 - val_loss: 4.3410e-06
Epoch 209/512
512/512 - 0s - loss: 4.2606e-04 - val_loss: 4.2819e-06
Epoch 210/512
512/512 - 0s - loss: 4.2861e-04 - val_loss: 4.2209e-06
Epoch 211/512
512/512 - 0s - loss: 4.2246e-04 - val_loss: 4.1819e-06
Epoch 212/512
512/512 - 0s - loss: 4.1743e-04 - val_loss: 4.2305e-06
Epoch 213/512
512/512 - 0s - loss: 4.2320e-04 - val_loss: 4.1796e-06
Epoch 214/512
512/512 - 0s - loss: 4.1566e-04 - val_loss: 4.0596e-06
Epoch 215/512
512/512 - 0s - loss: 4.0761e-04 - val_loss: 4.0358e-06
Epoch 216/512
512/512 - 0s - loss: 4.0470e-04 - val_loss: 4.1500e-06
Epoch 217/512
512/512 - 0s - loss: 4.1503e-04 - val_loss: 4.0450e-06
Epoch 218/512
512/512 - 0s - loss: 3.9622e-04 - val_loss: 3.9624e-06
Epoch 219/512
512/512 - 0s - loss: 3.9995e-04 - val_loss: 3.9835e-06
Epoch 220/512
512/512 - 0s - loss: 3.9540e-04 - val_loss: 4.0162e-06
Epoch 221/512
512/512 - 0s - loss: 3.9935e-04 - val_loss: 3.9153e-06
Epoch 222/512
512/512 - 0s - loss: 3.8621e-04 - val_loss: 3.8635e-06
Epoch 223/512
512/512 - 0s - loss: 3.8723e-04 - val_loss: 3.9107e-06
Epoch 224/512
512/512 - 0s - loss: 3.9057e-04 - val_loss: 3.8068e-06
Epoch 225/512
512/512 - 0s - loss: 3.7775e-04 - val_loss: 3.7522e-06
Epoch 226/512
512/512 - 0s - loss: 3.7822e-04 - val_loss: 3.8293e-06
Epoch 227/512
512/512 - 0s - loss: 3.8213e-04 - val_loss: 3.7073e-06
Epoch 228/512
512/512 - 0s - loss: 3.7049e-04 - val_loss: 3.6317e-06
Epoch 229/512
512/512 - 0s - loss: 3.6638e-04 - val_loss: 3.7607e-06
Epoch 230/512
512/512 - 0s - loss: 3.7313e-04 - val_loss: 3.7575e-06
Epoch 231/512
512/512 - 0s - loss: 3.7044e-04 - val_loss: 3.5763e-06
Epoch 232/512
512/512 - 0s - loss: 3.5602e-04 - val_loss: 3.5382e-06
Epoch 233/512
512/512 - 0s - loss: 3.5871e-04 - val_loss: 3.6397e-06
Epoch 234/512
512/512 - 0s - loss: 3.6228e-04 - val_loss: 3.6053e-06
Epoch 235/512
512/512 - 0s - loss: 3.5561e-04 - val_loss: 3.4684e-06
Epoch 236/512
512/512 - 0s - loss: 3.4741e-04 - val_loss: 3.4810e-06
Epoch 237/512
512/512 - 0s - loss: 3.5136e-04 - val_loss: 3.5182e-06
Epoch 238/512
512/512 - 0s - loss: 3.5003e-04 - val_loss: 3.4346e-06
Epoch 239/512
512/512 - 0s - loss: 3.4161e-04 - val_loss: 3.3986e-06
Epoch 240/512
512/512 - 0s - loss: 3.4083e-04 - val_loss: 3.4375e-06
Epoch 241/512
512/512 - 0s - loss: 3.4121e-04 - val_loss: 3.4230e-06
Epoch 242/512
512/512 - 0s - loss: 3.3837e-04 - val_loss: 3.3519e-06
Epoch 243/512
512/512 - 0s - loss: 3.3454e-04 - val_loss: 3.2714e-06
Epoch 244/512
512/512 - 0s - loss: 3.2841e-04 - val_loss: 3.3012e-06
Epoch 245/512
512/512 - 0s - loss: 3.3093e-04 - val_loss: 3.3306e-06
Epoch 246/512
512/512 - 0s - loss: 3.3138e-04 - val_loss: 3.2303e-06
Epoch 247/512
512/512 - 0s - loss: 3.1912e-04 - val_loss: 3.2360e-06
Epoch 248/512
512/512 - 0s - loss: 3.2262e-04 - val_loss: 3.2987e-06
Epoch 249/512
512/512 - 0s - loss: 3.2820e-04 - val_loss: 3.1587e-06
Epoch 250/512
512/512 - 0s - loss: 3.0988e-04 - val_loss: 3.1353e-06
Epoch 251/512
512/512 - 0s - loss: 3.1918e-04 - val_loss: 3.1377e-06
Epoch 252/512
512/512 - 0s - loss: 3.1172e-04 - val_loss: 3.1182e-06
Epoch 253/512
512/512 - 0s - loss: 3.1345e-04 - val_loss: 3.0875e-06
Epoch 254/512
512/512 - 0s - loss: 3.0568e-04 - val_loss: 3.1040e-06
Epoch 255/512
512/512 - 0s - loss: 3.0969e-04 - val_loss: 3.0806e-06
Epoch 256/512
512/512 - 0s - loss: 3.0551e-04 - val_loss: 2.9947e-06
Epoch 257/512
512/512 - 0s - loss: 3.0005e-04 - val_loss: 2.9996e-06
Epoch 258/512
512/512 - 0s - loss: 3.0011e-04 - val_loss: 3.0312e-06
Epoch 259/512
512/512 - 0s - loss: 3.0089e-04 - val_loss: 3.0150e-06
Epoch 260/512
512/512 - 0s - loss: 2.9527e-04 - val_loss: 2.9788e-06
Epoch 261/512
512/512 - 0s - loss: 2.9588e-04 - val_loss: 2.9314e-06
Epoch 262/512
512/512 - 0s - loss: 2.9287e-04 - val_loss: 2.8878e-06
Epoch 263/512
512/512 - 0s - loss: 2.8872e-04 - val_loss: 2.8912e-06
Epoch 264/512
512/512 - 0s - loss: 2.9263e-04 - val_loss: 2.8089e-06
Epoch 265/512
512/512 - 0s - loss: 2.8056e-04 - val_loss: 2.8424e-06
Epoch 266/512
512/512 - 0s - loss: 2.8522e-04 - val_loss: 2.9389e-06
Epoch 267/512
512/512 - 0s - loss: 2.9082e-04 - val_loss: 2.7993e-06
Epoch 268/512
512/512 - 0s - loss: 2.7609e-04 - val_loss: 2.7187e-06
Epoch 269/512
512/512 - 0s - loss: 2.7728e-04 - val_loss: 2.7840e-06
Epoch 270/512
512/512 - 0s - loss: 2.7743e-04 - val_loss: 2.8321e-06
Epoch 271/512
512/512 - 0s - loss: 2.7987e-04 - val_loss: 2.7577e-06
Epoch 272/512
512/512 - 0s - loss: 2.7298e-04 - val_loss: 2.6927e-06
Epoch 273/512
512/512 - 0s - loss: 2.6969e-04 - val_loss: 2.7095e-06
Epoch 274/512
512/512 - 0s - loss: 2.7167e-04 - val_loss: 2.7450e-06
Epoch 275/512
512/512 - 0s - loss: 2.7294e-04 - val_loss: 2.6411e-06
Epoch 276/512
512/512 - 0s - loss: 2.6209e-04 - val_loss: 2.6396e-06
Epoch 277/512
512/512 - 0s - loss: 2.6536e-04 - val_loss: 2.7117e-06
Epoch 278/512
512/512 - 0s - loss: 2.6854e-04 - val_loss: 2.6739e-06
Epoch 279/512
512/512 - 0s - loss: 2.6283e-04 - val_loss: 2.5736e-06
Epoch 280/512
512/512 - 0s - loss: 2.5713e-04 - val_loss: 2.5896e-06
Epoch 281/512
512/512 - 0s - loss: 2.6020e-04 - val_loss: 2.6326e-06
Epoch 282/512
512/512 - 0s - loss: 2.6321e-04 - val_loss: 2.5077e-06
Epoch 283/512
512/512 - 0s - loss: 2.4919e-04 - val_loss: 2.5391e-06
Epoch 284/512
512/512 - 0s - loss: 2.5790e-04 - val_loss: 2.5934e-06
Epoch 285/512
512/512 - 0s - loss: 2.5349e-04 - val_loss: 2.5698e-06
Epoch 286/512
512/512 - 0s - loss: 2.5418e-04 - val_loss: 2.5265e-06
Epoch 287/512
512/512 - 0s - loss: 2.4972e-04 - val_loss: 2.4819e-06
Epoch 288/512
512/512 - 0s - loss: 2.4971e-04 - val_loss: 2.4539e-06
Epoch 289/512
512/512 - 0s - loss: 2.4679e-04 - val_loss: 2.4633e-06
Epoch 290/512
512/512 - 0s - loss: 2.4954e-04 - val_loss: 2.4209e-06
Epoch 291/512
512/512 - 0s - loss: 2.4122e-04 - val_loss: 2.4484e-06
Epoch 292/512
512/512 - 0s - loss: 2.4746e-04 - val_loss: 2.4578e-06
Epoch 293/512
512/512 - 0s - loss: 2.4446e-04 - val_loss: 2.3430e-06
Epoch 294/512
512/512 - 0s - loss: 2.3734e-04 - val_loss: 2.3753e-06
Epoch 295/512
512/512 - 0s - loss: 2.4139e-04 - val_loss: 2.4109e-06
Epoch 296/512
512/512 - 0s - loss: 2.4076e-04 - val_loss: 2.3813e-06
Epoch 297/512
512/512 - 0s - loss: 2.3826e-04 - val_loss: 2.3359e-06
Epoch 298/512
512/512 - 0s - loss: 2.3449e-04 - val_loss: 2.3609e-06
Epoch 299/512
512/512 - 0s - loss: 2.3571e-04 - val_loss: 2.3939e-06
Epoch 300/512
512/512 - 0s - loss: 2.3659e-04 - val_loss: 2.3649e-06
Epoch 301/512
512/512 - 0s - loss: 2.3360e-04 - val_loss: 2.3203e-06
Epoch 302/512
512/512 - 0s - loss: 2.3124e-04 - val_loss: 2.3096e-06
Epoch 303/512
512/512 - 0s - loss: 2.3035e-04 - val_loss: 2.3243e-06
Epoch 304/512
512/512 - 0s - loss: 2.3279e-04 - val_loss: 2.2753e-06
Epoch 305/512
512/512 - 0s - loss: 2.2445e-04 - val_loss: 2.3293e-06
Epoch 306/512
512/512 - 0s - loss: 2.3259e-04 - val_loss: 2.3204e-06
Epoch 307/512
512/512 - 0s - loss: 2.2831e-04 - val_loss: 2.2173e-06
Epoch 308/512
512/512 - 0s - loss: 2.2272e-04 - val_loss: 2.2084e-06
Epoch 309/512
512/512 - 0s - loss: 2.2298e-04 - val_loss: 2.3031e-06
Epoch 310/512
512/512 - 0s - loss: 2.2999e-04 - val_loss: 2.2441e-06
Epoch 311/512
512/512 - 0s - loss: 2.2206e-04 - val_loss: 2.1427e-06
Epoch 312/512
512/512 - 0s - loss: 2.1817e-04 - val_loss: 2.1948e-06
Epoch 313/512
512/512 - 0s - loss: 2.2295e-04 - val_loss: 2.2305e-06
Epoch 314/512
512/512 - 0s - loss: 2.2251e-04 - val_loss: 2.1780e-06
Epoch 315/512
512/512 - 0s - loss: 2.1864e-04 - val_loss: 2.1420e-06
Epoch 316/512
512/512 - 0s - loss: 2.1513e-04 - val_loss: 2.2051e-06
Epoch 317/512
512/512 - 0s - loss: 2.2153e-04 - val_loss: 2.2002e-06
Epoch 318/512
512/512 - 0s - loss: 2.2050e-04 - val_loss: 2.0735e-06
Epoch 319/512
512/512 - 0s - loss: 2.0706e-04 - val_loss: 2.1301e-06
Epoch 320/512
512/512 - 0s - loss: 2.1725e-04 - val_loss: 2.2448e-06
Epoch 321/512
512/512 - 0s - loss: 2.2046e-04 - val_loss: 2.1460e-06
Epoch 322/512
512/512 - 0s - loss: 2.0862e-04 - val_loss: 2.1025e-06
Epoch 323/512
512/512 - 0s - loss: 2.1311e-04 - val_loss: 2.1417e-06
Epoch 324/512
512/512 - 0s - loss: 2.1346e-04 - val_loss: 2.1345e-06
Epoch 325/512
512/512 - 0s - loss: 2.1206e-04 - val_loss: 2.0809e-06
Epoch 326/512
512/512 - 0s - loss: 2.0797e-04 - val_loss: 2.1060e-06
Epoch 327/512
512/512 - 0s - loss: 2.1073e-04 - val_loss: 2.1176e-06
Epoch 328/512
512/512 - 0s - loss: 2.1050e-04 - val_loss: 2.0885e-06
Epoch 329/512
512/512 - 0s - loss: 2.0699e-04 - val_loss: 2.0583e-06
Epoch 330/512
512/512 - 0s - loss: 2.0837e-04 - val_loss: 2.0698e-06
Epoch 331/512
512/512 - 0s - loss: 2.0619e-04 - val_loss: 2.0734e-06
Epoch 332/512
512/512 - 0s - loss: 2.0822e-04 - val_loss: 2.0360e-06
Epoch 333/512
512/512 - 0s - loss: 2.0331e-04 - val_loss: 2.0405e-06
Epoch 334/512
512/512 - 0s - loss: 2.0492e-04 - val_loss: 2.0618e-06
Epoch 335/512
512/512 - 0s - loss: 2.0723e-04 - val_loss: 2.0032e-06
Epoch 336/512
512/512 - 0s - loss: 1.9936e-04 - val_loss: 2.0289e-06
Epoch 337/512
512/512 - 0s - loss: 2.0540e-04 - val_loss: 2.0437e-06
Epoch 338/512
512/512 - 0s - loss: 2.0190e-04 - val_loss: 2.0490e-06
Epoch 339/512
512/512 - 0s - loss: 2.0361e-04 - val_loss: 2.0120e-06
Epoch 340/512
512/512 - 0s - loss: 2.0133e-04 - val_loss: 1.9517e-06
Epoch 341/512
512/512 - 0s - loss: 1.9665e-04 - val_loss: 2.0041e-06
Epoch 342/512
512/512 - 0s - loss: 2.0308e-04 - val_loss: 2.0189e-06
Epoch 343/512
512/512 - 0s - loss: 2.0078e-04 - val_loss: 1.9482e-06
Epoch 344/512
512/512 - 0s - loss: 1.9344e-04 - val_loss: 2.0124e-06
Epoch 345/512
512/512 - 0s - loss: 2.0368e-04 - val_loss: 2.0148e-06
Epoch 346/512
512/512 - 0s - loss: 1.9897e-04 - val_loss: 1.9044e-06
Epoch 347/512
512/512 - 0s - loss: 1.8956e-04 - val_loss: 1.9906e-06
Epoch 348/512
512/512 - 0s - loss: 2.0333e-04 - val_loss: 1.9964e-06
Epoch 349/512
512/512 - 0s - loss: 1.9697e-04 - val_loss: 1.8946e-06
Epoch 350/512
512/512 - 0s - loss: 1.8922e-04 - val_loss: 1.9594e-06
Epoch 351/512
512/512 - 0s - loss: 1.9843e-04 - val_loss: 2.0094e-06
Epoch 352/512
512/512 - 0s - loss: 1.9921e-04 - val_loss: 1.8912e-06
Epoch 353/512
512/512 - 0s - loss: 1.8793e-04 - val_loss: 1.9125e-06
Epoch 354/512
512/512 - 0s - loss: 1.9305e-04 - val_loss: 2.0131e-06
Epoch 355/512
512/512 - 0s - loss: 1.9860e-04 - val_loss: 1.9514e-06
Epoch 356/512
512/512 - 0s - loss: 1.9237e-04 - val_loss: 1.8521e-06
Epoch 357/512
512/512 - 0s - loss: 1.8679e-04 - val_loss: 1.9247e-06
Epoch 358/512
512/512 - 0s - loss: 1.9467e-04 - val_loss: 1.9699e-06
Epoch 359/512
512/512 - 0s - loss: 1.9445e-04 - val_loss: 1.8845e-06
Epoch 360/512
512/512 - 0s - loss: 1.8753e-04 - val_loss: 1.8607e-06
Epoch 361/512
512/512 - 0s - loss: 1.8844e-04 - val_loss: 1.9494e-06
Epoch 362/512
512/512 - 0s - loss: 1.9395e-04 - val_loss: 1.9315e-06
Epoch 363/512
512/512 - 0s - loss: 1.8946e-04 - val_loss: 1.8622e-06
Epoch 364/512
512/512 - 0s - loss: 1.8666e-04 - val_loss: 1.8844e-06
Epoch 365/512
512/512 - 0s - loss: 1.8998e-04 - val_loss: 1.9018e-06
Epoch 366/512
512/512 - 0s - loss: 1.8916e-04 - val_loss: 1.8716e-06
Epoch 367/512
512/512 - 0s - loss: 1.8531e-04 - val_loss: 1.8973e-06
Epoch 368/512
512/512 - 0s - loss: 1.9156e-04 - val_loss: 1.8619e-06
Epoch 369/512
512/512 - 0s - loss: 1.8437e-04 - val_loss: 1.8436e-06
Epoch 370/512
512/512 - 0s - loss: 1.8566e-04 - val_loss: 1.8862e-06
Epoch 371/512
512/512 - 0s - loss: 1.8975e-04 - val_loss: 1.8464e-06
Epoch 372/512
512/512 - 0s - loss: 1.8250e-04 - val_loss: 1.8497e-06
Epoch 373/512
512/512 - 0s - loss: 1.8518e-04 - val_loss: 1.9045e-06
Epoch 374/512
512/512 - 0s - loss: 1.8930e-04 - val_loss: 1.8421e-06
Epoch 375/512
512/512 - 0s - loss: 1.8268e-04 - val_loss: 1.8048e-06
Epoch 376/512
512/512 - 0s - loss: 1.8316e-04 - val_loss: 1.8449e-06
Epoch 377/512
512/512 - 0s - loss: 1.8591e-04 - val_loss: 1.8363e-06
Epoch 378/512
512/512 - 0s - loss: 1.8207e-04 - val_loss: 1.8339e-06
Epoch 379/512
512/512 - 0s - loss: 1.8485e-04 - val_loss: 1.8137e-06
Epoch 380/512
512/512 - 0s - loss: 1.8102e-04 - val_loss: 1.8357e-06
Epoch 381/512
512/512 - 0s - loss: 1.8379e-04 - val_loss: 1.8349e-06
Epoch 382/512
512/512 - 0s - loss: 1.8286e-04 - val_loss: 1.8127e-06
Epoch 383/512
512/512 - 0s - loss: 1.8090e-04 - val_loss: 1.8169e-06
Epoch 384/512
512/512 - 0s - loss: 1.8531e-04 - val_loss: 1.7510e-06
Epoch 385/512
512/512 - 0s - loss: 1.7592e-04 - val_loss: 1.7750e-06
Epoch 386/512
512/512 - 0s - loss: 1.8059e-04 - val_loss: 1.8579e-06
Epoch 387/512
512/512 - 0s - loss: 1.8563e-04 - val_loss: 1.7989e-06
Epoch 388/512
512/512 - 0s - loss: 1.7712e-04 - val_loss: 1.7727e-06
Epoch 389/512
512/512 - 0s - loss: 1.7940e-04 - val_loss: 1.8185e-06
Epoch 390/512
512/512 - 0s - loss: 1.8079e-04 - val_loss: 1.8252e-06
Epoch 391/512
512/512 - 0s - loss: 1.7988e-04 - val_loss: 1.7852e-06
Epoch 392/512
512/512 - 0s - loss: 1.7862e-04 - val_loss: 1.7677e-06
Epoch 393/512
512/512 - 0s - loss: 1.7758e-04 - val_loss: 1.7871e-06
Epoch 394/512
512/512 - 0s - loss: 1.7945e-04 - val_loss: 1.7704e-06
Epoch 395/512
512/512 - 0s - loss: 1.7660e-04 - val_loss: 1.7774e-06
Epoch 396/512
512/512 - 0s - loss: 1.8009e-04 - val_loss: 1.7522e-06
Epoch 397/512
512/512 - 0s - loss: 1.7580e-04 - val_loss: 1.7455e-06
Epoch 398/512
512/512 - 0s - loss: 1.7739e-04 - val_loss: 1.7553e-06
Epoch 399/512
512/512 - 0s - loss: 1.7756e-04 - val_loss: 1.7256e-06
Epoch 400/512
512/512 - 0s - loss: 1.7417e-04 - val_loss: 1.7627e-06
Epoch 401/512
512/512 - 0s - loss: 1.7695e-04 - val_loss: 1.7893e-06
Epoch 402/512
512/512 - 0s - loss: 1.7740e-04 - val_loss: 1.7658e-06
Epoch 403/512
512/512 - 0s - loss: 1.7491e-04 - val_loss: 1.7328e-06
Epoch 404/512
512/512 - 0s - loss: 1.7458e-04 - val_loss: 1.7568e-06
Epoch 405/512
512/512 - 0s - loss: 1.7705e-04 - val_loss: 1.7302e-06
Epoch 406/512
512/512 - 0s - loss: 1.7363e-04 - val_loss: 1.7055e-06
Epoch 407/512
512/512 - 0s - loss: 1.7119e-04 - val_loss: 1.7782e-06
Epoch 408/512
512/512 - 0s - loss: 1.8004e-04 - val_loss: 1.7284e-06
Epoch 409/512
512/512 - 0s - loss: 1.7169e-04 - val_loss: 1.6688e-06
Epoch 410/512
512/512 - 0s - loss: 1.7041e-04 - val_loss: 1.7328e-06
Epoch 411/512
512/512 - 0s - loss: 1.7563e-04 - val_loss: 1.7543e-06
Epoch 412/512
512/512 - 0s - loss: 1.7303e-04 - val_loss: 1.7332e-06
Epoch 413/512
512/512 - 0s - loss: 1.7292e-04 - val_loss: 1.7089e-06
Epoch 414/512
512/512 - 0s - loss: 1.7245e-04 - val_loss: 1.6787e-06
Epoch 415/512
512/512 - 0s - loss: 1.6861e-04 - val_loss: 1.7459e-06
Epoch 416/512
512/512 - 0s - loss: 1.7575e-04 - val_loss: 1.7402e-06
Epoch 417/512
512/512 - 0s - loss: 1.7054e-04 - val_loss: 1.6945e-06
Epoch 418/512
512/512 - 0s - loss: 1.6947e-04 - val_loss: 1.7274e-06
Epoch 419/512
512/512 - 0s - loss: 1.7392e-04 - val_loss: 1.6940e-06
Epoch 420/512
512/512 - 0s - loss: 1.6818e-04 - val_loss: 1.6883e-06
Epoch 421/512
512/512 - 0s - loss: 1.7126e-04 - val_loss: 1.6992e-06
Epoch 422/512
512/512 - 0s - loss: 1.6874e-04 - val_loss: 1.7256e-06
Epoch 423/512
512/512 - 0s - loss: 1.7118e-04 - val_loss: 1.7190e-06
Epoch 424/512
512/512 - 0s - loss: 1.7261e-04 - val_loss: 1.6357e-06
Epoch 425/512
512/512 - 0s - loss: 1.6316e-04 - val_loss: 1.6754e-06
Epoch 426/512
512/512 - 0s - loss: 1.7051e-04 - val_loss: 1.7471e-06
Epoch 427/512
512/512 - 0s - loss: 1.7309e-04 - val_loss: 1.6597e-06
Epoch 428/512
512/512 - 0s - loss: 1.6429e-04 - val_loss: 1.6334e-06
Epoch 429/512
512/512 - 0s - loss: 1.6846e-04 - val_loss: 1.6706e-06
Epoch 430/512
512/512 - 0s - loss: 1.6756e-04 - val_loss: 1.6834e-06
Epoch 431/512
512/512 - 0s - loss: 1.6917e-04 - val_loss: 1.6630e-06
Epoch 432/512
512/512 - 0s - loss: 1.6598e-04 - val_loss: 1.6486e-06
Epoch 433/512
512/512 - 0s - loss: 1.6825e-04 - val_loss: 1.6218e-06
Epoch 434/512
512/512 - 0s - loss: 1.6380e-04 - val_loss: 1.6449e-06
Epoch 435/512
512/512 - 0s - loss: 1.6509e-04 - val_loss: 1.7283e-06
Epoch 436/512
512/512 - 0s - loss: 1.7052e-04 - val_loss: 1.6622e-06
Epoch 437/512
512/512 - 0s - loss: 1.6372e-04 - val_loss: 1.6132e-06
Epoch 438/512
512/512 - 0s - loss: 1.6325e-04 - val_loss: 1.6642e-06
Epoch 439/512
512/512 - 0s - loss: 1.6636e-04 - val_loss: 1.6796e-06
Epoch 440/512
512/512 - 0s - loss: 1.6665e-04 - val_loss: 1.6329e-06
Epoch 441/512
512/512 - 0s - loss: 1.6270e-04 - val_loss: 1.6221e-06
Epoch 442/512
512/512 - 0s - loss: 1.6473e-04 - val_loss: 1.6207e-06
Epoch 443/512
512/512 - 0s - loss: 1.6208e-04 - val_loss: 1.6468e-06
Epoch 444/512
512/512 - 0s - loss: 1.6505e-04 - val_loss: 1.6533e-06
Epoch 445/512
512/512 - 0s - loss: 1.6478e-04 - val_loss: 1.5973e-06
Epoch 446/512
512/512 - 0s - loss: 1.5890e-04 - val_loss: 1.6326e-06
Epoch 447/512
512/512 - 0s - loss: 1.6449e-04 - val_loss: 1.6553e-06
Epoch 448/512
512/512 - 0s - loss: 1.6364e-04 - val_loss: 1.6170e-06
Epoch 449/512
512/512 - 0s - loss: 1.6024e-04 - val_loss: 1.6086e-06
Epoch 450/512
512/512 - 0s - loss: 1.6217e-04 - val_loss: 1.6151e-06
Epoch 451/512
512/512 - 0s - loss: 1.6160e-04 - val_loss: 1.5974e-06
Epoch 452/512
512/512 - 0s - loss: 1.5876e-04 - val_loss: 1.6330e-06
Epoch 453/512
512/512 - 0s - loss: 1.6244e-04 - val_loss: 1.6256e-06
Epoch 454/512
512/512 - 0s - loss: 1.6050e-04 - val_loss: 1.6100e-06
Epoch 455/512
512/512 - 0s - loss: 1.5931e-04 - val_loss: 1.6002e-06
Epoch 456/512
512/512 - 0s - loss: 1.6041e-04 - val_loss: 1.5697e-06
Epoch 457/512
512/512 - 0s - loss: 1.5779e-04 - val_loss: 1.5715e-06
Epoch 458/512
512/512 - 0s - loss: 1.5872e-04 - val_loss: 1.6089e-06
Epoch 459/512
512/512 - 0s - loss: 1.6055e-04 - val_loss: 1.5771e-06
Epoch 460/512
512/512 - 0s - loss: 1.5602e-04 - val_loss: 1.5756e-06
Epoch 461/512
512/512 - 0s - loss: 1.5889e-04 - val_loss: 1.5808e-06
Epoch 462/512
512/512 - 0s - loss: 1.5798e-04 - val_loss: 1.5490e-06
Epoch 463/512
512/512 - 0s - loss: 1.5489e-04 - val_loss: 1.5806e-06
Epoch 464/512
512/512 - 0s - loss: 1.5898e-04 - val_loss: 1.5728e-06
Epoch 465/512
512/512 - 0s - loss: 1.5586e-04 - val_loss: 1.5427e-06
Epoch 466/512
512/512 - 0s - loss: 1.5441e-04 - val_loss: 1.5616e-06
Epoch 467/512
512/512 - 0s - loss: 1.5658e-04 - val_loss: 1.5708e-06
Epoch 468/512
512/512 - 0s - loss: 1.5590e-04 - val_loss: 1.5480e-06
Epoch 469/512
512/512 - 0s - loss: 1.5447e-04 - val_loss: 1.5257e-06
Epoch 470/512
512/512 - 0s - loss: 1.5140e-04 - val_loss: 1.5879e-06
Epoch 471/512
512/512 - 0s - loss: 1.6057e-04 - val_loss: 1.5101e-06
Epoch 472/512
512/512 - 0s - loss: 1.5030e-04 - val_loss: 1.4624e-06
Epoch 473/512
512/512 - 0s - loss: 1.4898e-04 - val_loss: 1.5655e-06
Epoch 474/512
512/512 - 0s - loss: 1.5836e-04 - val_loss: 1.5603e-06
Epoch 475/512
512/512 - 0s - loss: 1.5279e-04 - val_loss: 1.4669e-06
Epoch 476/512
512/512 - 0s - loss: 1.4749e-04 - val_loss: 1.5117e-06
Epoch 477/512
512/512 - 0s - loss: 1.5467e-04 - val_loss: 1.5222e-06
Epoch 478/512
512/512 - 0s - loss: 1.5066e-04 - val_loss: 1.4931e-06
Epoch 479/512
512/512 - 0s - loss: 1.4984e-04 - val_loss: 1.5121e-06
Epoch 480/512
512/512 - 0s - loss: 1.5202e-04 - val_loss: 1.4859e-06
Epoch 481/512
512/512 - 0s - loss: 1.4757e-04 - val_loss: 1.4988e-06
Epoch 482/512
512/512 - 0s - loss: 1.5092e-04 - val_loss: 1.5042e-06
Epoch 483/512
512/512 - 0s - loss: 1.5048e-04 - val_loss: 1.4496e-06
Epoch 484/512
512/512 - 0s - loss: 1.4561e-04 - val_loss: 1.4549e-06
Epoch 485/512
512/512 - 0s - loss: 1.4872e-04 - val_loss: 1.4838e-06
Epoch 486/512
512/512 - 0s - loss: 1.4808e-04 - val_loss: 1.4802e-06
Epoch 487/512
512/512 - 0s - loss: 1.4668e-04 - val_loss: 1.4795e-06
Epoch 488/512
512/512 - 0s - loss: 1.4687e-04 - val_loss: 1.4791e-06
Epoch 489/512
512/512 - 0s - loss: 1.4672e-04 - val_loss: 1.4595e-06
Epoch 490/512
512/512 - 0s - loss: 1.4437e-04 - val_loss: 1.4762e-06
Epoch 491/512
512/512 - 0s - loss: 1.4789e-04 - val_loss: 1.4377e-06
Epoch 492/512
512/512 - 0s - loss: 1.4240e-04 - val_loss: 1.4330e-06
Epoch 493/512
512/512 - 0s - loss: 1.4387e-04 - val_loss: 1.4629e-06
Epoch 494/512
512/512 - 0s - loss: 1.4651e-04 - val_loss: 1.4162e-06
Epoch 495/512
512/512 - 0s - loss: 1.4160e-04 - val_loss: 1.3994e-06
Epoch 496/512
512/512 - 0s - loss: 1.4127e-04 - val_loss: 1.4281e-06
Epoch 497/512
512/512 - 0s - loss: 1.4391e-04 - val_loss: 1.4294e-06
Epoch 498/512
512/512 - 0s - loss: 1.4248e-04 - val_loss: 1.3863e-06
Epoch 499/512
512/512 - 0s - loss: 1.3915e-04 - val_loss: 1.3957e-06
Epoch 500/512
512/512 - 0s - loss: 1.4043e-04 - val_loss: 1.4302e-06
Epoch 501/512
512/512 - 0s - loss: 1.4336e-04 - val_loss: 1.3821e-06
Epoch 502/512
512/512 - 0s - loss: 1.3724e-04 - val_loss: 1.3505e-06
Epoch 503/512
512/512 - 0s - loss: 1.3732e-04 - val_loss: 1.4023e-06
Epoch 504/512
512/512 - 0s - loss: 1.4080e-04 - val_loss: 1.3806e-06
Epoch 505/512
512/512 - 0s - loss: 1.3743e-04 - val_loss: 1.3533e-06
Epoch 506/512
512/512 - 0s - loss: 1.3607e-04 - val_loss: 1.3707e-06
Epoch 507/512
512/512 - 0s - loss: 1.3773e-04 - val_loss: 1.3643e-06
Epoch 508/512
512/512 - 0s - loss: 1.3661e-04 - val_loss: 1.3415e-06
Epoch 509/512
512/512 - 0s - loss: 1.3386e-04 - val_loss: 1.3512e-06
Epoch 510/512
512/512 - 0s - loss: 1.3653e-04 - val_loss: 1.3446e-06
Epoch 511/512
512/512 - 0s - loss: 1.3458e-04 - val_loss: 1.3072e-06
Epoch 512/512
512/512 - 0s - loss: 1.3103e-04 - val_loss: 1.3367e-06
2024-04-09 17:45:19.740030: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
Train on 512 samples, validate on 512 samples
Epoch 1/512

Epoch 00001: val_loss improved from inf to 0.00008, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0152e-04 - val_loss: 8.3624e-05
Epoch 2/512

Epoch 00002: val_loss did not improve from 0.00008
512/512 - 0s - loss: 9.7554e-05 - val_loss: 1.3428e-04
Epoch 3/512

Epoch 00003: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.5146e-04 - val_loss: 1.5139e-04
Epoch 4/512

Epoch 00004: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.3126e-04 - val_loss: 1.0522e-04
Epoch 5/512

Epoch 00005: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.0406e-04 - val_loss: 1.1388e-04
Epoch 6/512

Epoch 00006: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.2621e-04 - val_loss: 1.3954e-04
Epoch 7/512

Epoch 00007: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.3452e-04 - val_loss: 1.2009e-04
Epoch 8/512

Epoch 00008: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.1427e-04 - val_loss: 1.1141e-04
Epoch 9/512

Epoch 00009: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.1652e-04 - val_loss: 1.2603e-04
Epoch 10/512

Epoch 00010: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.2749e-04 - val_loss: 1.2510e-04
Epoch 11/512

Epoch 00011: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.2010e-04 - val_loss: 1.1455e-04
Epoch 12/512

Epoch 00012: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.1485e-04 - val_loss: 1.1806e-04
Epoch 13/512

Epoch 00013: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.2035e-04 - val_loss: 1.2205e-04
Epoch 14/512

Epoch 00014: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.2039e-04 - val_loss: 1.1609e-04
Epoch 15/512

Epoch 00015: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.1500e-04 - val_loss: 1.1439e-04
Epoch 16/512

Epoch 00016: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.1598e-04 - val_loss: 1.1775e-04
Epoch 17/512

Epoch 00017: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.1787e-04 - val_loss: 1.1609e-04
Epoch 18/512

Epoch 00018: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.1473e-04 - val_loss: 1.1355e-04
Epoch 19/512

Epoch 00019: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.1377e-04 - val_loss: 1.1424e-04
Epoch 20/512

Epoch 00020: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.1451e-04 - val_loss: 1.1425e-04
Epoch 21/512

Epoch 00021: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.1367e-04 - val_loss: 1.1204e-04
Epoch 22/512

Epoch 00022: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.1174e-04 - val_loss: 1.1167e-04
Epoch 23/512

Epoch 00023: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.1165e-04 - val_loss: 1.1237e-04
Epoch 24/512

Epoch 00024: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.1223e-04 - val_loss: 1.1018e-04
Epoch 25/512

Epoch 00025: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.0952e-04 - val_loss: 1.0906e-04
Epoch 26/512

Epoch 00026: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.0940e-04 - val_loss: 1.0969e-04
Epoch 27/512

Epoch 00027: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.0963e-04 - val_loss: 1.0835e-04
Epoch 28/512

Epoch 00028: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.0774e-04 - val_loss: 1.0728e-04
Epoch 29/512

Epoch 00029: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.0731e-04 - val_loss: 1.0710e-04
Epoch 30/512

Epoch 00030: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.0699e-04 - val_loss: 1.0611e-04
Epoch 31/512

Epoch 00031: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.0542e-04 - val_loss: 1.0596e-04
Epoch 32/512

Epoch 00032: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.0569e-04 - val_loss: 1.0511e-04
Epoch 33/512

Epoch 00033: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.0460e-04 - val_loss: 1.0291e-04
Epoch 34/512

Epoch 00034: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.0295e-04 - val_loss: 1.0280e-04
Epoch 35/512

Epoch 00035: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.0309e-04 - val_loss: 1.0287e-04
Epoch 36/512

Epoch 00036: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.0231e-04 - val_loss: 1.0169e-04
Epoch 37/512

Epoch 00037: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.0116e-04 - val_loss: 1.0055e-04
Epoch 38/512

Epoch 00038: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.0032e-04 - val_loss: 1.0024e-04
Epoch 39/512

Epoch 00039: val_loss did not improve from 0.00008
512/512 - 0s - loss: 1.0002e-04 - val_loss: 9.9517e-05
Epoch 40/512

Epoch 00040: val_loss did not improve from 0.00008
512/512 - 0s - loss: 9.8950e-05 - val_loss: 9.8218e-05
Epoch 41/512

Epoch 00041: val_loss did not improve from 0.00008
512/512 - 0s - loss: 9.7986e-05 - val_loss: 9.7462e-05
Epoch 42/512

Epoch 00042: val_loss did not improve from 0.00008
512/512 - 0s - loss: 9.7350e-05 - val_loss: 9.6791e-05
Epoch 43/512

Epoch 00043: val_loss did not improve from 0.00008
512/512 - 0s - loss: 9.6452e-05 - val_loss: 9.6212e-05
Epoch 44/512

Epoch 00044: val_loss did not improve from 0.00008
512/512 - 0s - loss: 9.5834e-05 - val_loss: 9.5361e-05
Epoch 45/512

Epoch 00045: val_loss did not improve from 0.00008
512/512 - 0s - loss: 9.4878e-05 - val_loss: 9.4474e-05
Epoch 46/512

Epoch 00046: val_loss did not improve from 0.00008
512/512 - 0s - loss: 9.4201e-05 - val_loss: 9.3259e-05
Epoch 47/512

Epoch 00047: val_loss did not improve from 0.00008
512/512 - 0s - loss: 9.2958e-05 - val_loss: 9.2686e-05
Epoch 48/512

Epoch 00048: val_loss did not improve from 0.00008
512/512 - 0s - loss: 9.2676e-05 - val_loss: 9.1955e-05
Epoch 49/512

Epoch 00049: val_loss did not improve from 0.00008
512/512 - 0s - loss: 9.1382e-05 - val_loss: 9.1315e-05
Epoch 50/512

Epoch 00050: val_loss did not improve from 0.00008
512/512 - 0s - loss: 9.0965e-05 - val_loss: 9.0440e-05
Epoch 51/512

Epoch 00051: val_loss did not improve from 0.00008
512/512 - 0s - loss: 9.0011e-05 - val_loss: 8.9153e-05
Epoch 52/512

Epoch 00052: val_loss did not improve from 0.00008
512/512 - 0s - loss: 8.8863e-05 - val_loss: 8.8423e-05
Epoch 53/512

Epoch 00053: val_loss did not improve from 0.00008
512/512 - 0s - loss: 8.8229e-05 - val_loss: 8.8083e-05
Epoch 54/512

Epoch 00054: val_loss did not improve from 0.00008
512/512 - 0s - loss: 8.7738e-05 - val_loss: 8.6781e-05
Epoch 55/512

Epoch 00055: val_loss did not improve from 0.00008
512/512 - 0s - loss: 8.6398e-05 - val_loss: 8.5445e-05
Epoch 56/512

Epoch 00056: val_loss did not improve from 0.00008
512/512 - 0s - loss: 8.5454e-05 - val_loss: 8.5182e-05
Epoch 57/512

Epoch 00057: val_loss did not improve from 0.00008
512/512 - 0s - loss: 8.5079e-05 - val_loss: 8.4537e-05
Epoch 58/512

Epoch 00058: val_loss improved from 0.00008 to 0.00008, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.4165e-05 - val_loss: 8.3200e-05
Epoch 59/512

Epoch 00059: val_loss improved from 0.00008 to 0.00008, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.2895e-05 - val_loss: 8.2477e-05
Epoch 60/512

Epoch 00060: val_loss improved from 0.00008 to 0.00008, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.2455e-05 - val_loss: 8.1677e-05
Epoch 61/512

Epoch 00061: val_loss improved from 0.00008 to 0.00008, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.1269e-05 - val_loss: 8.1083e-05
Epoch 62/512

Epoch 00062: val_loss improved from 0.00008 to 0.00008, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.0757e-05 - val_loss: 8.0271e-05
Epoch 63/512

Epoch 00063: val_loss improved from 0.00008 to 0.00008, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.9813e-05 - val_loss: 7.9053e-05
Epoch 64/512

Epoch 00064: val_loss improved from 0.00008 to 0.00008, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.8693e-05 - val_loss: 7.8231e-05
Epoch 65/512

Epoch 00065: val_loss improved from 0.00008 to 0.00008, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.8137e-05 - val_loss: 7.7334e-05
Epoch 66/512

Epoch 00066: val_loss improved from 0.00008 to 0.00008, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.6973e-05 - val_loss: 7.6570e-05
Epoch 67/512

Epoch 00067: val_loss improved from 0.00008 to 0.00008, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.6496e-05 - val_loss: 7.5619e-05
Epoch 68/512

Epoch 00068: val_loss improved from 0.00008 to 0.00007, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.5408e-05 - val_loss: 7.4433e-05
Epoch 69/512

Epoch 00069: val_loss improved from 0.00007 to 0.00007, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.4405e-05 - val_loss: 7.3747e-05
Epoch 70/512

Epoch 00070: val_loss improved from 0.00007 to 0.00007, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.3584e-05 - val_loss: 7.3442e-05
Epoch 71/512

Epoch 00071: val_loss improved from 0.00007 to 0.00007, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.3086e-05 - val_loss: 7.2489e-05
Epoch 72/512

Epoch 00072: val_loss improved from 0.00007 to 0.00007, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.1830e-05 - val_loss: 7.1482e-05
Epoch 73/512

Epoch 00073: val_loss improved from 0.00007 to 0.00007, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.1270e-05 - val_loss: 7.0387e-05
Epoch 74/512

Epoch 00074: val_loss improved from 0.00007 to 0.00007, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.9993e-05 - val_loss: 6.9651e-05
Epoch 75/512

Epoch 00075: val_loss improved from 0.00007 to 0.00007, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.9443e-05 - val_loss: 6.9109e-05
Epoch 76/512

Epoch 00076: val_loss improved from 0.00007 to 0.00007, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.8599e-05 - val_loss: 6.8168e-05
Epoch 77/512

Epoch 00077: val_loss improved from 0.00007 to 0.00007, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.7742e-05 - val_loss: 6.7062e-05
Epoch 78/512

Epoch 00078: val_loss improved from 0.00007 to 0.00007, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.6770e-05 - val_loss: 6.6089e-05
Epoch 79/512

Epoch 00079: val_loss improved from 0.00007 to 0.00007, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.5853e-05 - val_loss: 6.5423e-05
Epoch 80/512

Epoch 00080: val_loss improved from 0.00007 to 0.00006, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.5076e-05 - val_loss: 6.4885e-05
Epoch 81/512

Epoch 00081: val_loss improved from 0.00006 to 0.00006, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.4478e-05 - val_loss: 6.3795e-05
Epoch 82/512

Epoch 00082: val_loss improved from 0.00006 to 0.00006, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.3347e-05 - val_loss: 6.2620e-05
Epoch 83/512

Epoch 00083: val_loss improved from 0.00006 to 0.00006, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.2336e-05 - val_loss: 6.2214e-05
Epoch 84/512

Epoch 00084: val_loss improved from 0.00006 to 0.00006, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.1995e-05 - val_loss: 6.1302e-05
Epoch 85/512

Epoch 00085: val_loss improved from 0.00006 to 0.00006, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.0819e-05 - val_loss: 6.0213e-05
Epoch 86/512

Epoch 00086: val_loss improved from 0.00006 to 0.00006, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.9942e-05 - val_loss: 5.9543e-05
Epoch 87/512

Epoch 00087: val_loss improved from 0.00006 to 0.00006, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.9239e-05 - val_loss: 5.8874e-05
Epoch 88/512

Epoch 00088: val_loss improved from 0.00006 to 0.00006, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.8555e-05 - val_loss: 5.7749e-05
Epoch 89/512

Epoch 00089: val_loss improved from 0.00006 to 0.00006, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.7420e-05 - val_loss: 5.6759e-05
Epoch 90/512

Epoch 00090: val_loss improved from 0.00006 to 0.00006, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.6748e-05 - val_loss: 5.6016e-05
Epoch 91/512

Epoch 00091: val_loss improved from 0.00006 to 0.00006, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.5839e-05 - val_loss: 5.5404e-05
Epoch 92/512

Epoch 00092: val_loss improved from 0.00006 to 0.00005, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.5172e-05 - val_loss: 5.4607e-05
Epoch 93/512

Epoch 00093: val_loss improved from 0.00005 to 0.00005, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.4294e-05 - val_loss: 5.3653e-05
Epoch 94/512

Epoch 00094: val_loss improved from 0.00005 to 0.00005, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.3371e-05 - val_loss: 5.2983e-05
Epoch 95/512

Epoch 00095: val_loss improved from 0.00005 to 0.00005, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.2777e-05 - val_loss: 5.2128e-05
Epoch 96/512

Epoch 00096: val_loss improved from 0.00005 to 0.00005, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.1871e-05 - val_loss: 5.1258e-05
Epoch 97/512

Epoch 00097: val_loss improved from 0.00005 to 0.00005, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.1086e-05 - val_loss: 5.0410e-05
Epoch 98/512

Epoch 00098: val_loss improved from 0.00005 to 0.00005, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.0271e-05 - val_loss: 4.9647e-05
Epoch 99/512

Epoch 00099: val_loss improved from 0.00005 to 0.00005, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.9378e-05 - val_loss: 4.9150e-05
Epoch 100/512

Epoch 00100: val_loss improved from 0.00005 to 0.00005, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.8903e-05 - val_loss: 4.8329e-05
Epoch 101/512

Epoch 00101: val_loss improved from 0.00005 to 0.00005, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.7939e-05 - val_loss: 4.7389e-05
Epoch 102/512

Epoch 00102: val_loss improved from 0.00005 to 0.00005, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.7132e-05 - val_loss: 4.6705e-05
Epoch 103/512

Epoch 00103: val_loss improved from 0.00005 to 0.00005, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.6425e-05 - val_loss: 4.6024e-05
Epoch 104/512

Epoch 00104: val_loss improved from 0.00005 to 0.00005, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.5722e-05 - val_loss: 4.5262e-05
Epoch 105/512

Epoch 00105: val_loss improved from 0.00005 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.4973e-05 - val_loss: 4.4397e-05
Epoch 106/512

Epoch 00106: val_loss improved from 0.00004 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.4096e-05 - val_loss: 4.3665e-05
Epoch 107/512

Epoch 00107: val_loss improved from 0.00004 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.3459e-05 - val_loss: 4.3005e-05
Epoch 108/512

Epoch 00108: val_loss improved from 0.00004 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.2731e-05 - val_loss: 4.2224e-05
Epoch 109/512

Epoch 00109: val_loss improved from 0.00004 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.2028e-05 - val_loss: 4.1418e-05
Epoch 110/512

Epoch 00110: val_loss improved from 0.00004 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.1061e-05 - val_loss: 4.1081e-05
Epoch 111/512

Epoch 00111: val_loss improved from 0.00004 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.0823e-05 - val_loss: 4.0278e-05
Epoch 112/512

Epoch 00112: val_loss improved from 0.00004 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.9831e-05 - val_loss: 3.9250e-05
Epoch 113/512

Epoch 00113: val_loss improved from 0.00004 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.9076e-05 - val_loss: 3.8434e-05
Epoch 114/512

Epoch 00114: val_loss improved from 0.00004 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.8301e-05 - val_loss: 3.8171e-05
Epoch 115/512

Epoch 00115: val_loss improved from 0.00004 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.7908e-05 - val_loss: 3.7635e-05
Epoch 116/512

Epoch 00116: val_loss improved from 0.00004 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.7265e-05 - val_loss: 3.6564e-05
Epoch 117/512

Epoch 00117: val_loss improved from 0.00004 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.6235e-05 - val_loss: 3.5806e-05
Epoch 118/512

Epoch 00118: val_loss improved from 0.00004 to 0.00004, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.5776e-05 - val_loss: 3.5341e-05
Epoch 119/512

Epoch 00119: val_loss improved from 0.00004 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.5118e-05 - val_loss: 3.4770e-05
Epoch 120/512

Epoch 00120: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.4498e-05 - val_loss: 3.4032e-05
Epoch 121/512

Epoch 00121: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3772e-05 - val_loss: 3.3362e-05
Epoch 122/512

Epoch 00122: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3164e-05 - val_loss: 3.2834e-05
Epoch 123/512

Epoch 00123: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.2663e-05 - val_loss: 3.2085e-05
Epoch 124/512

Epoch 00124: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1854e-05 - val_loss: 3.1415e-05
Epoch 125/512

Epoch 00125: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1277e-05 - val_loss: 3.0925e-05
Epoch 126/512

Epoch 00126: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.0766e-05 - val_loss: 3.0398e-05
Epoch 127/512

Epoch 00127: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.0120e-05 - val_loss: 2.9734e-05
Epoch 128/512

Epoch 00128: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9524e-05 - val_loss: 2.9158e-05
Epoch 129/512

Epoch 00129: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8935e-05 - val_loss: 2.8579e-05
Epoch 130/512

Epoch 00130: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8390e-05 - val_loss: 2.7996e-05
Epoch 131/512

Epoch 00131: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7808e-05 - val_loss: 2.7435e-05
Epoch 132/512

Epoch 00132: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7248e-05 - val_loss: 2.6842e-05
Epoch 133/512

Epoch 00133: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6676e-05 - val_loss: 2.6353e-05
Epoch 134/512

Epoch 00134: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6140e-05 - val_loss: 2.5888e-05
Epoch 135/512

Epoch 00135: val_loss improved from 0.00003 to 0.00003, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5700e-05 - val_loss: 2.5260e-05
Epoch 136/512

Epoch 00136: val_loss improved from 0.00003 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5016e-05 - val_loss: 2.4733e-05
Epoch 137/512

Epoch 00137: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4551e-05 - val_loss: 2.4349e-05
Epoch 138/512

Epoch 00138: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4105e-05 - val_loss: 2.3881e-05
Epoch 139/512

Epoch 00139: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3634e-05 - val_loss: 2.3133e-05
Epoch 140/512

Epoch 00140: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2943e-05 - val_loss: 2.2634e-05
Epoch 141/512

Epoch 00141: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2516e-05 - val_loss: 2.2405e-05
Epoch 142/512

Epoch 00142: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2249e-05 - val_loss: 2.1813e-05
Epoch 143/512

Epoch 00143: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1575e-05 - val_loss: 2.1148e-05
Epoch 144/512

Epoch 00144: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1007e-05 - val_loss: 2.0921e-05
Epoch 145/512

Epoch 00145: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0833e-05 - val_loss: 2.0476e-05
Epoch 146/512

Epoch 00146: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0207e-05 - val_loss: 1.9862e-05
Epoch 147/512

Epoch 00147: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9735e-05 - val_loss: 1.9516e-05
Epoch 148/512

Epoch 00148: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9379e-05 - val_loss: 1.9135e-05
Epoch 149/512

Epoch 00149: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8946e-05 - val_loss: 1.8644e-05
Epoch 150/512

Epoch 00150: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8469e-05 - val_loss: 1.8241e-05
Epoch 151/512

Epoch 00151: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8130e-05 - val_loss: 1.7803e-05
Epoch 152/512

Epoch 00152: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7613e-05 - val_loss: 1.7459e-05
Epoch 153/512

Epoch 00153: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7340e-05 - val_loss: 1.7075e-05
Epoch 154/512

Epoch 00154: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6881e-05 - val_loss: 1.6629e-05
Epoch 155/512

Epoch 00155: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6498e-05 - val_loss: 1.6203e-05
Epoch 156/512

Epoch 00156: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6041e-05 - val_loss: 1.5977e-05
Epoch 157/512

Epoch 00157: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5848e-05 - val_loss: 1.5586e-05
Epoch 158/512

Epoch 00158: val_loss improved from 0.00002 to 0.00002, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5415e-05 - val_loss: 1.5035e-05
Epoch 159/512

Epoch 00159: val_loss improved from 0.00002 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4906e-05 - val_loss: 1.4754e-05
Epoch 160/512

Epoch 00160: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4708e-05 - val_loss: 1.4544e-05
Epoch 161/512

Epoch 00161: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4385e-05 - val_loss: 1.4125e-05
Epoch 162/512

Epoch 00162: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3953e-05 - val_loss: 1.3756e-05
Epoch 163/512

Epoch 00163: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3643e-05 - val_loss: 1.3492e-05
Epoch 164/512

Epoch 00164: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3387e-05 - val_loss: 1.3100e-05
Epoch 165/512

Epoch 00165: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2950e-05 - val_loss: 1.2786e-05
Epoch 166/512

Epoch 00166: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2718e-05 - val_loss: 1.2560e-05
Epoch 167/512

Epoch 00167: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2440e-05 - val_loss: 1.2159e-05
Epoch 168/512

Epoch 00168: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2032e-05 - val_loss: 1.1882e-05
Epoch 169/512

Epoch 00169: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1813e-05 - val_loss: 1.1665e-05
Epoch 170/512

Epoch 00170: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1534e-05 - val_loss: 1.1360e-05
Epoch 171/512

Epoch 00171: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1253e-05 - val_loss: 1.0987e-05
Epoch 172/512

Epoch 00172: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0876e-05 - val_loss: 1.0771e-05
Epoch 173/512

Epoch 00173: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0718e-05 - val_loss: 1.0577e-05
Epoch 174/512

Epoch 00174: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0456e-05 - val_loss: 1.0225e-05
Epoch 175/512

Epoch 00175: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0110e-05 - val_loss: 9.9456e-06
Epoch 176/512

Epoch 00176: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.8634e-06 - val_loss: 9.8483e-06
Epoch 177/512

Epoch 00177: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.7505e-06 - val_loss: 9.5263e-06
Epoch 178/512

Epoch 00178: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.3701e-06 - val_loss: 9.1947e-06
Epoch 179/512

Epoch 00179: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.1393e-06 - val_loss: 9.0605e-06
Epoch 180/512

Epoch 00180: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.9849e-06 - val_loss: 8.8215e-06
Epoch 181/512

Epoch 00181: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.6987e-06 - val_loss: 8.5539e-06
Epoch 182/512

Epoch 00182: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.4747e-06 - val_loss: 8.3816e-06
Epoch 183/512

Epoch 00183: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.2836e-06 - val_loss: 8.1789e-06
Epoch 184/512

Epoch 00184: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.0831e-06 - val_loss: 7.9167e-06
Epoch 185/512

Epoch 00185: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.8297e-06 - val_loss: 7.7009e-06
Epoch 186/512

Epoch 00186: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.6455e-06 - val_loss: 7.5316e-06
Epoch 187/512

Epoch 00187: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.4624e-06 - val_loss: 7.3332e-06
Epoch 188/512

Epoch 00188: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.2619e-06 - val_loss: 7.1051e-06
Epoch 189/512

Epoch 00189: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.0429e-06 - val_loss: 6.9534e-06
Epoch 190/512

Epoch 00190: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.8948e-06 - val_loss: 6.7811e-06
Epoch 191/512

Epoch 00191: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.7159e-06 - val_loss: 6.5733e-06
Epoch 192/512

Epoch 00192: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.5025e-06 - val_loss: 6.4085e-06
Epoch 193/512

Epoch 00193: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.3483e-06 - val_loss: 6.2765e-06
Epoch 194/512

Epoch 00194: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.2151e-06 - val_loss: 6.0688e-06
Epoch 195/512

Epoch 00195: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.9916e-06 - val_loss: 5.8962e-06
Epoch 196/512

Epoch 00196: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.8629e-06 - val_loss: 5.7723e-06
Epoch 197/512

Epoch 00197: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.7070e-06 - val_loss: 5.6194e-06
Epoch 198/512

Epoch 00198: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.5574e-06 - val_loss: 5.4493e-06
Epoch 199/512

Epoch 00199: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.3980e-06 - val_loss: 5.2708e-06
Epoch 200/512

Epoch 00200: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.2263e-06 - val_loss: 5.1824e-06
Epoch 201/512

Epoch 00201: val_loss improved from 0.00001 to 0.00001, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.1473e-06 - val_loss: 5.0322e-06
Epoch 202/512

Epoch 00202: val_loss improved from 0.00001 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.9620e-06 - val_loss: 4.8668e-06
Epoch 203/512

Epoch 00203: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.8338e-06 - val_loss: 4.7503e-06
Epoch 204/512

Epoch 00204: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.7126e-06 - val_loss: 4.6244e-06
Epoch 205/512

Epoch 00205: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.5668e-06 - val_loss: 4.5159e-06
Epoch 206/512

Epoch 00206: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.4735e-06 - val_loss: 4.3889e-06
Epoch 207/512

Epoch 00207: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.3299e-06 - val_loss: 4.2342e-06
Epoch 208/512

Epoch 00208: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.1902e-06 - val_loss: 4.1480e-06
Epoch 209/512

Epoch 00209: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.1137e-06 - val_loss: 4.0484e-06
Epoch 210/512

Epoch 00210: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.9905e-06 - val_loss: 3.8993e-06
Epoch 211/512

Epoch 00211: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.8518e-06 - val_loss: 3.8043e-06
Epoch 212/512

Epoch 00212: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.7711e-06 - val_loss: 3.7227e-06
Epoch 213/512

Epoch 00213: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.6746e-06 - val_loss: 3.5940e-06
Epoch 214/512

Epoch 00214: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.5497e-06 - val_loss: 3.4832e-06
Epoch 215/512

Epoch 00215: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.4592e-06 - val_loss: 3.3941e-06
Epoch 216/512

Epoch 00216: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3558e-06 - val_loss: 3.3090e-06
Epoch 217/512

Epoch 00217: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.2778e-06 - val_loss: 3.2173e-06
Epoch 218/512

Epoch 00218: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1743e-06 - val_loss: 3.1165e-06
Epoch 219/512

Epoch 00219: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.0785e-06 - val_loss: 3.0488e-06
Epoch 220/512

Epoch 00220: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.0201e-06 - val_loss: 2.9390e-06
Epoch 221/512

Epoch 00221: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8962e-06 - val_loss: 2.8563e-06
Epoch 222/512

Epoch 00222: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8375e-06 - val_loss: 2.7971e-06
Epoch 223/512

Epoch 00223: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7594e-06 - val_loss: 2.7035e-06
Epoch 224/512

Epoch 00224: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6708e-06 - val_loss: 2.6178e-06
Epoch 225/512

Epoch 00225: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5908e-06 - val_loss: 2.5560e-06
Epoch 226/512

Epoch 00226: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5380e-06 - val_loss: 2.4706e-06
Epoch 227/512

Epoch 00227: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4392e-06 - val_loss: 2.3995e-06
Epoch 228/512

Epoch 00228: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3819e-06 - val_loss: 2.3505e-06
Epoch 229/512

Epoch 00229: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3223e-06 - val_loss: 2.2749e-06
Epoch 230/512

Epoch 00230: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2394e-06 - val_loss: 2.2055e-06
Epoch 231/512

Epoch 00231: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1804e-06 - val_loss: 2.1561e-06
Epoch 232/512

Epoch 00232: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1299e-06 - val_loss: 2.0872e-06
Epoch 233/512

Epoch 00233: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0560e-06 - val_loss: 2.0104e-06
Epoch 234/512

Epoch 00234: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9942e-06 - val_loss: 1.9561e-06
Epoch 235/512

Epoch 00235: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9400e-06 - val_loss: 1.9110e-06
Epoch 236/512

Epoch 00236: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8907e-06 - val_loss: 1.8505e-06
Epoch 237/512

Epoch 00237: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8239e-06 - val_loss: 1.7952e-06
Epoch 238/512

Epoch 00238: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7799e-06 - val_loss: 1.7434e-06
Epoch 239/512

Epoch 00239: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7257e-06 - val_loss: 1.6890e-06
Epoch 240/512

Epoch 00240: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6671e-06 - val_loss: 1.6528e-06
Epoch 241/512

Epoch 00241: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6362e-06 - val_loss: 1.5990e-06
Epoch 242/512

Epoch 00242: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5758e-06 - val_loss: 1.5416e-06
Epoch 243/512

Epoch 00243: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5240e-06 - val_loss: 1.5077e-06
Epoch 244/512

Epoch 00244: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4932e-06 - val_loss: 1.4701e-06
Epoch 245/512

Epoch 00245: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4445e-06 - val_loss: 1.4192e-06
Epoch 246/512

Epoch 00246: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3983e-06 - val_loss: 1.3766e-06
Epoch 247/512

Epoch 00247: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3597e-06 - val_loss: 1.3391e-06
Epoch 248/512

Epoch 00248: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3233e-06 - val_loss: 1.2946e-06
Epoch 249/512

Epoch 00249: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2784e-06 - val_loss: 1.2524e-06
Epoch 250/512

Epoch 00250: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2377e-06 - val_loss: 1.2253e-06
Epoch 251/512

Epoch 00251: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2149e-06 - val_loss: 1.1843e-06
Epoch 252/512

Epoch 00252: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1674e-06 - val_loss: 1.1398e-06
Epoch 253/512

Epoch 00253: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1324e-06 - val_loss: 1.1124e-06
Epoch 254/512

Epoch 00254: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1032e-06 - val_loss: 1.0822e-06
Epoch 255/512

Epoch 00255: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0681e-06 - val_loss: 1.0535e-06
Epoch 256/512

Epoch 00256: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0408e-06 - val_loss: 1.0190e-06
Epoch 257/512

Epoch 00257: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0032e-06 - val_loss: 9.8499e-07
Epoch 258/512

Epoch 00258: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.7769e-07 - val_loss: 9.5694e-07
Epoch 259/512

Epoch 00259: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.4720e-07 - val_loss: 9.2789e-07
Epoch 260/512

Epoch 00260: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.1696e-07 - val_loss: 9.0227e-07
Epoch 261/512

Epoch 00261: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.9396e-07 - val_loss: 8.7493e-07
Epoch 262/512

Epoch 00262: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.6360e-07 - val_loss: 8.4720e-07
Epoch 263/512

Epoch 00263: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.3623e-07 - val_loss: 8.2594e-07
Epoch 264/512

Epoch 00264: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.1656e-07 - val_loss: 8.0200e-07
Epoch 265/512

Epoch 00265: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.9139e-07 - val_loss: 7.6904e-07
Epoch 266/512

Epoch 00266: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.5958e-07 - val_loss: 7.4887e-07
Epoch 267/512

Epoch 00267: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.4431e-07 - val_loss: 7.3342e-07
Epoch 268/512

Epoch 00268: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.2324e-07 - val_loss: 7.0426e-07
Epoch 269/512

Epoch 00269: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.9507e-07 - val_loss: 6.8135e-07
Epoch 270/512

Epoch 00270: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.7634e-07 - val_loss: 6.6679e-07
Epoch 271/512

Epoch 00271: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.5851e-07 - val_loss: 6.4729e-07
Epoch 272/512

Epoch 00272: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.3795e-07 - val_loss: 6.2324e-07
Epoch 273/512

Epoch 00273: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.1433e-07 - val_loss: 6.0600e-07
Epoch 274/512

Epoch 00274: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.9989e-07 - val_loss: 5.9167e-07
Epoch 275/512

Epoch 00275: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.8367e-07 - val_loss: 5.6832e-07
Epoch 276/512

Epoch 00276: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.6048e-07 - val_loss: 5.4828e-07
Epoch 277/512

Epoch 00277: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.4416e-07 - val_loss: 5.3842e-07
Epoch 278/512

Epoch 00278: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.3211e-07 - val_loss: 5.2282e-07
Epoch 279/512

Epoch 00279: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.1480e-07 - val_loss: 5.0032e-07
Epoch 280/512

Epoch 00280: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.9355e-07 - val_loss: 4.8756e-07
Epoch 281/512

Epoch 00281: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.8479e-07 - val_loss: 4.7649e-07
Epoch 282/512

Epoch 00282: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.6839e-07 - val_loss: 4.5811e-07
Epoch 283/512

Epoch 00283: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.5216e-07 - val_loss: 4.4463e-07
Epoch 284/512

Epoch 00284: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.4008e-07 - val_loss: 4.3172e-07
Epoch 285/512

Epoch 00285: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.2589e-07 - val_loss: 4.1901e-07
Epoch 286/512

Epoch 00286: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.1370e-07 - val_loss: 4.0631e-07
Epoch 287/512

Epoch 00287: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.0072e-07 - val_loss: 3.9220e-07
Epoch 288/512

Epoch 00288: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.8736e-07 - val_loss: 3.8204e-07
Epoch 289/512

Epoch 00289: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.7790e-07 - val_loss: 3.6916e-07
Epoch 290/512

Epoch 00290: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.6341e-07 - val_loss: 3.5753e-07
Epoch 291/512

Epoch 00291: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.5413e-07 - val_loss: 3.4825e-07
Epoch 292/512

Epoch 00292: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.4377e-07 - val_loss: 3.3649e-07
Epoch 293/512

Epoch 00293: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3162e-07 - val_loss: 3.2467e-07
Epoch 294/512

Epoch 00294: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.2128e-07 - val_loss: 3.1660e-07
Epoch 295/512

Epoch 00295: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1303e-07 - val_loss: 3.0763e-07
Epoch 296/512

Epoch 00296: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.0299e-07 - val_loss: 2.9611e-07
Epoch 297/512

Epoch 00297: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9188e-07 - val_loss: 2.8797e-07
Epoch 298/512

Epoch 00298: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8453e-07 - val_loss: 2.8100e-07
Epoch 299/512

Epoch 00299: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7739e-07 - val_loss: 2.6922e-07
Epoch 300/512

Epoch 00300: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6483e-07 - val_loss: 2.6087e-07
Epoch 301/512

Epoch 00301: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5855e-07 - val_loss: 2.5632e-07
Epoch 302/512

Epoch 00302: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5272e-07 - val_loss: 2.4651e-07
Epoch 303/512

Epoch 00303: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4218e-07 - val_loss: 2.3704e-07
Epoch 304/512

Epoch 00304: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3469e-07 - val_loss: 2.3129e-07
Epoch 305/512

Epoch 00305: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2882e-07 - val_loss: 2.2491e-07
Epoch 306/512

Epoch 00306: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2186e-07 - val_loss: 2.1620e-07
Epoch 307/512

Epoch 00307: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1365e-07 - val_loss: 2.0888e-07
Epoch 308/512

Epoch 00308: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0676e-07 - val_loss: 2.0511e-07
Epoch 309/512

Epoch 00309: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0293e-07 - val_loss: 1.9816e-07
Epoch 310/512

Epoch 00310: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9478e-07 - val_loss: 1.8960e-07
Epoch 311/512

Epoch 00311: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8768e-07 - val_loss: 1.8509e-07
Epoch 312/512

Epoch 00312: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8350e-07 - val_loss: 1.8055e-07
Epoch 313/512

Epoch 00313: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7812e-07 - val_loss: 1.7414e-07
Epoch 314/512

Epoch 00314: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7153e-07 - val_loss: 1.6819e-07
Epoch 315/512

Epoch 00315: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6629e-07 - val_loss: 1.6368e-07
Epoch 316/512

Epoch 00316: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6169e-07 - val_loss: 1.5890e-07
Epoch 317/512

Epoch 00317: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5685e-07 - val_loss: 1.5318e-07
Epoch 318/512

Epoch 00318: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5077e-07 - val_loss: 1.4836e-07
Epoch 319/512

Epoch 00319: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4697e-07 - val_loss: 1.4473e-07
Epoch 320/512

Epoch 00320: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4249e-07 - val_loss: 1.3965e-07
Epoch 321/512

Epoch 00321: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3771e-07 - val_loss: 1.3530e-07
Epoch 322/512

Epoch 00322: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3365e-07 - val_loss: 1.3094e-07
Epoch 323/512

Epoch 00323: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2925e-07 - val_loss: 1.2654e-07
Epoch 324/512

Epoch 00324: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2515e-07 - val_loss: 1.2342e-07
Epoch 325/512

Epoch 00325: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2185e-07 - val_loss: 1.1943e-07
Epoch 326/512

Epoch 00326: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1752e-07 - val_loss: 1.1518e-07
Epoch 327/512

Epoch 00327: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1370e-07 - val_loss: 1.1175e-07
Epoch 328/512

Epoch 00328: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1035e-07 - val_loss: 1.0846e-07
Epoch 329/512

Epoch 00329: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0709e-07 - val_loss: 1.0533e-07
Epoch 330/512

Epoch 00330: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0359e-07 - val_loss: 1.0202e-07
Epoch 331/512

Epoch 00331: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0044e-07 - val_loss: 9.9085e-08
Epoch 332/512

Epoch 00332: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.7471e-08 - val_loss: 9.5308e-08
Epoch 333/512

Epoch 00333: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.4080e-08 - val_loss: 9.1957e-08
Epoch 334/512

Epoch 00334: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.0735e-08 - val_loss: 9.0151e-08
Epoch 335/512

Epoch 00335: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.9063e-08 - val_loss: 8.7157e-08
Epoch 336/512

Epoch 00336: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.5732e-08 - val_loss: 8.3486e-08
Epoch 337/512

Epoch 00337: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.2340e-08 - val_loss: 8.1406e-08
Epoch 338/512

Epoch 00338: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.0689e-08 - val_loss: 7.9242e-08
Epoch 339/512

Epoch 00339: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.8127e-08 - val_loss: 7.5941e-08
Epoch 340/512

Epoch 00340: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.4907e-08 - val_loss: 7.3990e-08
Epoch 341/512

Epoch 00341: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.3192e-08 - val_loss: 7.2160e-08
Epoch 342/512

Epoch 00342: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.0905e-08 - val_loss: 6.9696e-08
Epoch 343/512

Epoch 00343: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.8692e-08 - val_loss: 6.6811e-08
Epoch 344/512

Epoch 00344: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.5904e-08 - val_loss: 6.5126e-08
Epoch 345/512

Epoch 00345: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.4448e-08 - val_loss: 6.3711e-08
Epoch 346/512

Epoch 00346: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.2696e-08 - val_loss: 6.1093e-08
Epoch 347/512

Epoch 00347: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.0020e-08 - val_loss: 5.9045e-08
Epoch 348/512

Epoch 00348: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.8426e-08 - val_loss: 5.7784e-08
Epoch 349/512

Epoch 00349: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.6998e-08 - val_loss: 5.5616e-08
Epoch 350/512

Epoch 00350: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.4570e-08 - val_loss: 5.3774e-08
Epoch 351/512

Epoch 00351: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.3139e-08 - val_loss: 5.2365e-08
Epoch 352/512

Epoch 00352: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.1502e-08 - val_loss: 5.0571e-08
Epoch 353/512

Epoch 00353: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.9946e-08 - val_loss: 4.8907e-08
Epoch 354/512

Epoch 00354: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.8150e-08 - val_loss: 4.7531e-08
Epoch 355/512

Epoch 00355: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.6853e-08 - val_loss: 4.6091e-08
Epoch 356/512

Epoch 00356: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.5458e-08 - val_loss: 4.4383e-08
Epoch 357/512

Epoch 00357: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.3634e-08 - val_loss: 4.2924e-08
Epoch 358/512

Epoch 00358: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.2408e-08 - val_loss: 4.2015e-08
Epoch 359/512

Epoch 00359: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.1467e-08 - val_loss: 4.0716e-08
Epoch 360/512

Epoch 00360: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.9951e-08 - val_loss: 3.8881e-08
Epoch 361/512

Epoch 00361: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.8295e-08 - val_loss: 3.7765e-08
Epoch 362/512

Epoch 00362: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.7351e-08 - val_loss: 3.7304e-08
Epoch 363/512

Epoch 00363: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.6737e-08 - val_loss: 3.5825e-08
Epoch 364/512

Epoch 00364: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.5044e-08 - val_loss: 3.4061e-08
Epoch 365/512

Epoch 00365: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3646e-08 - val_loss: 3.3322e-08
Epoch 366/512

Epoch 00366: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3059e-08 - val_loss: 3.2764e-08
Epoch 367/512

Epoch 00367: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.2194e-08 - val_loss: 3.1326e-08
Epoch 368/512

Epoch 00368: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.0692e-08 - val_loss: 3.0144e-08
Epoch 369/512

Epoch 00369: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9896e-08 - val_loss: 2.9633e-08
Epoch 370/512

Epoch 00370: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9205e-08 - val_loss: 2.8640e-08
Epoch 371/512

Epoch 00371: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8119e-08 - val_loss: 2.7490e-08
Epoch 372/512

Epoch 00372: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7051e-08 - val_loss: 2.6669e-08
Epoch 373/512

Epoch 00373: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6418e-08 - val_loss: 2.6016e-08
Epoch 374/512

Epoch 00374: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5615e-08 - val_loss: 2.5114e-08
Epoch 375/512

Epoch 00375: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4786e-08 - val_loss: 2.4195e-08
Epoch 376/512

Epoch 00376: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3782e-08 - val_loss: 2.3531e-08
Epoch 377/512

Epoch 00377: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3312e-08 - val_loss: 2.3030e-08
Epoch 378/512

Epoch 00378: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2596e-08 - val_loss: 2.2226e-08
Epoch 379/512

Epoch 00379: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1834e-08 - val_loss: 2.1297e-08
Epoch 380/512

Epoch 00380: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0981e-08 - val_loss: 2.0700e-08
Epoch 381/512

Epoch 00381: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0464e-08 - val_loss: 2.0261e-08
Epoch 382/512

Epoch 00382: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9966e-08 - val_loss: 1.9536e-08
Epoch 383/512

Epoch 00383: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9167e-08 - val_loss: 1.8792e-08
Epoch 384/512

Epoch 00384: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8505e-08 - val_loss: 1.8365e-08
Epoch 385/512

Epoch 00385: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8155e-08 - val_loss: 1.7903e-08
Epoch 386/512

Epoch 00386: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7559e-08 - val_loss: 1.7090e-08
Epoch 387/512

Epoch 00387: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6787e-08 - val_loss: 1.6552e-08
Epoch 388/512

Epoch 00388: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6368e-08 - val_loss: 1.6269e-08
Epoch 389/512

Epoch 00389: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6033e-08 - val_loss: 1.5699e-08
Epoch 390/512

Epoch 00390: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5394e-08 - val_loss: 1.5044e-08
Epoch 391/512

Epoch 00391: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4840e-08 - val_loss: 1.4630e-08
Epoch 392/512

Epoch 00392: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4414e-08 - val_loss: 1.4382e-08
Epoch 393/512

Epoch 00393: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4189e-08 - val_loss: 1.3931e-08
Epoch 394/512

Epoch 00394: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3611e-08 - val_loss: 1.3338e-08
Epoch 395/512

Epoch 00395: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3120e-08 - val_loss: 1.2911e-08
Epoch 396/512

Epoch 00396: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2738e-08 - val_loss: 1.2644e-08
Epoch 397/512

Epoch 00397: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2491e-08 - val_loss: 1.2285e-08
Epoch 398/512

Epoch 00398: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2032e-08 - val_loss: 1.1796e-08
Epoch 399/512

Epoch 00399: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1560e-08 - val_loss: 1.1459e-08
Epoch 400/512

Epoch 00400: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1296e-08 - val_loss: 1.1160e-08
Epoch 401/512

Epoch 00401: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1000e-08 - val_loss: 1.0745e-08
Epoch 402/512

Epoch 00402: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0545e-08 - val_loss: 1.0410e-08
Epoch 403/512

Epoch 00403: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0283e-08 - val_loss: 1.0129e-08
Epoch 404/512

Epoch 00404: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.9887e-09 - val_loss: 9.8072e-09
Epoch 405/512

Epoch 00405: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.6432e-09 - val_loss: 9.5168e-09
Epoch 406/512

Epoch 00406: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.3863e-09 - val_loss: 9.2451e-09
Epoch 407/512

Epoch 00407: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.1050e-09 - val_loss: 8.9463e-09
Epoch 408/512

Epoch 00408: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.8184e-09 - val_loss: 8.7247e-09
Epoch 409/512

Epoch 00409: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.5988e-09 - val_loss: 8.4098e-09
Epoch 410/512

Epoch 00410: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.2688e-09 - val_loss: 8.1707e-09
Epoch 411/512

Epoch 00411: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.0311e-09 - val_loss: 7.9404e-09
Epoch 412/512

Epoch 00412: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.8248e-09 - val_loss: 7.7502e-09
Epoch 413/512

Epoch 00413: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.6289e-09 - val_loss: 7.4690e-09
Epoch 414/512

Epoch 00414: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.3189e-09 - val_loss: 7.1703e-09
Epoch 415/512

Epoch 00415: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.0861e-09 - val_loss: 7.0621e-09
Epoch 416/512

Epoch 00416: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.9515e-09 - val_loss: 6.8903e-09
Epoch 417/512

Epoch 00417: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.7681e-09 - val_loss: 6.6521e-09
Epoch 418/512

Epoch 00418: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.5184e-09 - val_loss: 6.4349e-09
Epoch 419/512

Epoch 00419: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.3145e-09 - val_loss: 6.2425e-09
Epoch 420/512

Epoch 00420: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.1730e-09 - val_loss: 6.0879e-09
Epoch 421/512

Epoch 00421: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.9758e-09 - val_loss: 5.8894e-09
Epoch 422/512

Epoch 00422: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.8087e-09 - val_loss: 5.7392e-09
Epoch 423/512

Epoch 00423: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.6307e-09 - val_loss: 5.5110e-09
Epoch 424/512

Epoch 00424: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.4419e-09 - val_loss: 5.4228e-09
Epoch 425/512

Epoch 00425: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.3693e-09 - val_loss: 5.3093e-09
Epoch 426/512

Epoch 00426: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.1809e-09 - val_loss: 5.0198e-09
Epoch 427/512

Epoch 00427: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.9356e-09 - val_loss: 4.8896e-09
Epoch 428/512

Epoch 00428: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8425e-09 - val_loss: 4.9023e-09
Epoch 429/512

Epoch 00429: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.8500e-09 - val_loss: 4.7346e-09
Epoch 430/512

Epoch 00430: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.5904e-09 - val_loss: 4.5095e-09
Epoch 431/512

Epoch 00431: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.4260e-09 - val_loss: 4.3980e-09
Epoch 432/512

Epoch 00432: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.3515e-09 - val_loss: 4.2841e-09
Epoch 433/512

Epoch 00433: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.2068e-09 - val_loss: 4.1524e-09
Epoch 434/512

Epoch 00434: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.0933e-09 - val_loss: 4.0531e-09
Epoch 435/512

Epoch 00435: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.9934e-09 - val_loss: 3.9231e-09
Epoch 436/512

Epoch 00436: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.8514e-09 - val_loss: 3.8266e-09
Epoch 437/512

Epoch 00437: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.7703e-09 - val_loss: 3.7697e-09
Epoch 438/512

Epoch 00438: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.7294e-09 - val_loss: 3.6697e-09
Epoch 439/512

Epoch 00439: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.5859e-09 - val_loss: 3.5160e-09
Epoch 440/512

Epoch 00440: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.4491e-09 - val_loss: 3.4125e-09
Epoch 441/512

Epoch 00441: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3629e-09 - val_loss: 3.3605e-09
Epoch 442/512

Epoch 00442: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3294e-09 - val_loss: 3.2832e-09
Epoch 443/512

Epoch 00443: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.2135e-09 - val_loss: 3.1614e-09
Epoch 444/512

Epoch 00444: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1078e-09 - val_loss: 3.0699e-09
Epoch 445/512

Epoch 00445: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.0247e-09 - val_loss: 2.9993e-09
Epoch 446/512

Epoch 00446: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9595e-09 - val_loss: 2.9506e-09
Epoch 447/512

Epoch 00447: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8973e-09 - val_loss: 2.8591e-09
Epoch 448/512

Epoch 00448: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8136e-09 - val_loss: 2.7705e-09
Epoch 449/512

Epoch 00449: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7114e-09 - val_loss: 2.6679e-09
Epoch 450/512

Epoch 00450: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6282e-09 - val_loss: 2.6174e-09
Epoch 451/512

Epoch 00451: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5790e-09 - val_loss: 2.5674e-09
Epoch 452/512

Epoch 00452: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5342e-09 - val_loss: 2.4969e-09
Epoch 453/512

Epoch 00453: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4598e-09 - val_loss: 2.4643e-09
Epoch 454/512

Epoch 00454: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4289e-09 - val_loss: 2.3880e-09
Epoch 455/512

Epoch 00455: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3427e-09 - val_loss: 2.3001e-09
Epoch 456/512

Epoch 00456: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2527e-09 - val_loss: 2.2278e-09
Epoch 457/512

Epoch 00457: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1987e-09 - val_loss: 2.1817e-09
Epoch 458/512

Epoch 00458: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1705e-09 - val_loss: 2.1720e-09
Epoch 459/512

Epoch 00459: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1398e-09 - val_loss: 2.1182e-09
Epoch 460/512

Epoch 00460: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0820e-09 - val_loss: 2.0516e-09
Epoch 461/512

Epoch 00461: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0152e-09 - val_loss: 1.9940e-09
Epoch 462/512

Epoch 00462: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9652e-09 - val_loss: 1.9215e-09
Epoch 463/512

Epoch 00463: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8841e-09 - val_loss: 1.8530e-09
Epoch 464/512

Epoch 00464: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8296e-09 - val_loss: 1.8479e-09
Epoch 465/512

Epoch 00465: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8313e-09 - val_loss: 1.8212e-09
Epoch 466/512

Epoch 00466: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7940e-09 - val_loss: 1.7682e-09
Epoch 467/512

Epoch 00467: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7377e-09 - val_loss: 1.7099e-09
Epoch 468/512

Epoch 00468: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6879e-09 - val_loss: 1.6635e-09
Epoch 469/512

Epoch 00469: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6421e-09 - val_loss: 1.6489e-09
Epoch 470/512

Epoch 00470: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6395e-09 - val_loss: 1.6346e-09
Epoch 471/512

Epoch 00471: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6037e-09 - val_loss: 1.5773e-09
Epoch 472/512

Epoch 00472: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5452e-09 - val_loss: 1.5096e-09
Epoch 473/512

Epoch 00473: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4884e-09 - val_loss: 1.4762e-09
Epoch 474/512

Epoch 00474: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4687e-09 - val_loss: 1.4717e-09
Epoch 475/512

Epoch 00475: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4516e-09 - val_loss: 1.4490e-09
Epoch 476/512

Epoch 00476: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4227e-09 - val_loss: 1.3996e-09
Epoch 477/512

Epoch 00477: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3770e-09 - val_loss: 1.3598e-09
Epoch 478/512

Epoch 00478: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3298e-09 - val_loss: 1.3228e-09
Epoch 479/512

Epoch 00479: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2993e-09 - val_loss: 1.3078e-09
Epoch 480/512

Epoch 00480: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2970e-09 - val_loss: 1.2906e-09
Epoch 481/512

Epoch 00481: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2623e-09 - val_loss: 1.2295e-09
Epoch 482/512

Epoch 00482: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2095e-09 - val_loss: 1.1962e-09
Epoch 483/512

Epoch 00483: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1841e-09 - val_loss: 1.1891e-09
Epoch 484/512

Epoch 00484: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1838e-09 - val_loss: 1.1933e-09
Epoch 485/512

Epoch 00485: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1748e-09 - val_loss: 1.1638e-09
Epoch 486/512

Epoch 00486: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1393e-09 - val_loss: 1.1107e-09
Epoch 487/512

Epoch 00487: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0928e-09 - val_loss: 1.0870e-09
Epoch 488/512

Epoch 00488: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0814e-09 - val_loss: 1.0841e-09
Epoch 489/512

Epoch 00489: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0752e-09 - val_loss: 1.0628e-09
Epoch 490/512

Epoch 00490: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0462e-09 - val_loss: 1.0339e-09
Epoch 491/512

Epoch 00491: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0162e-09 - val_loss: 1.0084e-09
Epoch 492/512

Epoch 00492: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.9227e-10 - val_loss: 9.7652e-10
Epoch 493/512

Epoch 00493: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.6494e-10 - val_loss: 9.5158e-10
Epoch 494/512

Epoch 00494: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.4192e-10 - val_loss: 9.4612e-10
Epoch 495/512

Epoch 00495: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.4109e-10 - val_loss: 9.3976e-10
Epoch 496/512

Epoch 00496: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.2026e-10 - val_loss: 9.0912e-10
Epoch 497/512

Epoch 00497: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.0561e-10 - val_loss: 9.0200e-10
Epoch 498/512

Epoch 00498: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.8277e-10 - val_loss: 8.6148e-10
Epoch 499/512

Epoch 00499: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.4922e-10 - val_loss: 8.4243e-10
Epoch 500/512

Epoch 00500: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.3691e-10 - val_loss: 8.4250e-10
Epoch 501/512

Epoch 00501: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.3260e-10 - val_loss: 8.3131e-10
Epoch 502/512

Epoch 00502: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.1937e-10 - val_loss: 8.1773e-10
Epoch 503/512

Epoch 00503: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.0692e-10 - val_loss: 8.0253e-10
Epoch 504/512

Epoch 00504: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.9208e-10 - val_loss: 7.9502e-10
Epoch 505/512

Epoch 00505: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.8867e-10 - val_loss: 7.8006e-10
Epoch 506/512

Epoch 00506: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.6585e-10 - val_loss: 7.4900e-10
Epoch 507/512

Epoch 00507: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.3828e-10 - val_loss: 7.2814e-10
Epoch 508/512

Epoch 00508: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.1998e-10 - val_loss: 7.1847e-10
Epoch 509/512

Epoch 00509: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.0981e-10 - val_loss: 7.0975e-10
Epoch 510/512

Epoch 00510: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.9818e-10 - val_loss: 6.9488e-10
Epoch 511/512

Epoch 00511: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.8646e-10 - val_loss: 6.6557e-10
Epoch 512/512

Epoch 00512: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.6059e-10 - val_loss: 6.6172e-10
Train on 512 samples, validate on 512 samples
Epoch 1/512
512/512 - 1s - loss: 0.6646 - val_loss: 0.0848
Epoch 2/512
512/512 - 0s - loss: 0.0685 - val_loss: 0.0772
Epoch 3/512
512/512 - 0s - loss: 0.0551 - val_loss: 0.0713
Epoch 4/512
512/512 - 0s - loss: 0.0491 - val_loss: 0.0663
Epoch 5/512
512/512 - 0s - loss: 0.0464 - val_loss: 0.0618
Epoch 6/512
512/512 - 0s - loss: 0.0447 - val_loss: 0.0574
Epoch 7/512
512/512 - 0s - loss: 0.0433 - val_loss: 0.0526
Epoch 8/512
512/512 - 0s - loss: 0.0416 - val_loss: 0.0475
Epoch 9/512
512/512 - 0s - loss: 0.0395 - val_loss: 0.0418
Epoch 10/512
512/512 - 0s - loss: 0.0369 - val_loss: 0.0356
Epoch 11/512
512/512 - 0s - loss: 0.0337 - val_loss: 0.0292
Epoch 12/512
512/512 - 0s - loss: 0.0297 - val_loss: 0.0228
Epoch 13/512
512/512 - 0s - loss: 0.0248 - val_loss: 0.0171
Epoch 14/512
512/512 - 0s - loss: 0.0193 - val_loss: 0.0126
Epoch 15/512
512/512 - 0s - loss: 0.0140 - val_loss: 0.0091
Epoch 16/512
512/512 - 0s - loss: 0.0096 - val_loss: 0.0064
Epoch 17/512
512/512 - 0s - loss: 0.0062 - val_loss: 0.0042
Epoch 18/512
512/512 - 0s - loss: 0.0038 - val_loss: 0.0026
Epoch 19/512
512/512 - 0s - loss: 0.0024 - val_loss: 0.0017
Epoch 20/512
512/512 - 0s - loss: 0.0016 - val_loss: 0.0013
Epoch 21/512
512/512 - 0s - loss: 0.0013 - val_loss: 0.0011
Epoch 22/512
512/512 - 0s - loss: 8.4090e-04 - val_loss: 0.0010
Epoch 23/512
512/512 - 0s - loss: 5.8730e-04 - val_loss: 9.0162e-04
Epoch 24/512
512/512 - 0s - loss: 4.4705e-04 - val_loss: 7.4728e-04
Epoch 25/512
512/512 - 0s - loss: 3.9891e-04 - val_loss: 6.5181e-04
Epoch 26/512
512/512 - 0s - loss: 3.3052e-04 - val_loss: 6.3749e-04
Epoch 27/512
512/512 - 0s - loss: 2.7219e-04 - val_loss: 5.9030e-04
Epoch 28/512
512/512 - 0s - loss: 2.8153e-04 - val_loss: 5.2624e-04
Epoch 29/512
512/512 - 0s - loss: 3.1902e-04 - val_loss: 5.1332e-04
Epoch 30/512
512/512 - 0s - loss: 2.9541e-04 - val_loss: 5.1973e-04
Epoch 31/512
512/512 - 0s - loss: 2.7701e-04 - val_loss: 4.8960e-04
Epoch 32/512
512/512 - 0s - loss: 2.9169e-04 - val_loss: 4.7853e-04
Epoch 33/512
512/512 - 0s - loss: 2.7550e-04 - val_loss: 4.9023e-04
Epoch 34/512
512/512 - 0s - loss: 2.4078e-04 - val_loss: 4.7624e-04
Epoch 35/512
512/512 - 0s - loss: 2.2911e-04 - val_loss: 4.5097e-04
Epoch 36/512
512/512 - 0s - loss: 2.2379e-04 - val_loss: 4.4446e-04
Epoch 37/512
512/512 - 0s - loss: 1.9491e-04 - val_loss: 4.4825e-04
Epoch 38/512
512/512 - 0s - loss: 1.6764e-04 - val_loss: 4.2345e-04
Epoch 39/512
512/512 - 0s - loss: 1.6184e-04 - val_loss: 3.9947e-04
Epoch 40/512
512/512 - 0s - loss: 1.5077e-04 - val_loss: 3.9885e-04
Epoch 41/512
512/512 - 0s - loss: 1.2445e-04 - val_loss: 3.8867e-04
Epoch 42/512
512/512 - 0s - loss: 1.1356e-04 - val_loss: 3.6432e-04
Epoch 43/512
512/512 - 0s - loss: 1.0897e-04 - val_loss: 3.5521e-04
Epoch 44/512
512/512 - 0s - loss: 9.3889e-05 - val_loss: 3.5282e-04
Epoch 45/512
512/512 - 0s - loss: 8.0614e-05 - val_loss: 3.3761e-04
Epoch 46/512
512/512 - 0s - loss: 7.7597e-05 - val_loss: 3.2179e-04
Epoch 47/512
512/512 - 0s - loss: 7.1176e-05 - val_loss: 3.2167e-04
Epoch 48/512
512/512 - 0s - loss: 5.9873e-05 - val_loss: 3.1463e-04
Epoch 49/512
512/512 - 0s - loss: 5.5987e-05 - val_loss: 3.0300e-04
Epoch 50/512
512/512 - 0s - loss: 5.1820e-05 - val_loss: 3.0012e-04
Epoch 51/512
512/512 - 0s - loss: 4.5019e-05 - val_loss: 2.9395e-04
Epoch 52/512
512/512 - 0s - loss: 4.2147e-05 - val_loss: 2.8598e-04
Epoch 53/512
512/512 - 0s - loss: 3.8698e-05 - val_loss: 2.8254e-04
Epoch 54/512
512/512 - 0s - loss: 3.4036e-05 - val_loss: 2.7841e-04
Epoch 55/512
512/512 - 0s - loss: 3.1239e-05 - val_loss: 2.7118e-04
Epoch 56/512
512/512 - 0s - loss: 2.9433e-05 - val_loss: 2.6788e-04
Epoch 57/512
512/512 - 0s - loss: 2.6074e-05 - val_loss: 2.6509e-04
Epoch 58/512
512/512 - 0s - loss: 2.3648e-05 - val_loss: 2.5773e-04
Epoch 59/512
512/512 - 0s - loss: 2.2450e-05 - val_loss: 2.5410e-04
Epoch 60/512
512/512 - 0s - loss: 1.9963e-05 - val_loss: 2.5048e-04
Epoch 61/512
512/512 - 0s - loss: 1.7823e-05 - val_loss: 2.4399e-04
Epoch 62/512
512/512 - 0s - loss: 1.7081e-05 - val_loss: 2.3903e-04
Epoch 63/512
512/512 - 0s - loss: 1.5438e-05 - val_loss: 2.3544e-04
Epoch 64/512
512/512 - 0s - loss: 1.3744e-05 - val_loss: 2.2920e-04
Epoch 65/512
512/512 - 0s - loss: 1.3055e-05 - val_loss: 2.2331e-04
Epoch 66/512
512/512 - 0s - loss: 1.1887e-05 - val_loss: 2.1883e-04
Epoch 67/512
512/512 - 0s - loss: 1.0760e-05 - val_loss: 2.1307e-04
Epoch 68/512
512/512 - 0s - loss: 1.0064e-05 - val_loss: 2.0713e-04
Epoch 69/512
512/512 - 0s - loss: 9.2241e-06 - val_loss: 2.0253e-04
Epoch 70/512
512/512 - 0s - loss: 8.3430e-06 - val_loss: 1.9663e-04
Epoch 71/512
512/512 - 0s - loss: 7.7614e-06 - val_loss: 1.9086e-04
Epoch 72/512
512/512 - 0s - loss: 7.2286e-06 - val_loss: 1.8535e-04
Epoch 73/512
512/512 - 0s - loss: 6.6835e-06 - val_loss: 1.8039e-04
Epoch 74/512
512/512 - 0s - loss: 6.0992e-06 - val_loss: 1.7509e-04
Epoch 75/512
512/512 - 0s - loss: 5.7010e-06 - val_loss: 1.6971e-04
Epoch 76/512
512/512 - 0s - loss: 5.2769e-06 - val_loss: 1.6484e-04
Epoch 77/512
512/512 - 0s - loss: 4.8580e-06 - val_loss: 1.5966e-04
Epoch 78/512
512/512 - 0s - loss: 4.5549e-06 - val_loss: 1.5467e-04
Epoch 79/512
512/512 - 0s - loss: 4.2571e-06 - val_loss: 1.5012e-04
Epoch 80/512
512/512 - 0s - loss: 3.9272e-06 - val_loss: 1.4542e-04
Epoch 81/512
512/512 - 0s - loss: 3.6808e-06 - val_loss: 1.4076e-04
Epoch 82/512
512/512 - 0s - loss: 3.4611e-06 - val_loss: 1.3651e-04
Epoch 83/512
512/512 - 0s - loss: 3.2164e-06 - val_loss: 1.3239e-04
Epoch 84/512
512/512 - 0s - loss: 2.9977e-06 - val_loss: 1.2813e-04
Epoch 85/512
512/512 - 0s - loss: 2.8669e-06 - val_loss: 1.2428e-04
Epoch 86/512
512/512 - 0s - loss: 2.6697e-06 - val_loss: 1.2059e-04
Epoch 87/512
512/512 - 0s - loss: 2.5058e-06 - val_loss: 1.1691e-04
Epoch 88/512
512/512 - 0s - loss: 2.3576e-06 - val_loss: 1.1330e-04
Epoch 89/512
512/512 - 0s - loss: 2.2650e-06 - val_loss: 1.0999e-04
Epoch 90/512
512/512 - 0s - loss: 2.1153e-06 - val_loss: 1.0687e-04
Epoch 91/512
512/512 - 0s - loss: 1.9958e-06 - val_loss: 1.0367e-04
Epoch 92/512
512/512 - 0s - loss: 1.9095e-06 - val_loss: 1.0065e-04
Epoch 93/512
512/512 - 0s - loss: 1.8152e-06 - val_loss: 9.7835e-05
Epoch 94/512
512/512 - 0s - loss: 1.7183e-06 - val_loss: 9.5111e-05
Epoch 95/512
512/512 - 0s - loss: 1.6319e-06 - val_loss: 9.2440e-05
Epoch 96/512
512/512 - 0s - loss: 1.5739e-06 - val_loss: 8.9860e-05
Epoch 97/512
512/512 - 0s - loss: 1.4997e-06 - val_loss: 8.7553e-05
Epoch 98/512
512/512 - 0s - loss: 1.4191e-06 - val_loss: 8.5166e-05
Epoch 99/512
512/512 - 0s - loss: 1.3724e-06 - val_loss: 8.2883e-05
Epoch 100/512
512/512 - 0s - loss: 1.3185e-06 - val_loss: 8.0801e-05
Epoch 101/512
512/512 - 0s - loss: 1.2600e-06 - val_loss: 7.8780e-05
Epoch 102/512
512/512 - 0s - loss: 1.2085e-06 - val_loss: 7.6788e-05
Epoch 103/512
512/512 - 0s - loss: 1.1679e-06 - val_loss: 7.4887e-05
Epoch 104/512
512/512 - 0s - loss: 1.1272e-06 - val_loss: 7.3109e-05
Epoch 105/512
512/512 - 0s - loss: 1.0829e-06 - val_loss: 7.1391e-05
Epoch 106/512
512/512 - 0s - loss: 1.0442e-06 - val_loss: 6.9725e-05
Epoch 107/512
512/512 - 0s - loss: 1.0103e-06 - val_loss: 6.8113e-05
Epoch 108/512
512/512 - 0s - loss: 9.7846e-07 - val_loss: 6.6598e-05
Epoch 109/512
512/512 - 0s - loss: 9.4613e-07 - val_loss: 6.5133e-05
Epoch 110/512
512/512 - 0s - loss: 9.1591e-07 - val_loss: 6.3713e-05
Epoch 111/512
512/512 - 0s - loss: 8.8880e-07 - val_loss: 6.2348e-05
Epoch 112/512
512/512 - 0s - loss: 8.6274e-07 - val_loss: 6.1051e-05
Epoch 113/512
512/512 - 0s - loss: 8.3564e-07 - val_loss: 5.9796e-05
Epoch 114/512
512/512 - 0s - loss: 8.1547e-07 - val_loss: 5.8574e-05
Epoch 115/512
512/512 - 0s - loss: 7.9118e-07 - val_loss: 5.7422e-05
Epoch 116/512
512/512 - 0s - loss: 7.7046e-07 - val_loss: 5.6297e-05
Epoch 117/512
512/512 - 0s - loss: 7.4984e-07 - val_loss: 5.5226e-05
Epoch 118/512
512/512 - 0s - loss: 7.3175e-07 - val_loss: 5.4167e-05
Epoch 119/512
512/512 - 0s - loss: 7.1462e-07 - val_loss: 5.3172e-05
Epoch 120/512
512/512 - 0s - loss: 6.9609e-07 - val_loss: 5.2233e-05
Epoch 121/512
512/512 - 0s - loss: 6.7797e-07 - val_loss: 5.1282e-05
Epoch 122/512
512/512 - 0s - loss: 6.6383e-07 - val_loss: 5.0370e-05
Epoch 123/512
512/512 - 0s - loss: 6.4980e-07 - val_loss: 4.9513e-05
Epoch 124/512
512/512 - 0s - loss: 6.3466e-07 - val_loss: 4.8674e-05
Epoch 125/512
512/512 - 0s - loss: 6.1966e-07 - val_loss: 4.7865e-05
Epoch 126/512
512/512 - 0s - loss: 6.0711e-07 - val_loss: 4.7062e-05
Epoch 127/512
512/512 - 0s - loss: 5.9660e-07 - val_loss: 4.6297e-05
Epoch 128/512
512/512 - 0s - loss: 5.8427e-07 - val_loss: 4.5584e-05
Epoch 129/512
512/512 - 0s - loss: 5.7052e-07 - val_loss: 4.4884e-05
Epoch 130/512
512/512 - 0s - loss: 5.5999e-07 - val_loss: 4.4170e-05
Epoch 131/512
512/512 - 0s - loss: 5.5077e-07 - val_loss: 4.3499e-05
Epoch 132/512
512/512 - 0s - loss: 5.4092e-07 - val_loss: 4.2864e-05
Epoch 133/512
512/512 - 0s - loss: 5.2946e-07 - val_loss: 4.2247e-05
Epoch 134/512
512/512 - 0s - loss: 5.2005e-07 - val_loss: 4.1624e-05
Epoch 135/512
512/512 - 0s - loss: 5.1261e-07 - val_loss: 4.1023e-05
Epoch 136/512
512/512 - 0s - loss: 5.0387e-07 - val_loss: 4.0466e-05
Epoch 137/512
512/512 - 0s - loss: 4.9434e-07 - val_loss: 3.9916e-05
Epoch 138/512
512/512 - 0s - loss: 4.8584e-07 - val_loss: 3.9376e-05
Epoch 139/512
512/512 - 0s - loss: 4.7826e-07 - val_loss: 3.8838e-05
Epoch 140/512
512/512 - 0s - loss: 4.7138e-07 - val_loss: 3.8326e-05
Epoch 141/512
512/512 - 0s - loss: 4.6413e-07 - val_loss: 3.7840e-05
Epoch 142/512
512/512 - 0s - loss: 4.5636e-07 - val_loss: 3.7363e-05
Epoch 143/512
512/512 - 0s - loss: 4.4899e-07 - val_loss: 3.6890e-05
Epoch 144/512
512/512 - 0s - loss: 4.4335e-07 - val_loss: 3.6415e-05
Epoch 145/512
512/512 - 0s - loss: 4.3768e-07 - val_loss: 3.5976e-05
Epoch 146/512
512/512 - 0s - loss: 4.3081e-07 - val_loss: 3.5556e-05
Epoch 147/512
512/512 - 0s - loss: 4.2402e-07 - val_loss: 3.5139e-05
Epoch 148/512
512/512 - 0s - loss: 4.1820e-07 - val_loss: 3.4714e-05
Epoch 149/512
512/512 - 0s - loss: 4.1302e-07 - val_loss: 3.4308e-05
Epoch 150/512
512/512 - 0s - loss: 4.0789e-07 - val_loss: 3.3918e-05
Epoch 151/512
512/512 - 0s - loss: 4.0223e-07 - val_loss: 3.3554e-05
Epoch 152/512
512/512 - 0s - loss: 3.9639e-07 - val_loss: 3.3177e-05
Epoch 153/512
512/512 - 0s - loss: 3.9201e-07 - val_loss: 3.2800e-05
Epoch 154/512
512/512 - 0s - loss: 3.8756e-07 - val_loss: 3.2447e-05
Epoch 155/512
512/512 - 0s - loss: 3.8254e-07 - val_loss: 3.2108e-05
Epoch 156/512
512/512 - 0s - loss: 3.7725e-07 - val_loss: 3.1786e-05
Epoch 157/512
512/512 - 0s - loss: 3.7251e-07 - val_loss: 3.1443e-05
Epoch 158/512
512/512 - 0s - loss: 3.6880e-07 - val_loss: 3.1103e-05
Epoch 159/512
512/512 - 0s - loss: 3.6489e-07 - val_loss: 3.0795e-05
Epoch 160/512
512/512 - 0s - loss: 3.6052e-07 - val_loss: 3.0492e-05
Epoch 161/512
512/512 - 0s - loss: 3.5603e-07 - val_loss: 3.0200e-05
Epoch 162/512
512/512 - 0s - loss: 3.5174e-07 - val_loss: 2.9895e-05
Epoch 163/512
512/512 - 0s - loss: 3.4873e-07 - val_loss: 2.9588e-05
Epoch 164/512
512/512 - 0s - loss: 3.4516e-07 - val_loss: 2.9321e-05
Epoch 165/512
512/512 - 0s - loss: 3.4074e-07 - val_loss: 2.9054e-05
Epoch 166/512
512/512 - 0s - loss: 3.3698e-07 - val_loss: 2.8777e-05
Epoch 167/512
512/512 - 0s - loss: 3.3373e-07 - val_loss: 2.8501e-05
Epoch 168/512
512/512 - 0s - loss: 3.3082e-07 - val_loss: 2.8235e-05
Epoch 169/512
512/512 - 0s - loss: 3.2715e-07 - val_loss: 2.7997e-05
Epoch 170/512
512/512 - 0s - loss: 3.2337e-07 - val_loss: 2.7753e-05
Epoch 171/512
512/512 - 0s - loss: 3.2031e-07 - val_loss: 2.7494e-05
Epoch 172/512
512/512 - 0s - loss: 3.1745e-07 - val_loss: 2.7245e-05
Epoch 173/512
512/512 - 0s - loss: 3.1478e-07 - val_loss: 2.7001e-05
Epoch 174/512
512/512 - 0s - loss: 3.1175e-07 - val_loss: 2.6785e-05
Epoch 175/512
512/512 - 0s - loss: 3.0836e-07 - val_loss: 2.6564e-05
Epoch 176/512
512/512 - 0s - loss: 3.0554e-07 - val_loss: 2.6336e-05
Epoch 177/512
512/512 - 0s - loss: 3.0269e-07 - val_loss: 2.6117e-05
Epoch 178/512
512/512 - 0s - loss: 2.9984e-07 - val_loss: 2.5909e-05
Epoch 179/512
512/512 - 0s - loss: 2.9711e-07 - val_loss: 2.5691e-05
Epoch 180/512
512/512 - 0s - loss: 2.9470e-07 - val_loss: 2.5470e-05
Epoch 181/512
512/512 - 0s - loss: 2.9244e-07 - val_loss: 2.5268e-05
Epoch 182/512
512/512 - 0s - loss: 2.8943e-07 - val_loss: 2.5093e-05
Epoch 183/512
512/512 - 0s - loss: 2.8668e-07 - val_loss: 2.4884e-05
Epoch 184/512
512/512 - 0s - loss: 2.8484e-07 - val_loss: 2.4668e-05
Epoch 185/512
512/512 - 0s - loss: 2.8260e-07 - val_loss: 2.4489e-05
Epoch 186/512
512/512 - 0s - loss: 2.7976e-07 - val_loss: 2.4315e-05
Epoch 187/512
512/512 - 0s - loss: 2.7718e-07 - val_loss: 2.4144e-05
Epoch 188/512
512/512 - 0s - loss: 2.7460e-07 - val_loss: 2.3961e-05
Epoch 189/512
512/512 - 0s - loss: 2.7288e-07 - val_loss: 2.3739e-05
Epoch 190/512
512/512 - 0s - loss: 2.7158e-07 - val_loss: 2.3569e-05
Epoch 191/512
512/512 - 0s - loss: 2.6887e-07 - val_loss: 2.3425e-05
Epoch 192/512
512/512 - 0s - loss: 2.6610e-07 - val_loss: 2.3266e-05
Epoch 193/512
512/512 - 0s - loss: 2.6401e-07 - val_loss: 2.3086e-05
Epoch 194/512
512/512 - 0s - loss: 2.6217e-07 - val_loss: 2.2901e-05
Epoch 195/512
512/512 - 0s - loss: 2.6085e-07 - val_loss: 2.2718e-05
Epoch 196/512
512/512 - 0s - loss: 2.5889e-07 - val_loss: 2.2580e-05
Epoch 197/512
512/512 - 0s - loss: 2.5621e-07 - val_loss: 2.2448e-05
Epoch 198/512
512/512 - 0s - loss: 2.5414e-07 - val_loss: 2.2273e-05
Epoch 199/512
512/512 - 0s - loss: 2.5276e-07 - val_loss: 2.2107e-05
Epoch 200/512
512/512 - 0s - loss: 2.5116e-07 - val_loss: 2.1946e-05
Epoch 201/512
512/512 - 0s - loss: 2.4929e-07 - val_loss: 2.1805e-05
Epoch 202/512
512/512 - 0s - loss: 2.4722e-07 - val_loss: 2.1680e-05
Epoch 203/512
512/512 - 0s - loss: 2.4508e-07 - val_loss: 2.1532e-05
Epoch 204/512
512/512 - 0s - loss: 2.4364e-07 - val_loss: 2.1361e-05
Epoch 205/512
512/512 - 0s - loss: 2.4225e-07 - val_loss: 2.1219e-05
Epoch 206/512
512/512 - 0s - loss: 2.4037e-07 - val_loss: 2.1092e-05
Epoch 207/512
512/512 - 0s - loss: 2.3843e-07 - val_loss: 2.0959e-05
Epoch 208/512
512/512 - 0s - loss: 2.3673e-07 - val_loss: 2.0817e-05
Epoch 209/512
512/512 - 0s - loss: 2.3531e-07 - val_loss: 2.0670e-05
Epoch 210/512
512/512 - 0s - loss: 2.3400e-07 - val_loss: 2.0520e-05
Epoch 211/512
512/512 - 0s - loss: 2.3243e-07 - val_loss: 2.0409e-05
Epoch 212/512
512/512 - 0s - loss: 2.3051e-07 - val_loss: 2.0287e-05
Epoch 213/512
512/512 - 0s - loss: 2.2894e-07 - val_loss: 2.0142e-05
Epoch 214/512
512/512 - 0s - loss: 2.2760e-07 - val_loss: 2.0013e-05
Epoch 215/512
512/512 - 0s - loss: 2.2627e-07 - val_loss: 1.9871e-05
Epoch 216/512
512/512 - 0s - loss: 2.2483e-07 - val_loss: 1.9756e-05
Epoch 217/512
512/512 - 0s - loss: 2.2327e-07 - val_loss: 1.9638e-05
Epoch 218/512
512/512 - 0s - loss: 2.2154e-07 - val_loss: 1.9523e-05
Epoch 219/512
512/512 - 0s - loss: 2.2007e-07 - val_loss: 1.9387e-05
Epoch 220/512
512/512 - 0s - loss: 2.1898e-07 - val_loss: 1.9264e-05
Epoch 221/512
512/512 - 0s - loss: 2.1761e-07 - val_loss: 1.9142e-05
Epoch 222/512
512/512 - 0s - loss: 2.1634e-07 - val_loss: 1.9020e-05
Epoch 223/512
512/512 - 0s - loss: 2.1500e-07 - val_loss: 1.8910e-05
Epoch 224/512
512/512 - 0s - loss: 2.1345e-07 - val_loss: 1.8806e-05
Epoch 225/512
512/512 - 0s - loss: 2.1211e-07 - val_loss: 1.8687e-05
Epoch 226/512
512/512 - 0s - loss: 2.1081e-07 - val_loss: 1.8579e-05
Epoch 227/512
512/512 - 0s - loss: 2.0963e-07 - val_loss: 1.8442e-05
Epoch 228/512
512/512 - 0s - loss: 2.0878e-07 - val_loss: 1.8339e-05
Epoch 229/512
512/512 - 0s - loss: 2.0720e-07 - val_loss: 1.8261e-05
Epoch 230/512
512/512 - 0s - loss: 2.0579e-07 - val_loss: 1.8146e-05
Epoch 231/512
512/512 - 0s - loss: 2.0461e-07 - val_loss: 1.8034e-05
Epoch 232/512
512/512 - 0s - loss: 2.0374e-07 - val_loss: 1.7929e-05
Epoch 233/512
512/512 - 0s - loss: 2.0264e-07 - val_loss: 1.7849e-05
Epoch 234/512
512/512 - 0s - loss: 2.0102e-07 - val_loss: 1.7787e-05
Epoch 235/512
512/512 - 0s - loss: 1.9961e-07 - val_loss: 1.7694e-05
Epoch 236/512
512/512 - 0s - loss: 1.9892e-07 - val_loss: 1.7554e-05
Epoch 237/512
512/512 - 0s - loss: 1.9865e-07 - val_loss: 1.7436e-05
Epoch 238/512
512/512 - 0s - loss: 1.9771e-07 - val_loss: 1.7394e-05
Epoch 239/512
512/512 - 0s - loss: 1.9581e-07 - val_loss: 1.7353e-05
Epoch 240/512
512/512 - 0s - loss: 1.9446e-07 - val_loss: 1.7269e-05
Epoch 241/512
512/512 - 0s - loss: 1.9340e-07 - val_loss: 1.7205e-05
Epoch 242/512
512/512 - 0s - loss: 1.9264e-07 - val_loss: 1.7063e-05
Epoch 243/512
512/512 - 0s - loss: 1.9244e-07 - val_loss: 1.6953e-05
Epoch 244/512
512/512 - 0s - loss: 1.9152e-07 - val_loss: 1.6916e-05
Epoch 245/512
512/512 - 0s - loss: 1.8986e-07 - val_loss: 1.6880e-05
Epoch 246/512
512/512 - 0s - loss: 1.8873e-07 - val_loss: 1.6792e-05
Epoch 247/512
512/512 - 0s - loss: 1.8822e-07 - val_loss: 1.6676e-05
Epoch 248/512
512/512 - 0s - loss: 1.8762e-07 - val_loss: 1.6605e-05
Epoch 249/512
512/512 - 0s - loss: 1.8644e-07 - val_loss: 1.6576e-05
Epoch 250/512
512/512 - 0s - loss: 1.8508e-07 - val_loss: 1.6524e-05
Epoch 251/512
512/512 - 0s - loss: 1.8415e-07 - val_loss: 1.6444e-05
Epoch 252/512
512/512 - 0s - loss: 1.8331e-07 - val_loss: 1.6377e-05
Epoch 253/512
512/512 - 0s - loss: 1.8261e-07 - val_loss: 1.6270e-05
Epoch 254/512
512/512 - 0s - loss: 1.8188e-07 - val_loss: 1.6218e-05
Epoch 255/512
512/512 - 0s - loss: 1.8084e-07 - val_loss: 1.6154e-05
Epoch 256/512
512/512 - 0s - loss: 1.8018e-07 - val_loss: 1.6068e-05
Epoch 257/512
512/512 - 0s - loss: 1.7966e-07 - val_loss: 1.5997e-05
Epoch 258/512
512/512 - 0s - loss: 1.7857e-07 - val_loss: 1.5968e-05
Epoch 259/512
512/512 - 0s - loss: 1.7745e-07 - val_loss: 1.5918e-05
Epoch 260/512
512/512 - 0s - loss: 1.7651e-07 - val_loss: 1.5858e-05
Epoch 261/512
512/512 - 0s - loss: 1.7574e-07 - val_loss: 1.5781e-05
Epoch 262/512
512/512 - 0s - loss: 1.7554e-07 - val_loss: 1.5638e-05
Epoch 263/512
512/512 - 0s - loss: 1.7519e-07 - val_loss: 1.5624e-05
Epoch 264/512
512/512 - 0s - loss: 1.7373e-07 - val_loss: 1.5586e-05
Epoch 265/512
512/512 - 0s - loss: 1.7282e-07 - val_loss: 1.5542e-05
Epoch 266/512
512/512 - 0s - loss: 1.7196e-07 - val_loss: 1.5476e-05
Epoch 267/512
512/512 - 0s - loss: 1.7133e-07 - val_loss: 1.5393e-05
Epoch 268/512
512/512 - 0s - loss: 1.7075e-07 - val_loss: 1.5325e-05
Epoch 269/512
512/512 - 0s - loss: 1.7011e-07 - val_loss: 1.5268e-05
Epoch 270/512
512/512 - 0s - loss: 1.6938e-07 - val_loss: 1.5205e-05
Epoch 271/512
512/512 - 0s - loss: 1.6866e-07 - val_loss: 1.5153e-05
Epoch 272/512
512/512 - 0s - loss: 1.6781e-07 - val_loss: 1.5102e-05
Epoch 273/512
512/512 - 0s - loss: 1.6723e-07 - val_loss: 1.5032e-05
Epoch 274/512
512/512 - 0s - loss: 1.6667e-07 - val_loss: 1.4964e-05
Epoch 275/512
512/512 - 0s - loss: 1.6602e-07 - val_loss: 1.4926e-05
Epoch 276/512
512/512 - 0s - loss: 1.6516e-07 - val_loss: 1.4881e-05
Epoch 277/512
512/512 - 0s - loss: 1.6429e-07 - val_loss: 1.4848e-05
Epoch 278/512
512/512 - 0s - loss: 1.6363e-07 - val_loss: 1.4772e-05
Epoch 279/512
512/512 - 0s - loss: 1.6319e-07 - val_loss: 1.4694e-05
Epoch 280/512
512/512 - 0s - loss: 1.6255e-07 - val_loss: 1.4653e-05
Epoch 281/512
512/512 - 0s - loss: 1.6188e-07 - val_loss: 1.4591e-05
Epoch 282/512
512/512 - 0s - loss: 1.6130e-07 - val_loss: 1.4537e-05
Epoch 283/512
512/512 - 0s - loss: 1.6062e-07 - val_loss: 1.4505e-05
Epoch 284/512
512/512 - 0s - loss: 1.5980e-07 - val_loss: 1.4468e-05
Epoch 285/512
512/512 - 0s - loss: 1.5913e-07 - val_loss: 1.4413e-05
Epoch 286/512
512/512 - 0s - loss: 1.5852e-07 - val_loss: 1.4363e-05
Epoch 287/512
512/512 - 0s - loss: 1.5807e-07 - val_loss: 1.4258e-05
Epoch 288/512
512/512 - 0s - loss: 1.5771e-07 - val_loss: 1.4221e-05
Epoch 289/512
512/512 - 0s - loss: 1.5695e-07 - val_loss: 1.4200e-05
Epoch 290/512
512/512 - 0s - loss: 1.5626e-07 - val_loss: 1.4139e-05
Epoch 291/512
512/512 - 0s - loss: 1.5569e-07 - val_loss: 1.4099e-05
Epoch 292/512
512/512 - 0s - loss: 1.5505e-07 - val_loss: 1.4050e-05
Epoch 293/512
512/512 - 0s - loss: 1.5454e-07 - val_loss: 1.3983e-05
Epoch 294/512
512/512 - 0s - loss: 1.5405e-07 - val_loss: 1.3944e-05
Epoch 295/512
512/512 - 0s - loss: 1.5345e-07 - val_loss: 1.3885e-05
Epoch 296/512
512/512 - 0s - loss: 1.5298e-07 - val_loss: 1.3851e-05
Epoch 297/512
512/512 - 0s - loss: 1.5225e-07 - val_loss: 1.3829e-05
Epoch 298/512
512/512 - 0s - loss: 1.5163e-07 - val_loss: 1.3773e-05
Epoch 299/512
512/512 - 0s - loss: 1.5114e-07 - val_loss: 1.3708e-05
Epoch 300/512
512/512 - 0s - loss: 1.5071e-07 - val_loss: 1.3658e-05
Epoch 301/512
512/512 - 0s - loss: 1.5016e-07 - val_loss: 1.3616e-05
Epoch 302/512
512/512 - 0s - loss: 1.4954e-07 - val_loss: 1.3572e-05
Epoch 303/512
512/512 - 0s - loss: 1.4906e-07 - val_loss: 1.3524e-05
Epoch 304/512
512/512 - 0s - loss: 1.4855e-07 - val_loss: 1.3487e-05
Epoch 305/512
512/512 - 0s - loss: 1.4805e-07 - val_loss: 1.3440e-05
Epoch 306/512
512/512 - 0s - loss: 1.4756e-07 - val_loss: 1.3389e-05
Epoch 307/512
512/512 - 0s - loss: 1.4697e-07 - val_loss: 1.3364e-05
Epoch 308/512
512/512 - 0s - loss: 1.4643e-07 - val_loss: 1.3309e-05
Epoch 309/512
512/512 - 0s - loss: 1.4613e-07 - val_loss: 1.3248e-05
Epoch 310/512
512/512 - 0s - loss: 1.4547e-07 - val_loss: 1.3243e-05
Epoch 311/512
512/512 - 0s - loss: 1.4488e-07 - val_loss: 1.3205e-05
Epoch 312/512
512/512 - 0s - loss: 1.4440e-07 - val_loss: 1.3146e-05
Epoch 313/512
512/512 - 0s - loss: 1.4395e-07 - val_loss: 1.3102e-05
Epoch 314/512
512/512 - 0s - loss: 1.4348e-07 - val_loss: 1.3065e-05
Epoch 315/512
512/512 - 0s - loss: 1.4304e-07 - val_loss: 1.3015e-05
Epoch 316/512
512/512 - 0s - loss: 1.4259e-07 - val_loss: 1.2978e-05
Epoch 317/512
512/512 - 0s - loss: 1.4206e-07 - val_loss: 1.2941e-05
Epoch 318/512
512/512 - 0s - loss: 1.4153e-07 - val_loss: 1.2907e-05
Epoch 319/512
512/512 - 0s - loss: 1.4114e-07 - val_loss: 1.2861e-05
Epoch 320/512
512/512 - 0s - loss: 1.4063e-07 - val_loss: 1.2820e-05
Epoch 321/512
512/512 - 0s - loss: 1.4030e-07 - val_loss: 1.2767e-05
Epoch 322/512
512/512 - 0s - loss: 1.3995e-07 - val_loss: 1.2728e-05
Epoch 323/512
512/512 - 0s - loss: 1.3939e-07 - val_loss: 1.2704e-05
Epoch 324/512
512/512 - 0s - loss: 1.3883e-07 - val_loss: 1.2688e-05
Epoch 325/512
512/512 - 0s - loss: 1.3831e-07 - val_loss: 1.2645e-05
Epoch 326/512
512/512 - 0s - loss: 1.3795e-07 - val_loss: 1.2586e-05
Epoch 327/512
512/512 - 0s - loss: 1.3768e-07 - val_loss: 1.2533e-05
Epoch 328/512
512/512 - 0s - loss: 1.3718e-07 - val_loss: 1.2514e-05
Epoch 329/512
512/512 - 0s - loss: 1.3670e-07 - val_loss: 1.2475e-05
Epoch 330/512
512/512 - 0s - loss: 1.3636e-07 - val_loss: 1.2433e-05
Epoch 331/512
512/512 - 0s - loss: 1.3587e-07 - val_loss: 1.2403e-05
Epoch 332/512
512/512 - 0s - loss: 1.3547e-07 - val_loss: 1.2361e-05
Epoch 333/512
512/512 - 0s - loss: 1.3509e-07 - val_loss: 1.2318e-05
Epoch 334/512
512/512 - 0s - loss: 1.3464e-07 - val_loss: 1.2300e-05
Epoch 335/512
512/512 - 0s - loss: 1.3419e-07 - val_loss: 1.2255e-05
Epoch 336/512
512/512 - 0s - loss: 1.3380e-07 - val_loss: 1.2235e-05
Epoch 337/512
512/512 - 0s - loss: 1.3341e-07 - val_loss: 1.2178e-05
Epoch 338/512
512/512 - 0s - loss: 1.3309e-07 - val_loss: 1.2146e-05
Epoch 339/512
512/512 - 0s - loss: 1.3260e-07 - val_loss: 1.2129e-05
Epoch 340/512
512/512 - 0s - loss: 1.3212e-07 - val_loss: 1.2101e-05
Epoch 341/512
512/512 - 0s - loss: 1.3170e-07 - val_loss: 1.2062e-05
Epoch 342/512
512/512 - 0s - loss: 1.3134e-07 - val_loss: 1.2035e-05
Epoch 343/512
512/512 - 0s - loss: 1.3094e-07 - val_loss: 1.1987e-05
Epoch 344/512
512/512 - 0s - loss: 1.3061e-07 - val_loss: 1.1950e-05
Epoch 345/512
512/512 - 0s - loss: 1.3025e-07 - val_loss: 1.1919e-05
Epoch 346/512
512/512 - 0s - loss: 1.2996e-07 - val_loss: 1.1864e-05
Epoch 347/512
512/512 - 0s - loss: 1.2961e-07 - val_loss: 1.1846e-05
Epoch 348/512
512/512 - 0s - loss: 1.2908e-07 - val_loss: 1.1837e-05
Epoch 349/512
512/512 - 0s - loss: 1.2869e-07 - val_loss: 1.1792e-05
Epoch 350/512
512/512 - 0s - loss: 1.2833e-07 - val_loss: 1.1769e-05
Epoch 351/512
512/512 - 0s - loss: 1.2796e-07 - val_loss: 1.1729e-05
Epoch 352/512
512/512 - 0s - loss: 1.2755e-07 - val_loss: 1.1718e-05
Epoch 353/512
512/512 - 0s - loss: 1.2717e-07 - val_loss: 1.1685e-05
Epoch 354/512
512/512 - 0s - loss: 1.2689e-07 - val_loss: 1.1612e-05
Epoch 355/512
512/512 - 0s - loss: 1.2669e-07 - val_loss: 1.1580e-05
Epoch 356/512
512/512 - 0s - loss: 1.2635e-07 - val_loss: 1.1558e-05
Epoch 357/512
512/512 - 0s - loss: 1.2586e-07 - val_loss: 1.1541e-05
Epoch 358/512
512/512 - 0s - loss: 1.2547e-07 - val_loss: 1.1516e-05
Epoch 359/512
512/512 - 0s - loss: 1.2512e-07 - val_loss: 1.1483e-05
Epoch 360/512
512/512 - 0s - loss: 1.2478e-07 - val_loss: 1.1450e-05
Epoch 361/512
512/512 - 0s - loss: 1.2444e-07 - val_loss: 1.1429e-05
Epoch 362/512
512/512 - 0s - loss: 1.2406e-07 - val_loss: 1.1405e-05
Epoch 363/512
512/512 - 0s - loss: 1.2373e-07 - val_loss: 1.1367e-05
Epoch 364/512
512/512 - 0s - loss: 1.2340e-07 - val_loss: 1.1337e-05
Epoch 365/512
512/512 - 0s - loss: 1.2309e-07 - val_loss: 1.1301e-05
Epoch 366/512
512/512 - 0s - loss: 1.2286e-07 - val_loss: 1.1252e-05
Epoch 367/512
512/512 - 0s - loss: 1.2252e-07 - val_loss: 1.1238e-05
Epoch 368/512
512/512 - 0s - loss: 1.2211e-07 - val_loss: 1.1225e-05
Epoch 369/512
512/512 - 0s - loss: 1.2174e-07 - val_loss: 1.1191e-05
Epoch 370/512
512/512 - 0s - loss: 1.2142e-07 - val_loss: 1.1168e-05
Epoch 371/512
512/512 - 0s - loss: 1.2114e-07 - val_loss: 1.1121e-05
Epoch 372/512
512/512 - 0s - loss: 1.2088e-07 - val_loss: 1.1092e-05
Epoch 373/512
512/512 - 0s - loss: 1.2059e-07 - val_loss: 1.1061e-05
Epoch 374/512
512/512 - 0s - loss: 1.2029e-07 - val_loss: 1.1029e-05
Epoch 375/512
512/512 - 0s - loss: 1.1995e-07 - val_loss: 1.1019e-05
Epoch 376/512
512/512 - 0s - loss: 1.1959e-07 - val_loss: 1.0984e-05
Epoch 377/512
512/512 - 0s - loss: 1.1931e-07 - val_loss: 1.0960e-05
Epoch 378/512
512/512 - 0s - loss: 1.1899e-07 - val_loss: 1.0930e-05
Epoch 379/512
512/512 - 0s - loss: 1.1866e-07 - val_loss: 1.0912e-05
Epoch 380/512
512/512 - 0s - loss: 1.1838e-07 - val_loss: 1.0877e-05
Epoch 381/512
512/512 - 0s - loss: 1.1809e-07 - val_loss: 1.0857e-05
Epoch 382/512
512/512 - 0s - loss: 1.1776e-07 - val_loss: 1.0825e-05
Epoch 383/512
512/512 - 0s - loss: 1.1744e-07 - val_loss: 1.0813e-05
Epoch 384/512
512/512 - 0s - loss: 1.1711e-07 - val_loss: 1.0786e-05
Epoch 385/512
512/512 - 0s - loss: 1.1685e-07 - val_loss: 1.0757e-05
Epoch 386/512
512/512 - 0s - loss: 1.1659e-07 - val_loss: 1.0713e-05
Epoch 387/512
512/512 - 0s - loss: 1.1640e-07 - val_loss: 1.0686e-05
Epoch 388/512
512/512 - 0s - loss: 1.1609e-07 - val_loss: 1.0672e-05
Epoch 389/512
512/512 - 0s - loss: 1.1570e-07 - val_loss: 1.0650e-05
Epoch 390/512
512/512 - 0s - loss: 1.1539e-07 - val_loss: 1.0639e-05
Epoch 391/512
512/512 - 0s - loss: 1.1510e-07 - val_loss: 1.0608e-05
Epoch 392/512
512/512 - 0s - loss: 1.1480e-07 - val_loss: 1.0585e-05
Epoch 393/512
512/512 - 0s - loss: 1.1452e-07 - val_loss: 1.0578e-05
Epoch 394/512
512/512 - 0s - loss: 1.1425e-07 - val_loss: 1.0569e-05
Epoch 395/512
512/512 - 0s - loss: 1.1408e-07 - val_loss: 1.0566e-05
Epoch 396/512
512/512 - 0s - loss: 1.1382e-07 - val_loss: 1.0532e-05
Epoch 397/512
512/512 - 0s - loss: 1.1353e-07 - val_loss: 1.0502e-05
Epoch 398/512
512/512 - 0s - loss: 1.1318e-07 - val_loss: 1.0468e-05
Epoch 399/512
512/512 - 0s - loss: 1.1293e-07 - val_loss: 1.0447e-05
Epoch 400/512
512/512 - 0s - loss: 1.1267e-07 - val_loss: 1.0429e-05
Epoch 401/512
512/512 - 0s - loss: 1.1237e-07 - val_loss: 1.0394e-05
Epoch 402/512
512/512 - 0s - loss: 1.1210e-07 - val_loss: 1.0368e-05
Epoch 403/512
512/512 - 0s - loss: 1.1182e-07 - val_loss: 1.0344e-05
Epoch 404/512
512/512 - 0s - loss: 1.1155e-07 - val_loss: 1.0314e-05
Epoch 405/512
512/512 - 0s - loss: 1.1128e-07 - val_loss: 1.0283e-05
Epoch 406/512
512/512 - 0s - loss: 1.1102e-07 - val_loss: 1.0262e-05
Epoch 407/512
512/512 - 0s - loss: 1.1077e-07 - val_loss: 1.0241e-05
Epoch 408/512
512/512 - 0s - loss: 1.1052e-07 - val_loss: 1.0230e-05
Epoch 409/512
512/512 - 0s - loss: 1.1029e-07 - val_loss: 1.0216e-05
Epoch 410/512
512/512 - 0s - loss: 1.1008e-07 - val_loss: 1.0201e-05
Epoch 411/512
512/512 - 0s - loss: 1.0991e-07 - val_loss: 1.0188e-05
Epoch 412/512
512/512 - 0s - loss: 1.0972e-07 - val_loss: 1.0164e-05
Epoch 413/512
512/512 - 0s - loss: 1.0932e-07 - val_loss: 1.0117e-05
Epoch 414/512
512/512 - 0s - loss: 1.0901e-07 - val_loss: 1.0081e-05
Epoch 415/512
512/512 - 0s - loss: 1.0876e-07 - val_loss: 1.0062e-05
Epoch 416/512
512/512 - 0s - loss: 1.0851e-07 - val_loss: 1.0027e-05
Epoch 417/512
512/512 - 0s - loss: 1.0828e-07 - val_loss: 9.9911e-06
Epoch 418/512
512/512 - 0s - loss: 1.0809e-07 - val_loss: 9.9708e-06
Epoch 419/512
512/512 - 0s - loss: 1.0782e-07 - val_loss: 9.9517e-06
Epoch 420/512
512/512 - 0s - loss: 1.0759e-07 - val_loss: 9.9250e-06
Epoch 421/512
512/512 - 0s - loss: 1.0735e-07 - val_loss: 9.9054e-06
Epoch 422/512
512/512 - 0s - loss: 1.0716e-07 - val_loss: 9.8701e-06
Epoch 423/512
512/512 - 0s - loss: 1.0696e-07 - val_loss: 9.8494e-06
Epoch 424/512
512/512 - 0s - loss: 1.0674e-07 - val_loss: 9.8296e-06
Epoch 425/512
512/512 - 0s - loss: 1.0646e-07 - val_loss: 9.8189e-06
Epoch 426/512
512/512 - 0s - loss: 1.0617e-07 - val_loss: 9.8085e-06
Epoch 427/512
512/512 - 0s - loss: 1.0590e-07 - val_loss: 9.7996e-06
Epoch 428/512
512/512 - 0s - loss: 1.0567e-07 - val_loss: 9.7735e-06
Epoch 429/512
512/512 - 0s - loss: 1.0544e-07 - val_loss: 9.7490e-06
Epoch 430/512
512/512 - 0s - loss: 1.0523e-07 - val_loss: 9.7188e-06
Epoch 431/512
512/512 - 0s - loss: 1.0505e-07 - val_loss: 9.6804e-06
Epoch 432/512
512/512 - 0s - loss: 1.0491e-07 - val_loss: 9.6626e-06
Epoch 433/512
512/512 - 0s - loss: 1.0466e-07 - val_loss: 9.6496e-06
Epoch 434/512
512/512 - 0s - loss: 1.0442e-07 - val_loss: 9.6296e-06
Epoch 435/512
512/512 - 0s - loss: 1.0418e-07 - val_loss: 9.6164e-06
Epoch 436/512
512/512 - 0s - loss: 1.0392e-07 - val_loss: 9.5961e-06
Epoch 437/512
512/512 - 0s - loss: 1.0370e-07 - val_loss: 9.5805e-06
Epoch 438/512
512/512 - 0s - loss: 1.0348e-07 - val_loss: 9.5495e-06
Epoch 439/512
512/512 - 0s - loss: 1.0330e-07 - val_loss: 9.5362e-06
Epoch 440/512
512/512 - 0s - loss: 1.0307e-07 - val_loss: 9.5174e-06
Epoch 441/512
512/512 - 0s - loss: 1.0288e-07 - val_loss: 9.4907e-06
Epoch 442/512
512/512 - 0s - loss: 1.0270e-07 - val_loss: 9.4746e-06
Epoch 443/512
512/512 - 0s - loss: 1.0247e-07 - val_loss: 9.4505e-06
Epoch 444/512
512/512 - 0s - loss: 1.0225e-07 - val_loss: 9.4477e-06
Epoch 445/512
512/512 - 0s - loss: 1.0199e-07 - val_loss: 9.4276e-06
Epoch 446/512
512/512 - 0s - loss: 1.0175e-07 - val_loss: 9.4136e-06
Epoch 447/512
512/512 - 0s - loss: 1.0155e-07 - val_loss: 9.3867e-06
Epoch 448/512
512/512 - 0s - loss: 1.0136e-07 - val_loss: 9.3673e-06
Epoch 449/512
512/512 - 0s - loss: 1.0113e-07 - val_loss: 9.3579e-06
Epoch 450/512
512/512 - 0s - loss: 1.0091e-07 - val_loss: 9.3508e-06
Epoch 451/512
512/512 - 0s - loss: 1.0072e-07 - val_loss: 9.3506e-06
Epoch 452/512
512/512 - 0s - loss: 1.0053e-07 - val_loss: 9.3315e-06
Epoch 453/512
512/512 - 0s - loss: 1.0037e-07 - val_loss: 9.3217e-06
Epoch 454/512
512/512 - 0s - loss: 1.0021e-07 - val_loss: 9.3028e-06
Epoch 455/512
512/512 - 0s - loss: 9.9951e-08 - val_loss: 9.2709e-06
Epoch 456/512
512/512 - 0s - loss: 9.9711e-08 - val_loss: 9.2462e-06
Epoch 457/512
512/512 - 0s - loss: 9.9500e-08 - val_loss: 9.2186e-06
Epoch 458/512
512/512 - 0s - loss: 9.9303e-08 - val_loss: 9.2013e-06
Epoch 459/512
512/512 - 0s - loss: 9.9107e-08 - val_loss: 9.1880e-06
Epoch 460/512
512/512 - 0s - loss: 9.8928e-08 - val_loss: 9.1847e-06
Epoch 461/512
512/512 - 0s - loss: 9.8736e-08 - val_loss: 9.1587e-06
Epoch 462/512
512/512 - 0s - loss: 9.8552e-08 - val_loss: 9.1472e-06
Epoch 463/512
512/512 - 0s - loss: 9.8374e-08 - val_loss: 9.1421e-06
Epoch 464/512
512/512 - 0s - loss: 9.8210e-08 - val_loss: 9.1129e-06
Epoch 465/512
512/512 - 0s - loss: 9.8036e-08 - val_loss: 9.1127e-06
Epoch 466/512
512/512 - 0s - loss: 9.7908e-08 - val_loss: 9.0915e-06
Epoch 467/512
512/512 - 0s - loss: 9.7647e-08 - val_loss: 9.0566e-06
Epoch 468/512
512/512 - 0s - loss: 9.7413e-08 - val_loss: 9.0476e-06
Epoch 469/512
512/512 - 0s - loss: 9.7251e-08 - val_loss: 9.0310e-06
Epoch 470/512
512/512 - 0s - loss: 9.7055e-08 - val_loss: 9.0147e-06
Epoch 471/512
512/512 - 0s - loss: 9.6911e-08 - val_loss: 9.0013e-06
Epoch 472/512
512/512 - 0s - loss: 9.6716e-08 - val_loss: 8.9820e-06
Epoch 473/512
512/512 - 0s - loss: 9.6531e-08 - val_loss: 8.9678e-06
Epoch 474/512
512/512 - 0s - loss: 9.6322e-08 - val_loss: 8.9404e-06
Epoch 475/512
512/512 - 0s - loss: 9.6116e-08 - val_loss: 8.9243e-06
Epoch 476/512
512/512 - 0s - loss: 9.5933e-08 - val_loss: 8.9083e-06
Epoch 477/512
512/512 - 0s - loss: 9.5754e-08 - val_loss: 8.8912e-06
Epoch 478/512
512/512 - 0s - loss: 9.5587e-08 - val_loss: 8.8778e-06
Epoch 479/512
512/512 - 0s - loss: 9.5403e-08 - val_loss: 8.8565e-06
Epoch 480/512
512/512 - 0s - loss: 9.5210e-08 - val_loss: 8.8404e-06
Epoch 481/512
512/512 - 0s - loss: 9.5027e-08 - val_loss: 8.8221e-06
Epoch 482/512
512/512 - 0s - loss: 9.4845e-08 - val_loss: 8.7958e-06
Epoch 483/512
512/512 - 0s - loss: 9.4670e-08 - val_loss: 8.7822e-06
Epoch 484/512
512/512 - 0s - loss: 9.4505e-08 - val_loss: 8.7798e-06
Epoch 485/512
512/512 - 0s - loss: 9.4337e-08 - val_loss: 8.7629e-06
Epoch 486/512
512/512 - 0s - loss: 9.4196e-08 - val_loss: 8.7575e-06
Epoch 487/512
512/512 - 0s - loss: 9.4087e-08 - val_loss: 8.7490e-06
Epoch 488/512
512/512 - 0s - loss: 9.3987e-08 - val_loss: 8.7355e-06
Epoch 489/512
512/512 - 0s - loss: 9.3774e-08 - val_loss: 8.7090e-06
Epoch 490/512
512/512 - 0s - loss: 9.3538e-08 - val_loss: 8.6919e-06
Epoch 491/512
512/512 - 0s - loss: 9.3372e-08 - val_loss: 8.6751e-06
Epoch 492/512
512/512 - 0s - loss: 9.3153e-08 - val_loss: 8.6533e-06
Epoch 493/512
512/512 - 0s - loss: 9.3012e-08 - val_loss: 8.6469e-06
Epoch 494/512
512/512 - 0s - loss: 9.2878e-08 - val_loss: 8.6335e-06
Epoch 495/512
512/512 - 0s - loss: 9.2666e-08 - val_loss: 8.6023e-06
Epoch 496/512
512/512 - 0s - loss: 9.2477e-08 - val_loss: 8.5891e-06
Epoch 497/512
512/512 - 0s - loss: 9.2325e-08 - val_loss: 8.5812e-06
Epoch 498/512
512/512 - 0s - loss: 9.2171e-08 - val_loss: 8.5642e-06
Epoch 499/512
512/512 - 0s - loss: 9.2042e-08 - val_loss: 8.5549e-06
Epoch 500/512
512/512 - 0s - loss: 9.1902e-08 - val_loss: 8.5451e-06
Epoch 501/512
512/512 - 0s - loss: 9.1739e-08 - val_loss: 8.5260e-06
Epoch 502/512
512/512 - 0s - loss: 9.1522e-08 - val_loss: 8.5037e-06
Epoch 503/512
512/512 - 0s - loss: 9.1356e-08 - val_loss: 8.4817e-06
Epoch 504/512
512/512 - 0s - loss: 9.1173e-08 - val_loss: 8.4636e-06
Epoch 505/512
512/512 - 0s - loss: 9.1018e-08 - val_loss: 8.4548e-06
Epoch 506/512
512/512 - 0s - loss: 9.0859e-08 - val_loss: 8.4408e-06
Epoch 507/512
512/512 - 0s - loss: 9.0706e-08 - val_loss: 8.4244e-06
Epoch 508/512
512/512 - 0s - loss: 9.0551e-08 - val_loss: 8.4164e-06
Epoch 509/512
512/512 - 0s - loss: 9.0412e-08 - val_loss: 8.4037e-06
Epoch 510/512
512/512 - 0s - loss: 9.0268e-08 - val_loss: 8.3922e-06
Epoch 511/512
512/512 - 0s - loss: 9.0108e-08 - val_loss: 8.3792e-06
Epoch 512/512
512/512 - 0s - loss: 8.9989e-08 - val_loss: 8.3742e-06
Train on 512 samples, validate on 512 samples
Epoch 1/512

Epoch 00001: val_loss improved from inf to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.1177e-09 - val_loss: 6.9609e-09
Epoch 2/512

Epoch 00002: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.2628e-09 - val_loss: 1.1854e-09
Epoch 3/512

Epoch 00003: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.7895e-10 - val_loss: 2.6362e-10
Epoch 4/512

Epoch 00004: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.0654e-10 - val_loss: 1.5711e-10
Epoch 5/512

Epoch 00005: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5734e-10 - val_loss: 1.8364e-10
Epoch 6/512

Epoch 00006: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4113e-10 - val_loss: 4.1184e-10
Epoch 7/512

Epoch 00007: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5879e-10 - val_loss: 1.2449e-09
Epoch 8/512

Epoch 00008: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5471e-09 - val_loss: 1.7934e-09
Epoch 9/512

Epoch 00009: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5002e-09 - val_loss: 1.0352e-09
Epoch 10/512

Epoch 00010: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.0577e-10 - val_loss: 5.5826e-10
Epoch 11/512

Epoch 00011: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8811e-10 - val_loss: 4.3496e-10
Epoch 12/512

Epoch 00012: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4118e-10 - val_loss: 4.9236e-10
Epoch 13/512

Epoch 00013: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4667e-10 - val_loss: 6.7710e-10
Epoch 14/512

Epoch 00014: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.4287e-10 - val_loss: 8.5116e-10
Epoch 15/512

Epoch 00015: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.4521e-10 - val_loss: 8.2515e-10
Epoch 16/512

Epoch 00016: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.5824e-10 - val_loss: 6.7073e-10
Epoch 17/512

Epoch 00017: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.1169e-10 - val_loss: 5.5145e-10
Epoch 18/512

Epoch 00018: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2244e-10 - val_loss: 5.0588e-10
Epoch 19/512

Epoch 00019: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0028e-10 - val_loss: 5.1652e-10
Epoch 20/512

Epoch 00020: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2530e-10 - val_loss: 5.5738e-10
Epoch 21/512

Epoch 00021: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.6042e-10 - val_loss: 5.7822e-10
Epoch 22/512

Epoch 00022: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.6705e-10 - val_loss: 5.6075e-10
Epoch 23/512

Epoch 00023: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4002e-10 - val_loss: 5.1927e-10
Epoch 24/512

Epoch 00024: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9663e-10 - val_loss: 4.7688e-10
Epoch 25/512

Epoch 00025: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6272e-10 - val_loss: 4.5696e-10
Epoch 26/512

Epoch 00026: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5047e-10 - val_loss: 4.5431e-10
Epoch 27/512

Epoch 00027: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4981e-10 - val_loss: 4.5186e-10
Epoch 28/512

Epoch 00028: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4564e-10 - val_loss: 4.4645e-10
Epoch 29/512

Epoch 00029: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3725e-10 - val_loss: 4.3531e-10
Epoch 30/512

Epoch 00030: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2549e-10 - val_loss: 4.2051e-10
Epoch 31/512

Epoch 00031: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0985e-10 - val_loss: 4.0412e-10
Epoch 32/512

Epoch 00032: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9529e-10 - val_loss: 3.9171e-10
Epoch 33/512

Epoch 00033: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8390e-10 - val_loss: 3.8109e-10
Epoch 34/512

Epoch 00034: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7347e-10 - val_loss: 3.7190e-10
Epoch 35/512

Epoch 00035: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6603e-10 - val_loss: 3.6603e-10
Epoch 36/512

Epoch 00036: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6045e-10 - val_loss: 3.5893e-10
Epoch 37/512

Epoch 00037: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5178e-10 - val_loss: 3.4889e-10
Epoch 38/512

Epoch 00038: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4279e-10 - val_loss: 3.4192e-10
Epoch 39/512

Epoch 00039: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3697e-10 - val_loss: 3.3681e-10
Epoch 40/512

Epoch 00040: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2936e-10 - val_loss: 3.2438e-10
Epoch 41/512

Epoch 00041: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.1844e-10 - val_loss: 3.1653e-10
Epoch 42/512

Epoch 00042: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.1028e-10 - val_loss: 3.0716e-10
Epoch 43/512

Epoch 00043: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.0075e-10 - val_loss: 2.9747e-10
Epoch 44/512

Epoch 00044: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9336e-10 - val_loss: 2.9426e-10
Epoch 45/512

Epoch 00045: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8980e-10 - val_loss: 2.8982e-10
Epoch 46/512

Epoch 00046: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8579e-10 - val_loss: 2.8519e-10
Epoch 47/512

Epoch 00047: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7964e-10 - val_loss: 2.7855e-10
Epoch 48/512

Epoch 00048: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7430e-10 - val_loss: 2.7320e-10
Epoch 49/512

Epoch 00049: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6797e-10 - val_loss: 2.6554e-10
Epoch 50/512

Epoch 00050: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6156e-10 - val_loss: 2.6151e-10
Epoch 51/512

Epoch 00051: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5726e-10 - val_loss: 2.5607e-10
Epoch 52/512

Epoch 00052: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5243e-10 - val_loss: 2.5069e-10
Epoch 53/512

Epoch 00053: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4603e-10 - val_loss: 2.4193e-10
Epoch 54/512

Epoch 00054: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3790e-10 - val_loss: 2.3552e-10
Epoch 55/512

Epoch 00055: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3158e-10 - val_loss: 2.3159e-10
Epoch 56/512

Epoch 00056: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3008e-10 - val_loss: 2.3093e-10
Epoch 57/512

Epoch 00057: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2701e-10 - val_loss: 2.2402e-10
Epoch 58/512

Epoch 00058: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2031e-10 - val_loss: 2.1752e-10
Epoch 59/512

Epoch 00059: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1566e-10 - val_loss: 2.1583e-10
Epoch 60/512

Epoch 00060: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1245e-10 - val_loss: 2.1039e-10
Epoch 61/512

Epoch 00061: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0747e-10 - val_loss: 2.0724e-10
Epoch 62/512

Epoch 00062: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0497e-10 - val_loss: 2.0405e-10
Epoch 63/512

Epoch 00063: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0193e-10 - val_loss: 2.0243e-10
Epoch 64/512

Epoch 00064: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0023e-10 - val_loss: 1.9900e-10
Epoch 65/512

Epoch 00065: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9469e-10 - val_loss: 1.9045e-10
Epoch 66/512

Epoch 00066: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8799e-10 - val_loss: 1.8672e-10
Epoch 67/512

Epoch 00067: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8402e-10 - val_loss: 1.8311e-10
Epoch 68/512

Epoch 00068: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8058e-10 - val_loss: 1.7994e-10
Epoch 69/512

Epoch 00069: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7870e-10 - val_loss: 1.8005e-10
Epoch 70/512

Epoch 00070: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7917e-10 - val_loss: 1.7892e-10
Epoch 71/512

Epoch 00071: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7545e-10 - val_loss: 1.7359e-10
Epoch 72/512

Epoch 00072: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7093e-10 - val_loss: 1.6983e-10
Epoch 73/512

Epoch 00073: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6738e-10 - val_loss: 1.6544e-10
Epoch 74/512

Epoch 00074: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6305e-10 - val_loss: 1.6251e-10
Epoch 75/512

Epoch 00075: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6040e-10 - val_loss: 1.5911e-10
Epoch 76/512

Epoch 00076: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5758e-10 - val_loss: 1.5770e-10
Epoch 77/512

Epoch 00077: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5581e-10 - val_loss: 1.5517e-10
Epoch 78/512

Epoch 00078: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5281e-10 - val_loss: 1.5148e-10
Epoch 79/512

Epoch 00079: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5013e-10 - val_loss: 1.5098e-10
Epoch 80/512

Epoch 00080: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.4927e-10 - val_loss: 1.4742e-10
Epoch 81/512

Epoch 00081: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.4586e-10 - val_loss: 1.4534e-10
Epoch 82/512

Epoch 00082: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.4391e-10 - val_loss: 1.4349e-10
Epoch 83/512

Epoch 00083: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.4135e-10 - val_loss: 1.4141e-10
Epoch 84/512

Epoch 00084: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.3982e-10 - val_loss: 1.3865e-10
Epoch 85/512

Epoch 00085: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.3770e-10 - val_loss: 1.3798e-10
Epoch 86/512

Epoch 00086: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.3628e-10 - val_loss: 1.3478e-10
Epoch 87/512

Epoch 00087: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.3261e-10 - val_loss: 1.3026e-10
Epoch 88/512

Epoch 00088: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.2803e-10 - val_loss: 1.2653e-10
Epoch 89/512

Epoch 00089: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.2574e-10 - val_loss: 1.2642e-10
Epoch 90/512

Epoch 00090: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2655e-10 - val_loss: 1.2775e-10
Epoch 91/512

Epoch 00091: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.2593e-10 - val_loss: 1.2499e-10
Epoch 92/512

Epoch 00092: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.2311e-10 - val_loss: 1.2229e-10
Epoch 93/512

Epoch 00093: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.2125e-10 - val_loss: 1.2108e-10
Epoch 94/512

Epoch 00094: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1994e-10 - val_loss: 1.1868e-10
Epoch 95/512

Epoch 00095: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1680e-10 - val_loss: 1.1556e-10
Epoch 96/512

Epoch 00096: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1371e-10 - val_loss: 1.1301e-10
Epoch 97/512

Epoch 00097: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1225e-10 - val_loss: 1.1201e-10
Epoch 98/512

Epoch 00098: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1131e-10 - val_loss: 1.1173e-10
Epoch 99/512

Epoch 00099: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1112e-10 - val_loss: 1.1114e-10
Epoch 100/512

Epoch 00100: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1024e-10 - val_loss: 1.1010e-10
Epoch 101/512

Epoch 00101: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0890e-10 - val_loss: 1.0767e-10
Epoch 102/512

Epoch 00102: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0610e-10 - val_loss: 1.0520e-10
Epoch 103/512

Epoch 00103: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0357e-10 - val_loss: 1.0228e-10
Epoch 104/512

Epoch 00104: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0134e-10 - val_loss: 1.0153e-10
Epoch 105/512

Epoch 00105: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0068e-10 - val_loss: 1.0061e-10
Epoch 106/512

Epoch 00106: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0009e-10 - val_loss: 1.0063e-10
Epoch 107/512

Epoch 00107: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0030e-10 - val_loss: 1.0027e-10
Epoch 108/512

Epoch 00108: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0014e-10 - val_loss: 9.9683e-11
Epoch 109/512

Epoch 00109: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.8309e-11 - val_loss: 9.6890e-11
Epoch 110/512

Epoch 00110: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.5123e-11 - val_loss: 9.3870e-11
Epoch 111/512

Epoch 00111: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.2726e-11 - val_loss: 9.1666e-11
Epoch 112/512

Epoch 00112: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.0680e-11 - val_loss: 9.1065e-11
Epoch 113/512

Epoch 00113: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.0386e-11 - val_loss: 8.9800e-11
Epoch 114/512

Epoch 00114: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.9169e-11 - val_loss: 8.9298e-11
Epoch 115/512

Epoch 00115: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.8839e-11 - val_loss: 8.8951e-11
Epoch 116/512

Epoch 00116: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.7284e-11 - val_loss: 8.6119e-11
Epoch 117/512

Epoch 00117: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.5158e-11 - val_loss: 8.4783e-11
Epoch 118/512

Epoch 00118: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.3967e-11 - val_loss: 8.3626e-11
Epoch 119/512

Epoch 00119: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.3108e-11 - val_loss: 8.2833e-11
Epoch 120/512

Epoch 00120: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.3068e-11 - val_loss: 8.4120e-11
Epoch 121/512

Epoch 00121: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.3810e-11 - val_loss: 8.4357e-11
Epoch 122/512

Epoch 00122: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.3780e-11 - val_loss: 8.3775e-11
Epoch 123/512

Epoch 00123: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.2909e-11 - val_loss: 8.2349e-11
Epoch 124/512

Epoch 00124: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.1274e-11 - val_loss: 8.0946e-11
Epoch 125/512

Epoch 00125: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.0616e-11 - val_loss: 8.0702e-11
Epoch 126/512

Epoch 00126: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.9716e-11 - val_loss: 7.7901e-11
Epoch 127/512

Epoch 00127: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.6832e-11 - val_loss: 7.6135e-11
Epoch 128/512

Epoch 00128: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.5854e-11 - val_loss: 7.6057e-11
Epoch 129/512

Epoch 00129: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.5457e-11 - val_loss: 7.4523e-11
Epoch 130/512

Epoch 00130: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.4200e-11 - val_loss: 7.3978e-11
Epoch 131/512

Epoch 00131: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.3121e-11 - val_loss: 7.2324e-11
Epoch 132/512

Epoch 00132: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.1779e-11 - val_loss: 7.1026e-11
Epoch 133/512

Epoch 00133: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.0652e-11 - val_loss: 7.0132e-11
Epoch 134/512

Epoch 00134: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.9734e-11 - val_loss: 6.9882e-11
Epoch 135/512

Epoch 00135: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.0201e-11 - val_loss: 7.1309e-11
Epoch 136/512

Epoch 00136: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.0984e-11 - val_loss: 7.1039e-11
Epoch 137/512

Epoch 00137: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.0708e-11 - val_loss: 7.0577e-11
Epoch 138/512

Epoch 00138: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.9428e-11 - val_loss: 6.7673e-11
Epoch 139/512

Epoch 00139: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.7047e-11 - val_loss: 6.7161e-11
Epoch 140/512

Epoch 00140: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.6080e-11 - val_loss: 6.5182e-11
Epoch 141/512

Epoch 00141: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.4354e-11 - val_loss: 6.3140e-11
Epoch 142/512

Epoch 00142: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.2654e-11 - val_loss: 6.2399e-11
Epoch 143/512

Epoch 00143: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.1849e-11 - val_loss: 6.1730e-11
Epoch 144/512

Epoch 00144: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.1163e-11 - val_loss: 6.1053e-11
Epoch 145/512

Epoch 00145: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.1114e-11 - val_loss: 6.1592e-11
Epoch 146/512

Epoch 00146: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.1432e-11 - val_loss: 6.1507e-11
Epoch 147/512

Epoch 00147: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.1215e-11 - val_loss: 6.0676e-11
Epoch 148/512

Epoch 00148: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.0154e-11 - val_loss: 6.0072e-11
Epoch 149/512

Epoch 00149: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.0020e-11 - val_loss: 6.0536e-11
Epoch 150/512

Epoch 00150: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.0376e-11 - val_loss: 6.0399e-11
Epoch 151/512

Epoch 00151: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.0247e-11 - val_loss: 6.0172e-11
Epoch 152/512

Epoch 00152: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.9561e-11 - val_loss: 5.8492e-11
Epoch 153/512

Epoch 00153: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.7626e-11 - val_loss: 5.7241e-11
Epoch 154/512

Epoch 00154: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.7001e-11 - val_loss: 5.6955e-11
Epoch 155/512

Epoch 00155: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.6369e-11 - val_loss: 5.5913e-11
Epoch 156/512

Epoch 00156: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.5438e-11 - val_loss: 5.5321e-11
Epoch 157/512

Epoch 00157: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.4954e-11 - val_loss: 5.4613e-11
Epoch 158/512

Epoch 00158: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.4270e-11 - val_loss: 5.3576e-11
Epoch 159/512

Epoch 00159: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.3227e-11 - val_loss: 5.3110e-11
Epoch 160/512

Epoch 00160: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2984e-11 - val_loss: 5.3117e-11
Epoch 161/512

Epoch 00161: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3271e-11 - val_loss: 5.3115e-11
Epoch 162/512

Epoch 00162: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.3081e-11 - val_loss: 5.2791e-11
Epoch 163/512

Epoch 00163: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.2176e-11 - val_loss: 5.2057e-11
Epoch 164/512

Epoch 00164: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1926e-11 - val_loss: 5.2293e-11
Epoch 165/512

Epoch 00165: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2400e-11 - val_loss: 5.2204e-11
Epoch 166/512

Epoch 00166: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.1089e-11 - val_loss: 4.9783e-11
Epoch 167/512

Epoch 00167: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.9026e-11 - val_loss: 4.8480e-11
Epoch 168/512

Epoch 00168: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.8167e-11 - val_loss: 4.8260e-11
Epoch 169/512

Epoch 00169: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.7974e-11 - val_loss: 4.7664e-11
Epoch 170/512

Epoch 00170: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.7491e-11 - val_loss: 4.7188e-11
Epoch 171/512

Epoch 00171: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.6111e-11 - val_loss: 4.5482e-11
Epoch 172/512

Epoch 00172: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5381e-11 - val_loss: 4.5520e-11
Epoch 173/512

Epoch 00173: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5758e-11 - val_loss: 4.6693e-11
Epoch 174/512

Epoch 00174: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6651e-11 - val_loss: 4.7043e-11
Epoch 175/512

Epoch 00175: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7309e-11 - val_loss: 4.8270e-11
Epoch 176/512

Epoch 00176: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8192e-11 - val_loss: 4.8039e-11
Epoch 177/512

Epoch 00177: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7567e-11 - val_loss: 4.6789e-11
Epoch 178/512

Epoch 00178: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6462e-11 - val_loss: 4.6174e-11
Epoch 179/512

Epoch 00179: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6184e-11 - val_loss: 4.6006e-11
Epoch 180/512

Epoch 00180: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5760e-11 - val_loss: 4.5501e-11
Epoch 181/512

Epoch 00181: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.5066e-11 - val_loss: 4.4111e-11
Epoch 182/512

Epoch 00182: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.3551e-11 - val_loss: 4.2901e-11
Epoch 183/512

Epoch 00183: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1854e-11 - val_loss: 4.0724e-11
Epoch 184/512

Epoch 00184: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0199e-11 - val_loss: 4.0493e-11
Epoch 185/512

Epoch 00185: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0450e-11 - val_loss: 4.0352e-11
Epoch 186/512

Epoch 00186: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0101e-11 - val_loss: 4.0378e-11
Epoch 187/512

Epoch 00187: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0066e-11 - val_loss: 3.9826e-11
Epoch 188/512

Epoch 00188: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9945e-11 - val_loss: 4.0369e-11
Epoch 189/512

Epoch 00189: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0482e-11 - val_loss: 4.0976e-11
Epoch 190/512

Epoch 00190: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1138e-11 - val_loss: 4.0931e-11
Epoch 191/512

Epoch 00191: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0776e-11 - val_loss: 4.0937e-11
Epoch 192/512

Epoch 00192: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0961e-11 - val_loss: 4.1100e-11
Epoch 193/512

Epoch 00193: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0897e-11 - val_loss: 4.0689e-11
Epoch 194/512

Epoch 00194: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0579e-11 - val_loss: 4.0454e-11
Epoch 195/512

Epoch 00195: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0178e-11 - val_loss: 4.0151e-11
Epoch 196/512

Epoch 00196: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9724e-11 - val_loss: 3.9464e-11
Epoch 197/512

Epoch 00197: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.9129e-11 - val_loss: 3.8494e-11
Epoch 198/512

Epoch 00198: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8151e-11 - val_loss: 3.7935e-11
Epoch 199/512

Epoch 00199: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7319e-11 - val_loss: 3.6384e-11
Epoch 200/512

Epoch 00200: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6343e-11 - val_loss: 3.6765e-11
Epoch 201/512

Epoch 00201: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7002e-11 - val_loss: 3.7470e-11
Epoch 202/512

Epoch 00202: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7524e-11 - val_loss: 3.6962e-11
Epoch 203/512

Epoch 00203: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6942e-11 - val_loss: 3.6883e-11
Epoch 204/512

Epoch 00204: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6856e-11 - val_loss: 3.6276e-11
Epoch 205/512

Epoch 00205: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5727e-11 - val_loss: 3.5165e-11
Epoch 206/512

Epoch 00206: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4467e-11 - val_loss: 3.3517e-11
Epoch 207/512

Epoch 00207: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3352e-11 - val_loss: 3.3645e-11
Epoch 208/512

Epoch 00208: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3645e-11 - val_loss: 3.3923e-11
Epoch 209/512

Epoch 00209: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3864e-11 - val_loss: 3.3760e-11
Epoch 210/512

Epoch 00210: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3833e-11 - val_loss: 3.3650e-11
Epoch 211/512

Epoch 00211: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3371e-11 - val_loss: 3.3319e-11
Epoch 212/512

Epoch 00212: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2849e-11 - val_loss: 3.2712e-11
Epoch 213/512

Epoch 00213: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2955e-11 - val_loss: 3.3693e-11
Epoch 214/512

Epoch 00214: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3505e-11 - val_loss: 3.3395e-11
Epoch 215/512

Epoch 00215: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3438e-11 - val_loss: 3.3579e-11
Epoch 216/512

Epoch 00216: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3291e-11 - val_loss: 3.3138e-11
Epoch 217/512

Epoch 00217: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3095e-11 - val_loss: 3.2933e-11
Epoch 218/512

Epoch 00218: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2684e-11 - val_loss: 3.2943e-11
Epoch 219/512

Epoch 00219: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2873e-11 - val_loss: 3.2763e-11
Epoch 220/512

Epoch 00220: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2611e-11 - val_loss: 3.2933e-11
Epoch 221/512

Epoch 00221: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3159e-11 - val_loss: 3.3259e-11
Epoch 222/512

Epoch 00222: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3165e-11 - val_loss: 3.3051e-11
Epoch 223/512

Epoch 00223: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2632e-11 - val_loss: 3.2322e-11
Epoch 224/512

Epoch 00224: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2295e-11 - val_loss: 3.2158e-11
Epoch 225/512

Epoch 00225: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2031e-11 - val_loss: 3.1751e-11
Epoch 226/512

Epoch 00226: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.1542e-11 - val_loss: 3.1359e-11
Epoch 227/512

Epoch 00227: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.1241e-11 - val_loss: 3.0853e-11
Epoch 228/512

Epoch 00228: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.0355e-11 - val_loss: 2.9650e-11
Epoch 229/512

Epoch 00229: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.9306e-11 - val_loss: 2.9034e-11
Epoch 230/512

Epoch 00230: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.8660e-11 - val_loss: 2.8396e-11
Epoch 231/512

Epoch 00231: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8334e-11 - val_loss: 2.8530e-11
Epoch 232/512

Epoch 00232: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.8456e-11 - val_loss: 2.8299e-11
Epoch 233/512

Epoch 00233: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8516e-11 - val_loss: 2.8922e-11
Epoch 234/512

Epoch 00234: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8977e-11 - val_loss: 2.9023e-11
Epoch 235/512

Epoch 00235: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9373e-11 - val_loss: 2.9697e-11
Epoch 236/512

Epoch 00236: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9833e-11 - val_loss: 2.9588e-11
Epoch 237/512

Epoch 00237: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9574e-11 - val_loss: 2.9295e-11
Epoch 238/512

Epoch 00238: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.8919e-11 - val_loss: 2.8157e-11
Epoch 239/512

Epoch 00239: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8103e-11 - val_loss: 2.8347e-11
Epoch 240/512

Epoch 00240: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8596e-11 - val_loss: 2.8640e-11
Epoch 241/512

Epoch 00241: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.8253e-11 - val_loss: 2.7812e-11
Epoch 242/512

Epoch 00242: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.7782e-11 - val_loss: 2.7451e-11
Epoch 243/512

Epoch 00243: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7445e-11 - val_loss: 2.7609e-11
Epoch 244/512

Epoch 00244: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.7268e-11 - val_loss: 2.6996e-11
Epoch 245/512

Epoch 00245: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7188e-11 - val_loss: 2.7659e-11
Epoch 246/512

Epoch 00246: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7827e-11 - val_loss: 2.8069e-11
Epoch 247/512

Epoch 00247: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7893e-11 - val_loss: 2.7464e-11
Epoch 248/512

Epoch 00248: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7248e-11 - val_loss: 2.7238e-11
Epoch 249/512

Epoch 00249: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7504e-11 - val_loss: 2.7621e-11
Epoch 250/512

Epoch 00250: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7259e-11 - val_loss: 2.7202e-11
Epoch 251/512

Epoch 00251: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.7163e-11 - val_loss: 2.6857e-11
Epoch 252/512

Epoch 00252: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.6254e-11 - val_loss: 2.5543e-11
Epoch 253/512

Epoch 00253: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.5228e-11 - val_loss: 2.5105e-11
Epoch 254/512

Epoch 00254: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.4956e-11 - val_loss: 2.4627e-11
Epoch 255/512

Epoch 00255: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.4692e-11 - val_loss: 2.4621e-11
Epoch 256/512

Epoch 00256: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4433e-11 - val_loss: 2.4627e-11
Epoch 257/512

Epoch 00257: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.4544e-11 - val_loss: 2.4569e-11
Epoch 258/512

Epoch 00258: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4687e-11 - val_loss: 2.4821e-11
Epoch 259/512

Epoch 00259: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4815e-11 - val_loss: 2.5010e-11
Epoch 260/512

Epoch 00260: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5112e-11 - val_loss: 2.5109e-11
Epoch 261/512

Epoch 00261: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.4846e-11 - val_loss: 2.4446e-11
Epoch 262/512

Epoch 00262: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.4083e-11 - val_loss: 2.3858e-11
Epoch 263/512

Epoch 00263: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.3752e-11 - val_loss: 2.3652e-11
Epoch 264/512

Epoch 00264: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3751e-11 - val_loss: 2.3955e-11
Epoch 265/512

Epoch 00265: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4031e-11 - val_loss: 2.4184e-11
Epoch 266/512

Epoch 00266: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4064e-11 - val_loss: 2.3728e-11
Epoch 267/512

Epoch 00267: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.3761e-11 - val_loss: 2.3582e-11
Epoch 268/512

Epoch 00268: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.3206e-11 - val_loss: 2.2816e-11
Epoch 269/512

Epoch 00269: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.2775e-11 - val_loss: 2.2802e-11
Epoch 270/512

Epoch 00270: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2895e-11 - val_loss: 2.3158e-11
Epoch 271/512

Epoch 00271: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3164e-11 - val_loss: 2.3103e-11
Epoch 272/512

Epoch 00272: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3152e-11 - val_loss: 2.3176e-11
Epoch 273/512

Epoch 00273: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3422e-11 - val_loss: 2.3447e-11
Epoch 274/512

Epoch 00274: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3152e-11 - val_loss: 2.3037e-11
Epoch 275/512

Epoch 00275: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.2754e-11 - val_loss: 2.2730e-11
Epoch 276/512

Epoch 00276: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.2831e-11 - val_loss: 2.2708e-11
Epoch 277/512

Epoch 00277: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.2250e-11 - val_loss: 2.1457e-11
Epoch 278/512

Epoch 00278: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.1081e-11 - val_loss: 2.0766e-11
Epoch 279/512

Epoch 00279: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.0486e-11 - val_loss: 2.0107e-11
Epoch 280/512

Epoch 00280: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.0009e-11 - val_loss: 1.9961e-11
Epoch 281/512

Epoch 00281: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.9800e-11 - val_loss: 1.9651e-11
Epoch 282/512

Epoch 00282: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9697e-11 - val_loss: 1.9738e-11
Epoch 283/512

Epoch 00283: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9901e-11 - val_loss: 2.0289e-11
Epoch 284/512

Epoch 00284: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0514e-11 - val_loss: 2.0748e-11
Epoch 285/512

Epoch 00285: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1071e-11 - val_loss: 2.1354e-11
Epoch 286/512

Epoch 00286: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1323e-11 - val_loss: 2.1259e-11
Epoch 287/512

Epoch 00287: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1212e-11 - val_loss: 2.0873e-11
Epoch 288/512

Epoch 00288: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0779e-11 - val_loss: 2.0801e-11
Epoch 289/512

Epoch 00289: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0580e-11 - val_loss: 2.0186e-11
Epoch 290/512

Epoch 00290: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.9716e-11 - val_loss: 1.9467e-11
Epoch 291/512

Epoch 00291: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9491e-11 - val_loss: 1.9933e-11
Epoch 292/512

Epoch 00292: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0155e-11 - val_loss: 2.0285e-11
Epoch 293/512

Epoch 00293: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0193e-11 - val_loss: 1.9837e-11
Epoch 294/512

Epoch 00294: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9803e-11 - val_loss: 1.9818e-11
Epoch 295/512

Epoch 00295: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9771e-11 - val_loss: 1.9606e-11
Epoch 296/512

Epoch 00296: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9667e-11 - val_loss: 1.9948e-11
Epoch 297/512

Epoch 00297: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9909e-11 - val_loss: 1.9972e-11
Epoch 298/512

Epoch 00298: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0160e-11 - val_loss: 2.0252e-11
Epoch 299/512

Epoch 00299: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0192e-11 - val_loss: 1.9839e-11
Epoch 300/512

Epoch 00300: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.9647e-11 - val_loss: 1.9277e-11
Epoch 301/512

Epoch 00301: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.9230e-11 - val_loss: 1.9201e-11
Epoch 302/512

Epoch 00302: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.8952e-11 - val_loss: 1.8478e-11
Epoch 303/512

Epoch 00303: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.8430e-11 - val_loss: 1.8263e-11
Epoch 304/512

Epoch 00304: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.7883e-11 - val_loss: 1.7585e-11
Epoch 305/512

Epoch 00305: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.7465e-11 - val_loss: 1.7324e-11
Epoch 306/512

Epoch 00306: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7441e-11 - val_loss: 1.7548e-11
Epoch 307/512

Epoch 00307: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7867e-11 - val_loss: 1.8392e-11
Epoch 308/512

Epoch 00308: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8241e-11 - val_loss: 1.8028e-11
Epoch 309/512

Epoch 00309: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8088e-11 - val_loss: 1.8234e-11
Epoch 310/512

Epoch 00310: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8021e-11 - val_loss: 1.7822e-11
Epoch 311/512

Epoch 00311: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7801e-11 - val_loss: 1.7870e-11
Epoch 312/512

Epoch 00312: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8136e-11 - val_loss: 1.8422e-11
Epoch 313/512

Epoch 00313: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8345e-11 - val_loss: 1.8249e-11
Epoch 314/512

Epoch 00314: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8187e-11 - val_loss: 1.8056e-11
Epoch 315/512

Epoch 00315: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7921e-11 - val_loss: 1.7841e-11
Epoch 316/512

Epoch 00316: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7746e-11 - val_loss: 1.7597e-11
Epoch 317/512

Epoch 00317: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7559e-11 - val_loss: 1.7419e-11
Epoch 318/512

Epoch 00318: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.7304e-11 - val_loss: 1.6939e-11
Epoch 319/512

Epoch 00319: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7128e-11 - val_loss: 1.7191e-11
Epoch 320/512

Epoch 00320: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7366e-11 - val_loss: 1.7448e-11
Epoch 321/512

Epoch 00321: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7651e-11 - val_loss: 1.7810e-11
Epoch 322/512

Epoch 00322: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7839e-11 - val_loss: 1.8105e-11
Epoch 323/512

Epoch 00323: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8263e-11 - val_loss: 1.8329e-11
Epoch 324/512

Epoch 00324: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8302e-11 - val_loss: 1.8321e-11
Epoch 325/512

Epoch 00325: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8424e-11 - val_loss: 1.8465e-11
Epoch 326/512

Epoch 00326: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8257e-11 - val_loss: 1.7792e-11
Epoch 327/512

Epoch 00327: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7669e-11 - val_loss: 1.7465e-11
Epoch 328/512

Epoch 00328: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7574e-11 - val_loss: 1.7726e-11
Epoch 329/512

Epoch 00329: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7990e-11 - val_loss: 1.8317e-11
Epoch 330/512

Epoch 00330: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8040e-11 - val_loss: 1.7624e-11
Epoch 331/512

Epoch 00331: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7491e-11 - val_loss: 1.7481e-11
Epoch 332/512

Epoch 00332: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7433e-11 - val_loss: 1.7233e-11
Epoch 333/512

Epoch 00333: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7368e-11 - val_loss: 1.7306e-11
Epoch 334/512

Epoch 00334: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7142e-11 - val_loss: 1.6973e-11
Epoch 335/512

Epoch 00335: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.6837e-11 - val_loss: 1.6503e-11
Epoch 336/512

Epoch 00336: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.6258e-11 - val_loss: 1.6084e-11
Epoch 337/512

Epoch 00337: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5920e-11 - val_loss: 1.5638e-11
Epoch 338/512

Epoch 00338: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5653e-11 - val_loss: 1.5529e-11
Epoch 339/512

Epoch 00339: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5613e-11 - val_loss: 1.5276e-11
Epoch 340/512

Epoch 00340: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5259e-11 - val_loss: 1.5221e-11
Epoch 341/512

Epoch 00341: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5090e-11 - val_loss: 1.4971e-11
Epoch 342/512

Epoch 00342: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5033e-11 - val_loss: 1.4824e-11
Epoch 343/512

Epoch 00343: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5012e-11 - val_loss: 1.5106e-11
Epoch 344/512

Epoch 00344: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5076e-11 - val_loss: 1.5261e-11
Epoch 345/512

Epoch 00345: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5167e-11 - val_loss: 1.5052e-11
Epoch 346/512

Epoch 00346: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4955e-11 - val_loss: 1.4996e-11
Epoch 347/512

Epoch 00347: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.4855e-11 - val_loss: 1.4599e-11
Epoch 348/512

Epoch 00348: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4685e-11 - val_loss: 1.4942e-11
Epoch 349/512

Epoch 00349: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5062e-11 - val_loss: 1.5122e-11
Epoch 350/512

Epoch 00350: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5162e-11 - val_loss: 1.5092e-11
Epoch 351/512

Epoch 00351: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.4796e-11 - val_loss: 1.4516e-11
Epoch 352/512

Epoch 00352: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4619e-11 - val_loss: 1.4539e-11
Epoch 353/512

Epoch 00353: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.4355e-11 - val_loss: 1.4155e-11
Epoch 354/512

Epoch 00354: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4292e-11 - val_loss: 1.4335e-11
Epoch 355/512

Epoch 00355: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4511e-11 - val_loss: 1.4575e-11
Epoch 356/512

Epoch 00356: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4504e-11 - val_loss: 1.4285e-11
Epoch 357/512

Epoch 00357: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.4347e-11 - val_loss: 1.4155e-11
Epoch 358/512

Epoch 00358: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.4212e-11 - val_loss: 1.4122e-11
Epoch 359/512

Epoch 00359: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4314e-11 - val_loss: 1.4649e-11
Epoch 360/512

Epoch 00360: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4782e-11 - val_loss: 1.4974e-11
Epoch 361/512

Epoch 00361: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4958e-11 - val_loss: 1.4882e-11
Epoch 362/512

Epoch 00362: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4883e-11 - val_loss: 1.4872e-11
Epoch 363/512

Epoch 00363: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4957e-11 - val_loss: 1.4948e-11
Epoch 364/512

Epoch 00364: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4884e-11 - val_loss: 1.4697e-11
Epoch 365/512

Epoch 00365: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4798e-11 - val_loss: 1.4944e-11
Epoch 366/512

Epoch 00366: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5068e-11 - val_loss: 1.5027e-11
Epoch 367/512

Epoch 00367: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4832e-11 - val_loss: 1.4873e-11
Epoch 368/512

Epoch 00368: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5025e-11 - val_loss: 1.5085e-11
Epoch 369/512

Epoch 00369: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5188e-11 - val_loss: 1.5112e-11
Epoch 370/512

Epoch 00370: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4999e-11 - val_loss: 1.4869e-11
Epoch 371/512

Epoch 00371: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4929e-11 - val_loss: 1.5019e-11
Epoch 372/512

Epoch 00372: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4988e-11 - val_loss: 1.4779e-11
Epoch 373/512

Epoch 00373: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4711e-11 - val_loss: 1.4467e-11
Epoch 374/512

Epoch 00374: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4478e-11 - val_loss: 1.4160e-11
Epoch 375/512

Epoch 00375: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.3705e-11 - val_loss: 1.3256e-11
Epoch 376/512

Epoch 00376: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.3260e-11 - val_loss: 1.3202e-11
Epoch 377/512

Epoch 00377: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.3233e-11 - val_loss: 1.3169e-11
Epoch 378/512

Epoch 00378: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.3078e-11 - val_loss: 1.2843e-11
Epoch 379/512

Epoch 00379: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.2834e-11 - val_loss: 1.2617e-11
Epoch 380/512

Epoch 00380: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.2352e-11 - val_loss: 1.2111e-11
Epoch 381/512

Epoch 00381: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2046e-11 - val_loss: 1.2164e-11
Epoch 382/512

Epoch 00382: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2196e-11 - val_loss: 1.2290e-11
Epoch 383/512

Epoch 00383: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.2103e-11 - val_loss: 1.2040e-11
Epoch 384/512

Epoch 00384: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2190e-11 - val_loss: 1.2427e-11
Epoch 385/512

Epoch 00385: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2531e-11 - val_loss: 1.2414e-11
Epoch 386/512

Epoch 00386: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2618e-11 - val_loss: 1.2706e-11
Epoch 387/512

Epoch 00387: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2934e-11 - val_loss: 1.3124e-11
Epoch 388/512

Epoch 00388: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3012e-11 - val_loss: 1.3285e-11
Epoch 389/512

Epoch 00389: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3496e-11 - val_loss: 1.3625e-11
Epoch 390/512

Epoch 00390: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3531e-11 - val_loss: 1.3353e-11
Epoch 391/512

Epoch 00391: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3304e-11 - val_loss: 1.3289e-11
Epoch 392/512

Epoch 00392: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3316e-11 - val_loss: 1.3285e-11
Epoch 393/512

Epoch 00393: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3381e-11 - val_loss: 1.3053e-11
Epoch 394/512

Epoch 00394: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3113e-11 - val_loss: 1.2895e-11
Epoch 395/512

Epoch 00395: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2990e-11 - val_loss: 1.2754e-11
Epoch 396/512

Epoch 00396: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2695e-11 - val_loss: 1.2499e-11
Epoch 397/512

Epoch 00397: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2503e-11 - val_loss: 1.2436e-11
Epoch 398/512

Epoch 00398: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2677e-11 - val_loss: 1.2921e-11
Epoch 399/512

Epoch 00399: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2772e-11 - val_loss: 1.2417e-11
Epoch 400/512

Epoch 00400: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2281e-11 - val_loss: 1.2101e-11
Epoch 401/512

Epoch 00401: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.2075e-11 - val_loss: 1.1885e-11
Epoch 402/512

Epoch 00402: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1829e-11 - val_loss: 1.1610e-11
Epoch 403/512

Epoch 00403: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1469e-11 - val_loss: 1.1157e-11
Epoch 404/512

Epoch 00404: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1322e-11 - val_loss: 1.1570e-11
Epoch 405/512

Epoch 00405: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1544e-11 - val_loss: 1.1369e-11
Epoch 406/512

Epoch 00406: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1403e-11 - val_loss: 1.1362e-11
Epoch 407/512

Epoch 00407: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1232e-11 - val_loss: 1.1059e-11
Epoch 408/512

Epoch 00408: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1194e-11 - val_loss: 1.1393e-11
Epoch 409/512

Epoch 00409: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1468e-11 - val_loss: 1.1525e-11
Epoch 410/512

Epoch 00410: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1730e-11 - val_loss: 1.1844e-11
Epoch 411/512

Epoch 00411: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1860e-11 - val_loss: 1.2090e-11
Epoch 412/512

Epoch 00412: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2366e-11 - val_loss: 1.2422e-11
Epoch 413/512

Epoch 00413: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2448e-11 - val_loss: 1.2510e-11
Epoch 414/512

Epoch 00414: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2680e-11 - val_loss: 1.2784e-11
Epoch 415/512

Epoch 00415: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2750e-11 - val_loss: 1.2758e-11
Epoch 416/512

Epoch 00416: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2793e-11 - val_loss: 1.2556e-11
Epoch 417/512

Epoch 00417: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2432e-11 - val_loss: 1.2140e-11
Epoch 418/512

Epoch 00418: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1867e-11 - val_loss: 1.1610e-11
Epoch 419/512

Epoch 00419: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1685e-11 - val_loss: 1.1533e-11
Epoch 420/512

Epoch 00420: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1454e-11 - val_loss: 1.1079e-11
Epoch 421/512

Epoch 00421: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0950e-11 - val_loss: 1.0891e-11
Epoch 422/512

Epoch 00422: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0788e-11 - val_loss: 1.0780e-11
Epoch 423/512

Epoch 00423: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0913e-11 - val_loss: 1.0931e-11
Epoch 424/512

Epoch 00424: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1077e-11 - val_loss: 1.1046e-11
Epoch 425/512

Epoch 00425: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1014e-11 - val_loss: 1.1067e-11
Epoch 426/512

Epoch 00426: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1074e-11 - val_loss: 1.0926e-11
Epoch 427/512

Epoch 00427: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0938e-11 - val_loss: 1.0873e-11
Epoch 428/512

Epoch 00428: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1044e-11 - val_loss: 1.1199e-11
Epoch 429/512

Epoch 00429: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1305e-11 - val_loss: 1.1154e-11
Epoch 430/512

Epoch 00430: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1128e-11 - val_loss: 1.0982e-11
Epoch 431/512

Epoch 00431: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0907e-11 - val_loss: 1.0802e-11
Epoch 432/512

Epoch 00432: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0734e-11 - val_loss: 1.0601e-11
Epoch 433/512

Epoch 00433: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0697e-11 - val_loss: 1.0844e-11
Epoch 434/512

Epoch 00434: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1094e-11 - val_loss: 1.1187e-11
Epoch 435/512

Epoch 00435: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1098e-11 - val_loss: 1.1008e-11
Epoch 436/512

Epoch 00436: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0905e-11 - val_loss: 1.0648e-11
Epoch 437/512

Epoch 00437: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0662e-11 - val_loss: 1.0791e-11
Epoch 438/512

Epoch 00438: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1040e-11 - val_loss: 1.1199e-11
Epoch 439/512

Epoch 00439: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1082e-11 - val_loss: 1.0759e-11
Epoch 440/512

Epoch 00440: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0616e-11 - val_loss: 1.0363e-11
Epoch 441/512

Epoch 00441: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0315e-11 - val_loss: 1.0167e-11
Epoch 442/512

Epoch 00442: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0208e-11 - val_loss: 1.0124e-11
Epoch 443/512

Epoch 00443: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0227e-11 - val_loss: 1.0351e-11
Epoch 444/512

Epoch 00444: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0415e-11 - val_loss: 1.0330e-11
Epoch 445/512

Epoch 00445: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0281e-11 - val_loss: 1.0261e-11
Epoch 446/512

Epoch 00446: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0330e-11 - val_loss: 1.0296e-11
Epoch 447/512

Epoch 00447: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0336e-11 - val_loss: 1.0293e-11
Epoch 448/512

Epoch 00448: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0156e-11 - val_loss: 9.9516e-12
Epoch 449/512

Epoch 00449: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0008e-11 - val_loss: 1.0153e-11
Epoch 450/512

Epoch 00450: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0233e-11 - val_loss: 1.0286e-11
Epoch 451/512

Epoch 00451: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0292e-11 - val_loss: 1.0165e-11
Epoch 452/512

Epoch 00452: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0191e-11 - val_loss: 1.0303e-11
Epoch 453/512

Epoch 00453: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0228e-11 - val_loss: 1.0132e-11
Epoch 454/512

Epoch 00454: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0198e-11 - val_loss: 1.0307e-11
Epoch 455/512

Epoch 00455: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0370e-11 - val_loss: 1.0178e-11
Epoch 456/512

Epoch 00456: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0259e-11 - val_loss: 1.0316e-11
Epoch 457/512

Epoch 00457: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0298e-11 - val_loss: 1.0228e-11
Epoch 458/512

Epoch 00458: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0199e-11 - val_loss: 1.0100e-11
Epoch 459/512

Epoch 00459: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0330e-11 - val_loss: 1.0576e-11
Epoch 460/512

Epoch 00460: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0597e-11 - val_loss: 1.0669e-11
Epoch 461/512

Epoch 00461: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0643e-11 - val_loss: 1.0459e-11
Epoch 462/512

Epoch 00462: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0366e-11 - val_loss: 1.0218e-11
Epoch 463/512

Epoch 00463: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0108e-11 - val_loss: 9.7997e-12
Epoch 464/512

Epoch 00464: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.6817e-12 - val_loss: 9.4935e-12
Epoch 465/512

Epoch 00465: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.3200e-12 - val_loss: 9.1020e-12
Epoch 466/512

Epoch 00466: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.0014e-12 - val_loss: 8.7593e-12
Epoch 467/512

Epoch 00467: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.7275e-12 - val_loss: 8.6129e-12
Epoch 468/512

Epoch 00468: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.6990e-12 - val_loss: 8.6049e-12
Epoch 469/512

Epoch 00469: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-lr0.00005-sigmoid-RMS-18/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.5773e-12 - val_loss: 8.4935e-12
Epoch 470/512

Epoch 00470: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.6857e-12 - val_loss: 8.8355e-12
Epoch 471/512

Epoch 00471: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.0531e-12 - val_loss: 9.1048e-12
Epoch 472/512

Epoch 00472: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.0284e-12 - val_loss: 8.6921e-12
Epoch 473/512

Epoch 00473: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.6707e-12 - val_loss: 8.6810e-12
Epoch 474/512

Epoch 00474: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.7589e-12 - val_loss: 8.8964e-12
Epoch 475/512

Epoch 00475: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.8640e-12 - val_loss: 8.8505e-12
Epoch 476/512

Epoch 00476: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.9029e-12 - val_loss: 8.8014e-12
Epoch 477/512

Epoch 00477: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.9483e-12 - val_loss: 9.0275e-12
Epoch 478/512

Epoch 00478: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.9825e-12 - val_loss: 8.8457e-12
Epoch 479/512

Epoch 00479: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.8498e-12 - val_loss: 8.9318e-12
Epoch 480/512

Epoch 00480: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.9684e-12 - val_loss: 8.9023e-12
Epoch 481/512

Epoch 00481: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.8026e-12 - val_loss: 8.7624e-12
Epoch 482/512

Epoch 00482: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.8681e-12 - val_loss: 8.7917e-12
Epoch 483/512

Epoch 00483: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.0605e-12 - val_loss: 9.3971e-12
Epoch 484/512

Epoch 00484: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.4706e-12 - val_loss: 9.3991e-12
Epoch 485/512

Epoch 00485: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.6461e-12 - val_loss: 9.7910e-12
Epoch 486/512

Epoch 00486: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.8712e-12 - val_loss: 9.8616e-12
Epoch 487/512

Epoch 00487: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.9807e-12 - val_loss: 9.8347e-12
Epoch 488/512

Epoch 00488: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.7690e-12 - val_loss: 9.4468e-12
Epoch 489/512

Epoch 00489: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.4025e-12 - val_loss: 9.1465e-12
Epoch 490/512

Epoch 00490: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.0802e-12 - val_loss: 8.7688e-12
Epoch 491/512

Epoch 00491: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.7284e-12 - val_loss: 8.6170e-12
Epoch 492/512

Epoch 00492: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.6592e-12 - val_loss: 8.6220e-12
Epoch 493/512

Epoch 00493: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.6923e-12 - val_loss: 8.7398e-12
Epoch 494/512

Epoch 00494: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.8659e-12 - val_loss: 8.8432e-12
Epoch 495/512

Epoch 00495: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.8178e-12 - val_loss: 8.7895e-12
Epoch 496/512

Epoch 00496: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.9114e-12 - val_loss: 9.2212e-12
Epoch 497/512

Epoch 00497: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.1864e-12 - val_loss: 9.0545e-12
Epoch 498/512

Epoch 00498: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.1038e-12 - val_loss: 9.1664e-12
Epoch 499/512

Epoch 00499: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.1858e-12 - val_loss: 9.1118e-12
Epoch 500/512

Epoch 00500: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.2909e-12 - val_loss: 9.4734e-12
Epoch 501/512

Epoch 00501: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.5400e-12 - val_loss: 9.4644e-12
Epoch 502/512

Epoch 00502: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.3128e-12 - val_loss: 9.0806e-12
Epoch 503/512

Epoch 00503: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.1546e-12 - val_loss: 9.0052e-12
Epoch 504/512

Epoch 00504: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.9629e-12 - val_loss: 8.8088e-12
Epoch 505/512

Epoch 00505: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.7636e-12 - val_loss: 8.6916e-12
Epoch 506/512

Epoch 00506: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.7202e-12 - val_loss: 8.8123e-12
Epoch 507/512

Epoch 00507: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.9982e-12 - val_loss: 9.2078e-12
Epoch 508/512

Epoch 00508: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.3522e-12 - val_loss: 9.0891e-12
Epoch 509/512

Epoch 00509: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.1373e-12 - val_loss: 9.0729e-12
Epoch 510/512

Epoch 00510: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.1691e-12 - val_loss: 9.2400e-12
Epoch 511/512

Epoch 00511: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.2514e-12 - val_loss: 9.2012e-12
Epoch 512/512

Epoch 00512: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.1290e-12 - val_loss: 9.0377e-12
WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?
WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?
Epoch   0:   0% | abe: 9.784 | eve: 9.865 | bob: 9.463Epoch   0:   0% | abe: 9.637 | eve: 9.838 | bob: 9.391Epoch   0:   1% | abe: 9.542 | eve: 9.815 | bob: 9.352Epoch   0:   2% | abe: 9.500 | eve: 9.812 | bob: 9.343Epoch   0:   3% | abe: 9.447 | eve: 9.799 | bob: 9.310Epoch   0:   3% | abe: 9.427 | eve: 9.794 | bob: 9.303Epoch   0:   4% | abe: 9.392 | eve: 9.793 | bob: 9.278Epoch   0:   5% | abe: 9.379 | eve: 9.784 | bob: 9.273Epoch   0:   6% | abe: 9.372 | eve: 9.787 | bob: 9.271Epoch   0:   7% | abe: 9.359 | eve: 9.793 | bob: 9.264Epoch   0:   7% | abe: 9.354 | eve: 9.793 | bob: 9.263Epoch   0:   8% | abe: 9.342 | eve: 9.790 | bob: 9.254Epoch   0:   9% | abe: 9.327 | eve: 9.797 | bob: 9.242Epoch   0:  10% | abe: 9.319 | eve: 9.795 | bob: 9.236Epoch   0:  10% | abe: 9.311 | eve: 9.801 | bob: 9.231Epoch   0:  11% | abe: 9.303 | eve: 9.794 | bob: 9.225Epoch   0:  12% | abe: 9.295 | eve: 9.791 | bob: 9.218Epoch   0:  13% | abe: 9.293 | eve: 9.790 | bob: 9.217Epoch   0:  14% | abe: 9.291 | eve: 9.788 | bob: 9.217Epoch   0:  14% | abe: 9.284 | eve: 9.784 | bob: 9.210Epoch   0:  15% | abe: 9.282 | eve: 9.783 | bob: 9.210Epoch   0:  16% | abe: 9.275 | eve: 9.784 | bob: 9.203Epoch   0:  17% | abe: 9.269 | eve: 9.779 | bob: 9.198Epoch   0:  17% | abe: 9.263 | eve: 9.777 | bob: 9.193Epoch   0:  18% | abe: 9.261 | eve: 9.774 | bob: 9.191Epoch   0:  19% | abe: 9.258 | eve: 9.776 | bob: 9.189Epoch   0:  20% | abe: 9.255 | eve: 9.775 | bob: 9.187Epoch   0:  21% | abe: 9.250 | eve: 9.776 | bob: 9.183Epoch   0:  21% | abe: 9.248 | eve: 9.773 | bob: 9.180Epoch   0:  22% | abe: 9.244 | eve: 9.772 | bob: 9.177Epoch   0:  23% | abe: 9.240 | eve: 9.775 | bob: 9.174Epoch   0:  24% | abe: 9.237 | eve: 9.774 | bob: 9.171Epoch   0:  25% | abe: 9.236 | eve: 9.774 | bob: 9.171Epoch   0:  25% | abe: 9.233 | eve: 9.776 | bob: 9.168Epoch   0:  26% | abe: 9.228 | eve: 9.776 | bob: 9.163Epoch   0:  27% | abe: 9.225 | eve: 9.774 | bob: 9.160Epoch   0:  28% | abe: 9.221 | eve: 9.774 | bob: 9.157Epoch   0:  28% | abe: 9.219 | eve: 9.774 | bob: 9.155Epoch   0:  29% | abe: 9.215 | eve: 9.775 | bob: 9.152Epoch   0:  30% | abe: 9.212 | eve: 9.775 | bob: 9.148Epoch   0:  31% | abe: 9.209 | eve: 9.776 | bob: 9.146Epoch   0:  32% | abe: 9.206 | eve: 9.775 | bob: 9.143Epoch   0:  32% | abe: 9.205 | eve: 9.776 | bob: 9.143Epoch   0:  33% | abe: 9.203 | eve: 9.777 | bob: 9.141Epoch   0:  34% | abe: 9.199 | eve: 9.777 | bob: 9.137Epoch   0:  35% | abe: 9.196 | eve: 9.777 | bob: 9.134Epoch   0:  35% | abe: 9.194 | eve: 9.778 | bob: 9.132Epoch   0:  36% | abe: 9.190 | eve: 9.777 | bob: 9.129Epoch   0:  37% | abe: 9.189 | eve: 9.779 | bob: 9.127Epoch   0:  38% | abe: 9.187 | eve: 9.778 | bob: 9.125Epoch   0:  39% | abe: 9.185 | eve: 9.777 | bob: 9.123Epoch   0:  39% | abe: 9.184 | eve: 9.778 | bob: 9.123Epoch   0:  40% | abe: 9.182 | eve: 9.779 | bob: 9.121Epoch   0:  41% | abe: 9.182 | eve: 9.778 | bob: 9.121Epoch   0:  42% | abe: 9.181 | eve: 9.779 | bob: 9.119Epoch   0:  42% | abe: 9.180 | eve: 9.779 | bob: 9.119Epoch   0:  43% | abe: 9.178 | eve: 9.779 | bob: 9.117Epoch   0:  44% | abe: 9.176 | eve: 9.778 | bob: 9.115Epoch   0:  45% | abe: 9.175 | eve: 9.779 | bob: 9.113Epoch   0:  46% | abe: 9.173 | eve: 9.780 | bob: 9.112Epoch   0:  46% | abe: 9.172 | eve: 9.780 | bob: 9.110Epoch   0:  47% | abe: 9.170 | eve: 9.781 | bob: 9.109Epoch   0:  48% | abe: 9.169 | eve: 9.780 | bob: 9.108Epoch   0:  49% | abe: 9.168 | eve: 9.780 | bob: 9.107Epoch   0:  50% | abe: 9.166 | eve: 9.781 | bob: 9.105Epoch   0:  50% | abe: 9.165 | eve: 9.781 | bob: 9.104Epoch   0:  51% | abe: 9.163 | eve: 9.782 | bob: 9.102Epoch   0:  52% | abe: 9.162 | eve: 9.781 | bob: 9.101Epoch   0:  53% | abe: 9.161 | eve: 9.780 | bob: 9.099Epoch   0:  53% | abe: 9.160 | eve: 9.781 | bob: 9.099Epoch   0:  54% | abe: 9.160 | eve: 9.781 | bob: 9.099Epoch   0:  55% | abe: 9.158 | eve: 9.782 | bob: 9.097Epoch   0:  56% | abe: 9.156 | eve: 9.782 | bob: 9.095Epoch   0:  57% | abe: 9.155 | eve: 9.783 | bob: 9.094Epoch   0:  57% | abe: 9.154 | eve: 9.783 | bob: 9.092Epoch   0:  58% | abe: 9.153 | eve: 9.784 | bob: 9.091Epoch   0:  59% | abe: 9.151 | eve: 9.783 | bob: 9.090Epoch   0:  60% | abe: 9.150 | eve: 9.784 | bob: 9.089Epoch   0:  60% | abe: 9.150 | eve: 9.784 | bob: 9.089Epoch   0:  61% | abe: 9.149 | eve: 9.785 | bob: 9.088Epoch   0:  62% | abe: 9.149 | eve: 9.785 | bob: 9.088Epoch   0:  63% | abe: 9.148 | eve: 9.784 | bob: 9.086Epoch   0:  64% | abe: 9.147 | eve: 9.784 | bob: 9.086Epoch   0:  64% | abe: 9.146 | eve: 9.783 | bob: 9.085Epoch   0:  65% | abe: 9.146 | eve: 9.784 | bob: 9.084Epoch   0:  66% | abe: 9.144 | eve: 9.784 | bob: 9.083Epoch   0:  67% | abe: 9.144 | eve: 9.784 | bob: 9.082Epoch   0:  67% | abe: 9.143 | eve: 9.785 | bob: 9.081Epoch   0:  68% | abe: 9.142 | eve: 9.785 | bob: 9.081Epoch   0:  69% | abe: 9.142 | eve: 9.785 | bob: 9.081Epoch   0:  70% | abe: 9.141 | eve: 9.786 | bob: 9.080Epoch   0:  71% | abe: 9.141 | eve: 9.786 | bob: 9.079Epoch   0:  71% | abe: 9.140 | eve: 9.786 | bob: 9.078Epoch   0:  72% | abe: 9.138 | eve: 9.787 | bob: 9.077Epoch   0:  73% | abe: 9.137 | eve: 9.788 | bob: 9.076Epoch   0:  74% | abe: 9.136 | eve: 9.788 | bob: 9.075Epoch   0:  75% | abe: 9.136 | eve: 9.788 | bob: 9.075Epoch   0:  75% | abe: 9.135 | eve: 9.789 | bob: 9.074Epoch   0:  76% | abe: 9.134 | eve: 9.789 | bob: 9.073Epoch   0:  77% | abe: 9.134 | eve: 9.789 | bob: 9.072Epoch   0:  78% | abe: 9.133 | eve: 9.790 | bob: 9.072Epoch   0:  78% | abe: 9.133 | eve: 9.790 | bob: 9.071Epoch   0:  79% | abe: 9.132 | eve: 9.790 | bob: 9.070Epoch   0:  80% | abe: 9.131 | eve: 9.790 | bob: 9.069Epoch   0:  81% | abe: 9.130 | eve: 9.790 | bob: 9.069Epoch   0:  82% | abe: 9.130 | eve: 9.790 | bob: 9.068Epoch   0:  82% | abe: 9.130 | eve: 9.790 | bob: 9.068Epoch   0:  83% | abe: 9.129 | eve: 9.791 | bob: 9.067Epoch   0:  84% | abe: 9.129 | eve: 9.791 | bob: 9.067Epoch   0:  85% | abe: 9.129 | eve: 9.791 | bob: 9.067Epoch   0:  85% | abe: 9.128 | eve: 9.791 | bob: 9.066Epoch   0:  86% | abe: 9.127 | eve: 9.792 | bob: 9.066Epoch   0:  87% | abe: 9.126 | eve: 9.793 | bob: 9.065Epoch   0:  88% | abe: 9.127 | eve: 9.793 | bob: 9.065Epoch   0:  89% | abe: 9.127 | eve: 9.794 | bob: 9.065Epoch   0:  89% | abe: 9.127 | eve: 9.794 | bob: 9.065