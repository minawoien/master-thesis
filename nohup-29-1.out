WARNING:tensorflow:From /home/stud/minawoi/miniconda3/envs/conda-venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2024-04-11 15:48:30.783982: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-04-11 15:48:30.858670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:09:00.0
2024-04-11 15:48:30.859613: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-11 15:48:30.862168: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-04-11 15:48:30.864079: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-04-11 15:48:30.864946: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-04-11 15:48:30.867880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-04-11 15:48:30.870744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-04-11 15:48:30.876832: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-04-11 15:48:30.886341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-04-11 15:48:30.886898: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2024-04-11 15:48:30.898270: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199835000 Hz
2024-04-11 15:48:30.901180: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f0d670 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-04-11 15:48:30.901237: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-04-11 15:48:31.122876: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x48d6d70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-04-11 15:48:31.123048: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-04-11 15:48:31.131465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:09:00.0
2024-04-11 15:48:31.131570: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-11 15:48:31.131617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-04-11 15:48:31.131653: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-04-11 15:48:31.131688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-04-11 15:48:31.131724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-04-11 15:48:31.131785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-04-11 15:48:31.131853: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-04-11 15:48:31.138913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-04-11 15:48:31.139034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-11 15:48:31.143102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-04-11 15:48:31.143148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-04-11 15:48:31.143167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2024-04-11 15:48:31.149983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 25692 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:09:00.0, compute capability: 7.0)
WARNING:tensorflow:Output bob missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to bob.
WARNING:tensorflow:Output bob_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to bob_1.
WARNING:tensorflow:Output eve missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to eve.
WARNING:tensorflow:Output eve_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to eve_1.
2024-04-11 15:48:34.845397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
Train on 512 samples, validate on 512 samples
Epoch 1/512
512/512 - 1s - loss: 0.3975 - val_loss: 8.4153e-04
Epoch 2/512
512/512 - 0s - loss: 0.0399 - val_loss: 5.2591e-05
Epoch 3/512
512/512 - 0s - loss: 0.0029 - val_loss: 1.3641e-05
Epoch 4/512
512/512 - 0s - loss: 0.0012 - val_loss: 9.6781e-06
Epoch 5/512
512/512 - 0s - loss: 8.5057e-04 - val_loss: 6.6622e-06
Epoch 6/512
512/512 - 0s - loss: 5.6999e-04 - val_loss: 4.2252e-06
Epoch 7/512
512/512 - 0s - loss: 3.4991e-04 - val_loss: 2.4214e-06
Epoch 8/512
512/512 - 0s - loss: 1.9278e-04 - val_loss: 1.2228e-06
Epoch 9/512
512/512 - 0s - loss: 9.2791e-05 - val_loss: 5.2669e-07
Epoch 10/512
512/512 - 0s - loss: 3.7702e-05 - val_loss: 1.8522e-07
Epoch 11/512
512/512 - 0s - loss: 1.2358e-05 - val_loss: 5.0315e-08
Epoch 12/512
512/512 - 0s - loss: 3.1592e-06 - val_loss: 1.8982e-08
Epoch 13/512
512/512 - 0s - loss: 4.5623e-05 - val_loss: 1.0170e-05
Epoch 14/512
512/512 - 0s - loss: 0.0046 - val_loss: 1.4626e-05
Epoch 15/512
512/512 - 0s - loss: 6.2625e-04 - val_loss: 1.0005e-06
Epoch 16/512
512/512 - 0s - loss: 9.7019e-05 - val_loss: 1.6546e-06
Epoch 17/512
512/512 - 0s - loss: 5.5994e-04 - val_loss: 2.2779e-05
Epoch 18/512
512/512 - 0s - loss: 0.0029 - val_loss: 1.3219e-05
Epoch 19/512
512/512 - 0s - loss: 8.1352e-04 - val_loss: 3.8839e-06
Epoch 20/512
512/512 - 0s - loss: 4.7893e-04 - val_loss: 8.6695e-06
Epoch 21/512
512/512 - 0s - loss: 0.0015 - val_loss: 1.9710e-05
Epoch 22/512
512/512 - 0s - loss: 0.0016 - val_loss: 8.2024e-06
Epoch 23/512
512/512 - 0s - loss: 7.4437e-04 - val_loss: 7.2931e-06
Epoch 24/512
512/512 - 0s - loss: 9.8876e-04 - val_loss: 1.3643e-05
Epoch 25/512
512/512 - 0s - loss: 0.0015 - val_loss: 1.1592e-05
Epoch 26/512
512/512 - 0s - loss: 0.0010 - val_loss: 8.0372e-06
Epoch 27/512
512/512 - 0s - loss: 8.8268e-04 - val_loss: 1.0248e-05
Epoch 28/512
512/512 - 0s - loss: 0.0012 - val_loss: 1.1862e-05
Epoch 29/512
512/512 - 0s - loss: 0.0011 - val_loss: 9.0008e-06
Epoch 30/512
512/512 - 0s - loss: 8.9982e-04 - val_loss: 8.9912e-06
Epoch 31/512
512/512 - 0s - loss: 0.0010 - val_loss: 1.0700e-05
Epoch 32/512
512/512 - 0s - loss: 0.0011 - val_loss: 9.6425e-06
Epoch 33/512
512/512 - 0s - loss: 9.4361e-04 - val_loss: 8.6429e-06
Epoch 34/512
512/512 - 0s - loss: 9.1681e-04 - val_loss: 9.4024e-06
Epoch 35/512
512/512 - 0s - loss: 9.9551e-04 - val_loss: 9.4935e-06
Epoch 36/512
512/512 - 0s - loss: 9.4970e-04 - val_loss: 8.6076e-06
Epoch 37/512
512/512 - 0s - loss: 8.8553e-04 - val_loss: 8.6635e-06
Epoch 38/512
512/512 - 0s - loss: 9.0692e-04 - val_loss: 9.2026e-06
Epoch 39/512
512/512 - 0s - loss: 9.4306e-04 - val_loss: 8.4286e-06
Epoch 40/512
512/512 - 0s - loss: 8.4573e-04 - val_loss: 8.1791e-06
Epoch 41/512
512/512 - 0s - loss: 8.6358e-04 - val_loss: 8.5905e-06
Epoch 42/512
512/512 - 0s - loss: 8.7972e-04 - val_loss: 8.4309e-06
Epoch 43/512
512/512 - 0s - loss: 8.4732e-04 - val_loss: 7.9826e-06
Epoch 44/512
512/512 - 0s - loss: 8.1607e-04 - val_loss: 8.0118e-06
Epoch 45/512
512/512 - 0s - loss: 8.2652e-04 - val_loss: 8.0423e-06
Epoch 46/512
512/512 - 0s - loss: 8.2287e-04 - val_loss: 7.7495e-06
Epoch 47/512
512/512 - 0s - loss: 7.8555e-04 - val_loss: 7.6418e-06
Epoch 48/512
512/512 - 0s - loss: 7.8770e-04 - val_loss: 7.7410e-06
Epoch 49/512
512/512 - 0s - loss: 7.8979e-04 - val_loss: 7.4864e-06
Epoch 50/512
512/512 - 0s - loss: 7.5330e-04 - val_loss: 7.3372e-06
Epoch 51/512
512/512 - 0s - loss: 7.5100e-04 - val_loss: 7.5343e-06
Epoch 52/512
512/512 - 0s - loss: 7.6227e-04 - val_loss: 7.2883e-06
Epoch 53/512
512/512 - 0s - loss: 7.3029e-04 - val_loss: 7.0348e-06
Epoch 54/512
512/512 - 0s - loss: 7.1734e-04 - val_loss: 7.0633e-06
Epoch 55/512
512/512 - 0s - loss: 7.1451e-04 - val_loss: 7.1740e-06
Epoch 56/512
512/512 - 0s - loss: 7.1814e-04 - val_loss: 6.9726e-06
Epoch 57/512
512/512 - 0s - loss: 6.9635e-04 - val_loss: 6.6637e-06
Epoch 58/512
512/512 - 0s - loss: 6.7540e-04 - val_loss: 6.7459e-06
Epoch 59/512
512/512 - 0s - loss: 6.8850e-04 - val_loss: 6.6930e-06
Epoch 60/512
512/512 - 0s - loss: 6.6821e-04 - val_loss: 6.5305e-06
Epoch 61/512
512/512 - 0s - loss: 6.5821e-04 - val_loss: 6.4911e-06
Epoch 62/512
512/512 - 0s - loss: 6.5439e-04 - val_loss: 6.3688e-06
Epoch 63/512
512/512 - 0s - loss: 6.4349e-04 - val_loss: 6.2842e-06
Epoch 64/512
512/512 - 0s - loss: 6.3520e-04 - val_loss: 6.1910e-06
Epoch 65/512
512/512 - 0s - loss: 6.2470e-04 - val_loss: 6.1582e-06
Epoch 66/512
512/512 - 0s - loss: 6.1811e-04 - val_loss: 6.1409e-06
Epoch 67/512
512/512 - 0s - loss: 6.1577e-04 - val_loss: 5.9997e-06
Epoch 68/512
512/512 - 0s - loss: 6.0156e-04 - val_loss: 5.8649e-06
Epoch 69/512
512/512 - 0s - loss: 5.9200e-04 - val_loss: 5.8495e-06
Epoch 70/512
512/512 - 0s - loss: 5.8873e-04 - val_loss: 5.8311e-06
Epoch 71/512
512/512 - 0s - loss: 5.8540e-04 - val_loss: 5.6226e-06
Epoch 72/512
512/512 - 0s - loss: 5.6387e-04 - val_loss: 5.5966e-06
Epoch 73/512
512/512 - 0s - loss: 5.6217e-04 - val_loss: 5.6897e-06
Epoch 74/512
512/512 - 0s - loss: 5.7351e-04 - val_loss: 5.3821e-06
Epoch 75/512
512/512 - 0s - loss: 5.3675e-04 - val_loss: 5.3049e-06
Epoch 76/512
512/512 - 0s - loss: 5.3868e-04 - val_loss: 5.4698e-06
Epoch 77/512
512/512 - 0s - loss: 5.4701e-04 - val_loss: 5.3390e-06
Epoch 78/512
512/512 - 0s - loss: 5.3094e-04 - val_loss: 5.0434e-06
Epoch 79/512
512/512 - 0s - loss: 5.0932e-04 - val_loss: 5.0791e-06
Epoch 80/512
512/512 - 0s - loss: 5.1420e-04 - val_loss: 5.2898e-06
Epoch 81/512
512/512 - 0s - loss: 5.2225e-04 - val_loss: 5.0518e-06
Epoch 82/512
512/512 - 0s - loss: 4.9507e-04 - val_loss: 4.8319e-06
Epoch 83/512
512/512 - 0s - loss: 4.8831e-04 - val_loss: 4.8985e-06
Epoch 84/512
512/512 - 0s - loss: 4.9035e-04 - val_loss: 4.9377e-06
Epoch 85/512
512/512 - 0s - loss: 4.8925e-04 - val_loss: 4.7271e-06
Epoch 86/512
512/512 - 0s - loss: 4.6788e-04 - val_loss: 4.6229e-06
Epoch 87/512
512/512 - 0s - loss: 4.6604e-04 - val_loss: 4.6965e-06
Epoch 88/512
512/512 - 0s - loss: 4.6808e-04 - val_loss: 4.5943e-06
Epoch 89/512
512/512 - 0s - loss: 4.5080e-04 - val_loss: 4.5259e-06
Epoch 90/512
512/512 - 0s - loss: 4.4872e-04 - val_loss: 4.5244e-06
Epoch 91/512
512/512 - 0s - loss: 4.4684e-04 - val_loss: 4.4202e-06
Epoch 92/512
512/512 - 0s - loss: 4.3637e-04 - val_loss: 4.2755e-06
Epoch 93/512
512/512 - 0s - loss: 4.2885e-04 - val_loss: 4.2270e-06
Epoch 94/512
512/512 - 0s - loss: 4.2067e-04 - val_loss: 4.2391e-06
Epoch 95/512
512/512 - 0s - loss: 4.2349e-04 - val_loss: 4.1506e-06
Epoch 96/512
512/512 - 0s - loss: 4.1202e-04 - val_loss: 3.9989e-06
Epoch 97/512
512/512 - 0s - loss: 3.9610e-04 - val_loss: 4.1032e-06
Epoch 98/512
512/512 - 0s - loss: 4.0940e-04 - val_loss: 4.0604e-06
Epoch 99/512
512/512 - 0s - loss: 3.9608e-04 - val_loss: 3.8219e-06
Epoch 100/512
512/512 - 0s - loss: 3.7981e-04 - val_loss: 3.8075e-06
Epoch 101/512
512/512 - 0s - loss: 3.8356e-04 - val_loss: 3.8248e-06
Epoch 102/512
512/512 - 0s - loss: 3.7693e-04 - val_loss: 3.7635e-06
Epoch 103/512
512/512 - 0s - loss: 3.6757e-04 - val_loss: 3.7438e-06
Epoch 104/512
512/512 - 0s - loss: 3.6761e-04 - val_loss: 3.6659e-06
Epoch 105/512
512/512 - 0s - loss: 3.6091e-04 - val_loss: 3.5334e-06
Epoch 106/512
512/512 - 0s - loss: 3.4653e-04 - val_loss: 3.5394e-06
Epoch 107/512
512/512 - 0s - loss: 3.5027e-04 - val_loss: 3.5210e-06
Epoch 108/512
512/512 - 0s - loss: 3.4775e-04 - val_loss: 3.3042e-06
Epoch 109/512
512/512 - 0s - loss: 3.2370e-04 - val_loss: 3.3520e-06
Epoch 110/512
512/512 - 0s - loss: 3.3580e-04 - val_loss: 3.4085e-06
Epoch 111/512
512/512 - 0s - loss: 3.3214e-04 - val_loss: 3.1690e-06
Epoch 112/512
512/512 - 0s - loss: 3.1310e-04 - val_loss: 3.0448e-06
Epoch 113/512
512/512 - 0s - loss: 3.0868e-04 - val_loss: 3.1433e-06
Epoch 114/512
512/512 - 0s - loss: 3.1579e-04 - val_loss: 3.0923e-06
Epoch 115/512
512/512 - 0s - loss: 3.0141e-04 - val_loss: 2.9556e-06
Epoch 116/512
512/512 - 0s - loss: 2.9299e-04 - val_loss: 2.9780e-06
Epoch 117/512
512/512 - 0s - loss: 2.9476e-04 - val_loss: 2.9663e-06
Epoch 118/512
512/512 - 0s - loss: 2.8987e-04 - val_loss: 2.8596e-06
Epoch 119/512
512/512 - 0s - loss: 2.7862e-04 - val_loss: 2.7923e-06
Epoch 120/512
512/512 - 0s - loss: 2.7643e-04 - val_loss: 2.7758e-06
Epoch 121/512
512/512 - 0s - loss: 2.7298e-04 - val_loss: 2.7085e-06
Epoch 122/512
512/512 - 0s - loss: 2.6720e-04 - val_loss: 2.6194e-06
Epoch 123/512
512/512 - 0s - loss: 2.5746e-04 - val_loss: 2.6099e-06
Epoch 124/512
512/512 - 0s - loss: 2.5763e-04 - val_loss: 2.5910e-06
Epoch 125/512
512/512 - 0s - loss: 2.5429e-04 - val_loss: 2.4644e-06
Epoch 126/512
512/512 - 0s - loss: 2.4194e-04 - val_loss: 2.4296e-06
Epoch 127/512
512/512 - 0s - loss: 2.3984e-04 - val_loss: 2.4810e-06
Epoch 128/512
512/512 - 0s - loss: 2.4305e-04 - val_loss: 2.3769e-06
Epoch 129/512
512/512 - 0s - loss: 2.2896e-04 - val_loss: 2.2559e-06
Epoch 130/512
512/512 - 0s - loss: 2.2361e-04 - val_loss: 2.2850e-06
Epoch 131/512
512/512 - 0s - loss: 2.2570e-04 - val_loss: 2.2381e-06
Epoch 132/512
512/512 - 0s - loss: 2.1671e-04 - val_loss: 2.1600e-06
Epoch 133/512
512/512 - 0s - loss: 2.1236e-04 - val_loss: 2.1368e-06
Epoch 134/512
512/512 - 0s - loss: 2.0878e-04 - val_loss: 2.1009e-06
Epoch 135/512
512/512 - 0s - loss: 2.0461e-04 - val_loss: 2.0435e-06
Epoch 136/512
512/512 - 0s - loss: 1.9918e-04 - val_loss: 1.9883e-06
Epoch 137/512
512/512 - 0s - loss: 1.9526e-04 - val_loss: 1.9347e-06
Epoch 138/512
512/512 - 0s - loss: 1.8979e-04 - val_loss: 1.9094e-06
Epoch 139/512
512/512 - 0s - loss: 1.8701e-04 - val_loss: 1.8856e-06
Epoch 140/512
512/512 - 0s - loss: 1.8218e-04 - val_loss: 1.8400e-06
Epoch 141/512
512/512 - 0s - loss: 1.7881e-04 - val_loss: 1.7833e-06
Epoch 142/512
512/512 - 0s - loss: 1.7435e-04 - val_loss: 1.7126e-06
Epoch 143/512
512/512 - 0s - loss: 1.6775e-04 - val_loss: 1.7029e-06
Epoch 144/512
512/512 - 0s - loss: 1.6739e-04 - val_loss: 1.6847e-06
Epoch 145/512
512/512 - 0s - loss: 1.6256e-04 - val_loss: 1.6158e-06
Epoch 146/512
512/512 - 0s - loss: 1.5742e-04 - val_loss: 1.5637e-06
Epoch 147/512
512/512 - 0s - loss: 1.5290e-04 - val_loss: 1.5604e-06
Epoch 148/512
512/512 - 0s - loss: 1.5158e-04 - val_loss: 1.5460e-06
Epoch 149/512
512/512 - 0s - loss: 1.4925e-04 - val_loss: 1.4561e-06
Epoch 150/512
512/512 - 0s - loss: 1.3998e-04 - val_loss: 1.4188e-06
Epoch 151/512
512/512 - 0s - loss: 1.4027e-04 - val_loss: 1.4132e-06
Epoch 152/512
512/512 - 0s - loss: 1.3711e-04 - val_loss: 1.3600e-06
Epoch 153/512
512/512 - 0s - loss: 1.3165e-04 - val_loss: 1.3181e-06
Epoch 154/512
512/512 - 0s - loss: 1.2881e-04 - val_loss: 1.2971e-06
Epoch 155/512
512/512 - 0s - loss: 1.2579e-04 - val_loss: 1.2828e-06
Epoch 156/512
512/512 - 0s - loss: 1.2416e-04 - val_loss: 1.2197e-06
Epoch 157/512
512/512 - 0s - loss: 1.1776e-04 - val_loss: 1.1703e-06
Epoch 158/512
512/512 - 0s - loss: 1.1485e-04 - val_loss: 1.1791e-06
Epoch 159/512
512/512 - 0s - loss: 1.1464e-04 - val_loss: 1.1569e-06
Epoch 160/512
512/512 - 0s - loss: 1.1114e-04 - val_loss: 1.0725e-06
Epoch 161/512
512/512 - 0s - loss: 1.0401e-04 - val_loss: 1.0585e-06
Epoch 162/512
512/512 - 0s - loss: 1.0496e-04 - val_loss: 1.0569e-06
Epoch 163/512
512/512 - 0s - loss: 1.0176e-04 - val_loss: 1.0125e-06
Epoch 164/512
512/512 - 0s - loss: 9.6830e-05 - val_loss: 9.9172e-07
Epoch 165/512
512/512 - 0s - loss: 9.6493e-05 - val_loss: 9.6196e-07
Epoch 166/512
512/512 - 0s - loss: 9.2939e-05 - val_loss: 9.1698e-07
Epoch 167/512
512/512 - 0s - loss: 8.8876e-05 - val_loss: 9.0479e-07
Epoch 168/512
512/512 - 0s - loss: 8.7602e-05 - val_loss: 9.0198e-07
Epoch 169/512
512/512 - 0s - loss: 8.5342e-05 - val_loss: 8.7161e-07
Epoch 170/512
512/512 - 0s - loss: 8.3248e-05 - val_loss: 8.2154e-07
Epoch 171/512
512/512 - 0s - loss: 7.8853e-05 - val_loss: 7.9619e-07
Epoch 172/512
512/512 - 0s - loss: 7.7656e-05 - val_loss: 7.8539e-07
Epoch 173/512
512/512 - 0s - loss: 7.5791e-05 - val_loss: 7.5807e-07
Epoch 174/512
512/512 - 0s - loss: 7.2885e-05 - val_loss: 7.2960e-07
Epoch 175/512
512/512 - 0s - loss: 7.0708e-05 - val_loss: 7.0795e-07
Epoch 176/512
512/512 - 0s - loss: 6.8662e-05 - val_loss: 6.8727e-07
Epoch 177/512
512/512 - 0s - loss: 6.5818e-05 - val_loss: 6.7677e-07
Epoch 178/512
512/512 - 0s - loss: 6.5778e-05 - val_loss: 6.4572e-07
Epoch 179/512
512/512 - 0s - loss: 6.1592e-05 - val_loss: 6.1519e-07
Epoch 180/512
512/512 - 0s - loss: 5.9837e-05 - val_loss: 6.1710e-07
Epoch 181/512
512/512 - 0s - loss: 5.9215e-05 - val_loss: 6.0296e-07
Epoch 182/512
512/512 - 0s - loss: 5.6815e-05 - val_loss: 5.7607e-07
Epoch 183/512
512/512 - 0s - loss: 5.4816e-05 - val_loss: 5.5293e-07
Epoch 184/512
512/512 - 0s - loss: 5.3123e-05 - val_loss: 5.3448e-07
Epoch 185/512
512/512 - 0s - loss: 5.1273e-05 - val_loss: 5.1879e-07
Epoch 186/512
512/512 - 0s - loss: 4.9571e-05 - val_loss: 5.0554e-07
Epoch 187/512
512/512 - 0s - loss: 4.8547e-05 - val_loss: 4.8431e-07
Epoch 188/512
512/512 - 0s - loss: 4.6108e-05 - val_loss: 4.6450e-07
Epoch 189/512
512/512 - 0s - loss: 4.4729e-05 - val_loss: 4.5722e-07
Epoch 190/512
512/512 - 0s - loss: 4.3936e-05 - val_loss: 4.3884e-07
Epoch 191/512
512/512 - 0s - loss: 4.1830e-05 - val_loss: 4.1958e-07
Epoch 192/512
512/512 - 0s - loss: 3.9977e-05 - val_loss: 4.1656e-07
Epoch 193/512
512/512 - 0s - loss: 3.9790e-05 - val_loss: 4.0320e-07
Epoch 194/512
512/512 - 0s - loss: 3.8101e-05 - val_loss: 3.7477e-07
Epoch 195/512
512/512 - 0s - loss: 3.5951e-05 - val_loss: 3.6292e-07
Epoch 196/512
512/512 - 0s - loss: 3.5193e-05 - val_loss: 3.6209e-07
Epoch 197/512
512/512 - 0s - loss: 3.4260e-05 - val_loss: 3.4955e-07
Epoch 198/512
512/512 - 0s - loss: 3.3139e-05 - val_loss: 3.2848e-07
Epoch 199/512
512/512 - 0s - loss: 3.1560e-05 - val_loss: 3.1248e-07
Epoch 200/512
512/512 - 0s - loss: 3.0329e-05 - val_loss: 3.0416e-07
Epoch 201/512
512/512 - 0s - loss: 2.9225e-05 - val_loss: 3.0417e-07
Epoch 202/512
512/512 - 0s - loss: 2.8997e-05 - val_loss: 2.9095e-07
Epoch 203/512
512/512 - 0s - loss: 2.7438e-05 - val_loss: 2.7070e-07
Epoch 204/512
512/512 - 0s - loss: 2.5862e-05 - val_loss: 2.6789e-07
Epoch 205/512
512/512 - 0s - loss: 2.5902e-05 - val_loss: 2.6097e-07
Epoch 206/512
512/512 - 0s - loss: 2.4549e-05 - val_loss: 2.4453e-07
Epoch 207/512
512/512 - 0s - loss: 2.3286e-05 - val_loss: 2.4014e-07
Epoch 208/512
512/512 - 0s - loss: 2.3028e-05 - val_loss: 2.3277e-07
Epoch 209/512
512/512 - 0s - loss: 2.1811e-05 - val_loss: 2.2424e-07
Epoch 210/512
512/512 - 0s - loss: 2.1323e-05 - val_loss: 2.1313e-07
Epoch 211/512
512/512 - 0s - loss: 2.0214e-05 - val_loss: 2.0305e-07
Epoch 212/512
512/512 - 0s - loss: 1.9363e-05 - val_loss: 2.0060e-07
Epoch 213/512
512/512 - 0s - loss: 1.9138e-05 - val_loss: 1.9303e-07
Epoch 214/512
512/512 - 0s - loss: 1.8195e-05 - val_loss: 1.7976e-07
Epoch 215/512
512/512 - 0s - loss: 1.7139e-05 - val_loss: 1.7490e-07
Epoch 216/512
512/512 - 0s - loss: 1.6754e-05 - val_loss: 1.7450e-07
Epoch 217/512
512/512 - 0s - loss: 1.6419e-05 - val_loss: 1.6479e-07
Epoch 218/512
512/512 - 0s - loss: 1.5360e-05 - val_loss: 1.5474e-07
Epoch 219/512
512/512 - 0s - loss: 1.4844e-05 - val_loss: 1.5022e-07
Epoch 220/512
512/512 - 0s - loss: 1.4208e-05 - val_loss: 1.4956e-07
Epoch 221/512
512/512 - 0s - loss: 1.4007e-05 - val_loss: 1.4303e-07
Epoch 222/512
512/512 - 0s - loss: 1.3256e-05 - val_loss: 1.3315e-07
Epoch 223/512
512/512 - 0s - loss: 1.2520e-05 - val_loss: 1.2965e-07
Epoch 224/512
512/512 - 0s - loss: 1.2349e-05 - val_loss: 1.2579e-07
Epoch 225/512
512/512 - 0s - loss: 1.1871e-05 - val_loss: 1.1641e-07
Epoch 226/512
512/512 - 0s - loss: 1.0985e-05 - val_loss: 1.1360e-07
Epoch 227/512
512/512 - 0s - loss: 1.0905e-05 - val_loss: 1.1136e-07
Epoch 228/512
512/512 - 0s - loss: 1.0503e-05 - val_loss: 1.0444e-07
Epoch 229/512
512/512 - 0s - loss: 9.8269e-06 - val_loss: 1.0148e-07
Epoch 230/512
512/512 - 0s - loss: 9.5699e-06 - val_loss: 9.9477e-08
Epoch 231/512
512/512 - 0s - loss: 9.3635e-06 - val_loss: 9.2710e-08
Epoch 232/512
512/512 - 0s - loss: 8.6637e-06 - val_loss: 8.7921e-08
Epoch 233/512
512/512 - 0s - loss: 8.4519e-06 - val_loss: 8.6058e-08
Epoch 234/512
512/512 - 0s - loss: 8.1056e-06 - val_loss: 8.3233e-08
Epoch 235/512
512/512 - 0s - loss: 7.7995e-06 - val_loss: 7.9578e-08
Epoch 236/512
512/512 - 0s - loss: 7.4871e-06 - val_loss: 7.4877e-08
Epoch 237/512
512/512 - 0s - loss: 7.0640e-06 - val_loss: 7.2846e-08
Epoch 238/512
512/512 - 0s - loss: 6.8874e-06 - val_loss: 7.0829e-08
Epoch 239/512
512/512 - 0s - loss: 6.6294e-06 - val_loss: 6.6532e-08
Epoch 240/512
512/512 - 0s - loss: 6.2265e-06 - val_loss: 6.3452e-08
Epoch 241/512
512/512 - 0s - loss: 6.0053e-06 - val_loss: 6.2187e-08
Epoch 242/512
512/512 - 0s - loss: 5.8257e-06 - val_loss: 5.9293e-08
Epoch 243/512
512/512 - 0s - loss: 5.5355e-06 - val_loss: 5.5857e-08
Epoch 244/512
512/512 - 0s - loss: 5.2568e-06 - val_loss: 5.4058e-08
Epoch 245/512
512/512 - 0s - loss: 5.0915e-06 - val_loss: 5.2327e-08
Epoch 246/512
512/512 - 0s - loss: 4.8884e-06 - val_loss: 4.9638e-08
Epoch 247/512
512/512 - 0s - loss: 4.6218e-06 - val_loss: 4.7524e-08
Epoch 248/512
512/512 - 0s - loss: 4.4235e-06 - val_loss: 4.6366e-08
Epoch 249/512
512/512 - 0s - loss: 4.3456e-06 - val_loss: 4.3743e-08
Epoch 250/512
512/512 - 0s - loss: 4.0385e-06 - val_loss: 4.1245e-08
Epoch 251/512
512/512 - 0s - loss: 3.9105e-06 - val_loss: 3.9567e-08
Epoch 252/512
512/512 - 0s - loss: 3.7075e-06 - val_loss: 3.8371e-08
Epoch 253/512
512/512 - 0s - loss: 3.6294e-06 - val_loss: 3.6394e-08
Epoch 254/512
512/512 - 0s - loss: 3.3520e-06 - val_loss: 3.4935e-08
Epoch 255/512
512/512 - 0s - loss: 3.2989e-06 - val_loss: 3.4192e-08
Epoch 256/512
512/512 - 0s - loss: 3.1732e-06 - val_loss: 3.1556e-08
Epoch 257/512
512/512 - 0s - loss: 2.9517e-06 - val_loss: 2.9700e-08
Epoch 258/512
512/512 - 0s - loss: 2.7923e-06 - val_loss: 3.0147e-08
Epoch 259/512
512/512 - 0s - loss: 2.8363e-06 - val_loss: 2.8846e-08
Epoch 260/512
512/512 - 0s - loss: 2.5978e-06 - val_loss: 2.6156e-08
Epoch 261/512
512/512 - 0s - loss: 2.4501e-06 - val_loss: 2.5520e-08
Epoch 262/512
512/512 - 0s - loss: 2.4244e-06 - val_loss: 2.4764e-08
Epoch 263/512
512/512 - 0s - loss: 2.2832e-06 - val_loss: 2.3128e-08
Epoch 264/512
512/512 - 0s - loss: 2.1827e-06 - val_loss: 2.1538e-08
Epoch 265/512
512/512 - 0s - loss: 2.0262e-06 - val_loss: 2.1484e-08
Epoch 266/512
512/512 - 0s - loss: 2.0152e-06 - val_loss: 2.1407e-08
Epoch 267/512
512/512 - 0s - loss: 1.9650e-06 - val_loss: 1.9004e-08
Epoch 268/512
512/512 - 0s - loss: 1.7419e-06 - val_loss: 1.7778e-08
Epoch 269/512
512/512 - 0s - loss: 1.7078e-06 - val_loss: 1.8596e-08
Epoch 270/512
512/512 - 0s - loss: 1.7242e-06 - val_loss: 1.7366e-08
Epoch 271/512
512/512 - 0s - loss: 1.5636e-06 - val_loss: 1.5659e-08
Epoch 272/512
512/512 - 0s - loss: 1.4731e-06 - val_loss: 1.5482e-08
Epoch 273/512
512/512 - 0s - loss: 1.4572e-06 - val_loss: 1.5115e-08
Epoch 274/512
512/512 - 0s - loss: 1.3921e-06 - val_loss: 1.3966e-08
Epoch 275/512
512/512 - 0s - loss: 1.2945e-06 - val_loss: 1.3097e-08
Epoch 276/512
512/512 - 0s - loss: 1.2250e-06 - val_loss: 1.3192e-08
Epoch 277/512
512/512 - 0s - loss: 1.2292e-06 - val_loss: 1.2534e-08
Epoch 278/512
512/512 - 0s - loss: 1.1331e-06 - val_loss: 1.1574e-08
Epoch 279/512
512/512 - 0s - loss: 1.0813e-06 - val_loss: 1.1068e-08
Epoch 280/512
512/512 - 0s - loss: 1.0299e-06 - val_loss: 1.0700e-08
Epoch 281/512
512/512 - 0s - loss: 9.8949e-07 - val_loss: 1.0383e-08
Epoch 282/512
512/512 - 0s - loss: 9.5884e-07 - val_loss: 9.5759e-09
Epoch 283/512
512/512 - 0s - loss: 8.8342e-07 - val_loss: 9.1039e-09
Epoch 284/512
512/512 - 0s - loss: 8.5048e-07 - val_loss: 8.9898e-09
Epoch 285/512
512/512 - 0s - loss: 8.2758e-07 - val_loss: 8.5768e-09
Epoch 286/512
512/512 - 0s - loss: 7.8182e-07 - val_loss: 8.0231e-09
Epoch 287/512
512/512 - 0s - loss: 7.3268e-07 - val_loss: 7.6763e-09
Epoch 288/512
512/512 - 0s - loss: 7.1491e-07 - val_loss: 7.2773e-09
Epoch 289/512
512/512 - 0s - loss: 6.7553e-07 - val_loss: 6.8177e-09
Epoch 290/512
512/512 - 0s - loss: 6.3656e-07 - val_loss: 6.5515e-09
Epoch 291/512
512/512 - 0s - loss: 6.1387e-07 - val_loss: 6.3556e-09
Epoch 292/512
512/512 - 0s - loss: 5.8735e-07 - val_loss: 6.0313e-09
Epoch 293/512
512/512 - 0s - loss: 5.5687e-07 - val_loss: 5.6368e-09
Epoch 294/512
512/512 - 0s - loss: 5.2605e-07 - val_loss: 5.4086e-09
Epoch 295/512
512/512 - 0s - loss: 5.0556e-07 - val_loss: 5.1993e-09
Epoch 296/512
512/512 - 0s - loss: 4.8181e-07 - val_loss: 4.9722e-09
Epoch 297/512
512/512 - 0s - loss: 4.5846e-07 - val_loss: 4.7032e-09
Epoch 298/512
512/512 - 0s - loss: 4.3356e-07 - val_loss: 4.5227e-09
Epoch 299/512
512/512 - 0s - loss: 4.1474e-07 - val_loss: 4.3589e-09
Epoch 300/512
512/512 - 0s - loss: 3.9885e-07 - val_loss: 4.1468e-09
Epoch 301/512
512/512 - 0s - loss: 3.7740e-07 - val_loss: 3.8818e-09
Epoch 302/512
512/512 - 0s - loss: 3.5698e-07 - val_loss: 3.7145e-09
Epoch 303/512
512/512 - 0s - loss: 3.4101e-07 - val_loss: 3.5598e-09
Epoch 304/512
512/512 - 0s - loss: 3.2725e-07 - val_loss: 3.4055e-09
Epoch 305/512
512/512 - 0s - loss: 3.1011e-07 - val_loss: 3.1858e-09
Epoch 306/512
512/512 - 0s - loss: 2.9148e-07 - val_loss: 3.0954e-09
Epoch 307/512
512/512 - 0s - loss: 2.8562e-07 - val_loss: 2.9181e-09
Epoch 308/512
512/512 - 0s - loss: 2.6705e-07 - val_loss: 2.6844e-09
Epoch 309/512
512/512 - 0s - loss: 2.4722e-07 - val_loss: 2.6574e-09
Epoch 310/512
512/512 - 0s - loss: 2.4774e-07 - val_loss: 2.5668e-09
Epoch 311/512
512/512 - 0s - loss: 2.3488e-07 - val_loss: 2.2721e-09
Epoch 312/512
512/512 - 0s - loss: 2.1011e-07 - val_loss: 2.2137e-09
Epoch 313/512
512/512 - 0s - loss: 2.0910e-07 - val_loss: 2.2455e-09
Epoch 314/512
512/512 - 0s - loss: 2.0820e-07 - val_loss: 2.0134e-09
Epoch 315/512
512/512 - 0s - loss: 1.8176e-07 - val_loss: 1.8721e-09
Epoch 316/512
512/512 - 0s - loss: 1.7629e-07 - val_loss: 1.9198e-09
Epoch 317/512
512/512 - 0s - loss: 1.7845e-07 - val_loss: 1.8196e-09
Epoch 318/512
512/512 - 0s - loss: 1.6345e-07 - val_loss: 1.5977e-09
Epoch 319/512
512/512 - 0s - loss: 1.4729e-07 - val_loss: 1.5979e-09
Epoch 320/512
512/512 - 0s - loss: 1.5103e-07 - val_loss: 1.5984e-09
Epoch 321/512
512/512 - 0s - loss: 1.4331e-07 - val_loss: 1.4411e-09
Epoch 322/512
512/512 - 0s - loss: 1.2953e-07 - val_loss: 1.3656e-09
Epoch 323/512
512/512 - 0s - loss: 1.2707e-07 - val_loss: 1.3531e-09
Epoch 324/512
512/512 - 0s - loss: 1.2405e-07 - val_loss: 1.2545e-09
Epoch 325/512
512/512 - 0s - loss: 1.1376e-07 - val_loss: 1.1485e-09
Epoch 326/512
512/512 - 0s - loss: 1.0783e-07 - val_loss: 1.1275e-09
Epoch 327/512
512/512 - 0s - loss: 1.0417e-07 - val_loss: 1.1100e-09
Epoch 328/512
512/512 - 0s - loss: 1.0086e-07 - val_loss: 1.0333e-09
Epoch 329/512
512/512 - 0s - loss: 9.4045e-08 - val_loss: 9.5339e-10
Epoch 330/512
512/512 - 0s - loss: 8.8469e-08 - val_loss: 9.2226e-10
Epoch 331/512
512/512 - 0s - loss: 8.5478e-08 - val_loss: 8.9598e-10
Epoch 332/512
512/512 - 0s - loss: 8.1703e-08 - val_loss: 8.4752e-10
Epoch 333/512
512/512 - 0s - loss: 7.7489e-08 - val_loss: 7.9269e-10
Epoch 334/512
512/512 - 0s - loss: 7.3041e-08 - val_loss: 7.5532e-10
Epoch 335/512
512/512 - 0s - loss: 7.0254e-08 - val_loss: 7.1992e-10
Epoch 336/512
512/512 - 0s - loss: 6.6017e-08 - val_loss: 6.9374e-10
Epoch 337/512
512/512 - 0s - loss: 6.4259e-08 - val_loss: 6.5859e-10
Epoch 338/512
512/512 - 0s - loss: 5.9548e-08 - val_loss: 6.2436e-10
Epoch 339/512
512/512 - 0s - loss: 5.7615e-08 - val_loss: 6.0177e-10
Epoch 340/512
512/512 - 0s - loss: 5.5378e-08 - val_loss: 5.6267e-10
Epoch 341/512
512/512 - 0s - loss: 5.1518e-08 - val_loss: 5.3211e-10
Epoch 342/512
512/512 - 0s - loss: 4.8982e-08 - val_loss: 5.1802e-10
Epoch 343/512
512/512 - 0s - loss: 4.7669e-08 - val_loss: 4.9965e-10
Epoch 344/512
512/512 - 0s - loss: 4.5165e-08 - val_loss: 4.6915e-10
Epoch 345/512
512/512 - 0s - loss: 4.2843e-08 - val_loss: 4.4361e-10
Epoch 346/512
512/512 - 0s - loss: 4.0595e-08 - val_loss: 4.1961e-10
Epoch 347/512
512/512 - 0s - loss: 3.8596e-08 - val_loss: 4.0157e-10
Epoch 348/512
512/512 - 0s - loss: 3.7127e-08 - val_loss: 3.8502e-10
Epoch 349/512
512/512 - 0s - loss: 3.5423e-08 - val_loss: 3.6310e-10
Epoch 350/512
512/512 - 0s - loss: 3.3128e-08 - val_loss: 3.4863e-10
Epoch 351/512
512/512 - 0s - loss: 3.1973e-08 - val_loss: 3.3888e-10
Epoch 352/512
512/512 - 0s - loss: 3.1013e-08 - val_loss: 3.1741e-10
Epoch 353/512
512/512 - 0s - loss: 2.8853e-08 - val_loss: 3.0130e-10
Epoch 354/512
512/512 - 0s - loss: 2.7649e-08 - val_loss: 2.9182e-10
Epoch 355/512
512/512 - 0s - loss: 2.6739e-08 - val_loss: 2.7539e-10
Epoch 356/512
512/512 - 0s - loss: 2.5205e-08 - val_loss: 2.5881e-10
Epoch 357/512
512/512 - 0s - loss: 2.3778e-08 - val_loss: 2.5018e-10
Epoch 358/512
512/512 - 0s - loss: 2.3030e-08 - val_loss: 2.4187e-10
Epoch 359/512
512/512 - 0s - loss: 2.2065e-08 - val_loss: 2.2816e-10
Epoch 360/512
512/512 - 0s - loss: 2.0782e-08 - val_loss: 2.1449e-10
Epoch 361/512
512/512 - 0s - loss: 1.9915e-08 - val_loss: 2.0673e-10
Epoch 362/512
512/512 - 0s - loss: 1.9033e-08 - val_loss: 1.9791e-10
Epoch 363/512
512/512 - 0s - loss: 1.8010e-08 - val_loss: 1.9133e-10
Epoch 364/512
512/512 - 0s - loss: 1.7607e-08 - val_loss: 1.8328e-10
Epoch 365/512
512/512 - 0s - loss: 1.6778e-08 - val_loss: 1.7192e-10
Epoch 366/512
512/512 - 0s - loss: 1.5873e-08 - val_loss: 1.5948e-10
Epoch 367/512
512/512 - 0s - loss: 1.4765e-08 - val_loss: 1.5602e-10
Epoch 368/512
512/512 - 0s - loss: 1.4521e-08 - val_loss: 1.5475e-10
Epoch 369/512
512/512 - 0s - loss: 1.4142e-08 - val_loss: 1.4672e-10
Epoch 370/512
512/512 - 0s - loss: 1.3373e-08 - val_loss: 1.3618e-10
Epoch 371/512
512/512 - 0s - loss: 1.2673e-08 - val_loss: 1.2729e-10
Epoch 372/512
512/512 - 0s - loss: 1.1718e-08 - val_loss: 1.2552e-10
Epoch 373/512
512/512 - 0s - loss: 1.1661e-08 - val_loss: 1.2563e-10
Epoch 374/512
512/512 - 0s - loss: 1.1544e-08 - val_loss: 1.1812e-10
Epoch 375/512
512/512 - 0s - loss: 1.0710e-08 - val_loss: 1.0742e-10
Epoch 376/512
512/512 - 0s - loss: 9.9616e-09 - val_loss: 1.0349e-10
Epoch 377/512
512/512 - 0s - loss: 9.7198e-09 - val_loss: 1.0317e-10
Epoch 378/512
512/512 - 0s - loss: 9.5012e-09 - val_loss: 1.0012e-10
Epoch 379/512
512/512 - 0s - loss: 9.1948e-09 - val_loss: 9.2648e-11
Epoch 380/512
512/512 - 0s - loss: 8.5105e-09 - val_loss: 8.7265e-11
Epoch 381/512
512/512 - 0s - loss: 8.1652e-09 - val_loss: 8.5250e-11
Epoch 382/512
512/512 - 0s - loss: 8.0009e-09 - val_loss: 8.3413e-11
Epoch 383/512
512/512 - 0s - loss: 7.7607e-09 - val_loss: 7.9619e-11
Epoch 384/512
512/512 - 0s - loss: 7.3943e-09 - val_loss: 7.4443e-11
Epoch 385/512
512/512 - 0s - loss: 6.8960e-09 - val_loss: 7.1321e-11
Epoch 386/512
512/512 - 0s - loss: 6.7247e-09 - val_loss: 7.0635e-11
Epoch 387/512
512/512 - 0s - loss: 6.5909e-09 - val_loss: 6.8673e-11
Epoch 388/512
512/512 - 0s - loss: 6.3359e-09 - val_loss: 6.5003e-11
Epoch 389/512
512/512 - 0s - loss: 6.0399e-09 - val_loss: 6.1779e-11
Epoch 390/512
512/512 - 0s - loss: 5.7532e-09 - val_loss: 5.9409e-11
Epoch 391/512
512/512 - 0s - loss: 5.5605e-09 - val_loss: 5.7231e-11
Epoch 392/512
512/512 - 0s - loss: 5.3285e-09 - val_loss: 5.6000e-11
Epoch 393/512
512/512 - 0s - loss: 5.2260e-09 - val_loss: 5.4104e-11
Epoch 394/512
512/512 - 0s - loss: 5.0227e-09 - val_loss: 5.1403e-11
Epoch 395/512
512/512 - 0s - loss: 4.8083e-09 - val_loss: 4.9561e-11
Epoch 396/512
512/512 - 0s - loss: 4.6589e-09 - val_loss: 4.7630e-11
Epoch 397/512
512/512 - 0s - loss: 4.4302e-09 - val_loss: 4.6029e-11
Epoch 398/512
512/512 - 0s - loss: 4.3267e-09 - val_loss: 4.4819e-11
Epoch 399/512
512/512 - 0s - loss: 4.1949e-09 - val_loss: 4.2708e-11
Epoch 400/512
512/512 - 0s - loss: 3.9915e-09 - val_loss: 4.1340e-11
Epoch 401/512
512/512 - 0s - loss: 3.8644e-09 - val_loss: 3.9982e-11
Epoch 402/512
512/512 - 0s - loss: 3.7666e-09 - val_loss: 3.8949e-11
Epoch 403/512
512/512 - 0s - loss: 3.6491e-09 - val_loss: 3.7517e-11
Epoch 404/512
512/512 - 0s - loss: 3.5055e-09 - val_loss: 3.6063e-11
Epoch 405/512
512/512 - 0s - loss: 3.3907e-09 - val_loss: 3.4652e-11
Epoch 406/512
512/512 - 0s - loss: 3.2762e-09 - val_loss: 3.3670e-11
Epoch 407/512
512/512 - 0s - loss: 3.1364e-09 - val_loss: 3.2706e-11
Epoch 408/512
512/512 - 0s - loss: 3.0748e-09 - val_loss: 3.2241e-11
Epoch 409/512
512/512 - 0s - loss: 3.0322e-09 - val_loss: 3.0987e-11
Epoch 410/512
512/512 - 0s - loss: 2.8982e-09 - val_loss: 2.9895e-11
Epoch 411/512
512/512 - 0s - loss: 2.7861e-09 - val_loss: 2.8770e-11
Epoch 412/512
512/512 - 0s - loss: 2.6723e-09 - val_loss: 2.7560e-11
Epoch 413/512
512/512 - 0s - loss: 2.5988e-09 - val_loss: 2.6932e-11
Epoch 414/512
512/512 - 0s - loss: 2.5518e-09 - val_loss: 2.6587e-11
Epoch 415/512
512/512 - 0s - loss: 2.5276e-09 - val_loss: 2.5386e-11
Epoch 416/512
512/512 - 0s - loss: 2.3676e-09 - val_loss: 2.3778e-11
Epoch 417/512
512/512 - 0s - loss: 2.2119e-09 - val_loss: 2.3550e-11
Epoch 418/512
512/512 - 0s - loss: 2.2487e-09 - val_loss: 2.3812e-11
Epoch 419/512
512/512 - 0s - loss: 2.2491e-09 - val_loss: 2.2622e-11
Epoch 420/512
512/512 - 0s - loss: 2.1197e-09 - val_loss: 2.1536e-11
Epoch 421/512
512/512 - 0s - loss: 2.0173e-09 - val_loss: 2.0978e-11
Epoch 422/512
512/512 - 0s - loss: 1.9691e-09 - val_loss: 2.0681e-11
Epoch 423/512
512/512 - 0s - loss: 1.9473e-09 - val_loss: 2.0496e-11
Epoch 424/512
512/512 - 0s - loss: 1.9220e-09 - val_loss: 1.9709e-11
Epoch 425/512
512/512 - 0s - loss: 1.8464e-09 - val_loss: 1.8777e-11
Epoch 426/512
512/512 - 0s - loss: 1.7841e-09 - val_loss: 1.8107e-11
Epoch 427/512
512/512 - 0s - loss: 1.7204e-09 - val_loss: 1.7545e-11
Epoch 428/512
512/512 - 0s - loss: 1.6535e-09 - val_loss: 1.7407e-11
Epoch 429/512
512/512 - 0s - loss: 1.6943e-09 - val_loss: 1.7257e-11
Epoch 430/512
512/512 - 0s - loss: 1.6350e-09 - val_loss: 1.6383e-11
Epoch 431/512
512/512 - 0s - loss: 1.5572e-09 - val_loss: 1.5939e-11
Epoch 432/512
512/512 - 0s - loss: 1.5038e-09 - val_loss: 1.5378e-11
Epoch 433/512
512/512 - 0s - loss: 1.4751e-09 - val_loss: 1.4920e-11
Epoch 434/512
512/512 - 0s - loss: 1.4329e-09 - val_loss: 1.4754e-11
Epoch 435/512
512/512 - 0s - loss: 1.3992e-09 - val_loss: 1.4577e-11
Epoch 436/512
512/512 - 0s - loss: 1.3884e-09 - val_loss: 1.4345e-11
Epoch 437/512
512/512 - 0s - loss: 1.3545e-09 - val_loss: 1.4017e-11
Epoch 438/512
512/512 - 0s - loss: 1.3017e-09 - val_loss: 1.3428e-11
Epoch 439/512
512/512 - 0s - loss: 1.2690e-09 - val_loss: 1.3204e-11
Epoch 440/512
512/512 - 0s - loss: 1.2615e-09 - val_loss: 1.2819e-11
Epoch 441/512
512/512 - 0s - loss: 1.2326e-09 - val_loss: 1.2514e-11
Epoch 442/512
512/512 - 0s - loss: 1.1844e-09 - val_loss: 1.2143e-11
Epoch 443/512
512/512 - 0s - loss: 1.1655e-09 - val_loss: 1.1864e-11
Epoch 444/512
512/512 - 0s - loss: 1.1285e-09 - val_loss: 1.1278e-11
Epoch 445/512
512/512 - 0s - loss: 1.0845e-09 - val_loss: 1.0905e-11
Epoch 446/512
512/512 - 0s - loss: 1.0611e-09 - val_loss: 1.0982e-11
Epoch 447/512
512/512 - 0s - loss: 1.0628e-09 - val_loss: 1.1119e-11
Epoch 448/512
512/512 - 0s - loss: 1.0560e-09 - val_loss: 1.0782e-11
Epoch 449/512
512/512 - 0s - loss: 1.0213e-09 - val_loss: 1.0396e-11
Epoch 450/512
512/512 - 0s - loss: 9.9411e-10 - val_loss: 9.8964e-12
Epoch 451/512
512/512 - 0s - loss: 9.5075e-10 - val_loss: 9.5524e-12
Epoch 452/512
512/512 - 0s - loss: 9.1589e-10 - val_loss: 9.4392e-12
Epoch 453/512
512/512 - 0s - loss: 9.1152e-10 - val_loss: 9.3909e-12
Epoch 454/512
512/512 - 0s - loss: 9.0091e-10 - val_loss: 9.3560e-12
Epoch 455/512
512/512 - 0s - loss: 9.0409e-10 - val_loss: 9.2940e-12
Epoch 456/512
512/512 - 0s - loss: 8.8809e-10 - val_loss: 8.7325e-12
Epoch 457/512
512/512 - 0s - loss: 8.3967e-10 - val_loss: 8.4893e-12
Epoch 458/512
512/512 - 0s - loss: 8.2430e-10 - val_loss: 8.3240e-12
Epoch 459/512
512/512 - 0s - loss: 8.0740e-10 - val_loss: 8.3369e-12
Epoch 460/512
512/512 - 0s - loss: 8.0598e-10 - val_loss: 8.2487e-12
Epoch 461/512
512/512 - 0s - loss: 7.8195e-10 - val_loss: 8.0847e-12
Epoch 462/512
512/512 - 0s - loss: 7.7915e-10 - val_loss: 7.8746e-12
Epoch 463/512
512/512 - 0s - loss: 7.4179e-10 - val_loss: 7.6279e-12
Epoch 464/512
512/512 - 0s - loss: 7.3522e-10 - val_loss: 7.4789e-12
Epoch 465/512
512/512 - 0s - loss: 7.1921e-10 - val_loss: 7.3668e-12
Epoch 466/512
512/512 - 0s - loss: 7.1770e-10 - val_loss: 7.1788e-12
Epoch 467/512
512/512 - 0s - loss: 6.8509e-10 - val_loss: 6.8919e-12
Epoch 468/512
512/512 - 0s - loss: 6.6896e-10 - val_loss: 6.9090e-12
Epoch 469/512
512/512 - 0s - loss: 6.6945e-10 - val_loss: 6.9249e-12
Epoch 470/512
512/512 - 0s - loss: 6.6178e-10 - val_loss: 6.7105e-12
Epoch 471/512
512/512 - 0s - loss: 6.5661e-10 - val_loss: 6.6741e-12
Epoch 472/512
512/512 - 0s - loss: 6.3628e-10 - val_loss: 6.5792e-12
Epoch 473/512
512/512 - 0s - loss: 6.2814e-10 - val_loss: 6.4634e-12
Epoch 474/512
512/512 - 0s - loss: 6.1432e-10 - val_loss: 6.2777e-12
Epoch 475/512
512/512 - 0s - loss: 6.0346e-10 - val_loss: 6.0953e-12
Epoch 476/512
512/512 - 0s - loss: 5.8555e-10 - val_loss: 6.0821e-12
Epoch 477/512
512/512 - 0s - loss: 5.8916e-10 - val_loss: 5.9808e-12
Epoch 478/512
512/512 - 0s - loss: 5.7574e-10 - val_loss: 5.8574e-12
Epoch 479/512
512/512 - 0s - loss: 5.5672e-10 - val_loss: 5.5366e-12
Epoch 480/512
512/512 - 0s - loss: 5.3363e-10 - val_loss: 5.3397e-12
Epoch 481/512
512/512 - 0s - loss: 5.1809e-10 - val_loss: 5.3439e-12
Epoch 482/512
512/512 - 0s - loss: 5.2374e-10 - val_loss: 5.4456e-12
Epoch 483/512
512/512 - 0s - loss: 5.1700e-10 - val_loss: 5.3680e-12
Epoch 484/512
512/512 - 0s - loss: 5.1671e-10 - val_loss: 5.2875e-12
Epoch 485/512
512/512 - 0s - loss: 5.1044e-10 - val_loss: 5.2278e-12
Epoch 486/512
512/512 - 0s - loss: 4.9828e-10 - val_loss: 5.1489e-12
Epoch 487/512
512/512 - 0s - loss: 4.9694e-10 - val_loss: 5.0018e-12
Epoch 488/512
512/512 - 0s - loss: 4.8591e-10 - val_loss: 4.7865e-12
Epoch 489/512
512/512 - 0s - loss: 4.5839e-10 - val_loss: 4.6046e-12
Epoch 490/512
512/512 - 0s - loss: 4.4532e-10 - val_loss: 4.6030e-12
Epoch 491/512
512/512 - 0s - loss: 4.5353e-10 - val_loss: 4.5607e-12
Epoch 492/512
512/512 - 0s - loss: 4.4701e-10 - val_loss: 4.4619e-12
Epoch 493/512
512/512 - 0s - loss: 4.3596e-10 - val_loss: 4.4474e-12
Epoch 494/512
512/512 - 0s - loss: 4.3099e-10 - val_loss: 4.3741e-12
Epoch 495/512
512/512 - 0s - loss: 4.2271e-10 - val_loss: 4.3000e-12
Epoch 496/512
512/512 - 0s - loss: 4.1637e-10 - val_loss: 4.3126e-12
Epoch 497/512
512/512 - 0s - loss: 4.2406e-10 - val_loss: 4.2758e-12
Epoch 498/512
512/512 - 0s - loss: 4.0877e-10 - val_loss: 4.0635e-12
Epoch 499/512
512/512 - 0s - loss: 3.9502e-10 - val_loss: 3.9828e-12
Epoch 500/512
512/512 - 0s - loss: 3.8452e-10 - val_loss: 3.8807e-12
Epoch 501/512
512/512 - 0s - loss: 3.7932e-10 - val_loss: 3.8300e-12
Epoch 502/512
512/512 - 0s - loss: 3.7867e-10 - val_loss: 3.8130e-12
Epoch 503/512
512/512 - 0s - loss: 3.7536e-10 - val_loss: 3.8684e-12
Epoch 504/512
512/512 - 0s - loss: 3.7375e-10 - val_loss: 3.7212e-12
Epoch 505/512
512/512 - 0s - loss: 3.6495e-10 - val_loss: 3.7207e-12
Epoch 506/512
512/512 - 0s - loss: 3.5918e-10 - val_loss: 3.7369e-12
Epoch 507/512
512/512 - 0s - loss: 3.6312e-10 - val_loss: 3.6344e-12
Epoch 508/512
512/512 - 0s - loss: 3.5596e-10 - val_loss: 3.6139e-12
Epoch 509/512
512/512 - 0s - loss: 3.5123e-10 - val_loss: 3.5872e-12
Epoch 510/512
512/512 - 0s - loss: 3.4368e-10 - val_loss: 3.4597e-12
Epoch 511/512
512/512 - 0s - loss: 3.3508e-10 - val_loss: 3.3920e-12
Epoch 512/512
512/512 - 0s - loss: 3.3176e-10 - val_loss: 3.2779e-12
2024-04-11 15:49:02.682292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
Train on 512 samples, validate on 512 samples
Epoch 1/512

Epoch 00001: val_loss improved from inf to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.3066e-10 - val_loss: 6.2330e-10
Epoch 2/512

Epoch 00002: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.7646e-10 - val_loss: 7.6527e-10
Epoch 3/512

Epoch 00003: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.0905e-10 - val_loss: 6.3849e-10
Epoch 4/512

Epoch 00004: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.6101e-10 - val_loss: 4.8151e-10
Epoch 5/512

Epoch 00005: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.2824e-10 - val_loss: 3.8736e-10
Epoch 6/512

Epoch 00006: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.6269e-10 - val_loss: 3.5854e-10
Epoch 7/512

Epoch 00007: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5694e-10 - val_loss: 3.9054e-10
Epoch 8/512

Epoch 00008: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9442e-10 - val_loss: 4.2918e-10
Epoch 9/512

Epoch 00009: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3211e-10 - val_loss: 4.6926e-10
Epoch 10/512

Epoch 00010: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6130e-10 - val_loss: 4.7661e-10
Epoch 11/512

Epoch 00011: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5414e-10 - val_loss: 4.4556e-10
Epoch 12/512

Epoch 00012: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2244e-10 - val_loss: 4.1408e-10
Epoch 13/512

Epoch 00013: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9567e-10 - val_loss: 3.8855e-10
Epoch 14/512

Epoch 00014: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7529e-10 - val_loss: 3.7689e-10
Epoch 15/512

Epoch 00015: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6459e-10 - val_loss: 3.7282e-10
Epoch 16/512

Epoch 00016: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7017e-10 - val_loss: 3.8389e-10
Epoch 17/512

Epoch 00017: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8035e-10 - val_loss: 3.9707e-10
Epoch 18/512

Epoch 00018: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8568e-10 - val_loss: 3.9131e-10
Epoch 19/512

Epoch 00019: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7657e-10 - val_loss: 3.7255e-10
Epoch 20/512

Epoch 00020: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5815e-10 - val_loss: 3.6262e-10
Epoch 21/512

Epoch 00021: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.4689e-10 - val_loss: 3.4779e-10
Epoch 22/512

Epoch 00022: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4125e-10 - val_loss: 3.4918e-10
Epoch 23/512

Epoch 00023: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3854e-10 - val_loss: 3.3999e-10
Epoch 24/512

Epoch 00024: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3196e-10 - val_loss: 3.4336e-10
Epoch 25/512

Epoch 00025: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3458e-10 - val_loss: 3.3963e-10
Epoch 26/512

Epoch 00026: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3041e-10 - val_loss: 3.3138e-10
Epoch 27/512

Epoch 00027: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.2062e-10 - val_loss: 3.2903e-10
Epoch 28/512

Epoch 00028: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2314e-10 - val_loss: 3.2924e-10
Epoch 29/512

Epoch 00029: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1804e-10 - val_loss: 3.2518e-10
Epoch 30/512

Epoch 00030: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1516e-10 - val_loss: 3.1558e-10
Epoch 31/512

Epoch 00031: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.0917e-10 - val_loss: 3.1526e-10
Epoch 32/512

Epoch 00032: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.0525e-10 - val_loss: 3.0523e-10
Epoch 33/512

Epoch 00033: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9789e-10 - val_loss: 3.0142e-10
Epoch 34/512

Epoch 00034: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.9224e-10 - val_loss: 2.9370e-10
Epoch 35/512

Epoch 00035: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.8294e-10 - val_loss: 2.8694e-10
Epoch 36/512

Epoch 00036: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7907e-10 - val_loss: 2.8463e-10
Epoch 37/512

Epoch 00037: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7860e-10 - val_loss: 2.8384e-10
Epoch 38/512

Epoch 00038: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7839e-10 - val_loss: 2.8712e-10
Epoch 39/512

Epoch 00039: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8074e-10 - val_loss: 2.8622e-10
Epoch 40/512

Epoch 00040: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8083e-10 - val_loss: 2.8735e-10
Epoch 41/512

Epoch 00041: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.7624e-10 - val_loss: 2.7623e-10
Epoch 42/512

Epoch 00042: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6931e-10 - val_loss: 2.7398e-10
Epoch 43/512

Epoch 00043: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6351e-10 - val_loss: 2.5807e-10
Epoch 44/512

Epoch 00044: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5311e-10 - val_loss: 2.5888e-10
Epoch 45/512

Epoch 00045: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5207e-10 - val_loss: 2.5233e-10
Epoch 46/512

Epoch 00046: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4939e-10 - val_loss: 2.5822e-10
Epoch 47/512

Epoch 00047: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.5144e-10 - val_loss: 2.5200e-10
Epoch 48/512

Epoch 00048: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4554e-10 - val_loss: 2.5189e-10
Epoch 49/512

Epoch 00049: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4693e-10 - val_loss: 2.4875e-10
Epoch 50/512

Epoch 00050: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4067e-10 - val_loss: 2.4095e-10
Epoch 51/512

Epoch 00051: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.3412e-10 - val_loss: 2.3545e-10
Epoch 52/512

Epoch 00052: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2896e-10 - val_loss: 2.3233e-10
Epoch 53/512

Epoch 00053: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2743e-10 - val_loss: 2.3311e-10
Epoch 54/512

Epoch 00054: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2781e-10 - val_loss: 2.3283e-10
Epoch 55/512

Epoch 00055: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2643e-10 - val_loss: 2.2480e-10
Epoch 56/512

Epoch 00056: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2112e-10 - val_loss: 2.2580e-10
Epoch 57/512

Epoch 00057: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2267e-10 - val_loss: 2.2580e-10
Epoch 58/512

Epoch 00058: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1941e-10 - val_loss: 2.2102e-10
Epoch 59/512

Epoch 00059: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1730e-10 - val_loss: 2.2359e-10
Epoch 60/512

Epoch 00060: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.1695e-10 - val_loss: 2.1549e-10
Epoch 61/512

Epoch 00061: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0696e-10 - val_loss: 2.0910e-10
Epoch 62/512

Epoch 00062: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0712e-10 - val_loss: 2.1540e-10
Epoch 63/512

Epoch 00063: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0913e-10 - val_loss: 2.0608e-10
Epoch 64/512

Epoch 00064: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0210e-10 - val_loss: 2.0559e-10
Epoch 65/512

Epoch 00065: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0334e-10 - val_loss: 2.0682e-10
Epoch 66/512

Epoch 00066: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9942e-10 - val_loss: 1.9822e-10
Epoch 67/512

Epoch 00067: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9699e-10 - val_loss: 2.0545e-10
Epoch 68/512

Epoch 00068: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0116e-10 - val_loss: 2.0113e-10
Epoch 69/512

Epoch 00069: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9328e-10 - val_loss: 1.9148e-10
Epoch 70/512

Epoch 00070: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8998e-10 - val_loss: 1.9267e-10
Epoch 71/512

Epoch 00071: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8786e-10 - val_loss: 1.8904e-10
Epoch 72/512

Epoch 00072: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8318e-10 - val_loss: 1.8365e-10
Epoch 73/512

Epoch 00073: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8508e-10 - val_loss: 1.8970e-10
Epoch 74/512

Epoch 00074: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8323e-10 - val_loss: 1.8252e-10
Epoch 75/512

Epoch 00075: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7709e-10 - val_loss: 1.7956e-10
Epoch 76/512

Epoch 00076: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7960e-10 - val_loss: 1.8491e-10
Epoch 77/512

Epoch 00077: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7921e-10 - val_loss: 1.7980e-10
Epoch 78/512

Epoch 00078: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7536e-10 - val_loss: 1.7878e-10
Epoch 79/512

Epoch 00079: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7776e-10 - val_loss: 1.8104e-10
Epoch 80/512

Epoch 00080: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7473e-10 - val_loss: 1.7223e-10
Epoch 81/512

Epoch 00081: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6863e-10 - val_loss: 1.6933e-10
Epoch 82/512

Epoch 00082: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6423e-10 - val_loss: 1.6103e-10
Epoch 83/512

Epoch 00083: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5824e-10 - val_loss: 1.6278e-10
Epoch 84/512

Epoch 00084: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6292e-10 - val_loss: 1.6978e-10
Epoch 85/512

Epoch 00085: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6798e-10 - val_loss: 1.6986e-10
Epoch 86/512

Epoch 00086: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6508e-10 - val_loss: 1.6687e-10
Epoch 87/512

Epoch 00087: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6370e-10 - val_loss: 1.6663e-10
Epoch 88/512

Epoch 00088: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6434e-10 - val_loss: 1.6470e-10
Epoch 89/512

Epoch 00089: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5797e-10 - val_loss: 1.5999e-10
Epoch 90/512

Epoch 00090: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5657e-10 - val_loss: 1.6002e-10
Epoch 91/512

Epoch 00091: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5759e-10 - val_loss: 1.5713e-10
Epoch 92/512

Epoch 00092: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5166e-10 - val_loss: 1.4858e-10
Epoch 93/512

Epoch 00093: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4286e-10 - val_loss: 1.4670e-10
Epoch 94/512

Epoch 00094: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4685e-10 - val_loss: 1.5387e-10
Epoch 95/512

Epoch 00095: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5021e-10 - val_loss: 1.4742e-10
Epoch 96/512

Epoch 00096: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4349e-10 - val_loss: 1.4395e-10
Epoch 97/512

Epoch 00097: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4098e-10 - val_loss: 1.4682e-10
Epoch 98/512

Epoch 00098: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4675e-10 - val_loss: 1.5140e-10
Epoch 99/512

Epoch 00099: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4580e-10 - val_loss: 1.4405e-10
Epoch 100/512

Epoch 00100: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4100e-10 - val_loss: 1.4131e-10
Epoch 101/512

Epoch 00101: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4083e-10 - val_loss: 1.4775e-10
Epoch 102/512

Epoch 00102: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4398e-10 - val_loss: 1.4233e-10
Epoch 103/512

Epoch 00103: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3749e-10 - val_loss: 1.3560e-10
Epoch 104/512

Epoch 00104: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3035e-10 - val_loss: 1.3029e-10
Epoch 105/512

Epoch 00105: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2943e-10 - val_loss: 1.3436e-10
Epoch 106/512

Epoch 00106: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3235e-10 - val_loss: 1.3508e-10
Epoch 107/512

Epoch 00107: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3429e-10 - val_loss: 1.3606e-10
Epoch 108/512

Epoch 00108: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3272e-10 - val_loss: 1.3422e-10
Epoch 109/512

Epoch 00109: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3197e-10 - val_loss: 1.3599e-10
Epoch 110/512

Epoch 00110: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3246e-10 - val_loss: 1.3113e-10
Epoch 111/512

Epoch 00111: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2736e-10 - val_loss: 1.2868e-10
Epoch 112/512

Epoch 00112: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2645e-10 - val_loss: 1.2798e-10
Epoch 113/512

Epoch 00113: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2697e-10 - val_loss: 1.3066e-10
Epoch 114/512

Epoch 00114: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2697e-10 - val_loss: 1.2715e-10
Epoch 115/512

Epoch 00115: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2463e-10 - val_loss: 1.2673e-10
Epoch 116/512

Epoch 00116: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2562e-10 - val_loss: 1.2832e-10
Epoch 117/512

Epoch 00117: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.2340e-10 - val_loss: 1.2028e-10
Epoch 118/512

Epoch 00118: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1629e-10 - val_loss: 1.1812e-10
Epoch 119/512

Epoch 00119: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1698e-10 - val_loss: 1.2040e-10
Epoch 120/512

Epoch 00120: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1861e-10 - val_loss: 1.1917e-10
Epoch 121/512

Epoch 00121: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1807e-10 - val_loss: 1.1807e-10
Epoch 122/512

Epoch 00122: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1349e-10 - val_loss: 1.0988e-10
Epoch 123/512

Epoch 00123: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0750e-10 - val_loss: 1.1263e-10
Epoch 124/512

Epoch 00124: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1292e-10 - val_loss: 1.1736e-10
Epoch 125/512

Epoch 00125: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1678e-10 - val_loss: 1.2059e-10
Epoch 126/512

Epoch 00126: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1940e-10 - val_loss: 1.1998e-10
Epoch 127/512

Epoch 00127: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.1332e-10 - val_loss: 1.0848e-10
Epoch 128/512

Epoch 00128: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0489e-10 - val_loss: 1.0735e-10
Epoch 129/512

Epoch 00129: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0696e-10 - val_loss: 1.1136e-10
Epoch 130/512

Epoch 00130: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1192e-10 - val_loss: 1.1260e-10
Epoch 131/512

Epoch 00131: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0869e-10 - val_loss: 1.0482e-10
Epoch 132/512

Epoch 00132: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.0124e-10 - val_loss: 1.0092e-10
Epoch 133/512

Epoch 00133: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.8405e-11 - val_loss: 9.8396e-11
Epoch 134/512

Epoch 00134: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0119e-10 - val_loss: 1.0761e-10
Epoch 135/512

Epoch 00135: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0832e-10 - val_loss: 1.1002e-10
Epoch 136/512

Epoch 00136: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0514e-10 - val_loss: 1.0337e-10
Epoch 137/512

Epoch 00137: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.9734e-11 - val_loss: 9.9954e-11
Epoch 138/512

Epoch 00138: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.6654e-11 - val_loss: 9.4868e-11
Epoch 139/512

Epoch 00139: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.7979e-11 - val_loss: 1.0568e-10
Epoch 140/512

Epoch 00140: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0612e-10 - val_loss: 1.0816e-10
Epoch 141/512

Epoch 00141: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0356e-10 - val_loss: 9.9832e-11
Epoch 142/512

Epoch 00142: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.6014e-11 - val_loss: 9.6518e-11
Epoch 143/512

Epoch 00143: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.4963e-11 - val_loss: 9.6015e-11
Epoch 144/512

Epoch 00144: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.4444e-11 - val_loss: 9.8882e-11
Epoch 145/512

Epoch 00145: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.9787e-11 - val_loss: 1.0287e-10
Epoch 146/512

Epoch 00146: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.9130e-11 - val_loss: 9.6742e-11
Epoch 147/512

Epoch 00147: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.4286e-11 - val_loss: 9.3628e-11
Epoch 148/512

Epoch 00148: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.3101e-11 - val_loss: 9.3451e-11
Epoch 149/512

Epoch 00149: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 9.1183e-11 - val_loss: 9.1324e-11
Epoch 150/512

Epoch 00150: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.4611e-11 - val_loss: 1.0202e-10
Epoch 151/512

Epoch 00151: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.9059e-11 - val_loss: 9.7166e-11
Epoch 152/512

Epoch 00152: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.4561e-11 - val_loss: 9.3241e-11
Epoch 153/512

Epoch 00153: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.9612e-11 - val_loss: 8.8197e-11
Epoch 154/512

Epoch 00154: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.6766e-11 - val_loss: 8.8304e-11
Epoch 155/512

Epoch 00155: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 8.6049e-11 - val_loss: 8.3437e-11
Epoch 156/512

Epoch 00156: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.9009e-11 - val_loss: 7.6538e-11
Epoch 157/512

Epoch 00157: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.5701e-11 - val_loss: 7.9060e-11
Epoch 158/512

Epoch 00158: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.9966e-11 - val_loss: 8.3669e-11
Epoch 159/512

Epoch 00159: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.5245e-11 - val_loss: 9.0749e-11
Epoch 160/512

Epoch 00160: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.1373e-11 - val_loss: 9.3094e-11
Epoch 161/512

Epoch 00161: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.9453e-11 - val_loss: 8.6460e-11
Epoch 162/512

Epoch 00162: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.1607e-11 - val_loss: 7.7862e-11
Epoch 163/512

Epoch 00163: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.4578e-11 - val_loss: 7.2825e-11
Epoch 164/512

Epoch 00164: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.4752e-11 - val_loss: 8.0083e-11
Epoch 165/512

Epoch 00165: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.0466e-11 - val_loss: 8.5034e-11
Epoch 166/512

Epoch 00166: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.4867e-11 - val_loss: 8.5551e-11
Epoch 167/512

Epoch 00167: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.5059e-11 - val_loss: 8.7086e-11
Epoch 168/512

Epoch 00168: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.4433e-11 - val_loss: 8.0354e-11
Epoch 169/512

Epoch 00169: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.6169e-11 - val_loss: 7.3292e-11
Epoch 170/512

Epoch 00170: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.1917e-11 - val_loss: 7.4223e-11
Epoch 171/512

Epoch 00171: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.5023e-11 - val_loss: 7.8426e-11
Epoch 172/512

Epoch 00172: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.9571e-11 - val_loss: 8.3417e-11
Epoch 173/512

Epoch 00173: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.2476e-11 - val_loss: 8.3597e-11
Epoch 174/512

Epoch 00174: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.0622e-11 - val_loss: 7.6227e-11
Epoch 175/512

Epoch 00175: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 7.2469e-11 - val_loss: 7.1292e-11
Epoch 176/512

Epoch 00176: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.9431e-11 - val_loss: 6.7789e-11
Epoch 177/512

Epoch 00177: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.6400e-11 - val_loss: 6.8787e-11
Epoch 178/512

Epoch 00178: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.1847e-11 - val_loss: 7.6791e-11
Epoch 179/512

Epoch 00179: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.7319e-11 - val_loss: 7.9381e-11
Epoch 180/512

Epoch 00180: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8567e-11 - val_loss: 8.0393e-11
Epoch 181/512

Epoch 00181: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.9419e-11 - val_loss: 7.6448e-11
Epoch 182/512

Epoch 00182: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.2532e-11 - val_loss: 6.7978e-11
Epoch 183/512

Epoch 00183: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.5668e-11 - val_loss: 6.4142e-11
Epoch 184/512

Epoch 00184: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.3642e-11 - val_loss: 6.4907e-11
Epoch 185/512

Epoch 00185: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.6523e-11 - val_loss: 7.1205e-11
Epoch 186/512

Epoch 00186: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.2049e-11 - val_loss: 7.6642e-11
Epoch 187/512

Epoch 00187: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.6740e-11 - val_loss: 7.8661e-11
Epoch 188/512

Epoch 00188: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.7684e-11 - val_loss: 7.5519e-11
Epoch 189/512

Epoch 00189: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.2047e-11 - val_loss: 6.9902e-11
Epoch 190/512

Epoch 00190: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.7606e-11 - val_loss: 6.4936e-11
Epoch 191/512

Epoch 00191: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.2636e-11 - val_loss: 6.2746e-11
Epoch 192/512

Epoch 00192: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.1667e-11 - val_loss: 6.2113e-11
Epoch 193/512

Epoch 00193: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.4098e-11 - val_loss: 6.8962e-11
Epoch 194/512

Epoch 00194: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.0776e-11 - val_loss: 7.5118e-11
Epoch 195/512

Epoch 00195: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.6301e-11 - val_loss: 7.6472e-11
Epoch 196/512

Epoch 00196: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.3174e-11 - val_loss: 7.0531e-11
Epoch 197/512

Epoch 00197: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.8125e-11 - val_loss: 6.5717e-11
Epoch 198/512

Epoch 00198: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.3043e-11 - val_loss: 6.2113e-11
Epoch 199/512

Epoch 00199: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.0593e-11 - val_loss: 5.9333e-11
Epoch 200/512

Epoch 00200: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.9669e-11 - val_loss: 6.4451e-11
Epoch 201/512

Epoch 00201: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5133e-11 - val_loss: 6.9745e-11
Epoch 202/512

Epoch 00202: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.0767e-11 - val_loss: 7.2039e-11
Epoch 203/512

Epoch 00203: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.9014e-11 - val_loss: 6.6414e-11
Epoch 204/512

Epoch 00204: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.3838e-11 - val_loss: 6.2703e-11
Epoch 205/512

Epoch 00205: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.1268e-11 - val_loss: 6.1777e-11
Epoch 206/512

Epoch 00206: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 6.0244e-11 - val_loss: 5.9176e-11
Epoch 207/512

Epoch 00207: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.8089e-11 - val_loss: 5.7428e-11
Epoch 208/512

Epoch 00208: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8529e-11 - val_loss: 6.3806e-11
Epoch 209/512

Epoch 00209: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5803e-11 - val_loss: 7.1503e-11
Epoch 210/512

Epoch 00210: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.2743e-11 - val_loss: 7.3141e-11
Epoch 211/512

Epoch 00211: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.9850e-11 - val_loss: 6.6647e-11
Epoch 212/512

Epoch 00212: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.2927e-11 - val_loss: 5.8214e-11
Epoch 213/512

Epoch 00213: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.6181e-11 - val_loss: 5.6626e-11
Epoch 214/512

Epoch 00214: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.5965e-11 - val_loss: 5.4916e-11
Epoch 215/512

Epoch 00215: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4134e-11 - val_loss: 5.5600e-11
Epoch 216/512

Epoch 00216: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.5797e-11 - val_loss: 5.6643e-11
Epoch 217/512

Epoch 00217: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.4474e-11 - val_loss: 5.2073e-11
Epoch 218/512

Epoch 00218: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0808e-11 - val_loss: 5.3298e-11
Epoch 219/512

Epoch 00219: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3898e-11 - val_loss: 5.7544e-11
Epoch 220/512

Epoch 00220: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8269e-11 - val_loss: 5.9662e-11
Epoch 221/512

Epoch 00221: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7765e-11 - val_loss: 5.8051e-11
Epoch 222/512

Epoch 00222: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8103e-11 - val_loss: 5.9952e-11
Epoch 223/512

Epoch 00223: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.0123e-11 - val_loss: 6.0500e-11
Epoch 224/512

Epoch 00224: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8477e-11 - val_loss: 5.7762e-11
Epoch 225/512

Epoch 00225: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7067e-11 - val_loss: 5.4963e-11
Epoch 226/512

Epoch 00226: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 5.1831e-11 - val_loss: 4.9692e-11
Epoch 227/512

Epoch 00227: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.8117e-11 - val_loss: 4.5968e-11
Epoch 228/512

Epoch 00228: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.3822e-11 - val_loss: 4.2389e-11
Epoch 229/512

Epoch 00229: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1904e-11 - val_loss: 4.5480e-11
Epoch 230/512

Epoch 00230: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8068e-11 - val_loss: 5.2502e-11
Epoch 231/512

Epoch 00231: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3675e-11 - val_loss: 5.7922e-11
Epoch 232/512

Epoch 00232: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8807e-11 - val_loss: 6.0123e-11
Epoch 233/512

Epoch 00233: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8250e-11 - val_loss: 5.7812e-11
Epoch 234/512

Epoch 00234: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7693e-11 - val_loss: 5.9282e-11
Epoch 235/512

Epoch 00235: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7280e-11 - val_loss: 5.4079e-11
Epoch 236/512

Epoch 00236: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0512e-11 - val_loss: 4.6401e-11
Epoch 237/512

Epoch 00237: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.4056e-11 - val_loss: 4.2085e-11
Epoch 238/512

Epoch 00238: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.1241e-11 - val_loss: 4.1772e-11
Epoch 239/512

Epoch 00239: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1521e-11 - val_loss: 4.5563e-11
Epoch 240/512

Epoch 00240: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8357e-11 - val_loss: 5.3663e-11
Epoch 241/512

Epoch 00241: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4995e-11 - val_loss: 5.9292e-11
Epoch 242/512

Epoch 00242: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8334e-11 - val_loss: 5.7493e-11
Epoch 243/512

Epoch 00243: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.5208e-11 - val_loss: 5.3283e-11
Epoch 244/512

Epoch 00244: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1856e-11 - val_loss: 5.0462e-11
Epoch 245/512

Epoch 00245: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8141e-11 - val_loss: 4.6532e-11
Epoch 246/512

Epoch 00246: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4970e-11 - val_loss: 4.2945e-11
Epoch 247/512

Epoch 00247: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1877e-11 - val_loss: 4.2189e-11
Epoch 248/512

Epoch 00248: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2182e-11 - val_loss: 4.3366e-11
Epoch 249/512

Epoch 00249: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.1938e-11 - val_loss: 4.0764e-11
Epoch 250/512

Epoch 00250: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2292e-11 - val_loss: 4.6429e-11
Epoch 251/512

Epoch 00251: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7689e-11 - val_loss: 5.0361e-11
Epoch 252/512

Epoch 00252: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1684e-11 - val_loss: 5.4477e-11
Epoch 253/512

Epoch 00253: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4194e-11 - val_loss: 5.4915e-11
Epoch 254/512

Epoch 00254: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4761e-11 - val_loss: 5.5248e-11
Epoch 255/512

Epoch 00255: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4669e-11 - val_loss: 5.2745e-11
Epoch 256/512

Epoch 00256: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9364e-11 - val_loss: 4.5652e-11
Epoch 257/512

Epoch 00257: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 4.2530e-11 - val_loss: 3.9858e-11
Epoch 258/512

Epoch 00258: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.9039e-11 - val_loss: 3.8480e-11
Epoch 259/512

Epoch 00259: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.7557e-11 - val_loss: 3.7031e-11
Epoch 260/512

Epoch 00260: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6762e-11 - val_loss: 3.7144e-11
Epoch 261/512

Epoch 00261: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7744e-11 - val_loss: 4.2097e-11
Epoch 262/512

Epoch 00262: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4374e-11 - val_loss: 4.8246e-11
Epoch 263/512

Epoch 00263: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9415e-11 - val_loss: 5.1927e-11
Epoch 264/512

Epoch 00264: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2078e-11 - val_loss: 5.2734e-11
Epoch 265/512

Epoch 00265: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1700e-11 - val_loss: 5.1923e-11
Epoch 266/512

Epoch 00266: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9911e-11 - val_loss: 4.6842e-11
Epoch 267/512

Epoch 00267: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4529e-11 - val_loss: 4.2191e-11
Epoch 268/512

Epoch 00268: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0793e-11 - val_loss: 3.9639e-11
Epoch 269/512

Epoch 00269: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8326e-11 - val_loss: 3.7380e-11
Epoch 270/512

Epoch 00270: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.6973e-11 - val_loss: 3.6847e-11
Epoch 271/512

Epoch 00271: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6265e-11 - val_loss: 3.7476e-11
Epoch 272/512

Epoch 00272: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9047e-11 - val_loss: 4.3437e-11
Epoch 273/512

Epoch 00273: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5215e-11 - val_loss: 4.9454e-11
Epoch 274/512

Epoch 00274: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9669e-11 - val_loss: 5.1326e-11
Epoch 275/512

Epoch 00275: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0686e-11 - val_loss: 4.9451e-11
Epoch 276/512

Epoch 00276: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8098e-11 - val_loss: 4.9252e-11
Epoch 277/512

Epoch 00277: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7394e-11 - val_loss: 4.3877e-11
Epoch 278/512

Epoch 00278: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1541e-11 - val_loss: 3.9346e-11
Epoch 279/512

Epoch 00279: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8356e-11 - val_loss: 3.8246e-11
Epoch 280/512

Epoch 00280: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7507e-11 - val_loss: 3.6951e-11
Epoch 281/512

Epoch 00281: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.6050e-11 - val_loss: 3.5217e-11
Epoch 282/512

Epoch 00282: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3934e-11 - val_loss: 3.2848e-11
Epoch 283/512

Epoch 00283: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2441e-11 - val_loss: 3.3011e-11
Epoch 284/512

Epoch 00284: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3757e-11 - val_loss: 3.5605e-11
Epoch 285/512

Epoch 00285: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5650e-11 - val_loss: 3.8593e-11
Epoch 286/512

Epoch 00286: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0074e-11 - val_loss: 4.4496e-11
Epoch 287/512

Epoch 00287: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5164e-11 - val_loss: 4.7164e-11
Epoch 288/512

Epoch 00288: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6551e-11 - val_loss: 4.8077e-11
Epoch 289/512

Epoch 00289: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8339e-11 - val_loss: 4.7511e-11
Epoch 290/512

Epoch 00290: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4523e-11 - val_loss: 4.1234e-11
Epoch 291/512

Epoch 00291: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9391e-11 - val_loss: 3.7228e-11
Epoch 292/512

Epoch 00292: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5695e-11 - val_loss: 3.4345e-11
Epoch 293/512

Epoch 00293: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3792e-11 - val_loss: 3.3604e-11
Epoch 294/512

Epoch 00294: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3524e-11 - val_loss: 3.4343e-11
Epoch 295/512

Epoch 00295: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4369e-11 - val_loss: 3.4703e-11
Epoch 296/512

Epoch 00296: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4488e-11 - val_loss: 3.5052e-11
Epoch 297/512

Epoch 00297: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4948e-11 - val_loss: 3.5367e-11
Epoch 298/512

Epoch 00298: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6877e-11 - val_loss: 4.0638e-11
Epoch 299/512

Epoch 00299: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2018e-11 - val_loss: 4.5219e-11
Epoch 300/512

Epoch 00300: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5996e-11 - val_loss: 4.8054e-11
Epoch 301/512

Epoch 00301: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7916e-11 - val_loss: 4.6008e-11
Epoch 302/512

Epoch 00302: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3222e-11 - val_loss: 4.0603e-11
Epoch 303/512

Epoch 00303: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8948e-11 - val_loss: 3.6873e-11
Epoch 304/512

Epoch 00304: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5309e-11 - val_loss: 3.4424e-11
Epoch 305/512

Epoch 00305: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.3278e-11 - val_loss: 3.2549e-11
Epoch 306/512

Epoch 00306: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2467e-11 - val_loss: 3.2885e-11
Epoch 307/512

Epoch 00307: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1869e-11 - val_loss: 3.0927e-11
Epoch 308/512

Epoch 00308: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.0643e-11 - val_loss: 3.2962e-11
Epoch 309/512

Epoch 00309: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2965e-11 - val_loss: 3.3209e-11
Epoch 310/512

Epoch 00310: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3365e-11 - val_loss: 3.4174e-11
Epoch 311/512

Epoch 00311: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4434e-11 - val_loss: 3.8121e-11
Epoch 312/512

Epoch 00312: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9880e-11 - val_loss: 4.3261e-11
Epoch 313/512

Epoch 00313: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4275e-11 - val_loss: 4.7737e-11
Epoch 314/512

Epoch 00314: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6524e-11 - val_loss: 4.4122e-11
Epoch 315/512

Epoch 00315: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1140e-11 - val_loss: 3.8449e-11
Epoch 316/512

Epoch 00316: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6532e-11 - val_loss: 3.4158e-11
Epoch 317/512

Epoch 00317: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3160e-11 - val_loss: 3.2430e-11
Epoch 318/512

Epoch 00318: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.1890e-11 - val_loss: 3.2958e-11
Epoch 319/512

Epoch 00319: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2266e-11 - val_loss: 3.1304e-11
Epoch 320/512

Epoch 00320: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.1100e-11 - val_loss: 3.0703e-11
Epoch 321/512

Epoch 00321: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.0876e-11 - val_loss: 3.2116e-11
Epoch 322/512

Epoch 00322: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2421e-11 - val_loss: 3.3082e-11
Epoch 323/512

Epoch 00323: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2813e-11 - val_loss: 3.3263e-11
Epoch 324/512

Epoch 00324: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2915e-11 - val_loss: 3.2500e-11
Epoch 325/512

Epoch 00325: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2556e-11 - val_loss: 3.2306e-11
Epoch 326/512

Epoch 00326: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 3.0677e-11 - val_loss: 2.8096e-11
Epoch 327/512

Epoch 00327: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6476e-11 - val_loss: 2.4733e-11
Epoch 328/512

Epoch 00328: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.4405e-11 - val_loss: 2.4043e-11
Epoch 329/512

Epoch 00329: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3831e-11 - val_loss: 2.4272e-11
Epoch 330/512

Epoch 00330: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5488e-11 - val_loss: 2.7097e-11
Epoch 331/512

Epoch 00331: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7423e-11 - val_loss: 2.8540e-11
Epoch 332/512

Epoch 00332: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.0210e-11 - val_loss: 3.3171e-11
Epoch 333/512

Epoch 00333: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3044e-11 - val_loss: 3.3650e-11
Epoch 334/512

Epoch 00334: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3182e-11 - val_loss: 3.2180e-11
Epoch 335/512

Epoch 00335: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.1106e-11 - val_loss: 3.0589e-11
Epoch 336/512

Epoch 00336: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.1339e-11 - val_loss: 3.2553e-11
Epoch 337/512

Epoch 00337: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2564e-11 - val_loss: 3.3629e-11
Epoch 338/512

Epoch 00338: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3140e-11 - val_loss: 3.2093e-11
Epoch 339/512

Epoch 00339: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.0954e-11 - val_loss: 3.0830e-11
Epoch 340/512

Epoch 00340: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9704e-11 - val_loss: 2.8002e-11
Epoch 341/512

Epoch 00341: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.6116e-11 - val_loss: 2.3458e-11
Epoch 342/512

Epoch 00342: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.2141e-11 - val_loss: 2.0151e-11
Epoch 343/512

Epoch 00343: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0019e-11 - val_loss: 2.0342e-11
Epoch 344/512

Epoch 00344: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0647e-11 - val_loss: 2.1654e-11
Epoch 345/512

Epoch 00345: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2385e-11 - val_loss: 2.3777e-11
Epoch 346/512

Epoch 00346: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3312e-11 - val_loss: 2.2846e-11
Epoch 347/512

Epoch 00347: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2403e-11 - val_loss: 2.2271e-11
Epoch 348/512

Epoch 00348: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2287e-11 - val_loss: 2.3676e-11
Epoch 349/512

Epoch 00349: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5770e-11 - val_loss: 2.9457e-11
Epoch 350/512

Epoch 00350: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.0101e-11 - val_loss: 3.1127e-11
Epoch 351/512

Epoch 00351: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.1439e-11 - val_loss: 3.3281e-11
Epoch 352/512

Epoch 00352: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3220e-11 - val_loss: 3.4240e-11
Epoch 353/512

Epoch 00353: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3868e-11 - val_loss: 3.3967e-11
Epoch 354/512

Epoch 00354: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3433e-11 - val_loss: 3.2965e-11
Epoch 355/512

Epoch 00355: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.1576e-11 - val_loss: 3.0233e-11
Epoch 356/512

Epoch 00356: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9346e-11 - val_loss: 2.8644e-11
Epoch 357/512

Epoch 00357: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8604e-11 - val_loss: 2.8968e-11
Epoch 358/512

Epoch 00358: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8498e-11 - val_loss: 2.6506e-11
Epoch 359/512

Epoch 00359: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4772e-11 - val_loss: 2.3477e-11
Epoch 360/512

Epoch 00360: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2767e-11 - val_loss: 2.1887e-11
Epoch 361/512

Epoch 00361: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2050e-11 - val_loss: 2.2047e-11
Epoch 362/512

Epoch 00362: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1596e-11 - val_loss: 2.1629e-11
Epoch 363/512

Epoch 00363: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1114e-11 - val_loss: 2.0657e-11
Epoch 364/512

Epoch 00364: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0071e-11 - val_loss: 1.9559e-11
Epoch 365/512

Epoch 00365: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9842e-11 - val_loss: 2.0691e-11
Epoch 366/512

Epoch 00366: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0682e-11 - val_loss: 2.1625e-11
Epoch 367/512

Epoch 00367: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3911e-11 - val_loss: 2.7549e-11
Epoch 368/512

Epoch 00368: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8352e-11 - val_loss: 2.9801e-11
Epoch 369/512

Epoch 00369: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.0417e-11 - val_loss: 3.2168e-11
Epoch 370/512

Epoch 00370: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2443e-11 - val_loss: 3.3574e-11
Epoch 371/512

Epoch 00371: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2764e-11 - val_loss: 3.1498e-11
Epoch 372/512

Epoch 00372: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.0441e-11 - val_loss: 2.9700e-11
Epoch 373/512

Epoch 00373: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8951e-11 - val_loss: 2.8014e-11
Epoch 374/512

Epoch 00374: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7999e-11 - val_loss: 2.9081e-11
Epoch 375/512

Epoch 00375: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8655e-11 - val_loss: 2.8439e-11
Epoch 376/512

Epoch 00376: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8110e-11 - val_loss: 2.6936e-11
Epoch 377/512

Epoch 00377: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5406e-11 - val_loss: 2.3582e-11
Epoch 378/512

Epoch 00378: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3038e-11 - val_loss: 2.2199e-11
Epoch 379/512

Epoch 00379: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 2.0828e-11 - val_loss: 1.9554e-11
Epoch 380/512

Epoch 00380: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9087e-11 - val_loss: 1.9356e-11
Epoch 381/512

Epoch 00381: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9120e-11 - val_loss: 1.9311e-11
Epoch 382/512

Epoch 00382: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9236e-11 - val_loss: 1.9312e-11
Epoch 383/512

Epoch 00383: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.9040e-11 - val_loss: 1.8976e-11
Epoch 384/512

Epoch 00384: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9139e-11 - val_loss: 2.0166e-11
Epoch 385/512

Epoch 00385: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0222e-11 - val_loss: 2.0357e-11
Epoch 386/512

Epoch 00386: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9861e-11 - val_loss: 1.9532e-11
Epoch 387/512

Epoch 00387: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0156e-11 - val_loss: 2.2552e-11
Epoch 388/512

Epoch 00388: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3322e-11 - val_loss: 2.5768e-11
Epoch 389/512

Epoch 00389: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6947e-11 - val_loss: 2.8704e-11
Epoch 390/512

Epoch 00390: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8882e-11 - val_loss: 2.9428e-11
Epoch 391/512

Epoch 00391: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9696e-11 - val_loss: 3.0886e-11
Epoch 392/512

Epoch 00392: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.0549e-11 - val_loss: 3.0554e-11
Epoch 393/512

Epoch 00393: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.0440e-11 - val_loss: 3.0587e-11
Epoch 394/512

Epoch 00394: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9707e-11 - val_loss: 2.8982e-11
Epoch 395/512

Epoch 00395: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7983e-11 - val_loss: 2.7855e-11
Epoch 396/512

Epoch 00396: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6372e-11 - val_loss: 2.2763e-11
Epoch 397/512

Epoch 00397: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1007e-11 - val_loss: 1.9323e-11
Epoch 398/512

Epoch 00398: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8703e-11 - val_loss: 1.8486e-11
Epoch 399/512

Epoch 00399: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8412e-11 - val_loss: 1.8479e-11
Epoch 400/512

Epoch 00400: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8406e-11 - val_loss: 1.8866e-11
Epoch 401/512

Epoch 00401: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9593e-11 - val_loss: 2.1476e-11
Epoch 402/512

Epoch 00402: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1489e-11 - val_loss: 2.1907e-11
Epoch 403/512

Epoch 00403: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1338e-11 - val_loss: 2.0726e-11
Epoch 404/512

Epoch 00404: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0359e-11 - val_loss: 2.0693e-11
Epoch 405/512

Epoch 00405: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0159e-11 - val_loss: 1.9376e-11
Epoch 406/512

Epoch 00406: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8871e-11 - val_loss: 1.8563e-11
Epoch 407/512

Epoch 00407: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9369e-11 - val_loss: 2.1827e-11
Epoch 408/512

Epoch 00408: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3763e-11 - val_loss: 2.7042e-11
Epoch 409/512

Epoch 00409: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7414e-11 - val_loss: 2.8463e-11
Epoch 410/512

Epoch 00410: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8676e-11 - val_loss: 2.9377e-11
Epoch 411/512

Epoch 00411: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9215e-11 - val_loss: 2.9927e-11
Epoch 412/512

Epoch 00412: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9561e-11 - val_loss: 2.9303e-11
Epoch 413/512

Epoch 00413: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8794e-11 - val_loss: 2.8140e-11
Epoch 414/512

Epoch 00414: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7333e-11 - val_loss: 2.6633e-11
Epoch 415/512

Epoch 00415: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5915e-11 - val_loss: 2.3836e-11
Epoch 416/512

Epoch 00416: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1532e-11 - val_loss: 1.9159e-11
Epoch 417/512

Epoch 00417: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.8511e-11 - val_loss: 1.7834e-11
Epoch 418/512

Epoch 00418: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7566e-11 - val_loss: 1.7876e-11
Epoch 419/512

Epoch 00419: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.7521e-11 - val_loss: 1.6933e-11
Epoch 420/512

Epoch 00420: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.6450e-11 - val_loss: 1.5908e-11
Epoch 421/512

Epoch 00421: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5679e-11 - val_loss: 1.6022e-11
Epoch 422/512

Epoch 00422: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6387e-11 - val_loss: 1.7540e-11
Epoch 423/512

Epoch 00423: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8147e-11 - val_loss: 1.9188e-11
Epoch 424/512

Epoch 00424: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9261e-11 - val_loss: 1.9842e-11
Epoch 425/512

Epoch 00425: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9165e-11 - val_loss: 1.8422e-11
Epoch 426/512

Epoch 00426: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8069e-11 - val_loss: 1.7310e-11
Epoch 427/512

Epoch 00427: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6531e-11 - val_loss: 1.6335e-11
Epoch 428/512

Epoch 00428: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5980e-11 - val_loss: 1.6484e-11
Epoch 429/512

Epoch 00429: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6503e-11 - val_loss: 1.7357e-11
Epoch 430/512

Epoch 00430: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8104e-11 - val_loss: 1.9038e-11
Epoch 431/512

Epoch 00431: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0215e-11 - val_loss: 2.2649e-11
Epoch 432/512

Epoch 00432: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2980e-11 - val_loss: 2.4210e-11
Epoch 433/512

Epoch 00433: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5104e-11 - val_loss: 2.7162e-11
Epoch 434/512

Epoch 00434: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6911e-11 - val_loss: 2.6562e-11
Epoch 435/512

Epoch 00435: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6103e-11 - val_loss: 2.6512e-11
Epoch 436/512

Epoch 00436: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5992e-11 - val_loss: 2.5150e-11
Epoch 437/512

Epoch 00437: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4428e-11 - val_loss: 2.3711e-11
Epoch 438/512

Epoch 00438: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2374e-11 - val_loss: 2.0349e-11
Epoch 439/512

Epoch 00439: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9623e-11 - val_loss: 1.9392e-11
Epoch 440/512

Epoch 00440: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8924e-11 - val_loss: 1.8006e-11
Epoch 441/512

Epoch 00441: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7414e-11 - val_loss: 1.6510e-11
Epoch 442/512

Epoch 00442: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5745e-11 - val_loss: 1.4893e-11
Epoch 443/512

Epoch 00443: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4717e-11 - val_loss: 1.4847e-11
Epoch 444/512

Epoch 00444: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5371e-11 - val_loss: 1.6597e-11
Epoch 445/512

Epoch 00445: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7303e-11 - val_loss: 1.8628e-11
Epoch 446/512

Epoch 00446: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8906e-11 - val_loss: 1.8858e-11
Epoch 447/512

Epoch 00447: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8793e-11 - val_loss: 1.8002e-11
Epoch 448/512

Epoch 00448: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7415e-11 - val_loss: 1.6224e-11
Epoch 449/512

Epoch 00449: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6026e-11 - val_loss: 1.6376e-11
Epoch 450/512

Epoch 00450: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6469e-11 - val_loss: 1.7361e-11
Epoch 451/512

Epoch 00451: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7546e-11 - val_loss: 1.8537e-11
Epoch 452/512

Epoch 00452: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8926e-11 - val_loss: 1.9833e-11
Epoch 453/512

Epoch 00453: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9621e-11 - val_loss: 1.9516e-11
Epoch 454/512

Epoch 00454: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9588e-11 - val_loss: 2.1715e-11
Epoch 455/512

Epoch 00455: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3009e-11 - val_loss: 2.5437e-11
Epoch 456/512

Epoch 00456: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5598e-11 - val_loss: 2.6432e-11
Epoch 457/512

Epoch 00457: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6276e-11 - val_loss: 2.6571e-11
Epoch 458/512

Epoch 00458: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5534e-11 - val_loss: 2.4469e-11
Epoch 459/512

Epoch 00459: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3646e-11 - val_loss: 2.2971e-11
Epoch 460/512

Epoch 00460: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2282e-11 - val_loss: 2.1710e-11
Epoch 461/512

Epoch 00461: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2656e-11 - val_loss: 2.3910e-11
Epoch 462/512

Epoch 00462: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4378e-11 - val_loss: 2.5448e-11
Epoch 463/512

Epoch 00463: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4423e-11 - val_loss: 2.2008e-11
Epoch 464/512

Epoch 00464: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0603e-11 - val_loss: 1.9286e-11
Epoch 465/512

Epoch 00465: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8467e-11 - val_loss: 1.7620e-11
Epoch 466/512

Epoch 00466: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7144e-11 - val_loss: 1.6588e-11
Epoch 467/512

Epoch 00467: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5872e-11 - val_loss: 1.5220e-11
Epoch 468/512

Epoch 00468: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5047e-11 - val_loss: 1.5166e-11
Epoch 469/512

Epoch 00469: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4998e-11 - val_loss: 1.5201e-11
Epoch 470/512

Epoch 00470: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.5154e-11 - val_loss: 1.4675e-11
Epoch 471/512

Epoch 00471: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4712e-11 - val_loss: 1.5237e-11
Epoch 472/512

Epoch 00472: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5757e-11 - val_loss: 1.6448e-11
Epoch 473/512

Epoch 00473: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6917e-11 - val_loss: 1.7583e-11
Epoch 474/512

Epoch 00474: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7549e-11 - val_loss: 1.8023e-11
Epoch 475/512

Epoch 00475: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8005e-11 - val_loss: 1.8264e-11
Epoch 476/512

Epoch 00476: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7720e-11 - val_loss: 1.7357e-11
Epoch 477/512

Epoch 00477: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6955e-11 - val_loss: 1.6251e-11
Epoch 478/512

Epoch 00478: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5887e-11 - val_loss: 1.5579e-11
Epoch 479/512

Epoch 00479: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5308e-11 - val_loss: 1.5312e-11
Epoch 480/512

Epoch 00480: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5835e-11 - val_loss: 1.7084e-11
Epoch 481/512

Epoch 00481: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8723e-11 - val_loss: 2.1090e-11
Epoch 482/512

Epoch 00482: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1646e-11 - val_loss: 2.3052e-11
Epoch 483/512

Epoch 00483: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3694e-11 - val_loss: 2.4894e-11
Epoch 484/512

Epoch 00484: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5108e-11 - val_loss: 2.5690e-11
Epoch 485/512

Epoch 00485: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5341e-11 - val_loss: 2.5510e-11
Epoch 486/512

Epoch 00486: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5146e-11 - val_loss: 2.5005e-11
Epoch 487/512

Epoch 00487: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3995e-11 - val_loss: 2.1720e-11
Epoch 488/512

Epoch 00488: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0224e-11 - val_loss: 1.8422e-11
Epoch 489/512

Epoch 00489: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8023e-11 - val_loss: 1.7866e-11
Epoch 490/512

Epoch 00490: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6919e-11 - val_loss: 1.5434e-11
Epoch 491/512

Epoch 00491: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4983e-11 - val_loss: 1.4649e-11
Epoch 492/512

Epoch 00492: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.4278e-11 - val_loss: 1.4052e-11
Epoch 493/512

Epoch 00493: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_addition_weights.h5
512/512 - 0s - loss: 1.3935e-11 - val_loss: 1.3862e-11
Epoch 494/512

Epoch 00494: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4093e-11 - val_loss: 1.4950e-11
Epoch 495/512

Epoch 00495: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5650e-11 - val_loss: 1.7036e-11
Epoch 496/512

Epoch 00496: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7299e-11 - val_loss: 1.7676e-11
Epoch 497/512

Epoch 00497: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7480e-11 - val_loss: 1.7578e-11
Epoch 498/512

Epoch 00498: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7596e-11 - val_loss: 1.7353e-11
Epoch 499/512

Epoch 00499: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6753e-11 - val_loss: 1.5829e-11
Epoch 500/512

Epoch 00500: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5207e-11 - val_loss: 1.4419e-11
Epoch 501/512

Epoch 00501: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4691e-11 - val_loss: 1.5423e-11
Epoch 502/512

Epoch 00502: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5188e-11 - val_loss: 1.4750e-11
Epoch 503/512

Epoch 00503: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4512e-11 - val_loss: 1.5518e-11
Epoch 504/512

Epoch 00504: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6215e-11 - val_loss: 1.6988e-11
Epoch 505/512

Epoch 00505: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6786e-11 - val_loss: 1.6599e-11
Epoch 506/512

Epoch 00506: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6521e-11 - val_loss: 1.6340e-11
Epoch 507/512

Epoch 00507: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5777e-11 - val_loss: 1.5608e-11
Epoch 508/512

Epoch 00508: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5354e-11 - val_loss: 1.5197e-11
Epoch 509/512

Epoch 00509: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6087e-11 - val_loss: 1.7122e-11
Epoch 510/512

Epoch 00510: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7928e-11 - val_loss: 1.9896e-11
Epoch 511/512

Epoch 00511: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0820e-11 - val_loss: 2.2202e-11
Epoch 512/512

Epoch 00512: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2433e-11 - val_loss: 2.2909e-11
Train on 512 samples, validate on 512 samples
Epoch 1/512
512/512 - 1s - loss: 0.0698 - val_loss: 0.0094
Epoch 2/512
512/512 - 0s - loss: 0.0075 - val_loss: 0.0017
Epoch 3/512
512/512 - 0s - loss: 0.0042 - val_loss: 5.1939e-04
Epoch 4/512
512/512 - 0s - loss: 0.0030 - val_loss: 3.3444e-04
Epoch 5/512
512/512 - 0s - loss: 0.0022 - val_loss: 2.8730e-04
Epoch 6/512
512/512 - 0s - loss: 0.0016 - val_loss: 2.5339e-04
Epoch 7/512
512/512 - 0s - loss: 0.0012 - val_loss: 2.0642e-04
Epoch 8/512
512/512 - 0s - loss: 8.9629e-04 - val_loss: 1.5279e-04
Epoch 9/512
512/512 - 0s - loss: 6.5192e-04 - val_loss: 1.0365e-04
Epoch 10/512
512/512 - 0s - loss: 4.6952e-04 - val_loss: 6.2429e-05
Epoch 11/512
512/512 - 0s - loss: 3.3826e-04 - val_loss: 3.6247e-05
Epoch 12/512
512/512 - 0s - loss: 2.4978e-04 - val_loss: 2.1303e-05
Epoch 13/512
512/512 - 0s - loss: 2.5244e-04 - val_loss: 6.1876e-05
Epoch 14/512
512/512 - 0s - loss: 4.7827e-04 - val_loss: 5.6584e-05
Epoch 15/512
512/512 - 0s - loss: 1.8907e-04 - val_loss: 2.8712e-05
Epoch 16/512
512/512 - 0s - loss: 1.4814e-04 - val_loss: 5.0016e-05
Epoch 17/512
512/512 - 0s - loss: 2.4733e-04 - val_loss: 2.2127e-04
Epoch 18/512
512/512 - 0s - loss: 3.1706e-04 - val_loss: 1.0955e-04
Epoch 19/512
512/512 - 0s - loss: 1.4956e-04 - val_loss: 5.6690e-05
Epoch 20/512
512/512 - 0s - loss: 1.1551e-04 - val_loss: 1.0342e-04
Epoch 21/512
512/512 - 0s - loss: 1.9424e-04 - val_loss: 2.2606e-04
Epoch 22/512
512/512 - 0s - loss: 1.8348e-04 - val_loss: 9.4711e-05
Epoch 23/512
512/512 - 0s - loss: 9.5083e-05 - val_loss: 7.6110e-05
Epoch 24/512
512/512 - 0s - loss: 1.0561e-04 - val_loss: 1.5715e-04
Epoch 25/512
512/512 - 0s - loss: 1.3223e-04 - val_loss: 1.1055e-04
Epoch 26/512
512/512 - 0s - loss: 8.1776e-05 - val_loss: 7.8369e-05
Epoch 27/512
512/512 - 0s - loss: 7.2287e-05 - val_loss: 1.0557e-04
Epoch 28/512
512/512 - 0s - loss: 9.3856e-05 - val_loss: 1.2974e-04
Epoch 29/512
512/512 - 0s - loss: 6.0836e-05 - val_loss: 3.5566e-05
Epoch 30/512
512/512 - 0s - loss: 2.8674e-05 - val_loss: 4.1568e-05
Epoch 31/512
512/512 - 0s - loss: 4.5859e-05 - val_loss: 1.8323e-04
Epoch 32/512
512/512 - 0s - loss: 7.1631e-05 - val_loss: 3.8669e-05
Epoch 33/512
512/512 - 0s - loss: 2.3894e-05 - val_loss: 4.6964e-05
Epoch 34/512
512/512 - 0s - loss: 1.5828e-05 - val_loss: 2.7359e-05
Epoch 35/512
512/512 - 0s - loss: 2.4999e-05 - val_loss: 1.2100e-04
Epoch 36/512
512/512 - 0s - loss: 4.7370e-05 - val_loss: 3.0224e-05
Epoch 37/512
512/512 - 0s - loss: 1.1207e-05 - val_loss: 1.2457e-05
Epoch 38/512
512/512 - 0s - loss: 7.1265e-06 - val_loss: 2.6613e-05
Epoch 39/512
512/512 - 0s - loss: 2.2844e-05 - val_loss: 7.1800e-05
Epoch 40/512
512/512 - 0s - loss: 1.8780e-05 - val_loss: 1.6066e-05
Epoch 41/512
512/512 - 0s - loss: 6.8229e-06 - val_loss: 3.3722e-05
Epoch 42/512
512/512 - 0s - loss: 1.5715e-05 - val_loss: 2.6235e-05
Epoch 43/512
512/512 - 0s - loss: 7.8551e-06 - val_loss: 1.0728e-05
Epoch 44/512
512/512 - 0s - loss: 4.4954e-06 - val_loss: 2.1761e-05
Epoch 45/512
512/512 - 0s - loss: 1.4409e-05 - val_loss: 1.3121e-05
Epoch 46/512
512/512 - 0s - loss: 3.1187e-06 - val_loss: 5.0548e-06
Epoch 47/512
512/512 - 0s - loss: 1.7540e-06 - val_loss: 5.2532e-06
Epoch 48/512
512/512 - 0s - loss: 1.7842e-06 - val_loss: 1.1143e-05
Epoch 49/512
512/512 - 0s - loss: 1.1492e-05 - val_loss: 3.8250e-05
Epoch 50/512
512/512 - 0s - loss: 5.4870e-06 - val_loss: 2.2429e-06
Epoch 51/512
512/512 - 0s - loss: 1.0589e-06 - val_loss: 4.3495e-06
Epoch 52/512
512/512 - 0s - loss: 1.1592e-06 - val_loss: 7.2388e-06
Epoch 53/512
512/512 - 0s - loss: 2.8283e-06 - val_loss: 1.8236e-05
Epoch 54/512
512/512 - 0s - loss: 4.0033e-06 - val_loss: 2.9424e-06
Epoch 55/512
512/512 - 0s - loss: 1.0220e-06 - val_loss: 1.0897e-05
Epoch 56/512
512/512 - 0s - loss: 2.9359e-06 - val_loss: 7.8699e-06
Epoch 57/512
512/512 - 0s - loss: 4.2597e-06 - val_loss: 1.4174e-06
Epoch 58/512
512/512 - 0s - loss: 5.2535e-07 - val_loss: 1.7669e-06
Epoch 59/512
512/512 - 0s - loss: 3.6994e-07 - val_loss: 1.9172e-06
Epoch 60/512
512/512 - 0s - loss: 3.4942e-07 - val_loss: 1.7843e-06
Epoch 61/512
512/512 - 0s - loss: 3.2514e-07 - val_loss: 1.3975e-06
Epoch 62/512
512/512 - 0s - loss: 3.1418e-07 - val_loss: 5.4971e-07
Epoch 63/512
512/512 - 0s - loss: 2.5681e-06 - val_loss: 9.7447e-07
Epoch 64/512
512/512 - 0s - loss: 5.0904e-07 - val_loss: 6.6474e-07
Epoch 65/512
512/512 - 0s - loss: 4.4949e-07 - val_loss: 4.6625e-07
Epoch 66/512
512/512 - 0s - loss: 3.0377e-07 - val_loss: 6.5456e-07
Epoch 67/512
512/512 - 0s - loss: 1.9763e-07 - val_loss: 2.9297e-07
Epoch 68/512
512/512 - 0s - loss: 7.6757e-07 - val_loss: 4.6437e-07
Epoch 69/512
512/512 - 0s - loss: 9.1825e-07 - val_loss: 2.4668e-07
Epoch 70/512
512/512 - 0s - loss: 1.6412e-07 - val_loss: 3.0893e-07
Epoch 71/512
512/512 - 0s - loss: 2.3629e-07 - val_loss: 2.3805e-07
Epoch 72/512
512/512 - 0s - loss: 8.5920e-07 - val_loss: 1.7919e-07
Epoch 73/512
512/512 - 0s - loss: 1.7291e-07 - val_loss: 4.8127e-07
Epoch 74/512
512/512 - 0s - loss: 6.9451e-08 - val_loss: 4.1909e-07
Epoch 75/512
512/512 - 0s - loss: 6.1010e-08 - val_loss: 3.8269e-07
Epoch 76/512
512/512 - 0s - loss: 1.3077e-07 - val_loss: 7.9923e-07
Epoch 77/512
512/512 - 0s - loss: 1.7579e-07 - val_loss: 5.9500e-07
Epoch 78/512
512/512 - 0s - loss: 1.0854e-07 - val_loss: 6.6688e-07
Epoch 79/512
512/512 - 0s - loss: 1.3871e-07 - val_loss: 5.3415e-07
Epoch 80/512
512/512 - 0s - loss: 9.4224e-08 - val_loss: 4.5602e-07
Epoch 81/512
512/512 - 0s - loss: 1.6580e-07 - val_loss: 2.8200e-07
Epoch 82/512
512/512 - 0s - loss: 7.1004e-08 - val_loss: 2.4194e-07
Epoch 83/512
512/512 - 0s - loss: 5.6956e-08 - val_loss: 2.5214e-07
Epoch 84/512
512/512 - 0s - loss: 8.1573e-08 - val_loss: 3.8816e-07
Epoch 85/512
512/512 - 0s - loss: 1.0564e-07 - val_loss: 2.2909e-07
Epoch 86/512
512/512 - 0s - loss: 5.4493e-08 - val_loss: 2.2803e-07
Epoch 87/512
512/512 - 0s - loss: 4.4189e-08 - val_loss: 1.4787e-07
Epoch 88/512
512/512 - 0s - loss: 3.7498e-08 - val_loss: 1.8319e-07
Epoch 89/512
512/512 - 0s - loss: 7.2864e-08 - val_loss: 2.6896e-07
Epoch 90/512
512/512 - 0s - loss: 5.7253e-08 - val_loss: 1.0385e-07
Epoch 91/512
512/512 - 0s - loss: 2.4795e-08 - val_loss: 1.0962e-07
Epoch 92/512
512/512 - 0s - loss: 3.4451e-08 - val_loss: 1.5467e-07
Epoch 93/512
512/512 - 0s - loss: 5.5363e-08 - val_loss: 1.0518e-07
Epoch 94/512
512/512 - 0s - loss: 2.8452e-08 - val_loss: 9.4715e-08
Epoch 95/512
512/512 - 0s - loss: 2.7853e-08 - val_loss: 1.0813e-07
Epoch 96/512
512/512 - 0s - loss: 3.2567e-08 - val_loss: 9.2896e-08
Epoch 97/512
512/512 - 0s - loss: 2.9598e-08 - val_loss: 9.5625e-08
Epoch 98/512
512/512 - 0s - loss: 2.5349e-08 - val_loss: 8.2196e-08
Epoch 99/512
512/512 - 0s - loss: 2.0863e-08 - val_loss: 7.8650e-08
Epoch 100/512
512/512 - 0s - loss: 2.1295e-08 - val_loss: 8.0205e-08
Epoch 101/512
512/512 - 0s - loss: 2.0314e-08 - val_loss: 6.1412e-08
Epoch 102/512
512/512 - 0s - loss: 1.6740e-08 - val_loss: 6.9854e-08
Epoch 103/512
512/512 - 0s - loss: 2.0361e-08 - val_loss: 6.2823e-08
Epoch 104/512
512/512 - 0s - loss: 1.4852e-08 - val_loss: 5.3730e-08
Epoch 105/512
512/512 - 0s - loss: 1.3753e-08 - val_loss: 6.0647e-08
Epoch 106/512
512/512 - 0s - loss: 1.7518e-08 - val_loss: 5.8654e-08
Epoch 107/512
512/512 - 0s - loss: 1.4048e-08 - val_loss: 4.9967e-08
Epoch 108/512
512/512 - 0s - loss: 1.2247e-08 - val_loss: 4.9339e-08
Epoch 109/512
512/512 - 0s - loss: 1.1785e-08 - val_loss: 4.9300e-08
Epoch 110/512
512/512 - 0s - loss: 1.5957e-08 - val_loss: 7.3621e-08
Epoch 111/512
512/512 - 0s - loss: 1.4481e-08 - val_loss: 3.5968e-08
Epoch 112/512
512/512 - 0s - loss: 6.9195e-09 - val_loss: 3.3135e-08
Epoch 113/512
512/512 - 0s - loss: 6.5746e-09 - val_loss: 2.6822e-08
Epoch 114/512
512/512 - 0s - loss: 6.0056e-09 - val_loss: 4.4633e-08
Epoch 115/512
512/512 - 0s - loss: 2.2877e-08 - val_loss: 3.4188e-08
Epoch 116/512
512/512 - 0s - loss: 8.7920e-09 - val_loss: 3.2781e-08
Epoch 117/512
512/512 - 0s - loss: 7.2373e-09 - val_loss: 3.7888e-08
Epoch 118/512
512/512 - 0s - loss: 9.7032e-09 - val_loss: 4.0200e-08
Epoch 119/512
512/512 - 0s - loss: 1.1294e-08 - val_loss: 3.5901e-08
Epoch 120/512
512/512 - 0s - loss: 7.1459e-09 - val_loss: 3.1026e-08
Epoch 121/512
512/512 - 0s - loss: 5.9547e-09 - val_loss: 3.1372e-08
Epoch 122/512
512/512 - 0s - loss: 6.6621e-09 - val_loss: 3.2887e-08
Epoch 123/512
512/512 - 0s - loss: 9.5554e-09 - val_loss: 4.2939e-08
Epoch 124/512
512/512 - 0s - loss: 8.4221e-09 - val_loss: 2.7747e-08
Epoch 125/512
512/512 - 0s - loss: 4.8477e-09 - val_loss: 2.6540e-08
Epoch 126/512
512/512 - 0s - loss: 4.5878e-09 - val_loss: 2.6885e-08
Epoch 127/512
512/512 - 0s - loss: 5.3266e-09 - val_loss: 3.0485e-08
Epoch 128/512
512/512 - 0s - loss: 7.6431e-09 - val_loss: 3.1598e-08
Epoch 129/512
512/512 - 0s - loss: 6.5825e-09 - val_loss: 2.5887e-08
Epoch 130/512
512/512 - 0s - loss: 4.8089e-09 - val_loss: 2.4946e-08
Epoch 131/512
512/512 - 0s - loss: 4.4586e-09 - val_loss: 2.4453e-08
Epoch 132/512
512/512 - 0s - loss: 4.8612e-09 - val_loss: 2.6030e-08
Epoch 133/512
512/512 - 0s - loss: 5.9523e-09 - val_loss: 2.6108e-08
Epoch 134/512
512/512 - 0s - loss: 5.6129e-09 - val_loss: 2.4152e-08
Epoch 135/512
512/512 - 0s - loss: 4.7446e-09 - val_loss: 2.3015e-08
Epoch 136/512
512/512 - 0s - loss: 4.7296e-09 - val_loss: 2.3817e-08
Epoch 137/512
512/512 - 0s - loss: 4.5930e-09 - val_loss: 2.2112e-08
Epoch 138/512
512/512 - 0s - loss: 4.2270e-09 - val_loss: 2.1364e-08
Epoch 139/512
512/512 - 0s - loss: 4.5329e-09 - val_loss: 2.3438e-08
Epoch 140/512
512/512 - 0s - loss: 4.9324e-09 - val_loss: 2.0654e-08
Epoch 141/512
512/512 - 0s - loss: 4.2912e-09 - val_loss: 2.0499e-08
Epoch 142/512
512/512 - 0s - loss: 4.4050e-09 - val_loss: 2.1081e-08
Epoch 143/512
512/512 - 0s - loss: 4.4724e-09 - val_loss: 2.2106e-08
Epoch 144/512
512/512 - 0s - loss: 4.1126e-09 - val_loss: 1.9657e-08
Epoch 145/512
512/512 - 0s - loss: 3.4503e-09 - val_loss: 1.8608e-08
Epoch 146/512
512/512 - 0s - loss: 3.3479e-09 - val_loss: 2.1491e-08
Epoch 147/512
512/512 - 0s - loss: 4.0903e-09 - val_loss: 1.9383e-08
Epoch 148/512
512/512 - 0s - loss: 3.7641e-09 - val_loss: 1.8956e-08
Epoch 149/512
512/512 - 0s - loss: 3.4863e-09 - val_loss: 1.7901e-08
Epoch 150/512
512/512 - 0s - loss: 3.3567e-09 - val_loss: 1.7656e-08
Epoch 151/512
512/512 - 0s - loss: 3.4338e-09 - val_loss: 1.7842e-08
Epoch 152/512
512/512 - 0s - loss: 3.6348e-09 - val_loss: 1.6745e-08
Epoch 153/512
512/512 - 0s - loss: 3.4346e-09 - val_loss: 1.5426e-08
Epoch 154/512
512/512 - 0s - loss: 3.1626e-09 - val_loss: 1.6791e-08
Epoch 155/512
512/512 - 0s - loss: 3.7957e-09 - val_loss: 1.8262e-08
Epoch 156/512
512/512 - 0s - loss: 3.2430e-09 - val_loss: 1.4785e-08
Epoch 157/512
512/512 - 0s - loss: 2.7029e-09 - val_loss: 1.5234e-08
Epoch 158/512
512/512 - 0s - loss: 3.0494e-09 - val_loss: 1.6334e-08
Epoch 159/512
512/512 - 0s - loss: 3.1337e-09 - val_loss: 1.4916e-08
Epoch 160/512
512/512 - 0s - loss: 3.4866e-09 - val_loss: 1.7703e-08
Epoch 161/512
512/512 - 0s - loss: 3.6695e-09 - val_loss: 1.5721e-08
Epoch 162/512
512/512 - 0s - loss: 2.7954e-09 - val_loss: 1.4695e-08
Epoch 163/512
512/512 - 0s - loss: 2.5347e-09 - val_loss: 1.4082e-08
Epoch 164/512
512/512 - 0s - loss: 2.5641e-09 - val_loss: 1.4796e-08
Epoch 165/512
512/512 - 0s - loss: 2.9620e-09 - val_loss: 1.6848e-08
Epoch 166/512
512/512 - 0s - loss: 3.0500e-09 - val_loss: 1.4963e-08
Epoch 167/512
512/512 - 0s - loss: 2.5012e-09 - val_loss: 1.3873e-08
Epoch 168/512
512/512 - 0s - loss: 2.3278e-09 - val_loss: 1.3434e-08
Epoch 169/512
512/512 - 0s - loss: 2.3115e-09 - val_loss: 1.3654e-08
Epoch 170/512
512/512 - 0s - loss: 2.4952e-09 - val_loss: 1.4494e-08
Epoch 171/512
512/512 - 0s - loss: 2.6775e-09 - val_loss: 1.3962e-08
Epoch 172/512
512/512 - 0s - loss: 2.7469e-09 - val_loss: 1.4396e-08
Epoch 173/512
512/512 - 0s - loss: 2.4407e-09 - val_loss: 1.3057e-08
Epoch 174/512
512/512 - 0s - loss: 2.2363e-09 - val_loss: 1.2574e-08
Epoch 175/512
512/512 - 0s - loss: 2.2364e-09 - val_loss: 1.3258e-08
Epoch 176/512
512/512 - 0s - loss: 2.3423e-09 - val_loss: 1.3581e-08
Epoch 177/512
512/512 - 0s - loss: 2.4720e-09 - val_loss: 1.2947e-08
Epoch 178/512
512/512 - 0s - loss: 2.3601e-09 - val_loss: 1.2604e-08
Epoch 179/512
512/512 - 0s - loss: 2.2103e-09 - val_loss: 1.2344e-08
Epoch 180/512
512/512 - 0s - loss: 2.0607e-09 - val_loss: 1.2134e-08
Epoch 181/512
512/512 - 0s - loss: 2.0253e-09 - val_loss: 1.1886e-08
Epoch 182/512
512/512 - 0s - loss: 2.0721e-09 - val_loss: 1.2214e-08
Epoch 183/512
512/512 - 0s - loss: 2.1911e-09 - val_loss: 1.2364e-08
Epoch 184/512
512/512 - 0s - loss: 2.2657e-09 - val_loss: 1.2012e-08
Epoch 185/512
512/512 - 0s - loss: 2.1724e-09 - val_loss: 1.1824e-08
Epoch 186/512
512/512 - 0s - loss: 2.1307e-09 - val_loss: 1.1729e-08
Epoch 187/512
512/512 - 0s - loss: 2.0991e-09 - val_loss: 1.1238e-08
Epoch 188/512
512/512 - 0s - loss: 1.9610e-09 - val_loss: 1.1174e-08
Epoch 189/512
512/512 - 0s - loss: 1.9497e-09 - val_loss: 1.1226e-08
Epoch 190/512
512/512 - 0s - loss: 2.0012e-09 - val_loss: 1.1324e-08
Epoch 191/512
512/512 - 0s - loss: 2.0435e-09 - val_loss: 1.1980e-08
Epoch 192/512
512/512 - 0s - loss: 2.0810e-09 - val_loss: 1.1470e-08
Epoch 193/512
512/512 - 0s - loss: 1.8913e-09 - val_loss: 1.0741e-08
Epoch 194/512
512/512 - 0s - loss: 1.8202e-09 - val_loss: 1.0481e-08
Epoch 195/512
512/512 - 0s - loss: 1.8120e-09 - val_loss: 1.0449e-08
Epoch 196/512
512/512 - 0s - loss: 1.8420e-09 - val_loss: 1.0516e-08
Epoch 197/512
512/512 - 0s - loss: 1.8863e-09 - val_loss: 1.0496e-08
Epoch 198/512
512/512 - 0s - loss: 1.9365e-09 - val_loss: 1.0440e-08
Epoch 199/512
512/512 - 0s - loss: 1.9249e-09 - val_loss: 9.0515e-09
Epoch 200/512
512/512 - 0s - loss: 1.6780e-09 - val_loss: 9.1023e-09
Epoch 201/512
512/512 - 0s - loss: 1.7063e-09 - val_loss: 9.3641e-09
Epoch 202/512
512/512 - 0s - loss: 1.8411e-09 - val_loss: 9.8878e-09
Epoch 203/512
512/512 - 0s - loss: 1.9673e-09 - val_loss: 9.5221e-09
Epoch 204/512
512/512 - 0s - loss: 1.9791e-09 - val_loss: 1.0107e-08
Epoch 205/512
512/512 - 0s - loss: 1.8058e-09 - val_loss: 9.6690e-09
Epoch 206/512
512/512 - 0s - loss: 1.7053e-09 - val_loss: 9.5935e-09
Epoch 207/512
512/512 - 0s - loss: 1.7322e-09 - val_loss: 9.5452e-09
Epoch 208/512
512/512 - 0s - loss: 1.6530e-09 - val_loss: 9.2345e-09
Epoch 209/512
512/512 - 0s - loss: 1.6317e-09 - val_loss: 9.3293e-09
Epoch 210/512
512/512 - 0s - loss: 1.6732e-09 - val_loss: 9.5132e-09
Epoch 211/512
512/512 - 0s - loss: 1.6966e-09 - val_loss: 9.4500e-09
Epoch 212/512
512/512 - 0s - loss: 1.6752e-09 - val_loss: 9.3704e-09
Epoch 213/512
512/512 - 0s - loss: 1.6730e-09 - val_loss: 9.1673e-09
Epoch 214/512
512/512 - 0s - loss: 1.5884e-09 - val_loss: 8.3518e-09
Epoch 215/512
512/512 - 0s - loss: 1.6925e-09 - val_loss: 9.2059e-09
Epoch 216/512
512/512 - 0s - loss: 1.8217e-09 - val_loss: 9.5113e-09
Epoch 217/512
512/512 - 0s - loss: 1.5665e-09 - val_loss: 9.0592e-09
Epoch 218/512
512/512 - 0s - loss: 1.4047e-09 - val_loss: 8.7144e-09
Epoch 219/512
512/512 - 0s - loss: 1.3771e-09 - val_loss: 8.4817e-09
Epoch 220/512
512/512 - 0s - loss: 1.3938e-09 - val_loss: 8.5231e-09
Epoch 221/512
512/512 - 0s - loss: 1.4774e-09 - val_loss: 8.7237e-09
Epoch 222/512
512/512 - 0s - loss: 1.5690e-09 - val_loss: 8.9606e-09
Epoch 223/512
512/512 - 0s - loss: 1.6263e-09 - val_loss: 8.9997e-09
Epoch 224/512
512/512 - 0s - loss: 1.5490e-09 - val_loss: 8.8272e-09
Epoch 225/512
512/512 - 0s - loss: 1.4771e-09 - val_loss: 8.5738e-09
Epoch 226/512
512/512 - 0s - loss: 1.4271e-09 - val_loss: 8.4162e-09
Epoch 227/512
512/512 - 0s - loss: 1.3960e-09 - val_loss: 8.2303e-09
Epoch 228/512
512/512 - 0s - loss: 1.3705e-09 - val_loss: 8.1838e-09
Epoch 229/512
512/512 - 0s - loss: 1.4003e-09 - val_loss: 8.4172e-09
Epoch 230/512
512/512 - 0s - loss: 1.4434e-09 - val_loss: 8.3666e-09
Epoch 231/512
512/512 - 0s - loss: 1.4489e-09 - val_loss: 8.2433e-09
Epoch 232/512
512/512 - 0s - loss: 1.4161e-09 - val_loss: 8.3891e-09
Epoch 233/512
512/512 - 0s - loss: 1.4079e-09 - val_loss: 8.1319e-09
Epoch 234/512
512/512 - 0s - loss: 1.3615e-09 - val_loss: 8.4521e-09
Epoch 235/512
512/512 - 0s - loss: 1.4422e-09 - val_loss: 8.6054e-09
Epoch 236/512
512/512 - 0s - loss: 1.3706e-09 - val_loss: 8.0371e-09
Epoch 237/512
512/512 - 0s - loss: 1.2897e-09 - val_loss: 7.8143e-09
Epoch 238/512
512/512 - 0s - loss: 1.2980e-09 - val_loss: 8.0285e-09
Epoch 239/512
512/512 - 0s - loss: 1.2785e-09 - val_loss: 7.7460e-09
Epoch 240/512
512/512 - 0s - loss: 1.2592e-09 - val_loss: 7.6631e-09
Epoch 241/512
512/512 - 0s - loss: 1.2711e-09 - val_loss: 7.6730e-09
Epoch 242/512
512/512 - 0s - loss: 1.2907e-09 - val_loss: 7.6861e-09
Epoch 243/512
512/512 - 0s - loss: 1.3127e-09 - val_loss: 7.7068e-09
Epoch 244/512
512/512 - 0s - loss: 1.3084e-09 - val_loss: 7.6766e-09
Epoch 245/512
512/512 - 0s - loss: 1.2988e-09 - val_loss: 7.5191e-09
Epoch 246/512
512/512 - 0s - loss: 1.2823e-09 - val_loss: 7.5481e-09
Epoch 247/512
512/512 - 0s - loss: 1.2651e-09 - val_loss: 7.4792e-09
Epoch 248/512
512/512 - 0s - loss: 1.2497e-09 - val_loss: 7.3540e-09
Epoch 249/512
512/512 - 0s - loss: 1.2158e-09 - val_loss: 7.2061e-09
Epoch 250/512
512/512 - 0s - loss: 1.1872e-09 - val_loss: 7.3244e-09
Epoch 251/512
512/512 - 0s - loss: 1.1633e-09 - val_loss: 7.1086e-09
Epoch 252/512
512/512 - 0s - loss: 1.1561e-09 - val_loss: 7.0715e-09
Epoch 253/512
512/512 - 0s - loss: 1.1558e-09 - val_loss: 6.9961e-09
Epoch 254/512
512/512 - 0s - loss: 1.1565e-09 - val_loss: 7.0402e-09
Epoch 255/512
512/512 - 0s - loss: 1.2211e-09 - val_loss: 7.0642e-09
Epoch 256/512
512/512 - 0s - loss: 1.3199e-09 - val_loss: 7.1462e-09
Epoch 257/512
512/512 - 0s - loss: 1.2870e-09 - val_loss: 6.8379e-09
Epoch 258/512
512/512 - 0s - loss: 1.1887e-09 - val_loss: 6.6928e-09
Epoch 259/512
512/512 - 0s - loss: 1.1569e-09 - val_loss: 6.7277e-09
Epoch 260/512
512/512 - 0s - loss: 1.1493e-09 - val_loss: 6.7669e-09
Epoch 261/512
512/512 - 0s - loss: 1.1628e-09 - val_loss: 6.8515e-09
Epoch 262/512
512/512 - 0s - loss: 1.1471e-09 - val_loss: 6.8454e-09
Epoch 263/512
512/512 - 0s - loss: 1.1269e-09 - val_loss: 7.1201e-09
Epoch 264/512
512/512 - 0s - loss: 1.1560e-09 - val_loss: 6.9273e-09
Epoch 265/512
512/512 - 0s - loss: 1.1216e-09 - val_loss: 6.8282e-09
Epoch 266/512
512/512 - 0s - loss: 1.1025e-09 - val_loss: 6.6818e-09
Epoch 267/512
512/512 - 0s - loss: 1.0939e-09 - val_loss: 6.5792e-09
Epoch 268/512
512/512 - 0s - loss: 1.1045e-09 - val_loss: 6.6649e-09
Epoch 269/512
512/512 - 0s - loss: 1.1338e-09 - val_loss: 6.6957e-09
Epoch 270/512
512/512 - 0s - loss: 1.1678e-09 - val_loss: 6.5108e-09
Epoch 271/512
512/512 - 0s - loss: 1.1469e-09 - val_loss: 6.3848e-09
Epoch 272/512
512/512 - 0s - loss: 1.0988e-09 - val_loss: 6.4236e-09
Epoch 273/512
512/512 - 0s - loss: 1.0745e-09 - val_loss: 6.2953e-09
Epoch 274/512
512/512 - 0s - loss: 1.0434e-09 - val_loss: 6.1717e-09
Epoch 275/512
512/512 - 0s - loss: 1.0388e-09 - val_loss: 6.2959e-09
Epoch 276/512
512/512 - 0s - loss: 1.0767e-09 - val_loss: 6.3115e-09
Epoch 277/512
512/512 - 0s - loss: 1.0874e-09 - val_loss: 6.3327e-09
Epoch 278/512
512/512 - 0s - loss: 1.0717e-09 - val_loss: 6.1650e-09
Epoch 279/512
512/512 - 0s - loss: 1.0390e-09 - val_loss: 6.2409e-09
Epoch 280/512
512/512 - 0s - loss: 1.0594e-09 - val_loss: 6.1082e-09
Epoch 281/512
512/512 - 0s - loss: 1.0561e-09 - val_loss: 6.1184e-09
Epoch 282/512
512/512 - 0s - loss: 1.0415e-09 - val_loss: 6.0592e-09
Epoch 283/512
512/512 - 0s - loss: 1.0013e-09 - val_loss: 5.7500e-09
Epoch 284/512
512/512 - 0s - loss: 9.8725e-10 - val_loss: 5.8835e-09
Epoch 285/512
512/512 - 0s - loss: 1.0168e-09 - val_loss: 6.0290e-09
Epoch 286/512
512/512 - 0s - loss: 1.0379e-09 - val_loss: 5.9649e-09
Epoch 287/512
512/512 - 0s - loss: 1.0356e-09 - val_loss: 5.9998e-09
Epoch 288/512
512/512 - 0s - loss: 1.0267e-09 - val_loss: 5.7731e-09
Epoch 289/512
512/512 - 0s - loss: 1.0504e-09 - val_loss: 5.9396e-09
Epoch 290/512
512/512 - 0s - loss: 1.0799e-09 - val_loss: 5.8983e-09
Epoch 291/512
512/512 - 0s - loss: 1.0407e-09 - val_loss: 5.6874e-09
Epoch 292/512
512/512 - 0s - loss: 9.9070e-10 - val_loss: 5.6377e-09
Epoch 293/512
512/512 - 0s - loss: 9.9076e-10 - val_loss: 5.7592e-09
Epoch 294/512
512/512 - 0s - loss: 9.9674e-10 - val_loss: 5.8601e-09
Epoch 295/512
512/512 - 0s - loss: 9.9042e-10 - val_loss: 5.7593e-09
Epoch 296/512
512/512 - 0s - loss: 9.8965e-10 - val_loss: 5.7949e-09
Epoch 297/512
512/512 - 0s - loss: 1.0059e-09 - val_loss: 5.0401e-09
Epoch 298/512
512/512 - 0s - loss: 9.5876e-10 - val_loss: 5.6609e-09
Epoch 299/512
512/512 - 0s - loss: 1.0157e-09 - val_loss: 5.6721e-09
Epoch 300/512
512/512 - 0s - loss: 1.0520e-09 - val_loss: 5.8244e-09
Epoch 301/512
512/512 - 0s - loss: 1.0153e-09 - val_loss: 5.6396e-09
Epoch 302/512
512/512 - 0s - loss: 9.6211e-10 - val_loss: 5.4796e-09
Epoch 303/512
512/512 - 0s - loss: 9.3675e-10 - val_loss: 5.7673e-09
Epoch 304/512
512/512 - 0s - loss: 9.6098e-10 - val_loss: 5.6550e-09
Epoch 305/512
512/512 - 0s - loss: 9.4891e-10 - val_loss: 6.4876e-09
Epoch 306/512
512/512 - 0s - loss: 1.0367e-09 - val_loss: 5.9806e-09
Epoch 307/512
512/512 - 0s - loss: 9.2834e-10 - val_loss: 5.6648e-09
Epoch 308/512
512/512 - 0s - loss: 8.7793e-10 - val_loss: 5.4517e-09
Epoch 309/512
512/512 - 0s - loss: 8.5722e-10 - val_loss: 5.2624e-09
Epoch 310/512
512/512 - 0s - loss: 8.6125e-10 - val_loss: 5.4192e-09
Epoch 311/512
512/512 - 0s - loss: 8.9745e-10 - val_loss: 5.8919e-09
Epoch 312/512
512/512 - 0s - loss: 9.7328e-10 - val_loss: 5.7323e-09
Epoch 313/512
512/512 - 0s - loss: 9.4536e-10 - val_loss: 5.5806e-09
Epoch 314/512
512/512 - 0s - loss: 9.0645e-10 - val_loss: 5.4510e-09
Epoch 315/512
512/512 - 0s - loss: 8.7669e-10 - val_loss: 5.4356e-09
Epoch 316/512
512/512 - 0s - loss: 8.6208e-10 - val_loss: 5.3188e-09
Epoch 317/512
512/512 - 0s - loss: 8.5128e-10 - val_loss: 5.3177e-09
Epoch 318/512
512/512 - 0s - loss: 8.4009e-10 - val_loss: 5.3368e-09
Epoch 319/512
512/512 - 0s - loss: 8.4775e-10 - val_loss: 5.2641e-09
Epoch 320/512
512/512 - 0s - loss: 8.5561e-10 - val_loss: 5.3051e-09
Epoch 321/512
512/512 - 0s - loss: 8.6122e-10 - val_loss: 5.2491e-09
Epoch 322/512
512/512 - 0s - loss: 8.7342e-10 - val_loss: 5.2534e-09
Epoch 323/512
512/512 - 0s - loss: 8.7838e-10 - val_loss: 5.1846e-09
Epoch 324/512
512/512 - 0s - loss: 9.2329e-10 - val_loss: 5.1815e-09
Epoch 325/512
512/512 - 0s - loss: 9.1724e-10 - val_loss: 5.1478e-09
Epoch 326/512
512/512 - 0s - loss: 8.7279e-10 - val_loss: 5.0656e-09
Epoch 327/512
512/512 - 0s - loss: 8.2366e-10 - val_loss: 5.0163e-09
Epoch 328/512
512/512 - 0s - loss: 8.3008e-10 - val_loss: 5.1541e-09
Epoch 329/512
512/512 - 0s - loss: 8.4957e-10 - val_loss: 5.7020e-09
Epoch 330/512
512/512 - 0s - loss: 9.0636e-10 - val_loss: 5.3046e-09
Epoch 331/512
512/512 - 0s - loss: 8.5027e-10 - val_loss: 5.1171e-09
Epoch 332/512
512/512 - 0s - loss: 8.1831e-10 - val_loss: 5.0438e-09
Epoch 333/512
512/512 - 0s - loss: 8.1299e-10 - val_loss: 5.1324e-09
Epoch 334/512
512/512 - 0s - loss: 8.0845e-10 - val_loss: 5.0055e-09
Epoch 335/512
512/512 - 0s - loss: 8.1137e-10 - val_loss: 5.0016e-09
Epoch 336/512
512/512 - 0s - loss: 8.2815e-10 - val_loss: 4.4327e-09
Epoch 337/512
512/512 - 0s - loss: 7.8480e-10 - val_loss: 4.6253e-09
Epoch 338/512
512/512 - 0s - loss: 8.1673e-10 - val_loss: 4.8487e-09
Epoch 339/512
512/512 - 0s - loss: 8.6508e-10 - val_loss: 4.3316e-09
Epoch 340/512
512/512 - 0s - loss: 8.2032e-10 - val_loss: 4.5689e-09
Epoch 341/512
512/512 - 0s - loss: 8.3191e-10 - val_loss: 3.4513e-09
Epoch 342/512
512/512 - 0s - loss: 8.5996e-10 - val_loss: 3.9996e-09
Epoch 343/512
512/512 - 0s - loss: 1.1632e-09 - val_loss: 4.7851e-09
Epoch 344/512
512/512 - 0s - loss: 1.5405e-09 - val_loss: 4.7418e-09
Epoch 345/512
512/512 - 0s - loss: 1.1871e-09 - val_loss: 4.5228e-09
Epoch 346/512
512/512 - 0s - loss: 9.1264e-10 - val_loss: 4.0045e-09
Epoch 347/512
512/512 - 0s - loss: 9.0878e-10 - val_loss: 4.2158e-09
Epoch 348/512
512/512 - 0s - loss: 1.0243e-09 - val_loss: 4.6975e-09
Epoch 349/512
512/512 - 0s - loss: 1.1184e-09 - val_loss: 4.8507e-09
Epoch 350/512
512/512 - 0s - loss: 1.1934e-09 - val_loss: 4.8094e-09
Epoch 351/512
512/512 - 0s - loss: 1.0864e-09 - val_loss: 4.7499e-09
Epoch 352/512
512/512 - 0s - loss: 9.3960e-10 - val_loss: 4.6168e-09
Epoch 353/512
512/512 - 0s - loss: 9.5560e-10 - val_loss: 4.7994e-09
Epoch 354/512
512/512 - 0s - loss: 9.3686e-10 - val_loss: 4.7080e-09
Epoch 355/512
512/512 - 0s - loss: 9.9469e-10 - val_loss: 4.6635e-09
Epoch 356/512
512/512 - 0s - loss: 1.0905e-09 - val_loss: 4.6875e-09
Epoch 357/512
512/512 - 0s - loss: 1.0781e-09 - val_loss: 4.6686e-09
Epoch 358/512
512/512 - 0s - loss: 1.0181e-09 - val_loss: 4.6132e-09
Epoch 359/512
512/512 - 0s - loss: 9.3177e-10 - val_loss: 4.3182e-09
Epoch 360/512
512/512 - 0s - loss: 9.0647e-10 - val_loss: 4.6765e-09
Epoch 361/512
512/512 - 0s - loss: 9.0662e-10 - val_loss: 4.1613e-09
Epoch 362/512
512/512 - 0s - loss: 9.1448e-10 - val_loss: 4.8241e-09
Epoch 363/512
512/512 - 0s - loss: 9.5309e-10 - val_loss: 4.0516e-09
Epoch 364/512
512/512 - 0s - loss: 9.6104e-10 - val_loss: 4.6337e-09
Epoch 365/512
512/512 - 0s - loss: 1.0285e-09 - val_loss: 5.0002e-09
Epoch 366/512
512/512 - 0s - loss: 1.0058e-09 - val_loss: 4.6913e-09
Epoch 367/512
512/512 - 0s - loss: 8.9796e-10 - val_loss: 4.2772e-09
Epoch 368/512
512/512 - 0s - loss: 9.0758e-10 - val_loss: 4.4392e-09
Epoch 369/512
512/512 - 0s - loss: 9.8759e-10 - val_loss: 4.6181e-09
Epoch 370/512
512/512 - 0s - loss: 1.0131e-09 - val_loss: 4.6608e-09
Epoch 371/512
512/512 - 0s - loss: 1.0170e-09 - val_loss: 4.4636e-09
Epoch 372/512
512/512 - 0s - loss: 9.7802e-10 - val_loss: 4.4556e-09
Epoch 373/512
512/512 - 0s - loss: 1.0505e-09 - val_loss: 4.5265e-09
Epoch 374/512
512/512 - 0s - loss: 1.0374e-09 - val_loss: 4.4433e-09
Epoch 375/512
512/512 - 0s - loss: 1.0737e-09 - val_loss: 4.1515e-09
Epoch 376/512
512/512 - 0s - loss: 1.2570e-09 - val_loss: 4.1322e-09
Epoch 377/512
512/512 - 0s - loss: 1.1667e-09 - val_loss: 4.2201e-09
Epoch 378/512
512/512 - 0s - loss: 1.0868e-09 - val_loss: 3.9355e-09
Epoch 379/512
512/512 - 0s - loss: 1.0932e-09 - val_loss: 4.0993e-09
Epoch 380/512
512/512 - 0s - loss: 1.1785e-09 - val_loss: 4.0585e-09
Epoch 381/512
512/512 - 0s - loss: 1.4149e-09 - val_loss: 4.4112e-09
Epoch 382/512
512/512 - 0s - loss: 1.5183e-09 - val_loss: 4.6434e-09
Epoch 383/512
512/512 - 0s - loss: 1.3120e-09 - val_loss: 4.0481e-09
Epoch 384/512
512/512 - 0s - loss: 1.0738e-09 - val_loss: 4.0760e-09
Epoch 385/512
512/512 - 0s - loss: 9.7308e-10 - val_loss: 3.9597e-09
Epoch 386/512
512/512 - 0s - loss: 9.9136e-10 - val_loss: 4.1017e-09
Epoch 387/512
512/512 - 0s - loss: 1.1374e-09 - val_loss: 4.6349e-09
Epoch 388/512
512/512 - 0s - loss: 2.3198e-09 - val_loss: 5.0425e-09
Epoch 389/512
512/512 - 0s - loss: 2.0659e-09 - val_loss: 3.9322e-09
Epoch 390/512
512/512 - 0s - loss: 1.2594e-09 - val_loss: 3.4477e-09
Epoch 391/512
512/512 - 0s - loss: 9.7144e-10 - val_loss: 3.5518e-09
Epoch 392/512
512/512 - 0s - loss: 9.9841e-10 - val_loss: 5.1629e-09
Epoch 393/512
512/512 - 0s - loss: 8.8037e-10 - val_loss: 4.6868e-09
Epoch 394/512
512/512 - 0s - loss: 7.7999e-10 - val_loss: 4.2401e-09
Epoch 395/512
512/512 - 0s - loss: 7.6322e-10 - val_loss: 4.7092e-09
Epoch 396/512
512/512 - 0s - loss: 8.2479e-10 - val_loss: 4.0734e-09
Epoch 397/512
512/512 - 0s - loss: 8.3686e-10 - val_loss: 4.3447e-09
Epoch 398/512
512/512 - 0s - loss: 9.3048e-10 - val_loss: 4.5608e-09
Epoch 399/512
512/512 - 0s - loss: 9.8444e-10 - val_loss: 4.5575e-09
Epoch 400/512
512/512 - 0s - loss: 9.3793e-10 - val_loss: 4.1874e-09
Epoch 401/512
512/512 - 0s - loss: 8.7180e-10 - val_loss: 3.9477e-09
Epoch 402/512
512/512 - 0s - loss: 9.2823e-10 - val_loss: 4.6618e-09
Epoch 403/512
512/512 - 0s - loss: 1.0124e-09 - val_loss: 4.8292e-09
Epoch 404/512
512/512 - 0s - loss: 8.7642e-10 - val_loss: 4.6121e-09
Epoch 405/512
512/512 - 0s - loss: 7.3639e-10 - val_loss: 4.3309e-09
Epoch 406/512
512/512 - 0s - loss: 6.8506e-10 - val_loss: 3.9827e-09
Epoch 407/512
512/512 - 0s - loss: 6.7440e-10 - val_loss: 3.9937e-09
Epoch 408/512
512/512 - 0s - loss: 6.9509e-10 - val_loss: 4.1669e-09
Epoch 409/512
512/512 - 0s - loss: 7.4325e-10 - val_loss: 4.3375e-09
Epoch 410/512
512/512 - 0s - loss: 7.7951e-10 - val_loss: 4.2314e-09
Epoch 411/512
512/512 - 0s - loss: 8.0595e-10 - val_loss: 4.1819e-09
Epoch 412/512
512/512 - 0s - loss: 7.9927e-10 - val_loss: 3.9132e-09
Epoch 413/512
512/512 - 0s - loss: 7.8372e-10 - val_loss: 4.0417e-09
Epoch 414/512
512/512 - 0s - loss: 7.5571e-10 - val_loss: 3.9679e-09
Epoch 415/512
512/512 - 0s - loss: 7.2314e-10 - val_loss: 3.7908e-09
Epoch 416/512
512/512 - 0s - loss: 8.3630e-10 - val_loss: 2.4770e-09
Epoch 417/512
512/512 - 0s - loss: 9.3244e-10 - val_loss: 4.3383e-09
Epoch 418/512
512/512 - 0s - loss: 1.3506e-09 - val_loss: 4.5207e-09
Epoch 419/512
512/512 - 0s - loss: 1.0861e-09 - val_loss: 3.8315e-09
Epoch 420/512
512/512 - 0s - loss: 9.2557e-10 - val_loss: 3.6159e-09
Epoch 421/512
512/512 - 0s - loss: 1.0966e-09 - val_loss: 3.6143e-09
Epoch 422/512
512/512 - 0s - loss: 1.1409e-09 - val_loss: 3.7166e-09
Epoch 423/512
512/512 - 0s - loss: 1.2428e-09 - val_loss: 3.8902e-09
Epoch 424/512
512/512 - 0s - loss: 9.3848e-10 - val_loss: 4.0177e-09
Epoch 425/512
512/512 - 0s - loss: 8.0595e-10 - val_loss: 3.6836e-09
Epoch 426/512
512/512 - 0s - loss: 7.9112e-10 - val_loss: 3.8142e-09
Epoch 427/512
512/512 - 0s - loss: 7.7077e-10 - val_loss: 4.1312e-09
Epoch 428/512
512/512 - 0s - loss: 6.4872e-10 - val_loss: 4.0165e-09
Epoch 429/512
512/512 - 0s - loss: 6.2440e-10 - val_loss: 4.0506e-09
Epoch 430/512
512/512 - 0s - loss: 6.1043e-10 - val_loss: 4.0446e-09
Epoch 431/512
512/512 - 0s - loss: 5.9887e-10 - val_loss: 4.0195e-09
Epoch 432/512
512/512 - 0s - loss: 5.9797e-10 - val_loss: 3.7560e-09
Epoch 433/512
512/512 - 0s - loss: 6.0980e-10 - val_loss: 3.5450e-09
Epoch 434/512
512/512 - 0s - loss: 6.3144e-10 - val_loss: 3.4507e-09
Epoch 435/512
512/512 - 0s - loss: 6.4695e-10 - val_loss: 3.4164e-09
Epoch 436/512
512/512 - 0s - loss: 6.5134e-10 - val_loss: 3.3801e-09
Epoch 437/512
512/512 - 0s - loss: 6.3182e-10 - val_loss: 3.4525e-09
Epoch 438/512
512/512 - 0s - loss: 6.0207e-10 - val_loss: 3.3012e-09
Epoch 439/512
512/512 - 0s - loss: 5.9485e-10 - val_loss: 3.2975e-09
Epoch 440/512
512/512 - 0s - loss: 6.0259e-10 - val_loss: 3.3303e-09
Epoch 441/512
512/512 - 0s - loss: 5.8802e-10 - val_loss: 3.6463e-09
Epoch 442/512
512/512 - 0s - loss: 5.7541e-10 - val_loss: 3.7420e-09
Epoch 443/512
512/512 - 0s - loss: 5.9420e-10 - val_loss: 3.9986e-09
Epoch 444/512
512/512 - 0s - loss: 5.6664e-10 - val_loss: 3.6230e-09
Epoch 445/512
512/512 - 0s - loss: 5.6301e-10 - val_loss: 3.6873e-09
Epoch 446/512
512/512 - 0s - loss: 5.5148e-10 - val_loss: 3.5052e-09
Epoch 447/512
512/512 - 0s - loss: 5.3841e-10 - val_loss: 3.5371e-09
Epoch 448/512
512/512 - 0s - loss: 5.3937e-10 - val_loss: 3.5348e-09
Epoch 449/512
512/512 - 0s - loss: 5.4069e-10 - val_loss: 3.5506e-09
Epoch 450/512
512/512 - 0s - loss: 5.4035e-10 - val_loss: 3.5485e-09
Epoch 451/512
512/512 - 0s - loss: 5.3827e-10 - val_loss: 3.5201e-09
Epoch 452/512
512/512 - 0s - loss: 5.4015e-10 - val_loss: 3.5080e-09
Epoch 453/512
512/512 - 0s - loss: 5.4439e-10 - val_loss: 3.4717e-09
Epoch 454/512
512/512 - 0s - loss: 5.4388e-10 - val_loss: 3.4332e-09
Epoch 455/512
512/512 - 0s - loss: 5.4090e-10 - val_loss: 3.4398e-09
Epoch 456/512
512/512 - 0s - loss: 5.3515e-10 - val_loss: 3.4324e-09
Epoch 457/512
512/512 - 0s - loss: 5.3071e-10 - val_loss: 3.4954e-09
Epoch 458/512
512/512 - 0s - loss: 5.2451e-10 - val_loss: 3.5120e-09
Epoch 459/512
512/512 - 0s - loss: 5.2378e-10 - val_loss: 3.4669e-09
Epoch 460/512
512/512 - 0s - loss: 5.2848e-10 - val_loss: 3.4873e-09
Epoch 461/512
512/512 - 0s - loss: 5.1756e-10 - val_loss: 3.5326e-09
Epoch 462/512
512/512 - 0s - loss: 5.1481e-10 - val_loss: 3.5492e-09
Epoch 463/512
512/512 - 0s - loss: 5.1082e-10 - val_loss: 3.6201e-09
Epoch 464/512
512/512 - 0s - loss: 5.0974e-10 - val_loss: 3.4725e-09
Epoch 465/512
512/512 - 0s - loss: 5.1193e-10 - val_loss: 3.4227e-09
Epoch 466/512
512/512 - 0s - loss: 5.1032e-10 - val_loss: 3.4950e-09
Epoch 467/512
512/512 - 0s - loss: 5.1241e-10 - val_loss: 3.3779e-09
Epoch 468/512
512/512 - 0s - loss: 5.1128e-10 - val_loss: 3.3864e-09
Epoch 469/512
512/512 - 0s - loss: 5.1120e-10 - val_loss: 3.5076e-09
Epoch 470/512
512/512 - 0s - loss: 5.0644e-10 - val_loss: 3.8709e-09
Epoch 471/512
512/512 - 0s - loss: 5.0507e-10 - val_loss: 3.8793e-09
Epoch 472/512
512/512 - 0s - loss: 5.0190e-10 - val_loss: 3.8151e-09
Epoch 473/512
512/512 - 0s - loss: 5.1445e-10 - val_loss: 3.9971e-09
Epoch 474/512
512/512 - 0s - loss: 5.1439e-10 - val_loss: 3.9862e-09
Epoch 475/512
512/512 - 0s - loss: 4.9995e-10 - val_loss: 3.7729e-09
Epoch 476/512
512/512 - 0s - loss: 4.9440e-10 - val_loss: 3.7644e-09
Epoch 477/512
512/512 - 0s - loss: 4.9218e-10 - val_loss: 3.7082e-09
Epoch 478/512
512/512 - 0s - loss: 4.9079e-10 - val_loss: 3.5743e-09
Epoch 479/512
512/512 - 0s - loss: 4.8808e-10 - val_loss: 3.5561e-09
Epoch 480/512
512/512 - 0s - loss: 4.8622e-10 - val_loss: 3.5422e-09
Epoch 481/512
512/512 - 0s - loss: 4.8436e-10 - val_loss: 3.5486e-09
Epoch 482/512
512/512 - 0s - loss: 4.8329e-10 - val_loss: 3.5208e-09
Epoch 483/512
512/512 - 0s - loss: 4.8162e-10 - val_loss: 3.5241e-09
Epoch 484/512
512/512 - 0s - loss: 4.8092e-10 - val_loss: 3.6452e-09
Epoch 485/512
512/512 - 0s - loss: 4.8177e-10 - val_loss: 3.4813e-09
Epoch 486/512
512/512 - 0s - loss: 4.7808e-10 - val_loss: 3.4922e-09
Epoch 487/512
512/512 - 0s - loss: 4.8226e-10 - val_loss: 3.3611e-09
Epoch 488/512
512/512 - 0s - loss: 4.8246e-10 - val_loss: 3.3178e-09
Epoch 489/512
512/512 - 0s - loss: 4.8449e-10 - val_loss: 3.3220e-09
Epoch 490/512
512/512 - 0s - loss: 4.8074e-10 - val_loss: 3.2859e-09
Epoch 491/512
512/512 - 0s - loss: 4.7800e-10 - val_loss: 3.2965e-09
Epoch 492/512
512/512 - 0s - loss: 4.7531e-10 - val_loss: 3.2479e-09
Epoch 493/512
512/512 - 0s - loss: 4.7400e-10 - val_loss: 3.2222e-09
Epoch 494/512
512/512 - 0s - loss: 4.7608e-10 - val_loss: 3.2119e-09
Epoch 495/512
512/512 - 0s - loss: 4.7365e-10 - val_loss: 3.2184e-09
Epoch 496/512
512/512 - 0s - loss: 4.7153e-10 - val_loss: 3.3816e-09
Epoch 497/512
512/512 - 0s - loss: 4.7023e-10 - val_loss: 3.3637e-09
Epoch 498/512
512/512 - 0s - loss: 4.6891e-10 - val_loss: 3.3145e-09
Epoch 499/512
512/512 - 0s - loss: 4.6846e-10 - val_loss: 3.4935e-09
Epoch 500/512
512/512 - 0s - loss: 4.6550e-10 - val_loss: 3.4705e-09
Epoch 501/512
512/512 - 0s - loss: 4.6593e-10 - val_loss: 3.5984e-09
Epoch 502/512
512/512 - 0s - loss: 4.6568e-10 - val_loss: 3.5592e-09
Epoch 503/512
512/512 - 0s - loss: 4.6256e-10 - val_loss: 3.4450e-09
Epoch 504/512
512/512 - 0s - loss: 4.6017e-10 - val_loss: 3.4004e-09
Epoch 505/512
512/512 - 0s - loss: 4.5965e-10 - val_loss: 3.4322e-09
Epoch 506/512
512/512 - 0s - loss: 4.5939e-10 - val_loss: 3.4231e-09
Epoch 507/512
512/512 - 0s - loss: 4.5854e-10 - val_loss: 3.3200e-09
Epoch 508/512
512/512 - 0s - loss: 4.5524e-10 - val_loss: 3.3166e-09
Epoch 509/512
512/512 - 0s - loss: 4.5415e-10 - val_loss: 3.3319e-09
Epoch 510/512
512/512 - 0s - loss: 4.5393e-10 - val_loss: 3.1813e-09
Epoch 511/512
512/512 - 0s - loss: 4.5811e-10 - val_loss: 3.1127e-09
Epoch 512/512
512/512 - 0s - loss: 4.5651e-10 - val_loss: 3.1644e-09
Train on 512 samples, validate on 512 samples
Epoch 1/512

Epoch 00001: val_loss improved from inf to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.6187e-10 - val_loss: 4.6806e-09
Epoch 2/512

Epoch 00002: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.3094e-09 - val_loss: 1.2084e-09
Epoch 3/512

Epoch 00003: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.5574e-10 - val_loss: 1.0231e-10
Epoch 4/512

Epoch 00004: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.5657e-11 - val_loss: 3.6521e-11
Epoch 5/512

Epoch 00005: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5335e-11 - val_loss: 4.1996e-11
Epoch 6/512

Epoch 00006: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.2189e-11 - val_loss: 1.2870e-10
Epoch 7/512

Epoch 00007: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6515e-10 - val_loss: 6.8929e-10
Epoch 8/512

Epoch 00008: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1047e-09 - val_loss: 1.5436e-09
Epoch 9/512

Epoch 00009: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2259e-09 - val_loss: 6.9230e-10
Epoch 10/512

Epoch 00010: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8777e-10 - val_loss: 2.8230e-10
Epoch 11/512

Epoch 00011: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4048e-10 - val_loss: 2.1447e-10
Epoch 12/512

Epoch 00012: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3070e-10 - val_loss: 2.9101e-10
Epoch 13/512

Epoch 00013: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6061e-10 - val_loss: 5.1081e-10
Epoch 14/512

Epoch 00014: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8617e-10 - val_loss: 6.7597e-10
Epoch 15/512

Epoch 00015: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.3249e-10 - val_loss: 5.3968e-10
Epoch 16/512

Epoch 00016: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6469e-10 - val_loss: 3.7143e-10
Epoch 17/512

Epoch 00017: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3403e-10 - val_loss: 3.0074e-10
Epoch 18/512

Epoch 00018: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9755e-10 - val_loss: 3.1112e-10
Epoch 19/512

Epoch 00019: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2768e-10 - val_loss: 3.6658e-10
Epoch 20/512

Epoch 00020: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8305e-10 - val_loss: 4.0882e-10
Epoch 21/512

Epoch 00021: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0402e-10 - val_loss: 3.9258e-10
Epoch 22/512

Epoch 00022: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7114e-10 - val_loss: 3.4326e-10
Epoch 23/512

Epoch 00023: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2440e-10 - val_loss: 3.0414e-10
Epoch 24/512

Epoch 00024: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9268e-10 - val_loss: 2.8620e-10
Epoch 25/512

Epoch 00025: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8227e-10 - val_loss: 2.8518e-10
Epoch 26/512

Epoch 00026: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8630e-10 - val_loss: 2.9345e-10
Epoch 27/512

Epoch 00027: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9118e-10 - val_loss: 2.9256e-10
Epoch 28/512

Epoch 00028: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8689e-10 - val_loss: 2.8253e-10
Epoch 29/512

Epoch 00029: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7529e-10 - val_loss: 2.6805e-10
Epoch 30/512

Epoch 00030: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6008e-10 - val_loss: 2.5299e-10
Epoch 31/512

Epoch 00031: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4727e-10 - val_loss: 2.4279e-10
Epoch 32/512

Epoch 00032: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3820e-10 - val_loss: 2.3545e-10
Epoch 33/512

Epoch 00033: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3181e-10 - val_loss: 2.3091e-10
Epoch 34/512

Epoch 00034: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2902e-10 - val_loss: 2.2950e-10
Epoch 35/512

Epoch 00035: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2575e-10 - val_loss: 2.2349e-10
Epoch 36/512

Epoch 00036: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2013e-10 - val_loss: 2.1762e-10
Epoch 37/512

Epoch 00037: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1318e-10 - val_loss: 2.0914e-10
Epoch 38/512

Epoch 00038: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0476e-10 - val_loss: 2.0177e-10
Epoch 39/512

Epoch 00039: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9853e-10 - val_loss: 1.9714e-10
Epoch 40/512

Epoch 00040: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9362e-10 - val_loss: 1.9041e-10
Epoch 41/512

Epoch 00041: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8638e-10 - val_loss: 1.8315e-10
Epoch 42/512

Epoch 00042: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8123e-10 - val_loss: 1.8068e-10
Epoch 43/512

Epoch 00043: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7867e-10 - val_loss: 1.7777e-10
Epoch 44/512

Epoch 00044: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7465e-10 - val_loss: 1.7173e-10
Epoch 45/512

Epoch 00045: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6898e-10 - val_loss: 1.6605e-10
Epoch 46/512

Epoch 00046: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6280e-10 - val_loss: 1.6075e-10
Epoch 47/512

Epoch 00047: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5893e-10 - val_loss: 1.5885e-10
Epoch 48/512

Epoch 00048: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5675e-10 - val_loss: 1.5489e-10
Epoch 49/512

Epoch 00049: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5253e-10 - val_loss: 1.5108e-10
Epoch 50/512

Epoch 00050: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4882e-10 - val_loss: 1.4756e-10
Epoch 51/512

Epoch 00051: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4548e-10 - val_loss: 1.4342e-10
Epoch 52/512

Epoch 00052: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4108e-10 - val_loss: 1.3865e-10
Epoch 53/512

Epoch 00053: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3566e-10 - val_loss: 1.3311e-10
Epoch 54/512

Epoch 00054: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3161e-10 - val_loss: 1.3085e-10
Epoch 55/512

Epoch 00055: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2959e-10 - val_loss: 1.2908e-10
Epoch 56/512

Epoch 00056: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2801e-10 - val_loss: 1.2768e-10
Epoch 57/512

Epoch 00057: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2597e-10 - val_loss: 1.2511e-10
Epoch 58/512

Epoch 00058: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2340e-10 - val_loss: 1.2146e-10
Epoch 59/512

Epoch 00059: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1956e-10 - val_loss: 1.1810e-10
Epoch 60/512

Epoch 00060: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1668e-10 - val_loss: 1.1540e-10
Epoch 61/512

Epoch 00061: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1382e-10 - val_loss: 1.1245e-10
Epoch 62/512

Epoch 00062: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1075e-10 - val_loss: 1.0921e-10
Epoch 63/512

Epoch 00063: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0727e-10 - val_loss: 1.0579e-10
Epoch 64/512

Epoch 00064: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0452e-10 - val_loss: 1.0353e-10
Epoch 65/512

Epoch 00065: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0248e-10 - val_loss: 1.0233e-10
Epoch 66/512

Epoch 00066: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0161e-10 - val_loss: 1.0140e-10
Epoch 67/512

Epoch 00067: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0056e-10 - val_loss: 1.0029e-10
Epoch 68/512

Epoch 00068: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.9450e-11 - val_loss: 9.9457e-11
Epoch 69/512

Epoch 00069: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.7782e-11 - val_loss: 9.5903e-11
Epoch 70/512

Epoch 00070: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.4160e-11 - val_loss: 9.1815e-11
Epoch 71/512

Epoch 00071: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.0029e-11 - val_loss: 8.8518e-11
Epoch 72/512

Epoch 00072: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.7517e-11 - val_loss: 8.7219e-11
Epoch 73/512

Epoch 00073: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.6854e-11 - val_loss: 8.6997e-11
Epoch 74/512

Epoch 00074: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.6642e-11 - val_loss: 8.6600e-11
Epoch 75/512

Epoch 00075: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.5779e-11 - val_loss: 8.5674e-11
Epoch 76/512

Epoch 00076: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.4953e-11 - val_loss: 8.4392e-11
Epoch 77/512

Epoch 00077: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.3749e-11 - val_loss: 8.3616e-11
Epoch 78/512

Epoch 00078: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.2743e-11 - val_loss: 8.2016e-11
Epoch 79/512

Epoch 00079: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.0985e-11 - val_loss: 7.9568e-11
Epoch 80/512

Epoch 00080: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8107e-11 - val_loss: 7.6508e-11
Epoch 81/512

Epoch 00081: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.5310e-11 - val_loss: 7.4668e-11
Epoch 82/512

Epoch 00082: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.3762e-11 - val_loss: 7.2863e-11
Epoch 83/512

Epoch 00083: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.2019e-11 - val_loss: 7.1040e-11
Epoch 84/512

Epoch 00084: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.0510e-11 - val_loss: 7.0562e-11
Epoch 85/512

Epoch 00085: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.0778e-11 - val_loss: 7.1112e-11
Epoch 86/512

Epoch 00086: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.0330e-11 - val_loss: 6.9428e-11
Epoch 87/512

Epoch 00087: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.8497e-11 - val_loss: 6.7627e-11
Epoch 88/512

Epoch 00088: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.6682e-11 - val_loss: 6.5554e-11
Epoch 89/512

Epoch 00089: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.4818e-11 - val_loss: 6.4756e-11
Epoch 90/512

Epoch 00090: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.3870e-11 - val_loss: 6.3150e-11
Epoch 91/512

Epoch 00091: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.2588e-11 - val_loss: 6.2392e-11
Epoch 92/512

Epoch 00092: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.2045e-11 - val_loss: 6.1178e-11
Epoch 93/512

Epoch 00093: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.0127e-11 - val_loss: 5.9028e-11
Epoch 94/512

Epoch 00094: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8245e-11 - val_loss: 5.7626e-11
Epoch 95/512

Epoch 00095: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7153e-11 - val_loss: 5.7658e-11
Epoch 96/512

Epoch 00096: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7685e-11 - val_loss: 5.7486e-11
Epoch 97/512

Epoch 00097: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7175e-11 - val_loss: 5.7474e-11
Epoch 98/512

Epoch 00098: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7206e-11 - val_loss: 5.7066e-11
Epoch 99/512

Epoch 00099: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.6835e-11 - val_loss: 5.6208e-11
Epoch 100/512

Epoch 00100: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.5683e-11 - val_loss: 5.5539e-11
Epoch 101/512

Epoch 00101: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.5162e-11 - val_loss: 5.3821e-11
Epoch 102/512

Epoch 00102: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2928e-11 - val_loss: 5.2034e-11
Epoch 103/512

Epoch 00103: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1304e-11 - val_loss: 5.0597e-11
Epoch 104/512

Epoch 00104: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0205e-11 - val_loss: 4.9971e-11
Epoch 105/512

Epoch 00105: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9862e-11 - val_loss: 4.9851e-11
Epoch 106/512

Epoch 00106: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9795e-11 - val_loss: 4.9473e-11
Epoch 107/512

Epoch 00107: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9168e-11 - val_loss: 4.8355e-11
Epoch 108/512

Epoch 00108: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7447e-11 - val_loss: 4.6438e-11
Epoch 109/512

Epoch 00109: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6153e-11 - val_loss: 4.5620e-11
Epoch 110/512

Epoch 00110: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5458e-11 - val_loss: 4.5567e-11
Epoch 111/512

Epoch 00111: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5477e-11 - val_loss: 4.5561e-11
Epoch 112/512

Epoch 00112: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5407e-11 - val_loss: 4.5358e-11
Epoch 113/512

Epoch 00113: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5045e-11 - val_loss: 4.4673e-11
Epoch 114/512

Epoch 00114: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4556e-11 - val_loss: 4.4316e-11
Epoch 115/512

Epoch 00115: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3653e-11 - val_loss: 4.2889e-11
Epoch 116/512

Epoch 00116: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2457e-11 - val_loss: 4.1958e-11
Epoch 117/512

Epoch 00117: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1513e-11 - val_loss: 4.0725e-11
Epoch 118/512

Epoch 00118: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0241e-11 - val_loss: 3.9870e-11
Epoch 119/512

Epoch 00119: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9483e-11 - val_loss: 3.8947e-11
Epoch 120/512

Epoch 00120: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8935e-11 - val_loss: 3.8814e-11
Epoch 121/512

Epoch 00121: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8795e-11 - val_loss: 3.8732e-11
Epoch 122/512

Epoch 00122: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8627e-11 - val_loss: 3.8414e-11
Epoch 123/512

Epoch 00123: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8235e-11 - val_loss: 3.8224e-11
Epoch 124/512

Epoch 00124: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8505e-11 - val_loss: 3.8936e-11
Epoch 125/512

Epoch 00125: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8800e-11 - val_loss: 3.8515e-11
Epoch 126/512

Epoch 00126: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7982e-11 - val_loss: 3.7288e-11
Epoch 127/512

Epoch 00127: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6603e-11 - val_loss: 3.5736e-11
Epoch 128/512

Epoch 00128: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.5259e-11 - val_loss: 3.4699e-11
Epoch 129/512

Epoch 00129: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3999e-11 - val_loss: 3.3404e-11
Epoch 130/512

Epoch 00130: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.3095e-11 - val_loss: 3.2879e-11
Epoch 131/512

Epoch 00131: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2673e-11 - val_loss: 3.2715e-11
Epoch 132/512

Epoch 00132: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3368e-11 - val_loss: 3.4171e-11
Epoch 133/512

Epoch 00133: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4296e-11 - val_loss: 3.4589e-11
Epoch 134/512

Epoch 00134: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4643e-11 - val_loss: 3.5100e-11
Epoch 135/512

Epoch 00135: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4872e-11 - val_loss: 3.4771e-11
Epoch 136/512

Epoch 00136: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4329e-11 - val_loss: 3.3776e-11
Epoch 137/512

Epoch 00137: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3322e-11 - val_loss: 3.3388e-11
Epoch 138/512

Epoch 00138: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3158e-11 - val_loss: 3.3067e-11
Epoch 139/512

Epoch 00139: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2752e-11 - val_loss: 3.2637e-11
Epoch 140/512

Epoch 00140: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2597e-11 - val_loss: 3.2446e-11
Epoch 141/512

Epoch 00141: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2378e-11 - val_loss: 3.2154e-11
Epoch 142/512

Epoch 00142: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.1400e-11 - val_loss: 3.0723e-11
Epoch 143/512

Epoch 00143: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.0217e-11 - val_loss: 2.9621e-11
Epoch 144/512

Epoch 00144: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.9230e-11 - val_loss: 2.8904e-11
Epoch 145/512

Epoch 00145: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.8782e-11 - val_loss: 2.8615e-11
Epoch 146/512

Epoch 00146: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.8508e-11 - val_loss: 2.8578e-11
Epoch 147/512

Epoch 00147: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8601e-11 - val_loss: 2.8735e-11
Epoch 148/512

Epoch 00148: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.8504e-11 - val_loss: 2.8116e-11
Epoch 149/512

Epoch 00149: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.7770e-11 - val_loss: 2.7135e-11
Epoch 150/512

Epoch 00150: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.6745e-11 - val_loss: 2.6181e-11
Epoch 151/512

Epoch 00151: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.6034e-11 - val_loss: 2.6014e-11
Epoch 152/512

Epoch 00152: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.5872e-11 - val_loss: 2.5412e-11
Epoch 153/512

Epoch 00153: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5370e-11 - val_loss: 2.5439e-11
Epoch 154/512

Epoch 00154: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.5362e-11 - val_loss: 2.5380e-11
Epoch 155/512

Epoch 00155: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.5238e-11 - val_loss: 2.4884e-11
Epoch 156/512

Epoch 00156: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4874e-11 - val_loss: 2.4935e-11
Epoch 157/512

Epoch 00157: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.4943e-11 - val_loss: 2.4870e-11
Epoch 158/512

Epoch 00158: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.4596e-11 - val_loss: 2.4023e-11
Epoch 159/512

Epoch 00159: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.3878e-11 - val_loss: 2.3861e-11
Epoch 160/512

Epoch 00160: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.3836e-11 - val_loss: 2.3808e-11
Epoch 161/512

Epoch 00161: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.3587e-11 - val_loss: 2.3487e-11
Epoch 162/512

Epoch 00162: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.3313e-11 - val_loss: 2.3143e-11
Epoch 163/512

Epoch 00163: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.3126e-11 - val_loss: 2.3074e-11
Epoch 164/512

Epoch 00164: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.2954e-11 - val_loss: 2.3024e-11
Epoch 165/512

Epoch 00165: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2924e-11 - val_loss: 2.3039e-11
Epoch 166/512

Epoch 00166: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3069e-11 - val_loss: 2.3135e-11
Epoch 167/512

Epoch 00167: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.3129e-11 - val_loss: 2.2982e-11
Epoch 168/512

Epoch 00168: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.2782e-11 - val_loss: 2.2532e-11
Epoch 169/512

Epoch 00169: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.2238e-11 - val_loss: 2.1782e-11
Epoch 170/512

Epoch 00170: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.1555e-11 - val_loss: 2.1303e-11
Epoch 171/512

Epoch 00171: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.1118e-11 - val_loss: 2.0670e-11
Epoch 172/512

Epoch 00172: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.0484e-11 - val_loss: 2.0231e-11
Epoch 173/512

Epoch 00173: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.9993e-11 - val_loss: 1.9641e-11
Epoch 174/512

Epoch 00174: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.9317e-11 - val_loss: 1.8735e-11
Epoch 175/512

Epoch 00175: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.8446e-11 - val_loss: 1.7721e-11
Epoch 176/512

Epoch 00176: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.7394e-11 - val_loss: 1.6966e-11
Epoch 177/512

Epoch 00177: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.6777e-11 - val_loss: 1.6552e-11
Epoch 178/512

Epoch 00178: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6741e-11 - val_loss: 1.7117e-11
Epoch 179/512

Epoch 00179: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7401e-11 - val_loss: 1.7779e-11
Epoch 180/512

Epoch 00180: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7906e-11 - val_loss: 1.8086e-11
Epoch 181/512

Epoch 00181: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8290e-11 - val_loss: 1.8576e-11
Epoch 182/512

Epoch 00182: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8713e-11 - val_loss: 1.8734e-11
Epoch 183/512

Epoch 00183: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8574e-11 - val_loss: 1.8515e-11
Epoch 184/512

Epoch 00184: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8632e-11 - val_loss: 1.8683e-11
Epoch 185/512

Epoch 00185: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8658e-11 - val_loss: 1.8348e-11
Epoch 186/512

Epoch 00186: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8122e-11 - val_loss: 1.7952e-11
Epoch 187/512

Epoch 00187: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7794e-11 - val_loss: 1.7650e-11
Epoch 188/512

Epoch 00188: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7460e-11 - val_loss: 1.6982e-11
Epoch 189/512

Epoch 00189: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.6769e-11 - val_loss: 1.6503e-11
Epoch 190/512

Epoch 00190: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.6368e-11 - val_loss: 1.6312e-11
Epoch 191/512

Epoch 00191: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.6245e-11 - val_loss: 1.6013e-11
Epoch 192/512

Epoch 00192: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5963e-11 - val_loss: 1.5787e-11
Epoch 193/512

Epoch 00193: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5805e-11 - val_loss: 1.5741e-11
Epoch 194/512

Epoch 00194: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5660e-11 - val_loss: 1.5651e-11
Epoch 195/512

Epoch 00195: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5529e-11 - val_loss: 1.5565e-11
Epoch 196/512

Epoch 00196: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5651e-11 - val_loss: 1.5656e-11
Epoch 197/512

Epoch 00197: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5682e-11 - val_loss: 1.5610e-11
Epoch 198/512

Epoch 00198: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5654e-11 - val_loss: 1.5536e-11
Epoch 199/512

Epoch 00199: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5487e-11 - val_loss: 1.5235e-11
Epoch 200/512

Epoch 00200: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.5096e-11 - val_loss: 1.4886e-11
Epoch 201/512

Epoch 00201: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.4744e-11 - val_loss: 1.4660e-11
Epoch 202/512

Epoch 00202: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4663e-11 - val_loss: 1.4752e-11
Epoch 203/512

Epoch 00203: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.4636e-11 - val_loss: 1.4408e-11
Epoch 204/512

Epoch 00204: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.4293e-11 - val_loss: 1.4222e-11
Epoch 205/512

Epoch 00205: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.4141e-11 - val_loss: 1.4015e-11
Epoch 206/512

Epoch 00206: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.3968e-11 - val_loss: 1.3853e-11
Epoch 207/512

Epoch 00207: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.3725e-11 - val_loss: 1.3499e-11
Epoch 208/512

Epoch 00208: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.3354e-11 - val_loss: 1.2867e-11
Epoch 209/512

Epoch 00209: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.2526e-11 - val_loss: 1.2218e-11
Epoch 210/512

Epoch 00210: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.2081e-11 - val_loss: 1.1999e-11
Epoch 211/512

Epoch 00211: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1853e-11 - val_loss: 1.1909e-11
Epoch 212/512

Epoch 00212: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2002e-11 - val_loss: 1.2177e-11
Epoch 213/512

Epoch 00213: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2260e-11 - val_loss: 1.2472e-11
Epoch 214/512

Epoch 00214: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2517e-11 - val_loss: 1.2568e-11
Epoch 215/512

Epoch 00215: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2617e-11 - val_loss: 1.2680e-11
Epoch 216/512

Epoch 00216: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2522e-11 - val_loss: 1.2480e-11
Epoch 217/512

Epoch 00217: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2414e-11 - val_loss: 1.2208e-11
Epoch 218/512

Epoch 00218: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.2094e-11 - val_loss: 1.1833e-11
Epoch 219/512

Epoch 00219: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1807e-11 - val_loss: 1.1821e-11
Epoch 220/512

Epoch 00220: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1867e-11 - val_loss: 1.1895e-11
Epoch 221/512

Epoch 00221: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1731e-11 - val_loss: 1.1404e-11
Epoch 222/512

Epoch 00222: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1439e-11 - val_loss: 1.1429e-11
Epoch 223/512

Epoch 00223: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1434e-11 - val_loss: 1.1571e-11
Epoch 224/512

Epoch 00224: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1561e-11 - val_loss: 1.1412e-11
Epoch 225/512

Epoch 00225: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1250e-11 - val_loss: 1.1118e-11
Epoch 226/512

Epoch 00226: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1097e-11 - val_loss: 1.1073e-11
Epoch 227/512

Epoch 00227: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1180e-11 - val_loss: 1.1335e-11
Epoch 228/512

Epoch 00228: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1341e-11 - val_loss: 1.1233e-11
Epoch 229/512

Epoch 00229: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.1194e-11 - val_loss: 1.1026e-11
Epoch 230/512

Epoch 00230: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0891e-11 - val_loss: 1.0783e-11
Epoch 231/512

Epoch 00231: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1007e-11 - val_loss: 1.1294e-11
Epoch 232/512

Epoch 00232: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1374e-11 - val_loss: 1.1726e-11
Epoch 233/512

Epoch 00233: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1893e-11 - val_loss: 1.2064e-11
Epoch 234/512

Epoch 00234: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1878e-11 - val_loss: 1.1613e-11
Epoch 235/512

Epoch 00235: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1452e-11 - val_loss: 1.1032e-11
Epoch 236/512

Epoch 00236: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0784e-11 - val_loss: 1.0739e-11
Epoch 237/512

Epoch 00237: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0809e-11 - val_loss: 1.0778e-11
Epoch 238/512

Epoch 00238: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0930e-11 - val_loss: 1.1230e-11
Epoch 239/512

Epoch 00239: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1445e-11 - val_loss: 1.1791e-11
Epoch 240/512

Epoch 00240: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1903e-11 - val_loss: 1.1929e-11
Epoch 241/512

Epoch 00241: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1945e-11 - val_loss: 1.2046e-11
Epoch 242/512

Epoch 00242: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2093e-11 - val_loss: 1.2107e-11
Epoch 243/512

Epoch 00243: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2110e-11 - val_loss: 1.1973e-11
Epoch 244/512

Epoch 00244: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1835e-11 - val_loss: 1.1617e-11
Epoch 245/512

Epoch 00245: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1516e-11 - val_loss: 1.1330e-11
Epoch 246/512

Epoch 00246: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1129e-11 - val_loss: 1.0821e-11
Epoch 247/512

Epoch 00247: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0647e-11 - val_loss: 1.0436e-11
Epoch 248/512

Epoch 00248: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0363e-11 - val_loss: 1.0289e-11
Epoch 249/512

Epoch 00249: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0260e-11 - val_loss: 1.0341e-11
Epoch 250/512

Epoch 00250: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0524e-11 - val_loss: 1.0900e-11
Epoch 251/512

Epoch 00251: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1049e-11 - val_loss: 1.1362e-11
Epoch 252/512

Epoch 00252: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1259e-11 - val_loss: 1.1087e-11
Epoch 253/512

Epoch 00253: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1023e-11 - val_loss: 1.0673e-11
Epoch 254/512

Epoch 00254: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0589e-11 - val_loss: 1.0249e-11
Epoch 255/512

Epoch 00255: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.0025e-11 - val_loss: 9.8360e-12
Epoch 256/512

Epoch 00256: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.6029e-12 - val_loss: 9.2724e-12
Epoch 257/512

Epoch 00257: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.1505e-12 - val_loss: 9.0272e-12
Epoch 258/512

Epoch 00258: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.9176e-12 - val_loss: 8.8075e-12
Epoch 259/512

Epoch 00259: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.9179e-12 - val_loss: 8.9268e-12
Epoch 260/512

Epoch 00260: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.0167e-12 - val_loss: 8.9569e-12
Epoch 261/512

Epoch 00261: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.0525e-12 - val_loss: 9.1429e-12
Epoch 262/512

Epoch 00262: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.2394e-12 - val_loss: 9.3771e-12
Epoch 263/512

Epoch 00263: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.3863e-12 - val_loss: 9.4109e-12
Epoch 264/512

Epoch 00264: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.2918e-12 - val_loss: 9.1745e-12
Epoch 265/512

Epoch 00265: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 9.0211e-12 - val_loss: 8.8044e-12
Epoch 266/512

Epoch 00266: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.8057e-12 - val_loss: 8.8413e-12
Epoch 267/512

Epoch 00267: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.7857e-12 - val_loss: 8.8364e-12
Epoch 268/512

Epoch 00268: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.8960e-12 - val_loss: 8.9385e-12
Epoch 269/512

Epoch 00269: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.8991e-12 - val_loss: 8.9035e-12
Epoch 270/512

Epoch 00270: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.8998e-12 - val_loss: 8.8533e-12
Epoch 271/512

Epoch 00271: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.7435e-12 - val_loss: 8.5372e-12
Epoch 272/512

Epoch 00272: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.4680e-12 - val_loss: 8.3020e-12
Epoch 273/512

Epoch 00273: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.4016e-12 - val_loss: 8.5066e-12
Epoch 274/512

Epoch 00274: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.5472e-12 - val_loss: 8.5893e-12
Epoch 275/512

Epoch 00275: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.5886e-12 - val_loss: 8.5871e-12
Epoch 276/512

Epoch 00276: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.5024e-12 - val_loss: 8.3911e-12
Epoch 277/512

Epoch 00277: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.2727e-12 - val_loss: 8.1275e-12
Epoch 278/512

Epoch 00278: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.0548e-12 - val_loss: 7.9722e-12
Epoch 279/512

Epoch 00279: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.0344e-12 - val_loss: 8.1476e-12
Epoch 280/512

Epoch 00280: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.2713e-12 - val_loss: 8.3330e-12
Epoch 281/512

Epoch 00281: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.2212e-12 - val_loss: 8.0923e-12
Epoch 282/512

Epoch 00282: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 8.0723e-12 - val_loss: 7.9425e-12
Epoch 283/512

Epoch 00283: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.0129e-12 - val_loss: 8.1431e-12
Epoch 284/512

Epoch 00284: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.1482e-12 - val_loss: 8.0539e-12
Epoch 285/512

Epoch 00285: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.9833e-12 - val_loss: 7.9288e-12
Epoch 286/512

Epoch 00286: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.9355e-12 - val_loss: 8.0876e-12
Epoch 287/512

Epoch 00287: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.2005e-12 - val_loss: 8.1997e-12
Epoch 288/512

Epoch 00288: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.1746e-12 - val_loss: 8.1508e-12
Epoch 289/512

Epoch 00289: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.1256e-12 - val_loss: 7.9597e-12
Epoch 290/512

Epoch 00290: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.9359e-12 - val_loss: 7.7518e-12
Epoch 291/512

Epoch 00291: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.6809e-12 - val_loss: 7.5595e-12
Epoch 292/512

Epoch 00292: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.5522e-12 - val_loss: 7.3919e-12
Epoch 293/512

Epoch 00293: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 7.2657e-12 - val_loss: 6.9959e-12
Epoch 294/512

Epoch 00294: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.9093e-12 - val_loss: 6.8033e-12
Epoch 295/512

Epoch 00295: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.6902e-12 - val_loss: 6.4794e-12
Epoch 296/512

Epoch 00296: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.4077e-12 - val_loss: 6.3223e-12
Epoch 297/512

Epoch 00297: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.2174e-12 - val_loss: 6.0971e-12
Epoch 298/512

Epoch 00298: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.1214e-12 - val_loss: 6.3615e-12
Epoch 299/512

Epoch 00299: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.4385e-12 - val_loss: 6.6398e-12
Epoch 300/512

Epoch 00300: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.7635e-12 - val_loss: 6.9577e-12
Epoch 301/512

Epoch 00301: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.1909e-12 - val_loss: 7.6615e-12
Epoch 302/512

Epoch 00302: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8252e-12 - val_loss: 8.0482e-12
Epoch 303/512

Epoch 00303: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.0546e-12 - val_loss: 8.1290e-12
Epoch 304/512

Epoch 00304: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.1819e-12 - val_loss: 8.2158e-12
Epoch 305/512

Epoch 00305: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.1909e-12 - val_loss: 8.1278e-12
Epoch 306/512

Epoch 00306: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.1603e-12 - val_loss: 8.0957e-12
Epoch 307/512

Epoch 00307: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.0641e-12 - val_loss: 7.9834e-12
Epoch 308/512

Epoch 00308: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8625e-12 - val_loss: 7.5763e-12
Epoch 309/512

Epoch 00309: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.4116e-12 - val_loss: 7.1316e-12
Epoch 310/512

Epoch 00310: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.0235e-12 - val_loss: 6.7754e-12
Epoch 311/512

Epoch 00311: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.6122e-12 - val_loss: 6.2885e-12
Epoch 312/512

Epoch 00312: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 6.0976e-12 - val_loss: 5.8358e-12
Epoch 313/512

Epoch 00313: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.7327e-12 - val_loss: 5.5390e-12
Epoch 314/512

Epoch 00314: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.4731e-12 - val_loss: 5.3824e-12
Epoch 315/512

Epoch 00315: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.3801e-12 - val_loss: 5.3477e-12
Epoch 316/512

Epoch 00316: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.3072e-12 - val_loss: 5.3199e-12
Epoch 317/512

Epoch 00317: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3118e-12 - val_loss: 5.3550e-12
Epoch 318/512

Epoch 00318: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3999e-12 - val_loss: 5.4355e-12
Epoch 319/512

Epoch 00319: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4188e-12 - val_loss: 5.4215e-12
Epoch 320/512

Epoch 00320: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3948e-12 - val_loss: 5.4050e-12
Epoch 321/512

Epoch 00321: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4190e-12 - val_loss: 5.4072e-12
Epoch 322/512

Epoch 00322: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4318e-12 - val_loss: 5.4290e-12
Epoch 323/512

Epoch 00323: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4420e-12 - val_loss: 5.4479e-12
Epoch 324/512

Epoch 00324: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4056e-12 - val_loss: 5.3584e-12
Epoch 325/512

Epoch 00325: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 5.3053e-12 - val_loss: 5.1013e-12
Epoch 326/512

Epoch 00326: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.9865e-12 - val_loss: 4.7490e-12
Epoch 327/512

Epoch 00327: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.6887e-12 - val_loss: 4.5209e-12
Epoch 328/512

Epoch 00328: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.4884e-12 - val_loss: 4.4225e-12
Epoch 329/512

Epoch 00329: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.3937e-12 - val_loss: 4.3639e-12
Epoch 330/512

Epoch 00330: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.3778e-12 - val_loss: 4.3416e-12
Epoch 331/512

Epoch 00331: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.2834e-12 - val_loss: 4.2071e-12
Epoch 332/512

Epoch 00332: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2019e-12 - val_loss: 4.2083e-12
Epoch 333/512

Epoch 00333: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2978e-12 - val_loss: 4.4626e-12
Epoch 334/512

Epoch 00334: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4245e-12 - val_loss: 4.3791e-12
Epoch 335/512

Epoch 00335: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3591e-12 - val_loss: 4.2986e-12
Epoch 336/512

Epoch 00336: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2816e-12 - val_loss: 4.2277e-12
Epoch 337/512

Epoch 00337: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2324e-12 - val_loss: 4.2354e-12
Epoch 338/512

Epoch 00338: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3631e-12 - val_loss: 4.3891e-12
Epoch 339/512

Epoch 00339: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4077e-12 - val_loss: 4.3326e-12
Epoch 340/512

Epoch 00340: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3269e-12 - val_loss: 4.2393e-12
Epoch 341/512

Epoch 00341: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1943e-12 - val_loss: 4.1378e-12
Epoch 342/512

Epoch 00342: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1196e-12 - val_loss: 4.1430e-12
Epoch 343/512

Epoch 00343: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.1411e-12 - val_loss: 4.0981e-12
Epoch 344/512

Epoch 00344: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0828e-12 - val_loss: 4.0734e-12
Epoch 345/512

Epoch 00345: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0783e-12 - val_loss: 4.0727e-12
Epoch 346/512

Epoch 00346: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0615e-12 - val_loss: 4.0537e-12
Epoch 347/512

Epoch 00347: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 4.0105e-12 - val_loss: 3.9361e-12
Epoch 348/512

Epoch 00348: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8747e-12 - val_loss: 3.8609e-12
Epoch 349/512

Epoch 00349: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.8382e-12 - val_loss: 3.7970e-12
Epoch 350/512

Epoch 00350: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8700e-12 - val_loss: 3.9013e-12
Epoch 351/512

Epoch 00351: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0007e-12 - val_loss: 3.9956e-12
Epoch 352/512

Epoch 00352: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9607e-12 - val_loss: 3.9772e-12
Epoch 353/512

Epoch 00353: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9375e-12 - val_loss: 3.8756e-12
Epoch 354/512

Epoch 00354: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8536e-12 - val_loss: 3.8357e-12
Epoch 355/512

Epoch 00355: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8918e-12 - val_loss: 3.9397e-12
Epoch 356/512

Epoch 00356: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9563e-12 - val_loss: 4.0193e-12
Epoch 357/512

Epoch 00357: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0671e-12 - val_loss: 4.1785e-12
Epoch 358/512

Epoch 00358: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2086e-12 - val_loss: 4.2170e-12
Epoch 359/512

Epoch 00359: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2110e-12 - val_loss: 4.2699e-12
Epoch 360/512

Epoch 00360: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3734e-12 - val_loss: 4.5729e-12
Epoch 361/512

Epoch 00361: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6636e-12 - val_loss: 4.8133e-12
Epoch 362/512

Epoch 00362: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9049e-12 - val_loss: 5.0072e-12
Epoch 363/512

Epoch 00363: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0136e-12 - val_loss: 5.0234e-12
Epoch 364/512

Epoch 00364: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0815e-12 - val_loss: 5.1678e-12
Epoch 365/512

Epoch 00365: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1604e-12 - val_loss: 5.1293e-12
Epoch 366/512

Epoch 00366: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1601e-12 - val_loss: 5.1157e-12
Epoch 367/512

Epoch 00367: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0394e-12 - val_loss: 4.9207e-12
Epoch 368/512

Epoch 00368: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9087e-12 - val_loss: 4.8780e-12
Epoch 369/512

Epoch 00369: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8560e-12 - val_loss: 4.8491e-12
Epoch 370/512

Epoch 00370: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8313e-12 - val_loss: 4.7260e-12
Epoch 371/512

Epoch 00371: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5556e-12 - val_loss: 4.3729e-12
Epoch 372/512

Epoch 00372: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3015e-12 - val_loss: 4.1535e-12
Epoch 373/512

Epoch 00373: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0792e-12 - val_loss: 3.9432e-12
Epoch 374/512

Epoch 00374: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8840e-12 - val_loss: 3.8079e-12
Epoch 375/512

Epoch 00375: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.7569e-12 - val_loss: 3.7076e-12
Epoch 376/512

Epoch 00376: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.6579e-12 - val_loss: 3.5456e-12
Epoch 377/512

Epoch 00377: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.4201e-12 - val_loss: 3.2739e-12
Epoch 378/512

Epoch 00378: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.2439e-12 - val_loss: 3.1174e-12
Epoch 379/512

Epoch 00379: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 3.0614e-12 - val_loss: 2.9537e-12
Epoch 380/512

Epoch 00380: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.8803e-12 - val_loss: 2.8222e-12
Epoch 381/512

Epoch 00381: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.7641e-12 - val_loss: 2.7332e-12
Epoch 382/512

Epoch 00382: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7396e-12 - val_loss: 2.7380e-12
Epoch 383/512

Epoch 00383: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7473e-12 - val_loss: 2.7596e-12
Epoch 384/512

Epoch 00384: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.7101e-12 - val_loss: 2.6644e-12
Epoch 385/512

Epoch 00385: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.6740e-12 - val_loss: 2.6435e-12
Epoch 386/512

Epoch 00386: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6726e-12 - val_loss: 2.7407e-12
Epoch 387/512

Epoch 00387: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7487e-12 - val_loss: 2.7773e-12
Epoch 388/512

Epoch 00388: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7576e-12 - val_loss: 2.7051e-12
Epoch 389/512

Epoch 00389: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7234e-12 - val_loss: 2.7068e-12
Epoch 390/512

Epoch 00390: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7231e-12 - val_loss: 2.6469e-12
Epoch 391/512

Epoch 00391: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.6119e-12 - val_loss: 2.6232e-12
Epoch 392/512

Epoch 00392: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6266e-12 - val_loss: 2.6407e-12
Epoch 393/512

Epoch 00393: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7537e-12 - val_loss: 2.9115e-12
Epoch 394/512

Epoch 00394: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.0765e-12 - val_loss: 3.3648e-12
Epoch 395/512

Epoch 00395: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5565e-12 - val_loss: 3.8378e-12
Epoch 396/512

Epoch 00396: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0035e-12 - val_loss: 4.1739e-12
Epoch 397/512

Epoch 00397: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2901e-12 - val_loss: 4.4404e-12
Epoch 398/512

Epoch 00398: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4867e-12 - val_loss: 4.5488e-12
Epoch 399/512

Epoch 00399: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5421e-12 - val_loss: 4.6190e-12
Epoch 400/512

Epoch 00400: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6289e-12 - val_loss: 4.6150e-12
Epoch 401/512

Epoch 00401: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6122e-12 - val_loss: 4.5105e-12
Epoch 402/512

Epoch 00402: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4244e-12 - val_loss: 4.3511e-12
Epoch 403/512

Epoch 00403: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4214e-12 - val_loss: 4.4145e-12
Epoch 404/512

Epoch 00404: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3544e-12 - val_loss: 4.2884e-12
Epoch 405/512

Epoch 00405: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1894e-12 - val_loss: 4.1020e-12
Epoch 406/512

Epoch 00406: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1158e-12 - val_loss: 4.0720e-12
Epoch 407/512

Epoch 00407: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0864e-12 - val_loss: 4.0709e-12
Epoch 408/512

Epoch 00408: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0314e-12 - val_loss: 3.9704e-12
Epoch 409/512

Epoch 00409: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9384e-12 - val_loss: 3.9284e-12
Epoch 410/512

Epoch 00410: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9675e-12 - val_loss: 3.9567e-12
Epoch 411/512

Epoch 00411: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9958e-12 - val_loss: 4.0995e-12
Epoch 412/512

Epoch 00412: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0666e-12 - val_loss: 4.0102e-12
Epoch 413/512

Epoch 00413: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0200e-12 - val_loss: 3.9754e-12
Epoch 414/512

Epoch 00414: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9742e-12 - val_loss: 4.0069e-12
Epoch 415/512

Epoch 00415: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0093e-12 - val_loss: 4.0457e-12
Epoch 416/512

Epoch 00416: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9863e-12 - val_loss: 3.9248e-12
Epoch 417/512

Epoch 00417: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0070e-12 - val_loss: 4.0867e-12
Epoch 418/512

Epoch 00418: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1487e-12 - val_loss: 4.1081e-12
Epoch 419/512

Epoch 00419: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0301e-12 - val_loss: 3.8601e-12
Epoch 420/512

Epoch 00420: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7847e-12 - val_loss: 3.7474e-12
Epoch 421/512

Epoch 00421: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8140e-12 - val_loss: 3.8341e-12
Epoch 422/512

Epoch 00422: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8387e-12 - val_loss: 3.9197e-12
Epoch 423/512

Epoch 00423: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0074e-12 - val_loss: 4.0937e-12
Epoch 424/512

Epoch 00424: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0568e-12 - val_loss: 3.9247e-12
Epoch 425/512

Epoch 00425: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8450e-12 - val_loss: 3.6959e-12
Epoch 426/512

Epoch 00426: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6296e-12 - val_loss: 3.5341e-12
Epoch 427/512

Epoch 00427: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4882e-12 - val_loss: 3.4909e-12
Epoch 428/512

Epoch 00428: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6070e-12 - val_loss: 3.6814e-12
Epoch 429/512

Epoch 00429: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6377e-12 - val_loss: 3.6018e-12
Epoch 430/512

Epoch 00430: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6750e-12 - val_loss: 3.6803e-12
Epoch 431/512

Epoch 00431: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6455e-12 - val_loss: 3.6256e-12
Epoch 432/512

Epoch 00432: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6115e-12 - val_loss: 3.5837e-12
Epoch 433/512

Epoch 00433: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6413e-12 - val_loss: 3.6465e-12
Epoch 434/512

Epoch 00434: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6721e-12 - val_loss: 3.6057e-12
Epoch 435/512

Epoch 00435: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5321e-12 - val_loss: 3.4488e-12
Epoch 436/512

Epoch 00436: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4515e-12 - val_loss: 3.5012e-12
Epoch 437/512

Epoch 00437: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4728e-12 - val_loss: 3.5028e-12
Epoch 438/512

Epoch 00438: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4894e-12 - val_loss: 3.4786e-12
Epoch 439/512

Epoch 00439: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5831e-12 - val_loss: 3.7175e-12
Epoch 440/512

Epoch 00440: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6467e-12 - val_loss: 3.6329e-12
Epoch 441/512

Epoch 00441: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6628e-12 - val_loss: 3.5991e-12
Epoch 442/512

Epoch 00442: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5420e-12 - val_loss: 3.5375e-12
Epoch 443/512

Epoch 00443: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5540e-12 - val_loss: 3.5191e-12
Epoch 444/512

Epoch 00444: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5512e-12 - val_loss: 3.6337e-12
Epoch 445/512

Epoch 00445: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7174e-12 - val_loss: 3.8058e-12
Epoch 446/512

Epoch 00446: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8079e-12 - val_loss: 3.7973e-12
Epoch 447/512

Epoch 00447: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7939e-12 - val_loss: 3.7733e-12
Epoch 448/512

Epoch 00448: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8446e-12 - val_loss: 3.9147e-12
Epoch 449/512

Epoch 00449: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9160e-12 - val_loss: 3.8345e-12
Epoch 450/512

Epoch 00450: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9107e-12 - val_loss: 3.8884e-12
Epoch 451/512

Epoch 00451: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7837e-12 - val_loss: 3.6155e-12
Epoch 452/512

Epoch 00452: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5753e-12 - val_loss: 3.5499e-12
Epoch 453/512

Epoch 00453: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5182e-12 - val_loss: 3.4615e-12
Epoch 454/512

Epoch 00454: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3846e-12 - val_loss: 3.0832e-12
Epoch 455/512

Epoch 00455: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.8630e-12 - val_loss: 2.5660e-12
Epoch 456/512

Epoch 00456: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.4441e-12 - val_loss: 2.2484e-12
Epoch 457/512

Epoch 00457: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.2062e-12 - val_loss: 2.1222e-12
Epoch 458/512

Epoch 00458: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.0693e-12 - val_loss: 2.0759e-12
Epoch 459/512

Epoch 00459: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.0884e-12 - val_loss: 2.0394e-12
Epoch 460/512

Epoch 00460: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0296e-12 - val_loss: 2.0534e-12
Epoch 461/512

Epoch 00461: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0842e-12 - val_loss: 2.1321e-12
Epoch 462/512

Epoch 00462: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1725e-12 - val_loss: 2.2259e-12
Epoch 463/512

Epoch 00463: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2309e-12 - val_loss: 2.1582e-12
Epoch 464/512

Epoch 00464: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1647e-12 - val_loss: 2.1453e-12
Epoch 465/512

Epoch 00465: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1401e-12 - val_loss: 2.1948e-12
Epoch 466/512

Epoch 00466: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.1674e-12 - val_loss: 2.0362e-12
Epoch 467/512

Epoch 00467: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.0163e-12 - val_loss: 1.9918e-12
Epoch 468/512

Epoch 00468: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9792e-12 - val_loss: 2.0034e-12
Epoch 469/512

Epoch 00469: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0504e-12 - val_loss: 2.0724e-12
Epoch 470/512

Epoch 00470: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 2.0126e-12 - val_loss: 1.9887e-12
Epoch 471/512

Epoch 00471: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.9821e-12 - val_loss: 1.9432e-12
Epoch 472/512

Epoch 00472: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9838e-12 - val_loss: 2.0415e-12
Epoch 473/512

Epoch 00473: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1121e-12 - val_loss: 2.0929e-12
Epoch 474/512

Epoch 00474: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0943e-12 - val_loss: 2.0941e-12
Epoch 475/512

Epoch 00475: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0900e-12 - val_loss: 2.0437e-12
Epoch 476/512

Epoch 00476: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0335e-12 - val_loss: 2.0173e-12
Epoch 477/512

Epoch 00477: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0212e-12 - val_loss: 2.0608e-12
Epoch 478/512

Epoch 00478: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0986e-12 - val_loss: 2.0960e-12
Epoch 479/512

Epoch 00479: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1036e-12 - val_loss: 2.1052e-12
Epoch 480/512

Epoch 00480: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0613e-12 - val_loss: 1.9825e-12
Epoch 481/512

Epoch 00481: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.9430e-12 - val_loss: 1.9321e-12
Epoch 482/512

Epoch 00482: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9662e-12 - val_loss: 1.9555e-12
Epoch 483/512

Epoch 00483: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9897e-12 - val_loss: 2.0039e-12
Epoch 484/512

Epoch 00484: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9938e-12 - val_loss: 2.0161e-12
Epoch 485/512

Epoch 00485: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0584e-12 - val_loss: 2.1389e-12
Epoch 486/512

Epoch 00486: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1831e-12 - val_loss: 2.1813e-12
Epoch 487/512

Epoch 00487: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1629e-12 - val_loss: 2.1243e-12
Epoch 488/512

Epoch 00488: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0727e-12 - val_loss: 1.9937e-12
Epoch 489/512

Epoch 00489: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0141e-12 - val_loss: 2.0391e-12
Epoch 490/512

Epoch 00490: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0108e-12 - val_loss: 1.9328e-12
Epoch 491/512

Epoch 00491: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9386e-12 - val_loss: 1.9418e-12
Epoch 492/512

Epoch 00492: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.9427e-12 - val_loss: 1.9078e-12
Epoch 493/512

Epoch 00493: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.8778e-12 - val_loss: 1.8170e-12
Epoch 494/512

Epoch 00494: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.7900e-12 - val_loss: 1.7464e-12
Epoch 495/512

Epoch 00495: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7685e-12 - val_loss: 1.7607e-12
Epoch 496/512

Epoch 00496: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.7635e-12 - val_loss: 1.7106e-12
Epoch 497/512

Epoch 00497: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-and-addition-in-different-models-operation-29/multiplication_multiplication_weights.h5
512/512 - 0s - loss: 1.6980e-12 - val_loss: 1.7095e-12
Epoch 498/512

Epoch 00498: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7279e-12 - val_loss: 1.7555e-12
Epoch 499/512

Epoch 00499: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7722e-12 - val_loss: 1.8126e-12
Epoch 500/512

Epoch 00500: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8633e-12 - val_loss: 1.9388e-12
Epoch 501/512

Epoch 00501: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9775e-12 - val_loss: 2.1049e-12
Epoch 502/512

Epoch 00502: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1705e-12 - val_loss: 2.2668e-12
Epoch 503/512

Epoch 00503: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3787e-12 - val_loss: 2.5504e-12
Epoch 504/512

Epoch 00504: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5697e-12 - val_loss: 2.6711e-12
Epoch 505/512

Epoch 00505: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6903e-12 - val_loss: 2.7527e-12
Epoch 506/512

Epoch 00506: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7380e-12 - val_loss: 2.6934e-12
Epoch 507/512

Epoch 00507: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7386e-12 - val_loss: 2.7335e-12
Epoch 508/512

Epoch 00508: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7797e-12 - val_loss: 2.8246e-12
Epoch 509/512

Epoch 00509: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8859e-12 - val_loss: 2.9857e-12
Epoch 510/512

Epoch 00510: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.0008e-12 - val_loss: 3.0368e-12
Epoch 511/512

Epoch 00511: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.0183e-12 - val_loss: 2.9501e-12
Epoch 512/512

Epoch 00512: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9629e-12 - val_loss: 2.9812e-12
WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?
WARNING:tensorflow:From /home/stud/minawoi/miniconda3/envs/conda-venv/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?
Epoch   0:   0% | abe: 10.035 | eve: 9.299 | bob: 9.875Epoch   0:   0% | abe: 9.920 | eve: 9.287 | bob: 9.783Epoch   0:   1% | abe: 9.822 | eve: 9.276 | bob: 9.709Epoch   0:   2% | abe: 9.750 | eve: 9.284 | bob: 9.658Epoch   0:   3% | abe: 9.666 | eve: 9.276 | bob: 9.590Epoch   0:   3% | abe: 9.607 | eve: 9.274 | bob: 9.545Epoch   0:   4% | abe: 9.543 | eve: 9.275 | bob: 9.491Epoch   0:   5% | abe: 9.499 | eve: 9.269 | bob: 9.456Epoch   0:   6% | abe: 9.460 | eve: 9.275 | bob: 9.425Epoch   0:   7% | abe: 9.425 | eve: 9.282 | bob: 9.396Epoch   0:   7% | abe: 9.399 | eve: 9.284 | bob: 9.374Epoch   0:   8% | abe: 9.372 | eve: 9.283 | bob: 9.351Epoch   0:   9% | abe: 9.347 | eve: 9.290 | bob: 9.328Epoch   0:  10% | abe: 9.327 | eve: 9.290 | bob: 9.311Epoch   0:  10% | abe: 9.311 | eve: 9.298 | bob: 9.295Epoch   0:  11% | abe: 9.295 | eve: 9.292 | bob: 9.281Epoch   0:  12% | abe: 9.282 | eve: 9.290 | bob: 9.267Epoch   0:  13% | abe: 9.272 | eve: 9.289 | bob: 9.258Epoch   0:  14% | abe: 9.263 | eve: 9.288 | bob: 9.250Epoch   0:  14% | abe: 9.253 | eve: 9.285 | bob: 9.239Epoch   0:  15% | abe: 9.246 | eve: 9.285 | bob: 9.233Epoch   0:  16% | abe: 9.236 | eve: 9.286 | bob: 9.223Epoch   0:  17% | abe: 9.227 | eve: 9.282 | bob: 9.214Epoch   0:  17% | abe: 9.220 | eve: 9.280 | bob: 9.207Epoch   0:  18% | abe: 9.215 | eve: 9.278 | bob: 9.202Epoch   0:  19% | abe: 9.210 | eve: 9.280 | bob: 9.197Epoch   0:  20% | abe: 9.206 | eve: 9.281 | bob: 9.193Epoch   0:  21% | abe: 9.201 | eve: 9.282 | bob: 9.188Epoch   0:  21% | abe: 9.197 | eve: 9.280 | bob: 9.184Epoch   0:  22% | abe: 9.193 | eve: 9.279 | bob: 9.180Epoch   0:  23% | abe: 9.189 | eve: 9.283 | bob: 9.176Epoch   0:  24% | abe: 9.185 | eve: 9.282 | bob: 9.172Epoch   0:  25% | abe: 9.183 | eve: 9.283 | bob: 9.170Epoch   0:  25% | abe: 9.180 | eve: 9.285 | bob: 9.167Epoch   0:  26% | abe: 9.176 | eve: 9.286 | bob: 9.163Epoch   0:  27% | abe: 9.173 | eve: 9.284 | bob: 9.160Epoch   0:  28% | abe: 9.169 | eve: 9.284 | bob: 9.157Epoch   0:  28% | abe: 9.167 | eve: 9.285 | bob: 9.155Epoch   0:  29% | abe: 9.165 | eve: 9.286 | bob: 9.152Epoch   0:  30% | abe: 9.162 | eve: 9.286 | bob: 9.149Epoch   0:  31% | abe: 9.160 | eve: 9.287 | bob: 9.147Epoch   0:  32% | abe: 9.157 | eve: 9.286 | bob: 9.145Epoch   0:  32% | abe: 9.156 | eve: 9.288 | bob: 9.143Epoch   0:  33% | abe: 9.154 | eve: 9.289 | bob: 9.142Epoch   0:  34% | abe: 9.152 | eve: 9.289 | bob: 9.139Epoch   0:  35% | abe: 9.149 | eve: 9.289 | bob: 9.137Epoch   0:  35% | abe: 9.147 | eve: 9.291 | bob: 9.135Epoch   0:  36% | abe: 9.145 | eve: 9.290 | bob: 9.133Epoch   0:  37% | abe: 9.144 | eve: 9.292 | bob: 9.133Epoch   0:  38% | abe: 9.143 | eve: 9.290 | bob: 9.132Epoch   0:  39% | abe: 9.141 | eve: 9.290 | bob: 9.130Epoch   0:  39% | abe: 9.140 | eve: 9.291 | bob: 9.130Epoch   0:  40% | abe: 9.139 | eve: 9.292 | bob: 9.129Epoch   0:  41% | abe: 9.138 | eve: 9.292 | bob: 9.128Epoch   0:  42% | abe: 9.137 | eve: 9.292 | bob: 9.128Epoch   0:  42% | abe: 9.136 | eve: 9.292 | bob: 9.128Epoch   0:  43% | abe: 9.135 | eve: 9.292 | bob: 9.127Epoch   0:  44% | abe: 9.134 | eve: 9.291 | bob: 9.126Epoch   0:  45% | abe: 9.132 | eve: 9.291 | bob: 9.125Epoch   0:  46% | abe: 9.131 | eve: 9.293 | bob: 9.124Epoch   0:  46% | abe: 9.130 | eve: 9.293 | bob: 9.124Epoch   0:  47% | abe: 9.129 | eve: 9.294 | bob: 9.123Epoch   0:  48% | abe: 9.128 | eve: 9.293 | bob: 9.123Epoch   0:  49% | abe: 9.127 | eve: 9.294 | bob: 9.123Epoch   0:  50% | abe: 9.126 | eve: 9.294 | bob: 9.122Epoch   0:  50% | abe: 9.125 | eve: 9.294 | bob: 9.121Epoch   0:  51% | abe: 9.124 | eve: 9.295 | bob: 9.121Epoch   0:  52% | abe: 9.123 | eve: 9.294 | bob: 9.120Epoch   0:  53% | abe: 9.122 | eve: 9.293 | bob: 9.120Epoch   0:  53% | abe: 9.121 | eve: 9.294 | bob: 9.120Epoch   0:  54% | abe: 9.121 | eve: 9.294 | bob: 9.121Epoch   0:  55% | abe: 9.120 | eve: 9.295 | bob: 9.120Epoch   0:  56% | abe: 9.118 | eve: 9.296 | bob: 9.119Epoch   0:  57% | abe: 9.117 | eve: 9.296 | bob: 9.119Epoch   0:  57% | abe: 9.116 | eve: 9.296 | bob: 9.118Epoch   0:  58% | abe: 9.115 | eve: 9.296 | bob: 9.118Epoch   0:  59% | abe: 9.114 | eve: 9.296 | bob: 9.118Epoch   0:  60% | abe: 9.114 | eve: 9.297 | bob: 9.118Epoch   0:  60% | abe: 9.114 | eve: 9.297 | bob: 9.119Epoch   0:  61% | abe: 9.113 | eve: 9.297 | bob: 9.118Epoch   0:  62% | abe: 9.113 | eve: 9.297 | bob: 9.118Epoch   0:  63% | abe: 9.112 | eve: 9.297 | bob: 9.118Epoch   0:  64% | abe: 9.111 | eve: 9.296 | bob: 9.118Epoch   0:  64% | abe: 9.110 | eve: 9.296 | bob: 9.118Epoch   0:  65% | abe: 9.110 | eve: 9.296 | bob: 9.118Epoch   0:  66% | abe: 9.109 | eve: 9.297 | bob: 9.118Epoch   0:  67% | abe: 9.108 | eve: 9.297 | bob: 9.117Epoch   0:  67% | abe: 9.107 | eve: 9.297 | bob: 9.117Epoch   0:  68% | abe: 9.107 | eve: 9.298 | bob: 9.117Epoch   0:  69% | abe: 9.106 | eve: 9.298 | bob: 9.117Epoch   0:  70% | abe: 9.106 | eve: 9.299 | bob: 9.117Epoch   0:  71% | abe: 9.105 | eve: 9.299 | bob: 9.118Epoch   0:  71% | abe: 9.104 | eve: 9.299 | bob: 9.118Epoch   0:  72% | abe: 9.103 | eve: 9.300 | bob: 9.117Epoch   0:  73% | abe: 9.103 | eve: 9.301 | bob: 9.117Epoch   0:  74% | abe: 9.102 | eve: 9.301 | bob: 9.117Epoch   0:  75% | abe: 9.102 | eve: 9.301 | bob: 9.117Epoch   0:  75% | abe: 9.101 | eve: 9.301 | bob: 9.117Epoch   0:  76% | abe: 9.100 | eve: 9.302 | bob: 9.117Epoch   0:  77% | abe: 9.099 | eve: 9.302 | bob: 9.116Epoch   0:  78% | abe: 9.099 | eve: 9.302 | bob: 9.117Epoch   0:  78% | abe: 9.098 | eve: 9.303 | bob: 9.117Epoch   0:  79% | abe: 9.098 | eve: 9.303 | bob: 9.117Epoch   0:  80% | abe: 9.097 | eve: 9.303 | bob: 9.116Epoch   0:  81% | abe: 9.096 | eve: 9.302 | bob: 9.116Epoch   0:  82% | abe: 9.096 | eve: 9.302 | bob: 9.117Epoch   0:  82% | abe: 9.095 | eve: 9.303 | bob: 9.117Epoch   0:  83% | abe: 9.095 | eve: 9.303 | bob: 9.117Epoch   0:  84% | abe: 9.095 | eve: 9.303 | bob: 9.117Epoch   0:  85% | abe: 9.094 | eve: 9.303 | bob: 9.117Epoch   0:  85% | abe: 9.093 | eve: 9.303 | bob: 9.117Epoch   0:  86% | abe: 9.093 | eve: 9.304 | bob: 9.117Epoch   0:  87% | abe: 9.092 | eve: 9.305 | bob: 9.117Epoch   0:  88% | abe: 9.092 | eve: 9.305 | bob: 9.118Epoch   0:  89% | abe: 9.092 | eve: 9.305 | bob: 9.118Epoch   0:  89% | abe: 9.091 | eve: 9.306 | bob: 9.118Epoch   0:  90% | abe: 9.091 | eve: 9.306 | bob: 9.119Epoch   0:  91% | abe: 9.090 | eve: 9.306 | bob: 9.119Epoch   0:  92% | abe: 9.090 | eve: 9.306 | bob: 9.119Epoch   0:  92% | abe: 9.089 | eve: 9.306 | bob: 9.118Epoch   0:  93% | abe: 9.089 | eve: 9.306 | bob: 9.119Epoch   0:  94% | abe: 9.088 | eve: 9.307 | bob: 9.119Epoch   0:  95% | abe: 9.088 | eve: 9.307 | bob: 9.119Epoch   0:  96% | abe: 9.088 | eve: 9.307 | bob: 9.120Epoch   0:  96% | abe: 9.087 | eve: 9.306 | bob: 9.120Epoch   0:  97% | abe: 9.087 | eve: 9.307 | bob: 9.120Epoch   0:  98% | abe: 9.086 | eve: 9.307 | bob: 9.120Epoch   0:  99% | abe: 9.086 | eve: 9.307 | bob: 9.120
New best Bob loss 9.119823231001192 at epoch 0
Epoch   1:   0% | abe: 8.998 | eve: 9.389 | bob: 9.094Epoch   1:   0% | abe: 9.020 | eve: 9.343 | bob: 9.126Epoch   1:   1% | abe: 9.021 | eve: 9.357 | bob: 9.131Epoch   1:   2% | abe: 9.028 | eve: 9.352 | bob: 9.140Epoch   1:   3% | abe: 9.027 | eve: 9.342 | bob: 9.140Epoch   1:   3% | abe: 9.022 | eve: 9.343 | bob: 9.135Epoch   1:   4% | abe: 9.023 | eve: 9.332 | bob: 9.138Epoch   1:   5% | abe: 9.015 | eve: 9.328 | bob: 9.130Epoch   1:   6% | abe: 9.010 | eve: 9.322 | bob: 9.126Epoch   1:   7% | abe: 9.011 | eve: 9.311 | bob: 9.126Epoch   1:   7% | abe: 9.012 | eve: 9.310 | bob: 9.129Epoch   1:   8% | abe: 9.013 | eve: 9.317 | bob: 9.131Epoch   1:   9% | abe: 9.012 | eve: 9.315 | bob: 9.132Epoch   1:  10% | abe: 9.009 | eve: 9.314 | bob: 9.129Epoch   1:  10% | abe: 9.011 | eve: 9.315 | bob: 9.133Epoch   1:  11% | abe: 9.011 | eve: 9.315 | bob: 9.134Epoch   1:  12% | abe: 9.013 | eve: 9.316 | bob: 9.137Epoch   1:  13% | abe: 9.010 | eve: 9.316 | bob: 9.135Epoch   1:  14% | abe: 9.008 | eve: 9.314 | bob: 9.133Epoch   1:  14% | abe: 9.008 | eve: 9.315 | bob: 9.133Epoch   1:  15% | abe: 9.008 | eve: 9.315 | bob: 9.134Epoch   1:  16% | abe: 9.007 | eve: 9.315 | bob: 9.134Epoch   1:  17% | abe: 9.008 | eve: 9.314 | bob: 9.135Epoch   1:  17% | abe: 9.010 | eve: 9.315 | bob: 9.138Epoch   1:  18% | abe: 9.010 | eve: 9.318 | bob: 9.139Epoch   1:  19% | abe: 9.008 | eve: 9.317 | bob: 9.138Epoch   1:  20% | abe: 9.008 | eve: 9.316 | bob: 9.138Epoch   1:  21% | abe: 9.007 | eve: 9.316 | bob: 9.138Epoch   1:  21% | abe: 9.008 | eve: 9.316 | bob: 9.140Epoch   1:  22% | abe: 9.008 | eve: 9.317 | bob: 9.140Epoch   1:  23% | abe: 9.006 | eve: 9.317 | bob: 9.139Epoch   1:  24% | abe: 9.006 | eve: 9.315 | bob: 9.140Epoch   1:  25% | abe: 9.004 | eve: 9.315 | bob: 9.138Epoch   1:  25% | abe: 9.002 | eve: 9.319 | bob: 9.137Epoch   1:  26% | abe: 9.002 | eve: 9.319 | bob: 9.137Epoch   1:  27% | abe: 9.001 | eve: 9.319 | bob: 9.137Epoch   1:  28% | abe: 9.002 | eve: 9.321 | bob: 9.138Epoch   1:  28% | abe: 9.002 | eve: 9.321 | bob: 9.139Epoch   1:  29% | abe: 9.002 | eve: 9.322 | bob: 9.139Epoch   1:  30% | abe: 9.001 | eve: 9.323 | bob: 9.139Epoch   1:  31% | abe: 8.999 | eve: 9.325 | bob: 9.138Epoch   1:  32% | abe: 8.999 | eve: 9.324 | bob: 9.138Epoch   1:  32% | abe: 8.998 | eve: 9.326 | bob: 9.139Epoch   1:  33% | abe: 8.999 | eve: 9.325 | bob: 9.140Epoch   1:  34% | abe: 8.998 | eve: 9.326 | bob: 9.139Epoch   1:  35% | abe: 8.998 | eve: 9.326 | bob: 9.140Epoch   1:  35% | abe: 8.998 | eve: 9.326 | bob: 9.141Epoch   1:  36% | abe: 8.998 | eve: 9.326 | bob: 9.142Epoch   1:  37% | abe: 8.998 | eve: 9.325 | bob: 9.142Epoch   1:  38% | abe: 8.998 | eve: 9.326 | bob: 9.143Epoch   1:  39% | abe: 8.998 | eve: 9.327 | bob: 9.144Epoch   1:  39% | abe: 8.999 | eve: 9.327 | bob: 9.145Epoch   1:  40% | abe: 8.999 | eve: 9.328 | bob: 9.145Epoch   1:  41% | abe: 8.997 | eve: 9.328 | bob: 9.144Epoch   1:  42% | abe: 8.997 | eve: 9.329 | bob: 9.144Epoch   1:  42% | abe: 8.997 | eve: 9.329 | bob: 9.145Epoch   1:  43% | abe: 8.996 | eve: 9.329 | bob: 9.145Epoch   1:  44% | abe: 8.995 | eve: 9.328 | bob: 9.145Epoch   1:  45% | abe: 8.995 | eve: 9.329 | bob: 9.145Epoch   1:  46% | abe: 8.996 | eve: 9.329 | bob: 9.146Epoch   1:  46% | abe: 8.995 | eve: 9.329 | bob: 9.146Epoch   1:  47% | abe: 8.994 | eve: 9.331 | bob: 9.146Epoch   1:  48% | abe: 8.994 | eve: 9.331 | bob: 9.147Epoch   1:  49% | abe: 8.993 | eve: 9.331 | bob: 9.146Epoch   1:  50% | abe: 8.993 | eve: 9.332 | bob: 9.146Epoch   1:  50% | abe: 8.992 | eve: 9.333 | bob: 9.146Epoch   1:  51% | abe: 8.991 | eve: 9.333 | bob: 9.146Epoch   1:  52% | abe: 8.992 | eve: 9.332 | bob: 9.147Epoch   1:  53% | abe: 8.990 | eve: 9.332 | bob: 9.146Epoch   1:  53% | abe: 8.989 | eve: 9.332 | bob: 9.146Epoch   1:  54% | abe: 8.989 | eve: 9.332 | bob: 9.146Epoch   1:  55% | abe: 8.988 | eve: 9.333 | bob: 9.146Epoch   1:  56% | abe: 8.987 | eve: 9.332 | bob: 9.145Epoch   1:  57% | abe: 8.987 | eve: 9.333 | bob: 9.146Epoch   1:  57% | abe: 8.987 | eve: 9.332 | bob: 9.146Epoch   1:  58% | abe: 8.986 | eve: 9.332 | bob: 9.146Epoch   1:  59% | abe: 8.986 | eve: 9.333 | bob: 9.146Epoch   1:  60% | abe: 8.985 | eve: 9.332 | bob: 9.146Epoch   1:  60% | abe: 8.985 | eve: 9.330 | bob: 9.146Epoch   1:  61% | abe: 8.984 | eve: 9.331 | bob: 9.146Epoch   1:  62% | abe: 8.983 | eve: 9.330 | bob: 9.146Epoch   1:  63% | abe: 8.982 | eve: 9.331 | bob: 9.145Epoch   1:  64% | abe: 8.982 | eve: 9.332 | bob: 9.146Epoch   1:  64% | abe: 8.982 | eve: 9.332 | bob: 9.146Epoch   1:  65% | abe: 8.981 | eve: 9.331 | bob: 9.146Epoch   1:  66% | abe: 8.981 | eve: 9.331 | bob: 9.146Epoch   1:  67% | abe: 8.980 | eve: 9.330 | bob: 9.146Epoch   1:  67% | abe: 8.979 | eve: 9.332 | bob: 9.146Epoch   1:  68% | abe: 8.978 | eve: 9.332 | bob: 9.145Epoch   1:  69% | abe: 8.978 | eve: 9.333 | bob: 9.145Epoch   1:  70% | abe: 8.977 | eve: 9.332 | bob: 9.145Epoch   1:  71% | abe: 8.976 | eve: 9.332 | bob: 9.145Epoch   1:  71% | abe: 8.976 | eve: 9.332 | bob: 9.146Epoch   1:  72% | abe: 8.975 | eve: 9.332 | bob: 9.145Epoch   1:  73% | abe: 8.974 | eve: 9.332 | bob: 9.145Epoch   1:  74% | abe: 8.974 | eve: 9.333 | bob: 9.145Epoch   1:  75% | abe: 8.973 | eve: 9.333 | bob: 9.145Epoch   1:  75% | abe: 8.973 | eve: 9.333 | bob: 9.145Epoch   1:  76% | abe: 8.972 | eve: 9.333 | bob: 9.145Epoch   1:  77% | abe: 8.972 | eve: 9.334 | bob: 9.145Epoch   1:  78% | abe: 8.971 | eve: 9.333 | bob: 9.145Epoch   1:  78% | abe: 8.971 | eve: 9.333 | bob: 9.146Epoch   1:  79% | abe: 8.971 | eve: 9.333 | bob: 9.146Epoch   1:  80% | abe: 8.971 | eve: 9.333 | bob: 9.146Epoch   1:  81% | abe: 8.970 | eve: 9.333 | bob: 9.146Epoch   1:  82% | abe: 8.969 | eve: 9.334 | bob: 9.146Epoch   1:  82% | abe: 8.968 | eve: 9.334 | bob: 9.145Epoch   1:  83% | abe: 8.968 | eve: 9.333 | bob: 9.145Epoch   1:  84% | abe: 8.967 | eve: 9.333 | bob: 9.145Epoch   1:  85% | abe: 8.966 | eve: 9.333 | bob: 9.144Epoch   1:  85% | abe: 8.965 | eve: 9.333 | bob: 9.144Epoch   1:  86% | abe: 8.964 | eve: 9.333 | bob: 9.144Epoch   1:  87% | abe: 8.964 | eve: 9.334 | bob: 9.144Epoch   1:  88% | abe: 8.963 | eve: 9.333 | bob: 9.143Epoch   1:  89% | abe: 8.962 | eve: 9.333 | bob: 9.143Epoch   1:  89% | abe: 8.962 | eve: 9.333 | bob: 9.143Epoch   1:  90% | abe: 8.961 | eve: 9.333 | bob: 9.143Epoch   1:  91% | abe: 8.961 | eve: 9.332 | bob: 9.143Epoch   1:  92% | abe: 8.960 | eve: 9.332 | bob: 9.143Epoch   1:  92% | abe: 8.960 | eve: 9.332 | bob: 9.143Epoch   1:  93% | abe: 8.959 | eve: 9.332 | bob: 9.143Epoch   1:  94% | abe: 8.958 | eve: 9.332 | bob: 9.142Epoch   1:  95% | abe: 8.957 | eve: 9.332 | bob: 9.142Epoch   1:  96% | abe: 8.957 | eve: 9.333 | bob: 9.142Epoch   1:  96% | abe: 8.956 | eve: 9.332 | bob: 9.142Epoch   1:  97% | abe: 8.956 | eve: 9.332 | bob: 9.141Epoch   1:  98% | abe: 8.955 | eve: 9.332 | bob: 9.141Epoch   1:  99% | abe: 8.954 | eve: 9.332 | bob: 9.141Epoch   2:   0% | abe: 8.814 | eve: 9.315 | bob: 9.054Epoch   2:   0% | abe: 8.850 | eve: 9.347 | bob: 9.092Epoch   2:   1% | abe: 8.846 | eve: 9.322 | bob: 9.091Epoch   2:   2% | abe: 8.852 | eve: 9.320 | bob: 9.095Epoch   2:   3% | abe: 8.853 | eve: 9.327 | bob: 9.097Epoch   2:   3% | abe: 8.855 | eve: 9.330 | bob: 9.100Epoch   2:   4% | abe: 8.858 | eve: 9.331 | bob: 9.104Epoch   2:   5% | abe: 8.860 | eve: 9.326 | bob: 9.106Epoch   2:   6% | abe: 8.862 | eve: 9.331 | bob: 9.109Epoch   2:   7% | abe: 8.865 | eve: 9.329 | bob: 9.113Epoch   2:   7% | abe: 8.866 | eve: 9.333 | bob: 9.113Epoch   2:   8% | abe: 8.866 | eve: 9.339 | bob: 9.114Epoch   2:   9% | abe: 8.864 | eve: 9.334 | bob: 9.112Epoch   2:  10% | abe: 8.862 | eve: 9.331 | bob: 9.110Epoch   2:  10% | abe: 8.863 | eve: 9.333 | bob: 9.112Epoch   2:  11% | abe: 8.864 | eve: 9.335 | bob: 9.113Epoch   2:  12% | abe: 8.861 | eve: 9.339 | bob: 9.110Epoch   2:  13% | abe: 8.857 | eve: 9.340 | bob: 9.106Epoch   2:  14% | abe: 8.859 | eve: 9.342 | bob: 9.109Epoch   2:  14% | abe: 8.859 | eve: 9.343 | bob: 9.109Epoch   2:  15% | abe: 8.855 | eve: 9.342 | bob: 9.106Epoch   2:  16% | abe: 8.853 | eve: 9.340 | bob: 9.104Epoch   2:  17% | abe: 8.852 | eve: 9.340 | bob: 9.104Epoch   2:  17% | abe: 8.851 | eve: 9.338 | bob: 9.104Epoch   2:  18% | abe: 8.852 | eve: 9.338 | bob: 9.105Epoch   2:  19% | abe: 8.852 | eve: 9.336 | bob: 9.106Epoch   2:  20% | abe: 8.851 | eve: 9.337 | bob: 9.106Epoch   2:  21% | abe: 8.850 | eve: 9.337 | bob: 9.106Epoch   2:  21% | abe: 8.849 | eve: 9.337 | bob: 9.105Epoch   2:  22% | abe: 8.849 | eve: 9.333 | bob: 9.106Epoch   2:  23% | abe: 8.848 | eve: 9.333 | bob: 9.106Epoch   2:  24% | abe: 8.848 | eve: 9.333 | bob: 9.106Epoch   2:  25% | abe: 8.847 | eve: 9.334 | bob: 9.106Epoch   2:  25% | abe: 8.846 | eve: 9.334 | bob: 9.107Epoch   2:  26% | abe: 8.845 | eve: 9.334 | bob: 9.107Epoch   2:  27% | abe: 8.845 | eve: 9.333 | bob: 9.107Epoch   2:  28% | abe: 8.845 | eve: 9.332 | bob: 9.108Epoch   2:  28% | abe: 8.844 | eve: 9.333 | bob: 9.107Epoch   2:  29% | abe: 8.842 | eve: 9.333 | bob: 9.107Epoch   2:  30% | abe: 8.841 | eve: 9.332 | bob: 9.106Epoch   2:  31% | abe: 8.841 | eve: 9.331 | bob: 9.106Epoch   2:  32% | abe: 8.840 | eve: 9.333 | bob: 9.106Epoch   2:  32% | abe: 8.839 | eve: 9.332 | bob: 9.106Epoch   2:  33% | abe: 8.837 | eve: 9.332 | bob: 9.105Epoch   2:  34% | abe: 8.837 | eve: 9.331 | bob: 9.105Epoch   2:  35% | abe: 8.836 | eve: 9.331 | bob: 9.105Epoch   2:  35% | abe: 8.835 | eve: 9.331 | bob: 9.105Epoch   2:  36% | abe: 8.836 | eve: 9.330 | bob: 9.107Epoch   2:  37% | abe: 8.835 | eve: 9.331 | bob: 9.107Epoch   2:  38% | abe: 8.835 | eve: 9.332 | bob: 9.108Epoch   2:  39% | abe: 8.834 | eve: 9.332 | bob: 9.107Epoch   2:  39% | abe: 8.832 | eve: 9.333 | bob: 9.106Epoch   2:  40% | abe: 8.831 | eve: 9.334 | bob: 9.106Epoch   2:  41% | abe: 8.831 | eve: 9.334 | bob: 9.107Epoch   2:  42% | abe: 8.830 | eve: 9.333 | bob: 9.107Epoch   2:  42% | abe: 8.831 | eve: 9.333 | bob: 9.109Epoch   2:  43% | abe: 8.830 | eve: 9.334 | bob: 9.109Epoch   2:  44% | abe: 8.829 | eve: 9.333 | bob: 9.108Epoch   2:  45% | abe: 8.828 | eve: 9.333 | bob: 9.108Epoch   2:  46% | abe: 8.827 | eve: 9.332 | bob: 9.108Epoch   2:  46% | abe: 8.826 | eve: 9.331 | bob: 9.107Epoch   2:  47% | abe: 8.825 | eve: 9.332 | bob: 9.108Epoch   2:  48% | abe: 8.824 | eve: 9.331 | bob: 9.107Epoch   2:  49% | abe: 8.823 | eve: 9.332 | bob: 9.107Epoch   2:  50% | abe: 8.823 | eve: 9.332 | bob: 9.107Epoch   2:  50% | abe: 8.822 | eve: 9.331 | bob: 9.107Epoch   2:  51% | abe: 8.821 | eve: 9.330 | bob: 9.107Epoch   2:  52% | abe: 8.821 | eve: 9.330 | bob: 9.107Epoch   2:  53% | abe: 8.820 | eve: 9.330 | bob: 9.107Epoch   2:  53% | abe: 8.820 | eve: 9.330 | bob: 9.108Epoch   2:  54% | abe: 8.819 | eve: 9.331 | bob: 9.108Epoch   2:  55% | abe: 8.819 | eve: 9.330 | bob: 9.109Epoch   2:  56% | abe: 8.818 | eve: 9.331 | bob: 9.108Epoch   2:  57% | abe: 8.818 | eve: 9.331 | bob: 9.109Epoch   2:  57% | abe: 8.816 | eve: 9.332 | bob: 9.108Epoch   2:  58% | abe: 8.815 | eve: 9.331 | bob: 9.108Epoch   2:  59% | abe: 8.814 | eve: 9.331 | bob: 9.108Epoch   2:  60% | abe: 8.814 | eve: 9.332 | bob: 9.108Epoch   2:  60% | abe: 8.813 | eve: 9.332 | bob: 9.109Epoch   2:  61% | abe: 8.812 | eve: 9.331 | bob: 9.108Epoch   2:  62% | abe: 8.811 | eve: 9.331 | bob: 9.108Epoch   2:  63% | abe: 8.810 | eve: 9.331 | bob: 9.108Epoch   2:  64% | abe: 8.809 | eve: 9.331 | bob: 9.107Epoch   2:  64% | abe: 8.808 | eve: 9.330 | bob: 9.107Epoch   2:  65% | abe: 8.807 | eve: 9.329 | bob: 9.107Epoch   2:  66% | abe: 8.807 | eve: 9.329 | bob: 9.108Epoch   2:  67% | abe: 8.806 | eve: 9.329 | bob: 9.107Epoch   2:  67% | abe: 8.805 | eve: 9.329 | bob: 9.107Epoch   2:  68% | abe: 8.805 | eve: 9.330 | bob: 9.107Epoch   2:  69% | abe: 8.804 | eve: 9.331 | bob: 9.107Epoch   2:  70% | abe: 8.804 | eve: 9.330 | bob: 9.108Epoch   2:  71% | abe: 8.803 | eve: 9.330 | bob: 9.108Epoch   2:  71% | abe: 8.803 | eve: 9.330 | bob: 9.109Epoch   2:  72% | abe: 8.802 | eve: 9.330 | bob: 9.108Epoch   2:  73% | abe: 8.801 | eve: 9.330 | bob: 9.109Epoch   2:  74% | abe: 8.801 | eve: 9.329 | bob: 9.109Epoch   2:  75% | abe: 8.800 | eve: 9.330 | bob: 9.109Epoch   2:  75% | abe: 8.800 | eve: 9.330 | bob: 9.109Epoch   2:  76% | abe: 8.799 | eve: 9.330 | bob: 9.110Epoch   2:  77% | abe: 8.798 | eve: 9.330 | bob: 9.110Epoch   2:  78% | abe: 8.798 | eve: 9.329 | bob: 9.110Epoch   2:  78% | abe: 8.797 | eve: 9.329 | bob: 9.110Epoch   2:  79% | abe: 8.796 | eve: 9.328 | bob: 9.110Epoch   2:  80% | abe: 8.795 | eve: 9.327 | bob: 9.110Epoch   2:  81% | abe: 8.794 | eve: 9.326 | bob: 9.110Epoch   2:  82% | abe: 8.794 | eve: 9.326 | bob: 9.110Epoch   2:  82% | abe: 8.793 | eve: 9.326 | bob: 9.110Epoch   2:  83% | abe: 8.792 | eve: 9.326 | bob: 9.110Epoch   2:  84% | abe: 8.791 | eve: 9.326 | bob: 9.109Epoch   2:  85% | abe: 8.790 | eve: 9.326 | bob: 9.109Epoch   2:  85% | abe: 8.789 | eve: 9.326 | bob: 9.109Epoch   2:  86% | abe: 8.789 | eve: 9.325 | bob: 9.109Epoch   2:  87% | abe: 8.788 | eve: 9.325 | bob: 9.109Epoch   2:  88% | abe: 8.787 | eve: 9.325 | bob: 9.110Epoch   2:  89% | abe: 8.786 | eve: 9.324 | bob: 9.109Epoch   2:  89% | abe: 8.786 | eve: 9.324 | bob: 9.110Epoch   2:  90% | abe: 8.785 | eve: 9.324 | bob: 9.110Epoch   2:  91% | abe: 8.784 | eve: 9.325 | bob: 9.110Epoch   2:  92% | abe: 8.784 | eve: 9.325 | bob: 9.110Epoch   2:  92% | abe: 8.783 | eve: 9.324 | bob: 9.110Epoch   2:  93% | abe: 8.782 | eve: 9.324 | bob: 9.109Epoch   2:  94% | abe: 8.781 | eve: 9.323 | bob: 9.110Epoch   2:  95% | abe: 8.781 | eve: 9.322 | bob: 9.110Epoch   2:  96% | abe: 8.780 | eve: 9.322 | bob: 9.111Epoch   2:  96% | abe: 8.780 | eve: 9.322 | bob: 9.110Epoch   2:  97% | abe: 8.779 | eve: 9.323 | bob: 9.110Epoch   2:  98% | abe: 8.778 | eve: 9.322 | bob: 9.110Epoch   2:  99% | abe: 8.777 | eve: 9.322 | bob: 9.110
New best Bob loss 9.110027579428788 at epoch 2
Epoch   3:   0% | abe: 8.673 | eve: 9.292 | bob: 9.118Epoch   3:   0% | abe: 8.691 | eve: 9.307 | bob: 9.137Epoch   3:   1% | abe: 8.667 | eve: 9.322 | bob: 9.107Epoch   3:   2% | abe: 8.677 | eve: 9.328 | bob: 9.115Epoch   3:   3% | abe: 8.686 | eve: 9.315 | bob: 9.126Epoch   3:   3% | abe: 8.680 | eve: 9.317 | bob: 9.120Epoch   3:   4% | abe: 8.684 | eve: 9.313 | bob: 9.123Epoch   3:   5% | abe: 8.679 | eve: 9.318 | bob: 9.115Epoch   3:   6% | abe: 8.679 | eve: 9.316 | bob: 9.117Epoch   3:   7% | abe: 8.678 | eve: 9.317 | bob: 9.115Epoch   3:   7% | abe: 8.678 | eve: 9.319 | bob: 9.116Epoch   3:   8% | abe: 8.672 | eve: 9.329 | bob: 9.109Epoch   3:   9% | abe: 8.673 | eve: 9.327 | bob: 9.111Epoch   3:  10% | abe: 8.672 | eve: 9.323 | bob: 9.112Epoch   3:  10% | abe: 8.673 | eve: 9.318 | bob: 9.114Epoch   3:  11% | abe: 8.671 | eve: 9.315 | bob: 9.112Epoch   3:  12% | abe: 8.670 | eve: 9.314 | bob: 9.112Epoch   3:  13% | abe: 8.672 | eve: 9.313 | bob: 9.113Epoch   3:  14% | abe: 8.670 | eve: 9.309 | bob: 9.111Epoch   3:  14% | abe: 8.669 | eve: 9.309 | bob: 9.111Epoch   3:  15% | abe: 8.668 | eve: 9.307 | bob: 9.111Epoch   3:  16% | abe: 8.667 | eve: 9.305 | bob: 9.112Epoch   3:  17% | abe: 8.669 | eve: 9.307 | bob: 9.115Epoch   3:  17% | abe: 8.668 | eve: 9.307 | bob: 9.116Epoch   3:  18% | abe: 8.665 | eve: 9.305 | bob: 9.113Epoch   3:  19% | abe: 8.661 | eve: 9.304 | bob: 9.109Epoch   3:  20% | abe: 8.659 | eve: 9.303 | bob: 9.109Epoch   3:  21% | abe: 8.658 | eve: 9.303 | bob: 9.109Epoch   3:  21% | abe: 8.656 | eve: 9.305 | bob: 9.109Epoch   3:  22% | abe: 8.655 | eve: 9.305 | bob: 9.108Epoch   3:  23% | abe: 8.653 | eve: 9.308 | bob: 9.106Epoch   3:  24% | abe: 8.653 | eve: 9.304 | bob: 9.105Epoch   3:  25% | abe: 8.651 | eve: 9.305 | bob: 9.104Epoch   3:  25% | abe: 8.648 | eve: 9.306 | bob: 9.101Epoch   3:  26% | abe: 8.647 | eve: 9.304 | bob: 9.101Epoch   3:  27% | abe: 8.644 | eve: 9.303 | bob: 9.098Epoch   3:  28% | abe: 8.644 | eve: 9.304 | bob: 9.099Epoch   3:  28% | abe: 8.643 | eve: 9.304 | bob: 9.098Epoch   3:  29% | abe: 8.642 | eve: 9.305 | bob: 9.097Epoch   3:  30% | abe: 8.641 | eve: 9.304 | bob: 9.096Epoch   3:  31% | abe: 8.639 | eve: 9.304 | bob: 9.096Epoch   3:  32% | abe: 8.638 | eve: 9.305 | bob: 9.095Epoch   3:  32% | abe: 8.636 | eve: 9.305 | bob: 9.093Epoch   3:  33% | abe: 8.634 | eve: 9.304 | bob: 9.092Epoch   3:  34% | abe: 8.634 | eve: 9.305 | bob: 9.092Epoch   3:  35% | abe: 8.632 | eve: 9.304 | bob: 9.090Epoch   3:  35% | abe: 8.631 | eve: 9.304 | bob: 9.089Epoch   3:  36% | abe: 8.630 | eve: 9.304 | bob: 9.089Epoch   3:  37% | abe: 8.629 | eve: 9.305 | bob: 9.089Epoch   3:  38% | abe: 8.629 | eve: 9.304 | bob: 9.090Epoch   3:  39% | abe: 8.628 | eve: 9.304 | bob: 9.089Epoch   3:  39% | abe: 8.627 | eve: 9.303 | bob: 9.089Epoch   3:  40% | abe: 8.627 | eve: 9.303 | bob: 9.089Epoch   3:  41% | abe: 8.626 | eve: 9.302 | bob: 9.089Epoch   3:  42% | abe: 8.625 | eve: 9.301 | bob: 9.088Epoch   3:  42% | abe: 8.624 | eve: 9.300 | bob: 9.088Epoch   3:  43% | abe: 8.623 | eve: 9.300 | bob: 9.088Epoch   3:  44% | abe: 8.622 | eve: 9.300 | bob: 9.087Epoch   3:  45% | abe: 8.621 | eve: 9.300 | bob: 9.088Epoch   3:  46% | abe: 8.620 | eve: 9.301 | bob: 9.087Epoch   3:  46% | abe: 8.619 | eve: 9.302 | bob: 9.086Epoch   3:  47% | abe: 8.618 | eve: 9.302 | bob: 9.087Epoch   3:  48% | abe: 8.618 | eve: 9.302 | bob: 9.087Epoch   3:  49% | abe: 8.616 | eve: 9.303 | bob: 9.086Epoch   3:  50% | abe: 8.616 | eve: 9.304 | bob: 9.087Epoch   3:  50% | abe: 8.614 | eve: 9.305 | bob: 9.086Epoch   3:  51% | abe: 8.613 | eve: 9.305 | bob: 9.086Epoch   3:  52% | abe: 8.612 | eve: 9.304 | bob: 9.085Epoch   3:  53% | abe: 8.611 | eve: 9.304 | bob: 9.085Epoch   3:  53% | abe: 8.610 | eve: 9.304 | bob: 9.085Epoch   3:  54% | abe: 8.610 | eve: 9.303 | bob: 9.086Epoch   3:  55% | abe: 8.610 | eve: 9.303 | bob: 9.086Epoch   3:  56% | abe: 8.609 | eve: 9.303 | bob: 9.086Epoch   3:  57% | abe: 8.608 | eve: 9.302 | bob: 9.085Epoch   3:  57% | abe: 8.607 | eve: 9.302 | bob: 9.085Epoch   3:  58% | abe: 8.606 | eve: 9.302 | bob: 9.085Epoch   3:  59% | abe: 8.605 | eve: 9.302 | bob: 9.085Epoch   3:  60% | abe: 8.604 | eve: 9.303 | bob: 9.084Epoch   3:  60% | abe: 8.604 | eve: 9.303 | bob: 9.085Epoch   3:  61% | abe: 8.603 | eve: 9.303 | bob: 9.085Epoch   3:  62% | abe: 8.603 | eve: 9.303 | bob: 9.084Epoch   3:  63% | abe: 8.601 | eve: 9.304 | bob: 9.084Epoch   3:  64% | abe: 8.601 | eve: 9.304 | bob: 9.085Epoch   3:  64% | abe: 8.600 | eve: 9.304 | bob: 9.084Epoch   3:  65% | abe: 8.599 | eve: 9.304 | bob: 9.084Epoch   3:  66% | abe: 8.599 | eve: 9.304 | bob: 9.085Epoch   3:  67% | abe: 8.599 | eve: 9.304 | bob: 9.085Epoch   3:  67% | abe: 8.598 | eve: 9.303 | bob: 9.085Epoch   3:  68% | abe: 8.596 | eve: 9.303 | bob: 9.084Epoch   3:  69% | abe: 8.596 | eve: 9.303 | bob: 9.083Epoch   3:  70% | abe: 8.595 | eve: 9.303 | bob: 9.084Epoch   3:  71% | abe: 8.594 | eve: 9.303 | bob: 9.084Epoch   3:  71% | abe: 8.593 | eve: 9.303 | bob: 9.083Epoch   3:  72% | abe: 8.592 | eve: 9.304 | bob: 9.083Epoch   3:  73% | abe: 8.591 | eve: 9.304 | bob: 9.083Epoch   3:  74% | abe: 8.590 | eve: 9.304 | bob: 9.082Epoch   3:  75% | abe: 8.589 | eve: 9.304 | bob: 9.082Epoch   3:  75% | abe: 8.588 | eve: 9.304 | bob: 9.082Epoch   3:  76% | abe: 8.588 | eve: 9.304 | bob: 9.082Epoch   3:  77% | abe: 8.587 | eve: 9.304 | bob: 9.081Epoch   3:  78% | abe: 8.586 | eve: 9.304 | bob: 9.081Epoch   3:  78% | abe: 8.586 | eve: 9.303 | bob: 9.081Epoch   3:  79% | abe: 8.584 | eve: 9.304 | bob: 9.081Epoch   3:  80% | abe: 8.583 | eve: 9.304 | bob: 9.081Epoch   3:  81% | abe: 8.582 | eve: 9.304 | bob: 9.080Epoch   3:  82% | abe: 8.582 | eve: 9.305 | bob: 9.080Epoch   3:  82% | abe: 8.581 | eve: 9.305 | bob: 9.080Epoch   3:  83% | abe: 8.580 | eve: 9.306 | bob: 9.080Epoch   3:  84% | abe: 8.580 | eve: 9.306 | bob: 9.080Epoch   3:  85% | abe: 8.579 | eve: 9.306 | bob: 9.080Epoch   3:  85% | abe: 8.578 | eve: 9.306 | bob: 9.079Epoch   3:  86% | abe: 8.577 | eve: 9.307 | bob: 9.079Epoch   3:  87% | abe: 8.576 | eve: 9.307 | bob: 9.079Epoch   3:  88% | abe: 8.575 | eve: 9.307 | bob: 9.078Epoch   3:  89% | abe: 8.574 | eve: 9.307 | bob: 9.078Epoch   3:  89% | abe: 8.573 | eve: 9.306 | bob: 9.078Epoch   3:  90% | abe: 8.572 | eve: 9.306 | bob: 9.078Epoch   3:  91% | abe: 8.571 | eve: 9.306 | bob: 9.078Epoch   3:  92% | abe: 8.570 | eve: 9.306 | bob: 9.077Epoch   3:  92% | abe: 8.569 | eve: 9.306 | bob: 9.077Epoch   3:  93% | abe: 8.569 | eve: 9.307 | bob: 9.077Epoch   3:  94% | abe: 8.568 | eve: 9.307 | bob: 9.077Epoch   3:  95% | abe: 8.567 | eve: 9.307 | bob: 9.077Epoch   3:  96% | abe: 8.567 | eve: 9.307 | bob: 9.077Epoch   3:  96% | abe: 8.566 | eve: 9.307 | bob: 9.077Epoch   3:  97% | abe: 8.565 | eve: 9.307 | bob: 9.076Epoch   3:  98% | abe: 8.564 | eve: 9.308 | bob: 9.076Epoch   3:  99% | abe: 8.562 | eve: 9.308 | bob: 9.075
New best Bob loss 9.075442624031211 at epoch 3
Epoch   4:   0% | abe: 8.434 | eve: 9.378 | bob: 9.011Epoch   4:   0% | abe: 8.410 | eve: 9.387 | bob: 8.995Epoch   4:   1% | abe: 8.417 | eve: 9.367 | bob: 9.003Epoch   4:   2% | abe: 8.431 | eve: 9.341 | bob: 9.017Epoch   4:   3% | abe: 8.436 | eve: 9.333 | bob: 9.022Epoch   4:   3% | abe: 8.436 | eve: 9.336 | bob: 9.022Epoch   4:   4% | abe: 8.435 | eve: 9.337 | bob: 9.021Epoch   4:   5% | abe: 8.436 | eve: 9.327 | bob: 9.024Epoch   4:   6% | abe: 8.437 | eve: 9.330 | bob: 9.026Epoch   4:   7% | abe: 8.437 | eve: 9.333 | bob: 9.028Epoch   4:   7% | abe: 8.438 | eve: 9.323 | bob: 9.031Epoch   4:   8% | abe: 8.437 | eve: 9.325 | bob: 9.031Epoch   4:   9% | abe: 8.429 | eve: 9.319 | bob: 9.021Epoch   4:  10% | abe: 8.430 | eve: 9.318 | bob: 9.023Epoch   4:  10% | abe: 8.434 | eve: 9.318 | bob: 9.029Epoch   4:  11% | abe: 8.434 | eve: 9.317 | bob: 9.030Epoch   4:  12% | abe: 8.434 | eve: 9.314 | bob: 9.030Epoch   4:  13% | abe: 8.434 | eve: 9.318 | bob: 9.030Epoch   4:  14% | abe: 8.435 | eve: 9.322 | bob: 9.032Epoch   4:  14% | abe: 8.434 | eve: 9.320 | bob: 9.031Epoch   4:  15% | abe: 8.432 | eve: 9.321 | bob: 9.029Epoch   4:  16% | abe: 8.432 | eve: 9.323 | bob: 9.030Epoch   4:  17% | abe: 8.432 | eve: 9.322 | bob: 9.031Epoch   4:  17% | abe: 8.431 | eve: 9.323 | bob: 9.031Epoch   4:  18% | abe: 8.428 | eve: 9.325 | bob: 9.028Epoch   4:  19% | abe: 8.427 | eve: 9.323 | bob: 9.027Epoch   4:  20% | abe: 8.425 | eve: 9.324 | bob: 9.026Epoch   4:  21% | abe: 8.423 | eve: 9.322 | bob: 9.025Epoch   4:  21% | abe: 8.423 | eve: 9.322 | bob: 9.027Epoch   4:  22% | abe: 8.422 | eve: 9.324 | bob: 9.026Epoch   4:  23% | abe: 8.421 | eve: 9.323 | bob: 9.025Epoch   4:  24% | abe: 8.421 | eve: 9.327 | bob: 9.025Epoch   4:  25% | abe: 8.418 | eve: 9.328 | bob: 9.023Epoch   4:  25% | abe: 8.419 | eve: 9.326 | bob: 9.024Epoch   4:  26% | abe: 8.418 | eve: 9.325 | bob: 9.025Epoch   4:  27% | abe: 8.419 | eve: 9.325 | bob: 9.027Epoch   4:  28% | abe: 8.417 | eve: 9.327 | bob: 9.024Epoch   4:  28% | abe: 8.414 | eve: 9.327 | bob: 9.023Epoch   4:  29% | abe: 8.414 | eve: 9.325 | bob: 9.023Epoch   4:  30% | abe: 8.412 | eve: 9.325 | bob: 9.021Epoch   4:  31% | abe: 8.411 | eve: 9.325 | bob: 9.020Epoch   4:  32% | abe: 8.409 | eve: 9.325 | bob: 9.019Epoch   4:  32% | abe: 8.408 | eve: 9.325 | bob: 9.018Epoch   4:  33% | abe: 8.407 | eve: 9.325 | bob: 9.017Epoch   4:  34% | abe: 8.405 | eve: 9.325 | bob: 9.017Epoch   4:  35% | abe: 8.405 | eve: 9.327 | bob: 9.017Epoch   4:  35% | abe: 8.404 | eve: 9.327 | bob: 9.016Epoch   4:  36% | abe: 8.403 | eve: 9.326 | bob: 9.016Epoch   4:  37% | abe: 8.402 | eve: 9.326 | bob: 9.016Epoch   4:  38% | abe: 8.401 | eve: 9.326 | bob: 9.015Epoch   4:  39% | abe: 8.399 | eve: 9.326 | bob: 9.013Epoch   4:  39% | abe: 8.397 | eve: 9.327 | bob: 9.011Epoch   4:  40% | abe: 8.396 | eve: 9.325 | bob: 9.012Epoch   4:  41% | abe: 8.395 | eve: 9.324 | bob: 9.011Epoch   4:  42% | abe: 8.395 | eve: 9.324 | bob: 9.011Epoch   4:  42% | abe: 8.395 | eve: 9.323 | bob: 9.012Epoch   4:  43% | abe: 8.394 | eve: 9.323 | bob: 9.013Epoch   4:  44% | abe: 8.394 | eve: 9.322 | bob: 9.012Epoch   4:  45% | abe: 8.393 | eve: 9.322 | bob: 9.012Epoch   4:  46% | abe: 8.393 | eve: 9.322 | bob: 9.012Epoch   4:  46% | abe: 8.392 | eve: 9.322 | bob: 9.012Epoch   4:  47% | abe: 8.391 | eve: 9.322 | bob: 9.011Epoch   4:  48% | abe: 8.389 | eve: 9.321 | bob: 9.010Epoch   4:  49% | abe: 8.388 | eve: 9.320 | bob: 9.009Epoch   4:  50% | abe: 8.387 | eve: 9.319 | bob: 9.009Epoch   4:  50% | abe: 8.387 | eve: 9.319 | bob: 9.009Epoch   4:  51% | abe: 8.386 | eve: 9.320 | bob: 9.009Epoch   4:  52% | abe: 8.385 | eve: 9.319 | bob: 9.009Epoch   4:  53% | abe: 8.384 | eve: 9.318 | bob: 9.008Epoch   4:  53% | abe: 8.384 | eve: 9.318 | bob: 9.009Epoch   4:  54% | abe: 8.383 | eve: 9.317 | bob: 9.009Epoch   4:  55% | abe: 8.382 | eve: 9.317 | bob: 9.007Epoch   4:  56% | abe: 8.381 | eve: 9.317 | bob: 9.008Epoch   4:  57% | abe: 8.380 | eve: 9.316 | bob: 9.007Epoch   4:  57% | abe: 8.379 | eve: 9.316 | bob: 9.007Epoch   4:  58% | abe: 8.379 | eve: 9.315 | bob: 9.007Epoch   4:  59% | abe: 8.378 | eve: 9.314 | bob: 9.007Epoch   4:  60% | abe: 8.377 | eve: 9.313 | bob: 9.006Epoch   4:  60% | abe: 8.376 | eve: 9.313 | bob: 9.006Epoch   4:  61% | abe: 8.376 | eve: 9.312 | bob: 9.006Epoch   4:  62% | abe: 8.375 | eve: 9.312 | bob: 9.007Epoch   4:  63% | abe: 8.375 | eve: 9.313 | bob: 9.007Epoch   4:  64% | abe: 8.374 | eve: 9.313 | bob: 9.006Epoch   4:  64% | abe: 8.373 | eve: 9.312 | bob: 9.006Epoch   4:  65% | abe: 8.372 | eve: 9.311 | bob: 9.006Epoch   4:  66% | abe: 8.371 | eve: 9.311 | bob: 9.006Epoch   4:  67% | abe: 8.371 | eve: 9.311 | bob: 9.006Epoch   4:  67% | abe: 8.370 | eve: 9.310 | bob: 9.006Epoch   4:  68% | abe: 8.369 | eve: 9.310 | bob: 9.006Epoch   4:  69% | abe: 8.369 | eve: 9.309 | bob: 9.006Epoch   4:  70% | abe: 8.367 | eve: 9.310 | bob: 9.005Epoch   4:  71% | abe: 8.367 | eve: 9.310 | bob: 9.005Epoch   4:  71% | abe: 8.366 | eve: 9.309 | bob: 9.004Epoch   4:  72% | abe: 8.365 | eve: 9.310 | bob: 9.004Epoch   4:  73% | abe: 8.363 | eve: 9.310 | bob: 9.003Epoch   4:  74% | abe: 8.363 | eve: 9.310 | bob: 9.003Epoch   4:  75% | abe: 8.362 | eve: 9.311 | bob: 9.003Epoch   4:  75% | abe: 8.361 | eve: 9.311 | bob: 9.003Epoch   4:  76% | abe: 8.360 | eve: 9.311 | bob: 9.002Epoch   4:  77% | abe: 8.359 | eve: 9.310 | bob: 9.002Epoch   4:  78% | abe: 8.358 | eve: 9.310 | bob: 9.001Epoch   4:  78% | abe: 8.357 | eve: 9.310 | bob: 9.001Epoch   4:  79% | abe: 8.356 | eve: 9.310 | bob: 9.000Epoch   4:  80% | abe: 8.355 | eve: 9.311 | bob: 9.000Epoch   4:  81% | abe: 8.355 | eve: 9.311 | bob: 9.001Epoch   4:  82% | abe: 8.354 | eve: 9.310 | bob: 9.001Epoch   4:  82% | abe: 8.353 | eve: 9.310 | bob: 9.000Epoch   4:  83% | abe: 8.352 | eve: 9.310 | bob: 9.000Epoch   4:  84% | abe: 8.352 | eve: 9.310 | bob: 9.000Epoch   4:  85% | abe: 8.351 | eve: 9.310 | bob: 8.999Epoch   4:  85% | abe: 8.350 | eve: 9.309 | bob: 9.000Epoch   4:  86% | abe: 8.350 | eve: 9.308 | bob: 8.999Epoch   4:  87% | abe: 8.348 | eve: 9.308 | bob: 8.999Epoch   4:  88% | abe: 8.347 | eve: 9.308 | bob: 8.998Epoch   4:  89% | abe: 8.347 | eve: 9.308 | bob: 8.998Epoch   4:  89% | abe: 8.346 | eve: 9.307 | bob: 8.998Epoch   4:  90% | abe: 8.346 | eve: 9.307 | bob: 8.998Epoch   4:  91% | abe: 8.344 | eve: 9.307 | bob: 8.997Epoch   4:  92% | abe: 8.344 | eve: 9.308 | bob: 8.997Epoch   4:  92% | abe: 8.342 | eve: 9.308 | bob: 8.997Epoch   4:  93% | abe: 8.341 | eve: 9.309 | bob: 8.996Epoch   4:  94% | abe: 8.340 | eve: 9.309 | bob: 8.996Epoch   4:  95% | abe: 8.340 | eve: 9.309 | bob: 8.996Epoch   4:  96% | abe: 8.339 | eve: 9.309 | bob: 8.995Epoch   4:  96% | abe: 8.338 | eve: 9.309 | bob: 8.995Epoch   4:  97% | abe: 8.337 | eve: 9.309 | bob: 8.995Epoch   4:  98% | abe: 8.337 | eve: 9.309 | bob: 8.996Epoch   4:  99% | abe: 8.336 | eve: 9.310 | bob: 8.995
New best Bob loss 8.994971381134292 at epoch 4
Epoch   5:   0% | abe: 8.191 | eve: 9.360 | bob: 8.926Epoch   5:   0% | abe: 8.210 | eve: 9.345 | bob: 8.949Epoch   5:   1% | abe: 8.220 | eve: 9.343 | bob: 8.958Epoch   5:   2% | abe: 8.220 | eve: 9.332 | bob: 8.957Epoch   5:   3% | abe: 8.218 | eve: 9.336 | bob: 8.958Epoch   5:   3% | abe: 8.217 | eve: 9.344 | bob: 8.956Epoch   5:   4% | abe: 8.228 | eve: 9.334 | bob: 8.967Epoch   5:   5% | abe: 8.223 | eve: 9.337 | bob: 8.960Epoch   5:   6% | abe: 8.224 | eve: 9.336 | bob: 8.959Epoch   5:   7% | abe: 8.219 | eve: 9.327 | bob: 8.954Epoch   5:   7% | abe: 8.216 | eve: 9.331 | bob: 8.950Epoch   5:   8% | abe: 8.212 | eve: 9.331 | bob: 8.946Epoch   5:   9% | abe: 8.210 | eve: 9.332 | bob: 8.946Epoch   5:  10% | abe: 8.209 | eve: 9.332 | bob: 8.946Epoch   5:  10% | abe: 8.209 | eve: 9.329 | bob: 8.948Epoch   5:  11% | abe: 8.208 | eve: 9.327 | bob: 8.949Epoch   5:  12% | abe: 8.206 | eve: 9.332 | bob: 8.948Epoch   5:  13% | abe: 8.206 | eve: 9.330 | bob: 8.949Epoch   5:  14% | abe: 8.204 | eve: 9.329 | bob: 8.946Epoch   5:  14% | abe: 8.206 | eve: 9.329 | bob: 8.950Epoch   5:  15% | abe: 8.208 | eve: 9.329 | bob: 8.954Epoch   5:  16% | abe: 8.206 | eve: 9.329 | bob: 8.953Epoch   5:  17% | abe: 8.206 | eve: 9.329 | bob: 8.955Epoch   5:  17% | abe: 8.204 | eve: 9.330 | bob: 8.953Epoch   5:  18% | abe: 8.203 | eve: 9.331 | bob: 8.952Epoch   5:  19% | abe: 8.201 | eve: 9.329 | bob: 8.950Epoch   5:  20% | abe: 8.198 | eve: 9.329 | bob: 8.946Epoch   5:  21% | abe: 8.197 | eve: 9.328 | bob: 8.945Epoch   5:  21% | abe: 8.196 | eve: 9.328 | bob: 8.944Epoch   5:  22% | abe: 8.195 | eve: 9.328 | bob: 8.943Epoch   5:  23% | abe: 8.194 | eve: 9.326 | bob: 8.942Epoch   5:  24% | abe: 8.193 | eve: 9.324 | bob: 8.942Epoch   5:  25% | abe: 8.190 | eve: 9.323 | bob: 8.939Epoch   5:  25% | abe: 8.189 | eve: 9.323 | bob: 8.939Epoch   5:  26% | abe: 8.188 | eve: 9.322 | bob: 8.937Epoch   5:  27% | abe: 8.188 | eve: 9.323 | bob: 8.937Epoch   5:  28% | abe: 8.187 | eve: 9.322 | bob: 8.938Epoch   5:  28% | abe: 8.186 | eve: 9.322 | bob: 8.937Epoch   5:  29% | abe: 8.184 | eve: 9.323 | bob: 8.936Epoch   5:  30% | abe: 8.184 | eve: 9.323 | bob: 8.936Epoch   5:  31% | abe: 8.182 | eve: 9.321 | bob: 8.934Epoch   5:  32% | abe: 8.181 | eve: 9.322 | bob: 8.935Epoch   5:  32% | abe: 8.180 | eve: 9.324 | bob: 8.933Epoch   5:  33% | abe: 8.179 | eve: 9.323 | bob: 8.933Epoch   5:  34% | abe: 8.178 | eve: 9.322 | bob: 8.932Epoch   5:  35% | abe: 8.177 | eve: 9.324 | bob: 8.931Epoch   5:  35% | abe: 8.176 | eve: 9.323 | bob: 8.931Epoch   5:  36% | abe: 8.176 | eve: 9.323 | bob: 8.931Epoch   5:  37% | abe: 8.174 | eve: 9.322 | bob: 8.930Epoch   5:  38% | abe: 8.174 | eve: 9.321 | bob: 8.929Epoch   5:  39% | abe: 8.173 | eve: 9.322 | bob: 8.929Epoch   5:  39% | abe: 8.172 | eve: 9.322 | bob: 8.929Epoch   5:  40% | abe: 8.171 | eve: 9.322 | bob: 8.928Epoch   5:  41% | abe: 8.171 | eve: 9.322 | bob: 8.929Epoch   5:  42% | abe: 8.169 | eve: 9.322 | bob: 8.928Epoch   5:  42% | abe: 8.168 | eve: 9.321 | bob: 8.927Epoch   5:  43% | abe: 8.166 | eve: 9.320 | bob: 8.926Epoch   5:  44% | abe: 8.166 | eve: 9.321 | bob: 8.926Epoch   5:  45% | abe: 8.165 | eve: 9.321 | bob: 8.925Epoch   5:  46% | abe: 8.164 | eve: 9.323 | bob: 8.925Epoch   5:  46% | abe: 8.162 | eve: 9.322 | bob: 8.924Epoch   5:  47% | abe: 8.161 | eve: 9.321 | bob: 8.924Epoch   5:  48% | abe: 8.159 | eve: 9.322 | bob: 8.922Epoch   5:  49% | abe: 8.158 | eve: 9.323 | bob: 8.922Epoch   5:  50% | abe: 8.156 | eve: 9.322 | bob: 8.922Epoch   5:  50% | abe: 8.156 | eve: 9.321 | bob: 8.921Epoch   5:  51% | abe: 8.154 | eve: 9.321 | bob: 8.920Epoch   5:  52% | abe: 8.153 | eve: 9.320 | bob: 8.919Epoch   5:  53% | abe: 8.153 | eve: 9.320 | bob: 8.919Epoch   5:  53% | abe: 8.152 | eve: 9.320 | bob: 8.919Epoch   5:  54% | abe: 8.150 | eve: 9.320 | bob: 8.917Epoch   5:  55% | abe: 8.149 | eve: 9.322 | bob: 8.916Epoch   5:  56% | abe: 8.148 | eve: 9.321 | bob: 8.916Epoch   5:  57% | abe: 8.146 | eve: 9.322 | bob: 8.914Epoch   5:  57% | abe: 8.146 | eve: 9.322 | bob: 8.914Epoch   5:  58% | abe: 8.144 | eve: 9.322 | bob: 8.913Epoch   5:  59% | abe: 8.143 | eve: 9.321 | bob: 8.912Epoch   5:  60% | abe: 8.143 | eve: 9.321 | bob: 8.911Epoch   5:  60% | abe: 8.141 | eve: 9.321 | bob: 8.910Epoch   5:  61% | abe: 8.139 | eve: 9.321 | bob: 8.909Epoch   5:  62% | abe: 8.138 | eve: 9.321 | bob: 8.909Epoch   5:  63% | abe: 8.137 | eve: 9.321 | bob: 8.908Epoch   5:  64% | abe: 8.136 | eve: 9.320 | bob: 8.907Epoch   5:  64% | abe: 8.135 | eve: 9.320 | bob: 8.907Epoch   5:  65% | abe: 8.133 | eve: 9.321 | bob: 8.905Epoch   5:  66% | abe: 8.132 | eve: 9.321 | bob: 8.905Epoch   5:  67% | abe: 8.130 | eve: 9.321 | bob: 8.903Epoch   5:  67% | abe: 8.129 | eve: 9.320 | bob: 8.903Epoch   5:  68% | abe: 8.128 | eve: 9.320 | bob: 8.901Epoch   5:  69% | abe: 8.127 | eve: 9.320 | bob: 8.900Epoch   5:  70% | abe: 8.125 | eve: 9.320 | bob: 8.899Epoch   5:  71% | abe: 8.124 | eve: 9.320 | bob: 8.899Epoch   5:  71% | abe: 8.123 | eve: 9.320 | bob: 8.898Epoch   5:  72% | abe: 8.122 | eve: 9.319 | bob: 8.897Epoch   5:  73% | abe: 8.121 | eve: 9.320 | bob: 8.896Epoch   5:  74% | abe: 8.120 | eve: 9.320 | bob: 8.895Epoch   5:  75% | abe: 8.118 | eve: 9.320 | bob: 8.894Epoch   5:  75% | abe: 8.117 | eve: 9.320 | bob: 8.893Epoch   5:  76% | abe: 8.116 | eve: 9.320 | bob: 8.892Epoch   5:  77% | abe: 8.115 | eve: 9.320 | bob: 8.891Epoch   5:  78% | abe: 8.114 | eve: 9.320 | bob: 8.890Epoch   5:  78% | abe: 8.112 | eve: 9.321 | bob: 8.889Epoch   5:  79% | abe: 8.111 | eve: 9.320 | bob: 8.888Epoch   5:  80% | abe: 8.110 | eve: 9.320 | bob: 8.888Epoch   5:  81% | abe: 8.108 | eve: 9.321 | bob: 8.887Epoch   5:  82% | abe: 8.107 | eve: 9.321 | bob: 8.886Epoch   5:  82% | abe: 8.105 | eve: 9.321 | bob: 8.885Epoch   5:  83% | abe: 8.104 | eve: 9.321 | bob: 8.884Epoch   5:  84% | abe: 8.103 | eve: 9.320 | bob: 8.884Epoch   5:  85% | abe: 8.102 | eve: 9.321 | bob: 8.882Epoch   5:  85% | abe: 8.101 | eve: 9.321 | bob: 8.882Epoch   5:  86% | abe: 8.100 | eve: 9.321 | bob: 8.882Epoch   5:  87% | abe: 8.099 | eve: 9.320 | bob: 8.880Epoch   5:  88% | abe: 8.097 | eve: 9.321 | bob: 8.880Epoch   5:  89% | abe: 8.097 | eve: 9.322 | bob: 8.879Epoch   5:  89% | abe: 8.095 | eve: 9.321 | bob: 8.879Epoch   5:  90% | abe: 8.094 | eve: 9.321 | bob: 8.878Epoch   5:  91% | abe: 8.092 | eve: 9.321 | bob: 8.877Epoch   5:  92% | abe: 8.091 | eve: 9.321 | bob: 8.876Epoch   5:  92% | abe: 8.090 | eve: 9.321 | bob: 8.875Epoch   5:  93% | abe: 8.088 | eve: 9.321 | bob: 8.874Epoch   5:  94% | abe: 8.087 | eve: 9.321 | bob: 8.873Epoch   5:  95% | abe: 8.086 | eve: 9.321 | bob: 8.872Epoch   5:  96% | abe: 8.084 | eve: 9.321 | bob: 8.871Epoch   5:  96% | abe: 8.083 | eve: 9.322 | bob: 8.870Epoch   5:  97% | abe: 8.082 | eve: 9.322 | bob: 8.870Epoch   5:  98% | abe: 8.080 | eve: 9.321 | bob: 8.869Epoch   5:  99% | abe: 8.079 | eve: 9.322 | bob: 8.868
New best Bob loss 8.867777959115983 at epoch 5
Epoch   6:   0% | abe: 7.892 | eve: 9.358 | bob: 8.744Epoch   6:   0% | abe: 7.906 | eve: 9.313 | bob: 8.733Epoch   6:   1% | abe: 7.914 | eve: 9.341 | bob: 8.746Epoch   6:   2% | abe: 7.904 | eve: 9.321 | bob: 8.743Epoch   6:   3% | abe: 7.901 | eve: 9.318 | bob: 8.744Epoch   6:   3% | abe: 7.891 | eve: 9.317 | bob: 8.734Epoch   6:   4% | abe: 7.895 | eve: 9.331 | bob: 8.740Epoch   6:   5% | abe: 7.902 | eve: 9.326 | bob: 8.747Epoch   6:   6% | abe: 7.895 | eve: 9.328 | bob: 8.741Epoch   6:   7% | abe: 7.895 | eve: 9.328 | bob: 8.742Epoch   6:   7% | abe: 7.891 | eve: 9.334 | bob: 8.737Epoch   6:   8% | abe: 7.890 | eve: 9.331 | bob: 8.739Epoch   6:   9% | abe: 7.887 | eve: 9.333 | bob: 8.736Epoch   6:  10% | abe: 7.889 | eve: 9.330 | bob: 8.739Epoch   6:  10% | abe: 7.888 | eve: 9.329 | bob: 8.738Epoch   6:  11% | abe: 7.885 | eve: 9.329 | bob: 8.736Epoch   6:  12% | abe: 7.884 | eve: 9.327 | bob: 8.735Epoch   6:  13% | abe: 7.884 | eve: 9.328 | bob: 8.736Epoch   6:  14% | abe: 7.881 | eve: 9.320 | bob: 8.734Epoch   6:  14% | abe: 7.881 | eve: 9.323 | bob: 8.732Epoch   6:  15% | abe: 7.882 | eve: 9.324 | bob: 8.733Epoch   6:  16% | abe: 7.882 | eve: 9.327 | bob: 8.733Epoch   6:  17% | abe: 7.883 | eve: 9.327 | bob: 8.733Epoch   6:  17% | abe: 7.881 | eve: 9.322 | bob: 8.730Epoch   6:  18% | abe: 7.881 | eve: 9.322 | bob: 8.731Epoch   6:  19% | abe: 7.879 | eve: 9.326 | bob: 8.727Epoch   6:  20% | abe: 7.879 | eve: 9.330 | bob: 8.728Epoch   6:  21% | abe: 7.876 | eve: 9.331 | bob: 8.726Epoch   6:  21% | abe: 7.874 | eve: 9.330 | bob: 8.724Epoch   6:  22% | abe: 7.872 | eve: 9.329 | bob: 8.722Epoch   6:  23% | abe: 7.870 | eve: 9.330 | bob: 8.720Epoch   6:  24% | abe: 7.869 | eve: 9.329 | bob: 8.718Epoch   6:  25% | abe: 7.866 | eve: 9.331 | bob: 8.715Epoch   6:  25% | abe: 7.863 | eve: 9.331 | bob: 8.713Epoch   6:  26% | abe: 7.861 | eve: 9.331 | bob: 8.711Epoch   6:  27% | abe: 7.860 | eve: 9.331 | bob: 8.709Epoch   6:  28% | abe: 7.858 | eve: 9.330 | bob: 8.708Epoch   6:  28% | abe: 7.857 | eve: 9.330 | bob: 8.707Epoch   6:  29% | abe: 7.855 | eve: 9.329 | bob: 8.705Epoch   6:  30% | abe: 7.854 | eve: 9.329 | bob: 8.704Epoch   6:  31% | abe: 7.852 | eve: 9.330 | bob: 8.703Epoch   6:  32% | abe: 7.851 | eve: 9.330 | bob: 8.701Epoch   6:  32% | abe: 7.849 | eve: 9.332 | bob: 8.698Epoch   6:  33% | abe: 7.847 | eve: 9.331 | bob: 8.697Epoch   6:  34% | abe: 7.845 | eve: 9.331 | bob: 8.695Epoch   6:  35% | abe: 7.843 | eve: 9.330 | bob: 8.694Epoch   6:  35% | abe: 7.843 | eve: 9.330 | bob: 8.694Epoch   6:  36% | abe: 7.841 | eve: 9.330 | bob: 8.692Epoch   6:  37% | abe: 7.840 | eve: 9.330 | bob: 8.693Epoch   6:  38% | abe: 7.838 | eve: 9.331 | bob: 8.691Epoch   6:  39% | abe: 7.836 | eve: 9.331 | bob: 8.691Epoch   6:  39% | abe: 7.834 | eve: 9.331 | bob: 8.688Epoch   6:  40% | abe: 7.832 | eve: 9.330 | bob: 8.687Epoch   6:  41% | abe: 7.830 | eve: 9.330 | bob: 8.686Epoch   6:  42% | abe: 7.829 | eve: 9.330 | bob: 8.684Epoch   6:  42% | abe: 7.827 | eve: 9.330 | bob: 8.683Epoch   6:  43% | abe: 7.826 | eve: 9.331 | bob: 8.682Epoch   6:  44% | abe: 7.825 | eve: 9.331 | bob: 8.681Epoch   6:  45% | abe: 7.824 | eve: 9.331 | bob: 8.681Epoch   6:  46% | abe: 7.822 | eve: 9.329 | bob: 8.679Epoch   6:  46% | abe: 7.820 | eve: 9.330 | bob: 8.678Epoch   6:  47% | abe: 7.819 | eve: 9.330 | bob: 8.677Epoch   6:  48% | abe: 7.817 | eve: 9.330 | bob: 8.676Epoch   6:  49% | abe: 7.816 | eve: 9.330 | bob: 8.675Epoch   6:  50% | abe: 7.815 | eve: 9.329 | bob: 8.674Epoch   6:  50% | abe: 7.813 | eve: 9.330 | bob: 8.673Epoch   6:  51% | abe: 7.812 | eve: 9.330 | bob: 8.672Epoch   6:  52% | abe: 7.811 | eve: 9.330 | bob: 8.671Epoch   6:  53% | abe: 7.809 | eve: 9.331 | bob: 8.670Epoch   6:  53% | abe: 7.807 | eve: 9.330 | bob: 8.669Epoch   6:  54% | abe: 7.806 | eve: 9.329 | bob: 8.667Epoch   6:  55% | abe: 7.804 | eve: 9.329 | bob: 8.667Epoch   6:  56% | abe: 7.802 | eve: 9.328 | bob: 8.665Epoch   6:  57% | abe: 7.801 | eve: 9.327 | bob: 8.664Epoch   6:  57% | abe: 7.800 | eve: 9.327 | bob: 8.663Epoch   6:  58% | abe: 7.798 | eve: 9.324 | bob: 8.662Epoch   6:  59% | abe: 7.797 | eve: 9.325 | bob: 8.660Epoch   6:  60% | abe: 7.795 | eve: 9.324 | bob: 8.659Epoch   6:  60% | abe: 7.793 | eve: 9.324 | bob: 8.657Epoch   6:  61% | abe: 7.791 | eve: 9.323 | bob: 8.655Epoch   6:  62% | abe: 7.788 | eve: 9.323 | bob: 8.653Epoch   6:  63% | abe: 7.787 | eve: 9.323 | bob: 8.652Epoch   6:  64% | abe: 7.786 | eve: 9.323 | bob: 8.651Epoch   6:  64% | abe: 7.784 | eve: 9.323 | bob: 8.650Epoch   6:  65% | abe: 7.782 | eve: 9.323 | bob: 8.648Epoch   6:  66% | abe: 7.781 | eve: 9.324 | bob: 8.648Epoch   6:  67% | abe: 7.780 | eve: 9.324 | bob: 8.646Epoch   6:  67% | abe: 7.778 | eve: 9.323 | bob: 8.644Epoch   6:  68% | abe: 7.776 | eve: 9.323 | bob: 8.643Epoch   6:  69% | abe: 7.774 | eve: 9.322 | bob: 8.642Epoch   6:  70% | abe: 7.772 | eve: 9.322 | bob: 8.639Epoch   6:  71% | abe: 7.769 | eve: 9.321 | bob: 8.638Epoch   6:  71% | abe: 7.768 | eve: 9.321 | bob: 8.636Epoch   6:  72% | abe: 7.765 | eve: 9.321 | bob: 8.634Epoch   6:  73% | abe: 7.764 | eve: 9.320 | bob: 8.633Epoch   6:  74% | abe: 7.762 | eve: 9.321 | bob: 8.631Epoch   6:  75% | abe: 7.760 | eve: 9.321 | bob: 8.630Epoch   6:  75% | abe: 7.757 | eve: 9.321 | bob: 8.627Epoch   6:  76% | abe: 7.756 | eve: 9.321 | bob: 8.626Epoch   6:  77% | abe: 7.754 | eve: 9.321 | bob: 8.624Epoch   6:  78% | abe: 7.752 | eve: 9.321 | bob: 8.622Epoch   6:  78% | abe: 7.751 | eve: 9.321 | bob: 8.621Epoch   6:  79% | abe: 7.749 | eve: 9.322 | bob: 8.619Epoch   6:  80% | abe: 7.748 | eve: 9.321 | bob: 8.618Epoch   6:  81% | abe: 7.746 | eve: 9.321 | bob: 8.617Epoch   6:  82% | abe: 7.744 | eve: 9.321 | bob: 8.615Epoch   6:  82% | abe: 7.743 | eve: 9.321 | bob: 8.613Epoch   6:  83% | abe: 7.741 | eve: 9.321 | bob: 8.611Epoch   6:  84% | abe: 7.739 | eve: 9.321 | bob: 8.610Epoch   6:  85% | abe: 7.738 | eve: 9.321 | bob: 8.609Epoch   6:  85% | abe: 7.736 | eve: 9.321 | bob: 8.607Epoch   6:  86% | abe: 7.735 | eve: 9.320 | bob: 8.605Epoch   6:  87% | abe: 7.733 | eve: 9.320 | bob: 8.604Epoch   6:  88% | abe: 7.731 | eve: 9.320 | bob: 8.602Epoch   6:  89% | abe: 7.729 | eve: 9.319 | bob: 8.600Epoch   6:  89% | abe: 7.727 | eve: 9.319 | bob: 8.598Epoch   6:  90% | abe: 7.725 | eve: 9.319 | bob: 8.596Epoch   6:  91% | abe: 7.723 | eve: 9.319 | bob: 8.594Epoch   6:  92% | abe: 7.721 | eve: 9.318 | bob: 8.593Epoch   6:  92% | abe: 7.719 | eve: 9.318 | bob: 8.590Epoch   6:  93% | abe: 7.717 | eve: 9.318 | bob: 8.589Epoch   6:  94% | abe: 7.715 | eve: 9.318 | bob: 8.587Epoch   6:  95% | abe: 7.714 | eve: 9.318 | bob: 8.586Epoch   6:  96% | abe: 7.712 | eve: 9.318 | bob: 8.584Epoch   6:  96% | abe: 7.711 | eve: 9.317 | bob: 8.583Epoch   6:  97% | abe: 7.709 | eve: 9.317 | bob: 8.581Epoch   6:  98% | abe: 7.707 | eve: 9.317 | bob: 8.579Epoch   6:  99% | abe: 7.705 | eve: 9.317 | bob: 8.578
New best Bob loss 8.577758507199405 at epoch 6
Epoch   7:   0% | abe: 7.462 | eve: 9.325 | bob: 8.383Epoch   7:   0% | abe: 7.458 | eve: 9.326 | bob: 8.335Epoch   7:   1% | abe: 7.460 | eve: 9.323 | bob: 8.337Epoch   7:   2% | abe: 7.450 | eve: 9.304 | bob: 8.335Epoch   7:   3% | abe: 7.454 | eve: 9.281 | bob: 8.335Epoch   7:   3% | abe: 7.447 | eve: 9.281 | bob: 8.332Epoch   7:   4% | abe: 7.443 | eve: 9.283 | bob: 8.330Epoch   7:   5% | abe: 7.439 | eve: 9.278 | bob: 8.325Epoch   7:   6% | abe: 7.439 | eve: 9.287 | bob: 8.327Epoch   7:   7% | abe: 7.444 | eve: 9.294 | bob: 8.336Epoch   7:   7% | abe: 7.446 | eve: 9.296 | bob: 8.338Epoch   7:   8% | abe: 7.448 | eve: 9.292 | bob: 8.340Epoch   7:   9% | abe: 7.441 | eve: 9.291 | bob: 8.335Epoch   7:  10% | abe: 7.438 | eve: 9.292 | bob: 8.330Epoch   7:  10% | abe: 7.439 | eve: 9.297 | bob: 8.332Epoch   7:  11% | abe: 7.438 | eve: 9.298 | bob: 8.329Epoch   7:  12% | abe: 7.435 | eve: 9.300 | bob: 8.327Epoch   7:  13% | abe: 7.432 | eve: 9.300 | bob: 8.327Epoch   7:  14% | abe: 7.428 | eve: 9.302 | bob: 8.325Epoch   7:  14% | abe: 7.425 | eve: 9.304 | bob: 8.322Epoch   7:  15% | abe: 7.421 | eve: 9.304 | bob: 8.318Epoch   7:  16% | abe: 7.421 | eve: 9.302 | bob: 8.317Epoch   7:  17% | abe: 7.417 | eve: 9.304 | bob: 8.315Epoch   7:  17% | abe: 7.413 | eve: 9.306 | bob: 8.311Epoch   7:  18% | abe: 7.410 | eve: 9.309 | bob: 8.307Epoch   7:  19% | abe: 7.408 | eve: 9.313 | bob: 8.304Epoch   7:  20% | abe: 7.405 | eve: 9.314 | bob: 8.302Epoch   7:  21% | abe: 7.403 | eve: 9.313 | bob: 8.299Epoch   7:  21% | abe: 7.403 | eve: 9.315 | bob: 8.298Epoch   7:  22% | abe: 7.400 | eve: 9.314 | bob: 8.296Epoch   7:  23% | abe: 7.399 | eve: 9.315 | bob: 8.295Epoch   7:  24% | abe: 7.398 | eve: 9.313 | bob: 8.296Epoch   7:  25% | abe: 7.399 | eve: 9.314 | bob: 8.297Epoch   7:  25% | abe: 7.396 | eve: 9.315 | bob: 8.296Epoch   7:  26% | abe: 7.393 | eve: 9.317 | bob: 8.293Epoch   7:  27% | abe: 7.391 | eve: 9.315 | bob: 8.291Epoch   7:  28% | abe: 7.389 | eve: 9.314 | bob: 8.288Epoch   7:  28% | abe: 7.386 | eve: 9.314 | bob: 8.285Epoch   7:  29% | abe: 7.385 | eve: 9.316 | bob: 8.283Epoch   7:  30% | abe: 7.383 | eve: 9.315 | bob: 8.282Epoch   7:  31% | abe: 7.381 | eve: 9.315 | bob: 8.279Epoch   7:  32% | abe: 7.378 | eve: 9.314 | bob: 8.277Epoch   7:  32% | abe: 7.374 | eve: 9.315 | bob: 8.273Epoch   7:  33% | abe: 7.373 | eve: 9.314 | bob: 8.272Epoch   7:  34% | abe: 7.370 | eve: 9.313 | bob: 8.270Epoch   7:  35% | abe: 7.367 | eve: 9.311 | bob: 8.268Epoch   7:  35% | abe: 7.366 | eve: 9.312 | bob: 8.267Epoch   7:  36% | abe: 7.363 | eve: 9.312 | bob: 8.264Epoch   7:  37% | abe: 7.360 | eve: 9.314 | bob: 8.261Epoch   7:  38% | abe: 7.356 | eve: 9.312 | bob: 8.259Epoch   7:  39% | abe: 7.355 | eve: 9.311 | bob: 8.257Epoch   7:  39% | abe: 7.352 | eve: 9.310 | bob: 8.255Epoch   7:  40% | abe: 7.349 | eve: 9.309 | bob: 8.253Epoch   7:  41% | abe: 7.348 | eve: 9.310 | bob: 8.252Epoch   7:  42% | abe: 7.346 | eve: 9.310 | bob: 8.249Epoch   7:  42% | abe: 7.344 | eve: 9.309 | bob: 8.247Epoch   7:  43% | abe: 7.341 | eve: 9.309 | bob: 8.244Epoch   7:  44% | abe: 7.339 | eve: 9.310 | bob: 8.242Epoch   7:  45% | abe: 7.337 | eve: 9.311 | bob: 8.240Epoch   7:  46% | abe: 7.335 | eve: 9.312 | bob: 8.238Epoch   7:  46% | abe: 7.333 | eve: 9.313 | bob: 8.235Epoch   7:  47% | abe: 7.330 | eve: 9.312 | bob: 8.233Epoch   7:  48% | abe: 7.329 | eve: 9.312 | bob: 8.232Epoch   7:  49% | abe: 7.326 | eve: 9.311 | bob: 8.229Epoch   7:  50% | abe: 7.324 | eve: 9.313 | bob: 8.227Epoch   7:  50% | abe: 7.322 | eve: 9.314 | bob: 8.225Epoch   7:  51% | abe: 7.319 | eve: 9.313 | bob: 8.223Epoch   7:  52% | abe: 7.317 | eve: 9.312 | bob: 8.220Epoch   7:  53% | abe: 7.314 | eve: 9.312 | bob: 8.218Epoch   7:  53% | abe: 7.312 | eve: 9.313 | bob: 8.216Epoch   7:  54% | abe: 7.310 | eve: 9.313 | bob: 8.214Epoch   7:  55% | abe: 7.307 | eve: 9.314 | bob: 8.212Epoch   7:  56% | abe: 7.305 | eve: 9.315 | bob: 8.210Epoch   7:  57% | abe: 7.303 | eve: 9.315 | bob: 8.208Epoch   7:  57% | abe: 7.302 | eve: 9.314 | bob: 8.207Epoch   7:  58% | abe: 7.299 | eve: 9.315 | bob: 8.205Epoch   7:  59% | abe: 7.297 | eve: 9.315 | bob: 8.202Epoch   7:  60% | abe: 7.295 | eve: 9.316 | bob: 8.201Epoch   7:  60% | abe: 7.293 | eve: 9.316 | bob: 8.199Epoch   7:  61% | abe: 7.291 | eve: 9.316 | bob: 8.196Epoch   7:  62% | abe: 7.288 | eve: 9.316 | bob: 8.193Epoch   7:  63% | abe: 7.286 | eve: 9.316 | bob: 8.191Epoch   7:  64% | abe: 7.284 | eve: 9.316 | bob: 8.189Epoch   7:  64% | abe: 7.281 | eve: 9.316 | bob: 8.186Epoch   7:  65% | abe: 7.279 | eve: 9.316 | bob: 8.185Epoch   7:  66% | abe: 7.276 | eve: 9.316 | bob: 8.181Epoch   7:  67% | abe: 7.273 | eve: 9.316 | bob: 8.178Epoch   7:  67% | abe: 7.270 | eve: 9.317 | bob: 8.175Epoch   7:  68% | abe: 7.268 | eve: 9.317 | bob: 8.174Epoch   7:  69% | abe: 7.266 | eve: 9.316 | bob: 8.171Epoch   7:  70% | abe: 7.263 | eve: 9.317 | bob: 8.169Epoch   7:  71% | abe: 7.261 | eve: 9.317 | bob: 8.166Epoch   7:  71% | abe: 7.258 | eve: 9.316 | bob: 8.164Epoch   7:  72% | abe: 7.256 | eve: 9.316 | bob: 8.162Epoch   7:  73% | abe: 7.254 | eve: 9.317 | bob: 8.159Epoch   7:  74% | abe: 7.251 | eve: 9.316 | bob: 8.157Epoch   7:  75% | abe: 7.250 | eve: 9.316 | bob: 8.155Epoch   7:  75% | abe: 7.247 | eve: 9.316 | bob: 8.153Epoch   7:  76% | abe: 7.244 | eve: 9.316 | bob: 8.150Epoch   7:  77% | abe: 7.242 | eve: 9.316 | bob: 8.148Epoch   7:  78% | abe: 7.240 | eve: 9.316 | bob: 8.147Epoch   7:  78% | abe: 7.238 | eve: 9.317 | bob: 8.145Epoch   7:  79% | abe: 7.236 | eve: 9.317 | bob: 8.143Epoch   7:  80% | abe: 7.233 | eve: 9.318 | bob: 8.141Epoch   7:  81% | abe: 7.231 | eve: 9.318 | bob: 8.139Epoch   7:  82% | abe: 7.229 | eve: 9.318 | bob: 8.137Epoch   7:  82% | abe: 7.227 | eve: 9.318 | bob: 8.135Epoch   7:  83% | abe: 7.225 | eve: 9.317 | bob: 8.133Epoch   7:  84% | abe: 7.222 | eve: 9.317 | bob: 8.131Epoch   7:  85% | abe: 7.220 | eve: 9.317 | bob: 8.129Epoch   7:  85% | abe: 7.218 | eve: 9.317 | bob: 8.127Epoch   7:  86% | abe: 7.216 | eve: 9.317 | bob: 8.126Epoch   7:  87% | abe: 7.214 | eve: 9.318 | bob: 8.124Epoch   7:  88% | abe: 7.212 | eve: 9.318 | bob: 8.121Epoch   7:  89% | abe: 7.210 | eve: 9.318 | bob: 8.120Epoch   7:  89% | abe: 7.208 | eve: 9.318 | bob: 8.117Epoch   7:  90% | abe: 7.206 | eve: 9.318 | bob: 8.115Epoch   7:  91% | abe: 7.203 | eve: 9.318 | bob: 8.113Epoch   7:  92% | abe: 7.201 | eve: 9.319 | bob: 8.111Epoch   7:  92% | abe: 7.198 | eve: 9.318 | bob: 8.108Epoch   7:  93% | abe: 7.196 | eve: 9.318 | bob: 8.106Epoch   7:  94% | abe: 7.193 | eve: 9.318 | bob: 8.104Epoch   7:  95% | abe: 7.191 | eve: 9.318 | bob: 8.102Epoch   7:  96% | abe: 7.188 | eve: 9.318 | bob: 8.099Epoch   7:  96% | abe: 7.186 | eve: 9.318 | bob: 8.097Epoch   7:  97% | abe: 7.183 | eve: 9.318 | bob: 8.095Epoch   7:  98% | abe: 7.181 | eve: 9.318 | bob: 8.093Epoch   7:  99% | abe: 7.179 | eve: 9.318 | bob: 8.091
New best Bob loss 8.090849847779282 at epoch 7
Epoch   8:   0% | abe: 6.892 | eve: 9.308 | bob: 7.862Epoch   8:   0% | abe: 6.909 | eve: 9.315 | bob: 7.859Epoch   8:   1% | abe: 6.908 | eve: 9.307 | bob: 7.854Epoch   8:   2% | abe: 6.901 | eve: 9.293 | bob: 7.847Epoch   8:   3% | abe: 6.889 | eve: 9.308 | bob: 7.830Epoch   8:   3% | abe: 6.890 | eve: 9.316 | bob: 7.827Epoch   8:   4% | abe: 6.888 | eve: 9.327 | bob: 7.824Epoch   8:   5% | abe: 6.887 | eve: 9.335 | bob: 7.825Epoch   8:   6% | abe: 6.883 | eve: 9.337 | bob: 7.819Epoch   8:   7% | abe: 6.877 | eve: 9.346 | bob: 7.813Epoch   8:   7% | abe: 6.867 | eve: 9.343 | bob: 7.806Epoch   8:   8% | abe: 6.865 | eve: 9.334 | bob: 7.804Epoch   8:   9% | abe: 6.863 | eve: 9.336 | bob: 7.801Epoch   8:  10% | abe: 6.862 | eve: 9.334 | bob: 7.799Epoch   8:  10% | abe: 6.857 | eve: 9.329 | bob: 7.794Epoch   8:  11% | abe: 6.856 | eve: 9.336 | bob: 7.794Epoch   8:  12% | abe: 6.851 | eve: 9.338 | bob: 7.791Epoch   8:  13% | abe: 6.847 | eve: 9.337 | bob: 7.789Epoch   8:  14% | abe: 6.843 | eve: 9.336 | bob: 7.786Epoch   8:  14% | abe: 6.839 | eve: 9.336 | bob: 7.780Epoch   8:  15% | abe: 6.837 | eve: 9.331 | bob: 7.780Epoch   8:  16% | abe: 6.835 | eve: 9.330 | bob: 7.778Epoch   8:  17% | abe: 6.831 | eve: 9.332 | bob: 7.773Epoch   8:  17% | abe: 6.828 | eve: 9.329 | bob: 7.770Epoch   8:  18% | abe: 6.826 | eve: 9.328 | bob: 7.767Epoch   8:  19% | abe: 6.822 | eve: 9.327 | bob: 7.763Epoch   8:  20% | abe: 6.818 | eve: 9.324 | bob: 7.760Epoch   8:  21% | abe: 6.815 | eve: 9.324 | bob: 7.756Epoch   8:  21% | abe: 6.812 | eve: 9.323 | bob: 7.754Epoch   8:  22% | abe: 6.810 | eve: 9.323 | bob: 7.753Epoch   8:  23% | abe: 6.809 | eve: 9.323 | bob: 7.752Epoch   8:  24% | abe: 6.806 | eve: 9.324 | bob: 7.749Epoch   8:  25% | abe: 6.803 | eve: 9.326 | bob: 7.746Epoch   8:  25% | abe: 6.800 | eve: 9.327 | bob: 7.742Epoch   8:  26% | abe: 6.797 | eve: 9.325 | bob: 7.740Epoch   8:  27% | abe: 6.793 | eve: 9.324 | bob: 7.737Epoch   8:  28% | abe: 6.791 | eve: 9.324 | bob: 7.736Epoch   8:  28% | abe: 6.789 | eve: 9.326 | bob: 7.734Epoch   8:  29% | abe: 6.786 | eve: 9.326 | bob: 7.732Epoch   8:  30% | abe: 6.784 | eve: 9.325 | bob: 7.729Epoch   8:  31% | abe: 6.781 | eve: 9.324 | bob: 7.727Epoch   8:  32% | abe: 6.778 | eve: 9.323 | bob: 7.723Epoch   8:  32% | abe: 6.775 | eve: 9.322 | bob: 7.722Epoch   8:  33% | abe: 6.771 | eve: 9.322 | bob: 7.718Epoch   8:  34% | abe: 6.768 | eve: 9.320 | bob: 7.715Epoch   8:  35% | abe: 6.767 | eve: 9.319 | bob: 7.715Epoch   8:  35% | abe: 6.765 | eve: 9.318 | bob: 7.713Epoch   8:  36% | abe: 6.762 | eve: 9.320 | bob: 7.709Epoch   8:  37% | abe: 6.759 | eve: 9.320 | bob: 7.707Epoch   8:  38% | abe: 6.757 | eve: 9.320 | bob: 7.705Epoch   8:  39% | abe: 6.755 | eve: 9.320 | bob: 7.704Epoch   8:  39% | abe: 6.753 | eve: 9.320 | bob: 7.702Epoch   8:  40% | abe: 6.750 | eve: 9.321 | bob: 7.700Epoch   8:  41% | abe: 6.747 | eve: 9.320 | bob: 7.697Epoch   8:  42% | abe: 6.745 | eve: 9.320 | bob: 7.696Epoch   8:  42% | abe: 6.742 | eve: 9.320 | bob: 7.693Epoch   8:  43% | abe: 6.740 | eve: 9.319 | bob: 7.691Epoch   8:  44% | abe: 6.738 | eve: 9.319 | bob: 7.689Epoch   8:  45% | abe: 6.735 | eve: 9.320 | bob: 7.687Epoch   8:  46% | abe: 6.734 | eve: 9.320 | bob: 7.686Epoch   8:  46% | abe: 6.731 | eve: 9.319 | bob: 7.683Epoch   8:  47% | abe: 6.728 | eve: 9.318 | bob: 7.681Epoch   8:  48% | abe: 6.726 | eve: 9.318 | bob: 7.678Epoch   8:  49% | abe: 6.723 | eve: 9.318 | bob: 7.675Epoch   8:  50% | abe: 6.721 | eve: 9.318 | bob: 7.673Epoch   8:  50% | abe: 6.718 | eve: 9.318 | bob: 7.670Epoch   8:  51% | abe: 6.716 | eve: 9.319 | bob: 7.668Epoch   8:  52% | abe: 6.713 | eve: 9.319 | bob: 7.665Epoch   8:  53% | abe: 6.711 | eve: 9.319 | bob: 7.663Epoch   8:  53% | abe: 6.709 | eve: 9.319 | bob: 7.661Epoch   8:  54% | abe: 6.707 | eve: 9.318 | bob: 7.659Epoch   8:  55% | abe: 6.704 | eve: 9.318 | bob: 7.657Epoch   8:  56% | abe: 6.702 | eve: 9.319 | bob: 7.654Epoch   8:  57% | abe: 6.699 | eve: 9.318 | bob: 7.651Epoch   8:  57% | abe: 6.697 | eve: 9.318 | bob: 7.649Epoch   8:  58% | abe: 6.693 | eve: 9.318 | bob: 7.646Epoch   8:  59% | abe: 6.690 | eve: 9.317 | bob: 7.643Epoch   8:  60% | abe: 6.688 | eve: 9.318 | bob: 7.641Epoch   8:  60% | abe: 6.685 | eve: 9.318 | bob: 7.638Epoch   8:  61% | abe: 6.682 | eve: 9.318 | bob: 7.636Epoch   8:  62% | abe: 6.680 | eve: 9.317 | bob: 7.633Epoch   8:  63% | abe: 6.676 | eve: 9.317 | bob: 7.630Epoch   8:  64% | abe: 6.674 | eve: 9.317 | bob: 7.628Epoch   8:  64% | abe: 6.671 | eve: 9.317 | bob: 7.626Epoch   8:  65% | abe: 6.669 | eve: 9.317 | bob: 7.623Epoch   8:  66% | abe: 6.666 | eve: 9.317 | bob: 7.621Epoch   8:  67% | abe: 6.663 | eve: 9.317 | bob: 7.618Epoch   8:  67% | abe: 6.660 | eve: 9.317 | bob: 7.616Epoch   8:  68% | abe: 6.658 | eve: 9.318 | bob: 7.613Epoch   8:  69% | abe: 6.656 | eve: 9.317 | bob: 7.611Epoch   8:  70% | abe: 6.653 | eve: 9.317 | bob: 7.608Epoch   8:  71% | abe: 6.650 | eve: 9.317 | bob: 7.606Epoch   8:  71% | abe: 6.647 | eve: 9.317 | bob: 7.603Epoch   8:  72% | abe: 6.645 | eve: 9.318 | bob: 7.601Epoch   8:  73% | abe: 6.642 | eve: 9.319 | bob: 7.599Epoch   8:  74% | abe: 6.639 | eve: 9.319 | bob: 7.595Epoch   8:  75% | abe: 6.636 | eve: 9.319 | bob: 7.593Epoch   8:  75% | abe: 6.633 | eve: 9.317 | bob: 7.591Epoch   8:  76% | abe: 6.630 | eve: 9.316 | bob: 7.588Epoch   8:  77% | abe: 6.627 | eve: 9.316 | bob: 7.586Epoch   8:  78% | abe: 6.624 | eve: 9.316 | bob: 7.583Epoch   8:  78% | abe: 6.621 | eve: 9.316 | bob: 7.581Epoch   8:  79% | abe: 6.619 | eve: 9.316 | bob: 7.578Epoch   8:  80% | abe: 6.616 | eve: 9.316 | bob: 7.576Epoch   8:  81% | abe: 6.614 | eve: 9.316 | bob: 7.573Epoch   8:  82% | abe: 6.612 | eve: 9.317 | bob: 7.571Epoch   8:  82% | abe: 6.609 | eve: 9.317 | bob: 7.569Epoch   8:  83% | abe: 6.605 | eve: 9.316 | bob: 7.566Epoch   8:  84% | abe: 6.603 | eve: 9.316 | bob: 7.564Epoch   8:  85% | abe: 6.600 | eve: 9.316 | bob: 7.561Epoch   8:  85% | abe: 6.597 | eve: 9.316 | bob: 7.559Epoch   8:  86% | abe: 6.595 | eve: 9.316 | bob: 7.557Epoch   8:  87% | abe: 6.592 | eve: 9.316 | bob: 7.555Epoch   8:  88% | abe: 6.590 | eve: 9.316 | bob: 7.552Epoch   8:  89% | abe: 6.587 | eve: 9.317 | bob: 7.550Epoch   8:  89% | abe: 6.584 | eve: 9.316 | bob: 7.547Epoch   8:  90% | abe: 6.582 | eve: 9.316 | bob: 7.545Epoch   8:  91% | abe: 6.579 | eve: 9.315 | bob: 7.543Epoch   8:  92% | abe: 6.577 | eve: 9.315 | bob: 7.540Epoch   8:  92% | abe: 6.574 | eve: 9.314 | bob: 7.538Epoch   8:  93% | abe: 6.571 | eve: 9.314 | bob: 7.536Epoch   8:  94% | abe: 6.568 | eve: 9.314 | bob: 7.533Epoch   8:  95% | abe: 6.566 | eve: 9.313 | bob: 7.531Epoch   8:  96% | abe: 6.564 | eve: 9.313 | bob: 7.529Epoch   8:  96% | abe: 6.561 | eve: 9.314 | bob: 7.526Epoch   8:  97% | abe: 6.558 | eve: 9.314 | bob: 7.523Epoch   8:  98% | abe: 6.555 | eve: 9.314 | bob: 7.520Epoch   8:  99% | abe: 6.553 | eve: 9.313 | bob: 7.518
New best Bob loss 7.518434831174545 at epoch 8
Epoch   9:   0% | abe: 6.245 | eve: 9.279 | bob: 7.156Epoch   9:   0% | abe: 6.224 | eve: 9.278 | bob: 7.211Epoch   9:   1% | abe: 6.224 | eve: 9.281 | bob: 7.200Epoch   9:   2% | abe: 6.223 | eve: 9.301 | bob: 7.200Epoch   9:   3% | abe: 6.219 | eve: 9.313 | bob: 7.205Epoch   9:   3% | abe: 6.207 | eve: 9.322 | bob: 7.200Epoch   9:   4% | abe: 6.202 | eve: 9.315 | bob: 7.201Epoch   9:   5% | abe: 6.194 | eve: 9.304 | bob: 7.198Epoch   9:   6% | abe: 6.201 | eve: 9.302 | bob: 7.202Epoch   9:   7% | abe: 6.204 | eve: 9.296 | bob: 7.203Epoch   9:   7% | abe: 6.201 | eve: 9.298 | bob: 7.201Epoch   9:   8% | abe: 6.193 | eve: 9.304 | bob: 7.194Epoch   9:   9% | abe: 6.195 | eve: 9.305 | bob: 7.197Epoch   9:  10% | abe: 6.190 | eve: 9.306 | bob: 7.191Epoch   9:  10% | abe: 6.190 | eve: 9.304 | bob: 7.190Epoch   9:  11% | abe: 6.188 | eve: 9.305 | bob: 7.190Epoch   9:  12% | abe: 6.181 | eve: 9.310 | bob: 7.184Epoch   9:  13% | abe: 6.182 | eve: 9.307 | bob: 7.182Epoch   9:  14% | abe: 6.181 | eve: 9.307 | bob: 7.180Epoch   9:  14% | abe: 6.177 | eve: 9.306 | bob: 7.178Epoch   9:  15% | abe: 6.175 | eve: 9.308 | bob: 7.175Epoch   9:  16% | abe: 6.169 | eve: 9.302 | bob: 7.169Epoch   9:  17% | abe: 6.167 | eve: 9.303 | bob: 7.167Epoch   9:  17% | abe: 6.164 | eve: 9.303 | bob: 7.163Epoch   9:  18% | abe: 6.161 | eve: 9.300 | bob: 7.162Epoch   9:  19% | abe: 6.159 | eve: 9.300 | bob: 7.160Epoch   9:  20% | abe: 6.153 | eve: 9.300 | bob: 7.155Epoch   9:  21% | abe: 6.150 | eve: 9.296 | bob: 7.152Epoch   9:  21% | abe: 6.148 | eve: 9.296 | bob: 7.150Epoch   9:  22% | abe: 6.146 | eve: 9.297 | bob: 7.149Epoch   9:  23% | abe: 6.145 | eve: 9.297 | bob: 7.148Epoch   9:  24% | abe: 6.144 | eve: 9.297 | bob: 7.147Epoch   9:  25% | abe: 6.142 | eve: 9.297 | bob: 7.145Epoch   9:  25% | abe: 6.140 | eve: 9.297 | bob: 7.143Epoch   9:  26% | abe: 6.138 | eve: 9.296 | bob: 7.143Epoch   9:  27% | abe: 6.134 | eve: 9.297 | bob: 7.139Epoch   9:  28% | abe: 6.132 | eve: 9.295 | bob: 7.136Epoch   9:  28% | abe: 6.131 | eve: 9.293 | bob: 7.134Epoch   9:  29% | abe: 6.128 | eve: 9.294 | bob: 7.131Epoch   9:  30% | abe: 6.126 | eve: 9.294 | bob: 7.130Epoch   9:  31% | abe: 6.124 | eve: 9.294 | bob: 7.128Epoch   9:  32% | abe: 6.122 | eve: 9.296 | bob: 7.126Epoch   9:  32% | abe: 6.121 | eve: 9.293 | bob: 7.124Epoch   9:  33% | abe: 6.117 | eve: 9.294 | bob: 7.121Epoch   9:  34% | abe: 6.114 | eve: 9.295 | bob: 7.118Epoch   9:  35% | abe: 6.111 | eve: 9.296 | bob: 7.116Epoch   9:  35% | abe: 6.108 | eve: 9.296 | bob: 7.112Epoch   9:  36% | abe: 6.105 | eve: 9.297 | bob: 7.111Epoch   9:  37% | abe: 6.104 | eve: 9.299 | bob: 7.109Epoch   9:  38% | abe: 6.102 | eve: 9.297 | bob: 7.107Epoch   9:  39% | abe: 6.099 | eve: 9.297 | bob: 7.105Epoch   9:  39% | abe: 6.097 | eve: 9.298 | bob: 7.103Epoch   9:  40% | abe: 6.094 | eve: 9.298 | bob: 7.100Epoch   9:  41% | abe: 6.092 | eve: 9.298 | bob: 7.097Epoch   9:  42% | abe: 6.088 | eve: 9.297 | bob: 7.094Epoch   9:  42% | abe: 6.087 | eve: 9.297 | bob: 7.093Epoch   9:  43% | abe: 6.084 | eve: 9.297 | bob: 7.090Epoch   9:  44% | abe: 6.081 | eve: 9.296 | bob: 7.087Epoch   9:  45% | abe: 6.079 | eve: 9.295 | bob: 7.084Epoch   9:  46% | abe: 6.076 | eve: 9.295 | bob: 7.081Epoch   9:  46% | abe: 6.073 | eve: 9.296 | bob: 7.078Epoch   9:  47% | abe: 6.070 | eve: 9.297 | bob: 7.076Epoch   9:  48% | abe: 6.068 | eve: 9.297 | bob: 7.074Epoch   9:  49% | abe: 6.066 | eve: 9.296 | bob: 7.072Epoch   9:  50% | abe: 6.063 | eve: 9.296 | bob: 7.070Epoch   9:  50% | abe: 6.061 | eve: 9.296 | bob: 7.067Epoch   9:  51% | abe: 6.058 | eve: 9.295 | bob: 7.064Epoch   9:  52% | abe: 6.055 | eve: 9.295 | bob: 7.062Epoch   9:  53% | abe: 6.051 | eve: 9.295 | bob: 7.059Epoch   9:  53% | abe: 6.049 | eve: 9.295 | bob: 7.056Epoch   9:  54% | abe: 6.046 | eve: 9.295 | bob: 7.054Epoch   9:  55% | abe: 6.044 | eve: 9.295 | bob: 7.051Epoch   9:  56% | abe: 6.041 | eve: 9.295 | bob: 7.049Epoch   9:  57% | abe: 6.038 | eve: 9.294 | bob: 7.046Epoch   9:  57% | abe: 6.035 | eve: 9.295 | bob: 7.044Epoch   9:  58% | abe: 6.032 | eve: 9.294 | bob: 7.042Epoch   9:  59% | abe: 6.031 | eve: 9.294 | bob: 7.040Epoch   9:  60% | abe: 6.029 | eve: 9.294 | bob: 7.038Epoch   9:  60% | abe: 6.026 | eve: 9.294 | bob: 7.036Epoch   9:  61% | abe: 6.024 | eve: 9.294 | bob: 7.033Epoch   9:  62% | abe: 6.022 | eve: 9.294 | bob: 7.031Epoch   9:  63% | abe: 6.019 | eve: 9.294 | bob: 7.029Epoch   9:  64% | abe: 6.017 | eve: 9.294 | bob: 7.026Epoch   9:  64% | abe: 6.014 | eve: 9.294 | bob: 7.024Epoch   9:  65% | abe: 6.012 | eve: 9.293 | bob: 7.021Epoch   9:  66% | abe: 6.009 | eve: 9.293 | bob: 7.018Epoch   9:  67% | abe: 6.006 | eve: 9.293 | bob: 7.016Epoch   9:  67% | abe: 6.003 | eve: 9.293 | bob: 7.013Epoch   9:  68% | abe: 6.001 | eve: 9.293 | bob: 7.010Epoch   9:  69% | abe: 5.998 | eve: 9.292 | bob: 7.008Epoch   9:  70% | abe: 5.996 | eve: 9.292 | bob: 7.005Epoch   9:  71% | abe: 5.993 | eve: 9.292 | bob: 7.003Epoch   9:  71% | abe: 5.991 | eve: 9.292 | bob: 7.001Epoch   9:  72% | abe: 5.989 | eve: 9.292 | bob: 6.998Epoch   9:  73% | abe: 5.986 | eve: 9.293 | bob: 6.996Epoch   9:  74% | abe: 5.984 | eve: 9.292 | bob: 6.994Epoch   9:  75% | abe: 5.981 | eve: 9.292 | bob: 6.992Epoch   9:  75% | abe: 5.979 | eve: 9.292 | bob: 6.989Epoch   9:  76% | abe: 5.976 | eve: 9.292 | bob: 6.987Epoch   9:  77% | abe: 5.974 | eve: 9.291 | bob: 6.984Epoch   9:  78% | abe: 5.971 | eve: 9.291 | bob: 6.981Epoch   9:  78% | abe: 5.969 | eve: 9.291 | bob: 6.979Epoch   9:  79% | abe: 5.966 | eve: 9.290 | bob: 6.976Epoch   9:  80% | abe: 5.964 | eve: 9.290 | bob: 6.974Epoch   9:  81% | abe: 5.961 | eve: 9.291 | bob: 6.971Epoch   9:  82% | abe: 5.959 | eve: 9.292 | bob: 6.969Epoch   9:  82% | abe: 5.956 | eve: 9.292 | bob: 6.966Epoch   9:  83% | abe: 5.954 | eve: 9.292 | bob: 6.964Epoch   9:  84% | abe: 5.951 | eve: 9.292 | bob: 6.961Epoch   9:  85% | abe: 5.949 | eve: 9.291 | bob: 6.958Epoch   9:  85% | abe: 5.947 | eve: 9.292 | bob: 6.956Epoch   9:  86% | abe: 5.944 | eve: 9.292 | bob: 6.954Epoch   9:  87% | abe: 5.942 | eve: 9.292 | bob: 6.951Epoch   9:  88% | abe: 5.940 | eve: 9.292 | bob: 6.949Epoch   9:  89% | abe: 5.938 | eve: 9.292 | bob: 6.948Epoch   9:  89% | abe: 5.936 | eve: 9.292 | bob: 6.945Epoch   9:  90% | abe: 5.933 | eve: 9.292 | bob: 6.942Epoch   9:  91% | abe: 5.931 | eve: 9.292 | bob: 6.940Epoch   9:  92% | abe: 5.928 | eve: 9.292 | bob: 6.937Epoch   9:  92% | abe: 5.927 | eve: 9.292 | bob: 6.935Epoch   9:  93% | abe: 5.924 | eve: 9.293 | bob: 6.933Epoch   9:  94% | abe: 5.922 | eve: 9.293 | bob: 6.931Epoch   9:  95% | abe: 5.920 | eve: 9.293 | bob: 6.928Epoch   9:  96% | abe: 5.918 | eve: 9.294 | bob: 6.926Epoch   9:  96% | abe: 5.916 | eve: 9.293 | bob: 6.924Epoch   9:  97% | abe: 5.914 | eve: 9.294 | bob: 6.922Epoch   9:  98% | abe: 5.912 | eve: 9.293 | bob: 6.920Epoch   9:  99% | abe: 5.910 | eve: 9.293 | bob: 6.918
New best Bob loss 6.917559766619206 at epoch 9
Epoch  10:   0% | abe: 5.599 | eve: 9.230 | bob: 6.595Epoch  10:   0% | abe: 5.633 | eve: 9.258 | bob: 6.613Epoch  10:   1% | abe: 5.626 | eve: 9.273 | bob: 6.597Epoch  10:   2% | abe: 5.628 | eve: 9.287 | bob: 6.603Epoch  10:   3% | abe: 5.618 | eve: 9.305 | bob: 6.594Epoch  10:   3% | abe: 5.611 | eve: 9.311 | bob: 6.585Epoch  10:   4% | abe: 5.614 | eve: 9.311 | bob: 6.594Epoch  10:   5% | abe: 5.615 | eve: 9.303 | bob: 6.592Epoch  10:   6% | abe: 5.613 | eve: 9.299 | bob: 6.587Epoch  10:   7% | abe: 5.613 | eve: 9.293 | bob: 6.589Epoch  10:   7% | abe: 5.609 | eve: 9.294 | bob: 6.587Epoch  10:   8% | abe: 5.609 | eve: 9.290 | bob: 6.587Epoch  10:   9% | abe: 5.610 | eve: 9.288 | bob: 6.593Epoch  10:  10% | abe: 5.611 | eve: 9.291 | bob: 6.594Epoch  10:  10% | abe: 5.610 | eve: 9.291 | bob: 6.591Epoch  10:  11% | abe: 5.606 | eve: 9.294 | bob: 6.587Epoch  10:  12% | abe: 5.599 | eve: 9.294 | bob: 6.582Epoch  10:  13% | abe: 5.598 | eve: 9.290 | bob: 6.582Epoch  10:  14% | abe: 5.597 | eve: 9.295 | bob: 6.580Epoch  10:  14% | abe: 5.592 | eve: 9.295 | bob: 6.576Epoch  10:  15% | abe: 5.590 | eve: 9.294 | bob: 6.572Epoch  10:  16% | abe: 5.588 | eve: 9.294 | bob: 6.571Epoch  10:  17% | abe: 5.588 | eve: 9.297 | bob: 6.573Epoch  10:  17% | abe: 5.584 | eve: 9.298 | bob: 6.571Epoch  10:  18% | abe: 5.584 | eve: 9.295 | bob: 6.571Epoch  10:  19% | abe: 5.583 | eve: 9.295 | bob: 6.568Epoch  10:  20% | abe: 5.582 | eve: 9.297 | bob: 6.565Epoch  10:  21% | abe: 5.582 | eve: 9.297 | bob: 6.567Epoch  10:  21% | abe: 5.580 | eve: 9.298 | bob: 6.562Epoch  10:  22% | abe: 5.578 | eve: 9.299 | bob: 6.562Epoch  10:  23% | abe: 5.576 | eve: 9.299 | bob: 6.557Epoch  10:  24% | abe: 5.573 | eve: 9.297 | bob: 6.554Epoch  10:  25% | abe: 5.572 | eve: 9.298 | bob: 6.553Epoch  10:  25% | abe: 5.571 | eve: 9.298 | bob: 6.551Epoch  10:  26% | abe: 5.571 | eve: 9.297 | bob: 6.550Epoch  10:  27% | abe: 5.571 | eve: 9.295 | bob: 6.549Epoch  10:  28% | abe: 5.569 | eve: 9.293 | bob: 6.547Epoch  10:  28% | abe: 5.568 | eve: 9.292 | bob: 6.546Epoch  10:  29% | abe: 5.567 | eve: 9.290 | bob: 6.544Epoch  10:  30% | abe: 5.565 | eve: 9.289 | bob: 6.542Epoch  10:  31% | abe: 5.563 | eve: 9.289 | bob: 6.538Epoch  10:  32% | abe: 5.560 | eve: 9.288 | bob: 6.536Epoch  10:  32% | abe: 5.557 | eve: 9.288 | bob: 6.533Epoch  10:  33% | abe: 5.555 | eve: 9.288 | bob: 6.531Epoch  10:  34% | abe: 5.553 | eve: 9.288 | bob: 6.529Epoch  10:  35% | abe: 5.551 | eve: 9.290 | bob: 6.526Epoch  10:  35% | abe: 5.549 | eve: 9.289 | bob: 6.523Epoch  10:  36% | abe: 5.547 | eve: 9.288 | bob: 6.521Epoch  10:  37% | abe: 5.545 | eve: 9.287 | bob: 6.518Epoch  10:  38% | abe: 5.542 | eve: 9.288 | bob: 6.515Epoch  10:  39% | abe: 5.541 | eve: 9.288 | bob: 6.513Epoch  10:  39% | abe: 5.538 | eve: 9.288 | bob: 6.510Epoch  10:  40% | abe: 5.536 | eve: 9.289 | bob: 6.507Epoch  10:  41% | abe: 5.534 | eve: 9.288 | bob: 6.504Epoch  10:  42% | abe: 5.532 | eve: 9.289 | bob: 6.503Epoch  10:  42% | abe: 5.529 | eve: 9.289 | bob: 6.500Epoch  10:  43% | abe: 5.528 | eve: 9.289 | bob: 6.497Epoch  10:  44% | abe: 5.526 | eve: 9.289 | bob: 6.496Epoch  10:  45% | abe: 5.523 | eve: 9.289 | bob: 6.494Epoch  10:  46% | abe: 5.520 | eve: 9.288 | bob: 6.490Epoch  10:  46% | abe: 5.518 | eve: 9.288 | bob: 6.487Epoch  10:  47% | abe: 5.515 | eve: 9.287 | bob: 6.485Epoch  10:  48% | abe: 5.512 | eve: 9.286 | bob: 6.481Epoch  10:  49% | abe: 5.510 | eve: 9.285 | bob: 6.479Epoch  10:  50% | abe: 5.508 | eve: 9.287 | bob: 6.476Epoch  10:  50% | abe: 5.506 | eve: 9.286 | bob: 6.473Epoch  10:  51% | abe: 5.504 | eve: 9.286 | bob: 6.470Epoch  10:  52% | abe: 5.501 | eve: 9.286 | bob: 6.468Epoch  10:  53% | abe: 5.499 | eve: 9.286 | bob: 6.466Epoch  10:  53% | abe: 5.497 | eve: 9.286 | bob: 6.463Epoch  10:  54% | abe: 5.496 | eve: 9.286 | bob: 6.462Epoch  10:  55% | abe: 5.495 | eve: 9.287 | bob: 6.460Epoch  10:  56% | abe: 5.492 | eve: 9.289 | bob: 6.458Epoch  10:  57% | abe: 5.490 | eve: 9.289 | bob: 6.455Epoch  10:  57% | abe: 5.488 | eve: 9.289 | bob: 6.453Epoch  10:  58% | abe: 5.485 | eve: 9.291 | bob: 6.450Epoch  10:  59% | abe: 5.482 | eve: 9.291 | bob: 6.447Epoch  10:  60% | abe: 5.480 | eve: 9.291 | bob: 6.443Epoch  10:  60% | abe: 5.478 | eve: 9.291 | bob: 6.441Epoch  10:  61% | abe: 5.476 | eve: 9.292 | bob: 6.439Epoch  10:  62% | abe: 5.474 | eve: 9.292 | bob: 6.436Epoch  10:  63% | abe: 5.471 | eve: 9.291 | bob: 6.433Epoch  10:  64% | abe: 5.469 | eve: 9.292 | bob: 6.431Epoch  10:  64% | abe: 5.468 | eve: 9.292 | bob: 6.429Epoch  10:  65% | abe: 5.465 | eve: 9.293 | bob: 6.426Epoch  10:  66% | abe: 5.463 | eve: 9.292 | bob: 6.423Epoch  10:  67% | abe: 5.462 | eve: 9.292 | bob: 6.422Epoch  10:  67% | abe: 5.459 | eve: 9.293 | bob: 6.419Epoch  10:  68% | abe: 5.457 | eve: 9.292 | bob: 6.417Epoch  10:  69% | abe: 5.455 | eve: 9.292 | bob: 6.414Epoch  10:  70% | abe: 5.453 | eve: 9.292 | bob: 6.412Epoch  10:  71% | abe: 5.452 | eve: 9.291 | bob: 6.410Epoch  10:  71% | abe: 5.450 | eve: 9.291 | bob: 6.408Epoch  10:  72% | abe: 5.447 | eve: 9.291 | bob: 6.405Epoch  10:  73% | abe: 5.446 | eve: 9.291 | bob: 6.403Epoch  10:  74% | abe: 5.444 | eve: 9.291 | bob: 6.401Epoch  10:  75% | abe: 5.443 | eve: 9.291 | bob: 6.399Epoch  10:  75% | abe: 5.441 | eve: 9.291 | bob: 6.396Epoch  10:  76% | abe: 5.439 | eve: 9.291 | bob: 6.394Epoch  10:  77% | abe: 5.437 | eve: 9.291 | bob: 6.391Epoch  10:  78% | abe: 5.436 | eve: 9.291 | bob: 6.390Epoch  10:  78% | abe: 5.434 | eve: 9.290 | bob: 6.387Epoch  10:  79% | abe: 5.432 | eve: 9.291 | bob: 6.385Epoch  10:  80% | abe: 5.431 | eve: 9.290 | bob: 6.383Epoch  10:  81% | abe: 5.428 | eve: 9.291 | bob: 6.380Epoch  10:  82% | abe: 5.426 | eve: 9.291 | bob: 6.377Epoch  10:  82% | abe: 5.425 | eve: 9.291 | bob: 6.375Epoch  10:  83% | abe: 5.423 | eve: 9.291 | bob: 6.373Epoch  10:  84% | abe: 5.421 | eve: 9.290 | bob: 6.370Epoch  10:  85% | abe: 5.419 | eve: 9.290 | bob: 6.368Epoch  10:  85% | abe: 5.417 | eve: 9.290 | bob: 6.366Epoch  10:  86% | abe: 5.415 | eve: 9.290 | bob: 6.364Epoch  10:  87% | abe: 5.414 | eve: 9.290 | bob: 6.362Epoch  10:  88% | abe: 5.411 | eve: 9.290 | bob: 6.360Epoch  10:  89% | abe: 5.410 | eve: 9.291 | bob: 6.358Epoch  10:  89% | abe: 5.408 | eve: 9.290 | bob: 6.356Epoch  10:  90% | abe: 5.406 | eve: 9.290 | bob: 6.354Epoch  10:  91% | abe: 5.405 | eve: 9.290 | bob: 6.352Epoch  10:  92% | abe: 5.402 | eve: 9.290 | bob: 6.349Epoch  10:  92% | abe: 5.401 | eve: 9.290 | bob: 6.347Epoch  10:  93% | abe: 5.400 | eve: 9.290 | bob: 6.346Epoch  10:  94% | abe: 5.398 | eve: 9.290 | bob: 6.343Epoch  10:  95% | abe: 5.396 | eve: 9.289 | bob: 6.341Epoch  10:  96% | abe: 5.394 | eve: 9.289 | bob: 6.339Epoch  10:  96% | abe: 5.392 | eve: 9.289 | bob: 6.337Epoch  10:  97% | abe: 5.390 | eve: 9.289 | bob: 6.335Epoch  10:  98% | abe: 5.388 | eve: 9.289 | bob: 6.332Epoch  10:  99% | abe: 5.386 | eve: 9.290 | bob: 6.330
New best Bob loss 6.329991310174364 at epoch 10
Epoch  11:   0% | abe: 5.101 | eve: 9.249 | bob: 6.031Epoch  11:   0% | abe: 5.160 | eve: 9.300 | bob: 6.063Epoch  11:   1% | abe: 5.147 | eve: 9.305 | bob: 6.074Epoch  11:   2% | abe: 5.154 | eve: 9.287 | bob: 6.079Epoch  11:   3% | abe: 5.137 | eve: 9.281 | bob: 6.061Epoch  11:   3% | abe: 5.141 | eve: 9.263 | bob: 6.071Epoch  11:   4% | abe: 5.142 | eve: 9.269 | bob: 6.069Epoch  11:   5% | abe: 5.142 | eve: 9.266 | bob: 6.069Epoch  11:   6% | abe: 5.132 | eve: 9.262 | bob: 6.058Epoch  11:   7% | abe: 5.128 | eve: 9.265 | bob: 6.047Epoch  11:   7% | abe: 5.126 | eve: 9.266 | bob: 6.044Epoch  11:   8% | abe: 5.123 | eve: 9.268 | bob: 6.041Epoch  11:   9% | abe: 5.123 | eve: 9.268 | bob: 6.038Epoch  11:  10% | abe: 5.121 | eve: 9.267 | bob: 6.035Epoch  11:  10% | abe: 5.119 | eve: 9.270 | bob: 6.032Epoch  11:  11% | abe: 5.117 | eve: 9.275 | bob: 6.030Epoch  11:  12% | abe: 5.115 | eve: 9.276 | bob: 6.029Epoch  11:  13% | abe: 5.112 | eve: 9.276 | bob: 6.025Epoch  11:  14% | abe: 5.109 | eve: 9.270 | bob: 6.021Epoch  11:  14% | abe: 5.105 | eve: 9.271 | bob: 6.019Epoch  11:  15% | abe: 5.101 | eve: 9.272 | bob: 6.014Epoch  11:  16% | abe: 5.100 | eve: 9.271 | bob: 6.012Epoch  11:  17% | abe: 5.100 | eve: 9.271 | bob: 6.012Epoch  11:  17% | abe: 5.099 | eve: 9.267 | bob: 6.012Epoch  11:  18% | abe: 5.095 | eve: 9.266 | bob: 6.008Epoch  11:  19% | abe: 5.093 | eve: 9.269 | bob: 6.008Epoch  11:  20% | abe: 5.092 | eve: 9.271 | bob: 6.006Epoch  11:  21% | abe: 5.091 | eve: 9.272 | bob: 6.006Epoch  11:  21% | abe: 5.088 | eve: 9.273 | bob: 6.003Epoch  11:  22% | abe: 5.084 | eve: 9.272 | bob: 5.999Epoch  11:  23% | abe: 5.083 | eve: 9.270 | bob: 5.996Epoch  11:  24% | abe: 5.079 | eve: 9.270 | bob: 5.991Epoch  11:  25% | abe: 5.079 | eve: 9.270 | bob: 5.991Epoch  11:  25% | abe: 5.076 | eve: 9.271 | bob: 5.987Epoch  11:  26% | abe: 5.074 | eve: 9.271 | bob: 5.984Epoch  11:  27% | abe: 5.073 | eve: 9.271 | bob: 5.982Epoch  11:  28% | abe: 5.071 | eve: 9.272 | bob: 5.979Epoch  11:  28% | abe: 5.070 | eve: 9.273 | bob: 5.977Epoch  11:  29% | abe: 5.066 | eve: 9.272 | bob: 5.972Epoch  11:  30% | abe: 5.065 | eve: 9.272 | bob: 5.969Epoch  11:  31% | abe: 5.064 | eve: 9.272 | bob: 5.968Epoch  11:  32% | abe: 5.062 | eve: 9.273 | bob: 5.965Epoch  11:  32% | abe: 5.060 | eve: 9.274 | bob: 5.962Epoch  11:  33% | abe: 5.058 | eve: 9.275 | bob: 5.959Epoch  11:  34% | abe: 5.058 | eve: 9.275 | bob: 5.958Epoch  11:  35% | abe: 5.057 | eve: 9.275 | bob: 5.957Epoch  11:  35% | abe: 5.055 | eve: 9.275 | bob: 5.955Epoch  11:  36% | abe: 5.054 | eve: 9.276 | bob: 5.953Epoch  11:  37% | abe: 5.054 | eve: 9.276 | bob: 5.952Epoch  11:  38% | abe: 5.052 | eve: 9.276 | bob: 5.949Epoch  11:  39% | abe: 5.051 | eve: 9.274 | bob: 5.948Epoch  11:  39% | abe: 5.049 | eve: 9.275 | bob: 5.946Epoch  11:  40% | abe: 5.047 | eve: 9.275 | bob: 5.943Epoch  11:  41% | abe: 5.046 | eve: 9.275 | bob: 5.942Epoch  11:  42% | abe: 5.044 | eve: 9.275 | bob: 5.939Epoch  11:  42% | abe: 5.041 | eve: 9.274 | bob: 5.936Epoch  11:  43% | abe: 5.038 | eve: 9.274 | bob: 5.933Epoch  11:  44% | abe: 5.038 | eve: 9.274 | bob: 5.932Epoch  11:  45% | abe: 5.036 | eve: 9.275 | bob: 5.929Epoch  11:  46% | abe: 5.034 | eve: 9.276 | bob: 5.927Epoch  11:  46% | abe: 5.032 | eve: 9.277 | bob: 5.924Epoch  11:  47% | abe: 5.030 | eve: 9.278 | bob: 5.922Epoch  11:  48% | abe: 5.028 | eve: 9.277 | bob: 5.919Epoch  11:  49% | abe: 5.027 | eve: 9.276 | bob: 5.917Epoch  11:  50% | abe: 5.025 | eve: 9.275 | bob: 5.914Epoch  11:  50% | abe: 5.023 | eve: 9.275 | bob: 5.913Epoch  11:  51% | abe: 5.022 | eve: 9.275 | bob: 5.911Epoch  11:  52% | abe: 5.020 | eve: 9.275 | bob: 5.908Epoch  11:  53% | abe: 5.019 | eve: 9.275 | bob: 5.907Epoch  11:  53% | abe: 5.017 | eve: 9.275 | bob: 5.905Epoch  11:  54% | abe: 5.015 | eve: 9.276 | bob: 5.903Epoch  11:  55% | abe: 5.013 | eve: 9.277 | bob: 5.900Epoch  11:  56% | abe: 5.012 | eve: 9.277 | bob: 5.898Epoch  11:  57% | abe: 5.010 | eve: 9.277 | bob: 5.896Epoch  11:  57% | abe: 5.010 | eve: 9.277 | bob: 5.895Epoch  11:  58% | abe: 5.007 | eve: 9.278 | bob: 5.892Epoch  11:  59% | abe: 5.005 | eve: 9.279 | bob: 5.889Epoch  11:  60% | abe: 5.003 | eve: 9.278 | bob: 5.887Epoch  11:  60% | abe: 5.001 | eve: 9.278 | bob: 5.884Epoch  11:  61% | abe: 4.998 | eve: 9.278 | bob: 5.881Epoch  11:  62% | abe: 4.996 | eve: 9.278 | bob: 5.879Epoch  11:  63% | abe: 4.994 | eve: 9.278 | bob: 5.876Epoch  11:  64% | abe: 4.993 | eve: 9.278 | bob: 5.874Epoch  11:  64% | abe: 4.991 | eve: 9.279 | bob: 5.871Epoch  11:  65% | abe: 4.989 | eve: 9.278 | bob: 5.869Epoch  11:  66% | abe: 4.987 | eve: 9.278 | bob: 5.867Epoch  11:  67% | abe: 4.985 | eve: 9.278 | bob: 5.864Epoch  11:  67% | abe: 4.984 | eve: 9.277 | bob: 5.863Epoch  11:  68% | abe: 4.982 | eve: 9.277 | bob: 5.860Epoch  11:  69% | abe: 4.980 | eve: 9.277 | bob: 5.858Epoch  11:  70% | abe: 4.979 | eve: 9.277 | bob: 5.856Epoch  11:  71% | abe: 4.978 | eve: 9.277 | bob: 5.854Epoch  11:  71% | abe: 4.976 | eve: 9.277 | bob: 5.852Epoch  11:  72% | abe: 4.975 | eve: 9.277 | bob: 5.851Epoch  11:  73% | abe: 4.973 | eve: 9.277 | bob: 5.848Epoch  11:  74% | abe: 4.970 | eve: 9.276 | bob: 5.845Epoch  11:  75% | abe: 4.968 | eve: 9.277 | bob: 5.843Epoch  11:  75% | abe: 4.967 | eve: 9.277 | bob: 5.841Epoch  11:  76% | abe: 4.965 | eve: 9.277 | bob: 5.840Epoch  11:  77% | abe: 4.964 | eve: 9.277 | bob: 5.838Epoch  11:  78% | abe: 4.963 | eve: 9.277 | bob: 5.836Epoch  11:  78% | abe: 4.961 | eve: 9.277 | bob: 5.834Epoch  11:  79% | abe: 4.959 | eve: 9.278 | bob: 5.832Epoch  11:  80% | abe: 4.958 | eve: 9.278 | bob: 5.830Epoch  11:  81% | abe: 4.956 | eve: 9.277 | bob: 5.827Epoch  11:  82% | abe: 4.954 | eve: 9.277 | bob: 5.825Epoch  11:  82% | abe: 4.952 | eve: 9.277 | bob: 5.823Epoch  11:  83% | abe: 4.950 | eve: 9.277 | bob: 5.821Epoch  11:  84% | abe: 4.948 | eve: 9.278 | bob: 5.818Epoch  11:  85% | abe: 4.947 | eve: 9.278 | bob: 5.817Epoch  11:  85% | abe: 4.945 | eve: 9.277 | bob: 5.815Epoch  11:  86% | abe: 4.943 | eve: 9.277 | bob: 5.813Epoch  11:  87% | abe: 4.942 | eve: 9.277 | bob: 5.811Epoch  11:  88% | abe: 4.939 | eve: 9.277 | bob: 5.808Epoch  11:  89% | abe: 4.937 | eve: 9.277 | bob: 5.806Epoch  11:  89% | abe: 4.936 | eve: 9.277 | bob: 5.804Epoch  11:  90% | abe: 4.934 | eve: 9.278 | bob: 5.802Epoch  11:  91% | abe: 4.933 | eve: 9.278 | bob: 5.800Epoch  11:  92% | abe: 4.931 | eve: 9.277 | bob: 5.798Epoch  11:  92% | abe: 4.929 | eve: 9.277 | bob: 5.795Epoch  11:  93% | abe: 4.927 | eve: 9.278 | bob: 5.793Epoch  11:  94% | abe: 4.926 | eve: 9.278 | bob: 5.792Epoch  11:  95% | abe: 4.924 | eve: 9.278 | bob: 5.790Epoch  11:  96% | abe: 4.923 | eve: 9.278 | bob: 5.788Epoch  11:  96% | abe: 4.921 | eve: 9.278 | bob: 5.786Epoch  11:  97% | abe: 4.920 | eve: 9.277 | bob: 5.784Epoch  11:  98% | abe: 4.918 | eve: 9.278 | bob: 5.782Epoch  11:  99% | abe: 4.916 | eve: 9.277 | bob: 5.780
New best Bob loss 5.779721038688422 at epoch 11
Epoch  12:   0% | abe: 4.733 | eve: 9.238 | bob: 5.560Epoch  12:   0% | abe: 4.711 | eve: 9.255 | bob: 5.537Epoch  12:   1% | abe: 4.722 | eve: 9.253 | bob: 5.540Epoch  12:   2% | abe: 4.703 | eve: 9.268 | bob: 5.522Epoch  12:   3% | abe: 4.700 | eve: 9.270 | bob: 5.514Epoch  12:   3% | abe: 4.693 | eve: 9.266 | bob: 5.511Epoch  12:   4% | abe: 4.695 | eve: 9.264 | bob: 5.511Epoch  12:   5% | abe: 4.686 | eve: 9.268 | bob: 5.502Epoch  12:   6% | abe: 4.683 | eve: 9.261 | bob: 5.494Epoch  12:   7% | abe: 4.683 | eve: 9.258 | bob: 5.496Epoch  12:   7% | abe: 4.691 | eve: 9.259 | bob: 5.497Epoch  12:   8% | abe: 4.691 | eve: 9.252 | bob: 5.499Epoch  12:   9% | abe: 4.691 | eve: 9.259 | bob: 5.497Epoch  12:  10% | abe: 4.688 | eve: 9.257 | bob: 5.493Epoch  12:  10% | abe: 4.689 | eve: 9.264 | bob: 5.494Epoch  12:  11% | abe: 4.691 | eve: 9.262 | bob: 5.494Epoch  12:  12% | abe: 4.689 | eve: 9.262 | bob: 5.490Epoch  12:  13% | abe: 4.690 | eve: 9.260 | bob: 5.491Epoch  12:  14% | abe: 4.688 | eve: 9.260 | bob: 5.490Epoch  12:  14% | abe: 4.687 | eve: 9.264 | bob: 5.488Epoch  12:  15% | abe: 4.688 | eve: 9.265 | bob: 5.489Epoch  12:  16% | abe: 4.687 | eve: 9.265 | bob: 5.489Epoch  12:  17% | abe: 4.684 | eve: 9.260 | bob: 5.486Epoch  12:  17% | abe: 4.679 | eve: 9.262 | bob: 5.480Epoch  12:  18% | abe: 4.677 | eve: 9.259 | bob: 5.477Epoch  12:  19% | abe: 4.676 | eve: 9.260 | bob: 5.476Epoch  12:  20% | abe: 4.673 | eve: 9.263 | bob: 5.473Epoch  12:  21% | abe: 4.672 | eve: 9.262 | bob: 5.473Epoch  12:  21% | abe: 4.670 | eve: 9.263 | bob: 5.470Epoch  12:  22% | abe: 4.669 | eve: 9.264 | bob: 5.468Epoch  12:  23% | abe: 4.666 | eve: 9.265 | bob: 5.464Epoch  12:  24% | abe: 4.666 | eve: 9.263 | bob: 5.463Epoch  12:  25% | abe: 4.665 | eve: 9.267 | bob: 5.462Epoch  12:  25% | abe: 4.663 | eve: 9.268 | bob: 5.460Epoch  12:  26% | abe: 4.663 | eve: 9.267 | bob: 5.459Epoch  12:  27% | abe: 4.659 | eve: 9.268 | bob: 5.455Epoch  12:  28% | abe: 4.659 | eve: 9.268 | bob: 5.454Epoch  12:  28% | abe: 4.657 | eve: 9.267 | bob: 5.452Epoch  12:  29% | abe: 4.656 | eve: 9.267 | bob: 5.450Epoch  12:  30% | abe: 4.655 | eve: 9.269 | bob: 5.448Epoch  12:  31% | abe: 4.654 | eve: 9.270 | bob: 5.447Epoch  12:  32% | abe: 4.654 | eve: 9.269 | bob: 5.447Epoch  12:  32% | abe: 4.652 | eve: 9.269 | bob: 5.445Epoch  12:  33% | abe: 4.651 | eve: 9.270 | bob: 5.443Epoch  12:  34% | abe: 4.649 | eve: 9.271 | bob: 5.440Epoch  12:  35% | abe: 4.647 | eve: 9.271 | bob: 5.438Epoch  12:  35% | abe: 4.645 | eve: 9.272 | bob: 5.436Epoch  12:  36% | abe: 4.645 | eve: 9.272 | bob: 5.435Epoch  12:  37% | abe: 4.643 | eve: 9.272 | bob: 5.433Epoch  12:  38% | abe: 4.641 | eve: 9.272 | bob: 5.431Epoch  12:  39% | abe: 4.640 | eve: 9.272 | bob: 5.429Epoch  12:  39% | abe: 4.638 | eve: 9.271 | bob: 5.428Epoch  12:  40% | abe: 4.636 | eve: 9.273 | bob: 5.426Epoch  12:  41% | abe: 4.635 | eve: 9.272 | bob: 5.424Epoch  12:  42% | abe: 4.634 | eve: 9.272 | bob: 5.423Epoch  12:  42% | abe: 4.633 | eve: 9.273 | bob: 5.421Epoch  12:  43% | abe: 4.632 | eve: 9.274 | bob: 5.419Epoch  12:  44% | abe: 4.630 | eve: 9.275 | bob: 5.417Epoch  12:  45% | abe: 4.630 | eve: 9.274 | bob: 5.416Epoch  12:  46% | abe: 4.628 | eve: 9.274 | bob: 5.414Epoch  12:  46% | abe: 4.627 | eve: 9.275 | bob: 5.414Epoch  12:  47% | abe: 4.626 | eve: 9.274 | bob: 5.411Epoch  12:  48% | abe: 4.624 | eve: 9.273 | bob: 5.409Epoch  12:  49% | abe: 4.621 | eve: 9.272 | bob: 5.406Epoch  12:  50% | abe: 4.619 | eve: 9.272 | bob: 5.404Epoch  12:  50% | abe: 4.618 | eve: 9.273 | bob: 5.402Epoch  12:  51% | abe: 4.617 | eve: 9.274 | bob: 5.401Epoch  12:  52% | abe: 4.616 | eve: 9.274 | bob: 5.399Epoch  12:  53% | abe: 4.615 | eve: 9.274 | bob: 5.399Epoch  12:  53% | abe: 4.614 | eve: 9.274 | bob: 5.396Epoch  12:  54% | abe: 4.612 | eve: 9.274 | bob: 5.394Epoch  12:  55% | abe: 4.612 | eve: 9.274 | bob: 5.394Epoch  12:  56% | abe: 4.609 | eve: 9.274 | bob: 5.392Epoch  12:  57% | abe: 4.608 | eve: 9.275 | bob: 5.390Epoch  12:  57% | abe: 4.607 | eve: 9.276 | bob: 5.388Epoch  12:  58% | abe: 4.606 | eve: 9.276 | bob: 5.387Epoch  12:  59% | abe: 4.606 | eve: 9.276 | bob: 5.386Epoch  12:  60% | abe: 4.604 | eve: 9.276 | bob: 5.384Epoch  12:  60% | abe: 4.603 | eve: 9.276 | bob: 5.383Epoch  12:  61% | abe: 4.602 | eve: 9.276 | bob: 5.381Epoch  12:  62% | abe: 4.600 | eve: 9.276 | bob: 5.380Epoch  12:  63% | abe: 4.599 | eve: 9.277 | bob: 5.378Epoch  12:  64% | abe: 4.597 | eve: 9.277 | bob: 5.376Epoch  12:  64% | abe: 4.596 | eve: 9.276 | bob: 5.374Epoch  12:  65% | abe: 4.595 | eve: 9.277 | bob: 5.372Epoch  12:  66% | abe: 4.593 | eve: 9.276 | bob: 5.370Epoch  12:  67% | abe: 4.591 | eve: 9.276 | bob: 5.369Epoch  12:  67% | abe: 4.591 | eve: 9.276 | bob: 5.368Epoch  12:  68% | abe: 4.589 | eve: 9.274 | bob: 5.366Epoch  12:  69% | abe: 4.588 | eve: 9.274 | bob: 5.364Epoch  12:  70% | abe: 4.586 | eve: 9.274 | bob: 5.362Epoch  12:  71% | abe: 4.585 | eve: 9.275 | bob: 5.360Epoch  12:  71% | abe: 4.583 | eve: 9.275 | bob: 5.358Epoch  12:  72% | abe: 4.581 | eve: 9.275 | bob: 5.357Epoch  12:  73% | abe: 4.581 | eve: 9.275 | bob: 5.355Epoch  12:  74% | abe: 4.579 | eve: 9.275 | bob: 5.354Epoch  12:  75% | abe: 4.578 | eve: 9.274 | bob: 5.352Epoch  12:  75% | abe: 4.576 | eve: 9.274 | bob: 5.350Epoch  12:  76% | abe: 4.575 | eve: 9.275 | bob: 5.349Epoch  12:  77% | abe: 4.573 | eve: 9.275 | bob: 5.347Epoch  12:  78% | abe: 4.572 | eve: 9.274 | bob: 5.345Epoch  12:  78% | abe: 4.571 | eve: 9.275 | bob: 5.344Epoch  12:  79% | abe: 4.569 | eve: 9.275 | bob: 5.342Epoch  12:  80% | abe: 4.568 | eve: 9.276 | bob: 5.341Epoch  12:  81% | abe: 4.567 | eve: 9.275 | bob: 5.339Epoch  12:  82% | abe: 4.565 | eve: 9.276 | bob: 5.337Epoch  12:  82% | abe: 4.563 | eve: 9.276 | bob: 5.335Epoch  12:  83% | abe: 4.562 | eve: 9.275 | bob: 5.334Epoch  12:  84% | abe: 4.560 | eve: 9.275 | bob: 5.332Epoch  12:  85% | abe: 4.559 | eve: 9.275 | bob: 5.331Epoch  12:  85% | abe: 4.558 | eve: 9.275 | bob: 5.329Epoch  12:  86% | abe: 4.557 | eve: 9.274 | bob: 5.327Epoch  12:  87% | abe: 4.556 | eve: 9.274 | bob: 5.326Epoch  12:  88% | abe: 4.554 | eve: 9.274 | bob: 5.324Epoch  12:  89% | abe: 4.553 | eve: 9.274 | bob: 5.322Epoch  12:  89% | abe: 4.552 | eve: 9.273 | bob: 5.321Epoch  12:  90% | abe: 4.550 | eve: 9.274 | bob: 5.319Epoch  12:  91% | abe: 4.550 | eve: 9.274 | bob: 5.318Epoch  12:  92% | abe: 4.548 | eve: 9.274 | bob: 5.316Epoch  12:  92% | abe: 4.546 | eve: 9.273 | bob: 5.314Epoch  12:  93% | abe: 4.545 | eve: 9.274 | bob: 5.313Epoch  12:  94% | abe: 4.544 | eve: 9.274 | bob: 5.311Epoch  12:  95% | abe: 4.542 | eve: 9.273 | bob: 5.310Epoch  12:  96% | abe: 4.541 | eve: 9.274 | bob: 5.308Epoch  12:  96% | abe: 4.540 | eve: 9.274 | bob: 5.307Epoch  12:  97% | abe: 4.539 | eve: 9.274 | bob: 5.306Epoch  12:  98% | abe: 4.537 | eve: 9.274 | bob: 5.304Epoch  12:  99% | abe: 4.536 | eve: 9.274 | bob: 5.303
New best Bob loss 5.302720456512816 at epoch 12
Epoch  13:   0% | abe: 4.349 | eve: 9.362 | bob: 5.051Epoch  13:   0% | abe: 4.374 | eve: 9.337 | bob: 5.079Epoch  13:   1% | abe: 4.382 | eve: 9.335 | bob: 5.109Epoch  13:   2% | abe: 4.380 | eve: 9.339 | bob: 5.114Epoch  13:   3% | abe: 4.367 | eve: 9.340 | bob: 5.100Epoch  13:   3% | abe: 4.358 | eve: 9.322 | bob: 5.091Epoch  13:   4% | abe: 4.362 | eve: 9.308 | bob: 5.096Epoch  13:   5% | abe: 4.361 | eve: 9.292 | bob: 5.092Epoch  13:   6% | abe: 4.357 | eve: 9.294 | bob: 5.084Epoch  13:   7% | abe: 4.355 | eve: 9.294 | bob: 5.083Epoch  13:   7% | abe: 4.360 | eve: 9.291 | bob: 5.083Epoch  13:   8% | abe: 4.359 | eve: 9.286 | bob: 5.083Epoch  13:   9% | abe: 4.360 | eve: 9.282 | bob: 5.084Epoch  13:  10% | abe: 4.360 | eve: 9.285 | bob: 5.083Epoch  13:  10% | abe: 4.358 | eve: 9.288 | bob: 5.079Epoch  13:  11% | abe: 4.358 | eve: 9.285 | bob: 5.078Epoch  13:  12% | abe: 4.356 | eve: 9.284 | bob: 5.074Epoch  13:  13% | abe: 4.358 | eve: 9.281 | bob: 5.076Epoch  13:  14% | abe: 4.354 | eve: 9.282 | bob: 5.071Epoch  13:  14% | abe: 4.351 | eve: 9.281 | bob: 5.070Epoch  13:  15% | abe: 4.348 | eve: 9.279 | bob: 5.067Epoch  13:  16% | abe: 4.348 | eve: 9.277 | bob: 5.066Epoch  13:  17% | abe: 4.348 | eve: 9.274 | bob: 5.064Epoch  13:  17% | abe: 4.347 | eve: 9.273 | bob: 5.065Epoch  13:  18% | abe: 4.346 | eve: 9.273 | bob: 5.063Epoch  13:  19% | abe: 4.343 | eve: 9.273 | bob: 5.060Epoch  13:  20% | abe: 4.340 | eve: 9.271 | bob: 5.058Epoch  13:  21% | abe: 4.339 | eve: 9.270 | bob: 5.056Epoch  13:  21% | abe: 4.337 | eve: 9.271 | bob: 5.054Epoch  13:  22% | abe: 4.334 | eve: 9.271 | bob: 5.052Epoch  13:  23% | abe: 4.333 | eve: 9.272 | bob: 5.051Epoch  13:  24% | abe: 4.332 | eve: 9.272 | bob: 5.050Epoch  13:  25% | abe: 4.330 | eve: 9.275 | bob: 5.048Epoch  13:  25% | abe: 4.328 | eve: 9.276 | bob: 5.046Epoch  13:  26% | abe: 4.326 | eve: 9.277 | bob: 5.044Epoch  13:  27% | abe: 4.325 | eve: 9.278 | bob: 5.043Epoch  13:  28% | abe: 4.323 | eve: 9.279 | bob: 5.040Epoch  13:  28% | abe: 4.321 | eve: 9.278 | bob: 5.038Epoch  13:  29% | abe: 4.320 | eve: 9.280 | bob: 5.037Epoch  13:  30% | abe: 4.319 | eve: 9.279 | bob: 5.037Epoch  13:  31% | abe: 4.318 | eve: 9.280 | bob: 5.036Epoch  13:  32% | abe: 4.317 | eve: 9.281 | bob: 5.034Epoch  13:  32% | abe: 4.315 | eve: 9.280 | bob: 5.032Epoch  13:  33% | abe: 4.314 | eve: 9.280 | bob: 5.030Epoch  13:  34% | abe: 4.313 | eve: 9.281 | bob: 5.029Epoch  13:  35% | abe: 4.312 | eve: 9.281 | bob: 5.028Epoch  13:  35% | abe: 4.311 | eve: 9.282 | bob: 5.027Epoch  13:  36% | abe: 4.311 | eve: 9.281 | bob: 5.027Epoch  13:  37% | abe: 4.310 | eve: 9.280 | bob: 5.026Epoch  13:  38% | abe: 4.309 | eve: 9.279 | bob: 5.024Epoch  13:  39% | abe: 4.308 | eve: 9.278 | bob: 5.023Epoch  13:  39% | abe: 4.307 | eve: 9.278 | bob: 5.022Epoch  13:  40% | abe: 4.305 | eve: 9.278 | bob: 5.019Epoch  13:  41% | abe: 4.305 | eve: 9.278 | bob: 5.019Epoch  13:  42% | abe: 4.304 | eve: 9.278 | bob: 5.018Epoch  13:  42% | abe: 4.302 | eve: 9.278 | bob: 5.016Epoch  13:  43% | abe: 4.301 | eve: 9.275 | bob: 5.015Epoch  13:  44% | abe: 4.301 | eve: 9.276 | bob: 5.014Epoch  13:  45% | abe: 4.301 | eve: 9.277 | bob: 5.014Epoch  13:  46% | abe: 4.300 | eve: 9.276 | bob: 5.013Epoch  13:  46% | abe: 4.299 | eve: 9.275 | bob: 5.011Epoch  13:  47% | abe: 4.297 | eve: 9.276 | bob: 5.010Epoch  13:  48% | abe: 4.296 | eve: 9.277 | bob: 5.008Epoch  13:  49% | abe: 4.296 | eve: 9.276 | bob: 5.008Epoch  13:  50% | abe: 4.294 | eve: 9.275 | bob: 5.007Epoch  13:  50% | abe: 4.293 | eve: 9.275 | bob: 5.005Epoch  13:  51% | abe: 4.292 | eve: 9.275 | bob: 5.005Epoch  13:  52% | abe: 4.291 | eve: 9.276 | bob: 5.003Epoch  13:  53% | abe: 4.289 | eve: 9.275 | bob: 5.003Epoch  13:  53% | abe: 4.288 | eve: 9.276 | bob: 5.002Epoch  13:  54% | abe: 4.286 | eve: 9.276 | bob: 5.000Epoch  13:  55% | abe: 4.285 | eve: 9.276 | bob: 5.000Epoch  13:  56% | abe: 4.283 | eve: 9.276 | bob: 4.997Epoch  13:  57% | abe: 4.282 | eve: 9.277 | bob: 4.996Epoch  13:  57% | abe: 4.281 | eve: 9.277 | bob: 4.995Epoch  13:  58% | abe: 4.279 | eve: 9.277 | bob: 4.993Epoch  13:  59% | abe: 4.278 | eve: 9.278 | bob: 4.992Epoch  13:  60% | abe: 4.277 | eve: 9.277 | bob: 4.991Epoch  13:  60% | abe: 4.276 | eve: 9.278 | bob: 4.989Epoch  13:  61% | abe: 4.275 | eve: 9.277 | bob: 4.988Epoch  13:  62% | abe: 4.274 | eve: 9.278 | bob: 4.987Epoch  13:  63% | abe: 4.272 | eve: 9.278 | bob: 4.986Epoch  13:  64% | abe: 4.271 | eve: 9.278 | bob: 4.984Epoch  13:  64% | abe: 4.271 | eve: 9.277 | bob: 4.983Epoch  13:  65% | abe: 4.269 | eve: 9.278 | bob: 4.982Epoch  13:  66% | abe: 4.267 | eve: 9.278 | bob: 4.981Epoch  13:  67% | abe: 4.267 | eve: 9.278 | bob: 4.980Epoch  13:  67% | abe: 4.265 | eve: 9.278 | bob: 4.979Epoch  13:  68% | abe: 4.264 | eve: 9.278 | bob: 4.977Epoch  13:  69% | abe: 4.263 | eve: 9.278 | bob: 4.976Epoch  13:  70% | abe: 4.262 | eve: 9.277 | bob: 4.975Epoch  13:  71% | abe: 4.261 | eve: 9.278 | bob: 4.974Epoch  13:  71% | abe: 4.259 | eve: 9.277 | bob: 4.973Epoch  13:  72% | abe: 4.259 | eve: 9.278 | bob: 4.972Epoch  13:  73% | abe: 4.258 | eve: 9.279 | bob: 4.971Epoch  13:  74% | abe: 4.256 | eve: 9.279 | bob: 4.970Epoch  13:  75% | abe: 4.255 | eve: 9.279 | bob: 4.968Epoch  13:  75% | abe: 4.254 | eve: 9.280 | bob: 4.967Epoch  13:  76% | abe: 4.252 | eve: 9.279 | bob: 4.965Epoch  13:  77% | abe: 4.252 | eve: 9.279 | bob: 4.964Epoch  13:  78% | abe: 4.250 | eve: 9.278 | bob: 4.963Epoch  13:  78% | abe: 4.249 | eve: 9.278 | bob: 4.961Epoch  13:  79% | abe: 4.247 | eve: 9.278 | bob: 4.960Epoch  13:  80% | abe: 4.247 | eve: 9.278 | bob: 4.959Epoch  13:  81% | abe: 4.246 | eve: 9.278 | bob: 4.958Epoch  13:  82% | abe: 4.246 | eve: 9.278 | bob: 4.958Epoch  13:  82% | abe: 4.245 | eve: 9.277 | bob: 4.956Epoch  13:  83% | abe: 4.244 | eve: 9.278 | bob: 4.955Epoch  13:  84% | abe: 4.242 | eve: 9.277 | bob: 4.953Epoch  13:  85% | abe: 4.241 | eve: 9.277 | bob: 4.952Epoch  13:  85% | abe: 4.240 | eve: 9.277 | bob: 4.950Epoch  13:  86% | abe: 4.238 | eve: 9.277 | bob: 4.949Epoch  13:  87% | abe: 4.237 | eve: 9.277 | bob: 4.948Epoch  13:  88% | abe: 4.236 | eve: 9.276 | bob: 4.946Epoch  13:  89% | abe: 4.234 | eve: 9.276 | bob: 4.944Epoch  13:  89% | abe: 4.233 | eve: 9.277 | bob: 4.943Epoch  13:  90% | abe: 4.232 | eve: 9.277 | bob: 4.942Epoch  13:  91% | abe: 4.231 | eve: 9.277 | bob: 4.940Epoch  13:  92% | abe: 4.230 | eve: 9.277 | bob: 4.938Epoch  13:  92% | abe: 4.228 | eve: 9.277 | bob: 4.937Epoch  13:  93% | abe: 4.227 | eve: 9.278 | bob: 4.936Epoch  13:  94% | abe: 4.226 | eve: 9.277 | bob: 4.935Epoch  13:  95% | abe: 4.226 | eve: 9.278 | bob: 4.934Epoch  13:  96% | abe: 4.224 | eve: 9.278 | bob: 4.932Epoch  13:  96% | abe: 4.224 | eve: 9.278 | bob: 4.931Epoch  13:  97% | abe: 4.222 | eve: 9.277 | bob: 4.930Epoch  13:  98% | abe: 4.221 | eve: 9.277 | bob: 4.929Epoch  13:  99% | abe: 4.220 | eve: 9.277 | bob: 4.927
New best Bob loss 4.927425878495114 at epoch 13
Epoch  14:   0% | abe: 4.062 | eve: 9.321 | bob: 4.712Epoch  14:   0% | abe: 4.075 | eve: 9.278 | bob: 4.735Epoch  14:   1% | abe: 4.069 | eve: 9.279 | bob: 4.742Epoch  14:   2% | abe: 4.084 | eve: 9.276 | bob: 4.761Epoch  14:   3% | abe: 4.088 | eve: 9.293 | bob: 4.764Epoch  14:   3% | abe: 4.080 | eve: 9.277 | bob: 4.754Epoch  14:   4% | abe: 4.081 | eve: 9.285 | bob: 4.757Epoch  14:   5% | abe: 4.083 | eve: 9.283 | bob: 4.756Epoch  14:   6% | abe: 4.083 | eve: 9.283 | bob: 4.756Epoch  14:   7% | abe: 4.080 | eve: 9.275 | bob: 4.752Epoch  14:   7% | abe: 4.078 | eve: 9.284 | bob: 4.750Epoch  14:   8% | abe: 4.078 | eve: 9.282 | bob: 4.751Epoch  14:   9% | abe: 4.077 | eve: 9.276 | bob: 4.747Epoch  14:  10% | abe: 4.078 | eve: 9.284 | bob: 4.748Epoch  14:  10% | abe: 4.079 | eve: 9.286 | bob: 4.747Epoch  14:  11% | abe: 4.077 | eve: 9.287 | bob: 4.747Epoch  14:  12% | abe: 4.076 | eve: 9.286 | bob: 4.747Epoch  14:  13% | abe: 4.074 | eve: 9.281 | bob: 4.743Epoch  14:  14% | abe: 4.070 | eve: 9.282 | bob: 4.740Epoch  14:  14% | abe: 4.071 | eve: 9.286 | bob: 4.740Epoch  14:  15% | abe: 4.070 | eve: 9.285 | bob: 4.738Epoch  14:  16% | abe: 4.067 | eve: 9.285 | bob: 4.736Epoch  14:  17% | abe: 4.068 | eve: 9.287 | bob: 4.735Epoch  14:  17% | abe: 4.067 | eve: 9.284 | bob: 4.734Epoch  14:  18% | abe: 4.066 | eve: 9.287 | bob: 4.734Epoch  14:  19% | abe: 4.066 | eve: 9.289 | bob: 4.733Epoch  14:  20% | abe: 4.065 | eve: 9.287 | bob: 4.734Epoch  14:  21% | abe: 4.061 | eve: 9.288 | bob: 4.729Epoch  14:  21% | abe: 4.061 | eve: 9.290 | bob: 4.728Epoch  14:  22% | abe: 4.058 | eve: 9.291 | bob: 4.728Epoch  14:  23% | abe: 4.059 | eve: 9.292 | bob: 4.728Epoch  14:  24% | abe: 4.059 | eve: 9.294 | bob: 4.728Epoch  14:  25% | abe: 4.057 | eve: 9.295 | bob: 4.726Epoch  14:  25% | abe: 4.055 | eve: 9.293 | bob: 4.723Epoch  14:  26% | abe: 4.055 | eve: 9.291 | bob: 4.722Epoch  14:  27% | abe: 4.054 | eve: 9.289 | bob: 4.721Epoch  14:  28% | abe: 4.053 | eve: 9.289 | bob: 4.720Epoch  14:  28% | abe: 4.052 | eve: 9.289 | bob: 4.718Epoch  14:  29% | abe: 4.050 | eve: 9.288 | bob: 4.716Epoch  14:  30% | abe: 4.048 | eve: 9.287 | bob: 4.714Epoch  14:  31% | abe: 4.047 | eve: 9.287 | bob: 4.713Epoch  14:  32% | abe: 4.047 | eve: 9.286 | bob: 4.712Epoch  14:  32% | abe: 4.045 | eve: 9.286 | bob: 4.711Epoch  14:  33% | abe: 4.044 | eve: 9.286 | bob: 4.709Epoch  14:  34% | abe: 4.042 | eve: 9.286 | bob: 4.707Epoch  14:  35% | abe: 4.042 | eve: 9.285 | bob: 4.706Epoch  14:  35% | abe: 4.040 | eve: 9.286 | bob: 4.704Epoch  14:  36% | abe: 4.039 | eve: 9.286 | bob: 4.703Epoch  14:  37% | abe: 4.038 | eve: 9.286 | bob: 4.701Epoch  14:  38% | abe: 4.037 | eve: 9.285 | bob: 4.700Epoch  14:  39% | abe: 4.035 | eve: 9.286 | bob: 4.699Epoch  14:  39% | abe: 4.033 | eve: 9.286 | bob: 4.696Epoch  14:  40% | abe: 4.032 | eve: 9.287 | bob: 4.695Epoch  14:  41% | abe: 4.031 | eve: 9.287 | bob: 4.693Epoch  14:  42% | abe: 4.031 | eve: 9.286 | bob: 4.693Epoch  14:  42% | abe: 4.030 | eve: 9.286 | bob: 4.692Epoch  14:  43% | abe: 4.030 | eve: 9.286 | bob: 4.692Epoch  14:  44% | abe: 4.030 | eve: 9.286 | bob: 4.691Epoch  14:  45% | abe: 4.029 | eve: 9.287 | bob: 4.690Epoch  14:  46% | abe: 4.027 | eve: 9.286 | bob: 4.688Epoch  14:  46% | abe: 4.027 | eve: 9.285 | bob: 4.688Epoch  14:  47% | abe: 4.027 | eve: 9.285 | bob: 4.687Epoch  14:  48% | abe: 4.025 | eve: 9.286 | bob: 4.685Epoch  14:  49% | abe: 4.024 | eve: 9.286 | bob: 4.684Epoch  14:  50% | abe: 4.023 | eve: 9.286 | bob: 4.683Epoch  14:  50% | abe: 4.023 | eve: 9.286 | bob: 4.682Epoch  14:  51% | abe: 4.023 | eve: 9.287 | bob: 4.682Epoch  14:  52% | abe: 4.022 | eve: 9.286 | bob: 4.681Epoch  14:  53% | abe: 4.021 | eve: 9.284 | bob: 4.679Epoch  14:  53% | abe: 4.019 | eve: 9.285 | bob: 4.677Epoch  14:  54% | abe: 4.017 | eve: 9.285 | bob: 4.675Epoch  14:  55% | abe: 4.016 | eve: 9.285 | bob: 4.674Epoch  14:  56% | abe: 4.015 | eve: 9.284 | bob: 4.673Epoch  14:  57% | abe: 4.014 | eve: 9.284 | bob: 4.671Epoch  14:  57% | abe: 4.013 | eve: 9.284 | bob: 4.670Epoch  14:  58% | abe: 4.012 | eve: 9.284 | bob: 4.668Epoch  14:  59% | abe: 4.010 | eve: 9.284 | bob: 4.667Epoch  14:  60% | abe: 4.010 | eve: 9.285 | bob: 4.666Epoch  14:  60% | abe: 4.009 | eve: 9.284 | bob: 4.665Epoch  14:  61% | abe: 4.008 | eve: 9.284 | bob: 4.664Epoch  14:  62% | abe: 4.008 | eve: 9.283 | bob: 4.663Epoch  14:  63% | abe: 4.007 | eve: 9.283 | bob: 4.662Epoch  14:  64% | abe: 4.006 | eve: 9.283 | bob: 4.661Epoch  14:  64% | abe: 4.005 | eve: 9.282 | bob: 4.660Epoch  14:  65% | abe: 4.005 | eve: 9.283 | bob: 4.659Epoch  14:  66% | abe: 4.004 | eve: 9.282 | bob: 4.658Epoch  14:  67% | abe: 4.003 | eve: 9.283 | bob: 4.656Epoch  14:  67% | abe: 4.002 | eve: 9.283 | bob: 4.655Epoch  14:  68% | abe: 4.001 | eve: 9.283 | bob: 4.653Epoch  14:  69% | abe: 4.000 | eve: 9.282 | bob: 4.652Epoch  14:  70% | abe: 4.000 | eve: 9.283 | bob: 4.651Epoch  14:  71% | abe: 3.999 | eve: 9.282 | bob: 4.650Epoch  14:  71% | abe: 3.999 | eve: 9.283 | bob: 4.649Epoch  14:  72% | abe: 3.998 | eve: 9.283 | bob: 4.648Epoch  14:  73% | abe: 3.998 | eve: 9.282 | bob: 4.647Epoch  14:  74% | abe: 3.998 | eve: 9.283 | bob: 4.646Epoch  14:  75% | abe: 3.997 | eve: 9.283 | bob: 4.646Epoch  14:  75% | abe: 3.997 | eve: 9.283 | bob: 4.645Epoch  14:  76% | abe: 3.996 | eve: 9.283 | bob: 4.644Epoch  14:  77% | abe: 3.996 | eve: 9.283 | bob: 4.643Epoch  14:  78% | abe: 3.996 | eve: 9.283 | bob: 4.643Epoch  14:  78% | abe: 3.995 | eve: 9.283 | bob: 4.642Epoch  14:  79% | abe: 3.994 | eve: 9.282 | bob: 4.641Epoch  14:  80% | abe: 3.993 | eve: 9.282 | bob: 4.639Epoch  14:  81% | abe: 3.991 | eve: 9.282 | bob: 4.638Epoch  14:  82% | abe: 3.990 | eve: 9.283 | bob: 4.637Epoch  14:  82% | abe: 3.990 | eve: 9.282 | bob: 4.636Epoch  14:  83% | abe: 3.989 | eve: 9.282 | bob: 4.635Epoch  14:  84% | abe: 3.988 | eve: 9.282 | bob: 4.634Epoch  14:  85% | abe: 3.987 | eve: 9.282 | bob: 4.633Epoch  14:  85% | abe: 3.986 | eve: 9.281 | bob: 4.632Epoch  14:  86% | abe: 3.986 | eve: 9.281 | bob: 4.631Epoch  14:  87% | abe: 3.985 | eve: 9.281 | bob: 4.630Epoch  14:  88% | abe: 3.984 | eve: 9.281 | bob: 4.629Epoch  14:  89% | abe: 3.984 | eve: 9.281 | bob: 4.628Epoch  14:  89% | abe: 3.982 | eve: 9.281 | bob: 4.627Epoch  14:  90% | abe: 3.981 | eve: 9.281 | bob: 4.625Epoch  14:  91% | abe: 3.981 | eve: 9.282 | bob: 4.624Epoch  14:  92% | abe: 3.980 | eve: 9.281 | bob: 4.623Epoch  14:  92% | abe: 3.979 | eve: 9.281 | bob: 4.621Epoch  14:  93% | abe: 3.978 | eve: 9.280 | bob: 4.620Epoch  14:  94% | abe: 3.976 | eve: 9.280 | bob: 4.618Epoch  14:  95% | abe: 3.975 | eve: 9.280 | bob: 4.617Epoch  14:  96% | abe: 3.975 | eve: 9.280 | bob: 4.616Epoch  14:  96% | abe: 3.974 | eve: 9.280 | bob: 4.615Epoch  14:  97% | abe: 3.974 | eve: 9.280 | bob: 4.614Epoch  14:  98% | abe: 3.973 | eve: 9.280 | bob: 4.613Epoch  14:  99% | abe: 3.973 | eve: 9.280 | bob: 4.612
New best Bob loss 4.612338087321632 at epoch 14
Epoch  15:   0% | abe: 3.901 | eve: 9.250 | bob: 4.460Epoch  15:   0% | abe: 3.891 | eve: 9.256 | bob: 4.485Epoch  15:   1% | abe: 3.888 | eve: 9.266 | bob: 4.478Epoch  15:   2% | abe: 3.874 | eve: 9.263 | bob: 4.458Epoch  15:   3% | abe: 3.870 | eve: 9.272 | bob: 4.451Epoch  15:   3% | abe: 3.862 | eve: 9.274 | bob: 4.448Epoch  15:   4% | abe: 3.861 | eve: 9.283 | bob: 4.445Epoch  15:   5% | abe: 3.856 | eve: 9.281 | bob: 4.446Epoch  15:   6% | abe: 3.855 | eve: 9.290 | bob: 4.446Epoch  15:   7% | abe: 3.848 | eve: 9.294 | bob: 4.441Epoch  15:   7% | abe: 3.843 | eve: 9.285 | bob: 4.437Epoch  15:   8% | abe: 3.841 | eve: 9.287 | bob: 4.436Epoch  15:   9% | abe: 3.843 | eve: 9.284 | bob: 4.436Epoch  15:  10% | abe: 3.847 | eve: 9.283 | bob: 4.439Epoch  15:  10% | abe: 3.851 | eve: 9.281 | bob: 4.441Epoch  15:  11% | abe: 3.852 | eve: 9.282 | bob: 4.444Epoch  15:  12% | abe: 3.853 | eve: 9.281 | bob: 4.444Epoch  15:  13% | abe: 3.850 | eve: 9.283 | bob: 4.442Epoch  15:  14% | abe: 3.853 | eve: 9.284 | bob: 4.446Epoch  15:  14% | abe: 3.852 | eve: 9.285 | bob: 4.447Epoch  15:  15% | abe: 3.852 | eve: 9.286 | bob: 4.446Epoch  15:  16% | abe: 3.849 | eve: 9.286 | bob: 4.445Epoch  15:  17% | abe: 3.848 | eve: 9.281 | bob: 4.442Epoch  15:  17% | abe: 3.846 | eve: 9.280 | bob: 4.442Epoch  15:  18% | abe: 3.844 | eve: 9.277 | bob: 4.439Epoch  15:  19% | abe: 3.844 | eve: 9.275 | bob: 4.439Epoch  15:  20% | abe: 3.840 | eve: 9.277 | bob: 4.435Epoch  15:  21% | abe: 3.839 | eve: 9.278 | bob: 4.434Epoch  15:  21% | abe: 3.841 | eve: 9.280 | bob: 4.436Epoch  15:  22% | abe: 3.840 | eve: 9.277 | bob: 4.434Epoch  15:  23% | abe: 3.839 | eve: 9.277 | bob: 4.434Epoch  15:  24% | abe: 3.839 | eve: 9.277 | bob: 4.434Epoch  15:  25% | abe: 3.837 | eve: 9.278 | bob: 4.431Epoch  15:  25% | abe: 3.839 | eve: 9.281 | bob: 4.434Epoch  15:  26% | abe: 3.838 | eve: 9.281 | bob: 4.432Epoch  15:  27% | abe: 3.838 | eve: 9.280 | bob: 4.432Epoch  15:  28% | abe: 3.836 | eve: 9.279 | bob: 4.430Epoch  15:  28% | abe: 3.838 | eve: 9.278 | bob: 4.431Epoch  15:  29% | abe: 3.838 | eve: 9.278 | bob: 4.431Epoch  15:  30% | abe: 3.837 | eve: 9.278 | bob: 4.429Epoch  15:  31% | abe: 3.837 | eve: 9.278 | bob: 4.429Epoch  15:  32% | abe: 3.836 | eve: 9.277 | bob: 4.428Epoch  15:  32% | abe: 3.835 | eve: 9.278 | bob: 4.427Epoch  15:  33% | abe: 3.834 | eve: 9.279 | bob: 4.426Epoch  15:  34% | abe: 3.834 | eve: 9.278 | bob: 4.426Epoch  15:  35% | abe: 3.834 | eve: 9.279 | bob: 4.426Epoch  15:  35% | abe: 3.831 | eve: 9.277 | bob: 4.424Epoch  15:  36% | abe: 3.832 | eve: 9.277 | bob: 4.425Epoch  15:  37% | abe: 3.832 | eve: 9.277 | bob: 4.424Epoch  15:  38% | abe: 3.833 | eve: 9.278 | bob: 4.425Epoch  15:  39% | abe: 3.832 | eve: 9.278 | bob: 4.424Epoch  15:  39% | abe: 3.833 | eve: 9.278 | bob: 4.425Epoch  15:  40% | abe: 3.832 | eve: 9.277 | bob: 4.423Epoch  15:  41% | abe: 3.832 | eve: 9.278 | bob: 4.423Epoch  15:  42% | abe: 3.832 | eve: 9.278 | bob: 4.422Epoch  15:  42% | abe: 3.830 | eve: 9.277 | bob: 4.421Epoch  15:  43% | abe: 3.830 | eve: 9.277 | bob: 4.421Epoch  15:  44% | abe: 3.830 | eve: 9.278 | bob: 4.420Epoch  15:  45% | abe: 3.828 | eve: 9.278 | bob: 4.418Epoch  15:  46% | abe: 3.828 | eve: 9.278 | bob: 4.417Epoch  15:  46% | abe: 3.828 | eve: 9.277 | bob: 4.417Epoch  15:  47% | abe: 3.829 | eve: 9.279 | bob: 4.417Epoch  15:  48% | abe: 3.828 | eve: 9.278 | bob: 4.416Epoch  15:  49% | abe: 3.828 | eve: 9.278 | bob: 4.415Epoch  15:  50% | abe: 3.828 | eve: 9.279 | bob: 4.415Epoch  15:  50% | abe: 3.827 | eve: 9.280 | bob: 4.413Epoch  15:  51% | abe: 3.826 | eve: 9.280 | bob: 4.412Epoch  15:  52% | abe: 3.824 | eve: 9.280 | bob: 4.410Epoch  15:  53% | abe: 3.824 | eve: 9.281 | bob: 4.410Epoch  15:  53% | abe: 3.824 | eve: 9.281 | bob: 4.410Epoch  15:  54% | abe: 3.823 | eve: 9.279 | bob: 4.409Epoch  15:  55% | abe: 3.824 | eve: 9.277 | bob: 4.409Epoch  15:  56% | abe: 3.824 | eve: 9.278 | bob: 4.409Epoch  15:  57% | abe: 3.823 | eve: 9.279 | bob: 4.408Epoch  15:  57% | abe: 3.823 | eve: 9.278 | bob: 4.408Epoch  15:  58% | abe: 3.823 | eve: 9.278 | bob: 4.407Epoch  15:  59% | abe: 3.823 | eve: 9.278 | bob: 4.407Epoch  15:  60% | abe: 3.823 | eve: 9.277 | bob: 4.406Epoch  15:  60% | abe: 3.822 | eve: 9.276 | bob: 4.406Epoch  15:  61% | abe: 3.821 | eve: 9.276 | bob: 4.405Epoch  15:  62% | abe: 3.821 | eve: 9.276 | bob: 4.404Epoch  15:  63% | abe: 3.821 | eve: 9.277 | bob: 4.404Epoch  15:  64% | abe: 3.820 | eve: 9.277 | bob: 4.403Epoch  15:  64% | abe: 3.820 | eve: 9.276 | bob: 4.402Epoch  15:  65% | abe: 3.819 | eve: 9.276 | bob: 4.402Epoch  15:  66% | abe: 3.818 | eve: 9.276 | bob: 4.400Epoch  15:  67% | abe: 3.819 | eve: 9.276 | bob: 4.400Epoch  15:  67% | abe: 3.818 | eve: 9.275 | bob: 4.400Epoch  15:  68% | abe: 3.817 | eve: 9.275 | bob: 4.398Epoch  15:  69% | abe: 3.816 | eve: 9.275 | bob: 4.397Epoch  15:  70% | abe: 3.816 | eve: 9.275 | bob: 4.397Epoch  15:  71% | abe: 3.816 | eve: 9.275 | bob: 4.396Epoch  15:  71% | abe: 3.815 | eve: 9.275 | bob: 4.395Epoch  15:  72% | abe: 3.815 | eve: 9.275 | bob: 4.394Epoch  15:  73% | abe: 3.814 | eve: 9.275 | bob: 4.393Epoch  15:  74% | abe: 3.814 | eve: 9.275 | bob: 4.393Epoch  15:  75% | abe: 3.813 | eve: 9.275 | bob: 4.392Epoch  15:  75% | abe: 3.812 | eve: 9.276 | bob: 4.392Epoch  15:  76% | abe: 3.812 | eve: 9.277 | bob: 4.391Epoch  15:  77% | abe: 3.812 | eve: 9.277 | bob: 4.390Epoch  15:  78% | abe: 3.811 | eve: 9.277 | bob: 4.389Epoch  15:  78% | abe: 3.810 | eve: 9.277 | bob: 4.388Epoch  15:  79% | abe: 3.810 | eve: 9.277 | bob: 4.387Epoch  15:  80% | abe: 3.809 | eve: 9.278 | bob: 4.386Epoch  15:  81% | abe: 3.809 | eve: 9.278 | bob: 4.385Epoch  15:  82% | abe: 3.808 | eve: 9.279 | bob: 4.384Epoch  15:  82% | abe: 3.808 | eve: 9.279 | bob: 4.384Epoch  15:  83% | abe: 3.807 | eve: 9.279 | bob: 4.383Epoch  15:  84% | abe: 3.806 | eve: 9.279 | bob: 4.382Epoch  15:  85% | abe: 3.806 | eve: 9.278 | bob: 4.382Epoch  15:  85% | abe: 3.805 | eve: 9.278 | bob: 4.381Epoch  15:  86% | abe: 3.804 | eve: 9.278 | bob: 4.380Epoch  15:  87% | abe: 3.804 | eve: 9.278 | bob: 4.379Epoch  15:  88% | abe: 3.803 | eve: 9.277 | bob: 4.378Epoch  15:  89% | abe: 3.803 | eve: 9.277 | bob: 4.378Epoch  15:  89% | abe: 3.802 | eve: 9.277 | bob: 4.377Epoch  15:  90% | abe: 3.802 | eve: 9.276 | bob: 4.376Epoch  15:  91% | abe: 3.801 | eve: 9.275 | bob: 4.376Epoch  15:  92% | abe: 3.801 | eve: 9.275 | bob: 4.375Epoch  15:  92% | abe: 3.801 | eve: 9.276 | bob: 4.374Epoch  15:  93% | abe: 3.801 | eve: 9.276 | bob: 4.374Epoch  15:  94% | abe: 3.801 | eve: 9.277 | bob: 4.373Epoch  15:  95% | abe: 3.800 | eve: 9.276 | bob: 4.373Epoch  15:  96% | abe: 3.800 | eve: 9.276 | bob: 4.372Epoch  15:  96% | abe: 3.799 | eve: 9.276 | bob: 4.371Epoch  15:  97% | abe: 3.799 | eve: 9.275 | bob: 4.371Epoch  15:  98% | abe: 3.798 | eve: 9.276 | bob: 4.370Epoch  15:  99% | abe: 3.798 | eve: 9.275 | bob: 4.370
New best Bob loss 4.369698376565111 at epoch 15
Epoch  16:   0% | abe: 3.741 | eve: 9.265 | bob: 4.259Epoch  16:   0% | abe: 3.754 | eve: 9.273 | bob: 4.293Epoch  16:   1% | abe: 3.780 | eve: 9.279 | bob: 4.308Epoch  16:   2% | abe: 3.758 | eve: 9.278 | bob: 4.299Epoch  16:   3% | abe: 3.761 | eve: 9.285 | bob: 4.293Epoch  16:   3% | abe: 3.751 | eve: 9.277 | bob: 4.288Epoch  16:   4% | abe: 3.750 | eve: 9.291 | bob: 4.288Epoch  16:   5% | abe: 3.748 | eve: 9.286 | bob: 4.287Epoch  16:   6% | abe: 3.741 | eve: 9.290 | bob: 4.280Epoch  16:   7% | abe: 3.737 | eve: 9.290 | bob: 4.274Epoch  16:   7% | abe: 3.735 | eve: 9.285 | bob: 4.274Epoch  16:   8% | abe: 3.737 | eve: 9.283 | bob: 4.274Epoch  16:   9% | abe: 3.737 | eve: 9.281 | bob: 4.274Epoch  16:  10% | abe: 3.734 | eve: 9.281 | bob: 4.272Epoch  16:  10% | abe: 3.733 | eve: 9.285 | bob: 4.272Epoch  16:  11% | abe: 3.730 | eve: 9.290 | bob: 4.268Epoch  16:  12% | abe: 3.732 | eve: 9.289 | bob: 4.270Epoch  16:  13% | abe: 3.730 | eve: 9.289 | bob: 4.270Epoch  16:  14% | abe: 3.731 | eve: 9.291 | bob: 4.270Epoch  16:  14% | abe: 3.728 | eve: 9.288 | bob: 4.267Epoch  16:  15% | abe: 3.727 | eve: 9.285 | bob: 4.267Epoch  16:  16% | abe: 3.726 | eve: 9.286 | bob: 4.267Epoch  16:  17% | abe: 3.728 | eve: 9.282 | bob: 4.269Epoch  16:  17% | abe: 3.727 | eve: 9.284 | bob: 4.267Epoch  16:  18% | abe: 3.723 | eve: 9.285 | bob: 4.265Epoch  16:  19% | abe: 3.724 | eve: 9.287 | bob: 4.264Epoch  16:  20% | abe: 3.724 | eve: 9.286 | bob: 4.264Epoch  16:  21% | abe: 3.723 | eve: 9.283 | bob: 4.265Epoch  16:  21% | abe: 3.723 | eve: 9.285 | bob: 4.264Epoch  16:  22% | abe: 3.724 | eve: 9.284 | bob: 4.264Epoch  16:  23% | abe: 3.722 | eve: 9.285 | bob: 4.262Epoch  16:  24% | abe: 3.723 | eve: 9.285 | bob: 4.263Epoch  16:  25% | abe: 3.721 | eve: 9.286 | bob: 4.261Epoch  16:  25% | abe: 3.721 | eve: 9.286 | bob: 4.260Epoch  16:  26% | abe: 3.721 | eve: 9.285 | bob: 4.260Epoch  16:  27% | abe: 3.720 | eve: 9.285 | bob: 4.259Epoch  16:  28% | abe: 3.719 | eve: 9.285 | bob: 4.259Epoch  16:  28% | abe: 3.717 | eve: 9.285 | bob: 4.257Epoch  16:  29% | abe: 3.718 | eve: 9.283 | bob: 4.258Epoch  16:  30% | abe: 3.719 | eve: 9.283 | bob: 4.258Epoch  16:  31% | abe: 3.719 | eve: 9.282 | bob: 4.258Epoch  16:  32% | abe: 3.719 | eve: 9.282 | bob: 4.258Epoch  16:  32% | abe: 3.719 | eve: 9.281 | bob: 4.258Epoch  16:  33% | abe: 3.720 | eve: 9.280 | bob: 4.259Epoch  16:  34% | abe: 3.720 | eve: 9.281 | bob: 4.259Epoch  16:  35% | abe: 3.719 | eve: 9.279 | bob: 4.257Epoch  16:  35% | abe: 3.718 | eve: 9.278 | bob: 4.256Epoch  16:  36% | abe: 3.718 | eve: 9.278 | bob: 4.257Epoch  16:  37% | abe: 3.717 | eve: 9.278 | bob: 4.256Epoch  16:  38% | abe: 3.716 | eve: 9.276 | bob: 4.256Epoch  16:  39% | abe: 3.717 | eve: 9.277 | bob: 4.256Epoch  16:  39% | abe: 3.716 | eve: 9.277 | bob: 4.255Epoch  16:  40% | abe: 3.715 | eve: 9.278 | bob: 4.254Epoch  16:  41% | abe: 3.715 | eve: 9.278 | bob: 4.253Epoch  16:  42% | abe: 3.714 | eve: 9.278 | bob: 4.253Epoch  16:  42% | abe: 3.713 | eve: 9.278 | bob: 4.252Epoch  16:  43% | abe: 3.712 | eve: 9.277 | bob: 4.251Epoch  16:  44% | abe: 3.711 | eve: 9.278 | bob: 4.251Epoch  16:  45% | abe: 3.710 | eve: 9.278 | bob: 4.249Epoch  16:  46% | abe: 3.709 | eve: 9.277 | bob: 4.249Epoch  16:  46% | abe: 3.708 | eve: 9.277 | bob: 4.248Epoch  16:  47% | abe: 3.708 | eve: 9.277 | bob: 4.247Epoch  16:  48% | abe: 3.708 | eve: 9.276 | bob: 4.247Epoch  16:  49% | abe: 3.708 | eve: 9.276 | bob: 4.247Epoch  16:  50% | abe: 3.706 | eve: 9.275 | bob: 4.245Epoch  16:  50% | abe: 3.707 | eve: 9.274 | bob: 4.246Epoch  16:  51% | abe: 3.706 | eve: 9.273 | bob: 4.245Epoch  16:  52% | abe: 3.705 | eve: 9.274 | bob: 4.244Epoch  16:  53% | abe: 3.706 | eve: 9.273 | bob: 4.244Epoch  16:  53% | abe: 3.705 | eve: 9.273 | bob: 4.243Epoch  16:  54% | abe: 3.705 | eve: 9.274 | bob: 4.243Epoch  16:  55% | abe: 3.704 | eve: 9.273 | bob: 4.242Epoch  16:  56% | abe: 3.704 | eve: 9.274 | bob: 4.242Epoch  16:  57% | abe: 3.704 | eve: 9.274 | bob: 4.243Epoch  16:  57% | abe: 3.703 | eve: 9.275 | bob: 4.241Epoch  16:  58% | abe: 3.703 | eve: 9.275 | bob: 4.241Epoch  16:  59% | abe: 3.703 | eve: 9.274 | bob: 4.240Epoch  16:  60% | abe: 3.703 | eve: 9.275 | bob: 4.240Epoch  16:  60% | abe: 3.702 | eve: 9.276 | bob: 4.239Epoch  16:  61% | abe: 3.702 | eve: 9.276 | bob: 4.239Epoch  16:  62% | abe: 3.700 | eve: 9.277 | bob: 4.237Epoch  16:  63% | abe: 3.700 | eve: 9.276 | bob: 4.237Epoch  16:  64% | abe: 3.699 | eve: 9.277 | bob: 4.236Epoch  16:  64% | abe: 3.699 | eve: 9.276 | bob: 4.235Epoch  16:  65% | abe: 3.698 | eve: 9.276 | bob: 4.234Epoch  16:  66% | abe: 3.697 | eve: 9.275 | bob: 4.233Epoch  16:  67% | abe: 3.697 | eve: 9.275 | bob: 4.233Epoch  16:  67% | abe: 3.696 | eve: 9.275 | bob: 4.232Epoch  16:  68% | abe: 3.695 | eve: 9.275 | bob: 4.232Epoch  16:  69% | abe: 3.695 | eve: 9.275 | bob: 4.231Epoch  16:  70% | abe: 3.695 | eve: 9.276 | bob: 4.231Epoch  16:  71% | abe: 3.694 | eve: 9.276 | bob: 4.231Epoch  16:  71% | abe: 3.693 | eve: 9.275 | bob: 4.230Epoch  16:  72% | abe: 3.693 | eve: 9.276 | bob: 4.229Epoch  16:  73% | abe: 3.693 | eve: 9.276 | bob: 4.230Epoch  16:  74% | abe: 3.693 | eve: 9.277 | bob: 4.230Epoch  16:  75% | abe: 3.693 | eve: 9.278 | bob: 4.229Epoch  16:  75% | abe: 3.692 | eve: 9.278 | bob: 4.229Epoch  16:  76% | abe: 3.692 | eve: 9.278 | bob: 4.229Epoch  16:  77% | abe: 3.693 | eve: 9.279 | bob: 4.230Epoch  16:  78% | abe: 3.692 | eve: 9.279 | bob: 4.229Epoch  16:  78% | abe: 3.692 | eve: 9.279 | bob: 4.228Epoch  16:  79% | abe: 3.691 | eve: 9.279 | bob: 4.227Epoch  16:  80% | abe: 3.691 | eve: 9.279 | bob: 4.227Epoch  16:  81% | abe: 3.691 | eve: 9.279 | bob: 4.226Epoch  16:  82% | abe: 3.691 | eve: 9.279 | bob: 4.226Epoch  16:  82% | abe: 3.690 | eve: 9.279 | bob: 4.226Epoch  16:  83% | abe: 3.690 | eve: 9.278 | bob: 4.225Epoch  16:  84% | abe: 3.690 | eve: 9.278 | bob: 4.224Epoch  16:  85% | abe: 3.689 | eve: 9.278 | bob: 4.224Epoch  16:  85% | abe: 3.689 | eve: 9.278 | bob: 4.224Epoch  16:  86% | abe: 3.689 | eve: 9.278 | bob: 4.223Epoch  16:  87% | abe: 3.688 | eve: 9.278 | bob: 4.223Epoch  16:  88% | abe: 3.688 | eve: 9.279 | bob: 4.222Epoch  16:  89% | abe: 3.688 | eve: 9.279 | bob: 4.222Epoch  16:  89% | abe: 3.689 | eve: 9.278 | bob: 4.222Epoch  16:  90% | abe: 3.689 | eve: 9.278 | bob: 4.222Epoch  16:  91% | abe: 3.688 | eve: 9.278 | bob: 4.222Epoch  16:  92% | abe: 3.688 | eve: 9.279 | bob: 4.221Epoch  16:  92% | abe: 3.688 | eve: 9.279 | bob: 4.220Epoch  16:  93% | abe: 3.687 | eve: 9.280 | bob: 4.220Epoch  16:  94% | abe: 3.686 | eve: 9.280 | bob: 4.219Epoch  16:  95% | abe: 3.686 | eve: 9.280 | bob: 4.219Epoch  16:  96% | abe: 3.686 | eve: 9.279 | bob: 4.218Epoch  16:  96% | abe: 3.685 | eve: 9.279 | bob: 4.217Epoch  16:  97% | abe: 3.685 | eve: 9.279 | bob: 4.217Epoch  16:  98% | abe: 3.685 | eve: 9.280 | bob: 4.216Epoch  16:  99% | abe: 3.684 | eve: 9.280 | bob: 4.216
New best Bob loss 4.216166288381373 at epoch 16
Epoch  17:   0% | abe: 3.622 | eve: 9.240 | bob: 4.157Epoch  17:   0% | abe: 3.655 | eve: 9.255 | bob: 4.180Epoch  17:   1% | abe: 3.660 | eve: 9.249 | bob: 4.179Epoch  17:   2% | abe: 3.637 | eve: 9.266 | bob: 4.160Epoch  17:   3% | abe: 3.640 | eve: 9.277 | bob: 4.157Epoch  17:   3% | abe: 3.643 | eve: 9.272 | bob: 4.158Epoch  17:   4% | abe: 3.641 | eve: 9.271 | bob: 4.157Epoch  17:   5% | abe: 3.632 | eve: 9.274 | bob: 4.151Epoch  17:   6% | abe: 3.631 | eve: 9.279 | bob: 4.152Epoch  17:   7% | abe: 3.627 | eve: 9.280 | bob: 4.146Epoch  17:   7% | abe: 3.622 | eve: 9.278 | bob: 4.143Epoch  17:   8% | abe: 3.624 | eve: 9.275 | bob: 4.145Epoch  17:   9% | abe: 3.627 | eve: 9.283 | bob: 4.149Epoch  17:  10% | abe: 3.624 | eve: 9.279 | bob: 4.144Epoch  17:  10% | abe: 3.620 | eve: 9.282 | bob: 4.141Epoch  17:  11% | abe: 3.621 | eve: 9.279 | bob: 4.143Epoch  17:  12% | abe: 3.624 | eve: 9.281 | bob: 4.143Epoch  17:  13% | abe: 3.625 | eve: 9.279 | bob: 4.145Epoch  17:  14% | abe: 3.628 | eve: 9.283 | bob: 4.147Epoch  17:  14% | abe: 3.628 | eve: 9.281 | bob: 4.148Epoch  17:  15% | abe: 3.629 | eve: 9.280 | bob: 4.146Epoch  17:  16% | abe: 3.630 | eve: 9.280 | bob: 4.147Epoch  17:  17% | abe: 3.628 | eve: 9.280 | bob: 4.145Epoch  17:  17% | abe: 3.629 | eve: 9.280 | bob: 4.145Epoch  17:  18% | abe: 3.627 | eve: 9.278 | bob: 4.143Epoch  17:  19% | abe: 3.626 | eve: 9.278 | bob: 4.143Epoch  17:  20% | abe: 3.627 | eve: 9.279 | bob: 4.144Epoch  17:  21% | abe: 3.626 | eve: 9.280 | bob: 4.143Epoch  17:  21% | abe: 3.625 | eve: 9.278 | bob: 4.141Epoch  17:  22% | abe: 3.627 | eve: 9.278 | bob: 4.143Epoch  17:  23% | abe: 3.629 | eve: 9.279 | bob: 4.144Epoch  17:  24% | abe: 3.628 | eve: 9.281 | bob: 4.143Epoch  17:  25% | abe: 3.629 | eve: 9.282 | bob: 4.142Epoch  17:  25% | abe: 3.629 | eve: 9.284 | bob: 4.143Epoch  17:  26% | abe: 3.628 | eve: 9.283 | bob: 4.142Epoch  17:  27% | abe: 3.626 | eve: 9.283 | bob: 4.140Epoch  17:  28% | abe: 3.626 | eve: 9.284 | bob: 4.141Epoch  17:  28% | abe: 3.626 | eve: 9.283 | bob: 4.140Epoch  17:  29% | abe: 3.624 | eve: 9.281 | bob: 4.139Epoch  17:  30% | abe: 3.623 | eve: 9.281 | bob: 4.138Epoch  17:  31% | abe: 3.622 | eve: 9.280 | bob: 4.136Epoch  17:  32% | abe: 3.622 | eve: 9.281 | bob: 4.137Epoch  17:  32% | abe: 3.620 | eve: 9.281 | bob: 4.135Epoch  17:  33% | abe: 3.619 | eve: 9.281 | bob: 4.134Epoch  17:  34% | abe: 3.619 | eve: 9.281 | bob: 4.134Epoch  17:  35% | abe: 3.619 | eve: 9.282 | bob: 4.133Epoch  17:  35% | abe: 3.618 | eve: 9.282 | bob: 4.133Epoch  17:  36% | abe: 3.617 | eve: 9.281 | bob: 4.132Epoch  17:  37% | abe: 3.617 | eve: 9.280 | bob: 4.132Epoch  17:  38% | abe: 3.616 | eve: 9.281 | bob: 4.131Epoch  17:  39% | abe: 3.615 | eve: 9.281 | bob: 4.130Epoch  17:  39% | abe: 3.615 | eve: 9.280 | bob: 4.130Epoch  17:  40% | abe: 3.616 | eve: 9.281 | bob: 4.130Epoch  17:  41% | abe: 3.615 | eve: 9.281 | bob: 4.130Epoch  17:  42% | abe: 3.615 | eve: 9.281 | bob: 4.129Epoch  17:  42% | abe: 3.614 | eve: 9.282 | bob: 4.128Epoch  17:  43% | abe: 3.615 | eve: 9.282 | bob: 4.129Epoch  17:  44% | abe: 3.614 | eve: 9.282 | bob: 4.128Epoch  17:  45% | abe: 3.614 | eve: 9.281 | bob: 4.128Epoch  17:  46% | abe: 3.613 | eve: 9.282 | bob: 4.126Epoch  17:  46% | abe: 3.613 | eve: 9.282 | bob: 4.126Epoch  17:  47% | abe: 3.613 | eve: 9.282 | bob: 4.126Epoch  17:  48% | abe: 3.613 | eve: 9.282 | bob: 4.126Epoch  17:  49% | abe: 3.613 | eve: 9.283 | bob: 4.126Epoch  17:  50% | abe: 3.613 | eve: 9.282 | bob: 4.126Epoch  17:  50% | abe: 3.613 | eve: 9.281 | bob: 4.126Epoch  17:  51% | abe: 3.613 | eve: 9.281 | bob: 4.126Epoch  17:  52% | abe: 3.612 | eve: 9.281 | bob: 4.125Epoch  17:  53% | abe: 3.612 | eve: 9.280 | bob: 4.125Epoch  17:  53% | abe: 3.611 | eve: 9.280 | bob: 4.124Epoch  17:  54% | abe: 3.611 | eve: 9.279 | bob: 4.123Epoch  17:  55% | abe: 3.610 | eve: 9.279 | bob: 4.123Epoch  17:  56% | abe: 3.610 | eve: 9.279 | bob: 4.122Epoch  17:  57% | abe: 3.609 | eve: 9.278 | bob: 4.121Epoch  17:  57% | abe: 3.609 | eve: 9.279 | bob: 4.121Epoch  17:  58% | abe: 3.609 | eve: 9.279 | bob: 4.121Epoch  17:  59% | abe: 3.608 | eve: 9.279 | bob: 4.120Epoch  17:  60% | abe: 3.608 | eve: 9.279 | bob: 4.120Epoch  17:  60% | abe: 3.607 | eve: 9.279 | bob: 4.120Epoch  17:  61% | abe: 3.607 | eve: 9.279 | bob: 4.119Epoch  17:  62% | abe: 3.606 | eve: 9.279 | bob: 4.118Epoch  17:  63% | abe: 3.606 | eve: 9.280 | bob: 4.118Epoch  17:  64% | abe: 3.605 | eve: 9.280 | bob: 4.118Epoch  17:  64% | abe: 3.605 | eve: 9.281 | bob: 4.117Epoch  17:  65% | abe: 3.604 | eve: 9.280 | bob: 4.117Epoch  17:  66% | abe: 3.604 | eve: 9.280 | bob: 4.117Epoch  17:  67% | abe: 3.604 | eve: 9.278 | bob: 4.117Epoch  17:  67% | abe: 3.605 | eve: 9.278 | bob: 4.117Epoch  17:  68% | abe: 3.604 | eve: 9.278 | bob: 4.117Epoch  17:  69% | abe: 3.604 | eve: 9.278 | bob: 4.116Epoch  17:  70% | abe: 3.604 | eve: 9.278 | bob: 4.117Epoch  17:  71% | abe: 3.603 | eve: 9.279 | bob: 4.116Epoch  17:  71% | abe: 3.603 | eve: 9.278 | bob: 4.115Epoch  17:  72% | abe: 3.603 | eve: 9.278 | bob: 4.115Epoch  17:  73% | abe: 3.602 | eve: 9.278 | bob: 4.114Epoch  17:  74% | abe: 3.601 | eve: 9.277 | bob: 4.113Epoch  17:  75% | abe: 3.600 | eve: 9.278 | bob: 4.112Epoch  17:  75% | abe: 3.600 | eve: 9.277 | bob: 4.111Epoch  17:  76% | abe: 3.600 | eve: 9.278 | bob: 4.111Epoch  17:  77% | abe: 3.599 | eve: 9.278 | bob: 4.111Epoch  17:  78% | abe: 3.599 | eve: 9.277 | bob: 4.111Epoch  17:  78% | abe: 3.599 | eve: 9.277 | bob: 4.110Epoch  17:  79% | abe: 3.598 | eve: 9.277 | bob: 4.110Epoch  17:  80% | abe: 3.598 | eve: 9.277 | bob: 4.110Epoch  17:  81% | abe: 3.598 | eve: 9.277 | bob: 4.109Epoch  17:  82% | abe: 3.598 | eve: 9.277 | bob: 4.109Epoch  17:  82% | abe: 3.598 | eve: 9.278 | bob: 4.108Epoch  17:  83% | abe: 3.599 | eve: 9.277 | bob: 4.109Epoch  17:  84% | abe: 3.599 | eve: 9.277 | bob: 4.109Epoch  17:  85% | abe: 3.598 | eve: 9.276 | bob: 4.108Epoch  17:  85% | abe: 3.597 | eve: 9.277 | bob: 4.107Epoch  17:  86% | abe: 3.597 | eve: 9.277 | bob: 4.107Epoch  17:  87% | abe: 3.597 | eve: 9.277 | bob: 4.107Epoch  17:  88% | abe: 3.596 | eve: 9.277 | bob: 4.106Epoch  17:  89% | abe: 3.596 | eve: 9.277 | bob: 4.106Epoch  17:  89% | abe: 3.596 | eve: 9.278 | bob: 4.106Epoch  17:  90% | abe: 3.596 | eve: 9.279 | bob: 4.106Epoch  17:  91% | abe: 3.595 | eve: 9.278 | bob: 4.106Epoch  17:  92% | abe: 3.595 | eve: 9.279 | bob: 4.105Epoch  17:  92% | abe: 3.594 | eve: 9.280 | bob: 4.104Epoch  17:  93% | abe: 3.594 | eve: 9.279 | bob: 4.104Epoch  17:  94% | abe: 3.594 | eve: 9.279 | bob: 4.104Epoch  17:  95% | abe: 3.594 | eve: 9.280 | bob: 4.104Epoch  17:  96% | abe: 3.593 | eve: 9.280 | bob: 4.103Epoch  17:  96% | abe: 3.593 | eve: 9.280 | bob: 4.103Epoch  17:  97% | abe: 3.592 | eve: 9.280 | bob: 4.102Epoch  17:  98% | abe: 3.592 | eve: 9.279 | bob: 4.102Epoch  17:  99% | abe: 3.591 | eve: 9.279 | bob: 4.101
New best Bob loss 4.101402713498828 at epoch 17
Epoch  18:   0% | abe: 3.547 | eve: 9.317 | bob: 4.022Epoch  18:   0% | abe: 3.525 | eve: 9.245 | bob: 4.019Epoch  18:   1% | abe: 3.536 | eve: 9.260 | bob: 4.038Epoch  18:   2% | abe: 3.544 | eve: 9.275 | bob: 4.041Epoch  18:   3% | abe: 3.541 | eve: 9.268 | bob: 4.037Epoch  18:   3% | abe: 3.539 | eve: 9.274 | bob: 4.036Epoch  18:   4% | abe: 3.542 | eve: 9.272 | bob: 4.040Epoch  18:   5% | abe: 3.543 | eve: 9.284 | bob: 4.043Epoch  18:   6% | abe: 3.541 | eve: 9.279 | bob: 4.042Epoch  18:   7% | abe: 3.542 | eve: 9.272 | bob: 4.043Epoch  18:   7% | abe: 3.539 | eve: 9.268 | bob: 4.039Epoch  18:   8% | abe: 3.541 | eve: 9.273 | bob: 4.039Epoch  18:   9% | abe: 3.545 | eve: 9.275 | bob: 4.043Epoch  18:  10% | abe: 3.545 | eve: 9.277 | bob: 4.043Epoch  18:  10% | abe: 3.541 | eve: 9.278 | bob: 4.040Epoch  18:  11% | abe: 3.540 | eve: 9.281 | bob: 4.038Epoch  18:  12% | abe: 3.540 | eve: 9.279 | bob: 4.038Epoch  18:  13% | abe: 3.541 | eve: 9.279 | bob: 4.039Epoch  18:  14% | abe: 3.545 | eve: 9.276 | bob: 4.042Epoch  18:  14% | abe: 3.547 | eve: 9.275 | bob: 4.043Epoch  18:  15% | abe: 3.545 | eve: 9.274 | bob: 4.041Epoch  18:  16% | abe: 3.542 | eve: 9.278 | bob: 4.041Epoch  18:  17% | abe: 3.541 | eve: 9.277 | bob: 4.041Epoch  18:  17% | abe: 3.543 | eve: 9.273 | bob: 4.043Epoch  18:  18% | abe: 3.542 | eve: 9.273 | bob: 4.041Epoch  18:  19% | abe: 3.540 | eve: 9.272 | bob: 4.041Epoch  18:  20% | abe: 3.541 | eve: 9.270 | bob: 4.042Epoch  18:  21% | abe: 3.541 | eve: 9.272 | bob: 4.041Epoch  18:  21% | abe: 3.540 | eve: 9.270 | bob: 4.040Epoch  18:  22% | abe: 3.542 | eve: 9.270 | bob: 4.043Epoch  18:  23% | abe: 3.542 | eve: 9.268 | bob: 4.042Epoch  18:  24% | abe: 3.541 | eve: 9.269 | bob: 4.041Epoch  18:  25% | abe: 3.540 | eve: 9.267 | bob: 4.039Epoch  18:  25% | abe: 3.540 | eve: 9.265 | bob: 4.040Epoch  18:  26% | abe: 3.539 | eve: 9.265 | bob: 4.039Epoch  18:  27% | abe: 3.539 | eve: 9.266 | bob: 4.040Epoch  18:  28% | abe: 3.538 | eve: 9.266 | bob: 4.040Epoch  18:  28% | abe: 3.537 | eve: 9.265 | bob: 4.039Epoch  18:  29% | abe: 3.538 | eve: 9.266 | bob: 4.039Epoch  18:  30% | abe: 3.538 | eve: 9.265 | bob: 4.038Epoch  18:  31% | abe: 3.538 | eve: 9.263 | bob: 4.038Epoch  18:  32% | abe: 3.539 | eve: 9.263 | bob: 4.039Epoch  18:  32% | abe: 3.539 | eve: 9.264 | bob: 4.039Epoch  18:  33% | abe: 3.540 | eve: 9.263 | bob: 4.040Epoch  18:  34% | abe: 3.539 | eve: 9.263 | bob: 4.040Epoch  18:  35% | abe: 3.540 | eve: 9.263 | bob: 4.040Epoch  18:  35% | abe: 3.540 | eve: 9.263 | bob: 4.040Epoch  18:  36% | abe: 3.541 | eve: 9.263 | bob: 4.042Epoch  18:  37% | abe: 3.542 | eve: 9.263 | bob: 4.042Epoch  18:  38% | abe: 3.541 | eve: 9.264 | bob: 4.042Epoch  18:  39% | abe: 3.541 | eve: 9.264 | bob: 4.041Epoch  18:  39% | abe: 3.541 | eve: 9.264 | bob: 4.042Epoch  18:  40% | abe: 3.541 | eve: 9.264 | bob: 4.042Epoch  18:  41% | abe: 3.540 | eve: 9.263 | bob: 4.041Epoch  18:  42% | abe: 3.539 | eve: 9.264 | bob: 4.039Epoch  18:  42% | abe: 3.538 | eve: 9.263 | bob: 4.038Epoch  18:  43% | abe: 3.537 | eve: 9.264 | bob: 4.037Epoch  18:  44% | abe: 3.537 | eve: 9.265 | bob: 4.037Epoch  18:  45% | abe: 3.537 | eve: 9.266 | bob: 4.037Epoch  18:  46% | abe: 3.537 | eve: 9.267 | bob: 4.037Epoch  18:  46% | abe: 3.538 | eve: 9.267 | bob: 4.037Epoch  18:  47% | abe: 3.539 | eve: 9.267 | bob: 4.037Epoch  18:  48% | abe: 3.539 | eve: 9.267 | bob: 4.037Epoch  18:  49% | abe: 3.538 | eve: 9.267 | bob: 4.037Epoch  18:  50% | abe: 3.538 | eve: 9.267 | bob: 4.036Epoch  18:  50% | abe: 3.538 | eve: 9.267 | bob: 4.036Epoch  18:  51% | abe: 3.537 | eve: 9.268 | bob: 4.036Epoch  18:  52% | abe: 3.536 | eve: 9.269 | bob: 4.035Epoch  18:  53% | abe: 3.536 | eve: 9.269 | bob: 4.034Epoch  18:  53% | abe: 3.535 | eve: 9.269 | bob: 4.034Epoch  18:  54% | abe: 3.534 | eve: 9.270 | bob: 4.033Epoch  18:  55% | abe: 3.534 | eve: 9.271 | bob: 4.032Epoch  18:  56% | abe: 3.533 | eve: 9.271 | bob: 4.032Epoch  18:  57% | abe: 3.533 | eve: 9.270 | bob: 4.031Epoch  18:  57% | abe: 3.532 | eve: 9.270 | bob: 4.031Epoch  18:  58% | abe: 3.532 | eve: 9.269 | bob: 4.030Epoch  18:  59% | abe: 3.532 | eve: 9.269 | bob: 4.030Epoch  18:  60% | abe: 3.532 | eve: 9.269 | bob: 4.029Epoch  18:  60% | abe: 3.531 | eve: 9.269 | bob: 4.028Epoch  18:  61% | abe: 3.531 | eve: 9.270 | bob: 4.028Epoch  18:  62% | abe: 3.530 | eve: 9.271 | bob: 4.027Epoch  18:  63% | abe: 3.530 | eve: 9.271 | bob: 4.027Epoch  18:  64% | abe: 3.530 | eve: 9.270 | bob: 4.027Epoch  18:  64% | abe: 3.530 | eve: 9.271 | bob: 4.027Epoch  18:  65% | abe: 3.530 | eve: 9.272 | bob: 4.026Epoch  18:  66% | abe: 3.529 | eve: 9.272 | bob: 4.026Epoch  18:  67% | abe: 3.529 | eve: 9.272 | bob: 4.025Epoch  18:  67% | abe: 3.529 | eve: 9.272 | bob: 4.025Epoch  18:  68% | abe: 3.529 | eve: 9.272 | bob: 4.025Epoch  18:  69% | abe: 3.529 | eve: 9.273 | bob: 4.024Epoch  18:  70% | abe: 3.528 | eve: 9.273 | bob: 4.024Epoch  18:  71% | abe: 3.528 | eve: 9.274 | bob: 4.024Epoch  18:  71% | abe: 3.528 | eve: 9.273 | bob: 4.024Epoch  18:  72% | abe: 3.528 | eve: 9.273 | bob: 4.023Epoch  18:  73% | abe: 3.527 | eve: 9.273 | bob: 4.022Epoch  18:  74% | abe: 3.527 | eve: 9.274 | bob: 4.022Epoch  18:  75% | abe: 3.527 | eve: 9.273 | bob: 4.022Epoch  18:  75% | abe: 3.526 | eve: 9.273 | bob: 4.021Epoch  18:  76% | abe: 3.525 | eve: 9.272 | bob: 4.020Epoch  18:  77% | abe: 3.525 | eve: 9.273 | bob: 4.020Epoch  18:  78% | abe: 3.524 | eve: 9.273 | bob: 4.019Epoch  18:  78% | abe: 3.524 | eve: 9.273 | bob: 4.018Epoch  18:  79% | abe: 3.524 | eve: 9.273 | bob: 4.019Epoch  18:  80% | abe: 3.524 | eve: 9.273 | bob: 4.018Epoch  18:  81% | abe: 3.523 | eve: 9.273 | bob: 4.018Epoch  18:  82% | abe: 3.523 | eve: 9.273 | bob: 4.017Epoch  18:  82% | abe: 3.522 | eve: 9.274 | bob: 4.016Epoch  18:  83% | abe: 3.522 | eve: 9.274 | bob: 4.016Epoch  18:  84% | abe: 3.521 | eve: 9.273 | bob: 4.015Epoch  18:  85% | abe: 3.520 | eve: 9.274 | bob: 4.014Epoch  18:  85% | abe: 3.521 | eve: 9.275 | bob: 4.015Epoch  18:  86% | abe: 3.521 | eve: 9.275 | bob: 4.015Epoch  18:  87% | abe: 3.520 | eve: 9.275 | bob: 4.014Epoch  18:  88% | abe: 3.520 | eve: 9.275 | bob: 4.014Epoch  18:  89% | abe: 3.520 | eve: 9.274 | bob: 4.013Epoch  18:  89% | abe: 3.519 | eve: 9.274 | bob: 4.013Epoch  18:  90% | abe: 3.519 | eve: 9.274 | bob: 4.013Epoch  18:  91% | abe: 3.518 | eve: 9.274 | bob: 4.012Epoch  18:  92% | abe: 3.518 | eve: 9.274 | bob: 4.012Epoch  18:  92% | abe: 3.518 | eve: 9.274 | bob: 4.011Epoch  18:  93% | abe: 3.517 | eve: 9.275 | bob: 4.011Epoch  18:  94% | abe: 3.517 | eve: 9.275 | bob: 4.010Epoch  18:  95% | abe: 3.517 | eve: 9.275 | bob: 4.010Epoch  18:  96% | abe: 3.516 | eve: 9.275 | bob: 4.009Epoch  18:  96% | abe: 3.515 | eve: 9.275 | bob: 4.009Epoch  18:  97% | abe: 3.515 | eve: 9.275 | bob: 4.009Epoch  18:  98% | abe: 3.515 | eve: 9.276 | bob: 4.008Epoch  18:  99% | abe: 3.515 | eve: 9.276 | bob: 4.008
New best Bob loss 4.007824905920415 at epoch 18
Epoch  19:   0% | abe: 3.467 | eve: 9.246 | bob: 3.949Epoch  19:   0% | abe: 3.460 | eve: 9.279 | bob: 3.941Epoch  19:   1% | abe: 3.472 | eve: 9.288 | bob: 3.954Epoch  19:   2% | abe: 3.463 | eve: 9.297 | bob: 3.944Epoch  19:   3% | abe: 3.454 | eve: 9.291 | bob: 3.933Epoch  19:   3% | abe: 3.463 | eve: 9.300 | bob: 3.938Epoch  19:   4% | abe: 3.463 | eve: 9.293 | bob: 3.937Epoch  19:   5% | abe: 3.468 | eve: 9.299 | bob: 3.944Epoch  19:   6% | abe: 3.461 | eve: 9.295 | bob: 3.940Epoch  19:   7% | abe: 3.466 | eve: 9.296 | bob: 3.941Epoch  19:   7% | abe: 3.469 | eve: 9.292 | bob: 3.944Epoch  19:   8% | abe: 3.465 | eve: 9.294 | bob: 3.942Epoch  19:   9% | abe: 3.462 | eve: 9.294 | bob: 3.940Epoch  19:  10% | abe: 3.462 | eve: 9.290 | bob: 3.940Epoch  19:  10% | abe: 3.461 | eve: 9.287 | bob: 3.938Epoch  19:  11% | abe: 3.459 | eve: 9.287 | bob: 3.936Epoch  19:  12% | abe: 3.459 | eve: 9.286 | bob: 3.936Epoch  19:  13% | abe: 3.453 | eve: 9.288 | bob: 3.930Epoch  19:  14% | abe: 3.454 | eve: 9.289 | bob: 3.932Epoch  19:  14% | abe: 3.457 | eve: 9.284 | bob: 3.934Epoch  19:  15% | abe: 3.460 | eve: 9.282 | bob: 3.936Epoch  19:  16% | abe: 3.460 | eve: 9.286 | bob: 3.935Epoch  19:  17% | abe: 3.460 | eve: 9.285 | bob: 3.934Epoch  19:  17% | abe: 3.462 | eve: 9.285 | bob: 3.937Epoch  19:  18% | abe: 3.463 | eve: 9.288 | bob: 3.939Epoch  19:  19% | abe: 3.464 | eve: 9.287 | bob: 3.940Epoch  19:  20% | abe: 3.464 | eve: 9.286 | bob: 3.939Epoch  19:  21% | abe: 3.464 | eve: 9.285 | bob: 3.939Epoch  19:  21% | abe: 3.465 | eve: 9.286 | bob: 3.940Epoch  19:  22% | abe: 3.465 | eve: 9.286 | bob: 3.940Epoch  19:  23% | abe: 3.466 | eve: 9.289 | bob: 3.940Epoch  19:  24% | abe: 3.466 | eve: 9.288 | bob: 3.940Epoch  19:  25% | abe: 3.466 | eve: 9.288 | bob: 3.941Epoch  19:  25% | abe: 3.467 | eve: 9.288 | bob: 3.940Epoch  19:  26% | abe: 3.467 | eve: 9.288 | bob: 3.940Epoch  19:  27% | abe: 3.468 | eve: 9.288 | bob: 3.940Epoch  19:  28% | abe: 3.466 | eve: 9.287 | bob: 3.938Epoch  19:  28% | abe: 3.466 | eve: 9.289 | bob: 3.938Epoch  19:  29% | abe: 3.464 | eve: 9.290 | bob: 3.937Epoch  19:  30% | abe: 3.465 | eve: 9.288 | bob: 3.938Epoch  19:  31% | abe: 3.464 | eve: 9.286 | bob: 3.936Epoch  19:  32% | abe: 3.463 | eve: 9.286 | bob: 3.936Epoch  19:  32% | abe: 3.462 | eve: 9.286 | bob: 3.935Epoch  19:  33% | abe: 3.461 | eve: 9.285 | bob: 3.935Epoch  19:  34% | abe: 3.462 | eve: 9.285 | bob: 3.936Epoch  19:  35% | abe: 3.462 | eve: 9.284 | bob: 3.936Epoch  19:  35% | abe: 3.463 | eve: 9.285 | bob: 3.938Epoch  19:  36% | abe: 3.463 | eve: 9.283 | bob: 3.938Epoch  19:  37% | abe: 3.464 | eve: 9.282 | bob: 3.938Epoch  19:  38% | abe: 3.464 | eve: 9.283 | bob: 3.939Epoch  19:  39% | abe: 3.463 | eve: 9.282 | bob: 3.938Epoch  19:  39% | abe: 3.463 | eve: 9.283 | bob: 3.939Epoch  19:  40% | abe: 3.463 | eve: 9.284 | bob: 3.937Epoch  19:  41% | abe: 3.463 | eve: 9.285 | bob: 3.938Epoch  19:  42% | abe: 3.462 | eve: 9.284 | bob: 3.937Epoch  19:  42% | abe: 3.461 | eve: 9.284 | bob: 3.936Epoch  19:  43% | abe: 3.462 | eve: 9.285 | bob: 3.937Epoch  19:  44% | abe: 3.461 | eve: 9.284 | bob: 3.936Epoch  19:  45% | abe: 3.461 | eve: 9.283 | bob: 3.936Epoch  19:  46% | abe: 3.461 | eve: 9.282 | bob: 3.936Epoch  19:  46% | abe: 3.460 | eve: 9.281 | bob: 3.935Epoch  19:  47% | abe: 3.460 | eve: 9.280 | bob: 3.935Epoch  19:  48% | abe: 3.460 | eve: 9.279 | bob: 3.934Epoch  19:  49% | abe: 3.459 | eve: 9.278 | bob: 3.934Epoch  19:  50% | abe: 3.458 | eve: 9.278 | bob: 3.933Epoch  19:  50% | abe: 3.458 | eve: 9.277 | bob: 3.933Epoch  19:  51% | abe: 3.457 | eve: 9.277 | bob: 3.932Epoch  19:  52% | abe: 3.455 | eve: 9.278 | bob: 3.930Epoch  19:  53% | abe: 3.456 | eve: 9.279 | bob: 3.930Epoch  19:  53% | abe: 3.456 | eve: 9.280 | bob: 3.931Epoch  19:  54% | abe: 3.455 | eve: 9.280 | bob: 3.931Epoch  19:  55% | abe: 3.455 | eve: 9.280 | bob: 3.930Epoch  19:  56% | abe: 3.455 | eve: 9.279 | bob: 3.930Epoch  19:  57% | abe: 3.456 | eve: 9.280 | bob: 3.931Epoch  19:  57% | abe: 3.456 | eve: 9.281 | bob: 3.930Epoch  19:  58% | abe: 3.455 | eve: 9.282 | bob: 3.930Epoch  19:  59% | abe: 3.455 | eve: 9.281 | bob: 3.930Epoch  19:  60% | abe: 3.455 | eve: 9.281 | bob: 3.929Epoch  19:  60% | abe: 3.455 | eve: 9.282 | bob: 3.929Epoch  19:  61% | abe: 3.455 | eve: 9.281 | bob: 3.929Epoch  19:  62% | abe: 3.454 | eve: 9.281 | bob: 3.929Epoch  19:  63% | abe: 3.454 | eve: 9.282 | bob: 3.928Epoch  19:  64% | abe: 3.453 | eve: 9.282 | bob: 3.927Epoch  19:  64% | abe: 3.453 | eve: 9.282 | bob: 3.927Epoch  19:  65% | abe: 3.453 | eve: 9.282 | bob: 3.927Epoch  19:  66% | abe: 3.452 | eve: 9.283 | bob: 3.926Epoch  19:  67% | abe: 3.451 | eve: 9.283 | bob: 3.925Epoch  19:  67% | abe: 3.451 | eve: 9.283 | bob: 3.925Epoch  19:  68% | abe: 3.451 | eve: 9.283 | bob: 3.925Epoch  19:  69% | abe: 3.451 | eve: 9.284 | bob: 3.925Epoch  19:  70% | abe: 3.450 | eve: 9.284 | bob: 3.924Epoch  19:  71% | abe: 3.449 | eve: 9.284 | bob: 3.923Epoch  19:  71% | abe: 3.450 | eve: 9.283 | bob: 3.924Epoch  19:  72% | abe: 3.450 | eve: 9.282 | bob: 3.923Epoch  19:  73% | abe: 3.449 | eve: 9.283 | bob: 3.923Epoch  19:  74% | abe: 3.449 | eve: 9.283 | bob: 3.923Epoch  19:  75% | abe: 3.448 | eve: 9.284 | bob: 3.922Epoch  19:  75% | abe: 3.448 | eve: 9.283 | bob: 3.921Epoch  19:  76% | abe: 3.447 | eve: 9.283 | bob: 3.921Epoch  19:  77% | abe: 3.447 | eve: 9.283 | bob: 3.920Epoch  19:  78% | abe: 3.446 | eve: 9.283 | bob: 3.920Epoch  19:  78% | abe: 3.446 | eve: 9.283 | bob: 3.920Epoch  19:  79% | abe: 3.446 | eve: 9.283 | bob: 3.920Epoch  19:  80% | abe: 3.446 | eve: 9.283 | bob: 3.919Epoch  19:  81% | abe: 3.446 | eve: 9.284 | bob: 3.919Epoch  19:  82% | abe: 3.446 | eve: 9.284 | bob: 3.919Epoch  19:  82% | abe: 3.445 | eve: 9.284 | bob: 3.918Epoch  19:  83% | abe: 3.445 | eve: 9.284 | bob: 3.918Epoch  19:  84% | abe: 3.445 | eve: 9.284 | bob: 3.917Epoch  19:  85% | abe: 3.444 | eve: 9.284 | bob: 3.917Epoch  19:  85% | abe: 3.444 | eve: 9.284 | bob: 3.916Epoch  19:  86% | abe: 3.444 | eve: 9.284 | bob: 3.916Epoch  19:  87% | abe: 3.443 | eve: 9.284 | bob: 3.916Epoch  19:  88% | abe: 3.443 | eve: 9.283 | bob: 3.915Epoch  19:  89% | abe: 3.443 | eve: 9.283 | bob: 3.915Epoch  19:  89% | abe: 3.442 | eve: 9.283 | bob: 3.915Epoch  19:  90% | abe: 3.442 | eve: 9.283 | bob: 3.915Epoch  19:  91% | abe: 3.442 | eve: 9.283 | bob: 3.914Epoch  19:  92% | abe: 3.442 | eve: 9.283 | bob: 3.914Epoch  19:  92% | abe: 3.442 | eve: 9.282 | bob: 3.914Epoch  19:  93% | abe: 3.441 | eve: 9.282 | bob: 3.913Epoch  19:  94% | abe: 3.441 | eve: 9.283 | bob: 3.913Epoch  19:  95% | abe: 3.441 | eve: 9.283 | bob: 3.913Epoch  19:  96% | abe: 3.441 | eve: 9.283 | bob: 3.912Epoch  19:  96% | abe: 3.440 | eve: 9.282 | bob: 3.911Epoch  19:  97% | abe: 3.440 | eve: 9.282 | bob: 3.911Epoch  19:  98% | abe: 3.439 | eve: 9.282 | bob: 3.910Epoch  19:  99% | abe: 3.438 | eve: 9.282 | bob: 3.910
New best Bob loss 3.909570369973835 at epoch 19
Epoch  20:   0% | abe: 3.459 | eve: 9.265 | bob: 3.893Epoch  20:   0% | abe: 3.437 | eve: 9.255 | bob: 3.892Epoch  20:   1% | abe: 3.417 | eve: 9.286 | bob: 3.880Epoch  20:   2% | abe: 3.401 | eve: 9.292 | bob: 3.866Epoch  20:   3% | abe: 3.397 | eve: 9.291 | bob: 3.866Epoch  20:   3% | abe: 3.405 | eve: 9.285 | bob: 3.865Epoch  20:   4% | abe: 3.398 | eve: 9.284 | bob: 3.861Epoch  20:   5% | abe: 3.394 | eve: 9.276 | bob: 3.852Epoch  20:   6% | abe: 3.395 | eve: 9.278 | bob: 3.848Epoch  20:   7% | abe: 3.398 | eve: 9.276 | bob: 3.850Epoch  20:   7% | abe: 3.396 | eve: 9.274 | bob: 3.851Epoch  20:   8% | abe: 3.395 | eve: 9.270 | bob: 3.849Epoch  20:   9% | abe: 3.395 | eve: 9.272 | bob: 3.851Epoch  20:  10% | abe: 3.392 | eve: 9.269 | bob: 3.851Epoch  20:  10% | abe: 3.387 | eve: 9.265 | bob: 3.846Epoch  20:  11% | abe: 3.390 | eve: 9.268 | bob: 3.847Epoch  20:  12% | abe: 3.391 | eve: 9.271 | bob: 3.850Epoch  20:  13% | abe: 3.392 | eve: 9.273 | bob: 3.851Epoch  20:  14% | abe: 3.392 | eve: 9.275 | bob: 3.851Epoch  20:  14% | abe: 3.393 | eve: 9.278 | bob: 3.852Epoch  20:  15% | abe: 3.394 | eve: 9.279 | bob: 3.853Epoch  20:  16% | abe: 3.392 | eve: 9.281 | bob: 3.851Epoch  20:  17% | abe: 3.390 | eve: 9.278 | bob: 3.850Epoch  20:  17% | abe: 3.388 | eve: 9.278 | bob: 3.848Epoch  20:  18% | abe: 3.389 | eve: 9.280 | bob: 3.850Epoch  20:  19% | abe: 3.390 | eve: 9.281 | bob: 3.850Epoch  20:  20% | abe: 3.391 | eve: 9.279 | bob: 3.851Epoch  20:  21% | abe: 3.389 | eve: 9.279 | bob: 3.849Epoch  20:  21% | abe: 3.389 | eve: 9.279 | bob: 3.848Epoch  20:  22% | abe: 3.389 | eve: 9.280 | bob: 3.848Epoch  20:  23% | abe: 3.387 | eve: 9.280 | bob: 3.846Epoch  20:  24% | abe: 3.385 | eve: 9.280 | bob: 3.844Epoch  20:  25% | abe: 3.385 | eve: 9.279 | bob: 3.843Epoch  20:  25% | abe: 3.384 | eve: 9.280 | bob: 3.842Epoch  20:  26% | abe: 3.387 | eve: 9.279 | bob: 3.845Epoch  20:  27% | abe: 3.386 | eve: 9.279 | bob: 3.845Epoch  20:  28% | abe: 3.387 | eve: 9.281 | bob: 3.845Epoch  20:  28% | abe: 3.388 | eve: 9.280 | bob: 3.845Epoch  20:  29% | abe: 3.388 | eve: 9.280 | bob: 3.846Epoch  20:  30% | abe: 3.389 | eve: 9.280 | bob: 3.847Epoch  20:  31% | abe: 3.389 | eve: 9.281 | bob: 3.847Epoch  20:  32% | abe: 3.389 | eve: 9.281 | bob: 3.847Epoch  20:  32% | abe: 3.389 | eve: 9.281 | bob: 3.847Epoch  20:  33% | abe: 3.389 | eve: 9.282 | bob: 3.847Epoch  20:  34% | abe: 3.387 | eve: 9.282 | bob: 3.845Epoch  20:  35% | abe: 3.386 | eve: 9.284 | bob: 3.844Epoch  20:  35% | abe: 3.386 | eve: 9.282 | bob: 3.844Epoch  20:  36% | abe: 3.386 | eve: 9.282 | bob: 3.844Epoch  20:  37% | abe: 3.386 | eve: 9.282 | bob: 3.843Epoch  20:  38% | abe: 3.386 | eve: 9.281 | bob: 3.843Epoch  20:  39% | abe: 3.386 | eve: 9.280 | bob: 3.843Epoch  20:  39% | abe: 3.385 | eve: 9.280 | bob: 3.842Epoch  20:  40% | abe: 3.383 | eve: 9.280 | bob: 3.840Epoch  20:  41% | abe: 3.383 | eve: 9.281 | bob: 3.839Epoch  20:  42% | abe: 3.382 | eve: 9.282 | bob: 3.838Epoch  20:  42% | abe: 3.381 | eve: 9.282 | bob: 3.838Epoch  20:  43% | abe: 3.381 | eve: 9.282 | bob: 3.838Epoch  20:  44% | abe: 3.380 | eve: 9.283 | bob: 3.837Epoch  20:  45% | abe: 3.380 | eve: 9.283 | bob: 3.837Epoch  20:  46% | abe: 3.380 | eve: 9.284 | bob: 3.837Epoch  20:  46% | abe: 3.381 | eve: 9.283 | bob: 3.838Epoch  20:  47% | abe: 3.381 | eve: 9.283 | bob: 3.838Epoch  20:  48% | abe: 3.380 | eve: 9.283 | bob: 3.837Epoch  20:  49% | abe: 3.380 | eve: 9.285 | bob: 3.836Epoch  20:  50% | abe: 3.380 | eve: 9.285 | bob: 3.836Epoch  20:  50% | abe: 3.380 | eve: 9.285 | bob: 3.836Epoch  20:  51% | abe: 3.380 | eve: 9.285 | bob: 3.835Epoch  20:  52% | abe: 3.380 | eve: 9.285 | bob: 3.836Epoch  20:  53% | abe: 3.381 | eve: 9.285 | bob: 3.836Epoch  20:  53% | abe: 3.379 | eve: 9.285 | bob: 3.835Epoch  20:  54% | abe: 3.380 | eve: 9.286 | bob: 3.835Epoch  20:  55% | abe: 3.380 | eve: 9.285 | bob: 3.835Epoch  20:  56% | abe: 3.380 | eve: 9.285 | bob: 3.834Epoch  20:  57% | abe: 3.379 | eve: 9.284 | bob: 3.834Epoch  20:  57% | abe: 3.379 | eve: 9.284 | bob: 3.834Epoch  20:  58% | abe: 3.379 | eve: 9.284 | bob: 3.834Epoch  20:  59% | abe: 3.379 | eve: 9.285 | bob: 3.834Epoch  20:  60% | abe: 3.378 | eve: 9.284 | bob: 3.833Epoch  20:  60% | abe: 3.378 | eve: 9.284 | bob: 3.832Epoch  20:  61% | abe: 3.377 | eve: 9.283 | bob: 3.832Epoch  20:  62% | abe: 3.376 | eve: 9.283 | bob: 3.831Epoch  20:  63% | abe: 3.376 | eve: 9.282 | bob: 3.830Epoch  20:  64% | abe: 3.376 | eve: 9.282 | bob: 3.830Epoch  20:  64% | abe: 3.375 | eve: 9.283 | bob: 3.830Epoch  20:  65% | abe: 3.376 | eve: 9.283 | bob: 3.830Epoch  20:  66% | abe: 3.374 | eve: 9.282 | bob: 3.829Epoch  20:  67% | abe: 3.374 | eve: 9.283 | bob: 3.829Epoch  20:  67% | abe: 3.373 | eve: 9.283 | bob: 3.828Epoch  20:  68% | abe: 3.373 | eve: 9.283 | bob: 3.828Epoch  20:  69% | abe: 3.373 | eve: 9.283 | bob: 3.828Epoch  20:  70% | abe: 3.373 | eve: 9.282 | bob: 3.828Epoch  20:  71% | abe: 3.373 | eve: 9.282 | bob: 3.827Epoch  20:  71% | abe: 3.373 | eve: 9.282 | bob: 3.827Epoch  20:  72% | abe: 3.373 | eve: 9.282 | bob: 3.826Epoch  20:  73% | abe: 3.372 | eve: 9.282 | bob: 3.826Epoch  20:  74% | abe: 3.372 | eve: 9.281 | bob: 3.826Epoch  20:  75% | abe: 3.372 | eve: 9.281 | bob: 3.826Epoch  20:  75% | abe: 3.372 | eve: 9.281 | bob: 3.826Epoch  20:  76% | abe: 3.371 | eve: 9.281 | bob: 3.825Epoch  20:  77% | abe: 3.371 | eve: 9.281 | bob: 3.825Epoch  20:  78% | abe: 3.371 | eve: 9.281 | bob: 3.824Epoch  20:  78% | abe: 3.371 | eve: 9.281 | bob: 3.824Epoch  20:  79% | abe: 3.371 | eve: 9.281 | bob: 3.824Epoch  20:  80% | abe: 3.371 | eve: 9.280 | bob: 3.824Epoch  20:  81% | abe: 3.370 | eve: 9.280 | bob: 3.824Epoch  20:  82% | abe: 3.370 | eve: 9.281 | bob: 3.824Epoch  20:  82% | abe: 3.370 | eve: 9.282 | bob: 3.823Epoch  20:  83% | abe: 3.370 | eve: 9.282 | bob: 3.823Epoch  20:  84% | abe: 3.370 | eve: 9.281 | bob: 3.823Epoch  20:  85% | abe: 3.369 | eve: 9.281 | bob: 3.822Epoch  20:  85% | abe: 3.369 | eve: 9.281 | bob: 3.822Epoch  20:  86% | abe: 3.368 | eve: 9.280 | bob: 3.821Epoch  20:  87% | abe: 3.368 | eve: 9.281 | bob: 3.822Epoch  20:  88% | abe: 3.368 | eve: 9.281 | bob: 3.821Epoch  20:  89% | abe: 3.368 | eve: 9.282 | bob: 3.822Epoch  20:  89% | abe: 3.368 | eve: 9.283 | bob: 3.821Epoch  20:  90% | abe: 3.368 | eve: 9.283 | bob: 3.820Epoch  20:  91% | abe: 3.368 | eve: 9.283 | bob: 3.820Epoch  20:  92% | abe: 3.367 | eve: 9.283 | bob: 3.820Epoch  20:  92% | abe: 3.367 | eve: 9.284 | bob: 3.819Epoch  20:  93% | abe: 3.367 | eve: 9.285 | bob: 3.819Epoch  20:  94% | abe: 3.367 | eve: 9.284 | bob: 3.819Epoch  20:  95% | abe: 3.366 | eve: 9.284 | bob: 3.819Epoch  20:  96% | abe: 3.366 | eve: 9.283 | bob: 3.818Epoch  20:  96% | abe: 3.365 | eve: 9.284 | bob: 3.818Epoch  20:  97% | abe: 3.365 | eve: 9.283 | bob: 3.818Epoch  20:  98% | abe: 3.365 | eve: 9.283 | bob: 3.818Epoch  20:  99% | abe: 3.365 | eve: 9.283 | bob: 3.817
New best Bob loss 3.8171291408068555 at epoch 20
Epoch  21:   0% | abe: 3.301 | eve: 9.326 | bob: 3.759Epoch  21:   0% | abe: 3.328 | eve: 9.265 | bob: 3.792Epoch  21:   1% | abe: 3.305 | eve: 9.279 | bob: 3.770Epoch  21:   2% | abe: 3.291 | eve: 9.282 | bob: 3.753Epoch  21:   3% | abe: 3.302 | eve: 9.276 | bob: 3.759Epoch  21:   3% | abe: 3.305 | eve: 9.286 | bob: 3.765Epoch  21:   4% | abe: 3.310 | eve: 9.280 | bob: 3.770Epoch  21:   5% | abe: 3.303 | eve: 9.277 | bob: 3.759Epoch  21:   6% | abe: 3.306 | eve: 9.267 | bob: 3.761Epoch  21:   7% | abe: 3.310 | eve: 9.265 | bob: 3.766Epoch  21:   7% | abe: 3.310 | eve: 9.271 | bob: 3.766Epoch  21:   8% | abe: 3.311 | eve: 9.278 | bob: 3.767Epoch  21:   9% | abe: 3.310 | eve: 9.280 | bob: 3.766Epoch  21:  10% | abe: 3.311 | eve: 9.284 | bob: 3.766Epoch  21:  10% | abe: 3.313 | eve: 9.287 | bob: 3.769Epoch  21:  11% | abe: 3.314 | eve: 9.286 | bob: 3.769Epoch  21:  12% | abe: 3.314 | eve: 9.286 | bob: 3.769Epoch  21:  13% | abe: 3.314 | eve: 9.281 | bob: 3.767Epoch  21:  14% | abe: 3.315 | eve: 9.277 | bob: 3.769Epoch  21:  14% | abe: 3.315 | eve: 9.276 | bob: 3.769Epoch  21:  15% | abe: 3.312 | eve: 9.276 | bob: 3.766Epoch  21:  16% | abe: 3.312 | eve: 9.273 | bob: 3.764Epoch  21:  17% | abe: 3.314 | eve: 9.273 | bob: 3.765Epoch  21:  17% | abe: 3.311 | eve: 9.269 | bob: 3.763Epoch  21:  18% | abe: 3.311 | eve: 9.271 | bob: 3.762Epoch  21:  19% | abe: 3.312 | eve: 9.272 | bob: 3.764Epoch  21:  20% | abe: 3.310 | eve: 9.276 | bob: 3.762Epoch  21:  21% | abe: 3.309 | eve: 9.276 | bob: 3.760Epoch  21:  21% | abe: 3.310 | eve: 9.278 | bob: 3.760Epoch  21:  22% | abe: 3.309 | eve: 9.278 | bob: 3.759Epoch  21:  23% | abe: 3.308 | eve: 9.277 | bob: 3.757Epoch  21:  24% | abe: 3.309 | eve: 9.276 | bob: 3.757Epoch  21:  25% | abe: 3.309 | eve: 9.279 | bob: 3.757Epoch  21:  25% | abe: 3.307 | eve: 9.280 | bob: 3.755Epoch  21:  26% | abe: 3.306 | eve: 9.280 | bob: 3.754Epoch  21:  27% | abe: 3.306 | eve: 9.279 | bob: 3.753Epoch  21:  28% | abe: 3.304 | eve: 9.277 | bob: 3.751Epoch  21:  28% | abe: 3.303 | eve: 9.278 | bob: 3.749Epoch  21:  29% | abe: 3.302 | eve: 9.278 | bob: 3.748Epoch  21:  30% | abe: 3.301 | eve: 9.279 | bob: 3.748Epoch  21:  31% | abe: 3.300 | eve: 9.279 | bob: 3.747Epoch  21:  32% | abe: 3.301 | eve: 9.278 | bob: 3.747Epoch  21:  32% | abe: 3.300 | eve: 9.279 | bob: 3.746Epoch  21:  33% | abe: 3.300 | eve: 9.279 | bob: 3.746Epoch  21:  34% | abe: 3.300 | eve: 9.277 | bob: 3.745Epoch  21:  35% | abe: 3.299 | eve: 9.279 | bob: 3.745Epoch  21:  35% | abe: 3.300 | eve: 9.277 | bob: 3.745Epoch  21:  36% | abe: 3.299 | eve: 9.277 | bob: 3.744Epoch  21:  37% | abe: 3.300 | eve: 9.276 | bob: 3.744Epoch  21:  38% | abe: 3.301 | eve: 9.276 | bob: 3.745Epoch  21:  39% | abe: 3.300 | eve: 9.274 | bob: 3.744Epoch  21:  39% | abe: 3.300 | eve: 9.274 | bob: 3.744Epoch  21:  40% | abe: 3.299 | eve: 9.274 | bob: 3.743Epoch  21:  41% | abe: 3.300 | eve: 9.275 | bob: 3.743Epoch  21:  42% | abe: 3.299 | eve: 9.276 | bob: 3.742Epoch  21:  42% | abe: 3.299 | eve: 9.275 | bob: 3.741Epoch  21:  43% | abe: 3.299 | eve: 9.277 | bob: 3.741Epoch  21:  44% | abe: 3.299 | eve: 9.277 | bob: 3.741Epoch  21:  45% | abe: 3.299 | eve: 9.277 | bob: 3.741Epoch  21:  46% | abe: 3.299 | eve: 9.276 | bob: 3.740Epoch  21:  46% | abe: 3.298 | eve: 9.276 | bob: 3.740Epoch  21:  47% | abe: 3.298 | eve: 9.276 | bob: 3.740Epoch  21:  48% | abe: 3.297 | eve: 9.276 | bob: 3.740Epoch  21:  49% | abe: 3.297 | eve: 9.276 | bob: 3.739Epoch  21:  50% | abe: 3.296 | eve: 9.276 | bob: 3.738Epoch  21:  50% | abe: 3.297 | eve: 9.276 | bob: 3.738Epoch  21:  51% | abe: 3.296 | eve: 9.277 | bob: 3.737Epoch  21:  52% | abe: 3.297 | eve: 9.278 | bob: 3.737Epoch  21:  53% | abe: 3.297 | eve: 9.278 | bob: 3.737Epoch  21:  53% | abe: 3.297 | eve: 9.279 | bob: 3.736Epoch  21:  54% | abe: 3.296 | eve: 9.278 | bob: 3.736Epoch  21:  55% | abe: 3.297 | eve: 9.276 | bob: 3.736Epoch  21:  56% | abe: 3.296 | eve: 9.277 | bob: 3.736Epoch  21:  57% | abe: 3.295 | eve: 9.277 | bob: 3.735Epoch  21:  57% | abe: 3.294 | eve: 9.277 | bob: 3.735Epoch  21:  58% | abe: 3.294 | eve: 9.277 | bob: 3.734Epoch  21:  59% | abe: 3.294 | eve: 9.278 | bob: 3.734Epoch  21:  60% | abe: 3.293 | eve: 9.278 | bob: 3.733Epoch  21:  60% | abe: 3.293 | eve: 9.278 | bob: 3.732Epoch  21:  61% | abe: 3.292 | eve: 9.278 | bob: 3.731Epoch  21:  62% | abe: 3.293 | eve: 9.277 | bob: 3.732Epoch  21:  63% | abe: 3.293 | eve: 9.276 | bob: 3.732Epoch  21:  64% | abe: 3.293 | eve: 9.276 | bob: 3.732Epoch  21:  64% | abe: 3.292 | eve: 9.277 | bob: 3.731Epoch  21:  65% | abe: 3.293 | eve: 9.277 | bob: 3.732Epoch  21:  66% | abe: 3.293 | eve: 9.278 | bob: 3.732Epoch  21:  67% | abe: 3.293 | eve: 9.278 | bob: 3.732Epoch  21:  67% | abe: 3.292 | eve: 9.279 | bob: 3.731Epoch  21:  68% | abe: 3.292 | eve: 9.279 | bob: 3.731Epoch  21:  69% | abe: 3.292 | eve: 9.279 | bob: 3.730Epoch  21:  70% | abe: 3.291 | eve: 9.279 | bob: 3.729Epoch  21:  71% | abe: 3.291 | eve: 9.279 | bob: 3.729Epoch  21:  71% | abe: 3.290 | eve: 9.279 | bob: 3.728Epoch  21:  72% | abe: 3.290 | eve: 9.279 | bob: 3.728Epoch  21:  73% | abe: 3.289 | eve: 9.278 | bob: 3.727Epoch  21:  74% | abe: 3.289 | eve: 9.279 | bob: 3.727Epoch  21:  75% | abe: 3.289 | eve: 9.278 | bob: 3.728Epoch  21:  75% | abe: 3.289 | eve: 9.278 | bob: 3.727Epoch  21:  76% | abe: 3.289 | eve: 9.278 | bob: 3.727Epoch  21:  77% | abe: 3.288 | eve: 9.278 | bob: 3.726Epoch  21:  78% | abe: 3.287 | eve: 9.278 | bob: 3.725Epoch  21:  78% | abe: 3.287 | eve: 9.278 | bob: 3.725Epoch  21:  79% | abe: 3.286 | eve: 9.278 | bob: 3.724Epoch  21:  80% | abe: 3.286 | eve: 9.279 | bob: 3.724Epoch  21:  81% | abe: 3.285 | eve: 9.278 | bob: 3.723Epoch  21:  82% | abe: 3.285 | eve: 9.279 | bob: 3.723Epoch  21:  82% | abe: 3.284 | eve: 9.278 | bob: 3.722Epoch  21:  83% | abe: 3.284 | eve: 9.278 | bob: 3.722Epoch  21:  84% | abe: 3.284 | eve: 9.278 | bob: 3.721Epoch  21:  85% | abe: 3.283 | eve: 9.279 | bob: 3.720Epoch  21:  85% | abe: 3.283 | eve: 9.279 | bob: 3.720Epoch  21:  86% | abe: 3.282 | eve: 9.280 | bob: 3.719Epoch  21:  87% | abe: 3.282 | eve: 9.280 | bob: 3.719Epoch  21:  88% | abe: 3.281 | eve: 9.280 | bob: 3.718Epoch  21:  89% | abe: 3.281 | eve: 9.280 | bob: 3.717Epoch  21:  89% | abe: 3.280 | eve: 9.281 | bob: 3.717Epoch  21:  90% | abe: 3.280 | eve: 9.281 | bob: 3.716Epoch  21:  91% | abe: 3.280 | eve: 9.281 | bob: 3.716Epoch  21:  92% | abe: 3.280 | eve: 9.281 | bob: 3.716Epoch  21:  92% | abe: 3.280 | eve: 9.281 | bob: 3.716Epoch  21:  93% | abe: 3.279 | eve: 9.282 | bob: 3.716Epoch  21:  94% | abe: 3.279 | eve: 9.282 | bob: 3.716Epoch  21:  95% | abe: 3.278 | eve: 9.282 | bob: 3.715Epoch  21:  96% | abe: 3.278 | eve: 9.282 | bob: 3.715Epoch  21:  96% | abe: 3.278 | eve: 9.282 | bob: 3.715Epoch  21:  97% | abe: 3.278 | eve: 9.282 | bob: 3.714Epoch  21:  98% | abe: 3.277 | eve: 9.282 | bob: 3.714Epoch  21:  99% | abe: 3.277 | eve: 9.281 | bob: 3.713
New best Bob loss 3.713358160001235 at epoch 21
Epoch  22:   0% | abe: 3.241 | eve: 9.259 | bob: 3.712Epoch  22:   0% | abe: 3.230 | eve: 9.274 | bob: 3.692Epoch  22:   1% | abe: 3.214 | eve: 9.288 | bob: 3.674Epoch  22:   2% | abe: 3.219 | eve: 9.278 | bob: 3.667Epoch  22:   3% | abe: 3.224 | eve: 9.278 | bob: 3.669Epoch  22:   3% | abe: 3.226 | eve: 9.284 | bob: 3.670Epoch  22:   4% | abe: 3.220 | eve: 9.278 | bob: 3.658Epoch  22:   5% | abe: 3.222 | eve: 9.266 | bob: 3.658Epoch  22:   6% | abe: 3.222 | eve: 9.267 | bob: 3.660Epoch  22:   7% | abe: 3.226 | eve: 9.269 | bob: 3.662Epoch  22:   7% | abe: 3.227 | eve: 9.264 | bob: 3.661Epoch  22:   8% | abe: 3.228 | eve: 9.267 | bob: 3.660Epoch  22:   9% | abe: 3.231 | eve: 9.268 | bob: 3.662Epoch  22:  10% | abe: 3.231 | eve: 9.266 | bob: 3.662Epoch  22:  10% | abe: 3.227 | eve: 9.268 | bob: 3.660Epoch  22:  11% | abe: 3.227 | eve: 9.270 | bob: 3.659Epoch  22:  12% | abe: 3.226 | eve: 9.274 | bob: 3.658Epoch  22:  13% | abe: 3.223 | eve: 9.276 | bob: 3.656Epoch  22:  14% | abe: 3.224 | eve: 9.276 | bob: 3.658Epoch  22:  14% | abe: 3.221 | eve: 9.278 | bob: 3.656Epoch  22:  15% | abe: 3.222 | eve: 9.277 | bob: 3.656Epoch  22:  16% | abe: 3.224 | eve: 9.281 | bob: 3.658Epoch  22:  17% | abe: 3.224 | eve: 9.281 | bob: 3.658Epoch  22:  17% | abe: 3.222 | eve: 9.283 | bob: 3.655Epoch  22:  18% | abe: 3.220 | eve: 9.284 | bob: 3.653Epoch  22:  19% | abe: 3.219 | eve: 9.281 | bob: 3.652Epoch  22:  20% | abe: 3.219 | eve: 9.282 | bob: 3.653Epoch  22:  21% | abe: 3.220 | eve: 9.284 | bob: 3.655Epoch  22:  21% | abe: 3.222 | eve: 9.287 | bob: 3.655Epoch  22:  22% | abe: 3.221 | eve: 9.285 | bob: 3.654Epoch  22:  23% | abe: 3.219 | eve: 9.285 | bob: 3.653Epoch  22:  24% | abe: 3.219 | eve: 9.284 | bob: 3.654Epoch  22:  25% | abe: 3.219 | eve: 9.284 | bob: 3.654Epoch  22:  25% | abe: 3.219 | eve: 9.282 | bob: 3.654Epoch  22:  26% | abe: 3.220 | eve: 9.284 | bob: 3.655Epoch  22:  27% | abe: 3.222 | eve: 9.282 | bob: 3.657Epoch  22:  28% | abe: 3.221 | eve: 9.281 | bob: 3.655Epoch  22:  28% | abe: 3.221 | eve: 9.283 | bob: 3.655Epoch  22:  29% | abe: 3.222 | eve: 9.284 | bob: 3.655Epoch  22:  30% | abe: 3.223 | eve: 9.283 | bob: 3.656Epoch  22:  31% | abe: 3.222 | eve: 9.282 | bob: 3.656Epoch  22:  32% | abe: 3.222 | eve: 9.283 | bob: 3.656Epoch  22:  32% | abe: 3.222 | eve: 9.282 | bob: 3.655Epoch  22:  33% | abe: 3.221 | eve: 9.281 | bob: 3.654Epoch  22:  34% | abe: 3.221 | eve: 9.281 | bob: 3.654Epoch  22:  35% | abe: 3.219 | eve: 9.281 | bob: 3.653Epoch  22:  35% | abe: 3.220 | eve: 9.282 | bob: 3.653Epoch  22:  36% | abe: 3.220 | eve: 9.280 | bob: 3.653Epoch  22:  37% | abe: 3.219 | eve: 9.279 | bob: 3.653Epoch  22:  38% | abe: 3.219 | eve: 9.280 | bob: 3.652Epoch  22:  39% | abe: 3.218 | eve: 9.281 | bob: 3.652Epoch  22:  39% | abe: 3.217 | eve: 9.280 | bob: 3.651Epoch  22:  40% | abe: 3.217 | eve: 9.281 | bob: 3.651Epoch  22:  41% | abe: 3.217 | eve: 9.280 | bob: 3.651Epoch  22:  42% | abe: 3.217 | eve: 9.280 | bob: 3.650Epoch  22:  42% | abe: 3.216 | eve: 9.279 | bob: 3.649Epoch  22:  43% | abe: 3.215 | eve: 9.278 | bob: 3.649Epoch  22:  44% | abe: 3.215 | eve: 9.278 | bob: 3.648