WARNING:tensorflow:From /home/stud/minawoi/miniconda3/envs/conda-venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2024-04-15 18:35:09.518949: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-04-15 18:35:09.597422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:09:00.0
2024-04-15 18:35:09.598165: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-15 18:35:09.601909: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-04-15 18:35:09.605007: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-04-15 18:35:09.606103: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-04-15 18:35:09.609428: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-04-15 18:35:09.612423: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-04-15 18:35:09.617827: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-04-15 18:35:09.625126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-04-15 18:35:09.625695: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2024-04-15 18:35:09.637525: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199835000 Hz
2024-04-15 18:35:09.640954: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2e8f790 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-04-15 18:35:09.641027: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-04-15 18:35:09.921502: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2bd1c70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-04-15 18:35:09.921574: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-04-15 18:35:09.926057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:09:00.0
2024-04-15 18:35:09.926194: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-15 18:35:09.926232: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-04-15 18:35:09.926266: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-04-15 18:35:09.926298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-04-15 18:35:09.926335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-04-15 18:35:09.926368: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-04-15 18:35:09.926403: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-04-15 18:35:09.941271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-04-15 18:35:09.941372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-15 18:35:09.946058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-04-15 18:35:09.946083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-04-15 18:35:09.946096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2024-04-15 18:35:09.952781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30593 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:09:00.0, compute capability: 7.0)
WARNING:tensorflow:Output bob missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to bob.
WARNING:tensorflow:Output bob_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to bob_1.
WARNING:tensorflow:Output eve missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to eve.
WARNING:tensorflow:Output eve_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to eve_1.
2024-04-15 18:35:13.322866: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
Train on 448 samples, validate on 448 samples
Epoch 1/512
448/448 - 1s - loss: 0.9218 - val_loss: 0.0058
Epoch 2/512
448/448 - 0s - loss: 0.4579 - val_loss: 0.0022
Epoch 3/512
448/448 - 0s - loss: 0.1464 - val_loss: 3.9144e-04
Epoch 4/512
448/448 - 0s - loss: 0.0224 - val_loss: 4.0186e-05
Epoch 5/512
448/448 - 0s - loss: 0.0024 - val_loss: 8.5939e-06
Epoch 6/512
448/448 - 0s - loss: 7.4157e-04 - val_loss: 5.8671e-06
Epoch 7/512
448/448 - 0s - loss: 5.3891e-04 - val_loss: 4.4188e-06
Epoch 8/512
448/448 - 0s - loss: 3.9882e-04 - val_loss: 3.1194e-06
Epoch 9/512
448/448 - 0s - loss: 2.7489e-04 - val_loss: 2.0215e-06
Epoch 10/512
448/448 - 0s - loss: 1.7300e-04 - val_loss: 1.1775e-06
Epoch 11/512
448/448 - 0s - loss: 9.7203e-05 - val_loss: 5.9934e-07
Epoch 12/512
448/448 - 0s - loss: 4.7358e-05 - val_loss: 2.5760e-07
Epoch 13/512
448/448 - 0s - loss: 1.9300e-05 - val_loss: 8.9355e-08
Epoch 14/512
448/448 - 0s - loss: 6.2792e-06 - val_loss: 2.3597e-08
Epoch 15/512
448/448 - 0s - loss: 1.5759e-06 - val_loss: 9.5786e-09
Epoch 16/512
448/448 - 0s - loss: 1.0995e-05 - val_loss: 3.0532e-06
Epoch 17/512
448/448 - 0s - loss: 0.0033 - val_loss: 3.3839e-05
Epoch 18/512
448/448 - 0s - loss: 0.0014 - val_loss: 1.3829e-06
Epoch 19/512
448/448 - 0s - loss: 1.1087e-04 - val_loss: 1.4000e-06
Epoch 20/512
448/448 - 0s - loss: 3.2693e-04 - val_loss: 1.6013e-05
Epoch 21/512
448/448 - 0s - loss: 0.0025 - val_loss: 1.7476e-05
Epoch 22/512
448/448 - 0s - loss: 0.0011 - val_loss: 4.2623e-06
Epoch 23/512
448/448 - 0s - loss: 4.4037e-04 - val_loss: 7.5774e-06
Epoch 24/512
448/448 - 0s - loss: 0.0012 - val_loss: 1.9690e-05
Epoch 25/512
448/448 - 0s - loss: 0.0016 - val_loss: 9.0677e-06
Epoch 26/512
448/448 - 0s - loss: 7.5109e-04 - val_loss: 7.1299e-06
Epoch 27/512
448/448 - 0s - loss: 8.5073e-04 - val_loss: 1.3057e-05
Epoch 28/512
448/448 - 0s - loss: 0.0013 - val_loss: 1.2218e-05
Epoch 29/512
448/448 - 0s - loss: 0.0010 - val_loss: 8.0987e-06
Epoch 30/512
448/448 - 0s - loss: 8.1616e-04 - val_loss: 9.8370e-06
Epoch 31/512
448/448 - 0s - loss: 0.0011 - val_loss: 1.1994e-05
Epoch 32/512
448/448 - 0s - loss: 0.0011 - val_loss: 9.3161e-06
Epoch 33/512
448/448 - 0s - loss: 8.7728e-04 - val_loss: 8.7981e-06
Epoch 34/512
448/448 - 0s - loss: 9.1253e-04 - val_loss: 1.0696e-05
Epoch 35/512
448/448 - 0s - loss: 0.0010 - val_loss: 1.0136e-05
Epoch 36/512
448/448 - 0s - loss: 9.3256e-04 - val_loss: 8.7123e-06
Epoch 37/512
448/448 - 0s - loss: 8.6170e-04 - val_loss: 9.2357e-06
Epoch 38/512
448/448 - 0s - loss: 9.3393e-04 - val_loss: 9.7559e-06
Epoch 39/512
448/448 - 0s - loss: 9.3151e-04 - val_loss: 8.9281e-06
Epoch 40/512
448/448 - 0s - loss: 8.5722e-04 - val_loss: 8.8757e-06
Epoch 41/512
448/448 - 0s - loss: 8.7872e-04 - val_loss: 9.1417e-06
Epoch 42/512
448/448 - 0s - loss: 8.8112e-04 - val_loss: 8.8481e-06
Epoch 43/512
448/448 - 0s - loss: 8.5469e-04 - val_loss: 8.4238e-06
Epoch 44/512
448/448 - 0s - loss: 8.3156e-04 - val_loss: 8.4683e-06
Epoch 45/512
448/448 - 0s - loss: 8.4668e-04 - val_loss: 8.3085e-06
Epoch 46/512
448/448 - 0s - loss: 8.1458e-04 - val_loss: 8.3022e-06
Epoch 47/512
448/448 - 0s - loss: 8.1636e-04 - val_loss: 8.4063e-06
Epoch 48/512
448/448 - 0s - loss: 8.1994e-04 - val_loss: 7.9642e-06
Epoch 49/512
448/448 - 0s - loss: 7.7780e-04 - val_loss: 7.9719e-06
Epoch 50/512
448/448 - 0s - loss: 7.9454e-04 - val_loss: 7.9586e-06
Epoch 51/512
448/448 - 0s - loss: 7.7208e-04 - val_loss: 8.0384e-06
Epoch 52/512
448/448 - 0s - loss: 7.8276e-04 - val_loss: 7.7873e-06
Epoch 53/512
448/448 - 0s - loss: 7.5613e-04 - val_loss: 7.5366e-06
Epoch 54/512
448/448 - 0s - loss: 7.4509e-04 - val_loss: 7.5774e-06
Epoch 55/512
448/448 - 0s - loss: 7.5024e-04 - val_loss: 7.4348e-06
Epoch 56/512
448/448 - 0s - loss: 7.3367e-04 - val_loss: 7.3265e-06
Epoch 57/512
448/448 - 0s - loss: 7.2673e-04 - val_loss: 7.2716e-06
Epoch 58/512
448/448 - 0s - loss: 7.1946e-04 - val_loss: 7.2668e-06
Epoch 59/512
448/448 - 0s - loss: 7.1636e-04 - val_loss: 7.1505e-06
Epoch 60/512
448/448 - 0s - loss: 7.0402e-04 - val_loss: 6.9892e-06
Epoch 61/512
448/448 - 0s - loss: 6.9580e-04 - val_loss: 6.8488e-06
Epoch 62/512
448/448 - 0s - loss: 6.7996e-04 - val_loss: 7.0191e-06
Epoch 63/512
448/448 - 0s - loss: 6.9476e-04 - val_loss: 6.8761e-06
Epoch 64/512
448/448 - 0s - loss: 6.7590e-04 - val_loss: 6.5933e-06
Epoch 65/512
448/448 - 0s - loss: 6.5751e-04 - val_loss: 6.6401e-06
Epoch 66/512
448/448 - 0s - loss: 6.6419e-04 - val_loss: 6.6418e-06
Epoch 67/512
448/448 - 0s - loss: 6.5688e-04 - val_loss: 6.5255e-06
Epoch 68/512
448/448 - 0s - loss: 6.4587e-04 - val_loss: 6.3770e-06
Epoch 69/512
448/448 - 0s - loss: 6.3556e-04 - val_loss: 6.4956e-06
Epoch 70/512
448/448 - 0s - loss: 6.4433e-04 - val_loss: 6.3651e-06
Epoch 71/512
448/448 - 0s - loss: 6.2400e-04 - val_loss: 6.2479e-06
Epoch 72/512
448/448 - 0s - loss: 6.2050e-04 - val_loss: 6.2718e-06
Epoch 73/512
448/448 - 0s - loss: 6.1734e-04 - val_loss: 6.2535e-06
Epoch 74/512
448/448 - 0s - loss: 6.1635e-04 - val_loss: 6.0348e-06
Epoch 75/512
448/448 - 0s - loss: 5.9713e-04 - val_loss: 6.0346e-06
Epoch 76/512
448/448 - 0s - loss: 6.0003e-04 - val_loss: 6.0613e-06
Epoch 77/512
448/448 - 0s - loss: 5.9946e-04 - val_loss: 5.8204e-06
Epoch 78/512
448/448 - 0s - loss: 5.7689e-04 - val_loss: 5.8023e-06
Epoch 79/512
448/448 - 0s - loss: 5.8071e-04 - val_loss: 5.9388e-06
Epoch 80/512
448/448 - 0s - loss: 5.8862e-04 - val_loss: 5.7008e-06
Epoch 81/512
448/448 - 0s - loss: 5.5843e-04 - val_loss: 5.7311e-06
Epoch 82/512
448/448 - 0s - loss: 5.7176e-04 - val_loss: 5.6836e-06
Epoch 83/512
448/448 - 0s - loss: 5.5662e-04 - val_loss: 5.6584e-06
Epoch 84/512
448/448 - 0s - loss: 5.5775e-04 - val_loss: 5.5378e-06
Epoch 85/512
448/448 - 0s - loss: 5.4811e-04 - val_loss: 5.4449e-06
Epoch 86/512
448/448 - 0s - loss: 5.4564e-04 - val_loss: 5.3494e-06
Epoch 87/512
448/448 - 0s - loss: 5.2963e-04 - val_loss: 5.5682e-06
Epoch 88/512
448/448 - 0s - loss: 5.4880e-04 - val_loss: 5.5282e-06
Epoch 89/512
448/448 - 0s - loss: 5.3863e-04 - val_loss: 5.0757e-06
Epoch 90/512
448/448 - 0s - loss: 5.0623e-04 - val_loss: 5.2020e-06
Epoch 91/512
448/448 - 0s - loss: 5.2736e-04 - val_loss: 5.3177e-06
Epoch 92/512
448/448 - 0s - loss: 5.2269e-04 - val_loss: 5.1103e-06
Epoch 93/512
448/448 - 0s - loss: 5.0455e-04 - val_loss: 5.0560e-06
Epoch 94/512
448/448 - 0s - loss: 5.0408e-04 - val_loss: 5.1555e-06
Epoch 95/512
448/448 - 0s - loss: 5.1027e-04 - val_loss: 4.9449e-06
Epoch 96/512
448/448 - 0s - loss: 4.9045e-04 - val_loss: 4.9011e-06
Epoch 97/512
448/448 - 0s - loss: 4.8859e-04 - val_loss: 5.1229e-06
Epoch 98/512
448/448 - 0s - loss: 5.0476e-04 - val_loss: 4.8772e-06
Epoch 99/512
448/448 - 0s - loss: 4.7673e-04 - val_loss: 4.7375e-06
Epoch 100/512
448/448 - 0s - loss: 4.7734e-04 - val_loss: 4.7474e-06
Epoch 101/512
448/448 - 0s - loss: 4.7830e-04 - val_loss: 4.6974e-06
Epoch 102/512
448/448 - 0s - loss: 4.7267e-04 - val_loss: 4.5823e-06
Epoch 103/512
448/448 - 0s - loss: 4.5930e-04 - val_loss: 4.7278e-06
Epoch 104/512
448/448 - 0s - loss: 4.7400e-04 - val_loss: 4.5921e-06
Epoch 105/512
448/448 - 0s - loss: 4.5251e-04 - val_loss: 4.5712e-06
Epoch 106/512
448/448 - 0s - loss: 4.5797e-04 - val_loss: 4.5062e-06
Epoch 107/512
448/448 - 0s - loss: 4.4771e-04 - val_loss: 4.5134e-06
Epoch 108/512
448/448 - 0s - loss: 4.5080e-04 - val_loss: 4.4389e-06
Epoch 109/512
448/448 - 0s - loss: 4.3949e-04 - val_loss: 4.4315e-06
Epoch 110/512
448/448 - 0s - loss: 4.3935e-04 - val_loss: 4.4661e-06
Epoch 111/512
448/448 - 0s - loss: 4.4046e-04 - val_loss: 4.3003e-06
Epoch 112/512
448/448 - 0s - loss: 4.2472e-04 - val_loss: 4.2848e-06
Epoch 113/512
448/448 - 0s - loss: 4.2786e-04 - val_loss: 4.2964e-06
Epoch 114/512
448/448 - 0s - loss: 4.2598e-04 - val_loss: 4.2055e-06
Epoch 115/512
448/448 - 0s - loss: 4.1729e-04 - val_loss: 4.1391e-06
Epoch 116/512
448/448 - 0s - loss: 4.1504e-04 - val_loss: 4.0979e-06
Epoch 117/512
448/448 - 0s - loss: 4.1359e-04 - val_loss: 4.0350e-06
Epoch 118/512
448/448 - 0s - loss: 4.0783e-04 - val_loss: 3.9921e-06
Epoch 119/512
448/448 - 0s - loss: 3.9921e-04 - val_loss: 4.1023e-06
Epoch 120/512
448/448 - 0s - loss: 4.0656e-04 - val_loss: 4.1048e-06
Epoch 121/512
448/448 - 0s - loss: 4.0252e-04 - val_loss: 3.8999e-06
Epoch 122/512
448/448 - 0s - loss: 3.8651e-04 - val_loss: 3.8890e-06
Epoch 123/512
448/448 - 0s - loss: 3.8989e-04 - val_loss: 3.9309e-06
Epoch 124/512
448/448 - 0s - loss: 3.9132e-04 - val_loss: 3.8764e-06
Epoch 125/512
448/448 - 0s - loss: 3.7980e-04 - val_loss: 3.8196e-06
Epoch 126/512
448/448 - 0s - loss: 3.7925e-04 - val_loss: 3.8161e-06
Epoch 127/512
448/448 - 0s - loss: 3.7637e-04 - val_loss: 3.7784e-06
Epoch 128/512
448/448 - 0s - loss: 3.7399e-04 - val_loss: 3.6801e-06
Epoch 129/512
448/448 - 0s - loss: 3.6455e-04 - val_loss: 3.7278e-06
Epoch 130/512
448/448 - 0s - loss: 3.7022e-04 - val_loss: 3.6973e-06
Epoch 131/512
448/448 - 0s - loss: 3.6326e-04 - val_loss: 3.5915e-06
Epoch 132/512
448/448 - 0s - loss: 3.5765e-04 - val_loss: 3.5007e-06
Epoch 133/512
448/448 - 0s - loss: 3.4857e-04 - val_loss: 3.6619e-06
Epoch 134/512
448/448 - 0s - loss: 3.6115e-04 - val_loss: 3.6032e-06
Epoch 135/512
448/448 - 0s - loss: 3.5377e-04 - val_loss: 3.2966e-06
Epoch 136/512
448/448 - 0s - loss: 3.2962e-04 - val_loss: 3.4599e-06
Epoch 137/512
448/448 - 0s - loss: 3.5117e-04 - val_loss: 3.5458e-06
Epoch 138/512
448/448 - 0s - loss: 3.4592e-04 - val_loss: 3.3401e-06
Epoch 139/512
448/448 - 0s - loss: 3.2927e-04 - val_loss: 3.2710e-06
Epoch 140/512
448/448 - 0s - loss: 3.2913e-04 - val_loss: 3.3978e-06
Epoch 141/512
448/448 - 0s - loss: 3.3965e-04 - val_loss: 3.2535e-06
Epoch 142/512
448/448 - 0s - loss: 3.2146e-04 - val_loss: 3.1815e-06
Epoch 143/512
448/448 - 0s - loss: 3.2129e-04 - val_loss: 3.2312e-06
Epoch 144/512
448/448 - 0s - loss: 3.2400e-04 - val_loss: 3.1775e-06
Epoch 145/512
448/448 - 0s - loss: 3.1710e-04 - val_loss: 3.0979e-06
Epoch 146/512
448/448 - 0s - loss: 3.1033e-04 - val_loss: 3.1187e-06
Epoch 147/512
448/448 - 0s - loss: 3.1422e-04 - val_loss: 3.0825e-06
Epoch 148/512
448/448 - 0s - loss: 3.0598e-04 - val_loss: 3.0867e-06
Epoch 149/512
448/448 - 0s - loss: 3.0865e-04 - val_loss: 3.0235e-06
Epoch 150/512
448/448 - 0s - loss: 3.0031e-04 - val_loss: 2.9892e-06
Epoch 151/512
448/448 - 0s - loss: 3.0110e-04 - val_loss: 2.9362e-06
Epoch 152/512
448/448 - 0s - loss: 2.9474e-04 - val_loss: 2.9061e-06
Epoch 153/512
448/448 - 0s - loss: 2.9332e-04 - val_loss: 2.9177e-06
Epoch 154/512
448/448 - 0s - loss: 2.9233e-04 - val_loss: 2.8715e-06
Epoch 155/512
448/448 - 0s - loss: 2.8647e-04 - val_loss: 2.8449e-06
Epoch 156/512
448/448 - 0s - loss: 2.8526e-04 - val_loss: 2.8373e-06
Epoch 157/512
448/448 - 0s - loss: 2.8253e-04 - val_loss: 2.8259e-06
Epoch 158/512
448/448 - 0s - loss: 2.7906e-04 - val_loss: 2.7954e-06
Epoch 159/512
448/448 - 0s - loss: 2.7699e-04 - val_loss: 2.7326e-06
Epoch 160/512
448/448 - 0s - loss: 2.7249e-04 - val_loss: 2.7053e-06
Epoch 161/512
448/448 - 0s - loss: 2.6869e-04 - val_loss: 2.7518e-06
Epoch 162/512
448/448 - 0s - loss: 2.7302e-04 - val_loss: 2.6467e-06
Epoch 163/512
448/448 - 0s - loss: 2.6065e-04 - val_loss: 2.6517e-06
Epoch 164/512
448/448 - 0s - loss: 2.6515e-04 - val_loss: 2.6198e-06
Epoch 165/512
448/448 - 0s - loss: 2.6020e-04 - val_loss: 2.5438e-06
Epoch 166/512
448/448 - 0s - loss: 2.5402e-04 - val_loss: 2.5657e-06
Epoch 167/512
448/448 - 0s - loss: 2.5605e-04 - val_loss: 2.5525e-06
Epoch 168/512
448/448 - 0s - loss: 2.5585e-04 - val_loss: 2.3951e-06
Epoch 169/512
448/448 - 0s - loss: 2.4032e-04 - val_loss: 2.4660e-06
Epoch 170/512
448/448 - 0s - loss: 2.5119e-04 - val_loss: 2.5047e-06
Epoch 171/512
448/448 - 0s - loss: 2.4820e-04 - val_loss: 2.3358e-06
Epoch 172/512
448/448 - 0s - loss: 2.3353e-04 - val_loss: 2.3508e-06
Epoch 173/512
448/448 - 0s - loss: 2.3924e-04 - val_loss: 2.4301e-06
Epoch 174/512
448/448 - 0s - loss: 2.4094e-04 - val_loss: 2.3360e-06
Epoch 175/512
448/448 - 0s - loss: 2.3059e-04 - val_loss: 2.2680e-06
Epoch 176/512
448/448 - 0s - loss: 2.3007e-04 - val_loss: 2.2807e-06
Epoch 177/512
448/448 - 0s - loss: 2.2830e-04 - val_loss: 2.3231e-06
Epoch 178/512
448/448 - 0s - loss: 2.3006e-04 - val_loss: 2.2291e-06
Epoch 179/512
448/448 - 0s - loss: 2.2052e-04 - val_loss: 2.1809e-06
Epoch 180/512
448/448 - 0s - loss: 2.1907e-04 - val_loss: 2.2216e-06
Epoch 181/512
448/448 - 0s - loss: 2.2194e-04 - val_loss: 2.1514e-06
Epoch 182/512
448/448 - 0s - loss: 2.1520e-04 - val_loss: 2.0816e-06
Epoch 183/512
448/448 - 0s - loss: 2.0995e-04 - val_loss: 2.1274e-06
Epoch 184/512
448/448 - 0s - loss: 2.1429e-04 - val_loss: 2.1097e-06
Epoch 185/512
448/448 - 0s - loss: 2.0861e-04 - val_loss: 2.0502e-06
Epoch 186/512
448/448 - 0s - loss: 2.0464e-04 - val_loss: 2.0414e-06
Epoch 187/512
448/448 - 0s - loss: 2.0653e-04 - val_loss: 1.9610e-06
Epoch 188/512
448/448 - 0s - loss: 1.9657e-04 - val_loss: 1.9817e-06
Epoch 189/512
448/448 - 0s - loss: 2.0154e-04 - val_loss: 1.9754e-06
Epoch 190/512
448/448 - 0s - loss: 1.9717e-04 - val_loss: 1.9259e-06
Epoch 191/512
448/448 - 0s - loss: 1.9346e-04 - val_loss: 1.8902e-06
Epoch 192/512
448/448 - 0s - loss: 1.9073e-04 - val_loss: 1.9056e-06
Epoch 193/512
448/448 - 0s - loss: 1.9102e-04 - val_loss: 1.8710e-06
Epoch 194/512
448/448 - 0s - loss: 1.8625e-04 - val_loss: 1.8671e-06
Epoch 195/512
448/448 - 0s - loss: 1.8619e-04 - val_loss: 1.8370e-06
Epoch 196/512
448/448 - 0s - loss: 1.8182e-04 - val_loss: 1.8052e-06
Epoch 197/512
448/448 - 0s - loss: 1.8144e-04 - val_loss: 1.7428e-06
Epoch 198/512
448/448 - 0s - loss: 1.7536e-04 - val_loss: 1.7411e-06
Epoch 199/512
448/448 - 0s - loss: 1.7628e-04 - val_loss: 1.7570e-06
Epoch 200/512
448/448 - 0s - loss: 1.7584e-04 - val_loss: 1.7163e-06
Epoch 201/512
448/448 - 0s - loss: 1.7056e-04 - val_loss: 1.6688e-06
Epoch 202/512
448/448 - 0s - loss: 1.6773e-04 - val_loss: 1.6820e-06
Epoch 203/512
448/448 - 0s - loss: 1.6854e-04 - val_loss: 1.6548e-06
Epoch 204/512
448/448 - 0s - loss: 1.6454e-04 - val_loss: 1.6111e-06
Epoch 205/512
448/448 - 0s - loss: 1.6177e-04 - val_loss: 1.5724e-06
Epoch 206/512
448/448 - 0s - loss: 1.5925e-04 - val_loss: 1.5635e-06
Epoch 207/512
448/448 - 0s - loss: 1.5918e-04 - val_loss: 1.5208e-06
Epoch 208/512
448/448 - 0s - loss: 1.5382e-04 - val_loss: 1.5239e-06
Epoch 209/512
448/448 - 0s - loss: 1.5450e-04 - val_loss: 1.5183e-06
Epoch 210/512
448/448 - 0s - loss: 1.5147e-04 - val_loss: 1.5046e-06
Epoch 211/512
448/448 - 0s - loss: 1.5036e-04 - val_loss: 1.4673e-06
Epoch 212/512
448/448 - 0s - loss: 1.4628e-04 - val_loss: 1.4380e-06
Epoch 213/512
448/448 - 0s - loss: 1.4489e-04 - val_loss: 1.4405e-06
Epoch 214/512
448/448 - 0s - loss: 1.4376e-04 - val_loss: 1.4270e-06
Epoch 215/512
448/448 - 0s - loss: 1.4095e-04 - val_loss: 1.4106e-06
Epoch 216/512
448/448 - 0s - loss: 1.4140e-04 - val_loss: 1.3386e-06
Epoch 217/512
448/448 - 0s - loss: 1.3421e-04 - val_loss: 1.3215e-06
Epoch 218/512
448/448 - 0s - loss: 1.3393e-04 - val_loss: 1.3607e-06
Epoch 219/512
448/448 - 0s - loss: 1.3635e-04 - val_loss: 1.2985e-06
Epoch 220/512
448/448 - 0s - loss: 1.2899e-04 - val_loss: 1.2594e-06
Epoch 221/512
448/448 - 0s - loss: 1.2758e-04 - val_loss: 1.2680e-06
Epoch 222/512
448/448 - 0s - loss: 1.2730e-04 - val_loss: 1.2695e-06
Epoch 223/512
448/448 - 0s - loss: 1.2763e-04 - val_loss: 1.1729e-06
Epoch 224/512
448/448 - 0s - loss: 1.1845e-04 - val_loss: 1.1790e-06
Epoch 225/512
448/448 - 0s - loss: 1.2068e-04 - val_loss: 1.2293e-06
Epoch 226/512
448/448 - 0s - loss: 1.2190e-04 - val_loss: 1.2002e-06
Epoch 227/512
448/448 - 0s - loss: 1.1811e-04 - val_loss: 1.0974e-06
Epoch 228/512
448/448 - 0s - loss: 1.1117e-04 - val_loss: 1.0935e-06
Epoch 229/512
448/448 - 0s - loss: 1.1203e-04 - val_loss: 1.1559e-06
Epoch 230/512
448/448 - 0s - loss: 1.1602e-04 - val_loss: 1.0798e-06
Epoch 231/512
448/448 - 0s - loss: 1.0702e-04 - val_loss: 1.0198e-06
Epoch 232/512
448/448 - 0s - loss: 1.0462e-04 - val_loss: 1.0798e-06
Epoch 233/512
448/448 - 0s - loss: 1.0934e-04 - val_loss: 1.0444e-06
Epoch 234/512
448/448 - 0s - loss: 1.0344e-04 - val_loss: 9.7025e-07
Epoch 235/512
448/448 - 0s - loss: 9.8700e-05 - val_loss: 9.8761e-07
Epoch 236/512
448/448 - 0s - loss: 1.0117e-04 - val_loss: 9.9607e-07
Epoch 237/512
448/448 - 0s - loss: 9.9456e-05 - val_loss: 9.4320e-07
Epoch 238/512
448/448 - 0s - loss: 9.4436e-05 - val_loss: 9.3002e-07
Epoch 239/512
448/448 - 0s - loss: 9.4466e-05 - val_loss: 9.4532e-07
Epoch 240/512
448/448 - 0s - loss: 9.4756e-05 - val_loss: 9.0923e-07
Epoch 241/512
448/448 - 0s - loss: 9.0400e-05 - val_loss: 8.6502e-07
Epoch 242/512
448/448 - 0s - loss: 8.7475e-05 - val_loss: 8.7604e-07
Epoch 243/512
448/448 - 0s - loss: 8.8708e-05 - val_loss: 8.7859e-07
Epoch 244/512
448/448 - 0s - loss: 8.7567e-05 - val_loss: 8.2449e-07
Epoch 245/512
448/448 - 0s - loss: 8.2500e-05 - val_loss: 8.1069e-07
Epoch 246/512
448/448 - 0s - loss: 8.2903e-05 - val_loss: 8.0822e-07
Epoch 247/512
448/448 - 0s - loss: 8.1032e-05 - val_loss: 8.0057e-07
Epoch 248/512
448/448 - 0s - loss: 8.0578e-05 - val_loss: 7.5643e-07
Epoch 249/512
448/448 - 0s - loss: 7.6112e-05 - val_loss: 7.5861e-07
Epoch 250/512
448/448 - 0s - loss: 7.6718e-05 - val_loss: 7.5726e-07
Epoch 251/512
448/448 - 0s - loss: 7.5522e-05 - val_loss: 7.1045e-07
Epoch 252/512
448/448 - 0s - loss: 7.1799e-05 - val_loss: 6.9175e-07
Epoch 253/512
448/448 - 0s - loss: 7.0902e-05 - val_loss: 6.9985e-07
Epoch 254/512
448/448 - 0s - loss: 7.1225e-05 - val_loss: 6.6952e-07
Epoch 255/512
448/448 - 0s - loss: 6.7352e-05 - val_loss: 6.5601e-07
Epoch 256/512
448/448 - 0s - loss: 6.6780e-05 - val_loss: 6.5717e-07
Epoch 257/512
448/448 - 0s - loss: 6.6264e-05 - val_loss: 6.3977e-07
Epoch 258/512
448/448 - 0s - loss: 6.4118e-05 - val_loss: 6.0483e-07
Epoch 259/512
448/448 - 0s - loss: 6.0892e-05 - val_loss: 6.2127e-07
Epoch 260/512
448/448 - 0s - loss: 6.2918e-05 - val_loss: 6.0049e-07
Epoch 261/512
448/448 - 0s - loss: 5.9886e-05 - val_loss: 5.5232e-07
Epoch 262/512
448/448 - 0s - loss: 5.5699e-05 - val_loss: 5.8577e-07
Epoch 263/512
448/448 - 0s - loss: 5.9985e-05 - val_loss: 5.6304e-07
Epoch 264/512
448/448 - 0s - loss: 5.5717e-05 - val_loss: 5.0642e-07
Epoch 265/512
448/448 - 0s - loss: 5.1640e-05 - val_loss: 5.2612e-07
Epoch 266/512
448/448 - 0s - loss: 5.4497e-05 - val_loss: 5.3600e-07
Epoch 267/512
448/448 - 0s - loss: 5.3188e-05 - val_loss: 4.8541e-07
Epoch 268/512
448/448 - 0s - loss: 4.8411e-05 - val_loss: 4.8781e-07
Epoch 269/512
448/448 - 0s - loss: 5.0246e-05 - val_loss: 4.8671e-07
Epoch 270/512
448/448 - 0s - loss: 4.8558e-05 - val_loss: 4.6005e-07
Epoch 271/512
448/448 - 0s - loss: 4.6502e-05 - val_loss: 4.4488e-07
Epoch 272/512
448/448 - 0s - loss: 4.5497e-05 - val_loss: 4.4341e-07
Epoch 273/512
448/448 - 0s - loss: 4.5116e-05 - val_loss: 4.2457e-07
Epoch 274/512
448/448 - 0s - loss: 4.2611e-05 - val_loss: 4.2747e-07
Epoch 275/512
448/448 - 0s - loss: 4.3149e-05 - val_loss: 4.1737e-07
Epoch 276/512
448/448 - 0s - loss: 4.1614e-05 - val_loss: 3.8765e-07
Epoch 277/512
448/448 - 0s - loss: 3.9136e-05 - val_loss: 3.8014e-07
Epoch 278/512
448/448 - 0s - loss: 3.8637e-05 - val_loss: 3.9885e-07
Epoch 279/512
448/448 - 0s - loss: 4.0106e-05 - val_loss: 3.5820e-07
Epoch 280/512
448/448 - 0s - loss: 3.5529e-05 - val_loss: 3.4028e-07
Epoch 281/512
448/448 - 0s - loss: 3.5266e-05 - val_loss: 3.5433e-07
Epoch 282/512
448/448 - 0s - loss: 3.6126e-05 - val_loss: 3.4527e-07
Epoch 283/512
448/448 - 0s - loss: 3.4071e-05 - val_loss: 3.2612e-07
Epoch 284/512
448/448 - 0s - loss: 3.2804e-05 - val_loss: 3.1503e-07
Epoch 285/512
448/448 - 0s - loss: 3.2046e-05 - val_loss: 3.0915e-07
Epoch 286/512
448/448 - 0s - loss: 3.1451e-05 - val_loss: 3.0220e-07
Epoch 287/512
448/448 - 0s - loss: 3.0463e-05 - val_loss: 2.9113e-07
Epoch 288/512
448/448 - 0s - loss: 2.9410e-05 - val_loss: 2.8712e-07
Epoch 289/512
448/448 - 0s - loss: 2.9000e-05 - val_loss: 2.7212e-07
Epoch 290/512
448/448 - 0s - loss: 2.7397e-05 - val_loss: 2.6902e-07
Epoch 291/512
448/448 - 0s - loss: 2.7174e-05 - val_loss: 2.6612e-07
Epoch 292/512
448/448 - 0s - loss: 2.6565e-05 - val_loss: 2.5763e-07
Epoch 293/512
448/448 - 0s - loss: 2.5697e-05 - val_loss: 2.3746e-07
Epoch 294/512
448/448 - 0s - loss: 2.4115e-05 - val_loss: 2.3173e-07
Epoch 295/512
448/448 - 0s - loss: 2.4010e-05 - val_loss: 2.3002e-07
Epoch 296/512
448/448 - 0s - loss: 2.3393e-05 - val_loss: 2.2489e-07
Epoch 297/512
448/448 - 0s - loss: 2.2585e-05 - val_loss: 2.1833e-07
Epoch 298/512
448/448 - 0s - loss: 2.2117e-05 - val_loss: 2.0435e-07
Epoch 299/512
448/448 - 0s - loss: 2.0650e-05 - val_loss: 2.0340e-07
Epoch 300/512
448/448 - 0s - loss: 2.0805e-05 - val_loss: 1.9834e-07
Epoch 301/512
448/448 - 0s - loss: 2.0124e-05 - val_loss: 1.8207e-07
Epoch 302/512
448/448 - 0s - loss: 1.8541e-05 - val_loss: 1.8597e-07
Epoch 303/512
448/448 - 0s - loss: 1.9111e-05 - val_loss: 1.8302e-07
Epoch 304/512
448/448 - 0s - loss: 1.8218e-05 - val_loss: 1.6855e-07
Epoch 305/512
448/448 - 0s - loss: 1.7087e-05 - val_loss: 1.6397e-07
Epoch 306/512
448/448 - 0s - loss: 1.7013e-05 - val_loss: 1.5999e-07
Epoch 307/512
448/448 - 0s - loss: 1.6302e-05 - val_loss: 1.5754e-07
Epoch 308/512
448/448 - 0s - loss: 1.5909e-05 - val_loss: 1.5286e-07
Epoch 309/512
448/448 - 0s - loss: 1.5261e-05 - val_loss: 1.4830e-07
Epoch 310/512
448/448 - 0s - loss: 1.4863e-05 - val_loss: 1.4166e-07
Epoch 311/512
448/448 - 0s - loss: 1.4312e-05 - val_loss: 1.3386e-07
Epoch 312/512
448/448 - 0s - loss: 1.3703e-05 - val_loss: 1.2805e-07
Epoch 313/512
448/448 - 0s - loss: 1.3154e-05 - val_loss: 1.2961e-07
Epoch 314/512
448/448 - 0s - loss: 1.3248e-05 - val_loss: 1.2379e-07
Epoch 315/512
448/448 - 0s - loss: 1.2401e-05 - val_loss: 1.1526e-07
Epoch 316/512
448/448 - 0s - loss: 1.1761e-05 - val_loss: 1.1501e-07
Epoch 317/512
448/448 - 0s - loss: 1.1785e-05 - val_loss: 1.1243e-07
Epoch 318/512
448/448 - 0s - loss: 1.1361e-05 - val_loss: 1.0407e-07
Epoch 319/512
448/448 - 0s - loss: 1.0637e-05 - val_loss: 9.9576e-08
Epoch 320/512
448/448 - 0s - loss: 1.0298e-05 - val_loss: 1.0102e-07
Epoch 321/512
448/448 - 0s - loss: 1.0279e-05 - val_loss: 9.7854e-08
Epoch 322/512
448/448 - 0s - loss: 9.8255e-06 - val_loss: 8.8466e-08
Epoch 323/512
448/448 - 0s - loss: 9.0582e-06 - val_loss: 8.7514e-08
Epoch 324/512
448/448 - 0s - loss: 9.1124e-06 - val_loss: 8.7112e-08
Epoch 325/512
448/448 - 0s - loss: 8.9329e-06 - val_loss: 7.9432e-08
Epoch 326/512
448/448 - 0s - loss: 8.0326e-06 - val_loss: 7.9995e-08
Epoch 327/512
448/448 - 0s - loss: 8.2574e-06 - val_loss: 7.9022e-08
Epoch 328/512
448/448 - 0s - loss: 7.9261e-06 - val_loss: 7.2808e-08
Epoch 329/512
448/448 - 0s - loss: 7.3930e-06 - val_loss: 6.8047e-08
Epoch 330/512
448/448 - 0s - loss: 7.0664e-06 - val_loss: 6.9248e-08
Epoch 331/512
448/448 - 0s - loss: 7.1065e-06 - val_loss: 6.7746e-08
Epoch 332/512
448/448 - 0s - loss: 6.7977e-06 - val_loss: 6.2719e-08
Epoch 333/512
448/448 - 0s - loss: 6.3086e-06 - val_loss: 6.1571e-08
Epoch 334/512
448/448 - 0s - loss: 6.2899e-06 - val_loss: 5.9665e-08
Epoch 335/512
448/448 - 0s - loss: 6.0514e-06 - val_loss: 5.5644e-08
Epoch 336/512
448/448 - 0s - loss: 5.6557e-06 - val_loss: 5.3637e-08
Epoch 337/512
448/448 - 0s - loss: 5.5357e-06 - val_loss: 5.2389e-08
Epoch 338/512
448/448 - 0s - loss: 5.3602e-06 - val_loss: 4.9835e-08
Epoch 339/512
448/448 - 0s - loss: 5.0621e-06 - val_loss: 4.8853e-08
Epoch 340/512
448/448 - 0s - loss: 5.0005e-06 - val_loss: 4.5504e-08
Epoch 341/512
448/448 - 0s - loss: 4.6149e-06 - val_loss: 4.5108e-08
Epoch 342/512
448/448 - 0s - loss: 4.6430e-06 - val_loss: 4.3475e-08
Epoch 343/512
448/448 - 0s - loss: 4.3559e-06 - val_loss: 4.1470e-08
Epoch 344/512
448/448 - 0s - loss: 4.2110e-06 - val_loss: 3.8954e-08
Epoch 345/512
448/448 - 0s - loss: 4.0032e-06 - val_loss: 3.7088e-08
Epoch 346/512
448/448 - 0s - loss: 3.8109e-06 - val_loss: 3.7088e-08
Epoch 347/512
448/448 - 0s - loss: 3.7930e-06 - val_loss: 3.5682e-08
Epoch 348/512
448/448 - 0s - loss: 3.6215e-06 - val_loss: 3.2182e-08
Epoch 349/512
448/448 - 0s - loss: 3.2891e-06 - val_loss: 3.1692e-08
Epoch 350/512
448/448 - 0s - loss: 3.3291e-06 - val_loss: 3.1815e-08
Epoch 351/512
448/448 - 0s - loss: 3.2487e-06 - val_loss: 2.8826e-08
Epoch 352/512
448/448 - 0s - loss: 2.9406e-06 - val_loss: 2.7537e-08
Epoch 353/512
448/448 - 0s - loss: 2.8838e-06 - val_loss: 2.7752e-08
Epoch 354/512
448/448 - 0s - loss: 2.8532e-06 - val_loss: 2.6530e-08
Epoch 355/512
448/448 - 0s - loss: 2.7042e-06 - val_loss: 2.3699e-08
Epoch 356/512
448/448 - 0s - loss: 2.4607e-06 - val_loss: 2.3546e-08
Epoch 357/512
448/448 - 0s - loss: 2.4861e-06 - val_loss: 2.3811e-08
Epoch 358/512
448/448 - 0s - loss: 2.4328e-06 - val_loss: 2.1762e-08
Epoch 359/512
448/448 - 0s - loss: 2.2005e-06 - val_loss: 2.0859e-08
Epoch 360/512
448/448 - 0s - loss: 2.1727e-06 - val_loss: 2.0594e-08
Epoch 361/512
448/448 - 0s - loss: 2.1108e-06 - val_loss: 1.9234e-08
Epoch 362/512
448/448 - 0s - loss: 1.9831e-06 - val_loss: 1.7497e-08
Epoch 363/512
448/448 - 0s - loss: 1.8198e-06 - val_loss: 1.8127e-08
Epoch 364/512
448/448 - 0s - loss: 1.9039e-06 - val_loss: 1.7372e-08
Epoch 365/512
448/448 - 0s - loss: 1.7411e-06 - val_loss: 1.5896e-08
Epoch 366/512
448/448 - 0s - loss: 1.6507e-06 - val_loss: 1.5193e-08
Epoch 367/512
448/448 - 0s - loss: 1.5917e-06 - val_loss: 1.5079e-08
Epoch 368/512
448/448 - 0s - loss: 1.5664e-06 - val_loss: 1.4161e-08
Epoch 369/512
448/448 - 0s - loss: 1.4514e-06 - val_loss: 1.3420e-08
Epoch 370/512
448/448 - 0s - loss: 1.3951e-06 - val_loss: 1.3266e-08
Epoch 371/512
448/448 - 0s - loss: 1.3762e-06 - val_loss: 1.2302e-08
Epoch 372/512
448/448 - 0s - loss: 1.2660e-06 - val_loss: 1.1693e-08
Epoch 373/512
448/448 - 0s - loss: 1.2214e-06 - val_loss: 1.1558e-08
Epoch 374/512
448/448 - 0s - loss: 1.1963e-06 - val_loss: 1.1025e-08
Epoch 375/512
448/448 - 0s - loss: 1.1308e-06 - val_loss: 1.0254e-08
Epoch 376/512
448/448 - 0s - loss: 1.0563e-06 - val_loss: 1.0022e-08
Epoch 377/512
448/448 - 0s - loss: 1.0374e-06 - val_loss: 9.8925e-09
Epoch 378/512
448/448 - 0s - loss: 1.0080e-06 - val_loss: 9.1497e-09
Epoch 379/512
448/448 - 0s - loss: 9.2792e-07 - val_loss: 8.6040e-09
Epoch 380/512
448/448 - 0s - loss: 8.9257e-07 - val_loss: 8.3282e-09
Epoch 381/512
448/448 - 0s - loss: 8.7211e-07 - val_loss: 7.9317e-09
Epoch 382/512
448/448 - 0s - loss: 8.1796e-07 - val_loss: 7.5569e-09
Epoch 383/512
448/448 - 0s - loss: 7.8101e-07 - val_loss: 7.5038e-09
Epoch 384/512
448/448 - 0s - loss: 7.7443e-07 - val_loss: 6.8583e-09
Epoch 385/512
448/448 - 0s - loss: 7.0207e-07 - val_loss: 6.4291e-09
Epoch 386/512
448/448 - 0s - loss: 6.8119e-07 - val_loss: 6.2806e-09
Epoch 387/512
448/448 - 0s - loss: 6.5419e-07 - val_loss: 6.2080e-09
Epoch 388/512
448/448 - 0s - loss: 6.3734e-07 - val_loss: 5.8762e-09
Epoch 389/512
448/448 - 0s - loss: 6.0495e-07 - val_loss: 5.1884e-09
Epoch 390/512
448/448 - 0s - loss: 5.4149e-07 - val_loss: 5.2619e-09
Epoch 391/512
448/448 - 0s - loss: 5.5895e-07 - val_loss: 5.3036e-09
Epoch 392/512
448/448 - 0s - loss: 5.3981e-07 - val_loss: 4.6435e-09
Epoch 393/512
448/448 - 0s - loss: 4.7033e-07 - val_loss: 4.5123e-09
Epoch 394/512
448/448 - 0s - loss: 4.8005e-07 - val_loss: 4.4080e-09
Epoch 395/512
448/448 - 0s - loss: 4.5604e-07 - val_loss: 4.1382e-09
Epoch 396/512
448/448 - 0s - loss: 4.2574e-07 - val_loss: 3.9430e-09
Epoch 397/512
448/448 - 0s - loss: 4.1257e-07 - val_loss: 3.7900e-09
Epoch 398/512
448/448 - 0s - loss: 3.9317e-07 - val_loss: 3.6385e-09
Epoch 399/512
448/448 - 0s - loss: 3.7364e-07 - val_loss: 3.5225e-09
Epoch 400/512
448/448 - 0s - loss: 3.6077e-07 - val_loss: 3.3916e-09
Epoch 401/512
448/448 - 0s - loss: 3.4573e-07 - val_loss: 3.0639e-09
Epoch 402/512
448/448 - 0s - loss: 3.1738e-07 - val_loss: 2.8972e-09
Epoch 403/512
448/448 - 0s - loss: 3.0766e-07 - val_loss: 2.8895e-09
Epoch 404/512
448/448 - 0s - loss: 3.0109e-07 - val_loss: 2.7720e-09
Epoch 405/512
448/448 - 0s - loss: 2.8359e-07 - val_loss: 2.5588e-09
Epoch 406/512
448/448 - 0s - loss: 2.6528e-07 - val_loss: 2.4594e-09
Epoch 407/512
448/448 - 0s - loss: 2.5676e-07 - val_loss: 2.3551e-09
Epoch 408/512
448/448 - 0s - loss: 2.4403e-07 - val_loss: 2.2597e-09
Epoch 409/512
448/448 - 0s - loss: 2.3524e-07 - val_loss: 2.1318e-09
Epoch 410/512
448/448 - 0s - loss: 2.2008e-07 - val_loss: 2.0509e-09
Epoch 411/512
448/448 - 0s - loss: 2.1378e-07 - val_loss: 1.9199e-09
Epoch 412/512
448/448 - 0s - loss: 2.0034e-07 - val_loss: 1.8166e-09
Epoch 413/512
448/448 - 0s - loss: 1.8960e-07 - val_loss: 1.8019e-09
Epoch 414/512
448/448 - 0s - loss: 1.8754e-07 - val_loss: 1.7148e-09
Epoch 415/512
448/448 - 0s - loss: 1.7463e-07 - val_loss: 1.5796e-09
Epoch 416/512
448/448 - 0s - loss: 1.6406e-07 - val_loss: 1.5339e-09
Epoch 417/512
448/448 - 0s - loss: 1.5932e-07 - val_loss: 1.4863e-09
Epoch 418/512
448/448 - 0s - loss: 1.5347e-07 - val_loss: 1.3616e-09
Epoch 419/512
448/448 - 0s - loss: 1.4044e-07 - val_loss: 1.3076e-09
Epoch 420/512
448/448 - 0s - loss: 1.3759e-07 - val_loss: 1.2883e-09
Epoch 421/512
448/448 - 0s - loss: 1.3257e-07 - val_loss: 1.2070e-09
Epoch 422/512
448/448 - 0s - loss: 1.2349e-07 - val_loss: 1.1136e-09
Epoch 423/512
448/448 - 0s - loss: 1.1649e-07 - val_loss: 1.0745e-09
Epoch 424/512
448/448 - 0s - loss: 1.1309e-07 - val_loss: 1.0217e-09
Epoch 425/512
448/448 - 0s - loss: 1.0667e-07 - val_loss: 9.9926e-10
Epoch 426/512
448/448 - 0s - loss: 1.0381e-07 - val_loss: 9.3037e-10
Epoch 427/512
448/448 - 0s - loss: 9.6919e-08 - val_loss: 8.5325e-10
Epoch 428/512
448/448 - 0s - loss: 8.9371e-08 - val_loss: 8.6397e-10
Epoch 429/512
448/448 - 0s - loss: 9.1479e-08 - val_loss: 8.2308e-10
Epoch 430/512
448/448 - 0s - loss: 8.4036e-08 - val_loss: 7.5480e-10
Epoch 431/512
448/448 - 0s - loss: 7.8989e-08 - val_loss: 7.1787e-10
Epoch 432/512
448/448 - 0s - loss: 7.6077e-08 - val_loss: 6.9295e-10
Epoch 433/512
448/448 - 0s - loss: 7.2427e-08 - val_loss: 6.6650e-10
Epoch 434/512
448/448 - 0s - loss: 6.9591e-08 - val_loss: 6.3026e-10
Epoch 435/512
448/448 - 0s - loss: 6.5138e-08 - val_loss: 5.9202e-10
Epoch 436/512
448/448 - 0s - loss: 6.2023e-08 - val_loss: 5.7314e-10
Epoch 437/512
448/448 - 0s - loss: 5.9685e-08 - val_loss: 5.5600e-10
Epoch 438/512
448/448 - 0s - loss: 5.7044e-08 - val_loss: 5.3179e-10
Epoch 439/512
448/448 - 0s - loss: 5.4601e-08 - val_loss: 4.8292e-10
Epoch 440/512
448/448 - 0s - loss: 5.0013e-08 - val_loss: 4.6298e-10
Epoch 441/512
448/448 - 0s - loss: 4.9060e-08 - val_loss: 4.5327e-10
Epoch 442/512
448/448 - 0s - loss: 4.7222e-08 - val_loss: 4.3109e-10
Epoch 443/512
448/448 - 0s - loss: 4.3902e-08 - val_loss: 4.1181e-10
Epoch 444/512
448/448 - 0s - loss: 4.2360e-08 - val_loss: 3.9314e-10
Epoch 445/512
448/448 - 0s - loss: 4.0677e-08 - val_loss: 3.5343e-10
Epoch 446/512
448/448 - 0s - loss: 3.6955e-08 - val_loss: 3.3915e-10
Epoch 447/512
448/448 - 0s - loss: 3.6075e-08 - val_loss: 3.4701e-10
Epoch 448/512
448/448 - 0s - loss: 3.6143e-08 - val_loss: 3.2131e-10
Epoch 449/512
448/448 - 0s - loss: 3.2840e-08 - val_loss: 2.8668e-10
Epoch 450/512
448/448 - 0s - loss: 3.0008e-08 - val_loss: 2.8783e-10
Epoch 451/512
448/448 - 0s - loss: 3.0591e-08 - val_loss: 2.8048e-10
Epoch 452/512
448/448 - 0s - loss: 2.8950e-08 - val_loss: 2.5915e-10
Epoch 453/512
448/448 - 0s - loss: 2.6993e-08 - val_loss: 2.3931e-10
Epoch 454/512
448/448 - 0s - loss: 2.5192e-08 - val_loss: 2.3309e-10
Epoch 455/512
448/448 - 0s - loss: 2.4706e-08 - val_loss: 2.2825e-10
Epoch 456/512
448/448 - 0s - loss: 2.3676e-08 - val_loss: 2.2070e-10
Epoch 457/512
448/448 - 0s - loss: 2.2526e-08 - val_loss: 2.0664e-10
Epoch 458/512
448/448 - 0s - loss: 2.1270e-08 - val_loss: 1.9027e-10
Epoch 459/512
448/448 - 0s - loss: 1.9870e-08 - val_loss: 1.8401e-10
Epoch 460/512
448/448 - 0s - loss: 1.9265e-08 - val_loss: 1.8324e-10
Epoch 461/512
448/448 - 0s - loss: 1.9109e-08 - val_loss: 1.6575e-10
Epoch 462/512
448/448 - 0s - loss: 1.7132e-08 - val_loss: 1.5455e-10
Epoch 463/512
448/448 - 0s - loss: 1.6177e-08 - val_loss: 1.5592e-10
Epoch 464/512
448/448 - 0s - loss: 1.6331e-08 - val_loss: 1.5193e-10
Epoch 465/512
448/448 - 0s - loss: 1.5548e-08 - val_loss: 1.3790e-10
Epoch 466/512
448/448 - 0s - loss: 1.4085e-08 - val_loss: 1.3011e-10
Epoch 467/512
448/448 - 0s - loss: 1.3736e-08 - val_loss: 1.2696e-10
Epoch 468/512
448/448 - 0s - loss: 1.3213e-08 - val_loss: 1.2250e-10
Epoch 469/512
448/448 - 0s - loss: 1.2814e-08 - val_loss: 1.1524e-10
Epoch 470/512
448/448 - 0s - loss: 1.1901e-08 - val_loss: 1.0649e-10
Epoch 471/512
448/448 - 0s - loss: 1.1164e-08 - val_loss: 1.0632e-10
Epoch 472/512
448/448 - 0s - loss: 1.1195e-08 - val_loss: 1.0060e-10
Epoch 473/512
448/448 - 0s - loss: 1.0426e-08 - val_loss: 9.3981e-11
Epoch 474/512
448/448 - 0s - loss: 9.8281e-09 - val_loss: 8.9527e-11
Epoch 475/512
448/448 - 0s - loss: 9.2992e-09 - val_loss: 8.9525e-11
Epoch 476/512
448/448 - 0s - loss: 9.2803e-09 - val_loss: 8.6651e-11
Epoch 477/512
448/448 - 0s - loss: 8.8228e-09 - val_loss: 8.1245e-11
Epoch 478/512
448/448 - 0s - loss: 8.3185e-09 - val_loss: 7.4949e-11
Epoch 479/512
448/448 - 0s - loss: 7.7320e-09 - val_loss: 7.3206e-11
Epoch 480/512
448/448 - 0s - loss: 7.6608e-09 - val_loss: 7.0529e-11
Epoch 481/512
448/448 - 0s - loss: 7.2533e-09 - val_loss: 6.7603e-11
Epoch 482/512
448/448 - 0s - loss: 6.9406e-09 - val_loss: 6.4492e-11
Epoch 483/512
448/448 - 0s - loss: 6.6279e-09 - val_loss: 6.1981e-11
Epoch 484/512
448/448 - 0s - loss: 6.4228e-09 - val_loss: 5.8325e-11
Epoch 485/512
448/448 - 0s - loss: 5.9556e-09 - val_loss: 5.6853e-11
Epoch 486/512
448/448 - 0s - loss: 5.9058e-09 - val_loss: 5.4810e-11
Epoch 487/512
448/448 - 0s - loss: 5.5717e-09 - val_loss: 5.3259e-11
Epoch 488/512
448/448 - 0s - loss: 5.4587e-09 - val_loss: 4.9838e-11
Epoch 489/512
448/448 - 0s - loss: 5.0572e-09 - val_loss: 4.6581e-11
Epoch 490/512
448/448 - 0s - loss: 4.8061e-09 - val_loss: 4.5594e-11
Epoch 491/512
448/448 - 0s - loss: 4.7556e-09 - val_loss: 4.4351e-11
Epoch 492/512
448/448 - 0s - loss: 4.5681e-09 - val_loss: 4.2618e-11
Epoch 493/512
448/448 - 0s - loss: 4.3797e-09 - val_loss: 3.9797e-11
Epoch 494/512
448/448 - 0s - loss: 4.1173e-09 - val_loss: 3.8469e-11
Epoch 495/512
448/448 - 0s - loss: 3.9730e-09 - val_loss: 3.7263e-11
Epoch 496/512
448/448 - 0s - loss: 3.8036e-09 - val_loss: 3.6769e-11
Epoch 497/512
448/448 - 0s - loss: 3.7402e-09 - val_loss: 3.6032e-11
Epoch 498/512
448/448 - 0s - loss: 3.6476e-09 - val_loss: 3.3147e-11
Epoch 499/512
448/448 - 0s - loss: 3.3489e-09 - val_loss: 3.0864e-11
Epoch 500/512
448/448 - 0s - loss: 3.1912e-09 - val_loss: 3.0431e-11
Epoch 501/512
448/448 - 0s - loss: 3.1517e-09 - val_loss: 3.0330e-11
Epoch 502/512
448/448 - 0s - loss: 3.1368e-09 - val_loss: 2.8637e-11
Epoch 503/512
448/448 - 0s - loss: 2.9221e-09 - val_loss: 2.6190e-11
Epoch 504/512
448/448 - 0s - loss: 2.6591e-09 - val_loss: 2.6322e-11
Epoch 505/512
448/448 - 0s - loss: 2.7511e-09 - val_loss: 2.5867e-11
Epoch 506/512
448/448 - 0s - loss: 2.6595e-09 - val_loss: 2.4913e-11
Epoch 507/512
448/448 - 0s - loss: 2.5323e-09 - val_loss: 2.3278e-11
Epoch 508/512
448/448 - 0s - loss: 2.3916e-09 - val_loss: 2.2099e-11
Epoch 509/512
448/448 - 0s - loss: 2.2821e-09 - val_loss: 2.1802e-11
Epoch 510/512
448/448 - 0s - loss: 2.2664e-09 - val_loss: 2.1769e-11
Epoch 511/512
448/448 - 0s - loss: 2.2295e-09 - val_loss: 2.1038e-11
Epoch 512/512
448/448 - 0s - loss: 2.1390e-09 - val_loss: 1.9851e-11
2024-04-15 18:35:28.756896: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
Train on 448 samples, validate on 448 samples
Epoch 1/512

Epoch 00001: val_loss improved from inf to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.8159e-09 - val_loss: 1.6379e-09
Epoch 2/512

Epoch 00002: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6896e-09 - val_loss: 1.6877e-09
Epoch 3/512

Epoch 00003: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7715e-09 - val_loss: 1.8010e-09
Epoch 4/512

Epoch 00004: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.8790e-09 - val_loss: 1.7933e-09
Epoch 5/512

Epoch 00005: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.8031e-09 - val_loss: 1.6245e-09
Epoch 6/512

Epoch 00006: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.6218e-09 - val_loss: 1.5116e-09
Epoch 7/512

Epoch 00007: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.5340e-09 - val_loss: 1.4704e-09
Epoch 8/512

Epoch 00008: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5180e-09 - val_loss: 1.4749e-09
Epoch 9/512

Epoch 00009: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.5129e-09 - val_loss: 1.4658e-09
Epoch 10/512

Epoch 00010: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.4860e-09 - val_loss: 1.3874e-09
Epoch 11/512

Epoch 00011: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.4022e-09 - val_loss: 1.3027e-09
Epoch 12/512

Epoch 00012: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.3186e-09 - val_loss: 1.2642e-09
Epoch 13/512

Epoch 00013: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.2949e-09 - val_loss: 1.2628e-09
Epoch 14/512

Epoch 00014: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.2903e-09 - val_loss: 1.2296e-09
Epoch 15/512

Epoch 00015: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.2533e-09 - val_loss: 1.1909e-09
Epoch 16/512

Epoch 00016: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.2062e-09 - val_loss: 1.1459e-09
Epoch 17/512

Epoch 00017: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.1655e-09 - val_loss: 1.0863e-09
Epoch 18/512

Epoch 00018: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.1035e-09 - val_loss: 1.0637e-09
Epoch 19/512

Epoch 00019: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.0878e-09 - val_loss: 1.0520e-09
Epoch 20/512

Epoch 00020: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.0760e-09 - val_loss: 1.0408e-09
Epoch 21/512

Epoch 00021: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.0549e-09 - val_loss: 1.0073e-09
Epoch 22/512

Epoch 00022: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.0162e-09 - val_loss: 9.6705e-10
Epoch 23/512

Epoch 00023: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 9.7214e-10 - val_loss: 9.1828e-10
Epoch 24/512

Epoch 00024: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 9.3044e-10 - val_loss: 8.9892e-10
Epoch 25/512

Epoch 00025: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 9.2246e-10 - val_loss: 8.8153e-10
Epoch 26/512

Epoch 00026: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 9.0315e-10 - val_loss: 8.6164e-10
Epoch 27/512

Epoch 00027: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 8.7684e-10 - val_loss: 8.3992e-10
Epoch 28/512

Epoch 00028: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 8.4691e-10 - val_loss: 8.0628e-10
Epoch 29/512

Epoch 00029: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 8.1637e-10 - val_loss: 7.9396e-10
Epoch 30/512

Epoch 00030: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 8.0981e-10 - val_loss: 7.8570e-10
Epoch 31/512

Epoch 00031: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 7.9501e-10 - val_loss: 7.5117e-10
Epoch 32/512

Epoch 00032: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 7.5941e-10 - val_loss: 7.2832e-10
Epoch 33/512

Epoch 00033: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 7.4230e-10 - val_loss: 7.1182e-10
Epoch 34/512

Epoch 00034: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 7.2980e-10 - val_loss: 6.9893e-10
Epoch 35/512

Epoch 00035: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 7.1356e-10 - val_loss: 6.8196e-10
Epoch 36/512

Epoch 00036: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 6.9234e-10 - val_loss: 6.6758e-10
Epoch 37/512

Epoch 00037: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 6.7343e-10 - val_loss: 6.4658e-10
Epoch 38/512

Epoch 00038: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 6.5329e-10 - val_loss: 6.2589e-10
Epoch 39/512

Epoch 00039: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 6.4000e-10 - val_loss: 6.0840e-10
Epoch 40/512

Epoch 00040: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 6.1314e-10 - val_loss: 5.9658e-10
Epoch 41/512

Epoch 00041: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.1139e-10 - val_loss: 5.9941e-10
Epoch 42/512

Epoch 00042: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 6.0796e-10 - val_loss: 5.8906e-10
Epoch 43/512

Epoch 00043: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 6.0119e-10 - val_loss: 5.7121e-10
Epoch 44/512

Epoch 00044: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 5.7670e-10 - val_loss: 5.5594e-10
Epoch 45/512

Epoch 00045: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 5.6007e-10 - val_loss: 5.3806e-10
Epoch 46/512

Epoch 00046: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 5.3991e-10 - val_loss: 5.1480e-10
Epoch 47/512

Epoch 00047: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.2556e-10 - val_loss: 5.1708e-10
Epoch 48/512

Epoch 00048: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 5.2523e-10 - val_loss: 5.0539e-10
Epoch 49/512

Epoch 00049: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 5.0970e-10 - val_loss: 4.9936e-10
Epoch 50/512

Epoch 00050: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 4.9980e-10 - val_loss: 4.8250e-10
Epoch 51/512

Epoch 00051: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 4.9176e-10 - val_loss: 4.6930e-10
Epoch 52/512

Epoch 00052: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 4.7040e-10 - val_loss: 4.5802e-10
Epoch 53/512

Epoch 00053: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 4.6456e-10 - val_loss: 4.5049e-10
Epoch 54/512

Epoch 00054: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 4.5639e-10 - val_loss: 4.4397e-10
Epoch 55/512

Epoch 00055: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 4.5250e-10 - val_loss: 4.4091e-10
Epoch 56/512

Epoch 00056: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 4.4404e-10 - val_loss: 4.2822e-10
Epoch 57/512

Epoch 00057: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 4.3356e-10 - val_loss: 4.1970e-10
Epoch 58/512

Epoch 00058: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 4.1986e-10 - val_loss: 4.1083e-10
Epoch 59/512

Epoch 00059: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 4.1466e-10 - val_loss: 3.9625e-10
Epoch 60/512

Epoch 00060: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 4.0109e-10 - val_loss: 3.9049e-10
Epoch 61/512

Epoch 00061: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.9429e-10 - val_loss: 3.8100e-10
Epoch 62/512

Epoch 00062: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.8818e-10 - val_loss: 3.8051e-10
Epoch 63/512

Epoch 00063: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.8774e-10 - val_loss: 3.7345e-10
Epoch 64/512

Epoch 00064: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.7829e-10 - val_loss: 3.6115e-10
Epoch 65/512

Epoch 00065: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.6730e-10 - val_loss: 3.5523e-10
Epoch 66/512

Epoch 00066: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.5975e-10 - val_loss: 3.4804e-10
Epoch 67/512

Epoch 00067: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.5199e-10 - val_loss: 3.3386e-10
Epoch 68/512

Epoch 00068: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.3630e-10 - val_loss: 3.3668e-10
Epoch 69/512

Epoch 00069: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.4035e-10 - val_loss: 3.3173e-10
Epoch 70/512

Epoch 00070: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.4131e-10 - val_loss: 3.3706e-10
Epoch 71/512

Epoch 00071: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.3874e-10 - val_loss: 3.2497e-10
Epoch 72/512

Epoch 00072: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.2762e-10 - val_loss: 3.1466e-10
Epoch 73/512

Epoch 00073: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.1542e-10 - val_loss: 3.0983e-10
Epoch 74/512

Epoch 00074: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.1839e-10 - val_loss: 3.0826e-10
Epoch 75/512

Epoch 00075: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.1192e-10 - val_loss: 3.0758e-10
Epoch 76/512

Epoch 00076: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.1292e-10 - val_loss: 3.0139e-10
Epoch 77/512

Epoch 00077: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.0010e-10 - val_loss: 2.8948e-10
Epoch 78/512

Epoch 00078: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.8973e-10 - val_loss: 2.7834e-10
Epoch 79/512

Epoch 00079: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.7649e-10 - val_loss: 2.6702e-10
Epoch 80/512

Epoch 00080: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.7222e-10 - val_loss: 2.6568e-10
Epoch 81/512

Epoch 00081: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.6999e-10 - val_loss: 2.6962e-10
Epoch 82/512

Epoch 00082: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.7217e-10 - val_loss: 2.6391e-10
Epoch 83/512

Epoch 00083: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.6646e-10 - val_loss: 2.6657e-10
Epoch 84/512

Epoch 00084: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.7191e-10 - val_loss: 2.6504e-10
Epoch 85/512

Epoch 00085: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.6888e-10 - val_loss: 2.6064e-10
Epoch 86/512

Epoch 00086: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.6010e-10 - val_loss: 2.5224e-10
Epoch 87/512

Epoch 00087: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.5222e-10 - val_loss: 2.4103e-10
Epoch 88/512

Epoch 00088: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.3800e-10 - val_loss: 2.2782e-10
Epoch 89/512

Epoch 00089: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.3238e-10 - val_loss: 2.2624e-10
Epoch 90/512

Epoch 00090: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.2761e-10 - val_loss: 2.2591e-10
Epoch 91/512

Epoch 00091: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2978e-10 - val_loss: 2.2843e-10
Epoch 92/512

Epoch 00092: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.3260e-10 - val_loss: 2.2446e-10
Epoch 93/512

Epoch 00093: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2775e-10 - val_loss: 2.2688e-10
Epoch 94/512

Epoch 00094: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.3125e-10 - val_loss: 2.2533e-10
Epoch 95/512

Epoch 00095: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.2122e-10 - val_loss: 2.1172e-10
Epoch 96/512

Epoch 00096: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.1199e-10 - val_loss: 2.0619e-10
Epoch 97/512

Epoch 00097: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.0521e-10 - val_loss: 1.9724e-10
Epoch 98/512

Epoch 00098: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9904e-10 - val_loss: 2.0039e-10
Epoch 99/512

Epoch 00099: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0335e-10 - val_loss: 1.9882e-10
Epoch 100/512

Epoch 00100: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0162e-10 - val_loss: 1.9996e-10
Epoch 101/512

Epoch 00101: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0343e-10 - val_loss: 2.0248e-10
Epoch 102/512

Epoch 00102: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.0179e-10 - val_loss: 1.9335e-10
Epoch 103/512

Epoch 00103: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.9664e-10 - val_loss: 1.9207e-10
Epoch 104/512

Epoch 00104: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.9368e-10 - val_loss: 1.8147e-10
Epoch 105/512

Epoch 00105: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.8059e-10 - val_loss: 1.7677e-10
Epoch 106/512

Epoch 00106: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.8179e-10 - val_loss: 1.8316e-10
Epoch 107/512

Epoch 00107: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.8617e-10 - val_loss: 1.7833e-10
Epoch 108/512

Epoch 00108: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.7755e-10 - val_loss: 1.7334e-10
Epoch 109/512

Epoch 00109: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7560e-10 - val_loss: 1.7736e-10
Epoch 110/512

Epoch 00110: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.7763e-10 - val_loss: 1.7213e-10
Epoch 111/512

Epoch 00111: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7388e-10 - val_loss: 1.7416e-10
Epoch 112/512

Epoch 00112: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7852e-10 - val_loss: 1.7524e-10
Epoch 113/512

Epoch 00113: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.7385e-10 - val_loss: 1.6353e-10
Epoch 114/512

Epoch 00114: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.6436e-10 - val_loss: 1.6056e-10
Epoch 115/512

Epoch 00115: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6558e-10 - val_loss: 1.6885e-10
Epoch 116/512

Epoch 00116: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.6833e-10 - val_loss: 1.5781e-10
Epoch 117/512

Epoch 00117: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.5757e-10 - val_loss: 1.5559e-10
Epoch 118/512

Epoch 00118: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6051e-10 - val_loss: 1.5824e-10
Epoch 119/512

Epoch 00119: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.5645e-10 - val_loss: 1.4940e-10
Epoch 120/512

Epoch 00120: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.4970e-10 - val_loss: 1.4633e-10
Epoch 121/512

Epoch 00121: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4961e-10 - val_loss: 1.5160e-10
Epoch 122/512

Epoch 00122: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5214e-10 - val_loss: 1.4688e-10
Epoch 123/512

Epoch 00123: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.4709e-10 - val_loss: 1.4134e-10
Epoch 124/512

Epoch 00124: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4282e-10 - val_loss: 1.4510e-10
Epoch 125/512

Epoch 00125: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4814e-10 - val_loss: 1.4674e-10
Epoch 126/512

Epoch 00126: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4780e-10 - val_loss: 1.4259e-10
Epoch 127/512

Epoch 00127: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.4178e-10 - val_loss: 1.3800e-10
Epoch 128/512

Epoch 00128: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4010e-10 - val_loss: 1.3820e-10
Epoch 129/512

Epoch 00129: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.3842e-10 - val_loss: 1.3537e-10
Epoch 130/512

Epoch 00130: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.3512e-10 - val_loss: 1.3137e-10
Epoch 131/512

Epoch 00131: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3221e-10 - val_loss: 1.3213e-10
Epoch 132/512

Epoch 00132: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3304e-10 - val_loss: 1.3187e-10
Epoch 133/512

Epoch 00133: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3353e-10 - val_loss: 1.3146e-10
Epoch 134/512

Epoch 00134: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.3305e-10 - val_loss: 1.3013e-10
Epoch 135/512

Epoch 00135: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3061e-10 - val_loss: 1.3150e-10
Epoch 136/512

Epoch 00136: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3306e-10 - val_loss: 1.3016e-10
Epoch 137/512

Epoch 00137: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.2898e-10 - val_loss: 1.2137e-10
Epoch 138/512

Epoch 00138: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.2048e-10 - val_loss: 1.1754e-10
Epoch 139/512

Epoch 00139: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1866e-10 - val_loss: 1.1830e-10
Epoch 140/512

Epoch 00140: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.1929e-10 - val_loss: 1.1534e-10
Epoch 141/512

Epoch 00141: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.1528e-10 - val_loss: 1.1478e-10
Epoch 142/512

Epoch 00142: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.1598e-10 - val_loss: 1.1267e-10
Epoch 143/512

Epoch 00143: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.1365e-10 - val_loss: 1.0926e-10
Epoch 144/512

Epoch 00144: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.0971e-10 - val_loss: 1.0822e-10
Epoch 145/512

Epoch 00145: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0990e-10 - val_loss: 1.0942e-10
Epoch 146/512

Epoch 00146: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1044e-10 - val_loss: 1.0905e-10
Epoch 147/512

Epoch 00147: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.0974e-10 - val_loss: 1.0760e-10
Epoch 148/512

Epoch 00148: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.0675e-10 - val_loss: 1.0553e-10
Epoch 149/512

Epoch 00149: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0809e-10 - val_loss: 1.0889e-10
Epoch 150/512

Epoch 00150: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0867e-10 - val_loss: 1.0606e-10
Epoch 151/512

Epoch 00151: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.0600e-10 - val_loss: 1.0247e-10
Epoch 152/512

Epoch 00152: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.0276e-10 - val_loss: 9.8822e-11
Epoch 153/512

Epoch 00153: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0026e-10 - val_loss: 9.8829e-11
Epoch 154/512

Epoch 00154: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 9.9993e-11 - val_loss: 9.8023e-11
Epoch 155/512

Epoch 00155: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.8505e-11 - val_loss: 9.8509e-11
Epoch 156/512

Epoch 00156: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.9198e-11 - val_loss: 1.0004e-10
Epoch 157/512

Epoch 00157: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 9.9142e-11 - val_loss: 9.4411e-11
Epoch 158/512

Epoch 00158: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.5960e-11 - val_loss: 9.5083e-11
Epoch 159/512

Epoch 00159: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 9.5204e-11 - val_loss: 9.4230e-11
Epoch 160/512

Epoch 00160: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.7015e-11 - val_loss: 9.8229e-11
Epoch 161/512

Epoch 00161: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.8878e-11 - val_loss: 9.6980e-11
Epoch 162/512

Epoch 00162: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 9.4239e-11 - val_loss: 8.6580e-11
Epoch 163/512

Epoch 00163: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 8.5175e-11 - val_loss: 8.2765e-11
Epoch 164/512

Epoch 00164: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.4263e-11 - val_loss: 8.7092e-11
Epoch 165/512

Epoch 00165: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.9557e-11 - val_loss: 9.2011e-11
Epoch 166/512

Epoch 00166: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.2963e-11 - val_loss: 9.2505e-11
Epoch 167/512

Epoch 00167: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.1819e-11 - val_loss: 8.5361e-11
Epoch 168/512

Epoch 00168: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 8.3492e-11 - val_loss: 8.1490e-11
Epoch 169/512

Epoch 00169: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.2351e-11 - val_loss: 8.3199e-11
Epoch 170/512

Epoch 00170: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.3731e-11 - val_loss: 8.1827e-11
Epoch 171/512

Epoch 00171: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.3140e-11 - val_loss: 8.4419e-11
Epoch 172/512

Epoch 00172: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.7190e-11 - val_loss: 8.6182e-11
Epoch 173/512

Epoch 00173: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 8.5304e-11 - val_loss: 8.1127e-11
Epoch 174/512

Epoch 00174: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 7.9920e-11 - val_loss: 7.6496e-11
Epoch 175/512

Epoch 00175: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.8552e-11 - val_loss: 8.3017e-11
Epoch 176/512

Epoch 00176: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.5113e-11 - val_loss: 8.4789e-11
Epoch 177/512

Epoch 00177: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.6457e-11 - val_loss: 8.7839e-11
Epoch 178/512

Epoch 00178: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.7791e-11 - val_loss: 8.3693e-11
Epoch 179/512

Epoch 00179: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 8.0815e-11 - val_loss: 7.5399e-11
Epoch 180/512

Epoch 00180: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 7.4298e-11 - val_loss: 7.0648e-11
Epoch 181/512

Epoch 00181: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.1807e-11 - val_loss: 7.3664e-11
Epoch 182/512

Epoch 00182: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.4932e-11 - val_loss: 7.5354e-11
Epoch 183/512

Epoch 00183: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.6786e-11 - val_loss: 7.8282e-11
Epoch 184/512

Epoch 00184: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.0582e-11 - val_loss: 8.3616e-11
Epoch 185/512

Epoch 00185: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.3610e-11 - val_loss: 7.7689e-11
Epoch 186/512

Epoch 00186: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 7.5490e-11 - val_loss: 6.9110e-11
Epoch 187/512

Epoch 00187: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 6.7406e-11 - val_loss: 6.3747e-11
Epoch 188/512

Epoch 00188: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.5178e-11 - val_loss: 6.7832e-11
Epoch 189/512

Epoch 00189: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.1391e-11 - val_loss: 7.3579e-11
Epoch 190/512

Epoch 00190: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.5573e-11 - val_loss: 7.7309e-11
Epoch 191/512

Epoch 00191: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.8470e-11 - val_loss: 7.6982e-11
Epoch 192/512

Epoch 00192: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.4415e-11 - val_loss: 6.8288e-11
Epoch 193/512

Epoch 00193: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 6.5975e-11 - val_loss: 6.0632e-11
Epoch 194/512

Epoch 00194: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 5.9567e-11 - val_loss: 5.7806e-11
Epoch 195/512

Epoch 00195: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.8472e-11 - val_loss: 6.1008e-11
Epoch 196/512

Epoch 00196: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.5403e-11 - val_loss: 7.0625e-11
Epoch 197/512

Epoch 00197: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.2784e-11 - val_loss: 7.6538e-11
Epoch 198/512

Epoch 00198: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.7170e-11 - val_loss: 7.7410e-11
Epoch 199/512

Epoch 00199: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.7572e-11 - val_loss: 7.1287e-11
Epoch 200/512

Epoch 00200: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.8392e-11 - val_loss: 6.3751e-11
Epoch 201/512

Epoch 00201: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.2025e-11 - val_loss: 5.7868e-11
Epoch 202/512

Epoch 00202: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 5.6893e-11 - val_loss: 5.3293e-11
Epoch 203/512

Epoch 00203: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.4681e-11 - val_loss: 5.8287e-11
Epoch 204/512

Epoch 00204: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.0787e-11 - val_loss: 6.4658e-11
Epoch 205/512

Epoch 00205: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.7023e-11 - val_loss: 6.9811e-11
Epoch 206/512

Epoch 00206: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.0912e-11 - val_loss: 7.1424e-11
Epoch 207/512

Epoch 00207: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.9943e-11 - val_loss: 6.4292e-11
Epoch 208/512

Epoch 00208: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.2835e-11 - val_loss: 5.9122e-11
Epoch 209/512

Epoch 00209: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 5.7505e-11 - val_loss: 5.3285e-11
Epoch 210/512

Epoch 00210: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 5.3433e-11 - val_loss: 5.2523e-11
Epoch 211/512

Epoch 00211: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.3205e-11 - val_loss: 5.6166e-11
Epoch 212/512

Epoch 00212: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.9034e-11 - val_loss: 6.2414e-11
Epoch 213/512

Epoch 00213: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.5081e-11 - val_loss: 6.6517e-11
Epoch 214/512

Epoch 00214: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.7890e-11 - val_loss: 6.8049e-11
Epoch 215/512

Epoch 00215: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.8196e-11 - val_loss: 6.4194e-11
Epoch 216/512

Epoch 00216: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.1700e-11 - val_loss: 5.5923e-11
Epoch 217/512

Epoch 00217: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 5.4896e-11 - val_loss: 5.2077e-11
Epoch 218/512

Epoch 00218: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 5.0920e-11 - val_loss: 4.6963e-11
Epoch 219/512

Epoch 00219: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 4.7117e-11 - val_loss: 4.6024e-11
Epoch 220/512

Epoch 00220: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 4.6034e-11 - val_loss: 4.5090e-11
Epoch 221/512

Epoch 00221: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.6740e-11 - val_loss: 5.1073e-11
Epoch 222/512

Epoch 00222: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.2884e-11 - val_loss: 5.6438e-11
Epoch 223/512

Epoch 00223: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.9328e-11 - val_loss: 6.4920e-11
Epoch 224/512

Epoch 00224: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.4771e-11 - val_loss: 6.2801e-11
Epoch 225/512

Epoch 00225: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.1526e-11 - val_loss: 5.7010e-11
Epoch 226/512

Epoch 00226: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.5214e-11 - val_loss: 5.0903e-11
Epoch 227/512

Epoch 00227: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.9815e-11 - val_loss: 4.8345e-11
Epoch 228/512

Epoch 00228: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.8970e-11 - val_loss: 4.7441e-11
Epoch 229/512

Epoch 00229: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.6710e-11 - val_loss: 4.6071e-11
Epoch 230/512

Epoch 00230: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 4.5902e-11 - val_loss: 4.4884e-11
Epoch 231/512

Epoch 00231: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.5126e-11 - val_loss: 4.7710e-11
Epoch 232/512

Epoch 00232: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.0301e-11 - val_loss: 5.4617e-11
Epoch 233/512

Epoch 00233: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.7159e-11 - val_loss: 6.1885e-11
Epoch 234/512

Epoch 00234: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.2746e-11 - val_loss: 6.1622e-11
Epoch 235/512

Epoch 00235: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.8152e-11 - val_loss: 5.1618e-11
Epoch 236/512

Epoch 00236: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.0199e-11 - val_loss: 4.6541e-11
Epoch 237/512

Epoch 00237: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 4.5326e-11 - val_loss: 4.2358e-11
Epoch 238/512

Epoch 00238: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 4.1633e-11 - val_loss: 3.9750e-11
Epoch 239/512

Epoch 00239: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.9838e-11 - val_loss: 4.1215e-11
Epoch 240/512

Epoch 00240: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.1737e-11 - val_loss: 4.2039e-11
Epoch 241/512

Epoch 00241: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.3605e-11 - val_loss: 4.4665e-11
Epoch 242/512

Epoch 00242: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.4966e-11 - val_loss: 4.3669e-11
Epoch 243/512

Epoch 00243: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.4853e-11 - val_loss: 4.8876e-11
Epoch 244/512

Epoch 00244: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.0832e-11 - val_loss: 5.2733e-11
Epoch 245/512

Epoch 00245: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.4096e-11 - val_loss: 5.6532e-11
Epoch 246/512

Epoch 00246: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.6107e-11 - val_loss: 5.0951e-11
Epoch 247/512

Epoch 00247: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.9232e-11 - val_loss: 4.5380e-11
Epoch 248/512

Epoch 00248: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.3946e-11 - val_loss: 4.1425e-11
Epoch 249/512

Epoch 00249: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 4.0753e-11 - val_loss: 3.7754e-11
Epoch 250/512

Epoch 00250: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.7352e-11 - val_loss: 3.6320e-11
Epoch 251/512

Epoch 00251: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.6598e-11 - val_loss: 3.6466e-11
Epoch 252/512

Epoch 00252: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.6307e-11 - val_loss: 3.5708e-11
Epoch 253/512

Epoch 00253: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.6568e-11 - val_loss: 3.7733e-11
Epoch 254/512

Epoch 00254: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.8536e-11 - val_loss: 3.7351e-11
Epoch 255/512

Epoch 00255: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.7683e-11 - val_loss: 3.7623e-11
Epoch 256/512

Epoch 00256: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.8379e-11 - val_loss: 4.0965e-11
Epoch 257/512

Epoch 00257: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.2640e-11 - val_loss: 4.6534e-11
Epoch 258/512

Epoch 00258: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.7853e-11 - val_loss: 4.8404e-11
Epoch 259/512

Epoch 00259: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.6594e-11 - val_loss: 4.3282e-11
Epoch 260/512

Epoch 00260: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.2511e-11 - val_loss: 3.9622e-11
Epoch 261/512

Epoch 00261: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.8368e-11 - val_loss: 3.6244e-11
Epoch 262/512

Epoch 00262: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.5714e-11 - val_loss: 3.3792e-11
Epoch 263/512

Epoch 00263: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.3307e-11 - val_loss: 3.2670e-11
Epoch 264/512

Epoch 00264: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.3409e-11 - val_loss: 3.3142e-11
Epoch 265/512

Epoch 00265: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.3947e-11 - val_loss: 3.5242e-11
Epoch 266/512

Epoch 00266: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.5463e-11 - val_loss: 3.5128e-11
Epoch 267/512

Epoch 00267: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.5241e-11 - val_loss: 3.5006e-11
Epoch 268/512

Epoch 00268: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.5026e-11 - val_loss: 3.4361e-11
Epoch 269/512

Epoch 00269: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.3739e-11 - val_loss: 3.2717e-11
Epoch 270/512

Epoch 00270: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.3021e-11 - val_loss: 3.2509e-11
Epoch 271/512

Epoch 00271: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.3729e-11 - val_loss: 3.6451e-11
Epoch 272/512

Epoch 00272: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.8801e-11 - val_loss: 4.1754e-11
Epoch 273/512

Epoch 00273: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.0939e-11 - val_loss: 3.9521e-11
Epoch 274/512

Epoch 00274: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.8819e-11 - val_loss: 3.7020e-11
Epoch 275/512

Epoch 00275: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.6227e-11 - val_loss: 3.5307e-11
Epoch 276/512

Epoch 00276: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.4905e-11 - val_loss: 3.3935e-11
Epoch 277/512

Epoch 00277: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.3324e-11 - val_loss: 3.2125e-11
Epoch 278/512

Epoch 00278: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 3.1922e-11 - val_loss: 3.0320e-11
Epoch 279/512

Epoch 00279: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.9815e-11 - val_loss: 2.8183e-11
Epoch 280/512

Epoch 00280: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.8177e-11 - val_loss: 2.8125e-11
Epoch 281/512

Epoch 00281: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.8861e-11 - val_loss: 3.0303e-11
Epoch 282/512

Epoch 00282: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.1191e-11 - val_loss: 3.2392e-11
Epoch 283/512

Epoch 00283: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.2395e-11 - val_loss: 3.2964e-11
Epoch 284/512

Epoch 00284: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.3640e-11 - val_loss: 3.1900e-11
Epoch 285/512

Epoch 00285: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.1679e-11 - val_loss: 2.9870e-11
Epoch 286/512

Epoch 00286: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.9753e-11 - val_loss: 2.9184e-11
Epoch 287/512

Epoch 00287: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.8992e-11 - val_loss: 2.9202e-11
Epoch 288/512

Epoch 00288: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.0236e-11 - val_loss: 3.2971e-11
Epoch 289/512

Epoch 00289: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.2581e-11 - val_loss: 3.1515e-11
Epoch 290/512

Epoch 00290: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.0660e-11 - val_loss: 2.9133e-11
Epoch 291/512

Epoch 00291: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.8359e-11 - val_loss: 2.7891e-11
Epoch 292/512

Epoch 00292: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.8660e-11 - val_loss: 2.9373e-11
Epoch 293/512

Epoch 00293: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.9382e-11 - val_loss: 2.9510e-11
Epoch 294/512

Epoch 00294: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.8588e-11 - val_loss: 2.7790e-11
Epoch 295/512

Epoch 00295: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.8045e-11 - val_loss: 2.6942e-11
Epoch 296/512

Epoch 00296: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.7301e-11 - val_loss: 2.6710e-11
Epoch 297/512

Epoch 00297: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.6986e-11 - val_loss: 2.7720e-11
Epoch 298/512

Epoch 00298: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.8211e-11 - val_loss: 2.7647e-11
Epoch 299/512

Epoch 00299: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.7968e-11 - val_loss: 2.9094e-11
Epoch 300/512

Epoch 00300: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.9815e-11 - val_loss: 2.9375e-11
Epoch 301/512

Epoch 00301: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.0185e-11 - val_loss: 2.9563e-11
Epoch 302/512

Epoch 00302: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.8833e-11 - val_loss: 2.6608e-11
Epoch 303/512

Epoch 00303: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.6345e-11 - val_loss: 2.7363e-11
Epoch 304/512

Epoch 00304: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.8340e-11 - val_loss: 2.7993e-11
Epoch 305/512

Epoch 00305: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.7554e-11 - val_loss: 2.7280e-11
Epoch 306/512

Epoch 00306: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.8050e-11 - val_loss: 2.9312e-11
Epoch 307/512

Epoch 00307: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.9587e-11 - val_loss: 3.0097e-11
Epoch 308/512

Epoch 00308: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.9692e-11 - val_loss: 2.7549e-11
Epoch 309/512

Epoch 00309: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.7702e-11 - val_loss: 2.9145e-11
Epoch 310/512

Epoch 00310: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.9062e-11 - val_loss: 2.9094e-11
Epoch 311/512

Epoch 00311: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.8645e-11 - val_loss: 2.6699e-11
Epoch 312/512

Epoch 00312: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.7018e-11 - val_loss: 2.7028e-11
Epoch 313/512

Epoch 00313: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.6656e-11 - val_loss: 2.6689e-11
Epoch 314/512

Epoch 00314: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.6537e-11 - val_loss: 2.6028e-11
Epoch 315/512

Epoch 00315: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.6364e-11 - val_loss: 2.7180e-11
Epoch 316/512

Epoch 00316: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.6491e-11 - val_loss: 2.6224e-11
Epoch 317/512

Epoch 00317: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.6827e-11 - val_loss: 2.7468e-11
Epoch 318/512

Epoch 00318: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.7450e-11 - val_loss: 2.7989e-11
Epoch 319/512

Epoch 00319: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.8773e-11 - val_loss: 2.9446e-11
Epoch 320/512

Epoch 00320: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.0242e-11 - val_loss: 3.0702e-11
Epoch 321/512

Epoch 00321: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.9857e-11 - val_loss: 2.7947e-11
Epoch 322/512

Epoch 00322: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.7753e-11 - val_loss: 2.7218e-11
Epoch 323/512

Epoch 00323: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.6352e-11 - val_loss: 2.5871e-11
Epoch 324/512

Epoch 00324: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.5639e-11 - val_loss: 2.4391e-11
Epoch 325/512

Epoch 00325: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.4408e-11 - val_loss: 2.3695e-11
Epoch 326/512

Epoch 00326: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.3726e-11 - val_loss: 2.4051e-11
Epoch 327/512

Epoch 00327: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.4261e-11 - val_loss: 2.4342e-11
Epoch 328/512

Epoch 00328: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.5167e-11 - val_loss: 2.6921e-11
Epoch 329/512

Epoch 00329: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.7685e-11 - val_loss: 2.9158e-11
Epoch 330/512

Epoch 00330: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.9062e-11 - val_loss: 2.9165e-11
Epoch 331/512

Epoch 00331: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.8594e-11 - val_loss: 2.4108e-11
Epoch 332/512

Epoch 00332: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 2.2441e-11 - val_loss: 1.9647e-11
Epoch 333/512

Epoch 00333: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.8187e-11 - val_loss: 1.4753e-11
Epoch 334/512

Epoch 00334: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.4610e-11 - val_loss: 1.3916e-11
Epoch 335/512

Epoch 00335: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.3667e-11 - val_loss: 1.2362e-11
Epoch 336/512

Epoch 00336: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2700e-11 - val_loss: 1.4249e-11
Epoch 337/512

Epoch 00337: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5273e-11 - val_loss: 1.8447e-11
Epoch 338/512

Epoch 00338: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0293e-11 - val_loss: 2.4072e-11
Epoch 339/512

Epoch 00339: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.5684e-11 - val_loss: 2.7525e-11
Epoch 340/512

Epoch 00340: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.7659e-11 - val_loss: 2.8318e-11
Epoch 341/512

Epoch 00341: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.9178e-11 - val_loss: 3.0516e-11
Epoch 342/512

Epoch 00342: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.0741e-11 - val_loss: 3.0546e-11
Epoch 343/512

Epoch 00343: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.0264e-11 - val_loss: 2.7654e-11
Epoch 344/512

Epoch 00344: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.7205e-11 - val_loss: 2.5702e-11
Epoch 345/512

Epoch 00345: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.5263e-11 - val_loss: 2.3627e-11
Epoch 346/512

Epoch 00346: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.3616e-11 - val_loss: 2.3023e-11
Epoch 347/512

Epoch 00347: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2682e-11 - val_loss: 2.2393e-11
Epoch 348/512

Epoch 00348: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2813e-11 - val_loss: 2.3666e-11
Epoch 349/512

Epoch 00349: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.3885e-11 - val_loss: 2.4074e-11
Epoch 350/512

Epoch 00350: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.3695e-11 - val_loss: 2.2111e-11
Epoch 351/512

Epoch 00351: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.1740e-11 - val_loss: 2.1939e-11
Epoch 352/512

Epoch 00352: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2303e-11 - val_loss: 2.2545e-11
Epoch 353/512

Epoch 00353: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2280e-11 - val_loss: 2.1337e-11
Epoch 354/512

Epoch 00354: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2176e-11 - val_loss: 2.3000e-11
Epoch 355/512

Epoch 00355: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.3231e-11 - val_loss: 2.2559e-11
Epoch 356/512

Epoch 00356: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2767e-11 - val_loss: 2.2905e-11
Epoch 357/512

Epoch 00357: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.3208e-11 - val_loss: 2.2964e-11
Epoch 358/512

Epoch 00358: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2410e-11 - val_loss: 1.9168e-11
Epoch 359/512

Epoch 00359: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7571e-11 - val_loss: 1.5071e-11
Epoch 360/512

Epoch 00360: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4629e-11 - val_loss: 1.3480e-11
Epoch 361/512

Epoch 00361: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3579e-11 - val_loss: 1.2807e-11
Epoch 362/512

Epoch 00362: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.2769e-11 - val_loss: 1.2176e-11
Epoch 363/512

Epoch 00363: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.1971e-11 - val_loss: 1.0840e-11
Epoch 364/512

Epoch 00364: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0982e-11 - val_loss: 1.1343e-11
Epoch 365/512

Epoch 00365: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1510e-11 - val_loss: 1.2001e-11
Epoch 366/512

Epoch 00366: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2252e-11 - val_loss: 1.3049e-11
Epoch 367/512

Epoch 00367: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3052e-11 - val_loss: 1.4560e-11
Epoch 368/512

Epoch 00368: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6023e-11 - val_loss: 1.8925e-11
Epoch 369/512

Epoch 00369: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0162e-11 - val_loss: 2.1160e-11
Epoch 370/512

Epoch 00370: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2191e-11 - val_loss: 2.4628e-11
Epoch 371/512

Epoch 00371: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.5062e-11 - val_loss: 2.5998e-11
Epoch 372/512

Epoch 00372: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.6760e-11 - val_loss: 2.6326e-11
Epoch 373/512

Epoch 00373: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.6227e-11 - val_loss: 2.5005e-11
Epoch 374/512

Epoch 00374: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.4492e-11 - val_loss: 2.4011e-11
Epoch 375/512

Epoch 00375: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.3990e-11 - val_loss: 2.3372e-11
Epoch 376/512

Epoch 00376: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2689e-11 - val_loss: 2.1481e-11
Epoch 377/512

Epoch 00377: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.1588e-11 - val_loss: 2.1016e-11
Epoch 378/512

Epoch 00378: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.1086e-11 - val_loss: 2.0058e-11
Epoch 379/512

Epoch 00379: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9512e-11 - val_loss: 1.8317e-11
Epoch 380/512

Epoch 00380: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.8556e-11 - val_loss: 1.8955e-11
Epoch 381/512

Epoch 00381: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9673e-11 - val_loss: 2.0861e-11
Epoch 382/512

Epoch 00382: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0996e-11 - val_loss: 2.0469e-11
Epoch 383/512

Epoch 00383: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0710e-11 - val_loss: 2.0922e-11
Epoch 384/512

Epoch 00384: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0963e-11 - val_loss: 2.1221e-11
Epoch 385/512

Epoch 00385: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.1306e-11 - val_loss: 2.1359e-11
Epoch 386/512

Epoch 00386: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.1299e-11 - val_loss: 2.0425e-11
Epoch 387/512

Epoch 00387: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0931e-11 - val_loss: 2.1036e-11
Epoch 388/512

Epoch 00388: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0680e-11 - val_loss: 1.9349e-11
Epoch 389/512

Epoch 00389: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9881e-11 - val_loss: 2.0379e-11
Epoch 390/512

Epoch 00390: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9939e-11 - val_loss: 1.9956e-11
Epoch 391/512

Epoch 00391: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0234e-11 - val_loss: 2.0272e-11
Epoch 392/512

Epoch 00392: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0366e-11 - val_loss: 2.0584e-11
Epoch 393/512

Epoch 00393: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0282e-11 - val_loss: 1.8172e-11
Epoch 394/512

Epoch 00394: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6795e-11 - val_loss: 1.4192e-11
Epoch 395/512

Epoch 00395: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3485e-11 - val_loss: 1.1773e-11
Epoch 396/512

Epoch 00396: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 1.0744e-11 - val_loss: 9.1134e-12
Epoch 397/512

Epoch 00397: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 9.1526e-12 - val_loss: 9.0362e-12
Epoch 398/512

Epoch 00398: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 8.9644e-12 - val_loss: 8.6194e-12
Epoch 399/512

Epoch 00399: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.6971e-12 - val_loss: 9.4425e-12
Epoch 400/512

Epoch 00400: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.6227e-12 - val_loss: 9.6151e-12
Epoch 401/512

Epoch 00401: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.6005e-12 - val_loss: 9.8969e-12
Epoch 402/512

Epoch 00402: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0113e-11 - val_loss: 1.0867e-11
Epoch 403/512

Epoch 00403: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0937e-11 - val_loss: 1.1051e-11
Epoch 404/512

Epoch 00404: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0861e-11 - val_loss: 1.0159e-11
Epoch 405/512

Epoch 00405: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0060e-11 - val_loss: 9.4568e-12
Epoch 406/512

Epoch 00406: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.5143e-12 - val_loss: 9.4787e-12
Epoch 407/512

Epoch 00407: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.8632e-12 - val_loss: 1.0190e-11
Epoch 408/512

Epoch 00408: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0655e-11 - val_loss: 1.2325e-11
Epoch 409/512

Epoch 00409: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2976e-11 - val_loss: 1.4470e-11
Epoch 410/512

Epoch 00410: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5350e-11 - val_loss: 1.6941e-11
Epoch 411/512

Epoch 00411: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7525e-11 - val_loss: 1.8304e-11
Epoch 412/512

Epoch 00412: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.8675e-11 - val_loss: 1.9248e-11
Epoch 413/512

Epoch 00413: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9398e-11 - val_loss: 1.9621e-11
Epoch 414/512

Epoch 00414: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9706e-11 - val_loss: 2.0293e-11
Epoch 415/512

Epoch 00415: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0332e-11 - val_loss: 1.9483e-11
Epoch 416/512

Epoch 00416: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9746e-11 - val_loss: 2.0117e-11
Epoch 417/512

Epoch 00417: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0091e-11 - val_loss: 1.9865e-11
Epoch 418/512

Epoch 00418: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9798e-11 - val_loss: 2.0275e-11
Epoch 419/512

Epoch 00419: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0283e-11 - val_loss: 1.9507e-11
Epoch 420/512

Epoch 00420: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9905e-11 - val_loss: 1.9854e-11
Epoch 421/512

Epoch 00421: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9480e-11 - val_loss: 1.8455e-11
Epoch 422/512

Epoch 00422: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.8909e-11 - val_loss: 1.9035e-11
Epoch 423/512

Epoch 00423: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.8577e-11 - val_loss: 1.7536e-11
Epoch 424/512

Epoch 00424: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7541e-11 - val_loss: 1.6738e-11
Epoch 425/512

Epoch 00425: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7045e-11 - val_loss: 1.7416e-11
Epoch 426/512

Epoch 00426: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7105e-11 - val_loss: 1.7236e-11
Epoch 427/512

Epoch 00427: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7439e-11 - val_loss: 1.6884e-11
Epoch 428/512

Epoch 00428: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6820e-11 - val_loss: 1.6042e-11
Epoch 429/512

Epoch 00429: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6300e-11 - val_loss: 1.6723e-11
Epoch 430/512

Epoch 00430: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7095e-11 - val_loss: 1.7497e-11
Epoch 431/512

Epoch 00431: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7195e-11 - val_loss: 1.7102e-11
Epoch 432/512

Epoch 00432: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7391e-11 - val_loss: 1.6641e-11
Epoch 433/512

Epoch 00433: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6667e-11 - val_loss: 1.6754e-11
Epoch 434/512

Epoch 00434: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6846e-11 - val_loss: 1.6706e-11
Epoch 435/512

Epoch 00435: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6365e-11 - val_loss: 1.6518e-11
Epoch 436/512

Epoch 00436: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6710e-11 - val_loss: 1.7329e-11
Epoch 437/512

Epoch 00437: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7488e-11 - val_loss: 1.6789e-11
Epoch 438/512

Epoch 00438: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5896e-11 - val_loss: 1.4142e-11
Epoch 439/512

Epoch 00439: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3499e-11 - val_loss: 1.1939e-11
Epoch 440/512

Epoch 00440: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1387e-11 - val_loss: 9.9683e-12
Epoch 441/512

Epoch 00441: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 9.4676e-12 - val_loss: 8.2479e-12
Epoch 442/512

Epoch 00442: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 7.8156e-12 - val_loss: 7.4446e-12
Epoch 443/512

Epoch 00443: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 7.4341e-12 - val_loss: 7.0505e-12
Epoch 444/512

Epoch 00444: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 7.0350e-12 - val_loss: 6.9952e-12
Epoch 445/512

Epoch 00445: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.0457e-12 - val_loss: 6.9968e-12
Epoch 446/512

Epoch 00446: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 7.0078e-12 - val_loss: 6.5917e-12
Epoch 447/512

Epoch 00447: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 6.6169e-12 - val_loss: 6.5056e-12
Epoch 448/512

Epoch 00448: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 6.2990e-12 - val_loss: 6.0388e-12
Epoch 449/512

Epoch 00449: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.0336e-12 - val_loss: 6.1282e-12
Epoch 450/512

Epoch 00450: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.1119e-12 - val_loss: 6.3796e-12
Epoch 451/512

Epoch 00451: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.5162e-12 - val_loss: 6.6016e-12
Epoch 452/512

Epoch 00452: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.5671e-12 - val_loss: 6.4760e-12
Epoch 453/512

Epoch 00453: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.5813e-12 - val_loss: 7.1174e-12
Epoch 454/512

Epoch 00454: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.1536e-12 - val_loss: 7.1691e-12
Epoch 455/512

Epoch 00455: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.1736e-12 - val_loss: 7.4705e-12
Epoch 456/512

Epoch 00456: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.6152e-12 - val_loss: 7.5415e-12
Epoch 457/512

Epoch 00457: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.2058e-12 - val_loss: 7.1312e-12
Epoch 458/512

Epoch 00458: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.2094e-12 - val_loss: 7.2780e-12
Epoch 459/512

Epoch 00459: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.5053e-12 - val_loss: 7.9127e-12
Epoch 460/512

Epoch 00460: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.8724e-12 - val_loss: 7.8204e-12
Epoch 461/512

Epoch 00461: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.8210e-12 - val_loss: 7.9782e-12
Epoch 462/512

Epoch 00462: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.6024e-12 - val_loss: 1.0354e-11
Epoch 463/512

Epoch 00463: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1403e-11 - val_loss: 1.3631e-11
Epoch 464/512

Epoch 00464: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4381e-11 - val_loss: 1.5827e-11
Epoch 465/512

Epoch 00465: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6212e-11 - val_loss: 1.6771e-11
Epoch 466/512

Epoch 00466: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7219e-11 - val_loss: 1.7938e-11
Epoch 467/512

Epoch 00467: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.8218e-11 - val_loss: 1.8337e-11
Epoch 468/512

Epoch 00468: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.8068e-11 - val_loss: 1.8277e-11
Epoch 469/512

Epoch 00469: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.8510e-11 - val_loss: 1.7819e-11
Epoch 470/512

Epoch 00470: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7946e-11 - val_loss: 1.7533e-11
Epoch 471/512

Epoch 00471: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7617e-11 - val_loss: 1.6693e-11
Epoch 472/512

Epoch 00472: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6616e-11 - val_loss: 1.7101e-11
Epoch 473/512

Epoch 00473: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7306e-11 - val_loss: 1.7424e-11
Epoch 474/512

Epoch 00474: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7465e-11 - val_loss: 1.6886e-11
Epoch 475/512

Epoch 00475: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6853e-11 - val_loss: 1.6210e-11
Epoch 476/512

Epoch 00476: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6245e-11 - val_loss: 1.5857e-11
Epoch 477/512

Epoch 00477: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5793e-11 - val_loss: 1.5142e-11
Epoch 478/512

Epoch 00478: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5288e-11 - val_loss: 1.4900e-11
Epoch 479/512

Epoch 00479: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4600e-11 - val_loss: 1.4977e-11
Epoch 480/512

Epoch 00480: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5361e-11 - val_loss: 1.5571e-11
Epoch 481/512

Epoch 00481: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5590e-11 - val_loss: 1.4658e-11
Epoch 482/512

Epoch 00482: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4460e-11 - val_loss: 1.4106e-11
Epoch 483/512

Epoch 00483: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4545e-11 - val_loss: 1.4812e-11
Epoch 484/512

Epoch 00484: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5305e-11 - val_loss: 1.5592e-11
Epoch 485/512

Epoch 00485: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5382e-11 - val_loss: 1.5491e-11
Epoch 486/512

Epoch 00486: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5628e-11 - val_loss: 1.6364e-11
Epoch 487/512

Epoch 00487: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6492e-11 - val_loss: 1.5758e-11
Epoch 488/512

Epoch 00488: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5361e-11 - val_loss: 1.4973e-11
Epoch 489/512

Epoch 00489: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5504e-11 - val_loss: 1.5917e-11
Epoch 490/512

Epoch 00490: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6044e-11 - val_loss: 1.5397e-11
Epoch 491/512

Epoch 00491: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5507e-11 - val_loss: 1.5263e-11
Epoch 492/512

Epoch 00492: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5180e-11 - val_loss: 1.4195e-11
Epoch 493/512

Epoch 00493: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4149e-11 - val_loss: 1.3210e-11
Epoch 494/512

Epoch 00494: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3461e-11 - val_loss: 1.3914e-11
Epoch 495/512

Epoch 00495: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4067e-11 - val_loss: 1.3593e-11
Epoch 496/512

Epoch 00496: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3335e-11 - val_loss: 1.1512e-11
Epoch 497/512

Epoch 00497: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0869e-11 - val_loss: 9.2706e-12
Epoch 498/512

Epoch 00498: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.7804e-12 - val_loss: 7.3971e-12
Epoch 499/512

Epoch 00499: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.8005e-12 - val_loss: 6.0861e-12
Epoch 500/512

Epoch 00500: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 5.8694e-12 - val_loss: 5.6016e-12
Epoch 501/512

Epoch 00501: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 5.2277e-12 - val_loss: 4.8496e-12
Epoch 502/512

Epoch 00502: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/addition_weights.h5
448/448 - 0s - loss: 4.7715e-12 - val_loss: 4.4627e-12
Epoch 503/512

Epoch 00503: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.4526e-12 - val_loss: 4.5123e-12
Epoch 504/512

Epoch 00504: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.5419e-12 - val_loss: 4.7474e-12
Epoch 505/512

Epoch 00505: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.6647e-12 - val_loss: 4.5292e-12
Epoch 506/512

Epoch 00506: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.7863e-12 - val_loss: 5.0321e-12
Epoch 507/512

Epoch 00507: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.0793e-12 - val_loss: 4.8536e-12
Epoch 508/512

Epoch 00508: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.0197e-12 - val_loss: 5.3927e-12
Epoch 509/512

Epoch 00509: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.4452e-12 - val_loss: 5.4424e-12
Epoch 510/512

Epoch 00510: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.3463e-12 - val_loss: 5.2405e-12
Epoch 511/512

Epoch 00511: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.7218e-12 - val_loss: 6.0290e-12
Epoch 512/512

Epoch 00512: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.0265e-12 - val_loss: 6.0821e-12
Train on 448 samples, validate on 448 samples
Epoch 1/512
448/448 - 1s - loss: 0.0458 - val_loss: 7.5950e-04
Epoch 2/512
448/448 - 0s - loss: 0.0021 - val_loss: 4.0501e-04
Epoch 3/512
448/448 - 0s - loss: 0.0010 - val_loss: 3.0801e-04
Epoch 4/512
448/448 - 0s - loss: 0.0010 - val_loss: 2.0346e-04
Epoch 5/512
448/448 - 0s - loss: 0.0022 - val_loss: 1.4349e-04
Epoch 6/512
448/448 - 0s - loss: 8.7935e-04 - val_loss: 1.3366e-04
Epoch 7/512
448/448 - 0s - loss: 5.7947e-04 - val_loss: 1.0348e-04
Epoch 8/512
448/448 - 0s - loss: 9.5200e-04 - val_loss: 4.0119e-05
Epoch 9/512
448/448 - 0s - loss: 0.0016 - val_loss: 2.2876e-05
Epoch 10/512
448/448 - 0s - loss: 5.8966e-04 - val_loss: 1.9469e-05
Epoch 11/512
448/448 - 0s - loss: 6.1376e-04 - val_loss: 9.7428e-06
Epoch 12/512
448/448 - 0s - loss: 0.0012 - val_loss: 1.0567e-05
Epoch 13/512
448/448 - 0s - loss: 5.9722e-04 - val_loss: 1.2144e-05
Epoch 14/512
448/448 - 0s - loss: 4.5074e-04 - val_loss: 1.4747e-05
Epoch 15/512
448/448 - 0s - loss: 8.2547e-04 - val_loss: 1.9201e-05
Epoch 16/512
448/448 - 0s - loss: 5.5576e-04 - val_loss: 2.0100e-05
Epoch 17/512
448/448 - 0s - loss: 3.5127e-04 - val_loss: 2.0614e-05
Epoch 18/512
448/448 - 0s - loss: 5.7108e-04 - val_loss: 2.2443e-05
Epoch 19/512
448/448 - 0s - loss: 4.6527e-04 - val_loss: 2.2497e-05
Epoch 20/512
448/448 - 0s - loss: 2.9435e-04 - val_loss: 2.1049e-05
Epoch 21/512
448/448 - 0s - loss: 3.9656e-04 - val_loss: 2.1084e-05
Epoch 22/512
448/448 - 0s - loss: 3.7646e-04 - val_loss: 2.0508e-05
Epoch 23/512
448/448 - 0s - loss: 2.3811e-04 - val_loss: 1.7971e-05
Epoch 24/512
448/448 - 0s - loss: 2.9364e-04 - val_loss: 1.7590e-05
Epoch 25/512
448/448 - 0s - loss: 2.8494e-04 - val_loss: 1.6011e-05
Epoch 26/512
448/448 - 0s - loss: 2.0666e-04 - val_loss: 1.3757e-05
Epoch 27/512
448/448 - 0s - loss: 2.1509e-04 - val_loss: 1.2550e-05
Epoch 28/512
448/448 - 0s - loss: 2.2029e-04 - val_loss: 1.1192e-05
Epoch 29/512
448/448 - 0s - loss: 1.7399e-04 - val_loss: 9.4078e-06
Epoch 30/512
448/448 - 0s - loss: 1.6988e-04 - val_loss: 8.1823e-06
Epoch 31/512
448/448 - 0s - loss: 1.7488e-04 - val_loss: 7.2667e-06
Epoch 32/512
448/448 - 0s - loss: 1.4757e-04 - val_loss: 6.5676e-06
Epoch 33/512
448/448 - 0s - loss: 1.4059e-04 - val_loss: 6.1237e-06
Epoch 34/512
448/448 - 0s - loss: 1.4074e-04 - val_loss: 5.9255e-06
Epoch 35/512
448/448 - 0s - loss: 1.3036e-04 - val_loss: 5.8638e-06
Epoch 36/512
448/448 - 0s - loss: 1.2192e-04 - val_loss: 5.8203e-06
Epoch 37/512
448/448 - 0s - loss: 1.1788e-04 - val_loss: 5.7551e-06
Epoch 38/512
448/448 - 0s - loss: 1.1260e-04 - val_loss: 5.6527e-06
Epoch 39/512
448/448 - 0s - loss: 1.0842e-04 - val_loss: 5.4686e-06
Epoch 40/512
448/448 - 0s - loss: 1.0354e-04 - val_loss: 5.2652e-06
Epoch 41/512
448/448 - 0s - loss: 9.8510e-05 - val_loss: 5.0982e-06
Epoch 42/512
448/448 - 0s - loss: 9.6299e-05 - val_loss: 4.9044e-06
Epoch 43/512
448/448 - 0s - loss: 9.3798e-05 - val_loss: 4.6039e-06
Epoch 44/512
448/448 - 0s - loss: 9.1068e-05 - val_loss: 4.3088e-06
Epoch 45/512
448/448 - 0s - loss: 8.4917e-05 - val_loss: 3.9164e-06
Epoch 46/512
448/448 - 0s - loss: 8.4726e-05 - val_loss: 3.7186e-06
Epoch 47/512
448/448 - 0s - loss: 8.4496e-05 - val_loss: 3.4815e-06
Epoch 48/512
448/448 - 0s - loss: 7.8046e-05 - val_loss: 3.1978e-06
Epoch 49/512
448/448 - 0s - loss: 7.7124e-05 - val_loss: 2.9956e-06
Epoch 50/512
448/448 - 0s - loss: 7.6511e-05 - val_loss: 2.7620e-06
Epoch 51/512
448/448 - 0s - loss: 7.4139e-05 - val_loss: 2.5646e-06
Epoch 52/512
448/448 - 0s - loss: 6.9757e-05 - val_loss: 2.3879e-06
Epoch 53/512
448/448 - 0s - loss: 7.0630e-05 - val_loss: 2.2911e-06
Epoch 54/512
448/448 - 0s - loss: 6.8415e-05 - val_loss: 2.0848e-06
Epoch 55/512
448/448 - 0s - loss: 6.7262e-05 - val_loss: 1.8928e-06
Epoch 56/512
448/448 - 0s - loss: 6.4259e-05 - val_loss: 1.7429e-06
Epoch 57/512
448/448 - 0s - loss: 6.3515e-05 - val_loss: 1.6667e-06
Epoch 58/512
448/448 - 0s - loss: 6.2629e-05 - val_loss: 1.5548e-06
Epoch 59/512
448/448 - 0s - loss: 6.0598e-05 - val_loss: 1.4536e-06
Epoch 60/512
448/448 - 0s - loss: 5.9513e-05 - val_loss: 1.3594e-06
Epoch 61/512
448/448 - 0s - loss: 5.7663e-05 - val_loss: 1.2676e-06
Epoch 62/512
448/448 - 0s - loss: 5.8604e-05 - val_loss: 1.1768e-06
Epoch 63/512
448/448 - 0s - loss: 5.5344e-05 - val_loss: 1.0731e-06
Epoch 64/512
448/448 - 0s - loss: 5.4556e-05 - val_loss: 1.0309e-06
Epoch 65/512
448/448 - 0s - loss: 5.3499e-05 - val_loss: 9.7617e-07
Epoch 66/512
448/448 - 0s - loss: 5.3985e-05 - val_loss: 9.1093e-07
Epoch 67/512
448/448 - 0s - loss: 5.1830e-05 - val_loss: 8.2967e-07
Epoch 68/512
448/448 - 0s - loss: 4.9497e-05 - val_loss: 7.8136e-07
Epoch 69/512
448/448 - 0s - loss: 5.1023e-05 - val_loss: 7.5126e-07
Epoch 70/512
448/448 - 0s - loss: 4.8916e-05 - val_loss: 7.0167e-07
Epoch 71/512
448/448 - 0s - loss: 4.7883e-05 - val_loss: 6.6613e-07
Epoch 72/512
448/448 - 0s - loss: 4.7613e-05 - val_loss: 6.3027e-07
Epoch 73/512
448/448 - 0s - loss: 4.5932e-05 - val_loss: 5.9769e-07
Epoch 74/512
448/448 - 0s - loss: 4.5999e-05 - val_loss: 5.7748e-07
Epoch 75/512
448/448 - 0s - loss: 4.6169e-05 - val_loss: 5.2245e-07
Epoch 76/512
448/448 - 0s - loss: 4.2791e-05 - val_loss: 4.9186e-07
Epoch 77/512
448/448 - 0s - loss: 4.3453e-05 - val_loss: 4.8631e-07
Epoch 78/512
448/448 - 0s - loss: 4.3373e-05 - val_loss: 4.6180e-07
Epoch 79/512
448/448 - 0s - loss: 4.1858e-05 - val_loss: 4.3775e-07
Epoch 80/512
448/448 - 0s - loss: 4.0909e-05 - val_loss: 4.1914e-07
Epoch 81/512
448/448 - 0s - loss: 4.1033e-05 - val_loss: 4.0309e-07
Epoch 82/512
448/448 - 0s - loss: 4.0163e-05 - val_loss: 3.8099e-07
Epoch 83/512
448/448 - 0s - loss: 3.9106e-05 - val_loss: 3.6562e-07
Epoch 84/512
448/448 - 0s - loss: 3.9281e-05 - val_loss: 3.4853e-07
Epoch 85/512
448/448 - 0s - loss: 3.7565e-05 - val_loss: 3.4004e-07
Epoch 86/512
448/448 - 0s - loss: 3.8233e-05 - val_loss: 3.2496e-07
Epoch 87/512
448/448 - 0s - loss: 3.7032e-05 - val_loss: 3.0754e-07
Epoch 88/512
448/448 - 0s - loss: 3.5930e-05 - val_loss: 2.9490e-07
Epoch 89/512
448/448 - 0s - loss: 3.5404e-05 - val_loss: 2.9276e-07
Epoch 90/512
448/448 - 0s - loss: 3.6084e-05 - val_loss: 2.8180e-07
Epoch 91/512
448/448 - 0s - loss: 3.4403e-05 - val_loss: 2.6758e-07
Epoch 92/512
448/448 - 0s - loss: 3.3580e-05 - val_loss: 2.6577e-07
Epoch 93/512
448/448 - 0s - loss: 3.4357e-05 - val_loss: 2.5374e-07
Epoch 94/512
448/448 - 0s - loss: 3.2577e-05 - val_loss: 2.4514e-07
Epoch 95/512
448/448 - 0s - loss: 3.3062e-05 - val_loss: 2.3684e-07
Epoch 96/512
448/448 - 0s - loss: 3.1739e-05 - val_loss: 2.2900e-07
Epoch 97/512
448/448 - 0s - loss: 3.1707e-05 - val_loss: 2.2273e-07
Epoch 98/512
448/448 - 0s - loss: 3.1284e-05 - val_loss: 2.1095e-07
Epoch 99/512
448/448 - 0s - loss: 3.0083e-05 - val_loss: 2.0852e-07
Epoch 100/512
448/448 - 0s - loss: 3.0351e-05 - val_loss: 2.0407e-07
Epoch 101/512
448/448 - 0s - loss: 2.9750e-05 - val_loss: 1.9538e-07
Epoch 102/512
448/448 - 0s - loss: 2.8738e-05 - val_loss: 1.9168e-07
Epoch 103/512
448/448 - 0s - loss: 2.8661e-05 - val_loss: 1.8856e-07
Epoch 104/512
448/448 - 0s - loss: 2.8507e-05 - val_loss: 1.7969e-07
Epoch 105/512
448/448 - 0s - loss: 2.7586e-05 - val_loss: 1.7134e-07
Epoch 106/512
448/448 - 0s - loss: 2.6987e-05 - val_loss: 1.7086e-07
Epoch 107/512
448/448 - 0s - loss: 2.6510e-05 - val_loss: 1.7344e-07
Epoch 108/512
448/448 - 0s - loss: 2.7076e-05 - val_loss: 1.6326e-07
Epoch 109/512
448/448 - 0s - loss: 2.5351e-05 - val_loss: 1.6007e-07
Epoch 110/512
448/448 - 0s - loss: 2.5370e-05 - val_loss: 1.5934e-07
Epoch 111/512
448/448 - 0s - loss: 2.5310e-05 - val_loss: 1.5676e-07
Epoch 112/512
448/448 - 0s - loss: 2.4406e-05 - val_loss: 1.5245e-07
Epoch 113/512
448/448 - 0s - loss: 2.4130e-05 - val_loss: 1.5037e-07
Epoch 114/512
448/448 - 0s - loss: 2.3668e-05 - val_loss: 1.4970e-07
Epoch 115/512
448/448 - 0s - loss: 2.3551e-05 - val_loss: 1.4337e-07
Epoch 116/512
448/448 - 0s - loss: 2.2590e-05 - val_loss: 1.4162e-07
Epoch 117/512
448/448 - 0s - loss: 2.2720e-05 - val_loss: 1.3904e-07
Epoch 118/512
448/448 - 0s - loss: 2.2085e-05 - val_loss: 1.3433e-07
Epoch 119/512
448/448 - 0s - loss: 2.1479e-05 - val_loss: 1.3135e-07
Epoch 120/512
448/448 - 0s - loss: 2.0983e-05 - val_loss: 1.3383e-07
Epoch 121/512
448/448 - 0s - loss: 2.1553e-05 - val_loss: 1.2680e-07
Epoch 122/512
448/448 - 0s - loss: 2.0056e-05 - val_loss: 1.2391e-07
Epoch 123/512
448/448 - 0s - loss: 2.0028e-05 - val_loss: 1.2387e-07
Epoch 124/512
448/448 - 0s - loss: 1.9905e-05 - val_loss: 1.2097e-07
Epoch 125/512
448/448 - 0s - loss: 1.9320e-05 - val_loss: 1.1617e-07
Epoch 126/512
448/448 - 0s - loss: 1.8839e-05 - val_loss: 1.1403e-07
Epoch 127/512
448/448 - 0s - loss: 1.8704e-05 - val_loss: 1.1100e-07
Epoch 128/512
448/448 - 0s - loss: 1.8149e-05 - val_loss: 1.0817e-07
Epoch 129/512
448/448 - 0s - loss: 1.7730e-05 - val_loss: 1.0792e-07
Epoch 130/512
448/448 - 0s - loss: 1.7511e-05 - val_loss: 1.0768e-07
Epoch 131/512
448/448 - 0s - loss: 1.7548e-05 - val_loss: 1.0167e-07
Epoch 132/512
448/448 - 0s - loss: 1.6466e-05 - val_loss: 9.7754e-08
Epoch 133/512
448/448 - 0s - loss: 1.6210e-05 - val_loss: 1.0004e-07
Epoch 134/512
448/448 - 0s - loss: 1.6537e-05 - val_loss: 9.6838e-08
Epoch 135/512
448/448 - 0s - loss: 1.5837e-05 - val_loss: 9.0517e-08
Epoch 136/512
448/448 - 0s - loss: 1.5025e-05 - val_loss: 9.0590e-08
Epoch 137/512
448/448 - 0s - loss: 1.5250e-05 - val_loss: 9.0218e-08
Epoch 138/512
448/448 - 0s - loss: 1.4947e-05 - val_loss: 8.7044e-08
Epoch 139/512
448/448 - 0s - loss: 1.4464e-05 - val_loss: 8.3129e-08
Epoch 140/512
448/448 - 0s - loss: 1.3935e-05 - val_loss: 8.2164e-08
Epoch 141/512
448/448 - 0s - loss: 1.3940e-05 - val_loss: 8.0106e-08
Epoch 142/512
448/448 - 0s - loss: 1.3409e-05 - val_loss: 7.9363e-08
Epoch 143/512
448/448 - 0s - loss: 1.3423e-05 - val_loss: 7.6016e-08
Epoch 144/512
448/448 - 0s - loss: 1.2788e-05 - val_loss: 7.3749e-08
Epoch 145/512
448/448 - 0s - loss: 1.2613e-05 - val_loss: 7.1981e-08
Epoch 146/512
448/448 - 0s - loss: 1.2317e-05 - val_loss: 7.0948e-08
Epoch 147/512
448/448 - 0s - loss: 1.2055e-05 - val_loss: 6.9758e-08
Epoch 148/512
448/448 - 0s - loss: 1.1899e-05 - val_loss: 6.6684e-08
Epoch 149/512
448/448 - 0s - loss: 1.1309e-05 - val_loss: 6.5195e-08
Epoch 150/512
448/448 - 0s - loss: 1.1249e-05 - val_loss: 6.4118e-08
Epoch 151/512
448/448 - 0s - loss: 1.1085e-05 - val_loss: 6.0333e-08
Epoch 152/512
448/448 - 0s - loss: 1.0353e-05 - val_loss: 6.0687e-08
Epoch 153/512
448/448 - 0s - loss: 1.0667e-05 - val_loss: 5.9189e-08
Epoch 154/512
448/448 - 0s - loss: 1.0068e-05 - val_loss: 5.6872e-08
Epoch 155/512
448/448 - 0s - loss: 9.8242e-06 - val_loss: 5.6013e-08
Epoch 156/512
448/448 - 0s - loss: 9.7193e-06 - val_loss: 5.4014e-08
Epoch 157/512
448/448 - 0s - loss: 9.3792e-06 - val_loss: 5.2258e-08
Epoch 158/512
448/448 - 0s - loss: 9.1201e-06 - val_loss: 5.0937e-08
Epoch 159/512
448/448 - 0s - loss: 8.8657e-06 - val_loss: 5.0150e-08
Epoch 160/512
448/448 - 0s - loss: 8.7828e-06 - val_loss: 4.8258e-08
Epoch 161/512
448/448 - 0s - loss: 8.3398e-06 - val_loss: 4.7430e-08
Epoch 162/512
448/448 - 0s - loss: 8.2734e-06 - val_loss: 4.6347e-08
Epoch 163/512
448/448 - 0s - loss: 8.0088e-06 - val_loss: 4.4902e-08
Epoch 164/512
448/448 - 0s - loss: 7.7403e-06 - val_loss: 4.3998e-08
Epoch 165/512
448/448 - 0s - loss: 7.6113e-06 - val_loss: 4.3061e-08
Epoch 166/512
448/448 - 0s - loss: 7.4307e-06 - val_loss: 4.1120e-08
Epoch 167/512
448/448 - 0s - loss: 7.0793e-06 - val_loss: 3.9721e-08
Epoch 168/512
448/448 - 0s - loss: 6.8855e-06 - val_loss: 3.9376e-08
Epoch 169/512
448/448 - 0s - loss: 6.8261e-06 - val_loss: 3.8362e-08
Epoch 170/512
448/448 - 0s - loss: 6.5658e-06 - val_loss: 3.6996e-08
Epoch 171/512
448/448 - 0s - loss: 6.3124e-06 - val_loss: 3.6608e-08
Epoch 172/512
448/448 - 0s - loss: 6.2735e-06 - val_loss: 3.5450e-08
Epoch 173/512
448/448 - 0s - loss: 5.9900e-06 - val_loss: 3.4361e-08
Epoch 174/512
448/448 - 0s - loss: 5.8284e-06 - val_loss: 3.3484e-08
Epoch 175/512
448/448 - 0s - loss: 5.6126e-06 - val_loss: 3.3431e-08
Epoch 176/512
448/448 - 0s - loss: 5.6409e-06 - val_loss: 3.1655e-08
Epoch 177/512
448/448 - 0s - loss: 5.2441e-06 - val_loss: 3.0389e-08
Epoch 178/512
448/448 - 0s - loss: 5.0961e-06 - val_loss: 3.0553e-08
Epoch 179/512
448/448 - 0s - loss: 5.0895e-06 - val_loss: 3.0014e-08
Epoch 180/512
448/448 - 0s - loss: 4.8904e-06 - val_loss: 2.8538e-08
Epoch 181/512
448/448 - 0s - loss: 4.6411e-06 - val_loss: 2.7658e-08
Epoch 182/512
448/448 - 0s - loss: 4.5457e-06 - val_loss: 2.7214e-08
Epoch 183/512
448/448 - 0s - loss: 4.4349e-06 - val_loss: 2.6556e-08
Epoch 184/512
448/448 - 0s - loss: 4.2846e-06 - val_loss: 2.5575e-08
Epoch 185/512
448/448 - 0s - loss: 4.0601e-06 - val_loss: 2.5547e-08
Epoch 186/512
448/448 - 0s - loss: 4.1110e-06 - val_loss: 2.4553e-08
Epoch 187/512
448/448 - 0s - loss: 3.8382e-06 - val_loss: 2.3396e-08
Epoch 188/512
448/448 - 0s - loss: 3.6570e-06 - val_loss: 2.3844e-08
Epoch 189/512
448/448 - 0s - loss: 3.7255e-06 - val_loss: 2.3275e-08
Epoch 190/512
448/448 - 0s - loss: 3.5272e-06 - val_loss: 2.1867e-08
Epoch 191/512
448/448 - 0s - loss: 3.2914e-06 - val_loss: 2.1727e-08
Epoch 192/512
448/448 - 0s - loss: 3.3403e-06 - val_loss: 2.1227e-08
Epoch 193/512
448/448 - 0s - loss: 3.1684e-06 - val_loss: 2.0367e-08
Epoch 194/512
448/448 - 0s - loss: 2.9994e-06 - val_loss: 2.0261e-08
Epoch 195/512
448/448 - 0s - loss: 3.0263e-06 - val_loss: 1.9449e-08
Epoch 196/512
448/448 - 0s - loss: 2.8218e-06 - val_loss: 1.8791e-08
Epoch 197/512
448/448 - 0s - loss: 2.7264e-06 - val_loss: 1.8676e-08
Epoch 198/512
448/448 - 0s - loss: 2.6842e-06 - val_loss: 1.8469e-08
Epoch 199/512
448/448 - 0s - loss: 2.6167e-06 - val_loss: 1.7310e-08
Epoch 200/512
448/448 - 0s - loss: 2.4180e-06 - val_loss: 1.6706e-08
Epoch 201/512
448/448 - 0s - loss: 2.3657e-06 - val_loss: 1.6773e-08
Epoch 202/512
448/448 - 0s - loss: 2.3275e-06 - val_loss: 1.6669e-08
Epoch 203/512
448/448 - 0s - loss: 2.2672e-06 - val_loss: 1.5739e-08
Epoch 204/512
448/448 - 0s - loss: 2.1026e-06 - val_loss: 1.5192e-08
Epoch 205/512
448/448 - 0s - loss: 2.0340e-06 - val_loss: 1.5399e-08
Epoch 206/512
448/448 - 0s - loss: 2.0572e-06 - val_loss: 1.4718e-08
Epoch 207/512
448/448 - 0s - loss: 1.8916e-06 - val_loss: 1.4036e-08
Epoch 208/512
448/448 - 0s - loss: 1.7934e-06 - val_loss: 1.4215e-08
Epoch 209/512
448/448 - 0s - loss: 1.8368e-06 - val_loss: 1.3870e-08
Epoch 210/512
448/448 - 0s - loss: 1.7087e-06 - val_loss: 1.3272e-08
Epoch 211/512
448/448 - 0s - loss: 1.6319e-06 - val_loss: 1.2986e-08
Epoch 212/512
448/448 - 0s - loss: 1.5896e-06 - val_loss: 1.2793e-08
Epoch 213/512
448/448 - 0s - loss: 1.5424e-06 - val_loss: 1.2353e-08
Epoch 214/512
448/448 - 0s - loss: 1.4600e-06 - val_loss: 1.1924e-08
Epoch 215/512
448/448 - 0s - loss: 1.3927e-06 - val_loss: 1.1914e-08
Epoch 216/512
448/448 - 0s - loss: 1.3788e-06 - val_loss: 1.1814e-08
Epoch 217/512
448/448 - 0s - loss: 1.3499e-06 - val_loss: 1.0859e-08
Epoch 218/512
448/448 - 0s - loss: 1.1855e-06 - val_loss: 1.0746e-08
Epoch 219/512
448/448 - 0s - loss: 1.2110e-06 - val_loss: 1.1070e-08
Epoch 220/512
448/448 - 0s - loss: 1.2248e-06 - val_loss: 1.0383e-08
Epoch 221/512
448/448 - 0s - loss: 1.0782e-06 - val_loss: 9.9653e-09
Epoch 222/512
448/448 - 0s - loss: 1.0492e-06 - val_loss: 1.0153e-08
Epoch 223/512
448/448 - 0s - loss: 1.0718e-06 - val_loss: 9.8748e-09
Epoch 224/512
448/448 - 0s - loss: 9.9466e-07 - val_loss: 9.3242e-09
Epoch 225/512
448/448 - 0s - loss: 9.2918e-07 - val_loss: 9.1355e-09
Epoch 226/512
448/448 - 0s - loss: 9.0705e-07 - val_loss: 9.1527e-09
Epoch 227/512
448/448 - 0s - loss: 8.9675e-07 - val_loss: 8.8526e-09
Epoch 228/512
448/448 - 0s - loss: 8.3683e-07 - val_loss: 8.4698e-09
Epoch 229/512
448/448 - 0s - loss: 7.8967e-07 - val_loss: 8.4774e-09
Epoch 230/512
448/448 - 0s - loss: 7.9325e-07 - val_loss: 8.2684e-09
Epoch 231/512
448/448 - 0s - loss: 7.4200e-07 - val_loss: 7.9322e-09
Epoch 232/512
448/448 - 0s - loss: 7.0371e-07 - val_loss: 7.8251e-09
Epoch 233/512
448/448 - 0s - loss: 6.8713e-07 - val_loss: 7.7220e-09
Epoch 234/512
448/448 - 0s - loss: 6.6259e-07 - val_loss: 7.4165e-09
Epoch 235/512
448/448 - 0s - loss: 6.1743e-07 - val_loss: 7.3120e-09
Epoch 236/512
448/448 - 0s - loss: 6.0559e-07 - val_loss: 7.2308e-09
Epoch 237/512
448/448 - 0s - loss: 5.8930e-07 - val_loss: 6.9277e-09
Epoch 238/512
448/448 - 0s - loss: 5.4429e-07 - val_loss: 6.7710e-09
Epoch 239/512
448/448 - 0s - loss: 5.2731e-07 - val_loss: 6.7324e-09
Epoch 240/512
448/448 - 0s - loss: 5.1542e-07 - val_loss: 6.5807e-09
Epoch 241/512
448/448 - 0s - loss: 4.8921e-07 - val_loss: 6.3250e-09
Epoch 242/512
448/448 - 0s - loss: 4.5542e-07 - val_loss: 6.3147e-09
Epoch 243/512
448/448 - 0s - loss: 4.6126e-07 - val_loss: 6.1017e-09
Epoch 244/512
448/448 - 0s - loss: 4.2164e-07 - val_loss: 5.9359e-09
Epoch 245/512
448/448 - 0s - loss: 4.0763e-07 - val_loss: 5.8287e-09
Epoch 246/512
448/448 - 0s - loss: 3.9106e-07 - val_loss: 5.7591e-09
Epoch 247/512
448/448 - 0s - loss: 3.7906e-07 - val_loss: 5.6386e-09
Epoch 248/512
448/448 - 0s - loss: 3.6166e-07 - val_loss: 5.4737e-09
Epoch 249/512
448/448 - 0s - loss: 3.3886e-07 - val_loss: 5.3867e-09
Epoch 250/512
448/448 - 0s - loss: 3.3582e-07 - val_loss: 5.2346e-09
Epoch 251/512
448/448 - 0s - loss: 3.1166e-07 - val_loss: 5.0902e-09
Epoch 252/512
448/448 - 0s - loss: 2.9638e-07 - val_loss: 5.0568e-09
Epoch 253/512
448/448 - 0s - loss: 2.9402e-07 - val_loss: 4.9606e-09
Epoch 254/512
448/448 - 0s - loss: 2.7691e-07 - val_loss: 4.7846e-09
Epoch 255/512
448/448 - 0s - loss: 2.5772e-07 - val_loss: 4.7427e-09
Epoch 256/512
448/448 - 0s - loss: 2.5674e-07 - val_loss: 4.6487e-09
Epoch 257/512
448/448 - 0s - loss: 2.4232e-07 - val_loss: 4.5045e-09
Epoch 258/512
448/448 - 0s - loss: 2.2690e-07 - val_loss: 4.4296e-09
Epoch 259/512
448/448 - 0s - loss: 2.2051e-07 - val_loss: 4.3806e-09
Epoch 260/512
448/448 - 0s - loss: 2.1306e-07 - val_loss: 4.2988e-09
Epoch 261/512
448/448 - 0s - loss: 2.0374e-07 - val_loss: 4.1552e-09
Epoch 262/512
448/448 - 0s - loss: 1.8986e-07 - val_loss: 4.0408e-09
Epoch 263/512
448/448 - 0s - loss: 1.8068e-07 - val_loss: 4.0206e-09
Epoch 264/512
448/448 - 0s - loss: 1.7856e-07 - val_loss: 3.9646e-09
Epoch 265/512
448/448 - 0s - loss: 1.7075e-07 - val_loss: 3.8284e-09
Epoch 266/512
448/448 - 0s - loss: 1.5649e-07 - val_loss: 3.7539e-09
Epoch 267/512
448/448 - 0s - loss: 1.5234e-07 - val_loss: 3.7325e-09
Epoch 268/512
448/448 - 0s - loss: 1.4822e-07 - val_loss: 3.6866e-09
Epoch 269/512
448/448 - 0s - loss: 1.4173e-07 - val_loss: 3.5989e-09
Epoch 270/512
448/448 - 0s - loss: 1.3525e-07 - val_loss: 3.4639e-09
Epoch 271/512
448/448 - 0s - loss: 1.2369e-07 - val_loss: 3.4186e-09
Epoch 272/512
448/448 - 0s - loss: 1.2143e-07 - val_loss: 3.4415e-09
Epoch 273/512
448/448 - 0s - loss: 1.2277e-07 - val_loss: 3.3260e-09
Epoch 274/512
448/448 - 0s - loss: 1.0954e-07 - val_loss: 3.2100e-09
Epoch 275/512
448/448 - 0s - loss: 1.0233e-07 - val_loss: 3.1974e-09
Epoch 276/512
448/448 - 0s - loss: 1.0397e-07 - val_loss: 3.1753e-09
Epoch 277/512
448/448 - 0s - loss: 1.0053e-07 - val_loss: 3.0575e-09
Epoch 278/512
448/448 - 0s - loss: 8.9067e-08 - val_loss: 3.0106e-09
Epoch 279/512
448/448 - 0s - loss: 8.8567e-08 - val_loss: 2.9986e-09
Epoch 280/512
448/448 - 0s - loss: 8.7263e-08 - val_loss: 2.9167e-09
Epoch 281/512
448/448 - 0s - loss: 7.9154e-08 - val_loss: 2.8551e-09
Epoch 282/512
448/448 - 0s - loss: 7.6576e-08 - val_loss: 2.8377e-09
Epoch 283/512
448/448 - 0s - loss: 7.5887e-08 - val_loss: 2.7817e-09
Epoch 284/512
448/448 - 0s - loss: 7.0496e-08 - val_loss: 2.7058e-09
Epoch 285/512
448/448 - 0s - loss: 6.5521e-08 - val_loss: 2.6848e-09
Epoch 286/512
448/448 - 0s - loss: 6.5630e-08 - val_loss: 2.6509e-09
Epoch 287/512
448/448 - 0s - loss: 6.2076e-08 - val_loss: 2.5870e-09
Epoch 288/512
448/448 - 0s - loss: 5.7662e-08 - val_loss: 2.5460e-09
Epoch 289/512
448/448 - 0s - loss: 5.5826e-08 - val_loss: 2.5188e-09
Epoch 290/512
448/448 - 0s - loss: 5.4362e-08 - val_loss: 2.4776e-09
Epoch 291/512
448/448 - 0s - loss: 5.1244e-08 - val_loss: 2.4237e-09
Epoch 292/512
448/448 - 0s - loss: 4.7989e-08 - val_loss: 2.4084e-09
Epoch 293/512
448/448 - 0s - loss: 4.7916e-08 - val_loss: 2.3740e-09
Epoch 294/512
448/448 - 0s - loss: 4.5159e-08 - val_loss: 2.3148e-09
Epoch 295/512
448/448 - 0s - loss: 4.1722e-08 - val_loss: 2.2919e-09
Epoch 296/512
448/448 - 0s - loss: 4.1548e-08 - val_loss: 2.2644e-09
Epoch 297/512
448/448 - 0s - loss: 3.9567e-08 - val_loss: 2.2210e-09
Epoch 298/512
448/448 - 0s - loss: 3.7213e-08 - val_loss: 2.1775e-09
Epoch 299/512
448/448 - 0s - loss: 3.5123e-08 - val_loss: 2.1617e-09
Epoch 300/512
448/448 - 0s - loss: 3.4765e-08 - val_loss: 2.1394e-09
Epoch 301/512
448/448 - 0s - loss: 3.3497e-08 - val_loss: 2.0898e-09
Epoch 302/512
448/448 - 0s - loss: 3.0250e-08 - val_loss: 2.0701e-09
Epoch 303/512
448/448 - 0s - loss: 3.0415e-08 - val_loss: 2.0437e-09
Epoch 304/512
448/448 - 0s - loss: 2.8504e-08 - val_loss: 2.0291e-09
Epoch 305/512
448/448 - 0s - loss: 2.8342e-08 - val_loss: 1.9919e-09
Epoch 306/512
448/448 - 0s - loss: 2.6255e-08 - val_loss: 1.9531e-09
Epoch 307/512
448/448 - 0s - loss: 2.4765e-08 - val_loss: 1.9236e-09
Epoch 308/512
448/448 - 0s - loss: 2.3705e-08 - val_loss: 1.9133e-09
Epoch 309/512
448/448 - 0s - loss: 2.3531e-08 - val_loss: 1.8956e-09
Epoch 310/512
448/448 - 0s - loss: 2.2745e-08 - val_loss: 1.8571e-09
Epoch 311/512
448/448 - 0s - loss: 2.0806e-08 - val_loss: 1.8278e-09
Epoch 312/512
448/448 - 0s - loss: 1.9803e-08 - val_loss: 1.8185e-09
Epoch 313/512
448/448 - 0s - loss: 2.0097e-08 - val_loss: 1.7991e-09
Epoch 314/512
448/448 - 0s - loss: 1.8993e-08 - val_loss: 1.7628e-09
Epoch 315/512
448/448 - 0s - loss: 1.7438e-08 - val_loss: 1.7429e-09
Epoch 316/512
448/448 - 0s - loss: 1.7086e-08 - val_loss: 1.7311e-09
Epoch 317/512
448/448 - 0s - loss: 1.6952e-08 - val_loss: 1.7091e-09
Epoch 318/512
448/448 - 0s - loss: 1.5949e-08 - val_loss: 1.6838e-09
Epoch 319/512
448/448 - 0s - loss: 1.5163e-08 - val_loss: 1.6623e-09
Epoch 320/512
448/448 - 0s - loss: 1.4424e-08 - val_loss: 1.6540e-09
Epoch 321/512
448/448 - 0s - loss: 1.4426e-08 - val_loss: 1.6331e-09
Epoch 322/512
448/448 - 0s - loss: 1.3607e-08 - val_loss: 1.6081e-09
Epoch 323/512
448/448 - 0s - loss: 1.2935e-08 - val_loss: 1.5881e-09
Epoch 324/512
448/448 - 0s - loss: 1.2336e-08 - val_loss: 1.5760e-09
Epoch 325/512
448/448 - 0s - loss: 1.2241e-08 - val_loss: 1.5584e-09
Epoch 326/512
448/448 - 0s - loss: 1.1657e-08 - val_loss: 1.5371e-09
Epoch 327/512
448/448 - 0s - loss: 1.1077e-08 - val_loss: 1.5166e-09
Epoch 328/512
448/448 - 0s - loss: 1.0408e-08 - val_loss: 1.5071e-09
Epoch 329/512
448/448 - 0s - loss: 1.0449e-08 - val_loss: 1.4974e-09
Epoch 330/512
448/448 - 0s - loss: 1.0377e-08 - val_loss: 1.4770e-09
Epoch 331/512
448/448 - 0s - loss: 9.5362e-09 - val_loss: 1.4550e-09
Epoch 332/512
448/448 - 0s - loss: 9.0663e-09 - val_loss: 1.4441e-09
Epoch 333/512
448/448 - 0s - loss: 8.9455e-09 - val_loss: 1.4323e-09
Epoch 334/512
448/448 - 0s - loss: 8.7559e-09 - val_loss: 1.4170e-09
Epoch 335/512
448/448 - 0s - loss: 8.3729e-09 - val_loss: 1.3991e-09
Epoch 336/512
448/448 - 0s - loss: 7.9028e-09 - val_loss: 1.3877e-09
Epoch 337/512
448/448 - 0s - loss: 7.7784e-09 - val_loss: 1.3761e-09
Epoch 338/512
448/448 - 0s - loss: 7.5892e-09 - val_loss: 1.3585e-09
Epoch 339/512
448/448 - 0s - loss: 7.1193e-09 - val_loss: 1.3465e-09
Epoch 340/512
448/448 - 0s - loss: 7.1175e-09 - val_loss: 1.3356e-09
Epoch 341/512
448/448 - 0s - loss: 6.7809e-09 - val_loss: 1.3216e-09
Epoch 342/512
448/448 - 0s - loss: 6.6538e-09 - val_loss: 1.3060e-09
Epoch 343/512
448/448 - 0s - loss: 6.2898e-09 - val_loss: 1.2943e-09
Epoch 344/512
448/448 - 0s - loss: 6.0607e-09 - val_loss: 1.2841e-09
Epoch 345/512
448/448 - 0s - loss: 6.0913e-09 - val_loss: 1.2694e-09
Epoch 346/512
448/448 - 0s - loss: 5.6737e-09 - val_loss: 1.2580e-09
Epoch 347/512
448/448 - 0s - loss: 5.5854e-09 - val_loss: 1.2464e-09
Epoch 348/512
448/448 - 0s - loss: 5.4116e-09 - val_loss: 1.2357e-09
Epoch 349/512
448/448 - 0s - loss: 5.2405e-09 - val_loss: 1.2258e-09
Epoch 350/512
448/448 - 0s - loss: 5.0848e-09 - val_loss: 1.2142e-09
Epoch 351/512
448/448 - 0s - loss: 4.9814e-09 - val_loss: 1.2042e-09
Epoch 352/512
448/448 - 0s - loss: 4.8344e-09 - val_loss: 1.1910e-09
Epoch 353/512
448/448 - 0s - loss: 4.5750e-09 - val_loss: 1.1810e-09
Epoch 354/512
448/448 - 0s - loss: 4.4811e-09 - val_loss: 1.1743e-09
Epoch 355/512
448/448 - 0s - loss: 4.5094e-09 - val_loss: 1.1639e-09
Epoch 356/512
448/448 - 0s - loss: 4.3243e-09 - val_loss: 1.1522e-09
Epoch 357/512
448/448 - 0s - loss: 4.1620e-09 - val_loss: 1.1403e-09
Epoch 358/512
448/448 - 0s - loss: 3.9725e-09 - val_loss: 1.1331e-09
Epoch 359/512
448/448 - 0s - loss: 4.0109e-09 - val_loss: 1.1222e-09
Epoch 360/512
448/448 - 0s - loss: 3.7831e-09 - val_loss: 1.1118e-09
Epoch 361/512
448/448 - 0s - loss: 3.7180e-09 - val_loss: 1.1040e-09
Epoch 362/512
448/448 - 0s - loss: 3.6617e-09 - val_loss: 1.0960e-09
Epoch 363/512
448/448 - 0s - loss: 3.5686e-09 - val_loss: 1.0879e-09
Epoch 364/512
448/448 - 0s - loss: 3.5054e-09 - val_loss: 1.0782e-09
Epoch 365/512
448/448 - 0s - loss: 3.3745e-09 - val_loss: 1.0657e-09
Epoch 366/512
448/448 - 0s - loss: 3.1769e-09 - val_loss: 1.0589e-09
Epoch 367/512
448/448 - 0s - loss: 3.1993e-09 - val_loss: 1.0541e-09
Epoch 368/512
448/448 - 0s - loss: 3.2206e-09 - val_loss: 1.0457e-09
Epoch 369/512
448/448 - 0s - loss: 3.1050e-09 - val_loss: 1.0336e-09
Epoch 370/512
448/448 - 0s - loss: 2.9035e-09 - val_loss: 1.0251e-09
Epoch 371/512
448/448 - 0s - loss: 2.8547e-09 - val_loss: 1.0190e-09
Epoch 372/512
448/448 - 0s - loss: 2.8721e-09 - val_loss: 1.0117e-09
Epoch 373/512
448/448 - 0s - loss: 2.8004e-09 - val_loss: 1.0068e-09
Epoch 374/512
448/448 - 0s - loss: 2.7954e-09 - val_loss: 9.9564e-10
Epoch 375/512
448/448 - 0s - loss: 2.6369e-09 - val_loss: 9.8691e-10
Epoch 376/512
448/448 - 0s - loss: 2.5382e-09 - val_loss: 9.7797e-10
Epoch 377/512
448/448 - 0s - loss: 2.4670e-09 - val_loss: 9.7242e-10
Epoch 378/512
448/448 - 0s - loss: 2.4837e-09 - val_loss: 9.6863e-10
Epoch 379/512
448/448 - 0s - loss: 2.4965e-09 - val_loss: 9.6206e-10
Epoch 380/512
448/448 - 0s - loss: 2.4389e-09 - val_loss: 9.5397e-10
Epoch 381/512
448/448 - 0s - loss: 2.3303e-09 - val_loss: 9.4298e-10
Epoch 382/512
448/448 - 0s - loss: 2.1670e-09 - val_loss: 9.3614e-10
Epoch 383/512
448/448 - 0s - loss: 2.1722e-09 - val_loss: 9.3090e-10
Epoch 384/512
448/448 - 0s - loss: 2.1776e-09 - val_loss: 9.2635e-10
Epoch 385/512
448/448 - 0s - loss: 2.1637e-09 - val_loss: 9.1982e-10
Epoch 386/512
448/448 - 0s - loss: 2.1258e-09 - val_loss: 9.1215e-10
Epoch 387/512
448/448 - 0s - loss: 2.0538e-09 - val_loss: 9.0591e-10
Epoch 388/512
448/448 - 0s - loss: 2.0069e-09 - val_loss: 8.9973e-10
Epoch 389/512
448/448 - 0s - loss: 1.9935e-09 - val_loss: 8.9450e-10
Epoch 390/512
448/448 - 0s - loss: 1.9669e-09 - val_loss: 8.8787e-10
Epoch 391/512
448/448 - 0s - loss: 1.8915e-09 - val_loss: 8.8048e-10
Epoch 392/512
448/448 - 0s - loss: 1.8297e-09 - val_loss: 8.7572e-10
Epoch 393/512
448/448 - 0s - loss: 1.8449e-09 - val_loss: 8.6996e-10
Epoch 394/512
448/448 - 0s - loss: 1.8146e-09 - val_loss: 8.6412e-10
Epoch 395/512
448/448 - 0s - loss: 1.7768e-09 - val_loss: 8.5804e-10
Epoch 396/512
448/448 - 0s - loss: 1.7450e-09 - val_loss: 8.5258e-10
Epoch 397/512
448/448 - 0s - loss: 1.6978e-09 - val_loss: 8.4628e-10
Epoch 398/512
448/448 - 0s - loss: 1.6758e-09 - val_loss: 8.4106e-10
Epoch 399/512
448/448 - 0s - loss: 1.6307e-09 - val_loss: 8.3627e-10
Epoch 400/512
448/448 - 0s - loss: 1.6122e-09 - val_loss: 8.3066e-10
Epoch 401/512
448/448 - 0s - loss: 1.5862e-09 - val_loss: 8.2549e-10
Epoch 402/512
448/448 - 0s - loss: 1.5661e-09 - val_loss: 8.2114e-10
Epoch 403/512
448/448 - 0s - loss: 1.5617e-09 - val_loss: 8.1567e-10
Epoch 404/512
448/448 - 0s - loss: 1.5271e-09 - val_loss: 8.0928e-10
Epoch 405/512
448/448 - 0s - loss: 1.4782e-09 - val_loss: 8.0544e-10
Epoch 406/512
448/448 - 0s - loss: 1.4580e-09 - val_loss: 7.9912e-10
Epoch 407/512
448/448 - 0s - loss: 1.4288e-09 - val_loss: 7.9438e-10
Epoch 408/512
448/448 - 0s - loss: 1.4097e-09 - val_loss: 7.9034e-10
Epoch 409/512
448/448 - 0s - loss: 1.4040e-09 - val_loss: 7.8547e-10
Epoch 410/512
448/448 - 0s - loss: 1.3784e-09 - val_loss: 7.8112e-10
Epoch 411/512
448/448 - 0s - loss: 1.3687e-09 - val_loss: 7.7692e-10
Epoch 412/512
448/448 - 0s - loss: 1.3535e-09 - val_loss: 7.7068e-10
Epoch 413/512
448/448 - 0s - loss: 1.2851e-09 - val_loss: 7.6690e-10
Epoch 414/512
448/448 - 0s - loss: 1.2905e-09 - val_loss: 7.6167e-10
Epoch 415/512
448/448 - 0s - loss: 1.2586e-09 - val_loss: 7.5676e-10
Epoch 416/512
448/448 - 0s - loss: 1.2261e-09 - val_loss: 7.5259e-10
Epoch 417/512
448/448 - 0s - loss: 1.2397e-09 - val_loss: 7.4955e-10
Epoch 418/512
448/448 - 0s - loss: 1.2390e-09 - val_loss: 7.4536e-10
Epoch 419/512
448/448 - 0s - loss: 1.2202e-09 - val_loss: 7.4013e-10
Epoch 420/512
448/448 - 0s - loss: 1.1853e-09 - val_loss: 7.3623e-10
Epoch 421/512
448/448 - 0s - loss: 1.1770e-09 - val_loss: 7.3196e-10
Epoch 422/512
448/448 - 0s - loss: 1.1537e-09 - val_loss: 7.2687e-10
Epoch 423/512
448/448 - 0s - loss: 1.1262e-09 - val_loss: 7.2340e-10
Epoch 424/512
448/448 - 0s - loss: 1.1177e-09 - val_loss: 7.1985e-10
Epoch 425/512
448/448 - 0s - loss: 1.1130e-09 - val_loss: 7.1570e-10
Epoch 426/512
448/448 - 0s - loss: 1.0977e-09 - val_loss: 7.1179e-10
Epoch 427/512
448/448 - 0s - loss: 1.0866e-09 - val_loss: 7.0822e-10
Epoch 428/512
448/448 - 0s - loss: 1.0674e-09 - val_loss: 7.0461e-10
Epoch 429/512
448/448 - 0s - loss: 1.0638e-09 - val_loss: 7.0056e-10
Epoch 430/512
448/448 - 0s - loss: 1.0359e-09 - val_loss: 6.9741e-10
Epoch 431/512
448/448 - 0s - loss: 1.0358e-09 - val_loss: 6.9264e-10
Epoch 432/512
448/448 - 0s - loss: 1.0039e-09 - val_loss: 6.8811e-10
Epoch 433/512
448/448 - 0s - loss: 9.8457e-10 - val_loss: 6.8445e-10
Epoch 434/512
448/448 - 0s - loss: 9.8412e-10 - val_loss: 6.8190e-10
Epoch 435/512
448/448 - 0s - loss: 9.7699e-10 - val_loss: 6.7935e-10
Epoch 436/512
448/448 - 0s - loss: 9.9007e-10 - val_loss: 6.7567e-10
Epoch 437/512
448/448 - 0s - loss: 9.8139e-10 - val_loss: 6.7087e-10
Epoch 438/512
448/448 - 0s - loss: 9.3322e-10 - val_loss: 6.6658e-10
Epoch 439/512
448/448 - 0s - loss: 9.1670e-10 - val_loss: 6.6320e-10
Epoch 440/512
448/448 - 0s - loss: 9.0548e-10 - val_loss: 6.6066e-10
Epoch 441/512
448/448 - 0s - loss: 9.0608e-10 - val_loss: 6.5763e-10
Epoch 442/512
448/448 - 0s - loss: 8.9866e-10 - val_loss: 6.5508e-10
Epoch 443/512
448/448 - 0s - loss: 9.1799e-10 - val_loss: 6.5142e-10
Epoch 444/512
448/448 - 0s - loss: 8.9401e-10 - val_loss: 6.4797e-10
Epoch 445/512
448/448 - 0s - loss: 8.8364e-10 - val_loss: 6.4421e-10
Epoch 446/512
448/448 - 0s - loss: 8.4098e-10 - val_loss: 6.4068e-10
Epoch 447/512
448/448 - 0s - loss: 8.4073e-10 - val_loss: 6.3763e-10
Epoch 448/512
448/448 - 0s - loss: 8.3560e-10 - val_loss: 6.3537e-10
Epoch 449/512
448/448 - 0s - loss: 8.3773e-10 - val_loss: 6.3108e-10
Epoch 450/512
448/448 - 0s - loss: 8.0798e-10 - val_loss: 6.2931e-10
Epoch 451/512
448/448 - 0s - loss: 8.3181e-10 - val_loss: 6.2635e-10
Epoch 452/512
448/448 - 0s - loss: 8.0516e-10 - val_loss: 6.2259e-10
Epoch 453/512
448/448 - 0s - loss: 7.9868e-10 - val_loss: 6.1981e-10
Epoch 454/512
448/448 - 0s - loss: 7.8619e-10 - val_loss: 6.1696e-10
Epoch 455/512
448/448 - 0s - loss: 7.8664e-10 - val_loss: 6.1344e-10
Epoch 456/512
448/448 - 0s - loss: 7.7680e-10 - val_loss: 6.1068e-10
Epoch 457/512
448/448 - 0s - loss: 7.6027e-10 - val_loss: 6.0777e-10
Epoch 458/512
448/448 - 0s - loss: 7.5051e-10 - val_loss: 6.0457e-10
Epoch 459/512
448/448 - 0s - loss: 7.4527e-10 - val_loss: 6.0263e-10
Epoch 460/512
448/448 - 0s - loss: 7.4754e-10 - val_loss: 6.0090e-10
Epoch 461/512
448/448 - 0s - loss: 7.5576e-10 - val_loss: 5.9768e-10
Epoch 462/512
448/448 - 0s - loss: 7.3350e-10 - val_loss: 5.9442e-10
Epoch 463/512
448/448 - 0s - loss: 7.2329e-10 - val_loss: 5.9016e-10
Epoch 464/512
448/448 - 0s - loss: 7.0332e-10 - val_loss: 5.8780e-10
Epoch 465/512
448/448 - 0s - loss: 6.9395e-10 - val_loss: 5.8569e-10
Epoch 466/512
448/448 - 0s - loss: 7.0387e-10 - val_loss: 5.8419e-10
Epoch 467/512
448/448 - 0s - loss: 7.0830e-10 - val_loss: 5.8254e-10
Epoch 468/512
448/448 - 0s - loss: 7.1324e-10 - val_loss: 5.7970e-10
Epoch 469/512
448/448 - 0s - loss: 7.1569e-10 - val_loss: 5.7699e-10
Epoch 470/512
448/448 - 0s - loss: 6.9110e-10 - val_loss: 5.7293e-10
Epoch 471/512
448/448 - 0s - loss: 6.5135e-10 - val_loss: 5.6961e-10
Epoch 472/512
448/448 - 0s - loss: 6.4000e-10 - val_loss: 5.6721e-10
Epoch 473/512
448/448 - 0s - loss: 6.3869e-10 - val_loss: 5.6592e-10
Epoch 474/512
448/448 - 0s - loss: 6.4642e-10 - val_loss: 5.6413e-10
Epoch 475/512
448/448 - 0s - loss: 6.7127e-10 - val_loss: 5.6156e-10
Epoch 476/512
448/448 - 0s - loss: 6.5769e-10 - val_loss: 5.5822e-10
Epoch 477/512
448/448 - 0s - loss: 6.3229e-10 - val_loss: 5.5524e-10
Epoch 478/512
448/448 - 0s - loss: 6.1225e-10 - val_loss: 5.5302e-10
Epoch 479/512
448/448 - 0s - loss: 6.0898e-10 - val_loss: 5.5084e-10
Epoch 480/512
448/448 - 0s - loss: 6.2081e-10 - val_loss: 5.4875e-10
Epoch 481/512
448/448 - 0s - loss: 6.1783e-10 - val_loss: 5.4704e-10
Epoch 482/512
448/448 - 0s - loss: 6.1183e-10 - val_loss: 5.4435e-10
Epoch 483/512
448/448 - 0s - loss: 6.0972e-10 - val_loss: 5.4264e-10
Epoch 484/512
448/448 - 0s - loss: 6.0096e-10 - val_loss: 5.3987e-10
Epoch 485/512
448/448 - 0s - loss: 6.0899e-10 - val_loss: 5.3821e-10
Epoch 486/512
448/448 - 0s - loss: 5.9943e-10 - val_loss: 5.3545e-10
Epoch 487/512
448/448 - 0s - loss: 5.8473e-10 - val_loss: 5.3211e-10
Epoch 488/512
448/448 - 0s - loss: 5.6273e-10 - val_loss: 5.2973e-10
Epoch 489/512
448/448 - 0s - loss: 5.5004e-10 - val_loss: 5.2778e-10
Epoch 490/512
448/448 - 0s - loss: 5.5245e-10 - val_loss: 5.2609e-10
Epoch 491/512
448/448 - 0s - loss: 5.7407e-10 - val_loss: 5.2481e-10
Epoch 492/512
448/448 - 0s - loss: 5.7491e-10 - val_loss: 5.2235e-10
Epoch 493/512
448/448 - 0s - loss: 5.6081e-10 - val_loss: 5.2060e-10
Epoch 494/512
448/448 - 0s - loss: 5.4725e-10 - val_loss: 5.1763e-10
Epoch 495/512
448/448 - 0s - loss: 5.3756e-10 - val_loss: 5.1525e-10
Epoch 496/512
448/448 - 0s - loss: 5.3502e-10 - val_loss: 5.1450e-10
Epoch 497/512
448/448 - 0s - loss: 5.4004e-10 - val_loss: 5.1257e-10
Epoch 498/512
448/448 - 0s - loss: 5.4471e-10 - val_loss: 5.0990e-10
Epoch 499/512
448/448 - 0s - loss: 5.3346e-10 - val_loss: 5.0802e-10
Epoch 500/512
448/448 - 0s - loss: 5.3500e-10 - val_loss: 5.0617e-10
Epoch 501/512
448/448 - 0s - loss: 5.3112e-10 - val_loss: 5.0361e-10
Epoch 502/512
448/448 - 0s - loss: 5.0963e-10 - val_loss: 5.0148e-10
Epoch 503/512
448/448 - 0s - loss: 5.0608e-10 - val_loss: 4.9970e-10
Epoch 504/512
448/448 - 0s - loss: 5.0520e-10 - val_loss: 4.9787e-10
Epoch 505/512
448/448 - 0s - loss: 5.0906e-10 - val_loss: 4.9615e-10
Epoch 506/512
448/448 - 0s - loss: 5.0229e-10 - val_loss: 4.9423e-10
Epoch 507/512
448/448 - 0s - loss: 5.0008e-10 - val_loss: 4.9224e-10
Epoch 508/512
448/448 - 0s - loss: 4.8976e-10 - val_loss: 4.9074e-10
Epoch 509/512
448/448 - 0s - loss: 4.8130e-10 - val_loss: 4.8825e-10
Epoch 510/512
448/448 - 0s - loss: 4.8873e-10 - val_loss: 4.8701e-10
Epoch 511/512
448/448 - 0s - loss: 4.9301e-10 - val_loss: 4.8600e-10
Epoch 512/512
448/448 - 0s - loss: 4.9355e-10 - val_loss: 4.8412e-10
Train on 448 samples, validate on 448 samples
Epoch 1/512

Epoch 00001: val_loss improved from inf to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 9.3123e-09 - val_loss: 2.2477e-08
Epoch 2/512

Epoch 00002: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.4331e-08 - val_loss: 1.8528e-09
Epoch 3/512

Epoch 00003: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.1365e-09 - val_loss: 3.9942e-10
Epoch 4/512

Epoch 00004: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 3.5546e-10 - val_loss: 3.4837e-10
Epoch 5/512

Epoch 00005: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.4497e-10 - val_loss: 8.6526e-10
Epoch 6/512

Epoch 00006: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6272e-09 - val_loss: 4.3938e-09
Epoch 7/512

Epoch 00007: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.5215e-09 - val_loss: 7.0098e-09
Epoch 8/512

Epoch 00008: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.8322e-09 - val_loss: 2.7641e-09
Epoch 9/512

Epoch 00009: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2501e-09 - val_loss: 1.4681e-09
Epoch 10/512

Epoch 00010: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4733e-09 - val_loss: 1.5955e-09
Epoch 11/512

Epoch 00011: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9583e-09 - val_loss: 2.8084e-09
Epoch 12/512

Epoch 00012: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.4206e-09 - val_loss: 3.9638e-09
Epoch 13/512

Epoch 00013: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.9980e-09 - val_loss: 3.1051e-09
Epoch 14/512

Epoch 00014: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.8505e-09 - val_loss: 2.1457e-09
Epoch 15/512

Epoch 00015: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0931e-09 - val_loss: 1.9258e-09
Epoch 16/512

Epoch 00016: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0755e-09 - val_loss: 2.2657e-09
Epoch 17/512

Epoch 00017: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.5055e-09 - val_loss: 2.6501e-09
Epoch 18/512

Epoch 00018: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.7926e-09 - val_loss: 2.6369e-09
Epoch 19/512

Epoch 00019: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.6253e-09 - val_loss: 2.2653e-09
Epoch 20/512

Epoch 00020: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2386e-09 - val_loss: 1.9955e-09
Epoch 21/512

Epoch 00021: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0471e-09 - val_loss: 1.9659e-09
Epoch 22/512

Epoch 00022: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0637e-09 - val_loss: 2.1056e-09
Epoch 23/512

Epoch 00023: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2205e-09 - val_loss: 2.1757e-09
Epoch 24/512

Epoch 00024: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2354e-09 - val_loss: 2.0518e-09
Epoch 25/512

Epoch 00025: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0750e-09 - val_loss: 1.9209e-09
Epoch 26/512

Epoch 00026: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9521e-09 - val_loss: 1.8547e-09
Epoch 27/512

Epoch 00027: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9011e-09 - val_loss: 1.8330e-09
Epoch 28/512

Epoch 00028: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.8902e-09 - val_loss: 1.8382e-09
Epoch 29/512

Epoch 00029: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.8776e-09 - val_loss: 1.7897e-09
Epoch 30/512

Epoch 00030: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.8290e-09 - val_loss: 1.7000e-09
Epoch 31/512

Epoch 00031: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7439e-09 - val_loss: 1.6525e-09
Epoch 32/512

Epoch 00032: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6957e-09 - val_loss: 1.6340e-09
Epoch 33/512

Epoch 00033: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6767e-09 - val_loss: 1.6166e-09
Epoch 34/512

Epoch 00034: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6594e-09 - val_loss: 1.5851e-09
Epoch 35/512

Epoch 00035: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6300e-09 - val_loss: 1.5591e-09
Epoch 36/512

Epoch 00036: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5961e-09 - val_loss: 1.5217e-09
Epoch 37/512

Epoch 00037: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5513e-09 - val_loss: 1.4667e-09
Epoch 38/512

Epoch 00038: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5000e-09 - val_loss: 1.4242e-09
Epoch 39/512

Epoch 00039: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4650e-09 - val_loss: 1.4088e-09
Epoch 40/512

Epoch 00040: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4439e-09 - val_loss: 1.4021e-09
Epoch 41/512

Epoch 00041: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4413e-09 - val_loss: 1.3517e-09
Epoch 42/512

Epoch 00042: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3782e-09 - val_loss: 1.2987e-09
Epoch 43/512

Epoch 00043: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3292e-09 - val_loss: 1.2885e-09
Epoch 44/512

Epoch 00044: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3281e-09 - val_loss: 1.2915e-09
Epoch 45/512

Epoch 00045: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3245e-09 - val_loss: 1.2744e-09
Epoch 46/512

Epoch 00046: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2967e-09 - val_loss: 1.2341e-09
Epoch 47/512

Epoch 00047: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2577e-09 - val_loss: 1.2025e-09
Epoch 48/512

Epoch 00048: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2219e-09 - val_loss: 1.1703e-09
Epoch 49/512

Epoch 00049: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1959e-09 - val_loss: 1.1551e-09
Epoch 50/512

Epoch 00050: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1814e-09 - val_loss: 1.1460e-09
Epoch 51/512

Epoch 00051: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1713e-09 - val_loss: 1.1242e-09
Epoch 52/512

Epoch 00052: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1472e-09 - val_loss: 1.1122e-09
Epoch 53/512

Epoch 00053: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1308e-09 - val_loss: 1.0848e-09
Epoch 54/512

Epoch 00054: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0994e-09 - val_loss: 1.0394e-09
Epoch 55/512

Epoch 00055: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0521e-09 - val_loss: 1.0152e-09
Epoch 56/512

Epoch 00056: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0416e-09 - val_loss: 1.0128e-09
Epoch 57/512

Epoch 00057: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0375e-09 - val_loss: 1.0044e-09
Epoch 58/512

Epoch 00058: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0290e-09 - val_loss: 9.9882e-10
Epoch 59/512

Epoch 00059: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0167e-09 - val_loss: 9.7609e-10
Epoch 60/512

Epoch 00060: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.9891e-10 - val_loss: 9.5490e-10
Epoch 61/512

Epoch 00061: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.7184e-10 - val_loss: 9.2855e-10
Epoch 62/512

Epoch 00062: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.4717e-10 - val_loss: 9.0449e-10
Epoch 63/512

Epoch 00063: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.2792e-10 - val_loss: 8.9542e-10
Epoch 64/512

Epoch 00064: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.1723e-10 - val_loss: 8.8172e-10
Epoch 65/512

Epoch 00065: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.0032e-10 - val_loss: 8.6492e-10
Epoch 66/512

Epoch 00066: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.8178e-10 - val_loss: 8.6213e-10
Epoch 67/512

Epoch 00067: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.8257e-10 - val_loss: 8.4710e-10
Epoch 68/512

Epoch 00068: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.6852e-10 - val_loss: 8.2986e-10
Epoch 69/512

Epoch 00069: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.4144e-10 - val_loss: 8.1974e-10
Epoch 70/512

Epoch 00070: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.3601e-10 - val_loss: 8.0785e-10
Epoch 71/512

Epoch 00071: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.1909e-10 - val_loss: 7.8764e-10
Epoch 72/512

Epoch 00072: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.9959e-10 - val_loss: 7.7057e-10
Epoch 73/512

Epoch 00073: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.8707e-10 - val_loss: 7.6650e-10
Epoch 74/512

Epoch 00074: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.7996e-10 - val_loss: 7.5196e-10
Epoch 75/512

Epoch 00075: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.6497e-10 - val_loss: 7.5219e-10
Epoch 76/512

Epoch 00076: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.6453e-10 - val_loss: 7.4845e-10
Epoch 77/512

Epoch 00077: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.6247e-10 - val_loss: 7.2972e-10
Epoch 78/512

Epoch 00078: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.3792e-10 - val_loss: 7.0538e-10
Epoch 79/512

Epoch 00079: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.1504e-10 - val_loss: 6.9074e-10
Epoch 80/512

Epoch 00080: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.0330e-10 - val_loss: 6.9045e-10
Epoch 81/512

Epoch 00081: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.0478e-10 - val_loss: 6.8812e-10
Epoch 82/512

Epoch 00082: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.9455e-10 - val_loss: 6.7151e-10
Epoch 83/512

Epoch 00083: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.8617e-10 - val_loss: 6.7200e-10
Epoch 84/512

Epoch 00084: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.8306e-10 - val_loss: 6.5709e-10
Epoch 85/512

Epoch 00085: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.6818e-10 - val_loss: 6.5359e-10
Epoch 86/512

Epoch 00086: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.6196e-10 - val_loss: 6.3606e-10
Epoch 87/512

Epoch 00087: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.4301e-10 - val_loss: 6.2133e-10
Epoch 88/512

Epoch 00088: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.3422e-10 - val_loss: 6.2368e-10
Epoch 89/512

Epoch 00089: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.3140e-10 - val_loss: 6.2164e-10
Epoch 90/512

Epoch 00090: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.3335e-10 - val_loss: 6.1151e-10
Epoch 91/512

Epoch 00091: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.1991e-10 - val_loss: 5.9283e-10
Epoch 92/512

Epoch 00092: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.0291e-10 - val_loss: 5.8488e-10
Epoch 93/512

Epoch 00093: val_loss did not improve from 0.00000
448/448 - 0s - loss: 6.0026e-10 - val_loss: 5.8614e-10
Epoch 94/512

Epoch 00094: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.9014e-10 - val_loss: 5.6795e-10
Epoch 95/512

Epoch 00095: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.7432e-10 - val_loss: 5.5806e-10
Epoch 96/512

Epoch 00096: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.6557e-10 - val_loss: 5.5377e-10
Epoch 97/512

Epoch 00097: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.6466e-10 - val_loss: 5.4997e-10
Epoch 98/512

Epoch 00098: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.6299e-10 - val_loss: 5.5038e-10
Epoch 99/512

Epoch 00099: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.6069e-10 - val_loss: 5.4268e-10
Epoch 100/512

Epoch 00100: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.4748e-10 - val_loss: 5.2509e-10
Epoch 101/512

Epoch 00101: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.3060e-10 - val_loss: 5.1675e-10
Epoch 102/512

Epoch 00102: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.2499e-10 - val_loss: 5.1624e-10
Epoch 103/512

Epoch 00103: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.2538e-10 - val_loss: 5.0704e-10
Epoch 104/512

Epoch 00104: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.1298e-10 - val_loss: 5.0171e-10
Epoch 105/512

Epoch 00105: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.0832e-10 - val_loss: 4.9853e-10
Epoch 106/512

Epoch 00106: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.0648e-10 - val_loss: 4.9324e-10
Epoch 107/512

Epoch 00107: val_loss did not improve from 0.00000
448/448 - 0s - loss: 5.0341e-10 - val_loss: 4.9254e-10
Epoch 108/512

Epoch 00108: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.9978e-10 - val_loss: 4.9378e-10
Epoch 109/512

Epoch 00109: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.9878e-10 - val_loss: 4.8430e-10
Epoch 110/512

Epoch 00110: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.8769e-10 - val_loss: 4.6896e-10
Epoch 111/512

Epoch 00111: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.7290e-10 - val_loss: 4.5533e-10
Epoch 112/512

Epoch 00112: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.6253e-10 - val_loss: 4.5216e-10
Epoch 113/512

Epoch 00113: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.6161e-10 - val_loss: 4.5478e-10
Epoch 114/512

Epoch 00114: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.6520e-10 - val_loss: 4.5647e-10
Epoch 115/512

Epoch 00115: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.5785e-10 - val_loss: 4.4738e-10
Epoch 116/512

Epoch 00116: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.5441e-10 - val_loss: 4.3965e-10
Epoch 117/512

Epoch 00117: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.4569e-10 - val_loss: 4.2914e-10
Epoch 118/512

Epoch 00118: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.3442e-10 - val_loss: 4.2778e-10
Epoch 119/512

Epoch 00119: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.3901e-10 - val_loss: 4.3726e-10
Epoch 120/512

Epoch 00120: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.4005e-10 - val_loss: 4.3237e-10
Epoch 121/512

Epoch 00121: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.3986e-10 - val_loss: 4.2228e-10
Epoch 122/512

Epoch 00122: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.2463e-10 - val_loss: 4.0998e-10
Epoch 123/512

Epoch 00123: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.1563e-10 - val_loss: 4.0297e-10
Epoch 124/512

Epoch 00124: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.0794e-10 - val_loss: 4.0091e-10
Epoch 125/512

Epoch 00125: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.0809e-10 - val_loss: 4.0428e-10
Epoch 126/512

Epoch 00126: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.1034e-10 - val_loss: 4.0369e-10
Epoch 127/512

Epoch 00127: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.1107e-10 - val_loss: 3.9868e-10
Epoch 128/512

Epoch 00128: val_loss did not improve from 0.00000
448/448 - 0s - loss: 4.0041e-10 - val_loss: 3.9374e-10
Epoch 129/512

Epoch 00129: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.9795e-10 - val_loss: 3.8179e-10
Epoch 130/512

Epoch 00130: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.8410e-10 - val_loss: 3.7504e-10
Epoch 131/512

Epoch 00131: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.7930e-10 - val_loss: 3.7476e-10
Epoch 132/512

Epoch 00132: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.8332e-10 - val_loss: 3.7954e-10
Epoch 133/512

Epoch 00133: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.8234e-10 - val_loss: 3.7209e-10
Epoch 134/512

Epoch 00134: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.7629e-10 - val_loss: 3.6625e-10
Epoch 135/512

Epoch 00135: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.7243e-10 - val_loss: 3.6717e-10
Epoch 136/512

Epoch 00136: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.7177e-10 - val_loss: 3.6246e-10
Epoch 137/512

Epoch 00137: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.6831e-10 - val_loss: 3.6383e-10
Epoch 138/512

Epoch 00138: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.6809e-10 - val_loss: 3.6517e-10
Epoch 139/512

Epoch 00139: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.6746e-10 - val_loss: 3.5412e-10
Epoch 140/512

Epoch 00140: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.5748e-10 - val_loss: 3.4997e-10
Epoch 141/512

Epoch 00141: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 3.5238e-10 - val_loss: 3.4257e-10
Epoch 142/512

Epoch 00142: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 3.4371e-10 - val_loss: 3.3680e-10
Epoch 143/512

Epoch 00143: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 3.3884e-10 - val_loss: 3.2729e-10
Epoch 144/512

Epoch 00144: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.3209e-10 - val_loss: 3.3214e-10
Epoch 145/512

Epoch 00145: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.3750e-10 - val_loss: 3.3594e-10
Epoch 146/512

Epoch 00146: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.3818e-10 - val_loss: 3.2821e-10
Epoch 147/512

Epoch 00147: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.3129e-10 - val_loss: 3.2923e-10
Epoch 148/512

Epoch 00148: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 3.3201e-10 - val_loss: 3.2600e-10
Epoch 149/512

Epoch 00149: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 3.2978e-10 - val_loss: 3.2233e-10
Epoch 150/512

Epoch 00150: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 3.2705e-10 - val_loss: 3.1763e-10
Epoch 151/512

Epoch 00151: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 3.2318e-10 - val_loss: 3.1416e-10
Epoch 152/512

Epoch 00152: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.1660e-10 - val_loss: 3.1535e-10
Epoch 153/512

Epoch 00153: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 3.1825e-10 - val_loss: 3.1349e-10
Epoch 154/512

Epoch 00154: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 3.1681e-10 - val_loss: 3.0779e-10
Epoch 155/512

Epoch 00155: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 3.1045e-10 - val_loss: 3.0225e-10
Epoch 156/512

Epoch 00156: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.0491e-10 - val_loss: 3.0299e-10
Epoch 157/512

Epoch 00157: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 3.0665e-10 - val_loss: 3.0198e-10
Epoch 158/512

Epoch 00158: val_loss did not improve from 0.00000
448/448 - 0s - loss: 3.0591e-10 - val_loss: 3.0228e-10
Epoch 159/512

Epoch 00159: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 3.0214e-10 - val_loss: 2.9330e-10
Epoch 160/512

Epoch 00160: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.9516e-10 - val_loss: 2.9239e-10
Epoch 161/512

Epoch 00161: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.9498e-10 - val_loss: 2.9109e-10
Epoch 162/512

Epoch 00162: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.9460e-10 - val_loss: 2.9362e-10
Epoch 163/512

Epoch 00163: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.9409e-10 - val_loss: 2.8424e-10
Epoch 164/512

Epoch 00164: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.8587e-10 - val_loss: 2.7873e-10
Epoch 165/512

Epoch 00165: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.8054e-10 - val_loss: 2.7629e-10
Epoch 166/512

Epoch 00166: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.7765e-10 - val_loss: 2.7328e-10
Epoch 167/512

Epoch 00167: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.7932e-10 - val_loss: 2.7542e-10
Epoch 168/512

Epoch 00168: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.7967e-10 - val_loss: 2.7731e-10
Epoch 169/512

Epoch 00169: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.8082e-10 - val_loss: 2.7467e-10
Epoch 170/512

Epoch 00170: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.7702e-10 - val_loss: 2.7061e-10
Epoch 171/512

Epoch 00171: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.7338e-10 - val_loss: 2.7231e-10
Epoch 172/512

Epoch 00172: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.7551e-10 - val_loss: 2.6818e-10
Epoch 173/512

Epoch 00173: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.7076e-10 - val_loss: 2.6571e-10
Epoch 174/512

Epoch 00174: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.6919e-10 - val_loss: 2.6597e-10
Epoch 175/512

Epoch 00175: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.6500e-10 - val_loss: 2.5947e-10
Epoch 176/512

Epoch 00176: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.6259e-10 - val_loss: 2.5952e-10
Epoch 177/512

Epoch 00177: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.6255e-10 - val_loss: 2.5661e-10
Epoch 178/512

Epoch 00178: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.5930e-10 - val_loss: 2.5316e-10
Epoch 179/512

Epoch 00179: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.5397e-10 - val_loss: 2.4913e-10
Epoch 180/512

Epoch 00180: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.5173e-10 - val_loss: 2.4885e-10
Epoch 181/512

Epoch 00181: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.5431e-10 - val_loss: 2.4659e-10
Epoch 182/512

Epoch 00182: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.5075e-10 - val_loss: 2.5037e-10
Epoch 183/512

Epoch 00183: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.5363e-10 - val_loss: 2.4677e-10
Epoch 184/512

Epoch 00184: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.5035e-10 - val_loss: 2.4924e-10
Epoch 185/512

Epoch 00185: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.5212e-10 - val_loss: 2.4500e-10
Epoch 186/512

Epoch 00186: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.4727e-10 - val_loss: 2.4605e-10
Epoch 187/512

Epoch 00187: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.4828e-10 - val_loss: 2.4177e-10
Epoch 188/512

Epoch 00188: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.4222e-10 - val_loss: 2.3604e-10
Epoch 189/512

Epoch 00189: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.3667e-10 - val_loss: 2.2916e-10
Epoch 190/512

Epoch 00190: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.3174e-10 - val_loss: 2.2717e-10
Epoch 191/512

Epoch 00191: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.3032e-10 - val_loss: 2.3201e-10
Epoch 192/512

Epoch 00192: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.3527e-10 - val_loss: 2.3613e-10
Epoch 193/512

Epoch 00193: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.4023e-10 - val_loss: 2.3721e-10
Epoch 194/512

Epoch 00194: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.3911e-10 - val_loss: 2.3764e-10
Epoch 195/512

Epoch 00195: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.3885e-10 - val_loss: 2.3001e-10
Epoch 196/512

Epoch 00196: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.3337e-10 - val_loss: 2.3280e-10
Epoch 197/512

Epoch 00197: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.3459e-10 - val_loss: 2.2903e-10
Epoch 198/512

Epoch 00198: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.3095e-10 - val_loss: 2.2372e-10
Epoch 199/512

Epoch 00199: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.2433e-10 - val_loss: 2.2238e-10
Epoch 200/512

Epoch 00200: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.2349e-10 - val_loss: 2.2071e-10
Epoch 201/512

Epoch 00201: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.2270e-10 - val_loss: 2.1757e-10
Epoch 202/512

Epoch 00202: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.1881e-10 - val_loss: 2.1541e-10
Epoch 203/512

Epoch 00203: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.1774e-10 - val_loss: 2.1478e-10
Epoch 204/512

Epoch 00204: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.1564e-10 - val_loss: 2.1811e-10
Epoch 205/512

Epoch 00205: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2235e-10 - val_loss: 2.2076e-10
Epoch 206/512

Epoch 00206: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2473e-10 - val_loss: 2.2462e-10
Epoch 207/512

Epoch 00207: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2571e-10 - val_loss: 2.2298e-10
Epoch 208/512

Epoch 00208: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.2282e-10 - val_loss: 2.1701e-10
Epoch 209/512

Epoch 00209: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.1692e-10 - val_loss: 2.1002e-10
Epoch 210/512

Epoch 00210: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.0796e-10 - val_loss: 1.9980e-10
Epoch 211/512

Epoch 00211: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 2.0057e-10 - val_loss: 1.9384e-10
Epoch 212/512

Epoch 00212: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9649e-10 - val_loss: 1.9742e-10
Epoch 213/512

Epoch 00213: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0149e-10 - val_loss: 2.0302e-10
Epoch 214/512

Epoch 00214: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0663e-10 - val_loss: 2.0518e-10
Epoch 215/512

Epoch 00215: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0807e-10 - val_loss: 2.0452e-10
Epoch 216/512

Epoch 00216: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0736e-10 - val_loss: 2.0216e-10
Epoch 217/512

Epoch 00217: val_loss did not improve from 0.00000
448/448 - 0s - loss: 2.0173e-10 - val_loss: 1.9880e-10
Epoch 218/512

Epoch 00218: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.9765e-10 - val_loss: 1.8890e-10
Epoch 219/512

Epoch 00219: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.8966e-10 - val_loss: 1.8886e-10
Epoch 220/512

Epoch 00220: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.9065e-10 - val_loss: 1.8757e-10
Epoch 221/512

Epoch 00221: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9133e-10 - val_loss: 1.9653e-10
Epoch 222/512

Epoch 00222: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9920e-10 - val_loss: 1.9711e-10
Epoch 223/512

Epoch 00223: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9901e-10 - val_loss: 1.9606e-10
Epoch 224/512

Epoch 00224: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9741e-10 - val_loss: 1.9485e-10
Epoch 225/512

Epoch 00225: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.9455e-10 - val_loss: 1.8931e-10
Epoch 226/512

Epoch 00226: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.9058e-10 - val_loss: 1.8737e-10
Epoch 227/512

Epoch 00227: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.8678e-10 - val_loss: 1.8456e-10
Epoch 228/512

Epoch 00228: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.8598e-10 - val_loss: 1.8420e-10
Epoch 229/512

Epoch 00229: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.8535e-10 - val_loss: 1.8199e-10
Epoch 230/512

Epoch 00230: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.8351e-10 - val_loss: 1.8253e-10
Epoch 231/512

Epoch 00231: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.8531e-10 - val_loss: 1.8487e-10
Epoch 232/512

Epoch 00232: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.8663e-10 - val_loss: 1.8500e-10
Epoch 233/512

Epoch 00233: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.8573e-10 - val_loss: 1.8390e-10
Epoch 234/512

Epoch 00234: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.8408e-10 - val_loss: 1.8179e-10
Epoch 235/512

Epoch 00235: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.8419e-10 - val_loss: 1.8214e-10
Epoch 236/512

Epoch 00236: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.8230e-10 - val_loss: 1.7872e-10
Epoch 237/512

Epoch 00237: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.8014e-10 - val_loss: 1.7729e-10
Epoch 238/512

Epoch 00238: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.7698e-10 - val_loss: 1.6970e-10
Epoch 239/512

Epoch 00239: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7076e-10 - val_loss: 1.7242e-10
Epoch 240/512

Epoch 00240: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7380e-10 - val_loss: 1.7172e-10
Epoch 241/512

Epoch 00241: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7316e-10 - val_loss: 1.6993e-10
Epoch 242/512

Epoch 00242: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7272e-10 - val_loss: 1.7435e-10
Epoch 243/512

Epoch 00243: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7588e-10 - val_loss: 1.7440e-10
Epoch 244/512

Epoch 00244: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7566e-10 - val_loss: 1.7432e-10
Epoch 245/512

Epoch 00245: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7536e-10 - val_loss: 1.7242e-10
Epoch 246/512

Epoch 00246: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7472e-10 - val_loss: 1.7343e-10
Epoch 247/512

Epoch 00247: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7533e-10 - val_loss: 1.7011e-10
Epoch 248/512

Epoch 00248: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.6992e-10 - val_loss: 1.6641e-10
Epoch 249/512

Epoch 00249: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6835e-10 - val_loss: 1.6825e-10
Epoch 250/512

Epoch 00250: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7070e-10 - val_loss: 1.7084e-10
Epoch 251/512

Epoch 00251: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.7199e-10 - val_loss: 1.6694e-10
Epoch 252/512

Epoch 00252: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.6678e-10 - val_loss: 1.6263e-10
Epoch 253/512

Epoch 00253: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6345e-10 - val_loss: 1.6412e-10
Epoch 254/512

Epoch 00254: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6463e-10 - val_loss: 1.6532e-10
Epoch 255/512

Epoch 00255: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6730e-10 - val_loss: 1.6693e-10
Epoch 256/512

Epoch 00256: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6859e-10 - val_loss: 1.6658e-10
Epoch 257/512

Epoch 00257: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6753e-10 - val_loss: 1.6608e-10
Epoch 258/512

Epoch 00258: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.6646e-10 - val_loss: 1.6037e-10
Epoch 259/512

Epoch 00259: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.6080e-10 - val_loss: 1.5925e-10
Epoch 260/512

Epoch 00260: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.6059e-10 - val_loss: 1.5720e-10
Epoch 261/512

Epoch 00261: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5898e-10 - val_loss: 1.5848e-10
Epoch 262/512

Epoch 00262: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5981e-10 - val_loss: 1.5916e-10
Epoch 263/512

Epoch 00263: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6094e-10 - val_loss: 1.6130e-10
Epoch 264/512

Epoch 00264: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6332e-10 - val_loss: 1.6028e-10
Epoch 265/512

Epoch 00265: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5993e-10 - val_loss: 1.6038e-10
Epoch 266/512

Epoch 00266: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.6051e-10 - val_loss: 1.5805e-10
Epoch 267/512

Epoch 00267: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.5748e-10 - val_loss: 1.5312e-10
Epoch 268/512

Epoch 00268: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.5181e-10 - val_loss: 1.4698e-10
Epoch 269/512

Epoch 00269: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.4720e-10 - val_loss: 1.4662e-10
Epoch 270/512

Epoch 00270: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.4684e-10 - val_loss: 1.4537e-10
Epoch 271/512

Epoch 00271: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4763e-10 - val_loss: 1.4863e-10
Epoch 272/512

Epoch 00272: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5012e-10 - val_loss: 1.5044e-10
Epoch 273/512

Epoch 00273: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5017e-10 - val_loss: 1.4644e-10
Epoch 274/512

Epoch 00274: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4892e-10 - val_loss: 1.4964e-10
Epoch 275/512

Epoch 00275: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5063e-10 - val_loss: 1.4980e-10
Epoch 276/512

Epoch 00276: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5117e-10 - val_loss: 1.5091e-10
Epoch 277/512

Epoch 00277: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.5198e-10 - val_loss: 1.4875e-10
Epoch 278/512

Epoch 00278: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4925e-10 - val_loss: 1.4655e-10
Epoch 279/512

Epoch 00279: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4779e-10 - val_loss: 1.4640e-10
Epoch 280/512

Epoch 00280: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.4602e-10 - val_loss: 1.4506e-10
Epoch 281/512

Epoch 00281: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4701e-10 - val_loss: 1.4612e-10
Epoch 282/512

Epoch 00282: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.4626e-10 - val_loss: 1.4450e-10
Epoch 283/512

Epoch 00283: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4597e-10 - val_loss: 1.4696e-10
Epoch 284/512

Epoch 00284: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4824e-10 - val_loss: 1.4659e-10
Epoch 285/512

Epoch 00285: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4672e-10 - val_loss: 1.4524e-10
Epoch 286/512

Epoch 00286: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4616e-10 - val_loss: 1.4553e-10
Epoch 287/512

Epoch 00287: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.4573e-10 - val_loss: 1.4307e-10
Epoch 288/512

Epoch 00288: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4323e-10 - val_loss: 1.4496e-10
Epoch 289/512

Epoch 00289: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4620e-10 - val_loss: 1.4373e-10
Epoch 290/512

Epoch 00290: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4594e-10 - val_loss: 1.4422e-10
Epoch 291/512

Epoch 00291: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.4492e-10 - val_loss: 1.4355e-10
Epoch 292/512

Epoch 00292: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.4249e-10 - val_loss: 1.3886e-10
Epoch 293/512

Epoch 00293: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.3960e-10 - val_loss: 1.3675e-10
Epoch 294/512

Epoch 00294: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.3637e-10 - val_loss: 1.3565e-10
Epoch 295/512

Epoch 00295: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.3614e-10 - val_loss: 1.3302e-10
Epoch 296/512

Epoch 00296: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.3339e-10 - val_loss: 1.3183e-10
Epoch 297/512

Epoch 00297: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3370e-10 - val_loss: 1.3552e-10
Epoch 298/512

Epoch 00298: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3677e-10 - val_loss: 1.3689e-10
Epoch 299/512

Epoch 00299: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3684e-10 - val_loss: 1.3315e-10
Epoch 300/512

Epoch 00300: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3476e-10 - val_loss: 1.3560e-10
Epoch 301/512

Epoch 00301: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3707e-10 - val_loss: 1.3750e-10
Epoch 302/512

Epoch 00302: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3896e-10 - val_loss: 1.3592e-10
Epoch 303/512

Epoch 00303: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3687e-10 - val_loss: 1.3623e-10
Epoch 304/512

Epoch 00304: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3662e-10 - val_loss: 1.3482e-10
Epoch 305/512

Epoch 00305: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.3538e-10 - val_loss: 1.3054e-10
Epoch 306/512

Epoch 00306: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.2958e-10 - val_loss: 1.2642e-10
Epoch 307/512

Epoch 00307: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.2668e-10 - val_loss: 1.2423e-10
Epoch 308/512

Epoch 00308: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2534e-10 - val_loss: 1.2480e-10
Epoch 309/512

Epoch 00309: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2581e-10 - val_loss: 1.2731e-10
Epoch 310/512

Epoch 00310: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2899e-10 - val_loss: 1.2965e-10
Epoch 311/512

Epoch 00311: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3064e-10 - val_loss: 1.2859e-10
Epoch 312/512

Epoch 00312: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2953e-10 - val_loss: 1.2880e-10
Epoch 313/512

Epoch 00313: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2948e-10 - val_loss: 1.2933e-10
Epoch 314/512

Epoch 00314: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2963e-10 - val_loss: 1.2660e-10
Epoch 315/512

Epoch 00315: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2752e-10 - val_loss: 1.2709e-10
Epoch 316/512

Epoch 00316: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2754e-10 - val_loss: 1.2616e-10
Epoch 317/512

Epoch 00317: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2744e-10 - val_loss: 1.2853e-10
Epoch 318/512

Epoch 00318: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3041e-10 - val_loss: 1.3121e-10
Epoch 319/512

Epoch 00319: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.3192e-10 - val_loss: 1.2991e-10
Epoch 320/512

Epoch 00320: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2951e-10 - val_loss: 1.2607e-10
Epoch 321/512

Epoch 00321: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2743e-10 - val_loss: 1.2531e-10
Epoch 322/512

Epoch 00322: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.2507e-10 - val_loss: 1.2377e-10
Epoch 323/512

Epoch 00323: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.2384e-10 - val_loss: 1.2172e-10
Epoch 324/512

Epoch 00324: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.2193e-10 - val_loss: 1.2069e-10
Epoch 325/512

Epoch 00325: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.2113e-10 - val_loss: 1.2025e-10
Epoch 326/512

Epoch 00326: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2172e-10 - val_loss: 1.2422e-10
Epoch 327/512

Epoch 00327: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2612e-10 - val_loss: 1.2595e-10
Epoch 328/512

Epoch 00328: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2657e-10 - val_loss: 1.2706e-10
Epoch 329/512

Epoch 00329: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2764e-10 - val_loss: 1.2460e-10
Epoch 330/512

Epoch 00330: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2515e-10 - val_loss: 1.2295e-10
Epoch 331/512

Epoch 00331: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2246e-10 - val_loss: 1.2151e-10
Epoch 332/512

Epoch 00332: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2227e-10 - val_loss: 1.2178e-10
Epoch 333/512

Epoch 00333: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.2215e-10 - val_loss: 1.1988e-10
Epoch 334/512

Epoch 00334: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.1931e-10 - val_loss: 1.1671e-10
Epoch 335/512

Epoch 00335: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1711e-10 - val_loss: 1.1915e-10
Epoch 336/512

Epoch 00336: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2005e-10 - val_loss: 1.1987e-10
Epoch 337/512

Epoch 00337: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2086e-10 - val_loss: 1.2009e-10
Epoch 338/512

Epoch 00338: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2118e-10 - val_loss: 1.2167e-10
Epoch 339/512

Epoch 00339: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2294e-10 - val_loss: 1.2115e-10
Epoch 340/512

Epoch 00340: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.2183e-10 - val_loss: 1.1986e-10
Epoch 341/512

Epoch 00341: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1874e-10 - val_loss: 1.1735e-10
Epoch 342/512

Epoch 00342: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1897e-10 - val_loss: 1.1955e-10
Epoch 343/512

Epoch 00343: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.1971e-10 - val_loss: 1.1514e-10
Epoch 344/512

Epoch 00344: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.1584e-10 - val_loss: 1.1494e-10
Epoch 345/512

Epoch 00345: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.1495e-10 - val_loss: 1.1316e-10
Epoch 346/512

Epoch 00346: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1415e-10 - val_loss: 1.1547e-10
Epoch 347/512

Epoch 00347: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1569e-10 - val_loss: 1.1542e-10
Epoch 348/512

Epoch 00348: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1568e-10 - val_loss: 1.1445e-10
Epoch 349/512

Epoch 00349: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1530e-10 - val_loss: 1.1527e-10
Epoch 350/512

Epoch 00350: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1617e-10 - val_loss: 1.1590e-10
Epoch 351/512

Epoch 00351: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1653e-10 - val_loss: 1.1513e-10
Epoch 352/512

Epoch 00352: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1614e-10 - val_loss: 1.1402e-10
Epoch 353/512

Epoch 00353: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.1483e-10 - val_loss: 1.1284e-10
Epoch 354/512

Epoch 00354: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1363e-10 - val_loss: 1.1303e-10
Epoch 355/512

Epoch 00355: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1425e-10 - val_loss: 1.1518e-10
Epoch 356/512

Epoch 00356: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1473e-10 - val_loss: 1.1346e-10
Epoch 357/512

Epoch 00357: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.1297e-10 - val_loss: 1.1211e-10
Epoch 358/512

Epoch 00358: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1290e-10 - val_loss: 1.1313e-10
Epoch 359/512

Epoch 00359: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1409e-10 - val_loss: 1.1241e-10
Epoch 360/512

Epoch 00360: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.1199e-10 - val_loss: 1.0930e-10
Epoch 361/512

Epoch 00361: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.0998e-10 - val_loss: 1.0769e-10
Epoch 362/512

Epoch 00362: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0803e-10 - val_loss: 1.0907e-10
Epoch 363/512

Epoch 00363: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1007e-10 - val_loss: 1.1178e-10
Epoch 364/512

Epoch 00364: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1274e-10 - val_loss: 1.1030e-10
Epoch 365/512

Epoch 00365: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1190e-10 - val_loss: 1.1076e-10
Epoch 366/512

Epoch 00366: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1110e-10 - val_loss: 1.0945e-10
Epoch 367/512

Epoch 00367: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0930e-10 - val_loss: 1.0908e-10
Epoch 368/512

Epoch 00368: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0925e-10 - val_loss: 1.0944e-10
Epoch 369/512

Epoch 00369: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.0901e-10 - val_loss: 1.0473e-10
Epoch 370/512

Epoch 00370: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.0419e-10 - val_loss: 1.0289e-10
Epoch 371/512

Epoch 00371: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0419e-10 - val_loss: 1.0323e-10
Epoch 372/512

Epoch 00372: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0454e-10 - val_loss: 1.0565e-10
Epoch 373/512

Epoch 00373: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0690e-10 - val_loss: 1.0732e-10
Epoch 374/512

Epoch 00374: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0890e-10 - val_loss: 1.0850e-10
Epoch 375/512

Epoch 00375: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1041e-10 - val_loss: 1.1111e-10
Epoch 376/512

Epoch 00376: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1185e-10 - val_loss: 1.1134e-10
Epoch 377/512

Epoch 00377: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.1180e-10 - val_loss: 1.0968e-10
Epoch 378/512

Epoch 00378: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0997e-10 - val_loss: 1.0775e-10
Epoch 379/512

Epoch 00379: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0822e-10 - val_loss: 1.0870e-10
Epoch 380/512

Epoch 00380: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0967e-10 - val_loss: 1.0827e-10
Epoch 381/512

Epoch 00381: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0745e-10 - val_loss: 1.0520e-10
Epoch 382/512

Epoch 00382: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0517e-10 - val_loss: 1.0463e-10
Epoch 383/512

Epoch 00383: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0502e-10 - val_loss: 1.0459e-10
Epoch 384/512

Epoch 00384: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.0439e-10 - val_loss: 1.0182e-10
Epoch 385/512

Epoch 00385: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.0209e-10 - val_loss: 1.0017e-10
Epoch 386/512

Epoch 00386: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0163e-10 - val_loss: 1.0126e-10
Epoch 387/512

Epoch 00387: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0209e-10 - val_loss: 1.0200e-10
Epoch 388/512

Epoch 00388: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0327e-10 - val_loss: 1.0210e-10
Epoch 389/512

Epoch 00389: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.0162e-10 - val_loss: 9.9854e-11
Epoch 390/512

Epoch 00390: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0108e-10 - val_loss: 1.0096e-10
Epoch 391/512

Epoch 00391: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0227e-10 - val_loss: 1.0121e-10
Epoch 392/512

Epoch 00392: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.0136e-10 - val_loss: 9.9391e-11
Epoch 393/512

Epoch 00393: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0005e-10 - val_loss: 9.9954e-11
Epoch 394/512

Epoch 00394: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.0086e-10 - val_loss: 9.9193e-11
Epoch 395/512

Epoch 00395: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0004e-10 - val_loss: 1.0032e-10
Epoch 396/512

Epoch 00396: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 1.0053e-10 - val_loss: 9.8080e-11
Epoch 397/512

Epoch 00397: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 9.7368e-11 - val_loss: 9.7062e-11
Epoch 398/512

Epoch 00398: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.7854e-11 - val_loss: 9.7680e-11
Epoch 399/512

Epoch 00399: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.8936e-11 - val_loss: 1.0024e-10
Epoch 400/512

Epoch 00400: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0092e-10 - val_loss: 1.0073e-10
Epoch 401/512

Epoch 00401: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0054e-10 - val_loss: 9.9999e-11
Epoch 402/512

Epoch 00402: val_loss did not improve from 0.00000
448/448 - 0s - loss: 1.0005e-10 - val_loss: 9.8576e-11
Epoch 403/512

Epoch 00403: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.8472e-11 - val_loss: 9.8185e-11
Epoch 404/512

Epoch 00404: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.9057e-11 - val_loss: 9.7545e-11
Epoch 405/512

Epoch 00405: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 9.8183e-11 - val_loss: 9.5944e-11
Epoch 406/512

Epoch 00406: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 9.6475e-11 - val_loss: 9.4707e-11
Epoch 407/512

Epoch 00407: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.5386e-11 - val_loss: 9.5205e-11
Epoch 408/512

Epoch 00408: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.6469e-11 - val_loss: 9.6347e-11
Epoch 409/512

Epoch 00409: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.6903e-11 - val_loss: 9.6825e-11
Epoch 410/512

Epoch 00410: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.7290e-11 - val_loss: 9.5511e-11
Epoch 411/512

Epoch 00411: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 9.6104e-11 - val_loss: 9.4327e-11
Epoch 412/512

Epoch 00412: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 9.4482e-11 - val_loss: 9.4156e-11
Epoch 413/512

Epoch 00413: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 9.4305e-11 - val_loss: 9.3572e-11
Epoch 414/512

Epoch 00414: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.4909e-11 - val_loss: 9.4662e-11
Epoch 415/512

Epoch 00415: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 9.4818e-11 - val_loss: 9.2303e-11
Epoch 416/512

Epoch 00416: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 9.2154e-11 - val_loss: 9.1568e-11
Epoch 417/512

Epoch 00417: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 9.2289e-11 - val_loss: 9.1210e-11
Epoch 418/512

Epoch 00418: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.2529e-11 - val_loss: 9.2940e-11
Epoch 419/512

Epoch 00419: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.3785e-11 - val_loss: 9.4741e-11
Epoch 420/512

Epoch 00420: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.5499e-11 - val_loss: 9.5406e-11
Epoch 421/512

Epoch 00421: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.5492e-11 - val_loss: 9.5279e-11
Epoch 422/512

Epoch 00422: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.5278e-11 - val_loss: 9.3982e-11
Epoch 423/512

Epoch 00423: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.4190e-11 - val_loss: 9.2910e-11
Epoch 424/512

Epoch 00424: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.3879e-11 - val_loss: 9.3920e-11
Epoch 425/512

Epoch 00425: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.3534e-11 - val_loss: 9.2843e-11
Epoch 426/512

Epoch 00426: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 9.2225e-11 - val_loss: 9.0528e-11
Epoch 427/512

Epoch 00427: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 9.0692e-11 - val_loss: 8.9737e-11
Epoch 428/512

Epoch 00428: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.0330e-11 - val_loss: 9.1292e-11
Epoch 429/512

Epoch 00429: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.1035e-11 - val_loss: 9.0807e-11
Epoch 430/512

Epoch 00430: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.1323e-11 - val_loss: 9.1283e-11
Epoch 431/512

Epoch 00431: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.1242e-11 - val_loss: 9.0372e-11
Epoch 432/512

Epoch 00432: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.0538e-11 - val_loss: 9.0532e-11
Epoch 433/512

Epoch 00433: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 9.1035e-11 - val_loss: 8.9692e-11
Epoch 434/512

Epoch 00434: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.0192e-11 - val_loss: 8.9971e-11
Epoch 435/512

Epoch 00435: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.0403e-11 - val_loss: 8.9914e-11
Epoch 436/512

Epoch 00436: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.0727e-11 - val_loss: 8.9843e-11
Epoch 437/512

Epoch 00437: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 9.0410e-11 - val_loss: 8.9660e-11
Epoch 438/512

Epoch 00438: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 8.9404e-11 - val_loss: 8.8181e-11
Epoch 439/512

Epoch 00439: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.8619e-11 - val_loss: 8.8499e-11
Epoch 440/512

Epoch 00440: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.9315e-11 - val_loss: 8.9866e-11
Epoch 441/512

Epoch 00441: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.0759e-11 - val_loss: 9.0494e-11
Epoch 442/512

Epoch 00442: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.0820e-11 - val_loss: 9.1234e-11
Epoch 443/512

Epoch 00443: val_loss did not improve from 0.00000
448/448 - 0s - loss: 9.1295e-11 - val_loss: 8.9409e-11
Epoch 444/512

Epoch 00444: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.9793e-11 - val_loss: 8.8641e-11
Epoch 445/512

Epoch 00445: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.8478e-11 - val_loss: 8.8559e-11
Epoch 446/512

Epoch 00446: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.9391e-11 - val_loss: 8.8526e-11
Epoch 447/512

Epoch 00447: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 8.8336e-11 - val_loss: 8.7815e-11
Epoch 448/512

Epoch 00448: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 8.7292e-11 - val_loss: 8.6402e-11
Epoch 449/512

Epoch 00449: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.7277e-11 - val_loss: 8.6625e-11
Epoch 450/512

Epoch 00450: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.7222e-11 - val_loss: 8.6758e-11
Epoch 451/512

Epoch 00451: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.7237e-11 - val_loss: 8.6941e-11
Epoch 452/512

Epoch 00452: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 8.6797e-11 - val_loss: 8.5933e-11
Epoch 453/512

Epoch 00453: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 8.6611e-11 - val_loss: 8.5677e-11
Epoch 454/512

Epoch 00454: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 8.5426e-11 - val_loss: 8.3550e-11
Epoch 455/512

Epoch 00455: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 8.3775e-11 - val_loss: 8.2123e-11
Epoch 456/512

Epoch 00456: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.2970e-11 - val_loss: 8.3233e-11
Epoch 457/512

Epoch 00457: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.4092e-11 - val_loss: 8.2821e-11
Epoch 458/512

Epoch 00458: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.3011e-11 - val_loss: 8.2717e-11
Epoch 459/512

Epoch 00459: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.3122e-11 - val_loss: 8.3883e-11
Epoch 460/512

Epoch 00460: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.3874e-11 - val_loss: 8.2422e-11
Epoch 461/512

Epoch 00461: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 8.2553e-11 - val_loss: 8.1705e-11
Epoch 462/512

Epoch 00462: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.1692e-11 - val_loss: 8.2656e-11
Epoch 463/512

Epoch 00463: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.3346e-11 - val_loss: 8.3998e-11
Epoch 464/512

Epoch 00464: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.4377e-11 - val_loss: 8.3936e-11
Epoch 465/512

Epoch 00465: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.4330e-11 - val_loss: 8.2917e-11
Epoch 466/512

Epoch 00466: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.3096e-11 - val_loss: 8.2940e-11
Epoch 467/512

Epoch 00467: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.3644e-11 - val_loss: 8.3572e-11
Epoch 468/512

Epoch 00468: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.3767e-11 - val_loss: 8.3178e-11
Epoch 469/512

Epoch 00469: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.3753e-11 - val_loss: 8.3936e-11
Epoch 470/512

Epoch 00470: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.4778e-11 - val_loss: 8.6096e-11
Epoch 471/512

Epoch 00471: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.6604e-11 - val_loss: 8.5666e-11
Epoch 472/512

Epoch 00472: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.4702e-11 - val_loss: 8.2469e-11
Epoch 473/512

Epoch 00473: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 8.2485e-11 - val_loss: 8.0246e-11
Epoch 474/512

Epoch 00474: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 8.0530e-11 - val_loss: 7.8643e-11
Epoch 475/512

Epoch 00475: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 7.8688e-11 - val_loss: 7.7765e-11
Epoch 476/512

Epoch 00476: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 7.7827e-11 - val_loss: 7.6124e-11
Epoch 477/512

Epoch 00477: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.6177e-11 - val_loss: 7.6335e-11
Epoch 478/512

Epoch 00478: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.6708e-11 - val_loss: 7.7289e-11
Epoch 479/512

Epoch 00479: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.8668e-11 - val_loss: 7.8926e-11
Epoch 480/512

Epoch 00480: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.9874e-11 - val_loss: 7.9064e-11
Epoch 481/512

Epoch 00481: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.9564e-11 - val_loss: 8.0104e-11
Epoch 482/512

Epoch 00482: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.0619e-11 - val_loss: 8.0969e-11
Epoch 483/512

Epoch 00483: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.1527e-11 - val_loss: 8.1962e-11
Epoch 484/512

Epoch 00484: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.3029e-11 - val_loss: 8.2842e-11
Epoch 485/512

Epoch 00485: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.4318e-11 - val_loss: 8.4664e-11
Epoch 486/512

Epoch 00486: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.5308e-11 - val_loss: 8.4027e-11
Epoch 487/512

Epoch 00487: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.3102e-11 - val_loss: 8.0581e-11
Epoch 488/512

Epoch 00488: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.9432e-11 - val_loss: 7.7630e-11
Epoch 489/512

Epoch 00489: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.8278e-11 - val_loss: 7.7487e-11
Epoch 490/512

Epoch 00490: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.7905e-11 - val_loss: 7.7826e-11
Epoch 491/512

Epoch 00491: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.8653e-11 - val_loss: 7.7074e-11
Epoch 492/512

Epoch 00492: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.7047e-11 - val_loss: 7.6269e-11
Epoch 493/512

Epoch 00493: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.6835e-11 - val_loss: 7.6598e-11
Epoch 494/512

Epoch 00494: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.7242e-11 - val_loss: 7.7898e-11
Epoch 495/512

Epoch 00495: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.9123e-11 - val_loss: 7.9329e-11
Epoch 496/512

Epoch 00496: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.9723e-11 - val_loss: 7.8565e-11
Epoch 497/512

Epoch 00497: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.8740e-11 - val_loss: 7.9227e-11
Epoch 498/512

Epoch 00498: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.0502e-11 - val_loss: 8.1473e-11
Epoch 499/512

Epoch 00499: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.1903e-11 - val_loss: 8.1668e-11
Epoch 500/512

Epoch 00500: val_loss did not improve from 0.00000
448/448 - 0s - loss: 8.1293e-11 - val_loss: 8.0056e-11
Epoch 501/512

Epoch 00501: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.9971e-11 - val_loss: 7.8843e-11
Epoch 502/512

Epoch 00502: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.8916e-11 - val_loss: 7.8773e-11
Epoch 503/512

Epoch 00503: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.8753e-11 - val_loss: 7.7230e-11
Epoch 504/512

Epoch 00504: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.7314e-11 - val_loss: 7.6338e-11
Epoch 505/512

Epoch 00505: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 7.5859e-11 - val_loss: 7.4541e-11
Epoch 506/512

Epoch 00506: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.5226e-11 - val_loss: 7.5258e-11
Epoch 507/512

Epoch 00507: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.5-cuvre-secp224r1-batch-448-0.00005-rrandom-0-65/multiplication_weights.h5
448/448 - 0s - loss: 7.4988e-11 - val_loss: 7.3894e-11
Epoch 508/512

Epoch 00508: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.3898e-11 - val_loss: 7.4479e-11
Epoch 509/512

Epoch 00509: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.5271e-11 - val_loss: 7.6481e-11
Epoch 510/512

Epoch 00510: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.7333e-11 - val_loss: 7.8195e-11
Epoch 511/512

Epoch 00511: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.8420e-11 - val_loss: 7.8519e-11
Epoch 512/512

Epoch 00512: val_loss did not improve from 0.00000
448/448 - 0s - loss: 7.8499e-11 - val_loss: 7.7517e-11
WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?
WARNING:tensorflow:From /home/stud/minawoi/miniconda3/envs/conda-venv/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?
Epoch   0:   0% | abe: 9.298 | eve: 9.713 | bob: 9.185Epoch   0:   0% | abe: 9.274 | eve: 9.725 | bob: 9.167Epoch   0:   1% | abe: 9.272 | eve: 9.728 | bob: 9.172Epoch   0:   2% | abe: 9.235 | eve: 9.723 | bob: 9.139Epoch   0:   2% | abe: 9.234 | eve: 9.717 | bob: 9.143Epoch   0:   3% | abe: 9.232 | eve: 9.717 | bob: 9.144Epoch   0:   4% | abe: 9.227 | eve: 9.714 | bob: 9.143Epoch   0:   4% | abe: 9.222 | eve: 9.719 | bob: 9.140Epoch   0:   5% | abe: 9.209 | eve: 9.727 | bob: 9.129Epoch   0:   6% | abe: 9.189 | eve: 9.727 | bob: 9.111Epoch   0:   6% | abe: 9.179 | eve: 9.726 | bob: 9.102Epoch   0:   7% | abe: 9.173 | eve: 9.730 | bob: 9.099Epoch   0:   8% | abe: 9.169 | eve: 9.731 | bob: 9.096Epoch   0:   8% | abe: 9.162 | eve: 9.734 | bob: 9.090Epoch   0:   9% | abe: 9.158 | eve: 9.739 | bob: 9.088Epoch   0:  10% | abe: 9.149 | eve: 9.737 | bob: 9.080Epoch   0:  10% | abe: 9.146 | eve: 9.737 | bob: 9.078Epoch   0:  11% | abe: 9.141 | eve: 9.738 | bob: 9.074Epoch   0:  12% | abe: 9.134 | eve: 9.739 | bob: 9.067Epoch   0:  13% | abe: 9.130 | eve: 9.743 | bob: 9.064Epoch   0:  13% | abe: 9.129 | eve: 9.745 | bob: 9.063Epoch   0:  14% | abe: 9.126 | eve: 9.750 | bob: 9.061Epoch   0:  15% | abe: 9.122 | eve: 9.750 | bob: 9.057Epoch   0:  15% | abe: 9.118 | eve: 9.756 | bob: 9.054Epoch   0:  16% | abe: 9.115 | eve: 9.757 | bob: 9.051Epoch   0:  17% | abe: 9.110 | eve: 9.757 | bob: 9.046Epoch   0:  17% | abe: 9.109 | eve: 9.758 | bob: 9.044Epoch   0:  18% | abe: 9.109 | eve: 9.756 | bob: 9.044Epoch   0:  19% | abe: 9.109 | eve: 9.756 | bob: 9.044Epoch   0:  19% | abe: 9.109 | eve: 9.757 | bob: 9.045Epoch   0:  20% | abe: 9.106 | eve: 9.759 | bob: 9.041Epoch   0:  21% | abe: 9.104 | eve: 9.760 | bob: 9.040Epoch   0:  21% | abe: 9.104 | eve: 9.762 | bob: 9.039Epoch   0:  22% | abe: 9.101 | eve: 9.767 | bob: 9.036Epoch   0:  23% | abe: 9.099 | eve: 9.769 | bob: 9.034Epoch   0:  23% | abe: 9.098 | eve: 9.771 | bob: 9.033Epoch   0:  24% | abe: 9.097 | eve: 9.771 | bob: 9.031Epoch   0:  25% | abe: 9.096 | eve: 9.774 | bob: 9.030Epoch   0:  26% | abe: 9.093 | eve: 9.777 | bob: 9.028Epoch   0:  26% | abe: 9.095 | eve: 9.777 | bob: 9.029Epoch   0:  27% | abe: 9.094 | eve: 9.776 | bob: 9.027Epoch   0:  28% | abe: 9.093 | eve: 9.779 | bob: 9.026Epoch   0:  28% | abe: 9.091 | eve: 9.781 | bob: 9.025Epoch   0:  29% | abe: 9.091 | eve: 9.780 | bob: 9.024Epoch   0:  30% | abe: 9.089 | eve: 9.783 | bob: 9.022Epoch   0:  30% | abe: 9.087 | eve: 9.783 | bob: 9.020Epoch   0:  31% | abe: 9.087 | eve: 9.785 | bob: 9.020Epoch   0:  32% | abe: 9.088 | eve: 9.786 | bob: 9.020Epoch   0:  32% | abe: 9.085 | eve: 9.787 | bob: 9.017Epoch   0:  33% | abe: 9.084 | eve: 9.789 | bob: 9.016Epoch   0:  34% | abe: 9.082 | eve: 9.790 | bob: 9.014Epoch   0:  34% | abe: 9.082 | eve: 9.791 | bob: 9.014Epoch   0:  35% | abe: 9.080 | eve: 9.792 | bob: 9.012Epoch   0:  36% | abe: 9.079 | eve: 9.793 | bob: 9.011Epoch   0:  36% | abe: 9.078 | eve: 9.793 | bob: 9.009Epoch   0:  37% | abe: 9.077 | eve: 9.795 | bob: 9.008Epoch   0:  38% | abe: 9.076 | eve: 9.794 | bob: 9.007Epoch   0:  39% | abe: 9.076 | eve: 9.794 | bob: 9.007Epoch   0:  39% | abe: 9.075 | eve: 9.795 | bob: 9.006Epoch   0:  40% | abe: 9.075 | eve: 9.797 | bob: 9.005Epoch   0:  41% | abe: 9.075 | eve: 9.797 | bob: 9.005Epoch   0:  41% | abe: 9.074 | eve: 9.797 | bob: 9.004Epoch   0:  42% | abe: 9.073 | eve: 9.797 | bob: 9.002Epoch   0:  43% | abe: 9.072 | eve: 9.798 | bob: 9.002Epoch   0:  43% | abe: 9.072 | eve: 9.800 | bob: 9.002Epoch   0:  44% | abe: 9.071 | eve: 9.800 | bob: 9.001Epoch   0:  45% | abe: 9.070 | eve: 9.801 | bob: 9.000Epoch   0:  45% | abe: 9.069 | eve: 9.801 | bob: 8.998Epoch   0:  46% | abe: 9.068 | eve: 9.802 | bob: 8.997Epoch   0:  47% | abe: 9.067 | eve: 9.803 | bob: 8.996Epoch   0:  47% | abe: 9.066 | eve: 9.803 | bob: 8.995Epoch   0:  48% | abe: 9.065 | eve: 9.805 | bob: 8.994Epoch   0:  49% | abe: 9.064 | eve: 9.806 | bob: 8.993Epoch   0:  50% | abe: 9.064 | eve: 9.806 | bob: 8.992Epoch   0:  50% | abe: 9.063 | eve: 9.808 | bob: 8.991Epoch   0:  51% | abe: 9.063 | eve: 9.807 | bob: 8.991Epoch   0:  52% | abe: 9.062 | eve: 9.807 | bob: 8.990Epoch   0:  52% | abe: 9.061 | eve: 9.808 | bob: 8.989Epoch   0:  53% | abe: 9.061 | eve: 9.808 | bob: 8.989Epoch   0:  54% | abe: 9.060 | eve: 9.808 | bob: 8.987Epoch   0:  54% | abe: 9.060 | eve: 9.809 | bob: 8.988Epoch   0:  55% | abe: 9.059 | eve: 9.810 | bob: 8.986Epoch   0:  56% | abe: 9.060 | eve: 9.810 | bob: 8.987Epoch   0:  56% | abe: 9.060 | eve: 9.811 | bob: 8.986Epoch   0:  57% | abe: 9.059 | eve: 9.811 | bob: 8.985Epoch   0:  58% | abe: 9.059 | eve: 9.811 | bob: 8.985Epoch   0:  58% | abe: 9.059 | eve: 9.811 | bob: 8.986Epoch   0:  59% | abe: 9.058 | eve: 9.812 | bob: 8.984Epoch   0:  60% | abe: 9.058 | eve: 9.812 | bob: 8.984Epoch   0:  60% | abe: 9.058 | eve: 9.811 | bob: 8.984Epoch   0:  61% | abe: 9.056 | eve: 9.812 | bob: 8.982Epoch   0:  62% | abe: 9.056 | eve: 9.812 | bob: 8.981Epoch   0:  63% | abe: 9.055 | eve: 9.812 | bob: 8.981Epoch   0:  63% | abe: 9.055 | eve: 9.812 | bob: 8.980Epoch   0:  64% | abe: 9.053 | eve: 9.813 | bob: 8.979Epoch   0:  65% | abe: 9.053 | eve: 9.814 | bob: 8.978Epoch   0:  65% | abe: 9.053 | eve: 9.814 | bob: 8.978Epoch   0:  66% | abe: 9.052 | eve: 9.813 | bob: 8.977Epoch   0:  67% | abe: 9.052 | eve: 9.815 | bob: 8.977Epoch   0:  67% | abe: 9.052 | eve: 9.814 | bob: 8.977Epoch   0:  68% | abe: 9.052 | eve: 9.814 | bob: 8.976Epoch   0:  69% | abe: 9.051 | eve: 9.814 | bob: 8.975Epoch   0:  69% | abe: 9.050 | eve: 9.814 | bob: 8.974Epoch   0:  70% | abe: 9.049 | eve: 9.815 | bob: 8.973Epoch   0:  71% | abe: 9.049 | eve: 9.816 | bob: 8.973Epoch   0:  71% | abe: 9.048 | eve: 9.815 | bob: 8.972Epoch   0:  72% | abe: 9.048 | eve: 9.815 | bob: 8.972Epoch   0:  73% | abe: 9.047 | eve: 9.816 | bob: 8.971Epoch   0:  73% | abe: 9.046 | eve: 9.817 | bob: 8.970Epoch   0:  74% | abe: 9.046 | eve: 9.817 | bob: 8.970Epoch   0:  75% | abe: 9.046 | eve: 9.816 | bob: 8.970Epoch   0:  76% | abe: 9.046 | eve: 9.816 | bob: 8.969Epoch   0:  76% | abe: 9.046 | eve: 9.816 | bob: 8.969Epoch   0:  77% | abe: 9.045 | eve: 9.816 | bob: 8.968Epoch   0:  78% | abe: 9.044 | eve: 9.817 | bob: 8.967Epoch   0:  78% | abe: 9.044 | eve: 9.817 | bob: 8.967Epoch   0:  79% | abe: 9.043 | eve: 9.818 | bob: 8.966Epoch   0:  80% | abe: 9.043 | eve: 9.818 | bob: 8.966Epoch   0:  80% | abe: 9.043 | eve: 9.818 | bob: 8.965Epoch   0:  81% | abe: 9.043 | eve: 9.818 | bob: 8.965Epoch   0:  82% | abe: 9.042 | eve: 9.819 | bob: 8.964Epoch   0:  82% | abe: 9.042 | eve: 9.819 | bob: 8.964Epoch   0:  83% | abe: 9.040 | eve: 9.818 | bob: 8.963Epoch   0:  84% | abe: 9.040 | eve: 9.819 | bob: 8.962Epoch   0:  84% | abe: 9.040 | eve: 9.819 | bob: 8.962Epoch   0:  85% | abe: 9.040 | eve: 9.820 | bob: 8.962Epoch   0:  86% | abe: 9.039 | eve: 9.819 | bob: 8.961Epoch   0:  86% | abe: 9.039 | eve: 9.820 | bob: 8.961Epoch   0:  87% | abe: 9.040 | eve: 9.820 | bob: 8.961Epoch   0:  88% | abe: 9.039 | eve: 9.820 | bob: 8.961Epoch   0:  89% | abe: 9.039 | eve: 9.820 | bob: 8.961Epoch   0:  89% | abe: 9.038 | eve: 9.820 | bob: 8.960Epoch   0:  90% | abe: 9.038 | eve: 9.820 | bob: 8.959Epoch   0:  91% | abe: 9.038 | eve: 9.820 | bob: 8.959Epoch   0:  91% | abe: 9.037 | eve: 9.821 | bob: 8.958Epoch   0:  92% | abe: 9.036 | eve: 9.821 | bob: 8.957Epoch   0:  93% | abe: 9.036 | eve: 9.821 | bob: 8.957Epoch   0:  93% | abe: 9.036 | eve: 9.822 | bob: 8.957Epoch   0:  94% | abe: 9.035 | eve: 9.822 | bob: 8.956Epoch   0:  95% | abe: 9.035 | eve: 9.823 | bob: 8.956Epoch   0:  95% | abe: 9.035 | eve: 9.823 | bob: 8.956Epoch   0:  96% | abe: 9.034 | eve: 9.823 | bob: 8.955Epoch   0:  97% | abe: 9.034 | eve: 9.823 | bob: 8.955Epoch   0:  97% | abe: 9.034 | eve: 9.823 | bob: 8.955Epoch   0:  98% | abe: 9.034 | eve: 9.823 | bob: 8.954Epoch   0:  99% | abe: 9.033 | eve: 9.823 | bob: 8.954
New best Bob loss 8.95386255322796 at epoch 0
Epoch   1:   0% | abe: 8.992 | eve: 9.768 | bob: 8.903Epoch   1:   0% | abe: 8.974 | eve: 9.802 | bob: 8.884Epoch   1:   1% | abe: 9.005 | eve: 9.796 | bob: 8.917Epoch   1:   2% | abe: 9.001 | eve: 9.786 | bob: 8.913Epoch   1:   2% | abe: 8.994 | eve: 9.792 | bob: 8.907Epoch   1:   3% | abe: 8.988 | eve: 9.792 | bob: 8.900Epoch   1:   4% | abe: 8.983 | eve: 9.787 | bob: 8.895Epoch   1:   4% | abe: 8.971 | eve: 9.801 | bob: 8.882Epoch   1:   5% | abe: 8.970 | eve: 9.810 | bob: 8.881Epoch   1:   6% | abe: 8.973 | eve: 9.804 | bob: 8.884Epoch   1:   6% | abe: 8.973 | eve: 9.802 | bob: 8.884Epoch   1:   7% | abe: 8.969 | eve: 9.807 | bob: 8.880Epoch   1:   8% | abe: 8.966 | eve: 9.808 | bob: 8.877Epoch   1:   8% | abe: 8.972 | eve: 9.806 | bob: 8.883Epoch   1:   9% | abe: 8.974 | eve: 9.808 | bob: 8.885Epoch   1:  10% | abe: 8.977 | eve: 9.808 | bob: 8.887Epoch   1:  10% | abe: 8.974 | eve: 9.810 | bob: 8.884Epoch   1:  11% | abe: 8.974 | eve: 9.812 | bob: 8.885Epoch   1:  12% | abe: 8.975 | eve: 9.813 | bob: 8.885Epoch   1:  13% | abe: 8.972 | eve: 9.813 | bob: 8.882Epoch   1:  13% | abe: 8.970 | eve: 9.812 | bob: 8.880Epoch   1:  14% | abe: 8.967 | eve: 9.810 | bob: 8.877Epoch   1:  15% | abe: 8.965 | eve: 9.811 | bob: 8.875Epoch   1:  15% | abe: 8.964 | eve: 9.815 | bob: 8.873Epoch   1:  16% | abe: 8.964 | eve: 9.815 | bob: 8.873Epoch   1:  17% | abe: 8.962 | eve: 9.813 | bob: 8.872Epoch   1:  17% | abe: 8.962 | eve: 9.812 | bob: 8.871Epoch   1:  18% | abe: 8.962 | eve: 9.813 | bob: 8.871Epoch   1:  19% | abe: 8.961 | eve: 9.817 | bob: 8.870Epoch   1:  19% | abe: 8.960 | eve: 9.814 | bob: 8.870Epoch   1:  20% | abe: 8.960 | eve: 9.811 | bob: 8.869Epoch   1:  21% | abe: 8.961 | eve: 9.810 | bob: 8.870Epoch   1:  21% | abe: 8.962 | eve: 9.810 | bob: 8.871Epoch   1:  22% | abe: 8.962 | eve: 9.811 | bob: 8.871Epoch   1:  23% | abe: 8.961 | eve: 9.811 | bob: 8.870Epoch   1:  23% | abe: 8.960 | eve: 9.811 | bob: 8.870Epoch   1:  24% | abe: 8.961 | eve: 9.811 | bob: 8.870Epoch   1:  25% | abe: 8.959 | eve: 9.812 | bob: 8.868Epoch   1:  26% | abe: 8.958 | eve: 9.812 | bob: 8.867Epoch   1:  26% | abe: 8.957 | eve: 9.813 | bob: 8.866Epoch   1:  27% | abe: 8.957 | eve: 9.814 | bob: 8.866Epoch   1:  28% | abe: 8.957 | eve: 9.815 | bob: 8.866Epoch   1:  28% | abe: 8.957 | eve: 9.816 | bob: 8.866Epoch   1:  29% | abe: 8.958 | eve: 9.816 | bob: 8.867Epoch   1:  30% | abe: 8.958 | eve: 9.817 | bob: 8.867Epoch   1:  30% | abe: 8.957 | eve: 9.818 | bob: 8.866Epoch   1:  31% | abe: 8.957 | eve: 9.817 | bob: 8.866Epoch   1:  32% | abe: 8.959 | eve: 9.818 | bob: 8.868Epoch   1:  32% | abe: 8.960 | eve: 9.818 | bob: 8.869Epoch   1:  33% | abe: 8.960 | eve: 9.818 | bob: 8.869Epoch   1:  34% | abe: 8.960 | eve: 9.818 | bob: 8.870Epoch   1:  34% | abe: 8.961 | eve: 9.817 | bob: 8.870Epoch   1:  35% | abe: 8.960 | eve: 9.817 | bob: 8.870Epoch   1:  36% | abe: 8.960 | eve: 9.817 | bob: 8.870Epoch   1:  36% | abe: 8.960 | eve: 9.816 | bob: 8.870Epoch   1:  37% | abe: 8.960 | eve: 9.818 | bob: 8.870Epoch   1:  38% | abe: 8.960 | eve: 9.819 | bob: 8.869Epoch   1:  39% | abe: 8.959 | eve: 9.819 | bob: 8.868Epoch   1:  39% | abe: 8.959 | eve: 9.821 | bob: 8.869Epoch   1:  40% | abe: 8.960 | eve: 9.819 | bob: 8.869Epoch   1:  41% | abe: 8.959 | eve: 9.820 | bob: 8.868Epoch   1:  41% | abe: 8.959 | eve: 9.821 | bob: 8.869Epoch   1:  42% | abe: 8.958 | eve: 9.822 | bob: 8.868Epoch   1:  43% | abe: 8.957 | eve: 9.821 | bob: 8.867Epoch   1:  43% | abe: 8.957 | eve: 9.822 | bob: 8.866Epoch   1:  44% | abe: 8.956 | eve: 9.822 | bob: 8.866Epoch   1:  45% | abe: 8.956 | eve: 9.823 | bob: 8.865Epoch   1:  45% | abe: 8.955 | eve: 9.822 | bob: 8.865Epoch   1:  46% | abe: 8.954 | eve: 9.822 | bob: 8.863Epoch   1:  47% | abe: 8.953 | eve: 9.821 | bob: 8.863Epoch   1:  47% | abe: 8.952 | eve: 9.820 | bob: 8.862Epoch   1:  48% | abe: 8.951 | eve: 9.820 | bob: 8.861Epoch   1:  49% | abe: 8.951 | eve: 9.820 | bob: 8.861Epoch   1:  50% | abe: 8.950 | eve: 9.819 | bob: 8.860Epoch   1:  50% | abe: 8.950 | eve: 9.820 | bob: 8.860Epoch   1:  51% | abe: 8.950 | eve: 9.821 | bob: 8.859Epoch   1:  52% | abe: 8.949 | eve: 9.821 | bob: 8.859Epoch   1:  52% | abe: 8.950 | eve: 9.821 | bob: 8.859Epoch   1:  53% | abe: 8.949 | eve: 9.821 | bob: 8.859Epoch   1:  54% | abe: 8.948 | eve: 9.821 | bob: 8.858Epoch   1:  54% | abe: 8.948 | eve: 9.822 | bob: 8.858Epoch   1:  55% | abe: 8.948 | eve: 9.822 | bob: 8.858Epoch   1:  56% | abe: 8.947 | eve: 9.823 | bob: 8.857Epoch   1:  56% | abe: 8.947 | eve: 9.824 | bob: 8.857Epoch   1:  57% | abe: 8.947 | eve: 9.825 | bob: 8.857Epoch   1:  58% | abe: 8.947 | eve: 9.825 | bob: 8.857Epoch   1:  58% | abe: 8.946 | eve: 9.825 | bob: 8.856Epoch   1:  59% | abe: 8.946 | eve: 9.825 | bob: 8.856Epoch   1:  60% | abe: 8.945 | eve: 9.824 | bob: 8.855Epoch   1:  60% | abe: 8.944 | eve: 9.824 | bob: 8.854Epoch   1:  61% | abe: 8.944 | eve: 9.823 | bob: 8.854Epoch   1:  62% | abe: 8.944 | eve: 9.823 | bob: 8.854Epoch   1:  63% | abe: 8.943 | eve: 9.823 | bob: 8.853Epoch   1:  63% | abe: 8.943 | eve: 9.822 | bob: 8.853Epoch   1:  64% | abe: 8.943 | eve: 9.822 | bob: 8.853Epoch   1:  65% | abe: 8.942 | eve: 9.823 | bob: 8.852Epoch   1:  65% | abe: 8.942 | eve: 9.823 | bob: 8.851Epoch   1:  66% | abe: 8.941 | eve: 9.823 | bob: 8.851Epoch   1:  67% | abe: 8.941 | eve: 9.823 | bob: 8.851Epoch   1:  67% | abe: 8.940 | eve: 9.823 | bob: 8.850Epoch   1:  68% | abe: 8.940 | eve: 9.824 | bob: 8.850Epoch   1:  69% | abe: 8.940 | eve: 9.825 | bob: 8.850Epoch   1:  69% | abe: 8.940 | eve: 9.824 | bob: 8.850Epoch   1:  70% | abe: 8.939 | eve: 9.824 | bob: 8.849Epoch   1:  71% | abe: 8.939 | eve: 9.824 | bob: 8.849Epoch   1:  71% | abe: 8.939 | eve: 9.824 | bob: 8.849Epoch   1:  72% | abe: 8.939 | eve: 9.825 | bob: 8.849Epoch   1:  73% | abe: 8.939 | eve: 9.825 | bob: 8.849Epoch   1:  73% | abe: 8.938 | eve: 9.825 | bob: 8.848Epoch   1:  74% | abe: 8.938 | eve: 9.826 | bob: 8.848Epoch   1:  75% | abe: 8.938 | eve: 9.826 | bob: 8.848Epoch   1:  76% | abe: 8.938 | eve: 9.827 | bob: 8.848Epoch   1:  76% | abe: 8.938 | eve: 9.826 | bob: 8.847Epoch   1:  77% | abe: 8.937 | eve: 9.826 | bob: 8.847Epoch   1:  78% | abe: 8.937 | eve: 9.826 | bob: 8.847Epoch   1:  78% | abe: 8.936 | eve: 9.826 | bob: 8.846Epoch   1:  79% | abe: 8.936 | eve: 9.826 | bob: 8.846Epoch   1:  80% | abe: 8.935 | eve: 9.827 | bob: 8.845Epoch   1:  80% | abe: 8.935 | eve: 9.828 | bob: 8.845Epoch   1:  81% | abe: 8.935 | eve: 9.828 | bob: 8.845Epoch   1:  82% | abe: 8.935 | eve: 9.828 | bob: 8.845Epoch   1:  82% | abe: 8.935 | eve: 9.828 | bob: 8.845Epoch   1:  83% | abe: 8.934 | eve: 9.828 | bob: 8.844Epoch   1:  84% | abe: 8.933 | eve: 9.829 | bob: 8.843Epoch   1:  84% | abe: 8.933 | eve: 9.828 | bob: 8.843Epoch   1:  85% | abe: 8.933 | eve: 9.828 | bob: 8.843Epoch   1:  86% | abe: 8.933 | eve: 9.828 | bob: 8.843Epoch   1:  86% | abe: 8.932 | eve: 9.828 | bob: 8.842Epoch   1:  87% | abe: 8.932 | eve: 9.828 | bob: 8.841Epoch   1:  88% | abe: 8.931 | eve: 9.828 | bob: 8.841Epoch   1:  89% | abe: 8.931 | eve: 9.828 | bob: 8.841Epoch   1:  89% | abe: 8.930 | eve: 9.828 | bob: 8.840Epoch   1:  90% | abe: 8.930 | eve: 9.828 | bob: 8.840Epoch   1:  91% | abe: 8.930 | eve: 9.828 | bob: 8.840Epoch   1:  91% | abe: 8.929 | eve: 9.828 | bob: 8.839Epoch   1:  92% | abe: 8.928 | eve: 9.828 | bob: 8.838Epoch   1:  93% | abe: 8.928 | eve: 9.828 | bob: 8.838Epoch   1:  93% | abe: 8.928 | eve: 9.828 | bob: 8.838Epoch   1:  94% | abe: 8.927 | eve: 9.828 | bob: 8.837Epoch   1:  95% | abe: 8.927 | eve: 9.828 | bob: 8.837Epoch   1:  95% | abe: 8.927 | eve: 9.828 | bob: 8.837Epoch   1:  96% | abe: 8.926 | eve: 9.828 | bob: 8.836Epoch   1:  97% | abe: 8.926 | eve: 9.828 | bob: 8.836Epoch   1:  97% | abe: 8.927 | eve: 9.828 | bob: 8.837Epoch   1:  98% | abe: 8.926 | eve: 9.829 | bob: 8.836Epoch   1:  99% | abe: 8.926 | eve: 9.829 | bob: 8.836
New best Bob loss 8.835898840812913 at epoch 1
Epoch   2:   0% | abe: 8.862 | eve: 9.769 | bob: 8.774Epoch   2:   0% | abe: 8.850 | eve: 9.813 | bob: 8.763Epoch   2:   1% | abe: 8.848 | eve: 9.830 | bob: 8.760Epoch   2:   2% | abe: 8.864 | eve: 9.828 | bob: 8.775Epoch   2:   2% | abe: 8.850 | eve: 9.826 | bob: 8.760Epoch   2:   3% | abe: 8.846 | eve: 9.820 | bob: 8.756Epoch   2:   4% | abe: 8.854 | eve: 9.832 | bob: 8.764Epoch   2:   4% | abe: 8.856 | eve: 9.829 | bob: 8.766Epoch   2:   5% | abe: 8.854 | eve: 9.822 | bob: 8.763Epoch   2:   6% | abe: 8.856 | eve: 9.820 | bob: 8.765Epoch   2:   6% | abe: 8.855 | eve: 9.814 | bob: 8.764Epoch   2:   7% | abe: 8.851 | eve: 9.817 | bob: 8.760Epoch   2:   8% | abe: 8.849 | eve: 9.817 | bob: 8.758Epoch   2:   8% | abe: 8.852 | eve: 9.814 | bob: 8.761Epoch   2:   9% | abe: 8.853 | eve: 9.812 | bob: 8.762Epoch   2:  10% | abe: 8.852 | eve: 9.804 | bob: 8.761Epoch   2:  10% | abe: 8.850 | eve: 9.801 | bob: 8.759Epoch   2:  11% | abe: 8.854 | eve: 9.798 | bob: 8.762Epoch   2:  12% | abe: 8.854 | eve: 9.799 | bob: 8.762Epoch   2:  13% | abe: 8.857 | eve: 9.801 | bob: 8.766Epoch   2:  13% | abe: 8.858 | eve: 9.799 | bob: 8.767Epoch   2:  14% | abe: 8.857 | eve: 9.802 | bob: 8.765Epoch   2:  15% | abe: 8.857 | eve: 9.804 | bob: 8.765Epoch   2:  15% | abe: 8.857 | eve: 9.804 | bob: 8.765Epoch   2:  16% | abe: 8.855 | eve: 9.801 | bob: 8.763Epoch   2:  17% | abe: 8.853 | eve: 9.799 | bob: 8.761Epoch   2:  17% | abe: 8.853 | eve: 9.797 | bob: 8.760Epoch   2:  18% | abe: 8.851 | eve: 9.800 | bob: 8.759Epoch   2:  19% | abe: 8.849 | eve: 9.802 | bob: 8.757Epoch   2:  19% | abe: 8.850 | eve: 9.805 | bob: 8.758Epoch   2:  20% | abe: 8.851 | eve: 9.804 | bob: 8.758Epoch   2:  21% | abe: 8.851 | eve: 9.806 | bob: 8.759Epoch   2:  21% | abe: 8.850 | eve: 9.808 | bob: 8.758Epoch   2:  22% | abe: 8.849 | eve: 9.809 | bob: 8.756Epoch   2:  23% | abe: 8.847 | eve: 9.810 | bob: 8.754Epoch   2:  23% | abe: 8.844 | eve: 9.810 | bob: 8.751Epoch   2:  24% | abe: 8.843 | eve: 9.810 | bob: 8.751Epoch   2:  25% | abe: 8.843 | eve: 9.813 | bob: 8.751Epoch   2:  26% | abe: 8.842 | eve: 9.811 | bob: 8.749Epoch   2:  26% | abe: 8.842 | eve: 9.810 | bob: 8.749Epoch   2:  27% | abe: 8.841 | eve: 9.808 | bob: 8.748Epoch   2:  28% | abe: 8.839 | eve: 9.809 | bob: 8.746Epoch   2:  28% | abe: 8.840 | eve: 9.808 | bob: 8.747Epoch   2:  29% | abe: 8.839 | eve: 9.812 | bob: 8.746Epoch   2:  30% | abe: 8.840 | eve: 9.811 | bob: 8.747Epoch   2:  30% | abe: 8.839 | eve: 9.812 | bob: 8.746Epoch   2:  31% | abe: 8.839 | eve: 9.814 | bob: 8.746Epoch   2:  32% | abe: 8.838 | eve: 9.814 | bob: 8.745Epoch   2:  32% | abe: 8.837 | eve: 9.814 | bob: 8.744Epoch   2:  33% | abe: 8.837 | eve: 9.815 | bob: 8.744Epoch   2:  34% | abe: 8.836 | eve: 9.815 | bob: 8.743Epoch   2:  34% | abe: 8.837 | eve: 9.814 | bob: 8.744Epoch   2:  35% | abe: 8.836 | eve: 9.813 | bob: 8.743Epoch   2:  36% | abe: 8.835 | eve: 9.813 | bob: 8.742Epoch   2:  36% | abe: 8.835 | eve: 9.812 | bob: 8.742Epoch   2:  37% | abe: 8.834 | eve: 9.810 | bob: 8.741Epoch   2:  38% | abe: 8.834 | eve: 9.811 | bob: 8.741Epoch   2:  39% | abe: 8.834 | eve: 9.810 | bob: 8.741Epoch   2:  39% | abe: 8.833 | eve: 9.812 | bob: 8.740Epoch   2:  40% | abe: 8.832 | eve: 9.811 | bob: 8.739Epoch   2:  41% | abe: 8.832 | eve: 9.812 | bob: 8.739Epoch   2:  41% | abe: 8.831 | eve: 9.813 | bob: 8.738Epoch   2:  42% | abe: 8.831 | eve: 9.814 | bob: 8.738Epoch   2:  43% | abe: 8.830 | eve: 9.814 | bob: 8.737Epoch   2:  43% | abe: 8.830 | eve: 9.815 | bob: 8.737Epoch   2:  44% | abe: 8.829 | eve: 9.816 | bob: 8.737Epoch   2:  45% | abe: 8.829 | eve: 9.815 | bob: 8.736Epoch   2:  45% | abe: 8.828 | eve: 9.815 | bob: 8.735Epoch   2:  46% | abe: 8.827 | eve: 9.814 | bob: 8.734Epoch   2:  47% | abe: 8.826 | eve: 9.815 | bob: 8.734Epoch   2:  47% | abe: 8.827 | eve: 9.815 | bob: 8.734Epoch   2:  48% | abe: 8.826 | eve: 9.816 | bob: 8.733Epoch   2:  49% | abe: 8.825 | eve: 9.816 | bob: 8.733Epoch   2:  50% | abe: 8.824 | eve: 9.815 | bob: 8.731Epoch   2:  50% | abe: 8.824 | eve: 9.815 | bob: 8.731Epoch   2:  51% | abe: 8.823 | eve: 9.815 | bob: 8.730Epoch   2:  52% | abe: 8.822 | eve: 9.814 | bob: 8.730Epoch   2:  52% | abe: 8.822 | eve: 9.815 | bob: 8.730Epoch   2:  53% | abe: 8.822 | eve: 9.816 | bob: 8.729Epoch   2:  54% | abe: 8.822 | eve: 9.817 | bob: 8.729Epoch   2:  54% | abe: 8.822 | eve: 9.816 | bob: 8.729Epoch   2:  55% | abe: 8.821 | eve: 9.816 | bob: 8.728Epoch   2:  56% | abe: 8.820 | eve: 9.817 | bob: 8.727Epoch   2:  56% | abe: 8.819 | eve: 9.815 | bob: 8.727Epoch   2:  57% | abe: 8.819 | eve: 9.814 | bob: 8.727Epoch   2:  58% | abe: 8.819 | eve: 9.814 | bob: 8.727Epoch   2:  58% | abe: 8.818 | eve: 9.814 | bob: 8.726Epoch   2:  59% | abe: 8.817 | eve: 9.815 | bob: 8.725Epoch   2:  60% | abe: 8.817 | eve: 9.816 | bob: 8.724Epoch   2:  60% | abe: 8.816 | eve: 9.816 | bob: 8.724Epoch   2:  61% | abe: 8.816 | eve: 9.816 | bob: 8.724Epoch   2:  62% | abe: 8.815 | eve: 9.816 | bob: 8.723Epoch   2:  63% | abe: 8.815 | eve: 9.816 | bob: 8.723Epoch   2:  63% | abe: 8.814 | eve: 9.816 | bob: 8.721Epoch   2:  64% | abe: 8.814 | eve: 9.817 | bob: 8.721Epoch   2:  65% | abe: 8.813 | eve: 9.816 | bob: 8.721Epoch   2:  65% | abe: 8.812 | eve: 9.816 | bob: 8.720Epoch   2:  66% | abe: 8.812 | eve: 9.816 | bob: 8.720Epoch   2:  67% | abe: 8.812 | eve: 9.816 | bob: 8.720Epoch   2:  67% | abe: 8.811 | eve: 9.816 | bob: 8.719Epoch   2:  68% | abe: 8.811 | eve: 9.817 | bob: 8.719Epoch   2:  69% | abe: 8.810 | eve: 9.818 | bob: 8.718Epoch   2:  69% | abe: 8.809 | eve: 9.817 | bob: 8.717Epoch   2:  70% | abe: 8.808 | eve: 9.817 | bob: 8.716Epoch   2:  71% | abe: 8.808 | eve: 9.816 | bob: 8.716Epoch   2:  71% | abe: 8.808 | eve: 9.816 | bob: 8.716Epoch   2:  72% | abe: 8.807 | eve: 9.816 | bob: 8.716Epoch   2:  73% | abe: 8.807 | eve: 9.816 | bob: 8.715Epoch   2:  73% | abe: 8.807 | eve: 9.817 | bob: 8.715Epoch   2:  74% | abe: 8.806 | eve: 9.818 | bob: 8.714Epoch   2:  75% | abe: 8.806 | eve: 9.818 | bob: 8.714Epoch   2:  76% | abe: 8.805 | eve: 9.818 | bob: 8.714Epoch   2:  76% | abe: 8.805 | eve: 9.817 | bob: 8.713Epoch   2:  77% | abe: 8.805 | eve: 9.817 | bob: 8.713Epoch   2:  78% | abe: 8.805 | eve: 9.817 | bob: 8.713Epoch   2:  78% | abe: 8.804 | eve: 9.817 | bob: 8.713Epoch   2:  79% | abe: 8.803 | eve: 9.818 | bob: 8.712Epoch   2:  80% | abe: 8.803 | eve: 9.819 | bob: 8.712Epoch   2:  80% | abe: 8.803 | eve: 9.819 | bob: 8.711Epoch   2:  81% | abe: 8.802 | eve: 9.818 | bob: 8.710Epoch   2:  82% | abe: 8.802 | eve: 9.818 | bob: 8.710Epoch   2:  82% | abe: 8.801 | eve: 9.819 | bob: 8.709Epoch   2:  83% | abe: 8.801 | eve: 9.819 | bob: 8.710Epoch   2:  84% | abe: 8.800 | eve: 9.819 | bob: 8.709Epoch   2:  84% | abe: 8.800 | eve: 9.818 | bob: 8.708Epoch   2:  85% | abe: 8.800 | eve: 9.818 | bob: 8.708Epoch   2:  86% | abe: 8.800 | eve: 9.818 | bob: 8.708Epoch   2:  86% | abe: 8.799 | eve: 9.818 | bob: 8.708Epoch   2:  87% | abe: 8.798 | eve: 9.818 | bob: 8.707Epoch   2:  88% | abe: 8.798 | eve: 9.818 | bob: 8.707Epoch   2:  89% | abe: 8.798 | eve: 9.818 | bob: 8.707Epoch   2:  89% | abe: 8.798 | eve: 9.817 | bob: 8.706Epoch   2:  90% | abe: 8.797 | eve: 9.817 | bob: 8.706Epoch   2:  91% | abe: 8.796 | eve: 9.818 | bob: 8.705Epoch   2:  91% | abe: 8.795 | eve: 9.817 | bob: 8.704Epoch   2:  92% | abe: 8.794 | eve: 9.818 | bob: 8.703Epoch   2:  93% | abe: 8.793 | eve: 9.818 | bob: 8.702Epoch   2:  93% | abe: 8.793 | eve: 9.818 | bob: 8.702Epoch   2:  94% | abe: 8.793 | eve: 9.818 | bob: 8.702Epoch   2:  95% | abe: 8.792 | eve: 9.818 | bob: 8.701Epoch   2:  95% | abe: 8.792 | eve: 9.818 | bob: 8.701Epoch   2:  96% | abe: 8.791 | eve: 9.818 | bob: 8.701Epoch   2:  97% | abe: 8.791 | eve: 9.818 | bob: 8.700Epoch   2:  97% | abe: 8.790 | eve: 9.818 | bob: 8.699Epoch   2:  98% | abe: 8.789 | eve: 9.818 | bob: 8.699Epoch   2:  99% | abe: 8.789 | eve: 9.818 | bob: 8.698
New best Bob loss 8.698415259150615 at epoch 2
Epoch   3:   0% | abe: 8.743 | eve: 9.859 | bob: 8.660Epoch   3:   0% | abe: 8.754 | eve: 9.814 | bob: 8.670Epoch   3:   1% | abe: 8.731 | eve: 9.808 | bob: 8.646Epoch   3:   2% | abe: 8.717 | eve: 9.820 | bob: 8.631Epoch   3:   2% | abe: 8.732 | eve: 9.837 | bob: 8.647Epoch   3:   3% | abe: 8.727 | eve: 9.839 | bob: 8.641Epoch   3:   4% | abe: 8.734 | eve: 9.832 | bob: 8.648Epoch   3:   4% | abe: 8.734 | eve: 9.830 | bob: 8.649Epoch   3:   5% | abe: 8.740 | eve: 9.818 | bob: 8.655Epoch   3:   6% | abe: 8.739 | eve: 9.823 | bob: 8.654Epoch   3:   6% | abe: 8.740 | eve: 9.830 | bob: 8.655Epoch   3:   7% | abe: 8.735 | eve: 9.828 | bob: 8.650Epoch   3:   8% | abe: 8.735 | eve: 9.829 | bob: 8.650Epoch   3:   8% | abe: 8.735 | eve: 9.825 | bob: 8.650Epoch   3:   9% | abe: 8.730 | eve: 9.828 | bob: 8.645Epoch   3:  10% | abe: 8.731 | eve: 9.828 | bob: 8.646Epoch   3:  10% | abe: 8.728 | eve: 9.827 | bob: 8.643Epoch   3:  11% | abe: 8.726 | eve: 9.829 | bob: 8.641Epoch   3:  12% | abe: 8.725 | eve: 9.829 | bob: 8.639Epoch   3:  13% | abe: 8.726 | eve: 9.826 | bob: 8.641Epoch   3:  13% | abe: 8.727 | eve: 9.822 | bob: 8.642Epoch   3:  14% | abe: 8.726 | eve: 9.820 | bob: 8.641Epoch   3:  15% | abe: 8.726 | eve: 9.817 | bob: 8.641Epoch   3:  15% | abe: 8.727 | eve: 9.816 | bob: 8.642Epoch   3:  16% | abe: 8.724 | eve: 9.817 | bob: 8.639Epoch   3:  17% | abe: 8.724 | eve: 9.816 | bob: 8.639Epoch   3:  17% | abe: 8.722 | eve: 9.816 | bob: 8.637Epoch   3:  18% | abe: 8.721 | eve: 9.818 | bob: 8.636Epoch   3:  19% | abe: 8.720 | eve: 9.819 | bob: 8.635Epoch   3:  19% | abe: 8.719 | eve: 9.818 | bob: 8.635Epoch   3:  20% | abe: 8.718 | eve: 9.817 | bob: 8.634Epoch   3:  21% | abe: 8.718 | eve: 9.813 | bob: 8.633Epoch   3:  21% | abe: 8.716 | eve: 9.814 | bob: 8.632Epoch   3:  22% | abe: 8.715 | eve: 9.813 | bob: 8.630Epoch   3:  23% | abe: 8.715 | eve: 9.814 | bob: 8.631Epoch   3:  23% | abe: 8.715 | eve: 9.815 | bob: 8.631Epoch   3:  24% | abe: 8.714 | eve: 9.816 | bob: 8.629Epoch   3:  25% | abe: 8.713 | eve: 9.814 | bob: 8.628Epoch   3:  26% | abe: 8.713 | eve: 9.816 | bob: 8.628Epoch   3:  26% | abe: 8.713 | eve: 9.814 | bob: 8.628Epoch   3:  27% | abe: 8.713 | eve: 9.816 | bob: 8.629Epoch   3:  28% | abe: 8.712 | eve: 9.816 | bob: 8.628Epoch   3:  28% | abe: 8.711 | eve: 9.816 | bob: 8.627Epoch   3:  29% | abe: 8.711 | eve: 9.815 | bob: 8.627Epoch   3:  30% | abe: 8.712 | eve: 9.815 | bob: 8.627Epoch   3:  30% | abe: 8.711 | eve: 9.815 | bob: 8.627Epoch   3:  31% | abe: 8.710 | eve: 9.814 | bob: 8.626Epoch   3:  32% | abe: 8.711 | eve: 9.813 | bob: 8.626Epoch   3:  32% | abe: 8.711 | eve: 9.812 | bob: 8.626Epoch   3:  33% | abe: 8.711 | eve: 9.811 | bob: 8.627Epoch   3:  34% | abe: 8.711 | eve: 9.810 | bob: 8.627Epoch   3:  34% | abe: 8.711 | eve: 9.809 | bob: 8.627Epoch   3:  35% | abe: 8.711 | eve: 9.809 | bob: 8.626Epoch   3:  36% | abe: 8.710 | eve: 9.809 | bob: 8.626Epoch   3:  36% | abe: 8.709 | eve: 9.812 | bob: 8.625Epoch   3:  37% | abe: 8.708 | eve: 9.810 | bob: 8.624Epoch   3:  38% | abe: 8.707 | eve: 9.810 | bob: 8.623Epoch   3:  39% | abe: 8.707 | eve: 9.810 | bob: 8.623Epoch   3:  39% | abe: 8.706 | eve: 9.809 | bob: 8.622Epoch   3:  40% | abe: 8.706 | eve: 9.809 | bob: 8.622Epoch   3:  41% | abe: 8.706 | eve: 9.811 | bob: 8.622Epoch   3:  41% | abe: 8.705 | eve: 9.810 | bob: 8.621Epoch   3:  42% | abe: 8.705 | eve: 9.809 | bob: 8.621Epoch   3:  43% | abe: 8.705 | eve: 9.809 | bob: 8.621Epoch   3:  43% | abe: 8.704 | eve: 9.809 | bob: 8.620Epoch   3:  44% | abe: 8.703 | eve: 9.809 | bob: 8.619Epoch   3:  45% | abe: 8.703 | eve: 9.809 | bob: 8.619Epoch   3:  45% | abe: 8.703 | eve: 9.809 | bob: 8.619Epoch   3:  46% | abe: 8.703 | eve: 9.810 | bob: 8.619Epoch   3:  47% | abe: 8.702 | eve: 9.809 | bob: 8.619Epoch   3:  47% | abe: 8.702 | eve: 9.810 | bob: 8.619Epoch   3:  48% | abe: 8.702 | eve: 9.811 | bob: 8.618Epoch   3:  49% | abe: 8.702 | eve: 9.811 | bob: 8.618Epoch   3:  50% | abe: 8.700 | eve: 9.811 | bob: 8.617Epoch   3:  50% | abe: 8.701 | eve: 9.811 | bob: 8.617Epoch   3:  51% | abe: 8.701 | eve: 9.811 | bob: 8.617Epoch   3:  52% | abe: 8.701 | eve: 9.813 | bob: 8.617Epoch   3:  52% | abe: 8.701 | eve: 9.812 | bob: 8.618Epoch   3:  53% | abe: 8.701 | eve: 9.811 | bob: 8.617Epoch   3:  54% | abe: 8.700 | eve: 9.811 | bob: 8.617Epoch   3:  54% | abe: 8.700 | eve: 9.810 | bob: 8.617Epoch   3:  55% | abe: 8.700 | eve: 9.810 | bob: 8.617Epoch   3:  56% | abe: 8.700 | eve: 9.810 | bob: 8.616Epoch   3:  56% | abe: 8.699 | eve: 9.810 | bob: 8.616Epoch   3:  57% | abe: 8.699 | eve: 9.810 | bob: 8.616Epoch   3:  58% | abe: 8.699 | eve: 9.809 | bob: 8.616Epoch   3:  58% | abe: 8.698 | eve: 9.809 | bob: 8.615Epoch   3:  59% | abe: 8.698 | eve: 9.809 | bob: 8.615Epoch   3:  60% | abe: 8.698 | eve: 9.810 | bob: 8.615Epoch   3:  60% | abe: 8.699 | eve: 9.810 | bob: 8.616Epoch   3:  61% | abe: 8.698 | eve: 9.809 | bob: 8.615Epoch   3:  62% | abe: 8.698 | eve: 9.809 | bob: 8.615Epoch   3:  63% | abe: 8.697 | eve: 9.809 | bob: 8.614Epoch   3:  63% | abe: 8.697 | eve: 9.809 | bob: 8.614Epoch   3:  64% | abe: 8.696 | eve: 9.809 | bob: 8.613Epoch   3:  65% | abe: 8.696 | eve: 9.809 | bob: 8.613Epoch   3:  65% | abe: 8.695 | eve: 9.809 | bob: 8.613Epoch   3:  66% | abe: 8.695 | eve: 9.810 | bob: 8.613Epoch   3:  67% | abe: 8.695 | eve: 9.810 | bob: 8.612Epoch   3:  67% | abe: 8.695 | eve: 9.810 | bob: 8.612Epoch   3:  68% | abe: 8.694 | eve: 9.809 | bob: 8.611Epoch   3:  69% | abe: 8.695 | eve: 9.810 | bob: 8.612Epoch   3:  69% | abe: 8.694 | eve: 9.810 | bob: 8.611Epoch   3:  70% | abe: 8.694 | eve: 9.809 | bob: 8.611Epoch   3:  71% | abe: 8.694 | eve: 9.810 | bob: 8.611Epoch   3:  71% | abe: 8.693 | eve: 9.810 | bob: 8.610Epoch   3:  72% | abe: 8.693 | eve: 9.809 | bob: 8.610Epoch   3:  73% | abe: 8.693 | eve: 9.810 | bob: 8.610Epoch   3:  73% | abe: 8.693 | eve: 9.810 | bob: 8.610Epoch   3:  74% | abe: 8.693 | eve: 9.809 | bob: 8.610Epoch   3:  75% | abe: 8.692 | eve: 9.808 | bob: 8.610Epoch   3:  76% | abe: 8.692 | eve: 9.808 | bob: 8.609Epoch   3:  76% | abe: 8.691 | eve: 9.808 | bob: 8.609Epoch   3:  77% | abe: 8.691 | eve: 9.807 | bob: 8.609Epoch   3:  78% | abe: 8.691 | eve: 9.807 | bob: 8.608Epoch   3:  78% | abe: 8.691 | eve: 9.807 | bob: 8.608Epoch   3:  79% | abe: 8.690 | eve: 9.808 | bob: 8.607Epoch   3:  80% | abe: 8.689 | eve: 9.807 | bob: 8.607Epoch   3:  80% | abe: 8.689 | eve: 9.807 | bob: 8.606Epoch   3:  81% | abe: 8.688 | eve: 9.808 | bob: 8.605Epoch   3:  82% | abe: 8.688 | eve: 9.808 | bob: 8.606Epoch   3:  82% | abe: 8.687 | eve: 9.808 | bob: 8.605Epoch   3:  83% | abe: 8.687 | eve: 9.808 | bob: 8.605Epoch   3:  84% | abe: 8.687 | eve: 9.808 | bob: 8.605Epoch   3:  84% | abe: 8.687 | eve: 9.808 | bob: 8.604Epoch   3:  85% | abe: 8.687 | eve: 9.808 | bob: 8.604Epoch   3:  86% | abe: 8.686 | eve: 9.808 | bob: 8.604Epoch   3:  86% | abe: 8.686 | eve: 9.807 | bob: 8.603Epoch   3:  87% | abe: 8.685 | eve: 9.807 | bob: 8.603Epoch   3:  88% | abe: 8.685 | eve: 9.808 | bob: 8.603Epoch   3:  89% | abe: 8.685 | eve: 9.809 | bob: 8.602Epoch   3:  89% | abe: 8.685 | eve: 9.808 | bob: 8.602Epoch   3:  90% | abe: 8.685 | eve: 9.808 | bob: 8.602Epoch   3:  91% | abe: 8.685 | eve: 9.808 | bob: 8.603Epoch   3:  91% | abe: 8.684 | eve: 9.809 | bob: 8.602Epoch   3:  92% | abe: 8.684 | eve: 9.808 | bob: 8.602Epoch   3:  93% | abe: 8.684 | eve: 9.809 | bob: 8.602Epoch   3:  93% | abe: 8.684 | eve: 9.809 | bob: 8.601Epoch   3:  94% | abe: 8.683 | eve: 9.809 | bob: 8.601Epoch   3:  95% | abe: 8.683 | eve: 9.809 | bob: 8.601Epoch   3:  95% | abe: 8.682 | eve: 9.809 | bob: 8.600Epoch   3:  96% | abe: 8.682 | eve: 9.809 | bob: 8.600Epoch   3:  97% | abe: 8.682 | eve: 9.809 | bob: 8.600Epoch   3:  97% | abe: 8.682 | eve: 9.809 | bob: 8.600Epoch   3:  98% | abe: 8.682 | eve: 9.809 | bob: 8.600Epoch   3:  99% | abe: 8.681 | eve: 9.810 | bob: 8.599
New best Bob loss 8.59884345994824 at epoch 3
Epoch   4:   0% | abe: 8.671 | eve: 9.836 | bob: 8.592Epoch   4:   0% | abe: 8.667 | eve: 9.815 | bob: 8.587Epoch   4:   1% | abe: 8.628 | eve: 9.811 | bob: 8.547Epoch   4:   2% | abe: 8.627 | eve: 9.804 | bob: 8.546Epoch   4:   2% | abe: 8.626 | eve: 9.798 | bob: 8.545Epoch   4:   3% | abe: 8.630 | eve: 9.802 | bob: 8.550Epoch   4:   4% | abe: 8.633 | eve: 9.804 | bob: 8.552Epoch   4:   4% | abe: 8.630 | eve: 9.805 | bob: 8.549Epoch   4:   5% | abe: 8.630 | eve: 9.813 | bob: 8.549Epoch   4:   6% | abe: 8.633 | eve: 9.810 | bob: 8.552Epoch   4:   6% | abe: 8.631 | eve: 9.804 | bob: 8.550Epoch   4:   7% | abe: 8.630 | eve: 9.807 | bob: 8.549Epoch   4:   8% | abe: 8.630 | eve: 9.808 | bob: 8.549Epoch   4:   8% | abe: 8.629 | eve: 9.801 | bob: 8.548Epoch   4:   9% | abe: 8.628 | eve: 9.796 | bob: 8.548Epoch   4:  10% | abe: 8.628 | eve: 9.794 | bob: 8.548Epoch   4:  10% | abe: 8.625 | eve: 9.793 | bob: 8.544Epoch   4:  11% | abe: 8.626 | eve: 9.796 | bob: 8.545Epoch   4:  12% | abe: 8.627 | eve: 9.797 | bob: 8.546Epoch   4:  13% | abe: 8.626 | eve: 9.796 | bob: 8.545Epoch   4:  13% | abe: 8.625 | eve: 9.793 | bob: 8.545Epoch   4:  14% | abe: 8.625 | eve: 9.790 | bob: 8.545Epoch   4:  15% | abe: 8.624 | eve: 9.788 | bob: 8.544Epoch   4:  15% | abe: 8.623 | eve: 9.789 | bob: 8.542Epoch   4:  16% | abe: 8.621 | eve: 9.786 | bob: 8.540Epoch   4:  17% | abe: 8.622 | eve: 9.784 | bob: 8.541Epoch   4:  17% | abe: 8.622 | eve: 9.784 | bob: 8.541Epoch   4:  18% | abe: 8.622 | eve: 9.782 | bob: 8.542Epoch   4:  19% | abe: 8.621 | eve: 9.782 | bob: 8.541Epoch   4:  19% | abe: 8.622 | eve: 9.783 | bob: 8.541Epoch   4:  20% | abe: 8.622 | eve: 9.785 | bob: 8.541Epoch   4:  21% | abe: 8.621 | eve: 9.786 | bob: 8.540Epoch   4:  21% | abe: 8.620 | eve: 9.788 | bob: 8.539Epoch   4:  22% | abe: 8.620 | eve: 9.787 | bob: 8.539Epoch   4:  23% | abe: 8.619 | eve: 9.786 | bob: 8.538Epoch   4:  23% | abe: 8.617 | eve: 9.788 | bob: 8.536Epoch   4:  24% | abe: 8.617 | eve: 9.787 | bob: 8.536Epoch   4:  25% | abe: 8.616 | eve: 9.787 | bob: 8.535Epoch   4:  26% | abe: 8.615 | eve: 9.788 | bob: 8.534Epoch   4:  26% | abe: 8.615 | eve: 9.790 | bob: 8.534Epoch   4:  27% | abe: 8.614 | eve: 9.791 | bob: 8.533Epoch   4:  28% | abe: 8.614 | eve: 9.792 | bob: 8.533Epoch   4:  28% | abe: 8.614 | eve: 9.792 | bob: 8.533Epoch   4:  29% | abe: 8.614 | eve: 9.793 | bob: 8.533Epoch   4:  30% | abe: 8.613 | eve: 9.792 | bob: 8.532Epoch   4:  30% | abe: 8.612 | eve: 9.792 | bob: 8.531Epoch   4:  31% | abe: 8.610 | eve: 9.794 | bob: 8.529Epoch   4:  32% | abe: 8.609 | eve: 9.794 | bob: 8.528Epoch   4:  32% | abe: 8.608 | eve: 9.794 | bob: 8.527Epoch   4:  33% | abe: 8.609 | eve: 9.794 | bob: 8.528Epoch   4:  34% | abe: 8.609 | eve: 9.794 | bob: 8.528Epoch   4:  34% | abe: 8.610 | eve: 9.793 | bob: 8.529Epoch   4:  35% | abe: 8.609 | eve: 9.794 | bob: 8.528Epoch   4:  36% | abe: 8.608 | eve: 9.794 | bob: 8.527Epoch   4:  36% | abe: 8.609 | eve: 9.794 | bob: 8.528Epoch   4:  37% | abe: 8.609 | eve: 9.794 | bob: 8.528Epoch   4:  38% | abe: 8.608 | eve: 9.794 | bob: 8.527Epoch   4:  39% | abe: 8.608 | eve: 9.793 | bob: 8.527Epoch   4:  39% | abe: 8.608 | eve: 9.791 | bob: 8.527Epoch   4:  40% | abe: 8.606 | eve: 9.791 | bob: 8.525Epoch   4:  41% | abe: 8.604 | eve: 9.791 | bob: 8.523Epoch   4:  41% | abe: 8.604 | eve: 9.791 | bob: 8.523Epoch   4:  42% | abe: 8.604 | eve: 9.791 | bob: 8.523Epoch   4:  43% | abe: 8.604 | eve: 9.792 | bob: 8.523Epoch   4:  43% | abe: 8.604 | eve: 9.791 | bob: 8.523Epoch   4:  44% | abe: 8.603 | eve: 9.791 | bob: 8.522Epoch   4:  45% | abe: 8.603 | eve: 9.790 | bob: 8.521Epoch   4:  45% | abe: 8.602 | eve: 9.790 | bob: 8.521Epoch   4:  46% | abe: 8.601 | eve: 9.789 | bob: 8.520Epoch   4:  47% | abe: 8.601 | eve: 9.788 | bob: 8.520Epoch   4:  47% | abe: 8.600 | eve: 9.787 | bob: 8.519Epoch   4:  48% | abe: 8.599 | eve: 9.787 | bob: 8.518Epoch   4:  49% | abe: 8.599 | eve: 9.787 | bob: 8.518Epoch   4:  50% | abe: 8.598 | eve: 9.787 | bob: 8.517Epoch   4:  50% | abe: 8.598 | eve: 9.787 | bob: 8.517Epoch   4:  51% | abe: 8.598 | eve: 9.787 | bob: 8.517Epoch   4:  52% | abe: 8.598 | eve: 9.787 | bob: 8.517Epoch   4:  52% | abe: 8.598 | eve: 9.786 | bob: 8.517Epoch   4:  53% | abe: 8.597 | eve: 9.787 | bob: 8.516Epoch   4:  54% | abe: 8.598 | eve: 9.787 | bob: 8.517Epoch   4:  54% | abe: 8.597 | eve: 9.787 | bob: 8.516Epoch   4:  55% | abe: 8.597 | eve: 9.787 | bob: 8.516Epoch   4:  56% | abe: 8.597 | eve: 9.787 | bob: 8.516Epoch   4:  56% | abe: 8.597 | eve: 9.787 | bob: 8.516Epoch   4:  57% | abe: 8.596 | eve: 9.787 | bob: 8.515Epoch   4:  58% | abe: 8.596 | eve: 9.786 | bob: 8.515Epoch   4:  58% | abe: 8.595 | eve: 9.785 | bob: 8.514Epoch   4:  59% | abe: 8.595 | eve: 9.785 | bob: 8.514Epoch   4:  60% | abe: 8.594 | eve: 9.785 | bob: 8.513Epoch   4:  60% | abe: 8.593 | eve: 9.785 | bob: 8.512Epoch   4:  61% | abe: 8.593 | eve: 9.785 | bob: 8.511Epoch   4:  62% | abe: 8.592 | eve: 9.785 | bob: 8.511Epoch   4:  63% | abe: 8.592 | eve: 9.785 | bob: 8.511Epoch   4:  63% | abe: 8.592 | eve: 9.784 | bob: 8.510Epoch   4:  64% | abe: 8.592 | eve: 9.783 | bob: 8.511Epoch   4:  65% | abe: 8.592 | eve: 9.783 | bob: 8.510Epoch   4:  65% | abe: 8.592 | eve: 9.783 | bob: 8.510Epoch   4:  66% | abe: 8.590 | eve: 9.784 | bob: 8.509Epoch   4:  67% | abe: 8.590 | eve: 9.782 | bob: 8.509Epoch   4:  67% | abe: 8.590 | eve: 9.783 | bob: 8.509Epoch   4:  68% | abe: 8.589 | eve: 9.782 | bob: 8.508Epoch   4:  69% | abe: 8.589 | eve: 9.781 | bob: 8.508Epoch   4:  69% | abe: 8.589 | eve: 9.781 | bob: 8.508Epoch   4:  70% | abe: 8.588 | eve: 9.781 | bob: 8.507Epoch   4:  71% | abe: 8.588 | eve: 9.780 | bob: 8.507Epoch   4:  71% | abe: 8.587 | eve: 9.780 | bob: 8.506Epoch   4:  72% | abe: 8.588 | eve: 9.779 | bob: 8.507Epoch   4:  73% | abe: 8.587 | eve: 9.779 | bob: 8.506Epoch   4:  73% | abe: 8.587 | eve: 9.779 | bob: 8.506Epoch   4:  74% | abe: 8.587 | eve: 9.778 | bob: 8.506Epoch   4:  75% | abe: 8.587 | eve: 9.777 | bob: 8.506Epoch   4:  76% | abe: 8.586 | eve: 9.777 | bob: 8.506Epoch   4:  76% | abe: 8.586 | eve: 9.777 | bob: 8.505Epoch   4:  77% | abe: 8.586 | eve: 9.776 | bob: 8.505Epoch   4:  78% | abe: 8.586 | eve: 9.777 | bob: 8.505Epoch   4:  78% | abe: 8.585 | eve: 9.776 | bob: 8.504Epoch   4:  79% | abe: 8.585 | eve: 9.776 | bob: 8.504Epoch   4:  80% | abe: 8.585 | eve: 9.775 | bob: 8.504Epoch   4:  80% | abe: 8.584 | eve: 9.775 | bob: 8.504Epoch   4:  81% | abe: 8.584 | eve: 9.775 | bob: 8.503Epoch   4:  82% | abe: 8.584 | eve: 9.776 | bob: 8.503Epoch   4:  82% | abe: 8.583 | eve: 9.776 | bob: 8.502Epoch   4:  83% | abe: 8.582 | eve: 9.776 | bob: 8.501Epoch   4:  84% | abe: 8.581 | eve: 9.776 | bob: 8.501Epoch   4:  84% | abe: 8.581 | eve: 9.776 | bob: 8.500Epoch   4:  85% | abe: 8.581 | eve: 9.776 | bob: 8.500Epoch   4:  86% | abe: 8.581 | eve: 9.775 | bob: 8.500Epoch   4:  86% | abe: 8.580 | eve: 9.775 | bob: 8.499Epoch   4:  87% | abe: 8.580 | eve: 9.775 | bob: 8.499Epoch   4:  88% | abe: 8.579 | eve: 9.775 | bob: 8.498Epoch   4:  89% | abe: 8.578 | eve: 9.775 | bob: 8.498Epoch   4:  89% | abe: 8.578 | eve: 9.774 | bob: 8.497Epoch   4:  90% | abe: 8.578 | eve: 9.774 | bob: 8.497Epoch   4:  91% | abe: 8.577 | eve: 9.774 | bob: 8.497Epoch   4:  91% | abe: 8.577 | eve: 9.774 | bob: 8.496Epoch   4:  92% | abe: 8.576 | eve: 9.774 | bob: 8.496Epoch   4:  93% | abe: 8.576 | eve: 9.775 | bob: 8.495Epoch   4:  93% | abe: 8.576 | eve: 9.775 | bob: 8.495Epoch   4:  94% | abe: 8.575 | eve: 9.774 | bob: 8.495Epoch   4:  95% | abe: 8.575 | eve: 9.775 | bob: 8.495Epoch   4:  95% | abe: 8.575 | eve: 9.774 | bob: 8.494Epoch   4:  96% | abe: 8.574 | eve: 9.775 | bob: 8.493Epoch   4:  97% | abe: 8.574 | eve: 9.775 | bob: 8.493Epoch   4:  97% | abe: 8.573 | eve: 9.774 | bob: 8.492Epoch   4:  98% | abe: 8.572 | eve: 9.775 | bob: 8.492Epoch   4:  99% | abe: 8.572 | eve: 9.774 | bob: 8.491
New best Bob loss 8.491360861934046 at epoch 4
Epoch   5:   0% | abe: 8.586 | eve: 9.691 | bob: 8.510Epoch   5:   0% | abe: 8.547 | eve: 9.705 | bob: 8.470Epoch   5:   1% | abe: 8.533 | eve: 9.750 | bob: 8.455Epoch   5:   2% | abe: 8.540 | eve: 9.751 | bob: 8.462Epoch   5:   2% | abe: 8.539 | eve: 9.751 | bob: 8.462Epoch   5:   3% | abe: 8.536 | eve: 9.759 | bob: 8.459Epoch   5:   4% | abe: 8.531 | eve: 9.762 | bob: 8.454Epoch   5:   4% | abe: 8.532 | eve: 9.765 | bob: 8.454Epoch   5:   5% | abe: 8.524 | eve: 9.761 | bob: 8.447Epoch   5:   6% | abe: 8.517 | eve: 9.756 | bob: 8.439Epoch   5:   6% | abe: 8.508 | eve: 9.755 | bob: 8.429Epoch   5:   7% | abe: 8.506 | eve: 9.758 | bob: 8.427Epoch   5:   8% | abe: 8.505 | eve: 9.759 | bob: 8.427Epoch   5:   8% | abe: 8.505 | eve: 9.758 | bob: 8.427Epoch   5:   9% | abe: 8.507 | eve: 9.755 | bob: 8.428Epoch   5:  10% | abe: 8.504 | eve: 9.751 | bob: 8.426Epoch   5:  10% | abe: 8.505 | eve: 9.750 | bob: 8.427Epoch   5:  11% | abe: 8.504 | eve: 9.749 | bob: 8.426Epoch   5:  12% | abe: 8.504 | eve: 9.755 | bob: 8.426Epoch   5:  13% | abe: 8.503 | eve: 9.757 | bob: 8.426Epoch   5:  13% | abe: 8.500 | eve: 9.762 | bob: 8.421Epoch   5:  14% | abe: 8.501 | eve: 9.761 | bob: 8.422Epoch   5:  15% | abe: 8.501 | eve: 9.758 | bob: 8.423Epoch   5:  15% | abe: 8.500 | eve: 9.757 | bob: 8.422Epoch   5:  16% | abe: 8.499 | eve: 9.758 | bob: 8.420Epoch   5:  17% | abe: 8.498 | eve: 9.758 | bob: 8.420Epoch   5:  17% | abe: 8.499 | eve: 9.759 | bob: 8.421Epoch   5:  18% | abe: 8.501 | eve: 9.760 | bob: 8.423Epoch   5:  19% | abe: 8.499 | eve: 9.758 | bob: 8.421Epoch   5:  19% | abe: 8.498 | eve: 9.758 | bob: 8.420Epoch   5:  20% | abe: 8.498 | eve: 9.754 | bob: 8.420Epoch   5:  21% | abe: 8.497 | eve: 9.753 | bob: 8.419Epoch   5:  21% | abe: 8.496 | eve: 9.751 | bob: 8.419Epoch   5:  22% | abe: 8.495 | eve: 9.752 | bob: 8.418Epoch   5:  23% | abe: 8.495 | eve: 9.751 | bob: 8.418Epoch   5:  23% | abe: 8.495 | eve: 9.752 | bob: 8.417Epoch   5:  24% | abe: 8.495 | eve: 9.749 | bob: 8.417Epoch   5:  25% | abe: 8.493 | eve: 9.749 | bob: 8.416Epoch   5:  26% | abe: 8.492 | eve: 9.747 | bob: 8.415Epoch   5:  26% | abe: 8.490 | eve: 9.747 | bob: 8.413Epoch   5:  27% | abe: 8.492 | eve: 9.745 | bob: 8.414Epoch   5:  28% | abe: 8.491 | eve: 9.745 | bob: 8.414Epoch   5:  28% | abe: 8.491 | eve: 9.745 | bob: 8.414Epoch   5:  29% | abe: 8.490 | eve: 9.746 | bob: 8.412Epoch   5:  30% | abe: 8.489 | eve: 9.747 | bob: 8.412Epoch   5:  30% | abe: 8.489 | eve: 9.747 | bob: 8.412Epoch   5:  31% | abe: 8.489 | eve: 9.746 | bob: 8.412Epoch   5:  32% | abe: 8.489 | eve: 9.747 | bob: 8.411Epoch   5:  32% | abe: 8.489 | eve: 9.746 | bob: 8.411Epoch   5:  33% | abe: 8.488 | eve: 9.748 | bob: 8.411Epoch   5:  34% | abe: 8.487 | eve: 9.749 | bob: 8.409Epoch   5:  34% | abe: 8.487 | eve: 9.750 | bob: 8.409Epoch   5:  35% | abe: 8.486 | eve: 9.748 | bob: 8.409Epoch   5:  36% | abe: 8.486 | eve: 9.748 | bob: 8.409Epoch   5:  36% | abe: 8.487 | eve: 9.749 | bob: 8.409Epoch   5:  37% | abe: 8.486 | eve: 9.750 | bob: 8.409Epoch   5:  38% | abe: 8.486 | eve: 9.751 | bob: 8.409Epoch   5:  39% | abe: 8.486 | eve: 9.751 | bob: 8.408Epoch   5:  39% | abe: 8.485 | eve: 9.752 | bob: 8.408Epoch   5:  40% | abe: 8.484 | eve: 9.752 | bob: 8.407Epoch   5:  41% | abe: 8.484 | eve: 9.753 | bob: 8.406Epoch   5:  41% | abe: 8.483 | eve: 9.753 | bob: 8.405Epoch   5:  42% | abe: 8.482 | eve: 9.754 | bob: 8.405Epoch   5:  43% | abe: 8.482 | eve: 9.754 | bob: 8.405Epoch   5:  43% | abe: 8.482 | eve: 9.753 | bob: 8.405Epoch   5:  44% | abe: 8.482 | eve: 9.753 | bob: 8.404Epoch   5:  45% | abe: 8.480 | eve: 9.754 | bob: 8.403Epoch   5:  45% | abe: 8.480 | eve: 9.753 | bob: 8.403Epoch   5:  46% | abe: 8.479 | eve: 9.755 | bob: 8.402Epoch   5:  47% | abe: 8.478 | eve: 9.756 | bob: 8.401Epoch   5:  47% | abe: 8.478 | eve: 9.756 | bob: 8.401Epoch   5:  48% | abe: 8.478 | eve: 9.757 | bob: 8.400Epoch   5:  49% | abe: 8.477 | eve: 9.756 | bob: 8.400Epoch   5:  50% | abe: 8.477 | eve: 9.755 | bob: 8.400Epoch   5:  50% | abe: 8.477 | eve: 9.756 | bob: 8.400Epoch   5:  51% | abe: 8.476 | eve: 9.756 | bob: 8.399Epoch   5:  52% | abe: 8.475 | eve: 9.756 | bob: 8.398Epoch   5:  52% | abe: 8.474 | eve: 9.755 | bob: 8.397Epoch   5:  53% | abe: 8.474 | eve: 9.756 | bob: 8.397Epoch   5:  54% | abe: 8.474 | eve: 9.755 | bob: 8.397Epoch   5:  54% | abe: 8.473 | eve: 9.754 | bob: 8.396Epoch   5:  55% | abe: 8.473 | eve: 9.754 | bob: 8.396Epoch   5:  56% | abe: 8.472 | eve: 9.754 | bob: 8.395Epoch   5:  56% | abe: 8.472 | eve: 9.754 | bob: 8.395Epoch   5:  57% | abe: 8.471 | eve: 9.754 | bob: 8.394Epoch   5:  58% | abe: 8.471 | eve: 9.754 | bob: 8.394Epoch   5:  58% | abe: 8.471 | eve: 9.753 | bob: 8.395Epoch   5:  59% | abe: 8.471 | eve: 9.752 | bob: 8.394Epoch   5:  60% | abe: 8.470 | eve: 9.752 | bob: 8.393Epoch   5:  60% | abe: 8.469 | eve: 9.751 | bob: 8.393Epoch   5:  61% | abe: 8.469 | eve: 9.751 | bob: 8.392Epoch   5:  62% | abe: 8.468 | eve: 9.751 | bob: 8.391Epoch   5:  63% | abe: 8.468 | eve: 9.751 | bob: 8.391Epoch   5:  63% | abe: 8.468 | eve: 9.751 | bob: 8.391Epoch   5:  64% | abe: 8.468 | eve: 9.750 | bob: 8.391Epoch   5:  65% | abe: 8.467 | eve: 9.750 | bob: 8.391Epoch   5:  65% | abe: 8.467 | eve: 9.750 | bob: 8.391Epoch   5:  66% | abe: 8.467 | eve: 9.750 | bob: 8.390Epoch   5:  67% | abe: 8.467 | eve: 9.750 | bob: 8.390Epoch   5:  67% | abe: 8.466 | eve: 9.751 | bob: 8.389Epoch   5:  68% | abe: 8.466 | eve: 9.750 | bob: 8.389Epoch   5:  69% | abe: 8.465 | eve: 9.751 | bob: 8.388Epoch   5:  69% | abe: 8.465 | eve: 9.751 | bob: 8.388Epoch   5:  70% | abe: 8.464 | eve: 9.751 | bob: 8.387Epoch   5:  71% | abe: 8.463 | eve: 9.750 | bob: 8.387Epoch   5:  71% | abe: 8.463 | eve: 9.750 | bob: 8.386Epoch   5:  72% | abe: 8.463 | eve: 9.749 | bob: 8.386Epoch   5:  73% | abe: 8.462 | eve: 9.750 | bob: 8.385Epoch   5:  73% | abe: 8.461 | eve: 9.750 | bob: 8.384Epoch   5:  74% | abe: 8.460 | eve: 9.749 | bob: 8.384Epoch   5:  75% | abe: 8.460 | eve: 9.749 | bob: 8.383Epoch   5:  76% | abe: 8.460 | eve: 9.748 | bob: 8.383Epoch   5:  76% | abe: 8.459 | eve: 9.748 | bob: 8.382Epoch   5:  77% | abe: 8.458 | eve: 9.748 | bob: 8.382Epoch   5:  78% | abe: 8.458 | eve: 9.748 | bob: 8.381Epoch   5:  78% | abe: 8.457 | eve: 9.749 | bob: 8.380Epoch   5:  79% | abe: 8.457 | eve: 9.749 | bob: 8.380Epoch   5:  80% | abe: 8.456 | eve: 9.748 | bob: 8.379Epoch   5:  80% | abe: 8.455 | eve: 9.748 | bob: 8.379Epoch   5:  81% | abe: 8.455 | eve: 9.747 | bob: 8.378Epoch   5:  82% | abe: 8.454 | eve: 9.748 | bob: 8.377Epoch   5:  82% | abe: 8.454 | eve: 9.748 | bob: 8.377Epoch   5:  83% | abe: 8.453 | eve: 9.747 | bob: 8.376Epoch   5:  84% | abe: 8.452 | eve: 9.747 | bob: 8.375Epoch   5:  84% | abe: 8.452 | eve: 9.746 | bob: 8.375Epoch   5:  85% | abe: 8.451 | eve: 9.747 | bob: 8.374Epoch   5:  86% | abe: 8.450 | eve: 9.746 | bob: 8.373Epoch   5:  86% | abe: 8.449 | eve: 9.745 | bob: 8.372Epoch   5:  87% | abe: 8.449 | eve: 9.745 | bob: 8.372Epoch   5:  88% | abe: 8.448 | eve: 9.745 | bob: 8.371Epoch   5:  89% | abe: 8.447 | eve: 9.745 | bob: 8.370Epoch   5:  89% | abe: 8.447 | eve: 9.746 | bob: 8.370Epoch   5:  90% | abe: 8.446 | eve: 9.745 | bob: 8.369Epoch   5:  91% | abe: 8.446 | eve: 9.746 | bob: 8.369Epoch   5:  91% | abe: 8.445 | eve: 9.745 | bob: 8.368Epoch   5:  92% | abe: 8.445 | eve: 9.745 | bob: 8.368Epoch   5:  93% | abe: 8.444 | eve: 9.745 | bob: 8.367Epoch   5:  93% | abe: 8.444 | eve: 9.745 | bob: 8.367Epoch   5:  94% | abe: 8.443 | eve: 9.745 | bob: 8.366Epoch   5:  95% | abe: 8.443 | eve: 9.745 | bob: 8.366Epoch   5:  95% | abe: 8.442 | eve: 9.745 | bob: 8.365Epoch   5:  96% | abe: 8.442 | eve: 9.745 | bob: 8.365Epoch   5:  97% | abe: 8.441 | eve: 9.745 | bob: 8.364Epoch   5:  97% | abe: 8.440 | eve: 9.745 | bob: 8.364Epoch   5:  98% | abe: 8.440 | eve: 9.745 | bob: 8.363Epoch   5:  99% | abe: 8.440 | eve: 9.744 | bob: 8.363
New best Bob loss 8.362741894861902 at epoch 5
Epoch   6:   0% | abe: 8.384 | eve: 9.736 | bob: 8.306Epoch   6:   0% | abe: 8.364 | eve: 9.761 | bob: 8.288Epoch   6:   1% | abe: 8.370 | eve: 9.762 | bob: 8.294Epoch   6:   2% | abe: 8.369 | eve: 9.750 | bob: 8.294Epoch   6:   2% | abe: 8.360 | eve: 9.749 | bob: 8.283Epoch   6:   3% | abe: 8.371 | eve: 9.738 | bob: 8.294Epoch   6:   4% | abe: 8.364 | eve: 9.734 | bob: 8.288Epoch   6:   4% | abe: 8.371 | eve: 9.729 | bob: 8.295Epoch   6:   5% | abe: 8.368 | eve: 9.723 | bob: 8.292Epoch   6:   6% | abe: 8.372 | eve: 9.725 | bob: 8.296Epoch   6:   6% | abe: 8.368 | eve: 9.728 | bob: 8.292Epoch   6:   7% | abe: 8.367 | eve: 9.731 | bob: 8.290Epoch   6:   8% | abe: 8.367 | eve: 9.734 | bob: 8.291Epoch   6:   8% | abe: 8.366 | eve: 9.736 | bob: 8.290Epoch   6:   9% | abe: 8.367 | eve: 9.738 | bob: 8.291Epoch   6:  10% | abe: 8.364 | eve: 9.741 | bob: 8.288Epoch   6:  10% | abe: 8.362 | eve: 9.738 | bob: 8.286Epoch   6:  11% | abe: 8.362 | eve: 9.740 | bob: 8.286Epoch   6:  12% | abe: 8.362 | eve: 9.743 | bob: 8.286Epoch   6:  13% | abe: 8.360 | eve: 9.742 | bob: 8.284Epoch   6:  13% | abe: 8.358 | eve: 9.742 | bob: 8.282Epoch   6:  14% | abe: 8.360 | eve: 9.745 | bob: 8.284Epoch   6:  15% | abe: 8.360 | eve: 9.746 | bob: 8.284Epoch   6:  15% | abe: 8.361 | eve: 9.742 | bob: 8.285Epoch   6:  16% | abe: 8.358 | eve: 9.743 | bob: 8.282Epoch   6:  17% | abe: 8.357 | eve: 9.742 | bob: 8.281Epoch   6:  17% | abe: 8.356 | eve: 9.742 | bob: 8.280Epoch   6:  18% | abe: 8.354 | eve: 9.740 | bob: 8.278Epoch   6:  19% | abe: 8.354 | eve: 9.740 | bob: 8.278Epoch   6:  19% | abe: 8.353 | eve: 9.738 | bob: 8.278Epoch   6:  20% | abe: 8.351 | eve: 9.738 | bob: 8.275Epoch   6:  21% | abe: 8.351 | eve: 9.737 | bob: 8.275Epoch   6:  21% | abe: 8.350 | eve: 9.739 | bob: 8.274Epoch   6:  22% | abe: 8.350 | eve: 9.738 | bob: 8.274Epoch   6:  23% | abe: 8.349 | eve: 9.736 | bob: 8.274Epoch   6:  23% | abe: 8.348 | eve: 9.736 | bob: 8.272Epoch   6:  24% | abe: 8.347 | eve: 9.736 | bob: 8.271Epoch   6:  25% | abe: 8.347 | eve: 9.734 | bob: 8.271Epoch   6:  26% | abe: 8.346 | eve: 9.734 | bob: 8.270Epoch   6:  26% | abe: 8.345 | eve: 9.736 | bob: 8.269Epoch   6:  27% | abe: 8.343 | eve: 9.734 | bob: 8.268Epoch   6:  28% | abe: 8.344 | eve: 9.736 | bob: 8.268Epoch   6:  28% | abe: 8.344 | eve: 9.737 | bob: 8.268Epoch   6:  29% | abe: 8.344 | eve: 9.737 | bob: 8.268Epoch   6:  30% | abe: 8.343 | eve: 9.737 | bob: 8.268Epoch   6:  30% | abe: 8.343 | eve: 9.734 | bob: 8.268Epoch   6:  31% | abe: 8.344 | eve: 9.735 | bob: 8.268Epoch   6:  32% | abe: 8.343 | eve: 9.734 | bob: 8.267Epoch   6:  32% | abe: 8.342 | eve: 9.736 | bob: 8.266Epoch   6:  33% | abe: 8.341 | eve: 9.736 | bob: 8.266Epoch   6:  34% | abe: 8.340 | eve: 9.735 | bob: 8.264Epoch   6:  34% | abe: 8.339 | eve: 9.735 | bob: 8.263Epoch   6:  35% | abe: 8.338 | eve: 9.735 | bob: 8.262Epoch   6:  36% | abe: 8.337 | eve: 9.734 | bob: 8.262Epoch   6:  36% | abe: 8.337 | eve: 9.733 | bob: 8.262Epoch   6:  37% | abe: 8.336 | eve: 9.733 | bob: 8.260Epoch   6:  38% | abe: 8.336 | eve: 9.733 | bob: 8.260Epoch   6:  39% | abe: 8.336 | eve: 9.733 | bob: 8.260Epoch   6:  39% | abe: 8.335 | eve: 9.732 | bob: 8.260Epoch   6:  40% | abe: 8.334 | eve: 9.733 | bob: 8.258Epoch   6:  41% | abe: 8.333 | eve: 9.733 | bob: 8.258Epoch   6:  41% | abe: 8.333 | eve: 9.733 | bob: 8.257Epoch   6:  42% | abe: 8.332 | eve: 9.735 | bob: 8.256Epoch   6:  43% | abe: 8.332 | eve: 9.735 | bob: 8.256Epoch   6:  43% | abe: 8.331 | eve: 9.736 | bob: 8.255Epoch   6:  44% | abe: 8.330 | eve: 9.736 | bob: 8.254Epoch   6:  45% | abe: 8.329 | eve: 9.738 | bob: 8.253Epoch   6:  45% | abe: 8.328 | eve: 9.738 | bob: 8.252Epoch   6:  46% | abe: 8.328 | eve: 9.739 | bob: 8.252Epoch   6:  47% | abe: 8.326 | eve: 9.738 | bob: 8.251Epoch   6:  47% | abe: 8.325 | eve: 9.739 | bob: 8.250Epoch   6:  48% | abe: 8.325 | eve: 9.741 | bob: 8.249Epoch   6:  49% | abe: 8.325 | eve: 9.740 | bob: 8.249Epoch   6:  50% | abe: 8.324 | eve: 9.740 | bob: 8.249Epoch   6:  50% | abe: 8.323 | eve: 9.740 | bob: 8.248Epoch   6:  51% | abe: 8.323 | eve: 9.740 | bob: 8.247Epoch   6:  52% | abe: 8.322 | eve: 9.740 | bob: 8.247Epoch   6:  52% | abe: 8.322 | eve: 9.741 | bob: 8.246Epoch   6:  53% | abe: 8.322 | eve: 9.740 | bob: 8.246Epoch   6:  54% | abe: 8.321 | eve: 9.740 | bob: 8.246Epoch   6:  54% | abe: 8.320 | eve: 9.740 | bob: 8.245Epoch   6:  55% | abe: 8.319 | eve: 9.739 | bob: 8.244Epoch   6:  56% | abe: 8.319 | eve: 9.740 | bob: 8.243Epoch   6:  56% | abe: 8.318 | eve: 9.740 | bob: 8.243Epoch   6:  57% | abe: 8.317 | eve: 9.740 | bob: 8.242Epoch   6:  58% | abe: 8.317 | eve: 9.740 | bob: 8.242Epoch   6:  58% | abe: 8.317 | eve: 9.739 | bob: 8.242Epoch   6:  59% | abe: 8.316 | eve: 9.739 | bob: 8.241Epoch   6:  60% | abe: 8.316 | eve: 9.739 | bob: 8.241Epoch   6:  60% | abe: 8.316 | eve: 9.739 | bob: 8.240Epoch   6:  61% | abe: 8.315 | eve: 9.739 | bob: 8.240Epoch   6:  62% | abe: 8.314 | eve: 9.739 | bob: 8.239Epoch   6:  63% | abe: 8.314 | eve: 9.739 | bob: 8.238Epoch   6:  63% | abe: 8.313 | eve: 9.739 | bob: 8.238Epoch   6:  64% | abe: 8.312 | eve: 9.739 | bob: 8.237Epoch   6:  65% | abe: 8.312 | eve: 9.739 | bob: 8.236Epoch   6:  65% | abe: 8.311 | eve: 9.739 | bob: 8.236Epoch   6:  66% | abe: 8.311 | eve: 9.739 | bob: 8.236Epoch   6:  67% | abe: 8.310 | eve: 9.739 | bob: 8.235Epoch   6:  67% | abe: 8.310 | eve: 9.739 | bob: 8.235Epoch   6:  68% | abe: 8.310 | eve: 9.740 | bob: 8.235Epoch   6:  69% | abe: 8.310 | eve: 9.740 | bob: 8.234Epoch   6:  69% | abe: 8.308 | eve: 9.739 | bob: 8.233Epoch   6:  70% | abe: 8.308 | eve: 9.739 | bob: 8.232Epoch   6:  71% | abe: 8.307 | eve: 9.739 | bob: 8.232Epoch   6:  71% | abe: 8.307 | eve: 9.739 | bob: 8.232Epoch   6:  72% | abe: 8.307 | eve: 9.739 | bob: 8.231Epoch   6:  73% | abe: 8.306 | eve: 9.739 | bob: 8.231Epoch   6:  73% | abe: 8.305 | eve: 9.738 | bob: 8.230Epoch   6:  74% | abe: 8.304 | eve: 9.738 | bob: 8.229Epoch   6:  75% | abe: 8.304 | eve: 9.739 | bob: 8.229Epoch   6:  76% | abe: 8.303 | eve: 9.740 | bob: 8.228Epoch   6:  76% | abe: 8.303 | eve: 9.740 | bob: 8.227Epoch   6:  77% | abe: 8.302 | eve: 9.740 | bob: 8.227Epoch   6:  78% | abe: 8.301 | eve: 9.740 | bob: 8.226Epoch   6:  78% | abe: 8.301 | eve: 9.739 | bob: 8.226Epoch   6:  79% | abe: 8.300 | eve: 9.739 | bob: 8.225Epoch   6:  80% | abe: 8.300 | eve: 9.739 | bob: 8.225Epoch   6:  80% | abe: 8.299 | eve: 9.739 | bob: 8.224Epoch   6:  81% | abe: 8.298 | eve: 9.739 | bob: 8.223Epoch   6:  82% | abe: 8.298 | eve: 9.738 | bob: 8.223Epoch   6:  82% | abe: 8.297 | eve: 9.738 | bob: 8.222Epoch   6:  83% | abe: 8.296 | eve: 9.738 | bob: 8.221Epoch   6:  84% | abe: 8.295 | eve: 9.739 | bob: 8.220Epoch   6:  84% | abe: 8.295 | eve: 9.738 | bob: 8.220Epoch   6:  85% | abe: 8.294 | eve: 9.739 | bob: 8.219Epoch   6:  86% | abe: 8.293 | eve: 9.738 | bob: 8.218Epoch   6:  86% | abe: 8.293 | eve: 9.738 | bob: 8.218Epoch   6:  87% | abe: 8.292 | eve: 9.737 | bob: 8.217Epoch   6:  88% | abe: 8.292 | eve: 9.737 | bob: 8.217Epoch   6:  89% | abe: 8.291 | eve: 9.737 | bob: 8.216Epoch   6:  89% | abe: 8.290 | eve: 9.737 | bob: 8.215Epoch   6:  90% | abe: 8.290 | eve: 9.737 | bob: 8.215Epoch   6:  91% | abe: 8.289 | eve: 9.737 | bob: 8.214Epoch   6:  91% | abe: 8.289 | eve: 9.737 | bob: 8.214Epoch   6:  92% | abe: 8.288 | eve: 9.736 | bob: 8.213Epoch   6:  93% | abe: 8.287 | eve: 9.736 | bob: 8.212Epoch   6:  93% | abe: 8.286 | eve: 9.735 | bob: 8.211Epoch   6:  94% | abe: 8.286 | eve: 9.735 | bob: 8.211Epoch   6:  95% | abe: 8.285 | eve: 9.735 | bob: 8.210Epoch   6:  95% | abe: 8.284 | eve: 9.735 | bob: 8.209Epoch   6:  96% | abe: 8.283 | eve: 9.735 | bob: 8.208Epoch   6:  97% | abe: 8.282 | eve: 9.735 | bob: 8.208Epoch   6:  97% | abe: 8.282 | eve: 9.735 | bob: 8.207Epoch   6:  98% | abe: 8.281 | eve: 9.735 | bob: 8.206Epoch   6:  99% | abe: 8.280 | eve: 9.734 | bob: 8.206
New best Bob loss 8.205623749027998 at epoch 6
Epoch   7:   0% | abe: 8.207 | eve: 9.746 | bob: 8.137Epoch   7:   0% | abe: 8.214 | eve: 9.678 | bob: 8.145Epoch   7:   1% | abe: 8.213 | eve: 9.713 | bob: 8.143Epoch   7:   2% | abe: 8.215 | eve: 9.740 | bob: 8.144Epoch   7:   2% | abe: 8.207 | eve: 9.730 | bob: 8.136Epoch   7:   3% | abe: 8.206 | eve: 9.727 | bob: 8.135Epoch   7:   4% | abe: 8.205 | eve: 9.719 | bob: 8.133Epoch   7:   4% | abe: 8.203 | eve: 9.728 | bob: 8.132Epoch   7:   5% | abe: 8.200 | eve: 9.723 | bob: 8.128Epoch   7:   6% | abe: 8.199 | eve: 9.730 | bob: 8.127Epoch   7:   6% | abe: 8.200 | eve: 9.727 | bob: 8.129Epoch   7:   7% | abe: 8.196 | eve: 9.726 | bob: 8.125Epoch   7:   8% | abe: 8.195 | eve: 9.725 | bob: 8.124Epoch   7:   8% | abe: 8.193 | eve: 9.728 | bob: 8.122Epoch   7:   9% | abe: 8.194 | eve: 9.723 | bob: 8.122Epoch   7:  10% | abe: 8.193 | eve: 9.723 | bob: 8.121Epoch   7:  10% | abe: 8.190 | eve: 9.721 | bob: 8.118Epoch   7:  11% | abe: 8.189 | eve: 9.723 | bob: 8.117Epoch   7:  12% | abe: 8.191 | eve: 9.727 | bob: 8.119Epoch   7:  13% | abe: 8.187 | eve: 9.728 | bob: 8.115Epoch   7:  13% | abe: 8.183 | eve: 9.728 | bob: 8.111Epoch   7:  14% | abe: 8.181 | eve: 9.727 | bob: 8.109Epoch   7:  15% | abe: 8.180 | eve: 9.728 | bob: 8.108Epoch   7:  15% | abe: 8.180 | eve: 9.726 | bob: 8.107Epoch   7:  16% | abe: 8.180 | eve: 9.727 | bob: 8.108Epoch   7:  17% | abe: 8.180 | eve: 9.728 | bob: 8.108Epoch   7:  17% | abe: 8.178 | eve: 9.729 | bob: 8.106Epoch   7:  18% | abe: 8.179 | eve: 9.730 | bob: 8.107Epoch   7:  19% | abe: 8.178 | eve: 9.730 | bob: 8.106Epoch   7:  19% | abe: 8.176 | eve: 9.731 | bob: 8.104Epoch   7:  20% | abe: 8.176 | eve: 9.732 | bob: 8.104Epoch   7:  21% | abe: 8.175 | eve: 9.730 | bob: 8.103Epoch   7:  21% | abe: 8.173 | eve: 9.730 | bob: 8.101Epoch   7:  22% | abe: 8.172 | eve: 9.728 | bob: 8.100Epoch   7:  23% | abe: 8.171 | eve: 9.728 | bob: 8.099Epoch   7:  23% | abe: 8.170 | eve: 9.725 | bob: 8.098Epoch   7:  24% | abe: 8.170 | eve: 9.725 | bob: 8.098Epoch   7:  25% | abe: 8.169 | eve: 9.725 | bob: 8.097Epoch   7:  26% | abe: 8.168 | eve: 9.725 | bob: 8.096Epoch   7:  26% | abe: 8.167 | eve: 9.727 | bob: 8.095Epoch   7:  27% | abe: 8.167 | eve: 9.727 | bob: 8.095Epoch   7:  28% | abe: 8.166 | eve: 9.726 | bob: 8.094Epoch   7:  28% | abe: 8.166 | eve: 9.726 | bob: 8.094Epoch   7:  29% | abe: 8.166 | eve: 9.728 | bob: 8.094Epoch   7:  30% | abe: 8.164 | eve: 9.725 | bob: 8.092Epoch   7:  30% | abe: 8.163 | eve: 9.726 | bob: 8.092Epoch   7:  31% | abe: 8.162 | eve: 9.727 | bob: 8.091Epoch   7:  32% | abe: 8.162 | eve: 9.727 | bob: 8.091Epoch   7:  32% | abe: 8.162 | eve: 9.728 | bob: 8.090Epoch   7:  33% | abe: 8.161 | eve: 9.728 | bob: 8.090Epoch   7:  34% | abe: 8.160 | eve: 9.727 | bob: 8.089Epoch   7:  34% | abe: 8.160 | eve: 9.728 | bob: 8.088Epoch   7:  35% | abe: 8.159 | eve: 9.730 | bob: 8.087Epoch   7:  36% | abe: 8.158 | eve: 9.729 | bob: 8.087Epoch   7:  36% | abe: 8.158 | eve: 9.729 | bob: 8.086Epoch   7:  37% | abe: 8.157 | eve: 9.728 | bob: 8.085Epoch   7:  38% | abe: 8.156 | eve: 9.729 | bob: 8.084Epoch   7:  39% | abe: 8.155 | eve: 9.729 | bob: 8.083Epoch   7:  39% | abe: 8.154 | eve: 9.731 | bob: 8.083Epoch   7:  40% | abe: 8.153 | eve: 9.730 | bob: 8.082Epoch   7:  41% | abe: 8.153 | eve: 9.731 | bob: 8.081Epoch   7:  41% | abe: 8.152 | eve: 9.732 | bob: 8.080Epoch   7:  42% | abe: 8.152 | eve: 9.731 | bob: 8.080Epoch   7:  43% | abe: 8.151 | eve: 9.731 | bob: 8.079Epoch   7:  43% | abe: 8.149 | eve: 9.731 | bob: 8.078Epoch   7:  44% | abe: 8.149 | eve: 9.731 | bob: 8.077Epoch   7:  45% | abe: 8.148 | eve: 9.732 | bob: 8.076Epoch   7:  45% | abe: 8.147 | eve: 9.733 | bob: 8.075Epoch   7:  46% | abe: 8.146 | eve: 9.732 | bob: 8.074Epoch   7:  47% | abe: 8.145 | eve: 9.731 | bob: 8.074Epoch   7:  47% | abe: 8.145 | eve: 9.732 | bob: 8.073Epoch   7:  48% | abe: 8.144 | eve: 9.731 | bob: 8.072Epoch   7:  49% | abe: 8.143 | eve: 9.730 | bob: 8.072Epoch   7:  50% | abe: 8.142 | eve: 9.731 | bob: 8.071Epoch   7:  50% | abe: 8.142 | eve: 9.732 | bob: 8.070Epoch   7:  51% | abe: 8.140 | eve: 9.733 | bob: 8.069Epoch   7:  52% | abe: 8.140 | eve: 9.733 | bob: 8.068Epoch   7:  52% | abe: 8.139 | eve: 9.734 | bob: 8.068Epoch   7:  53% | abe: 8.139 | eve: 9.733 | bob: 8.067Epoch   7:  54% | abe: 8.138 | eve: 9.733 | bob: 8.066Epoch   7:  54% | abe: 8.137 | eve: 9.733 | bob: 8.065Epoch   7:  55% | abe: 8.136 | eve: 9.732 | bob: 8.065Epoch   7:  56% | abe: 8.135 | eve: 9.732 | bob: 8.064Epoch   7:  56% | abe: 8.135 | eve: 9.733 | bob: 8.063Epoch   7:  57% | abe: 8.134 | eve: 9.732 | bob: 8.063Epoch   7:  58% | abe: 8.133 | eve: 9.733 | bob: 8.062Epoch   7:  58% | abe: 8.132 | eve: 9.733 | bob: 8.060Epoch   7:  59% | abe: 8.131 | eve: 9.732 | bob: 8.060Epoch   7:  60% | abe: 8.130 | eve: 9.732 | bob: 8.059Epoch   7:  60% | abe: 8.129 | eve: 9.732 | bob: 8.058Epoch   7:  61% | abe: 8.129 | eve: 9.732 | bob: 8.057Epoch   7:  62% | abe: 8.128 | eve: 9.731 | bob: 8.057Epoch   7:  63% | abe: 8.127 | eve: 9.731 | bob: 8.056Epoch   7:  63% | abe: 8.127 | eve: 9.731 | bob: 8.056Epoch   7:  64% | abe: 8.126 | eve: 9.731 | bob: 8.054Epoch   7:  65% | abe: 8.125 | eve: 9.730 | bob: 8.054Epoch   7:  65% | abe: 8.124 | eve: 9.731 | bob: 8.053Epoch   7:  66% | abe: 8.124 | eve: 9.731 | bob: 8.052Epoch   7:  67% | abe: 8.123 | eve: 9.730 | bob: 8.052Epoch   7:  67% | abe: 8.122 | eve: 9.731 | bob: 8.051Epoch   7:  68% | abe: 8.122 | eve: 9.731 | bob: 8.051Epoch   7:  69% | abe: 8.121 | eve: 9.731 | bob: 8.050Epoch   7:  69% | abe: 8.120 | eve: 9.731 | bob: 8.049Epoch   7:  70% | abe: 8.119 | eve: 9.732 | bob: 8.048Epoch   7:  71% | abe: 8.118 | eve: 9.731 | bob: 8.048Epoch   7:  71% | abe: 8.118 | eve: 9.731 | bob: 8.047Epoch   7:  72% | abe: 8.117 | eve: 9.731 | bob: 8.047Epoch   7:  73% | abe: 8.117 | eve: 9.732 | bob: 8.046Epoch   7:  73% | abe: 8.116 | eve: 9.732 | bob: 8.045Epoch   7:  74% | abe: 8.116 | eve: 9.732 | bob: 8.045Epoch   7:  75% | abe: 8.115 | eve: 9.732 | bob: 8.044Epoch   7:  76% | abe: 8.114 | eve: 9.732 | bob: 8.044Epoch   7:  76% | abe: 8.113 | eve: 9.732 | bob: 8.043Epoch   7:  77% | abe: 8.113 | eve: 9.731 | bob: 8.042Epoch   7:  78% | abe: 8.112 | eve: 9.731 | bob: 8.042Epoch   7:  78% | abe: 8.112 | eve: 9.730 | bob: 8.041Epoch   7:  79% | abe: 8.111 | eve: 9.731 | bob: 8.040Epoch   7:  80% | abe: 8.110 | eve: 9.732 | bob: 8.040Epoch   7:  80% | abe: 8.110 | eve: 9.731 | bob: 8.039Epoch   7:  81% | abe: 8.109 | eve: 9.731 | bob: 8.038Epoch   7:  82% | abe: 8.108 | eve: 9.732 | bob: 8.038Epoch   7:  82% | abe: 8.107 | eve: 9.731 | bob: 8.037Epoch   7:  83% | abe: 8.107 | eve: 9.732 | bob: 8.036Epoch   7:  84% | abe: 8.106 | eve: 9.732 | bob: 8.035Epoch   7:  84% | abe: 8.105 | eve: 9.732 | bob: 8.035Epoch   7:  85% | abe: 8.104 | eve: 9.731 | bob: 8.034Epoch   7:  86% | abe: 8.103 | eve: 9.732 | bob: 8.033Epoch   7:  86% | abe: 8.102 | eve: 9.732 | bob: 8.032Epoch   7:  87% | abe: 8.102 | eve: 9.731 | bob: 8.032Epoch   7:  88% | abe: 8.101 | eve: 9.731 | bob: 8.031Epoch   7:  89% | abe: 8.100 | eve: 9.731 | bob: 8.030Epoch   7:  89% | abe: 8.099 | eve: 9.731 | bob: 8.029Epoch   7:  90% | abe: 8.099 | eve: 9.731 | bob: 8.029Epoch   7:  91% | abe: 8.098 | eve: 9.731 | bob: 8.028Epoch   7:  91% | abe: 8.097 | eve: 9.731 | bob: 8.027Epoch   7:  92% | abe: 8.097 | eve: 9.731 | bob: 8.027Epoch   7:  93% | abe: 8.096 | eve: 9.732 | bob: 8.026Epoch   7:  93% | abe: 8.095 | eve: 9.731 | bob: 8.025Epoch   7:  94% | abe: 8.094 | eve: 9.731 | bob: 8.024Epoch   7:  95% | abe: 8.094 | eve: 9.731 | bob: 8.024Epoch   7:  95% | abe: 8.093 | eve: 9.730 | bob: 8.023Epoch   7:  96% | abe: 8.092 | eve: 9.730 | bob: 8.022Epoch   7:  97% | abe: 8.092 | eve: 9.730 | bob: 8.022Epoch   7:  97% | abe: 8.091 | eve: 9.730 | bob: 8.021Epoch   7:  98% | abe: 8.090 | eve: 9.730 | bob: 8.020Epoch   7:  99% | abe: 8.090 | eve: 9.730 | bob: 8.020
New best Bob loss 8.020060495094581 at epoch 7
Epoch   8:   0% | abe: 7.978 | eve: 9.659 | bob: 7.914Epoch   8:   0% | abe: 7.973 | eve: 9.728 | bob: 7.908Epoch   8:   1% | abe: 7.987 | eve: 9.700 | bob: 7.920Epoch   8:   2% | abe: 7.979 | eve: 9.702 | bob: 7.911Epoch   8:   2% | abe: 7.977 | eve: 9.717 | bob: 7.909Epoch   8:   3% | abe: 7.976 | eve: 9.721 | bob: 7.909Epoch   8:   4% | abe: 7.979 | eve: 9.735 | bob: 7.911Epoch   8:   4% | abe: 7.981 | eve: 9.731 | bob: 7.914Epoch   8:   5% | abe: 7.980 | eve: 9.732 | bob: 7.914Epoch   8:   6% | abe: 7.977 | eve: 9.731 | bob: 7.910Epoch   8:   6% | abe: 7.978 | eve: 9.729 | bob: 7.912Epoch   8:   7% | abe: 7.978 | eve: 9.733 | bob: 7.911Epoch   8:   8% | abe: 7.976 | eve: 9.727 | bob: 7.910Epoch   8:   8% | abe: 7.976 | eve: 9.727 | bob: 7.910Epoch   8:   9% | abe: 7.973 | eve: 9.723 | bob: 7.908Epoch   8:  10% | abe: 7.974 | eve: 9.723 | bob: 7.908Epoch   8:  10% | abe: 7.975 | eve: 9.721 | bob: 7.909Epoch   8:  11% | abe: 7.972 | eve: 9.728 | bob: 7.906Epoch   8:  12% | abe: 7.973 | eve: 9.724 | bob: 7.907Epoch   8:  13% | abe: 7.972 | eve: 9.722 | bob: 7.906Epoch   8:  13% | abe: 7.971 | eve: 9.727 | bob: 7.905Epoch   8:  14% | abe: 7.970 | eve: 9.729 | bob: 7.905Epoch   8:  15% | abe: 7.970 | eve: 9.730 | bob: 7.904Epoch   8:  15% | abe: 7.966 | eve: 9.730 | bob: 7.901Epoch   8:  16% | abe: 7.966 | eve: 9.728 | bob: 7.901Epoch   8:  17% | abe: 7.965 | eve: 9.731 | bob: 7.900Epoch   8:  17% | abe: 7.963 | eve: 9.733 | bob: 7.898Epoch   8:  18% | abe: 7.962 | eve: 9.730 | bob: 7.897Epoch   8:  19% | abe: 7.961 | eve: 9.730 | bob: 7.896Epoch   8:  19% | abe: 7.959 | eve: 9.730 | bob: 7.894Epoch   8:  20% | abe: 7.957 | eve: 9.729 | bob: 7.892Epoch   8:  21% | abe: 7.954 | eve: 9.729 | bob: 7.889Epoch   8:  21% | abe: 7.953 | eve: 9.730 | bob: 7.888Epoch   8:  22% | abe: 7.953 | eve: 9.729 | bob: 7.888Epoch   8:  23% | abe: 7.953 | eve: 9.730 | bob: 7.888Epoch   8:  23% | abe: 7.952 | eve: 9.729 | bob: 7.888Epoch   8:  24% | abe: 7.952 | eve: 9.729 | bob: 7.887Epoch   8:  25% | abe: 7.953 | eve: 9.729 | bob: 7.888Epoch   8:  26% | abe: 7.951 | eve: 9.727 | bob: 7.887Epoch   8:  26% | abe: 7.951 | eve: 9.725 | bob: 7.886Epoch   8:  27% | abe: 7.951 | eve: 9.725 | bob: 7.886Epoch   8:  28% | abe: 7.951 | eve: 9.726 | bob: 7.886Epoch   8:  28% | abe: 7.949 | eve: 9.725 | bob: 7.885Epoch   8:  29% | abe: 7.948 | eve: 9.724 | bob: 7.884Epoch   8:  30% | abe: 7.947 | eve: 9.726 | bob: 7.883Epoch   8:  30% | abe: 7.947 | eve: 9.726 | bob: 7.882Epoch   8:  31% | abe: 7.946 | eve: 9.728 | bob: 7.882Epoch   8:  32% | abe: 7.945 | eve: 9.728 | bob: 7.881Epoch   8:  32% | abe: 7.944 | eve: 9.728 | bob: 7.880Epoch   8:  33% | abe: 7.944 | eve: 9.727 | bob: 7.880Epoch   8:  34% | abe: 7.944 | eve: 9.727 | bob: 7.880Epoch   8:  34% | abe: 7.943 | eve: 9.726 | bob: 7.879Epoch   8:  35% | abe: 7.942 | eve: 9.726 | bob: 7.878Epoch   8:  36% | abe: 7.941 | eve: 9.725 | bob: 7.877Epoch   8:  36% | abe: 7.940 | eve: 9.726 | bob: 7.876Epoch   8:  37% | abe: 7.940 | eve: 9.725 | bob: 7.876Epoch   8:  38% | abe: 7.939 | eve: 9.725 | bob: 7.875Epoch   8:  39% | abe: 7.938 | eve: 9.725 | bob: 7.874Epoch   8:  39% | abe: 7.936 | eve: 9.725 | bob: 7.872Epoch   8:  40% | abe: 7.935 | eve: 9.724 | bob: 7.871Epoch   8:  41% | abe: 7.934 | eve: 9.724 | bob: 7.870Epoch   8:  41% | abe: 7.933 | eve: 9.724 | bob: 7.869Epoch   8:  42% | abe: 7.932 | eve: 9.724 | bob: 7.869Epoch   8:  43% | abe: 7.931 | eve: 9.725 | bob: 7.868Epoch   8:  43% | abe: 7.931 | eve: 9.725 | bob: 7.867Epoch   8:  44% | abe: 7.930 | eve: 9.724 | bob: 7.866Epoch   8:  45% | abe: 7.928 | eve: 9.724 | bob: 7.864Epoch   8:  45% | abe: 7.926 | eve: 9.725 | bob: 7.863Epoch   8:  46% | abe: 7.925 | eve: 9.727 | bob: 7.862Epoch   8:  47% | abe: 7.925 | eve: 9.727 | bob: 7.861Epoch   8:  47% | abe: 7.924 | eve: 9.727 | bob: 7.860Epoch   8:  48% | abe: 7.923 | eve: 9.726 | bob: 7.859Epoch   8:  49% | abe: 7.922 | eve: 9.726 | bob: 7.859Epoch   8:  50% | abe: 7.922 | eve: 9.727 | bob: 7.858Epoch   8:  50% | abe: 7.921 | eve: 9.727 | bob: 7.857Epoch   8:  51% | abe: 7.919 | eve: 9.728 | bob: 7.856Epoch   8:  52% | abe: 7.918 | eve: 9.728 | bob: 7.855Epoch   8:  52% | abe: 7.918 | eve: 9.727 | bob: 7.854Epoch   8:  53% | abe: 7.916 | eve: 9.727 | bob: 7.853Epoch   8:  54% | abe: 7.916 | eve: 9.727 | bob: 7.853Epoch   8:  54% | abe: 7.915 | eve: 9.727 | bob: 7.851Epoch   8:  55% | abe: 7.913 | eve: 9.727 | bob: 7.850Epoch   8:  56% | abe: 7.912 | eve: 9.727 | bob: 7.849Epoch   8:  56% | abe: 7.910 | eve: 9.726 | bob: 7.847Epoch   8:  57% | abe: 7.910 | eve: 9.728 | bob: 7.847Epoch   8:  58% | abe: 7.909 | eve: 9.727 | bob: 7.846Epoch   8:  58% | abe: 7.908 | eve: 9.727 | bob: 7.845Epoch   8:  59% | abe: 7.908 | eve: 9.728 | bob: 7.845Epoch   8:  60% | abe: 7.907 | eve: 9.727 | bob: 7.844Epoch   8:  60% | abe: 7.907 | eve: 9.728 | bob: 7.844Epoch   8:  61% | abe: 7.906 | eve: 9.727 | bob: 7.843Epoch   8:  62% | abe: 7.905 | eve: 9.727 | bob: 7.842Epoch   8:  63% | abe: 7.904 | eve: 9.727 | bob: 7.841Epoch   8:  63% | abe: 7.903 | eve: 9.727 | bob: 7.840Epoch   8:  64% | abe: 7.902 | eve: 9.727 | bob: 7.839Epoch   8:  65% | abe: 7.901 | eve: 9.727 | bob: 7.838Epoch   8:  65% | abe: 7.899 | eve: 9.726 | bob: 7.837Epoch   8:  66% | abe: 7.899 | eve: 9.727 | bob: 7.836Epoch   8:  67% | abe: 7.898 | eve: 9.726 | bob: 7.836Epoch   8:  67% | abe: 7.897 | eve: 9.726 | bob: 7.835Epoch   8:  68% | abe: 7.896 | eve: 9.726 | bob: 7.834Epoch   8:  69% | abe: 7.895 | eve: 9.726 | bob: 7.833Epoch   8:  69% | abe: 7.894 | eve: 9.726 | bob: 7.831Epoch   8:  70% | abe: 7.893 | eve: 9.726 | bob: 7.831Epoch   8:  71% | abe: 7.893 | eve: 9.725 | bob: 7.830Epoch   8:  71% | abe: 7.892 | eve: 9.726 | bob: 7.829Epoch   8:  72% | abe: 7.890 | eve: 9.726 | bob: 7.828Epoch   8:  73% | abe: 7.890 | eve: 9.727 | bob: 7.828Epoch   8:  73% | abe: 7.889 | eve: 9.728 | bob: 7.827Epoch   8:  74% | abe: 7.888 | eve: 9.727 | bob: 7.826Epoch   8:  75% | abe: 7.887 | eve: 9.727 | bob: 7.825Epoch   8:  76% | abe: 7.887 | eve: 9.727 | bob: 7.824Epoch   8:  76% | abe: 7.886 | eve: 9.727 | bob: 7.824Epoch   8:  77% | abe: 7.885 | eve: 9.727 | bob: 7.823Epoch   8:  78% | abe: 7.884 | eve: 9.727 | bob: 7.822Epoch   8:  78% | abe: 7.884 | eve: 9.726 | bob: 7.822Epoch   8:  79% | abe: 7.883 | eve: 9.726 | bob: 7.821Epoch   8:  80% | abe: 7.882 | eve: 9.726 | bob: 7.820Epoch   8:  80% | abe: 7.881 | eve: 9.726 | bob: 7.819Epoch   8:  81% | abe: 7.880 | eve: 9.726 | bob: 7.818Epoch   8:  82% | abe: 7.879 | eve: 9.726 | bob: 7.817Epoch   8:  82% | abe: 7.878 | eve: 9.726 | bob: 7.816Epoch   8:  83% | abe: 7.877 | eve: 9.727 | bob: 7.815Epoch   8:  84% | abe: 7.876 | eve: 9.727 | bob: 7.815Epoch   8:  84% | abe: 7.875 | eve: 9.727 | bob: 7.814Epoch   8:  85% | abe: 7.874 | eve: 9.727 | bob: 7.813Epoch   8:  86% | abe: 7.874 | eve: 9.727 | bob: 7.812Epoch   8:  86% | abe: 7.872 | eve: 9.726 | bob: 7.811Epoch   8:  87% | abe: 7.871 | eve: 9.726 | bob: 7.810Epoch   8:  88% | abe: 7.870 | eve: 9.726 | bob: 7.809Epoch   8:  89% | abe: 7.869 | eve: 9.726 | bob: 7.808Epoch   8:  89% | abe: 7.869 | eve: 9.727 | bob: 7.807Epoch   8:  90% | abe: 7.868 | eve: 9.727 | bob: 7.807Epoch   8:  91% | abe: 7.867 | eve: 9.727 | bob: 7.806Epoch   8:  91% | abe: 7.866 | eve: 9.727 | bob: 7.805Epoch   8:  92% | abe: 7.865 | eve: 9.727 | bob: 7.804Epoch   8:  93% | abe: 7.864 | eve: 9.727 | bob: 7.803Epoch   8:  93% | abe: 7.863 | eve: 9.727 | bob: 7.802Epoch   8:  94% | abe: 7.862 | eve: 9.727 | bob: 7.801Epoch   8:  95% | abe: 7.861 | eve: 9.728 | bob: 7.800Epoch   8:  95% | abe: 7.860 | eve: 9.728 | bob: 7.800Epoch   8:  96% | abe: 7.859 | eve: 9.728 | bob: 7.799Epoch   8:  97% | abe: 7.858 | eve: 9.728 | bob: 7.798Epoch   8:  97% | abe: 7.858 | eve: 9.728 | bob: 7.797Epoch   8:  98% | abe: 7.857 | eve: 9.728 | bob: 7.796Epoch   8:  99% | abe: 7.856 | eve: 9.728 | bob: 7.795
New best Bob loss 7.7952223482043745 at epoch 8
Epoch   9:   0% | abe: 7.741 | eve: 9.728 | bob: 7.692Epoch   9:   0% | abe: 7.721 | eve: 9.707 | bob: 7.669Epoch   9:   1% | abe: 7.707 | eve: 9.720 | bob: 7.656Epoch   9:   2% | abe: 7.707 | eve: 9.730 | bob: 7.658Epoch   9:   2% | abe: 7.703 | eve: 9.741 | bob: 7.652Epoch   9:   3% | abe: 7.704 | eve: 9.732 | bob: 7.654Epoch   9:   4% | abe: 7.714 | eve: 9.736 | bob: 7.663Epoch   9:   4% | abe: 7.713 | eve: 9.740 | bob: 7.662Epoch   9:   5% | abe: 7.711 | eve: 9.734 | bob: 7.662Epoch   9:   6% | abe: 7.712 | eve: 9.732 | bob: 7.662Epoch   9:   6% | abe: 7.714 | eve: 9.723 | bob: 7.665Epoch   9:   7% | abe: 7.710 | eve: 9.730 | bob: 7.660Epoch   9:   8% | abe: 7.708 | eve: 9.736 | bob: 7.659Epoch   9:   8% | abe: 7.708 | eve: 9.737 | bob: 7.659Epoch   9:   9% | abe: 7.709 | eve: 9.736 | bob: 7.660Epoch   9:  10% | abe: 7.705 | eve: 9.733 | bob: 7.656Epoch   9:  10% | abe: 7.702 | eve: 9.731 | bob: 7.653Epoch   9:  11% | abe: 7.700 | eve: 9.729 | bob: 7.651Epoch   9:  12% | abe: 7.699 | eve: 9.730 | bob: 7.650Epoch   9:  13% | abe: 7.697 | eve: 9.726 | bob: 7.648Epoch   9:  13% | abe: 7.697 | eve: 9.725 | bob: 7.648Epoch   9:  14% | abe: 7.694 | eve: 9.726 | bob: 7.645Epoch   9:  15% | abe: 7.694 | eve: 9.721 | bob: 7.645Epoch   9:  15% | abe: 7.692 | eve: 9.724 | bob: 7.644Epoch   9:  16% | abe: 7.691 | eve: 9.721 | bob: 7.642Epoch   9:  17% | abe: 7.690 | eve: 9.719 | bob: 7.641Epoch   9:  17% | abe: 7.687 | eve: 9.719 | bob: 7.638Epoch   9:  18% | abe: 7.686 | eve: 9.717 | bob: 7.637Epoch   9:  19% | abe: 7.685 | eve: 9.717 | bob: 7.637Epoch   9:  19% | abe: 7.684 | eve: 9.716 | bob: 7.636Epoch   9:  20% | abe: 7.683 | eve: 9.716 | bob: 7.635Epoch   9:  21% | abe: 7.682 | eve: 9.717 | bob: 7.635Epoch   9:  21% | abe: 7.682 | eve: 9.718 | bob: 7.635Epoch   9:  22% | abe: 7.682 | eve: 9.718 | bob: 7.634Epoch   9:  23% | abe: 7.681 | eve: 9.720 | bob: 7.633Epoch   9:  23% | abe: 7.680 | eve: 9.719 | bob: 7.633Epoch   9:  24% | abe: 7.680 | eve: 9.719 | bob: 7.633Epoch   9:  25% | abe: 7.679 | eve: 9.718 | bob: 7.632Epoch   9:  26% | abe: 7.677 | eve: 9.717 | bob: 7.631Epoch   9:  26% | abe: 7.676 | eve: 9.719 | bob: 7.629Epoch   9:  27% | abe: 7.674 | eve: 9.720 | bob: 7.628Epoch   9:  28% | abe: 7.674 | eve: 9.721 | bob: 7.628Epoch   9:  28% | abe: 7.673 | eve: 9.721 | bob: 7.627Epoch   9:  29% | abe: 7.672 | eve: 9.721 | bob: 7.626Epoch   9:  30% | abe: 7.671 | eve: 9.721 | bob: 7.625Epoch   9:  30% | abe: 7.669 | eve: 9.719 | bob: 7.624Epoch   9:  31% | abe: 7.668 | eve: 9.718 | bob: 7.623Epoch   9:  32% | abe: 7.667 | eve: 9.718 | bob: 7.621Epoch   9:  32% | abe: 7.665 | eve: 9.718 | bob: 7.620Epoch   9:  33% | abe: 7.665 | eve: 9.716 | bob: 7.620Epoch   9:  34% | abe: 7.664 | eve: 9.718 | bob: 7.619Epoch   9:  34% | abe: 7.663 | eve: 9.716 | bob: 7.618Epoch   9:  35% | abe: 7.662 | eve: 9.717 | bob: 7.617Epoch   9:  36% | abe: 7.661 | eve: 9.716 | bob: 7.616Epoch   9:  36% | abe: 7.659 | eve: 9.717 | bob: 7.615Epoch   9:  37% | abe: 7.658 | eve: 9.717 | bob: 7.614Epoch   9:  38% | abe: 7.658 | eve: 9.717 | bob: 7.613Epoch   9:  39% | abe: 7.657 | eve: 9.718 | bob: 7.612Epoch   9:  39% | abe: 7.655 | eve: 9.718 | bob: 7.611Epoch   9:  40% | abe: 7.654 | eve: 9.718 | bob: 7.610Epoch   9:  41% | abe: 7.653 | eve: 9.718 | bob: 7.609Epoch   9:  41% | abe: 7.652 | eve: 9.718 | bob: 7.608Epoch   9:  42% | abe: 7.651 | eve: 9.719 | bob: 7.608Epoch   9:  43% | abe: 7.650 | eve: 9.719 | bob: 7.607Epoch   9:  43% | abe: 7.649 | eve: 9.720 | bob: 7.606Epoch   9:  44% | abe: 7.648 | eve: 9.720 | bob: 7.605Epoch   9:  45% | abe: 7.647 | eve: 9.720 | bob: 7.605Epoch   9:  45% | abe: 7.646 | eve: 9.719 | bob: 7.604Epoch   9:  46% | abe: 7.645 | eve: 9.719 | bob: 7.603Epoch   9:  47% | abe: 7.643 | eve: 9.720 | bob: 7.602Epoch   9:  47% | abe: 7.642 | eve: 9.721 | bob: 7.601Epoch   9:  48% | abe: 7.641 | eve: 9.720 | bob: 7.600Epoch   9:  49% | abe: 7.639 | eve: 9.720 | bob: 7.598Epoch   9:  50% | abe: 7.638 | eve: 9.719 | bob: 7.597Epoch   9:  50% | abe: 7.637 | eve: 9.719 | bob: 7.596Epoch   9:  51% | abe: 7.635 | eve: 9.719 | bob: 7.595Epoch   9:  52% | abe: 7.634 | eve: 9.719 | bob: 7.594Epoch   9:  52% | abe: 7.632 | eve: 9.719 | bob: 7.593Epoch   9:  53% | abe: 7.631 | eve: 9.718 | bob: 7.592Epoch   9:  54% | abe: 7.630 | eve: 9.718 | bob: 7.591Epoch   9:  54% | abe: 7.629 | eve: 9.719 | bob: 7.590Epoch   9:  55% | abe: 7.627 | eve: 9.719 | bob: 7.588Epoch   9:  56% | abe: 7.626 | eve: 9.719 | bob: 7.587Epoch   9:  56% | abe: 7.625 | eve: 9.719 | bob: 7.586Epoch   9:  57% | abe: 7.623 | eve: 9.718 | bob: 7.585Epoch   9:  58% | abe: 7.621 | eve: 9.718 | bob: 7.584Epoch   9:  58% | abe: 7.620 | eve: 9.718 | bob: 7.583Epoch   9:  59% | abe: 7.619 | eve: 9.718 | bob: 7.582Epoch   9:  60% | abe: 7.618 | eve: 9.719 | bob: 7.581Epoch   9:  60% | abe: 7.617 | eve: 9.719 | bob: 7.580Epoch   9:  61% | abe: 7.615 | eve: 9.718 | bob: 7.579Epoch   9:  62% | abe: 7.614 | eve: 9.717 | bob: 7.578Epoch   9:  63% | abe: 7.613 | eve: 9.717 | bob: 7.577Epoch   9:  63% | abe: 7.612 | eve: 9.716 | bob: 7.576Epoch   9:  64% | abe: 7.610 | eve: 9.716 | bob: 7.575Epoch   9:  65% | abe: 7.609 | eve: 9.716 | bob: 7.574Epoch   9:  65% | abe: 7.608 | eve: 9.716 | bob: 7.573Epoch   9:  66% | abe: 7.607 | eve: 9.715 | bob: 7.572Epoch   9:  67% | abe: 7.606 | eve: 9.716 | bob: 7.572Epoch   9:  67% | abe: 7.605 | eve: 9.716 | bob: 7.571Epoch   9:  68% | abe: 7.604 | eve: 9.717 | bob: 7.570Epoch   9:  69% | abe: 7.603 | eve: 9.716 | bob: 7.569Epoch   9:  69% | abe: 7.602 | eve: 9.717 | bob: 7.569Epoch   9:  70% | abe: 7.600 | eve: 9.716 | bob: 7.567Epoch   9:  71% | abe: 7.599 | eve: 9.717 | bob: 7.566Epoch   9:  71% | abe: 7.598 | eve: 9.716 | bob: 7.566Epoch   9:  72% | abe: 7.597 | eve: 9.715 | bob: 7.565Epoch   9:  73% | abe: 7.595 | eve: 9.716 | bob: 7.563Epoch   9:  73% | abe: 7.594 | eve: 9.716 | bob: 7.563Epoch   9:  74% | abe: 7.592 | eve: 9.717 | bob: 7.561Epoch   9:  75% | abe: 7.591 | eve: 9.717 | bob: 7.561Epoch   9:  76% | abe: 7.590 | eve: 9.717 | bob: 7.560Epoch   9:  76% | abe: 7.588 | eve: 9.717 | bob: 7.559Epoch   9:  77% | abe: 7.587 | eve: 9.717 | bob: 7.558Epoch   9:  78% | abe: 7.586 | eve: 9.717 | bob: 7.556Epoch   9:  78% | abe: 7.584 | eve: 9.717 | bob: 7.555Epoch   9:  79% | abe: 7.582 | eve: 9.717 | bob: 7.553Epoch   9:  80% | abe: 7.580 | eve: 9.717 | bob: 7.552Epoch   9:  80% | abe: 7.579 | eve: 9.717 | bob: 7.551Epoch   9:  81% | abe: 7.578 | eve: 9.716 | bob: 7.550Epoch   9:  82% | abe: 7.576 | eve: 9.717 | bob: 7.549Epoch   9:  82% | abe: 7.575 | eve: 9.716 | bob: 7.548Epoch   9:  83% | abe: 7.574 | eve: 9.717 | bob: 7.547Epoch   9:  84% | abe: 7.572 | eve: 9.717 | bob: 7.547Epoch   9:  84% | abe: 7.571 | eve: 9.717 | bob: 7.546Epoch   9:  85% | abe: 7.570 | eve: 9.717 | bob: 7.545Epoch   9:  86% | abe: 7.568 | eve: 9.717 | bob: 7.543Epoch   9:  86% | abe: 7.567 | eve: 9.717 | bob: 7.542Epoch   9:  87% | abe: 7.565 | eve: 9.717 | bob: 7.541Epoch   9:  88% | abe: 7.564 | eve: 9.717 | bob: 7.540Epoch   9:  89% | abe: 7.562 | eve: 9.718 | bob: 7.539Epoch   9:  89% | abe: 7.561 | eve: 9.718 | bob: 7.538Epoch   9:  90% | abe: 7.559 | eve: 9.718 | bob: 7.537Epoch   9:  91% | abe: 7.558 | eve: 9.719 | bob: 7.536Epoch   9:  91% | abe: 7.556 | eve: 9.719 | bob: 7.534Epoch   9:  92% | abe: 7.555 | eve: 9.718 | bob: 7.533Epoch   9:  93% | abe: 7.553 | eve: 9.718 | bob: 7.532Epoch   9:  93% | abe: 7.552 | eve: 9.718 | bob: 7.531Epoch   9:  94% | abe: 7.550 | eve: 9.718 | bob: 7.530Epoch   9:  95% | abe: 7.548 | eve: 9.718 | bob: 7.528Epoch   9:  95% | abe: 7.546 | eve: 9.718 | bob: 7.527Epoch   9:  96% | abe: 7.545 | eve: 9.718 | bob: 7.526Epoch   9:  97% | abe: 7.543 | eve: 9.718 | bob: 7.525Epoch   9:  97% | abe: 7.541 | eve: 9.718 | bob: 7.523Epoch   9:  98% | abe: 7.540 | eve: 9.718 | bob: 7.522Epoch   9:  99% | abe: 7.538 | eve: 9.718 | bob: 7.521
New best Bob loss 7.5206089692494205 at epoch 9
Epoch  10:   0% | abe: 7.315 | eve: 9.750 | bob: 7.349Epoch  10:   0% | abe: 7.312 | eve: 9.742 | bob: 7.351Epoch  10:   1% | abe: 7.309 | eve: 9.734 | bob: 7.353Epoch  10:   2% | abe: 7.302 | eve: 9.734 | bob: 7.346Epoch  10:   2% | abe: 7.293 | eve: 9.728 | bob: 7.336Epoch  10:   3% | abe: 7.292 | eve: 9.713 | bob: 7.336Epoch  10:   4% | abe: 7.274 | eve: 9.722 | bob: 7.319Epoch  10:   4% | abe: 7.273 | eve: 9.722 | bob: 7.320Epoch  10:   5% | abe: 7.269 | eve: 9.719 | bob: 7.315Epoch  10:   6% | abe: 7.267 | eve: 9.718 | bob: 7.314Epoch  10:   6% | abe: 7.263 | eve: 9.715 | bob: 7.310Epoch  10:   7% | abe: 7.260 | eve: 9.710 | bob: 7.308Epoch  10:   8% | abe: 7.257 | eve: 9.716 | bob: 7.306Epoch  10:   8% | abe: 7.258 | eve: 9.714 | bob: 7.306Epoch  10:   9% | abe: 7.252 | eve: 9.712 | bob: 7.300Epoch  10:  10% | abe: 7.250 | eve: 9.712 | bob: 7.298Epoch  10:  10% | abe: 7.245 | eve: 9.714 | bob: 7.294Epoch  10:  11% | abe: 7.243 | eve: 9.715 | bob: 7.293Epoch  10:  12% | abe: 7.238 | eve: 9.717 | bob: 7.288Epoch  10:  13% | abe: 7.235 | eve: 9.716 | bob: 7.286Epoch  10:  13% | abe: 7.232 | eve: 9.720 | bob: 7.284Epoch  10:  14% | abe: 7.229 | eve: 9.722 | bob: 7.281Epoch  10:  15% | abe: 7.224 | eve: 9.723 | bob: 7.277Epoch  10:  15% | abe: 7.221 | eve: 9.722 | bob: 7.274Epoch  10:  16% | abe: 7.217 | eve: 9.728 | bob: 7.269Epoch  10:  17% | abe: 7.211 | eve: 9.731 | bob: 7.264Epoch  10:  17% | abe: 7.207 | eve: 9.730 | bob: 7.260Epoch  10:  18% | abe: 7.204 | eve: 9.730 | bob: 7.258Epoch  10:  19% | abe: 7.199 | eve: 9.729 | bob: 7.253Epoch  10:  19% | abe: 7.196 | eve: 9.726 | bob: 7.250Epoch  10:  20% | abe: 7.190 | eve: 9.725 | bob: 7.246Epoch  10:  21% | abe: 7.187 | eve: 9.723 | bob: 7.243Epoch  10:  21% | abe: 7.182 | eve: 9.724 | bob: 7.239Epoch  10:  22% | abe: 7.179 | eve: 9.727 | bob: 7.236Epoch  10:  23% | abe: 7.175 | eve: 9.730 | bob: 7.233Epoch  10:  23% | abe: 7.171 | eve: 9.730 | bob: 7.229Epoch  10:  24% | abe: 7.167 | eve: 9.732 | bob: 7.226Epoch  10:  25% | abe: 7.162 | eve: 9.731 | bob: 7.221Epoch  10:  26% | abe: 7.158 | eve: 9.729 | bob: 7.218Epoch  10:  26% | abe: 7.155 | eve: 9.728 | bob: 7.215Epoch  10:  27% | abe: 7.151 | eve: 9.727 | bob: 7.212Epoch  10:  28% | abe: 7.148 | eve: 9.726 | bob: 7.210Epoch  10:  28% | abe: 7.146 | eve: 9.726 | bob: 7.208Epoch  10:  29% | abe: 7.142 | eve: 9.726 | bob: 7.205Epoch  10:  30% | abe: 7.138 | eve: 9.727 | bob: 7.201Epoch  10:  30% | abe: 7.134 | eve: 9.727 | bob: 7.198Epoch  10:  31% | abe: 7.130 | eve: 9.727 | bob: 7.194Epoch  10:  32% | abe: 7.125 | eve: 9.727 | bob: 7.190Epoch  10:  32% | abe: 7.120 | eve: 9.726 | bob: 7.186Epoch  10:  33% | abe: 7.117 | eve: 9.726 | bob: 7.183Epoch  10:  34% | abe: 7.114 | eve: 9.726 | bob: 7.181Epoch  10:  34% | abe: 7.111 | eve: 9.726 | bob: 7.178Epoch  10:  35% | abe: 7.106 | eve: 9.725 | bob: 7.174Epoch  10:  36% | abe: 7.102 | eve: 9.725 | bob: 7.170Epoch  10:  36% | abe: 7.099 | eve: 9.725 | bob: 7.167Epoch  10:  37% | abe: 7.095 | eve: 9.725 | bob: 7.164Epoch  10:  38% | abe: 7.092 | eve: 9.726 | bob: 7.162Epoch  10:  39% | abe: 7.089 | eve: 9.726 | bob: 7.159Epoch  10:  39% | abe: 7.085 | eve: 9.726 | bob: 7.155Epoch  10:  40% | abe: 7.082 | eve: 9.727 | bob: 7.152Epoch  10:  41% | abe: 7.079 | eve: 9.727 | bob: 7.150Epoch  10:  41% | abe: 7.075 | eve: 9.726 | bob: 7.146Epoch  10:  42% | abe: 7.072 | eve: 9.726 | bob: 7.143Epoch  10:  43% | abe: 7.068 | eve: 9.725 | bob: 7.140Epoch  10:  43% | abe: 7.065 | eve: 9.724 | bob: 7.137Epoch  10:  44% | abe: 7.062 | eve: 9.725 | bob: 7.134Epoch  10:  45% | abe: 7.058 | eve: 9.725 | bob: 7.131Epoch  10:  45% | abe: 7.055 | eve: 9.725 | bob: 7.128Epoch  10:  46% | abe: 7.052 | eve: 9.725 | bob: 7.125Epoch  10:  47% | abe: 7.048 | eve: 9.725 | bob: 7.121Epoch  10:  47% | abe: 7.045 | eve: 9.725 | bob: 7.118Epoch  10:  48% | abe: 7.041 | eve: 9.724 | bob: 7.115Epoch  10:  49% | abe: 7.038 | eve: 9.724 | bob: 7.112Epoch  10:  50% | abe: 7.035 | eve: 9.725 | bob: 7.110Epoch  10:  50% | abe: 7.032 | eve: 9.724 | bob: 7.107Epoch  10:  51% | abe: 7.029 | eve: 9.723 | bob: 7.104Epoch  10:  52% | abe: 7.026 | eve: 9.723 | bob: 7.101Epoch  10:  52% | abe: 7.022 | eve: 9.724 | bob: 7.098Epoch  10:  53% | abe: 7.019 | eve: 9.724 | bob: 7.095Epoch  10:  54% | abe: 7.016 | eve: 9.724 | bob: 7.092Epoch  10:  54% | abe: 7.013 | eve: 9.724 | bob: 7.089Epoch  10:  55% | abe: 7.010 | eve: 9.723 | bob: 7.086Epoch  10:  56% | abe: 7.007 | eve: 9.723 | bob: 7.084Epoch  10:  56% | abe: 7.004 | eve: 9.722 | bob: 7.080Epoch  10:  57% | abe: 7.001 | eve: 9.722 | bob: 7.078Epoch  10:  58% | abe: 6.998 | eve: 9.722 | bob: 7.075Epoch  10:  58% | abe: 6.994 | eve: 9.722 | bob: 7.072Epoch  10:  59% | abe: 6.991 | eve: 9.722 | bob: 7.069Epoch  10:  60% | abe: 6.988 | eve: 9.722 | bob: 7.066Epoch  10:  60% | abe: 6.984 | eve: 9.722 | bob: 7.063Epoch  10:  61% | abe: 6.981 | eve: 9.722 | bob: 7.060Epoch  10:  62% | abe: 6.979 | eve: 9.722 | bob: 7.058Epoch  10:  63% | abe: 6.976 | eve: 9.722 | bob: 7.055Epoch  10:  63% | abe: 6.973 | eve: 9.720 | bob: 7.052Epoch  10:  64% | abe: 6.970 | eve: 9.721 | bob: 7.049Epoch  10:  65% | abe: 6.967 | eve: 9.721 | bob: 7.047Epoch  10:  65% | abe: 6.964 | eve: 9.721 | bob: 7.044Epoch  10:  66% | abe: 6.961 | eve: 9.721 | bob: 7.041Epoch  10:  67% | abe: 6.957 | eve: 9.722 | bob: 7.038Epoch  10:  67% | abe: 6.954 | eve: 9.721 | bob: 7.035Epoch  10:  68% | abe: 6.951 | eve: 9.721 | bob: 7.032Epoch  10:  69% | abe: 6.948 | eve: 9.721 | bob: 7.030Epoch  10:  69% | abe: 6.946 | eve: 9.722 | bob: 7.027Epoch  10:  70% | abe: 6.942 | eve: 9.722 | bob: 7.024Epoch  10:  71% | abe: 6.940 | eve: 9.722 | bob: 7.021Epoch  10:  71% | abe: 6.937 | eve: 9.722 | bob: 7.018Epoch  10:  72% | abe: 6.933 | eve: 9.723 | bob: 7.015Epoch  10:  73% | abe: 6.930 | eve: 9.723 | bob: 7.012Epoch  10:  73% | abe: 6.927 | eve: 9.723 | bob: 7.009Epoch  10:  74% | abe: 6.924 | eve: 9.723 | bob: 7.006Epoch  10:  75% | abe: 6.920 | eve: 9.723 | bob: 7.003Epoch  10:  76% | abe: 6.917 | eve: 9.723 | bob: 7.000Epoch  10:  76% | abe: 6.914 | eve: 9.723 | bob: 6.997Epoch  10:  77% | abe: 6.911 | eve: 9.723 | bob: 6.994Epoch  10:  78% | abe: 6.908 | eve: 9.723 | bob: 6.992Epoch  10:  78% | abe: 6.905 | eve: 9.723 | bob: 6.988Epoch  10:  79% | abe: 6.902 | eve: 9.723 | bob: 6.985Epoch  10:  80% | abe: 6.899 | eve: 9.723 | bob: 6.983Epoch  10:  80% | abe: 6.896 | eve: 9.724 | bob: 6.980Epoch  10:  81% | abe: 6.893 | eve: 9.724 | bob: 6.977Epoch  10:  82% | abe: 6.890 | eve: 9.725 | bob: 6.974Epoch  10:  82% | abe: 6.887 | eve: 9.725 | bob: 6.972Epoch  10:  83% | abe: 6.884 | eve: 9.725 | bob: 6.969Epoch  10:  84% | abe: 6.881 | eve: 9.725 | bob: 6.966Epoch  10:  84% | abe: 6.879 | eve: 9.725 | bob: 6.964Epoch  10:  85% | abe: 6.876 | eve: 9.725 | bob: 6.961Epoch  10:  86% | abe: 6.873 | eve: 9.725 | bob: 6.958Epoch  10:  86% | abe: 6.870 | eve: 9.725 | bob: 6.956Epoch  10:  87% | abe: 6.868 | eve: 9.726 | bob: 6.953Epoch  10:  88% | abe: 6.865 | eve: 9.726 | bob: 6.951Epoch  10:  89% | abe: 6.862 | eve: 9.727 | bob: 6.948Epoch  10:  89% | abe: 6.859 | eve: 9.727 | bob: 6.945Epoch  10:  90% | abe: 6.856 | eve: 9.727 | bob: 6.943Epoch  10:  91% | abe: 6.853 | eve: 9.728 | bob: 6.940Epoch  10:  91% | abe: 6.850 | eve: 9.727 | bob: 6.937Epoch  10:  92% | abe: 6.847 | eve: 9.727 | bob: 6.934Epoch  10:  93% | abe: 6.844 | eve: 9.728 | bob: 6.931Epoch  10:  93% | abe: 6.842 | eve: 9.727 | bob: 6.929Epoch  10:  94% | abe: 6.839 | eve: 9.727 | bob: 6.926Epoch  10:  95% | abe: 6.836 | eve: 9.727 | bob: 6.923Epoch  10:  95% | abe: 6.833 | eve: 9.728 | bob: 6.920Epoch  10:  96% | abe: 6.830 | eve: 9.728 | bob: 6.918Epoch  10:  97% | abe: 6.828 | eve: 9.728 | bob: 6.915Epoch  10:  97% | abe: 6.825 | eve: 9.729 | bob: 6.913Epoch  10:  98% | abe: 6.822 | eve: 9.728 | bob: 6.910Epoch  10:  99% | abe: 6.819 | eve: 9.728 | bob: 6.908
New best Bob loss 6.907521123365443 at epoch 10
Epoch  11:   0% | abe: 6.381 | eve: 9.702 | bob: 6.493Epoch  11:   0% | abe: 6.403 | eve: 9.735 | bob: 6.506Epoch  11:   1% | abe: 6.398 | eve: 9.724 | bob: 6.504Epoch  11:   2% | abe: 6.387 | eve: 9.700 | bob: 6.496Epoch  11:   2% | abe: 6.382 | eve: 9.716 | bob: 6.492Epoch  11:   3% | abe: 6.385 | eve: 9.725 | bob: 6.492Epoch  11:   4% | abe: 6.387 | eve: 9.724 | bob: 6.491Epoch  11:   4% | abe: 6.383 | eve: 9.729 | bob: 6.487Epoch  11:   5% | abe: 6.385 | eve: 9.731 | bob: 6.490Epoch  11:   6% | abe: 6.383 | eve: 9.719 | bob: 6.488Epoch  11:   6% | abe: 6.377 | eve: 9.715 | bob: 6.482Epoch  11:   7% | abe: 6.376 | eve: 9.705 | bob: 6.482Epoch  11:   8% | abe: 6.372 | eve: 9.715 | bob: 6.480Epoch  11:   8% | abe: 6.371 | eve: 9.715 | bob: 6.480Epoch  11:   9% | abe: 6.368 | eve: 9.720 | bob: 6.478Epoch  11:  10% | abe: 6.367 | eve: 9.719 | bob: 6.476Epoch  11:  10% | abe: 6.365 | eve: 9.715 | bob: 6.475Epoch  11:  11% | abe: 6.363 | eve: 9.720 | bob: 6.473Epoch  11:  12% | abe: 6.359 | eve: 9.721 | bob: 6.468Epoch  11:  13% | abe: 6.358 | eve: 9.719 | bob: 6.467Epoch  11:  13% | abe: 6.358 | eve: 9.719 | bob: 6.467Epoch  11:  14% | abe: 6.357 | eve: 9.720 | bob: 6.466Epoch  11:  15% | abe: 6.354 | eve: 9.717 | bob: 6.464Epoch  11:  15% | abe: 6.353 | eve: 9.717 | bob: 6.463Epoch  11:  16% | abe: 6.351 | eve: 9.720 | bob: 6.461Epoch  11:  17% | abe: 6.347 | eve: 9.720 | bob: 6.457Epoch  11:  17% | abe: 6.345 | eve: 9.720 | bob: 6.456Epoch  11:  18% | abe: 6.343 | eve: 9.717 | bob: 6.454Epoch  11:  19% | abe: 6.340 | eve: 9.719 | bob: 6.450Epoch  11:  19% | abe: 6.338 | eve: 9.720 | bob: 6.449Epoch  11:  20% | abe: 6.335 | eve: 9.718 | bob: 6.447Epoch  11:  21% | abe: 6.333 | eve: 9.718 | bob: 6.444Epoch  11:  21% | abe: 6.331 | eve: 9.719 | bob: 6.442Epoch  11:  22% | abe: 6.329 | eve: 9.721 | bob: 6.440Epoch  11:  23% | abe: 6.327 | eve: 9.721 | bob: 6.438Epoch  11:  23% | abe: 6.325 | eve: 9.722 | bob: 6.436Epoch  11:  24% | abe: 6.322 | eve: 9.720 | bob: 6.433Epoch  11:  25% | abe: 6.320 | eve: 9.720 | bob: 6.431Epoch  11:  26% | abe: 6.317 | eve: 9.720 | bob: 6.429Epoch  11:  26% | abe: 6.314 | eve: 9.720 | bob: 6.426Epoch  11:  27% | abe: 6.312 | eve: 9.720 | bob: 6.424Epoch  11:  28% | abe: 6.310 | eve: 9.720 | bob: 6.422Epoch  11:  28% | abe: 6.309 | eve: 9.721 | bob: 6.421Epoch  11:  29% | abe: 6.307 | eve: 9.721 | bob: 6.420Epoch  11:  30% | abe: 6.305 | eve: 9.721 | bob: 6.417Epoch  11:  30% | abe: 6.303 | eve: 9.722 | bob: 6.415Epoch  11:  31% | abe: 6.301 | eve: 9.720 | bob: 6.414Epoch  11:  32% | abe: 6.299 | eve: 9.718 | bob: 6.412Epoch  11:  32% | abe: 6.296 | eve: 9.716 | bob: 6.409Epoch  11:  33% | abe: 6.295 | eve: 9.715 | bob: 6.408Epoch  11:  34% | abe: 6.292 | eve: 9.715 | bob: 6.405Epoch  11:  34% | abe: 6.290 | eve: 9.714 | bob: 6.403Epoch  11:  35% | abe: 6.287 | eve: 9.713 | bob: 6.401Epoch  11:  36% | abe: 6.285 | eve: 9.714 | bob: 6.399Epoch  11:  36% | abe: 6.283 | eve: 9.713 | bob: 6.397Epoch  11:  37% | abe: 6.281 | eve: 9.712 | bob: 6.395Epoch  11:  38% | abe: 6.279 | eve: 9.713 | bob: 6.394Epoch  11:  39% | abe: 6.278 | eve: 9.713 | bob: 6.392Epoch  11:  39% | abe: 6.275 | eve: 9.712 | bob: 6.390Epoch  11:  40% | abe: 6.274 | eve: 9.712 | bob: 6.389Epoch  11:  41% | abe: 6.272 | eve: 9.713 | bob: 6.387Epoch  11:  41% | abe: 6.269 | eve: 9.713 | bob: 6.384Epoch  11:  42% | abe: 6.267 | eve: 9.714 | bob: 6.383Epoch  11:  43% | abe: 6.264 | eve: 9.713 | bob: 6.380Epoch  11:  43% | abe: 6.262 | eve: 9.713 | bob: 6.378Epoch  11:  44% | abe: 6.260 | eve: 9.713 | bob: 6.376Epoch  11:  45% | abe: 6.258 | eve: 9.714 | bob: 6.374Epoch  11:  45% | abe: 6.256 | eve: 9.714 | bob: 6.372Epoch  11:  46% | abe: 6.254 | eve: 9.715 | bob: 6.370Epoch  11:  47% | abe: 6.251 | eve: 9.716 | bob: 6.368Epoch  11:  47% | abe: 6.248 | eve: 9.716 | bob: 6.365Epoch  11:  48% | abe: 6.246 | eve: 9.716 | bob: 6.363Epoch  11:  49% | abe: 6.244 | eve: 9.717 | bob: 6.361Epoch  11:  50% | abe: 6.242 | eve: 9.717 | bob: 6.359Epoch  11:  50% | abe: 6.239 | eve: 9.717 | bob: 6.357Epoch  11:  51% | abe: 6.237 | eve: 9.718 | bob: 6.355Epoch  11:  52% | abe: 6.235 | eve: 9.718 | bob: 6.353Epoch  11:  52% | abe: 6.233 | eve: 9.717 | bob: 6.351Epoch  11:  53% | abe: 6.230 | eve: 9.718 | bob: 6.349Epoch  11:  54% | abe: 6.228 | eve: 9.718 | bob: 6.347Epoch  11:  54% | abe: 6.225 | eve: 9.719 | bob: 6.345Epoch  11:  55% | abe: 6.223 | eve: 9.719 | bob: 6.343Epoch  11:  56% | abe: 6.221 | eve: 9.719 | bob: 6.340Epoch  11:  56% | abe: 6.219 | eve: 9.719 | bob: 6.338Epoch  11:  57% | abe: 6.217 | eve: 9.718 | bob: 6.336Epoch  11:  58% | abe: 6.214 | eve: 9.718 | bob: 6.334Epoch  11:  58% | abe: 6.212 | eve: 9.718 | bob: 6.332Epoch  11:  59% | abe: 6.210 | eve: 9.718 | bob: 6.330Epoch  11:  60% | abe: 6.208 | eve: 9.719 | bob: 6.328Epoch  11:  60% | abe: 6.206 | eve: 9.719 | bob: 6.326Epoch  11:  61% | abe: 6.204 | eve: 9.720 | bob: 6.325Epoch  11:  62% | abe: 6.202 | eve: 9.720 | bob: 6.322Epoch  11:  63% | abe: 6.200 | eve: 9.720 | bob: 6.321Epoch  11:  63% | abe: 6.198 | eve: 9.720 | bob: 6.319Epoch  11:  64% | abe: 6.196 | eve: 9.720 | bob: 6.317Epoch  11:  65% | abe: 6.194 | eve: 9.719 | bob: 6.315Epoch  11:  65% | abe: 6.192 | eve: 9.720 | bob: 6.312Epoch  11:  66% | abe: 6.190 | eve: 9.720 | bob: 6.311Epoch  11:  67% | abe: 6.187 | eve: 9.720 | bob: 6.309Epoch  11:  67% | abe: 6.185 | eve: 9.719 | bob: 6.307Epoch  11:  68% | abe: 6.183 | eve: 9.718 | bob: 6.305Epoch  11:  69% | abe: 6.181 | eve: 9.719 | bob: 6.302Epoch  11:  69% | abe: 6.178 | eve: 9.719 | bob: 6.300Epoch  11:  70% | abe: 6.176 | eve: 9.718 | bob: 6.298Epoch  11:  71% | abe: 6.174 | eve: 9.719 | bob: 6.296Epoch  11:  71% | abe: 6.171 | eve: 9.718 | bob: 6.294Epoch  11:  72% | abe: 6.169 | eve: 9.718 | bob: 6.292Epoch  11:  73% | abe: 6.168 | eve: 9.718 | bob: 6.290Epoch  11:  73% | abe: 6.166 | eve: 9.719 | bob: 6.288Epoch  11:  74% | abe: 6.164 | eve: 9.719 | bob: 6.287Epoch  11:  75% | abe: 6.162 | eve: 9.718 | bob: 6.285Epoch  11:  76% | abe: 6.160 | eve: 9.718 | bob: 6.283Epoch  11:  76% | abe: 6.158 | eve: 9.718 | bob: 6.281Epoch  11:  77% | abe: 6.155 | eve: 9.718 | bob: 6.279Epoch  11:  78% | abe: 6.153 | eve: 9.718 | bob: 6.277Epoch  11:  78% | abe: 6.151 | eve: 9.718 | bob: 6.275Epoch  11:  79% | abe: 6.149 | eve: 9.719 | bob: 6.273Epoch  11:  80% | abe: 6.147 | eve: 9.718 | bob: 6.271Epoch  11:  80% | abe: 6.145 | eve: 9.719 | bob: 6.269Epoch  11:  81% | abe: 6.143 | eve: 9.719 | bob: 6.267Epoch  11:  82% | abe: 6.141 | eve: 9.719 | bob: 6.265Epoch  11:  82% | abe: 6.138 | eve: 9.719 | bob: 6.263Epoch  11:  83% | abe: 6.136 | eve: 9.718 | bob: 6.261Epoch  11:  84% | abe: 6.134 | eve: 9.718 | bob: 6.259Epoch  11:  84% | abe: 6.132 | eve: 9.718 | bob: 6.257Epoch  11:  85% | abe: 6.130 | eve: 9.718 | bob: 6.255Epoch  11:  86% | abe: 6.127 | eve: 9.718 | bob: 6.253Epoch  11:  86% | abe: 6.125 | eve: 9.718 | bob: 6.251Epoch  11:  87% | abe: 6.123 | eve: 9.718 | bob: 6.249Epoch  11:  88% | abe: 6.121 | eve: 9.718 | bob: 6.247Epoch  11:  89% | abe: 6.119 | eve: 9.719 | bob: 6.245Epoch  11:  89% | abe: 6.116 | eve: 9.719 | bob: 6.243Epoch  11:  90% | abe: 6.114 | eve: 9.719 | bob: 6.241Epoch  11:  91% | abe: 6.113 | eve: 9.718 | bob: 6.240Epoch  11:  91% | abe: 6.111 | eve: 9.719 | bob: 6.238Epoch  11:  92% | abe: 6.108 | eve: 9.718 | bob: 6.236Epoch  11:  93% | abe: 6.106 | eve: 9.718 | bob: 6.234Epoch  11:  93% | abe: 6.104 | eve: 9.718 | bob: 6.232Epoch  11:  94% | abe: 6.103 | eve: 9.718 | bob: 6.230Epoch  11:  95% | abe: 6.101 | eve: 9.718 | bob: 6.229Epoch  11:  95% | abe: 6.098 | eve: 9.719 | bob: 6.227Epoch  11:  96% | abe: 6.097 | eve: 9.718 | bob: 6.225Epoch  11:  97% | abe: 6.094 | eve: 9.718 | bob: 6.223Epoch  11:  97% | abe: 6.092 | eve: 9.719 | bob: 6.221Epoch  11:  98% | abe: 6.090 | eve: 9.718 | bob: 6.219Epoch  11:  99% | abe: 6.088 | eve: 9.718 | bob: 6.217
New best Bob loss 6.216971485179332 at epoch 11
Epoch  12:   0% | abe: 5.781 | eve: 9.688 | bob: 5.925Epoch  12:   0% | abe: 5.789 | eve: 9.715 | bob: 5.941Epoch  12:   1% | abe: 5.790 | eve: 9.742 | bob: 5.942Epoch  12:   2% | abe: 5.784 | eve: 9.760 | bob: 5.936Epoch  12:   2% | abe: 5.780 | eve: 9.753 | bob: 5.930Epoch  12:   3% | abe: 5.775 | eve: 9.750 | bob: 5.926Epoch  12:   4% | abe: 5.773 | eve: 9.749 | bob: 5.924Epoch  12:   4% | abe: 5.769 | eve: 9.752 | bob: 5.921Epoch  12:   5% | abe: 5.771 | eve: 9.750 | bob: 5.921Epoch  12:   6% | abe: 5.764 | eve: 9.747 | bob: 5.916Epoch  12:   6% | abe: 5.763 | eve: 9.744 | bob: 5.915Epoch  12:   7% | abe: 5.761 | eve: 9.748 | bob: 5.915Epoch  12:   8% | abe: 5.760 | eve: 9.746 | bob: 5.913Epoch  12:   8% | abe: 5.759 | eve: 9.744 | bob: 5.911Epoch  12:   9% | abe: 5.757 | eve: 9.748 | bob: 5.910Epoch  12:  10% | abe: 5.757 | eve: 9.749 | bob: 5.909Epoch  12:  10% | abe: 5.754 | eve: 9.750 | bob: 5.906Epoch  12:  11% | abe: 5.751 | eve: 9.754 | bob: 5.905Epoch  12:  12% | abe: 5.750 | eve: 9.754 | bob: 5.904Epoch  12:  13% | abe: 5.747 | eve: 9.747 | bob: 5.902Epoch  12:  13% | abe: 5.743 | eve: 9.745 | bob: 5.899Epoch  12:  14% | abe: 5.741 | eve: 9.744 | bob: 5.897Epoch  12:  15% | abe: 5.740 | eve: 9.741 | bob: 5.896Epoch  12:  15% | abe: 5.738 | eve: 9.739 | bob: 5.894Epoch  12:  16% | abe: 5.734 | eve: 9.739 | bob: 5.891Epoch  12:  17% | abe: 5.732 | eve: 9.736 | bob: 5.889Epoch  12:  17% | abe: 5.731 | eve: 9.737 | bob: 5.888Epoch  12:  18% | abe: 5.729 | eve: 9.737 | bob: 5.887Epoch  12:  19% | abe: 5.727 | eve: 9.735 | bob: 5.885Epoch  12:  19% | abe: 5.725 | eve: 9.734 | bob: 5.884Epoch  12:  20% | abe: 5.723 | eve: 9.733 | bob: 5.882Epoch  12:  21% | abe: 5.721 | eve: 9.734 | bob: 5.880Epoch  12:  21% | abe: 5.718 | eve: 9.734 | bob: 5.878Epoch  12:  22% | abe: 5.717 | eve: 9.734 | bob: 5.876Epoch  12:  23% | abe: 5.714 | eve: 9.732 | bob: 5.874Epoch  12:  23% | abe: 5.712 | eve: 9.731 | bob: 5.873Epoch  12:  24% | abe: 5.711 | eve: 9.732 | bob: 5.871Epoch  12:  25% | abe: 5.709 | eve: 9.730 | bob: 5.870Epoch  12:  26% | abe: 5.707 | eve: 9.731 | bob: 5.869Epoch  12:  26% | abe: 5.705 | eve: 9.728 | bob: 5.867Epoch  12:  27% | abe: 5.703 | eve: 9.727 | bob: 5.865Epoch  12:  28% | abe: 5.701 | eve: 9.725 | bob: 5.863Epoch  12:  28% | abe: 5.699 | eve: 9.726 | bob: 5.861Epoch  12:  29% | abe: 5.697 | eve: 9.726 | bob: 5.859Epoch  12:  30% | abe: 5.696 | eve: 9.727 | bob: 5.858Epoch  12:  30% | abe: 5.694 | eve: 9.725 | bob: 5.856Epoch  12:  31% | abe: 5.692 | eve: 9.725 | bob: 5.854Epoch  12:  32% | abe: 5.691 | eve: 9.724 | bob: 5.853Epoch  12:  32% | abe: 5.689 | eve: 9.725 | bob: 5.852Epoch  12:  33% | abe: 5.688 | eve: 9.726 | bob: 5.850Epoch  12:  34% | abe: 5.687 | eve: 9.726 | bob: 5.849Epoch  12:  34% | abe: 5.685 | eve: 9.727 | bob: 5.848Epoch  12:  35% | abe: 5.683 | eve: 9.726 | bob: 5.846Epoch  12:  36% | abe: 5.681 | eve: 9.726 | bob: 5.844Epoch  12:  36% | abe: 5.680 | eve: 9.726 | bob: 5.843Epoch  12:  37% | abe: 5.678 | eve: 9.726 | bob: 5.841Epoch  12:  38% | abe: 5.675 | eve: 9.726 | bob: 5.839Epoch  12:  39% | abe: 5.674 | eve: 9.727 | bob: 5.837Epoch  12:  39% | abe: 5.672 | eve: 9.727 | bob: 5.835Epoch  12:  40% | abe: 5.670 | eve: 9.727 | bob: 5.833Epoch  12:  41% | abe: 5.668 | eve: 9.726 | bob: 5.832Epoch  12:  41% | abe: 5.667 | eve: 9.726 | bob: 5.830Epoch  12:  42% | abe: 5.665 | eve: 9.725 | bob: 5.828Epoch  12:  43% | abe: 5.663 | eve: 9.725 | bob: 5.827Epoch  12:  43% | abe: 5.661 | eve: 9.727 | bob: 5.825Epoch  12:  44% | abe: 5.660 | eve: 9.727 | bob: 5.824Epoch  12:  45% | abe: 5.658 | eve: 9.728 | bob: 5.822Epoch  12:  45% | abe: 5.656 | eve: 9.727 | bob: 5.820Epoch  12:  46% | abe: 5.654 | eve: 9.727 | bob: 5.818Epoch  12:  47% | abe: 5.652 | eve: 9.726 | bob: 5.817Epoch  12:  47% | abe: 5.651 | eve: 9.727 | bob: 5.815Epoch  12:  48% | abe: 5.649 | eve: 9.728 | bob: 5.814Epoch  12:  49% | abe: 5.647 | eve: 9.729 | bob: 5.812Epoch  12:  50% | abe: 5.645 | eve: 9.729 | bob: 5.811Epoch  12:  50% | abe: 5.643 | eve: 9.730 | bob: 5.809Epoch  12:  51% | abe: 5.641 | eve: 9.730 | bob: 5.807Epoch  12:  52% | abe: 5.639 | eve: 9.729 | bob: 5.806Epoch  12:  52% | abe: 5.638 | eve: 9.730 | bob: 5.804Epoch  12:  53% | abe: 5.636 | eve: 9.731 | bob: 5.802Epoch  12:  54% | abe: 5.634 | eve: 9.731 | bob: 5.801Epoch  12:  54% | abe: 5.632 | eve: 9.730 | bob: 5.799Epoch  12:  55% | abe: 5.630 | eve: 9.729 | bob: 5.797Epoch  12:  56% | abe: 5.628 | eve: 9.728 | bob: 5.795Epoch  12:  56% | abe: 5.626 | eve: 9.728 | bob: 5.794Epoch  12:  57% | abe: 5.624 | eve: 9.728 | bob: 5.792Epoch  12:  58% | abe: 5.622 | eve: 9.728 | bob: 5.790Epoch  12:  58% | abe: 5.620 | eve: 9.727 | bob: 5.789Epoch  12:  59% | abe: 5.619 | eve: 9.727 | bob: 5.787Epoch  12:  60% | abe: 5.617 | eve: 9.726 | bob: 5.786Epoch  12:  60% | abe: 5.615 | eve: 9.725 | bob: 5.784Epoch  12:  61% | abe: 5.614 | eve: 9.725 | bob: 5.782Epoch  12:  62% | abe: 5.612 | eve: 9.725 | bob: 5.781Epoch  12:  63% | abe: 5.610 | eve: 9.724 | bob: 5.780Epoch  12:  63% | abe: 5.608 | eve: 9.724 | bob: 5.778Epoch  12:  64% | abe: 5.607 | eve: 9.724 | bob: 5.777Epoch  12:  65% | abe: 5.605 | eve: 9.724 | bob: 5.775Epoch  12:  65% | abe: 5.603 | eve: 9.725 | bob: 5.773Epoch  12:  66% | abe: 5.601 | eve: 9.724 | bob: 5.772Epoch  12:  67% | abe: 5.600 | eve: 9.724 | bob: 5.770Epoch  12:  67% | abe: 5.598 | eve: 9.723 | bob: 5.768Epoch  12:  68% | abe: 5.596 | eve: 9.724 | bob: 5.767Epoch  12:  69% | abe: 5.595 | eve: 9.724 | bob: 5.765Epoch  12:  69% | abe: 5.593 | eve: 9.724 | bob: 5.764Epoch  12:  70% | abe: 5.591 | eve: 9.724 | bob: 5.762Epoch  12:  71% | abe: 5.589 | eve: 9.724 | bob: 5.761Epoch  12:  71% | abe: 5.587 | eve: 9.724 | bob: 5.759Epoch  12:  72% | abe: 5.586 | eve: 9.724 | bob: 5.757Epoch  12:  73% | abe: 5.584 | eve: 9.724 | bob: 5.756Epoch  12:  73% | abe: 5.582 | eve: 9.725 | bob: 5.754Epoch  12:  74% | abe: 5.580 | eve: 9.725 | bob: 5.753Epoch  12:  75% | abe: 5.578 | eve: 9.725 | bob: 5.751Epoch  12:  76% | abe: 5.576 | eve: 9.724 | bob: 5.749Epoch  12:  76% | abe: 5.575 | eve: 9.724 | bob: 5.747Epoch  12:  77% | abe: 5.573 | eve: 9.724 | bob: 5.746Epoch  12:  78% | abe: 5.571 | eve: 9.724 | bob: 5.744Epoch  12:  78% | abe: 5.569 | eve: 9.724 | bob: 5.742Epoch  12:  79% | abe: 5.568 | eve: 9.725 | bob: 5.741Epoch  12:  80% | abe: 5.566 | eve: 9.725 | bob: 5.739Epoch  12:  80% | abe: 5.564 | eve: 9.725 | bob: 5.737Epoch  12:  81% | abe: 5.562 | eve: 9.725 | bob: 5.736Epoch  12:  82% | abe: 5.560 | eve: 9.724 | bob: 5.734Epoch  12:  82% | abe: 5.558 | eve: 9.724 | bob: 5.732Epoch  12:  83% | abe: 5.557 | eve: 9.723 | bob: 5.731Epoch  12:  84% | abe: 5.555 | eve: 9.723 | bob: 5.730Epoch  12:  84% | abe: 5.553 | eve: 9.723 | bob: 5.728Epoch  12:  85% | abe: 5.552 | eve: 9.723 | bob: 5.726Epoch  12:  86% | abe: 5.550 | eve: 9.723 | bob: 5.724Epoch  12:  86% | abe: 5.548 | eve: 9.723 | bob: 5.723Epoch  12:  87% | abe: 5.546 | eve: 9.724 | bob: 5.721Epoch  12:  88% | abe: 5.544 | eve: 9.724 | bob: 5.720Epoch  12:  89% | abe: 5.543 | eve: 9.724 | bob: 5.718Epoch  12:  89% | abe: 5.541 | eve: 9.724 | bob: 5.717Epoch  12:  90% | abe: 5.540 | eve: 9.724 | bob: 5.715Epoch  12:  91% | abe: 5.538 | eve: 9.723 | bob: 5.714Epoch  12:  91% | abe: 5.536 | eve: 9.723 | bob: 5.712Epoch  12:  92% | abe: 5.535 | eve: 9.723 | bob: 5.711Epoch  12:  93% | abe: 5.533 | eve: 9.723 | bob: 5.709Epoch  12:  93% | abe: 5.531 | eve: 9.723 | bob: 5.708Epoch  12:  94% | abe: 5.529 | eve: 9.722 | bob: 5.706Epoch  12:  95% | abe: 5.528 | eve: 9.721 | bob: 5.704Epoch  12:  95% | abe: 5.526 | eve: 9.721 | bob: 5.703Epoch  12:  96% | abe: 5.524 | eve: 9.720 | bob: 5.701Epoch  12:  97% | abe: 5.523 | eve: 9.720 | bob: 5.700Epoch  12:  97% | abe: 5.521 | eve: 9.721 | bob: 5.698Epoch  12:  98% | abe: 5.519 | eve: 9.722 | bob: 5.697Epoch  12:  99% | abe: 5.517 | eve: 9.721 | bob: 5.695
New best Bob loss 5.695138568083897 at epoch 12
Epoch  13:   0% | abe: 5.258 | eve: 9.655 | bob: 5.464Epoch  13:   0% | abe: 5.246 | eve: 9.699 | bob: 5.448Epoch  13:   1% | abe: 5.242 | eve: 9.706 | bob: 5.447Epoch  13:   2% | abe: 5.242 | eve: 9.706 | bob: 5.445Epoch  13:   2% | abe: 5.244 | eve: 9.703 | bob: 5.445Epoch  13:   3% | abe: 5.241 | eve: 9.715 | bob: 5.442Epoch  13:   4% | abe: 5.243 | eve: 9.718 | bob: 5.443Epoch  13:   4% | abe: 5.243 | eve: 9.710 | bob: 5.445Epoch  13:   5% | abe: 5.241 | eve: 9.713 | bob: 5.443Epoch  13:   6% | abe: 5.240 | eve: 9.706 | bob: 5.443Epoch  13:   6% | abe: 5.239 | eve: 9.703 | bob: 5.442Epoch  13:   7% | abe: 5.236 | eve: 9.704 | bob: 5.440Epoch  13:   8% | abe: 5.233 | eve: 9.703 | bob: 5.438Epoch  13:   8% | abe: 5.231 | eve: 9.707 | bob: 5.436Epoch  13:   9% | abe: 5.231 | eve: 9.709 | bob: 5.435Epoch  13:  10% | abe: 5.230 | eve: 9.705 | bob: 5.434Epoch  13:  10% | abe: 5.230 | eve: 9.708 | bob: 5.434Epoch  13:  11% | abe: 5.229 | eve: 9.709 | bob: 5.434Epoch  13:  12% | abe: 5.227 | eve: 9.708 | bob: 5.432Epoch  13:  13% | abe: 5.226 | eve: 9.706 | bob: 5.431Epoch  13:  13% | abe: 5.224 | eve: 9.706 | bob: 5.429Epoch  13:  14% | abe: 5.223 | eve: 9.705 | bob: 5.427Epoch  13:  15% | abe: 5.221 | eve: 9.707 | bob: 5.426Epoch  13:  15% | abe: 5.220 | eve: 9.707 | bob: 5.425Epoch  13:  16% | abe: 5.219 | eve: 9.709 | bob: 5.425Epoch  13:  17% | abe: 5.216 | eve: 9.708 | bob: 5.422Epoch  13:  17% | abe: 5.215 | eve: 9.707 | bob: 5.421Epoch  13:  18% | abe: 5.213 | eve: 9.706 | bob: 5.418Epoch  13:  19% | abe: 5.211 | eve: 9.706 | bob: 5.417Epoch  13:  19% | abe: 5.210 | eve: 9.705 | bob: 5.416Epoch  13:  20% | abe: 5.208 | eve: 9.705 | bob: 5.415Epoch  13:  21% | abe: 5.206 | eve: 9.706 | bob: 5.413Epoch  13:  21% | abe: 5.206 | eve: 9.705 | bob: 5.412Epoch  13:  22% | abe: 5.203 | eve: 9.704 | bob: 5.410Epoch  13:  23% | abe: 5.201 | eve: 9.701 | bob: 5.408Epoch  13:  23% | abe: 5.199 | eve: 9.703 | bob: 5.406Epoch  13:  24% | abe: 5.199 | eve: 9.705 | bob: 5.405Epoch  13:  25% | abe: 5.196 | eve: 9.708 | bob: 5.403Epoch  13:  26% | abe: 5.195 | eve: 9.710 | bob: 5.403Epoch  13:  26% | abe: 5.193 | eve: 9.711 | bob: 5.401Epoch  13:  27% | abe: 5.192 | eve: 9.712 | bob: 5.400Epoch  13:  28% | abe: 5.190 | eve: 9.710 | bob: 5.398Epoch  13:  28% | abe: 5.188 | eve: 9.710 | bob: 5.396Epoch  13:  29% | abe: 5.187 | eve: 9.711 | bob: 5.396Epoch  13:  30% | abe: 5.185 | eve: 9.711 | bob: 5.394Epoch  13:  30% | abe: 5.183 | eve: 9.710 | bob: 5.392Epoch  13:  31% | abe: 5.182 | eve: 9.710 | bob: 5.391Epoch  13:  32% | abe: 5.181 | eve: 9.710 | bob: 5.390Epoch  13:  32% | abe: 5.179 | eve: 9.711 | bob: 5.389Epoch  13:  33% | abe: 5.177 | eve: 9.711 | bob: 5.387Epoch  13:  34% | abe: 5.175 | eve: 9.713 | bob: 5.385Epoch  13:  34% | abe: 5.173 | eve: 9.714 | bob: 5.384Epoch  13:  35% | abe: 5.172 | eve: 9.715 | bob: 5.383Epoch  13:  36% | abe: 5.171 | eve: 9.715 | bob: 5.382Epoch  13:  36% | abe: 5.169 | eve: 9.716 | bob: 5.380Epoch  13:  37% | abe: 5.167 | eve: 9.716 | bob: 5.379Epoch  13:  38% | abe: 5.166 | eve: 9.716 | bob: 5.378Epoch  13:  39% | abe: 5.165 | eve: 9.715 | bob: 5.377Epoch  13:  39% | abe: 5.163 | eve: 9.714 | bob: 5.375Epoch  13:  40% | abe: 5.162 | eve: 9.714 | bob: 5.374Epoch  13:  41% | abe: 5.160 | eve: 9.715 | bob: 5.372Epoch  13:  41% | abe: 5.158 | eve: 9.715 | bob: 5.370Epoch  13:  42% | abe: 5.156 | eve: 9.717 | bob: 5.368Epoch  13:  43% | abe: 5.154 | eve: 9.717 | bob: 5.367Epoch  13:  43% | abe: 5.153 | eve: 9.716 | bob: 5.365Epoch  13:  44% | abe: 5.151 | eve: 9.718 | bob: 5.363Epoch  13:  45% | abe: 5.149 | eve: 9.718 | bob: 5.362Epoch  13:  45% | abe: 5.147 | eve: 9.717 | bob: 5.361Epoch  13:  46% | abe: 5.146 | eve: 9.717 | bob: 5.359Epoch  13:  47% | abe: 5.145 | eve: 9.717 | bob: 5.358Epoch  13:  47% | abe: 5.143 | eve: 9.716 | bob: 5.356Epoch  13:  48% | abe: 5.141 | eve: 9.715 | bob: 5.355Epoch  13:  49% | abe: 5.140 | eve: 9.714 | bob: 5.353Epoch  13:  50% | abe: 5.138 | eve: 9.715 | bob: 5.351Epoch  13:  50% | abe: 5.136 | eve: 9.715 | bob: 5.350Epoch  13:  51% | abe: 5.135 | eve: 9.715 | bob: 5.348Epoch  13:  52% | abe: 5.133 | eve: 9.715 | bob: 5.347Epoch  13:  52% | abe: 5.132 | eve: 9.716 | bob: 5.346Epoch  13:  53% | abe: 5.130 | eve: 9.715 | bob: 5.344Epoch  13:  54% | abe: 5.128 | eve: 9.715 | bob: 5.343Epoch  13:  54% | abe: 5.126 | eve: 9.716 | bob: 5.341Epoch  13:  55% | abe: 5.125 | eve: 9.716 | bob: 5.340Epoch  13:  56% | abe: 5.123 | eve: 9.715 | bob: 5.338Epoch  13:  56% | abe: 5.122 | eve: 9.715 | bob: 5.337Epoch  13:  57% | abe: 5.120 | eve: 9.715 | bob: 5.335Epoch  13:  58% | abe: 5.119 | eve: 9.716 | bob: 5.334Epoch  13:  58% | abe: 5.117 | eve: 9.717 | bob: 5.333Epoch  13:  59% | abe: 5.115 | eve: 9.716 | bob: 5.331Epoch  13:  60% | abe: 5.113 | eve: 9.716 | bob: 5.329Epoch  13:  60% | abe: 5.112 | eve: 9.716 | bob: 5.328Epoch  13:  61% | abe: 5.110 | eve: 9.715 | bob: 5.326Epoch  13:  62% | abe: 5.108 | eve: 9.715 | bob: 5.325Epoch  13:  63% | abe: 5.107 | eve: 9.714 | bob: 5.323Epoch  13:  63% | abe: 5.105 | eve: 9.714 | bob: 5.322Epoch  13:  64% | abe: 5.103 | eve: 9.715 | bob: 5.320Epoch  13:  65% | abe: 5.102 | eve: 9.714 | bob: 5.319Epoch  13:  65% | abe: 5.100 | eve: 9.714 | bob: 5.318Epoch  13:  66% | abe: 5.099 | eve: 9.714 | bob: 5.316Epoch  13:  67% | abe: 5.097 | eve: 9.715 | bob: 5.314Epoch  13:  67% | abe: 5.095 | eve: 9.714 | bob: 5.312Epoch  13:  68% | abe: 5.094 | eve: 9.714 | bob: 5.311Epoch  13:  69% | abe: 5.092 | eve: 9.714 | bob: 5.310Epoch  13:  69% | abe: 5.091 | eve: 9.714 | bob: 5.308Epoch  13:  70% | abe: 5.089 | eve: 9.715 | bob: 5.307Epoch  13:  71% | abe: 5.087 | eve: 9.714 | bob: 5.305Epoch  13:  71% | abe: 5.086 | eve: 9.714 | bob: 5.304Epoch  13:  72% | abe: 5.084 | eve: 9.715 | bob: 5.303Epoch  13:  73% | abe: 5.083 | eve: 9.715 | bob: 5.301Epoch  13:  73% | abe: 5.081 | eve: 9.716 | bob: 5.299Epoch  13:  74% | abe: 5.080 | eve: 9.716 | bob: 5.298Epoch  13:  75% | abe: 5.078 | eve: 9.716 | bob: 5.297Epoch  13:  76% | abe: 5.077 | eve: 9.716 | bob: 5.295Epoch  13:  76% | abe: 5.075 | eve: 9.716 | bob: 5.294Epoch  13:  77% | abe: 5.073 | eve: 9.715 | bob: 5.292Epoch  13:  78% | abe: 5.071 | eve: 9.716 | bob: 5.290Epoch  13:  78% | abe: 5.069 | eve: 9.716 | bob: 5.289Epoch  13:  79% | abe: 5.068 | eve: 9.716 | bob: 5.287Epoch  13:  80% | abe: 5.066 | eve: 9.716 | bob: 5.286Epoch  13:  80% | abe: 5.065 | eve: 9.717 | bob: 5.285Epoch  13:  81% | abe: 5.063 | eve: 9.716 | bob: 5.283Epoch  13:  82% | abe: 5.062 | eve: 9.716 | bob: 5.281Epoch  13:  82% | abe: 5.060 | eve: 9.716 | bob: 5.280Epoch  13:  83% | abe: 5.059 | eve: 9.716 | bob: 5.279Epoch  13:  84% | abe: 5.057 | eve: 9.715 | bob: 5.277Epoch  13:  84% | abe: 5.055 | eve: 9.715 | bob: 5.276Epoch  13:  85% | abe: 5.054 | eve: 9.716 | bob: 5.274Epoch  13:  86% | abe: 5.052 | eve: 9.716 | bob: 5.273Epoch  13:  86% | abe: 5.050 | eve: 9.716 | bob: 5.271Epoch  13:  87% | abe: 5.049 | eve: 9.716 | bob: 5.270Epoch  13:  88% | abe: 5.047 | eve: 9.716 | bob: 5.268Epoch  13:  89% | abe: 5.046 | eve: 9.716 | bob: 5.267Epoch  13:  89% | abe: 5.044 | eve: 9.716 | bob: 5.266Epoch  13:  90% | abe: 5.042 | eve: 9.716 | bob: 5.264Epoch  13:  91% | abe: 5.041 | eve: 9.716 | bob: 5.263Epoch  13:  91% | abe: 5.039 | eve: 9.716 | bob: 5.261Epoch  13:  92% | abe: 5.038 | eve: 9.716 | bob: 5.260Epoch  13:  93% | abe: 5.036 | eve: 9.717 | bob: 5.258Epoch  13:  93% | abe: 5.034 | eve: 9.717 | bob: 5.257Epoch  13:  94% | abe: 5.033 | eve: 9.717 | bob: 5.255Epoch  13:  95% | abe: 5.032 | eve: 9.717 | bob: 5.254Epoch  13:  95% | abe: 5.030 | eve: 9.717 | bob: 5.253Epoch  13:  96% | abe: 5.028 | eve: 9.716 | bob: 5.251Epoch  13:  97% | abe: 5.027 | eve: 9.716 | bob: 5.250Epoch  13:  97% | abe: 5.025 | eve: 9.717 | bob: 5.248Epoch  13:  98% | abe: 5.023 | eve: 9.717 | bob: 5.247Epoch  13:  99% | abe: 5.022 | eve: 9.717 | bob: 5.245
New best Bob loss 5.244997601777746 at epoch 13
Epoch  14:   0% | abe: 4.786 | eve: 9.686 | bob: 5.038Epoch  14:   0% | abe: 4.787 | eve: 9.721 | bob: 5.036Epoch  14:   1% | abe: 4.786 | eve: 9.683 | bob: 5.037Epoch  14:   2% | abe: 4.790 | eve: 9.687 | bob: 5.039Epoch  14:   2% | abe: 4.786 | eve: 9.684 | bob: 5.037Epoch  14:   3% | abe: 4.781 | eve: 9.691 | bob: 5.028Epoch  14:   4% | abe: 4.778 | eve: 9.700 | bob: 5.024Epoch  14:   4% | abe: 4.775 | eve: 9.707 | bob: 5.021Epoch  14:   5% | abe: 4.777 | eve: 9.703 | bob: 5.021Epoch  14:   6% | abe: 4.777 | eve: 9.713 | bob: 5.023Epoch  14:   6% | abe: 4.776 | eve: 9.710 | bob: 5.021Epoch  14:   7% | abe: 4.776 | eve: 9.712 | bob: 5.018Epoch  14:   8% | abe: 4.775 | eve: 9.708 | bob: 5.017Epoch  14:   8% | abe: 4.772 | eve: 9.709 | bob: 5.015Epoch  14:   9% | abe: 4.770 | eve: 9.704 | bob: 5.013Epoch  14:  10% | abe: 4.767 | eve: 9.701 | bob: 5.010Epoch  14:  10% | abe: 4.765 | eve: 9.708 | bob: 5.008Epoch  14:  11% | abe: 4.764 | eve: 9.709 | bob: 5.006Epoch  14:  12% | abe: 4.762 | eve: 9.709 | bob: 5.006Epoch  14:  13% | abe: 4.762 | eve: 9.710 | bob: 5.006Epoch  14:  13% | abe: 4.762 | eve: 9.708 | bob: 5.004Epoch  14:  14% | abe: 4.759 | eve: 9.706 | bob: 5.002Epoch  14:  15% | abe: 4.758 | eve: 9.706 | bob: 5.002Epoch  14:  15% | abe: 4.757 | eve: 9.704 | bob: 5.000Epoch  14:  16% | abe: 4.753 | eve: 9.705 | bob: 4.998Epoch  14:  17% | abe: 4.751 | eve: 9.707 | bob: 4.997Epoch  14:  17% | abe: 4.749 | eve: 9.706 | bob: 4.994Epoch  14:  18% | abe: 4.748 | eve: 9.709 | bob: 4.993Epoch  14:  19% | abe: 4.746 | eve: 9.711 | bob: 4.991Epoch  14:  19% | abe: 4.744 | eve: 9.711 | bob: 4.990Epoch  14:  20% | abe: 4.743 | eve: 9.708 | bob: 4.989Epoch  14:  21% | abe: 4.742 | eve: 9.705 | bob: 4.986Epoch  14:  21% | abe: 4.740 | eve: 9.708 | bob: 4.985Epoch  14:  22% | abe: 4.739 | eve: 9.709 | bob: 4.984Epoch  14:  23% | abe: 4.738 | eve: 9.710 | bob: 4.983Epoch  14:  23% | abe: 4.736 | eve: 9.710 | bob: 4.983Epoch  14:  24% | abe: 4.735 | eve: 9.710 | bob: 4.981Epoch  14:  25% | abe: 4.733 | eve: 9.711 | bob: 4.981Epoch  14:  26% | abe: 4.732 | eve: 9.711 | bob: 4.980Epoch  14:  26% | abe: 4.731 | eve: 9.711 | bob: 4.979Epoch  14:  27% | abe: 4.729 | eve: 9.710 | bob: 4.977Epoch  14:  28% | abe: 4.728 | eve: 9.711 | bob: 4.976Epoch  14:  28% | abe: 4.726 | eve: 9.710 | bob: 4.975Epoch  14:  29% | abe: 4.724 | eve: 9.710 | bob: 4.973Epoch  14:  30% | abe: 4.724 | eve: 9.707 | bob: 4.973Epoch  14:  30% | abe: 4.722 | eve: 9.707 | bob: 4.971Epoch  14:  31% | abe: 4.721 | eve: 9.706 | bob: 4.970Epoch  14:  32% | abe: 4.719 | eve: 9.707 | bob: 4.969Epoch  14:  32% | abe: 4.718 | eve: 9.706 | bob: 4.967Epoch  14:  33% | abe: 4.716 | eve: 9.706 | bob: 4.966Epoch  14:  34% | abe: 4.715 | eve: 9.704 | bob: 4.964Epoch  14:  34% | abe: 4.713 | eve: 9.704 | bob: 4.963Epoch  14:  35% | abe: 4.712 | eve: 9.702 | bob: 4.962Epoch  14:  36% | abe: 4.711 | eve: 9.702 | bob: 4.960Epoch  14:  36% | abe: 4.709 | eve: 9.701 | bob: 4.959Epoch  14:  37% | abe: 4.707 | eve: 9.700 | bob: 4.957Epoch  14:  38% | abe: 4.706 | eve: 9.699 | bob: 4.956Epoch  14:  39% | abe: 4.705 | eve: 9.698 | bob: 4.954Epoch  14:  39% | abe: 4.704 | eve: 9.698 | bob: 4.953Epoch  14:  40% | abe: 4.702 | eve: 9.697 | bob: 4.952Epoch  14:  41% | abe: 4.700 | eve: 9.698 | bob: 4.950Epoch  14:  41% | abe: 4.698 | eve: 9.697 | bob: 4.949Epoch  14:  42% | abe: 4.697 | eve: 9.698 | bob: 4.947Epoch  14:  43% | abe: 4.696 | eve: 9.698 | bob: 4.946Epoch  14:  43% | abe: 4.695 | eve: 9.699 | bob: 4.945Epoch  14:  44% | abe: 4.693 | eve: 9.699 | bob: 4.944Epoch  14:  45% | abe: 4.692 | eve: 9.699 | bob: 4.943Epoch  14:  45% | abe: 4.690 | eve: 9.699 | bob: 4.941Epoch  14:  46% | abe: 4.689 | eve: 9.697 | bob: 4.940Epoch  14:  47% | abe: 4.687 | eve: 9.695 | bob: 4.939Epoch  14:  47% | abe: 4.686 | eve: 9.695 | bob: 4.938Epoch  14:  48% | abe: 4.685 | eve: 9.696 | bob: 4.937Epoch  14:  49% | abe: 4.683 | eve: 9.696 | bob: 4.935Epoch  14:  50% | abe: 4.682 | eve: 9.696 | bob: 4.934Epoch  14:  50% | abe: 4.680 | eve: 9.697 | bob: 4.933Epoch  14:  51% | abe: 4.679 | eve: 9.698 | bob: 4.931Epoch  14:  52% | abe: 4.677 | eve: 9.697 | bob: 4.930Epoch  14:  52% | abe: 4.676 | eve: 9.697 | bob: 4.929Epoch  14:  53% | abe: 4.675 | eve: 9.696 | bob: 4.928Epoch  14:  54% | abe: 4.673 | eve: 9.696 | bob: 4.927Epoch  14:  54% | abe: 4.672 | eve: 9.697 | bob: 4.925Epoch  14:  55% | abe: 4.670 | eve: 9.698 | bob: 4.924Epoch  14:  56% | abe: 4.669 | eve: 9.698 | bob: 4.923Epoch  14:  56% | abe: 4.668 | eve: 9.698 | bob: 4.922Epoch  14:  57% | abe: 4.666 | eve: 9.699 | bob: 4.920Epoch  14:  58% | abe: 4.664 | eve: 9.699 | bob: 4.919Epoch  14:  58% | abe: 4.663 | eve: 9.698 | bob: 4.918Epoch  14:  59% | abe: 4.662 | eve: 9.699 | bob: 4.916Epoch  14:  60% | abe: 4.661 | eve: 9.699 | bob: 4.915Epoch  14:  60% | abe: 4.659 | eve: 9.699 | bob: 4.914Epoch  14:  61% | abe: 4.658 | eve: 9.699 | bob: 4.913Epoch  14:  62% | abe: 4.657 | eve: 9.699 | bob: 4.912Epoch  14:  63% | abe: 4.655 | eve: 9.699 | bob: 4.910Epoch  14:  63% | abe: 4.654 | eve: 9.700 | bob: 4.909Epoch  14:  64% | abe: 4.653 | eve: 9.698 | bob: 4.908Epoch  14:  65% | abe: 4.651 | eve: 9.698 | bob: 4.907Epoch  14:  65% | abe: 4.650 | eve: 9.698 | bob: 4.906Epoch  14:  66% | abe: 4.649 | eve: 9.697 | bob: 4.904Epoch  14:  67% | abe: 4.647 | eve: 9.697 | bob: 4.903Epoch  14:  67% | abe: 4.646 | eve: 9.697 | bob: 4.901Epoch  14:  68% | abe: 4.644 | eve: 9.697 | bob: 4.900Epoch  14:  69% | abe: 4.643 | eve: 9.697 | bob: 4.899Epoch  14:  69% | abe: 4.641 | eve: 9.698 | bob: 4.898Epoch  14:  70% | abe: 4.640 | eve: 9.698 | bob: 4.897Epoch  14:  71% | abe: 4.639 | eve: 9.698 | bob: 4.896Epoch  14:  71% | abe: 4.637 | eve: 9.698 | bob: 4.894Epoch  14:  72% | abe: 4.636 | eve: 9.699 | bob: 4.893Epoch  14:  73% | abe: 4.635 | eve: 9.699 | bob: 4.892Epoch  14:  73% | abe: 4.633 | eve: 9.699 | bob: 4.891Epoch  14:  74% | abe: 4.632 | eve: 9.700 | bob: 4.889Epoch  14:  75% | abe: 4.630 | eve: 9.700 | bob: 4.888Epoch  14:  76% | abe: 4.629 | eve: 9.700 | bob: 4.887Epoch  14:  76% | abe: 4.627 | eve: 9.700 | bob: 4.886Epoch  14:  77% | abe: 4.626 | eve: 9.700 | bob: 4.884Epoch  14:  78% | abe: 4.625 | eve: 9.700 | bob: 4.883Epoch  14:  78% | abe: 4.623 | eve: 9.700 | bob: 4.882Epoch  14:  79% | abe: 4.622 | eve: 9.700 | bob: 4.881Epoch  14:  80% | abe: 4.621 | eve: 9.700 | bob: 4.879Epoch  14:  80% | abe: 4.619 | eve: 9.700 | bob: 4.878Epoch  14:  81% | abe: 4.618 | eve: 9.701 | bob: 4.877Epoch  14:  82% | abe: 4.616 | eve: 9.701 | bob: 4.876Epoch  14:  82% | abe: 4.615 | eve: 9.701 | bob: 4.875Epoch  14:  83% | abe: 4.614 | eve: 9.701 | bob: 4.873Epoch  14:  84% | abe: 4.612 | eve: 9.702 | bob: 4.872Epoch  14:  84% | abe: 4.611 | eve: 9.702 | bob: 4.871Epoch  14:  85% | abe: 4.610 | eve: 9.701 | bob: 4.869Epoch  14:  86% | abe: 4.608 | eve: 9.702 | bob: 4.868Epoch  14:  86% | abe: 4.607 | eve: 9.702 | bob: 4.867Epoch  14:  87% | abe: 4.606 | eve: 9.702 | bob: 4.866Epoch  14:  88% | abe: 4.604 | eve: 9.701 | bob: 4.864Epoch  14:  89% | abe: 4.603 | eve: 9.701 | bob: 4.863Epoch  14:  89% | abe: 4.601 | eve: 9.701 | bob: 4.862Epoch  14:  90% | abe: 4.600 | eve: 9.701 | bob: 4.861Epoch  14:  91% | abe: 4.598 | eve: 9.702 | bob: 4.860Epoch  14:  91% | abe: 4.597 | eve: 9.702 | bob: 4.858Epoch  14:  92% | abe: 4.596 | eve: 9.702 | bob: 4.857Epoch  14:  93% | abe: 4.594 | eve: 9.702 | bob: 4.856Epoch  14:  93% | abe: 4.593 | eve: 9.702 | bob: 4.855Epoch  14:  94% | abe: 4.592 | eve: 9.702 | bob: 4.854Epoch  14:  95% | abe: 4.590 | eve: 9.702 | bob: 4.852Epoch  14:  95% | abe: 4.589 | eve: 9.702 | bob: 4.851Epoch  14:  96% | abe: 4.587 | eve: 9.702 | bob: 4.850Epoch  14:  97% | abe: 4.586 | eve: 9.702 | bob: 4.849Epoch  14:  97% | abe: 4.585 | eve: 9.702 | bob: 4.848Epoch  14:  98% | abe: 4.583 | eve: 9.702 | bob: 4.846Epoch  14:  99% | abe: 4.582 | eve: 9.701 | bob: 4.845
New best Bob loss 4.845077035103882 at epoch 14
Epoch  15:   0% | abe: 4.377 | eve: 9.689 | bob: 4.632Epoch  15:   0% | abe: 4.378 | eve: 9.729 | bob: 4.648Epoch  15:   1% | abe: 4.382 | eve: 9.730 | bob: 4.657Epoch  15:   2% | abe: 4.384 | eve: 9.728 | bob: 4.656Epoch  15:   2% | abe: 4.383 | eve: 9.722 | bob: 4.656Epoch  15:   3% | abe: 4.379 | eve: 9.711 | bob: 4.656Epoch  15:   4% | abe: 4.377 | eve: 9.722 | bob: 4.657Epoch  15:   4% | abe: 4.375 | eve: 9.724 | bob: 4.656Epoch  15:   5% | abe: 4.374 | eve: 9.718 | bob: 4.655Epoch  15:   6% | abe: 4.372 | eve: 9.712 | bob: 4.653Epoch  15:   6% | abe: 4.369 | eve: 9.712 | bob: 4.650Epoch  15:   7% | abe: 4.366 | eve: 9.710 | bob: 4.649Epoch  15:   8% | abe: 4.365 | eve: 9.708 | bob: 4.649Epoch  15:   8% | abe: 4.363 | eve: 9.708 | bob: 4.648Epoch  15:   9% | abe: 4.362 | eve: 9.708 | bob: 4.648Epoch  15:  10% | abe: 4.361 | eve: 9.716 | bob: 4.645Epoch  15:  10% | abe: 4.358 | eve: 9.709 | bob: 4.643Epoch  15:  11% | abe: 4.357 | eve: 9.715 | bob: 4.641Epoch  15:  12% | abe: 4.355 | eve: 9.711 | bob: 4.641Epoch  15:  13% | abe: 4.355 | eve: 9.708 | bob: 4.640Epoch  15:  13% | abe: 4.353 | eve: 9.707 | bob: 4.639Epoch  15:  14% | abe: 4.352 | eve: 9.707 | bob: 4.638Epoch  15:  15% | abe: 4.350 | eve: 9.706 | bob: 4.636Epoch  15:  15% | abe: 4.348 | eve: 9.700 | bob: 4.634Epoch  15:  16% | abe: 4.347 | eve: 9.700 | bob: 4.633Epoch  15:  17% | abe: 4.345 | eve: 9.702 | bob: 4.630Epoch  15:  17% | abe: 4.344 | eve: 9.699 | bob: 4.629Epoch  15:  18% | abe: 4.342 | eve: 9.698 | bob: 4.628Epoch  15:  19% | abe: 4.341 | eve: 9.701 | bob: 4.626Epoch  15:  19% | abe: 4.339 | eve: 9.703 | bob: 4.626Epoch  15:  20% | abe: 4.338 | eve: 9.703 | bob: 4.625Epoch  15:  21% | abe: 4.337 | eve: 9.700 | bob: 4.625Epoch  15:  21% | abe: 4.337 | eve: 9.699 | bob: 4.625Epoch  15:  22% | abe: 4.336 | eve: 9.699 | bob: 4.625Epoch  15:  23% | abe: 4.334 | eve: 9.702 | bob: 4.624Epoch  15:  23% | abe: 4.333 | eve: 9.702 | bob: 4.622Epoch  15:  24% | abe: 4.331 | eve: 9.703 | bob: 4.621Epoch  15:  25% | abe: 4.330 | eve: 9.706 | bob: 4.620Epoch  15:  26% | abe: 4.329 | eve: 9.703 | bob: 4.619Epoch  15:  26% | abe: 4.328 | eve: 9.704 | bob: 4.619Epoch  15:  27% | abe: 4.327 | eve: 9.706 | bob: 4.617Epoch  15:  28% | abe: 4.326 | eve: 9.706 | bob: 4.616Epoch  15:  28% | abe: 4.324 | eve: 9.704 | bob: 4.615Epoch  15:  29% | abe: 4.323 | eve: 9.704 | bob: 4.614Epoch  15:  30% | abe: 4.321 | eve: 9.705 | bob: 4.613Epoch  15:  30% | abe: 4.320 | eve: 9.704 | bob: 4.612Epoch  15:  31% | abe: 4.319 | eve: 9.703 | bob: 4.610Epoch  15:  32% | abe: 4.317 | eve: 9.704 | bob: 4.610Epoch  15:  32% | abe: 4.316 | eve: 9.704 | bob: 4.608Epoch  15:  33% | abe: 4.315 | eve: 9.703 | bob: 4.607Epoch  15:  34% | abe: 4.313 | eve: 9.704 | bob: 4.606Epoch  15:  34% | abe: 4.312 | eve: 9.703 | bob: 4.605Epoch  15:  35% | abe: 4.311 | eve: 9.704 | bob: 4.604Epoch  15:  36% | abe: 4.309 | eve: 9.703 | bob: 4.603Epoch  15:  36% | abe: 4.308 | eve: 9.703 | bob: 4.602Epoch  15:  37% | abe: 4.307 | eve: 9.703 | bob: 4.601Epoch  15:  38% | abe: 4.305 | eve: 9.702 | bob: 4.600Epoch  15:  39% | abe: 4.304 | eve: 9.701 | bob: 4.599Epoch  15:  39% | abe: 4.303 | eve: 9.701 | bob: 4.598Epoch  15:  40% | abe: 4.301 | eve: 9.700 | bob: 4.597Epoch  15:  41% | abe: 4.300 | eve: 9.701 | bob: 4.596Epoch  15:  41% | abe: 4.299 | eve: 9.702 | bob: 4.594Epoch  15:  42% | abe: 4.297 | eve: 9.702 | bob: 4.594Epoch  15:  43% | abe: 4.296 | eve: 9.701 | bob: 4.593Epoch  15:  43% | abe: 4.295 | eve: 9.702 | bob: 4.591Epoch  15:  44% | abe: 4.294 | eve: 9.702 | bob: 4.590Epoch  15:  45% | abe: 4.292 | eve: 9.702 | bob: 4.589Epoch  15:  45% | abe: 4.291 | eve: 9.702 | bob: 4.588Epoch  15:  46% | abe: 4.290 | eve: 9.703 | bob: 4.587Epoch  15:  47% | abe: 4.289 | eve: 9.703 | bob: 4.585Epoch  15:  47% | abe: 4.287 | eve: 9.705 | bob: 4.584Epoch  15:  48% | abe: 4.286 | eve: 9.704 | bob: 4.583Epoch  15:  49% | abe: 4.284 | eve: 9.704 | bob: 4.582Epoch  15:  50% | abe: 4.283 | eve: 9.704 | bob: 4.581Epoch  15:  50% | abe: 4.282 | eve: 9.704 | bob: 4.580Epoch  15:  51% | abe: 4.281 | eve: 9.705 | bob: 4.580Epoch  15:  52% | abe: 4.280 | eve: 9.705 | bob: 4.578Epoch  15:  52% | abe: 4.278 | eve: 9.705 | bob: 4.577Epoch  15:  53% | abe: 4.277 | eve: 9.705 | bob: 4.576Epoch  15:  54% | abe: 4.276 | eve: 9.705 | bob: 4.575Epoch  15:  54% | abe: 4.274 | eve: 9.704 | bob: 4.573Epoch  15:  55% | abe: 4.273 | eve: 9.704 | bob: 4.572Epoch  15:  56% | abe: 4.272 | eve: 9.704 | bob: 4.571Epoch  15:  56% | abe: 4.270 | eve: 9.703 | bob: 4.569Epoch  15:  57% | abe: 4.269 | eve: 9.702 | bob: 4.568Epoch  15:  58% | abe: 4.268 | eve: 9.702 | bob: 4.568Epoch  15:  58% | abe: 4.267 | eve: 9.702 | bob: 4.566Epoch  15:  59% | abe: 4.265 | eve: 9.702 | bob: 4.565Epoch  15:  60% | abe: 4.264 | eve: 9.703 | bob: 4.564Epoch  15:  60% | abe: 4.263 | eve: 9.702 | bob: 4.563Epoch  15:  61% | abe: 4.262 | eve: 9.703 | bob: 4.562Epoch  15:  62% | abe: 4.260 | eve: 9.703 | bob: 4.561Epoch  15:  63% | abe: 4.259 | eve: 9.702 | bob: 4.560Epoch  15:  63% | abe: 4.258 | eve: 9.703 | bob: 4.558Epoch  15:  64% | abe: 4.257 | eve: 9.703 | bob: 4.557Epoch  15:  65% | abe: 4.255 | eve: 9.702 | bob: 4.556Epoch  15:  65% | abe: 4.254 | eve: 9.702 | bob: 4.555Epoch  15:  66% | abe: 4.253 | eve: 9.702 | bob: 4.554Epoch  15:  67% | abe: 4.251 | eve: 9.702 | bob: 4.553Epoch  15:  67% | abe: 4.250 | eve: 9.701 | bob: 4.552Epoch  15:  68% | abe: 4.249 | eve: 9.701 | bob: 4.551Epoch  15:  69% | abe: 4.247 | eve: 9.700 | bob: 4.550Epoch  15:  69% | abe: 4.246 | eve: 9.700 | bob: 4.549Epoch  15:  70% | abe: 4.245 | eve: 9.700 | bob: 4.548Epoch  15:  71% | abe: 4.244 | eve: 9.700 | bob: 4.546Epoch  15:  71% | abe: 4.243 | eve: 9.700 | bob: 4.545Epoch  15:  72% | abe: 4.242 | eve: 9.700 | bob: 4.544Epoch  15:  73% | abe: 4.241 | eve: 9.700 | bob: 4.543Epoch  15:  73% | abe: 4.239 | eve: 9.700 | bob: 4.542Epoch  15:  74% | abe: 4.238 | eve: 9.700 | bob: 4.541Epoch  15:  75% | abe: 4.237 | eve: 9.700 | bob: 4.540Epoch  15:  76% | abe: 4.236 | eve: 9.700 | bob: 4.539Epoch  15:  76% | abe: 4.234 | eve: 9.700 | bob: 4.538Epoch  15:  77% | abe: 4.233 | eve: 9.699 | bob: 4.537Epoch  15:  78% | abe: 4.232 | eve: 9.699 | bob: 4.535Epoch  15:  78% | abe: 4.231 | eve: 9.699 | bob: 4.534Epoch  15:  79% | abe: 4.229 | eve: 9.700 | bob: 4.533Epoch  15:  80% | abe: 4.228 | eve: 9.700 | bob: 4.532Epoch  15:  80% | abe: 4.227 | eve: 9.701 | bob: 4.531Epoch  15:  81% | abe: 4.226 | eve: 9.701 | bob: 4.530Epoch  15:  82% | abe: 4.225 | eve: 9.701 | bob: 4.529Epoch  15:  82% | abe: 4.223 | eve: 9.701 | bob: 4.528Epoch  15:  83% | abe: 4.222 | eve: 9.700 | bob: 4.527Epoch  15:  84% | abe: 4.221 | eve: 9.701 | bob: 4.525Epoch  15:  84% | abe: 4.220 | eve: 9.700 | bob: 4.524Epoch  15:  85% | abe: 4.218 | eve: 9.701 | bob: 4.523Epoch  15:  86% | abe: 4.217 | eve: 9.701 | bob: 4.522Epoch  15:  86% | abe: 4.216 | eve: 9.701 | bob: 4.521Epoch  15:  87% | abe: 4.215 | eve: 9.702 | bob: 4.520Epoch  15:  88% | abe: 4.213 | eve: 9.702 | bob: 4.519Epoch  15:  89% | abe: 4.212 | eve: 9.701 | bob: 4.518Epoch  15:  89% | abe: 4.211 | eve: 9.701 | bob: 4.517Epoch  15:  90% | abe: 4.210 | eve: 9.702 | bob: 4.516Epoch  15:  91% | abe: 4.208 | eve: 9.702 | bob: 4.514Epoch  15:  91% | abe: 4.207 | eve: 9.701 | bob: 4.513Epoch  15:  92% | abe: 4.205 | eve: 9.701 | bob: 4.512Epoch  15:  93% | abe: 4.204 | eve: 9.700 | bob: 4.511Epoch  15:  93% | abe: 4.203 | eve: 9.700 | bob: 4.510Epoch  15:  94% | abe: 4.202 | eve: 9.701 | bob: 4.509Epoch  15:  95% | abe: 4.200 | eve: 9.701 | bob: 4.508Epoch  15:  95% | abe: 4.199 | eve: 9.701 | bob: 4.507Epoch  15:  96% | abe: 4.198 | eve: 9.701 | bob: 4.506Epoch  15:  97% | abe: 4.197 | eve: 9.700 | bob: 4.505Epoch  15:  97% | abe: 4.196 | eve: 9.700 | bob: 4.504Epoch  15:  98% | abe: 4.194 | eve: 9.700 | bob: 4.502Epoch  15:  99% | abe: 4.193 | eve: 9.700 | bob: 4.502
New best Bob loss 4.501627824005877 at epoch 15
Epoch  16:   0% | abe: 3.995 | eve: 9.682 | bob: 4.344Epoch  16:   0% | abe: 4.006 | eve: 9.630 | bob: 4.344Epoch  16:   1% | abe: 4.010 | eve: 9.669 | bob: 4.343Epoch  16:   2% | abe: 4.012 | eve: 9.680 | bob: 4.341Epoch  16:   2% | abe: 4.007 | eve: 9.688 | bob: 4.341Epoch  16:   3% | abe: 4.007 | eve: 9.700 | bob: 4.339Epoch  16:   4% | abe: 4.007 | eve: 9.707 | bob: 4.336Epoch  16:   4% | abe: 4.007 | eve: 9.698 | bob: 4.338Epoch  16:   5% | abe: 4.008 | eve: 9.691 | bob: 4.340Epoch  16:   6% | abe: 4.008 | eve: 9.694 | bob: 4.338Epoch  16:   6% | abe: 4.005 | eve: 9.693 | bob: 4.338Epoch  16:   7% | abe: 4.005 | eve: 9.689 | bob: 4.338Epoch  16:   8% | abe: 4.002 | eve: 9.698 | bob: 4.335Epoch  16:   8% | abe: 4.001 | eve: 9.690 | bob: 4.334Epoch  16:   9% | abe: 3.999 | eve: 9.689 | bob: 4.332Epoch  16:  10% | abe: 3.997 | eve: 9.692 | bob: 4.329Epoch  16:  10% | abe: 3.995 | eve: 9.697 | bob: 4.329Epoch  16:  11% | abe: 3.993 | eve: 9.694 | bob: 4.328Epoch  16:  12% | abe: 3.992 | eve: 9.692 | bob: 4.326Epoch  16:  13% | abe: 3.990 | eve: 9.695 | bob: 4.324Epoch  16:  13% | abe: 3.988 | eve: 9.694 | bob: 4.322Epoch  16:  14% | abe: 3.986 | eve: 9.691 | bob: 4.322Epoch  16:  15% | abe: 3.984 | eve: 9.692 | bob: 4.320Epoch  16:  15% | abe: 3.983 | eve: 9.693 | bob: 4.319Epoch  16:  16% | abe: 3.982 | eve: 9.694 | bob: 4.319Epoch  16:  17% | abe: 3.981 | eve: 9.692 | bob: 4.318Epoch  16:  17% | abe: 3.980 | eve: 9.695 | bob: 4.318Epoch  16:  18% | abe: 3.979 | eve: 9.695 | bob: 4.316Epoch  16:  19% | abe: 3.978 | eve: 9.693 | bob: 4.315Epoch  16:  19% | abe: 3.977 | eve: 9.694 | bob: 4.314Epoch  16:  20% | abe: 3.976 | eve: 9.694 | bob: 4.313Epoch  16:  21% | abe: 3.975 | eve: 9.690 | bob: 4.312Epoch  16:  21% | abe: 3.973 | eve: 9.690 | bob: 4.311Epoch  16:  22% | abe: 3.972 | eve: 9.689 | bob: 4.309Epoch  16:  23% | abe: 3.971 | eve: 9.691 | bob: 4.308