WARNING:tensorflow:From /home/stud/minawoi/miniconda3/envs/conda-venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2024-04-13 16:35:25.461287: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-04-13 16:35:25.593620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:8a:00.0
2024-04-13 16:35:25.594399: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-13 16:35:25.597681: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-04-13 16:35:25.599529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-04-13 16:35:25.600379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-04-13 16:35:25.606490: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-04-13 16:35:25.609546: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-04-13 16:35:25.615463: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-04-13 16:35:25.627963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-04-13 16:35:25.628451: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2024-04-13 16:35:25.648129: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199835000 Hz
2024-04-13 16:35:25.651005: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3f00fd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-04-13 16:35:25.651053: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-04-13 16:35:26.020886: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x38ca490 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-04-13 16:35:26.020970: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-04-13 16:35:26.026549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:8a:00.0
2024-04-13 16:35:26.026662: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-13 16:35:26.026696: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-04-13 16:35:26.026724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-04-13 16:35:26.026753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-04-13 16:35:26.026783: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-04-13 16:35:26.026819: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-04-13 16:35:26.026863: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-04-13 16:35:26.031823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-04-13 16:35:26.031927: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-13 16:35:26.038583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-04-13 16:35:26.038627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-04-13 16:35:26.038654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2024-04-13 16:35:26.045546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30593 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0)
WARNING:tensorflow:Output bob missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to bob.
WARNING:tensorflow:Output bob_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to bob_1.
WARNING:tensorflow:Output eve missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to eve.
WARNING:tensorflow:Output eve_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to eve_1.
2024-04-13 16:35:29.549989: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
Train on 512 samples, validate on 512 samples
Epoch 1/512
512/512 - 1s - loss: 0.6103 - val_loss: 0.0256
Epoch 2/512
512/512 - 0s - loss: 0.0675 - val_loss: 0.0827
Epoch 3/512
512/512 - 0s - loss: 0.0312 - val_loss: 0.0523
Epoch 4/512
512/512 - 0s - loss: 0.0186 - val_loss: 0.0276
Epoch 5/512
512/512 - 0s - loss: 0.0091 - val_loss: 0.0108
Epoch 6/512
512/512 - 0s - loss: 0.0034 - val_loss: 0.0028
Epoch 7/512
512/512 - 0s - loss: 9.0481e-04 - val_loss: 2.7573e-04
Epoch 8/512
512/512 - 0s - loss: 0.0011 - val_loss: 0.0023
Epoch 9/512
512/512 - 0s - loss: 0.0080 - val_loss: 3.9172e-04
Epoch 10/512
512/512 - 0s - loss: 9.3573e-04 - val_loss: 6.3602e-05
Epoch 11/512
512/512 - 0s - loss: 4.0866e-04 - val_loss: 2.1188e-04
Epoch 12/512
512/512 - 0s - loss: 0.0028 - val_loss: 0.0015
Epoch 13/512
512/512 - 0s - loss: 0.0047 - val_loss: 2.7989e-04
Epoch 14/512
512/512 - 0s - loss: 7.4604e-04 - val_loss: 1.1558e-04
Epoch 15/512
512/512 - 0s - loss: 8.3062e-04 - val_loss: 3.3238e-04
Epoch 16/512
512/512 - 0s - loss: 0.0035 - val_loss: 4.5606e-04
Epoch 17/512
512/512 - 0s - loss: 0.0020 - val_loss: 1.1744e-04
Epoch 18/512
512/512 - 0s - loss: 6.8075e-04 - val_loss: 1.1152e-04
Epoch 19/512
512/512 - 0s - loss: 0.0016 - val_loss: 2.6165e-04
Epoch 20/512
512/512 - 0s - loss: 0.0026 - val_loss: 1.2631e-04
Epoch 21/512
512/512 - 0s - loss: 0.0010 - val_loss: 7.0360e-05
Epoch 22/512
512/512 - 0s - loss: 9.7924e-04 - val_loss: 1.0480e-04
Epoch 23/512
512/512 - 0s - loss: 0.0020 - val_loss: 1.0324e-04
Epoch 24/512
512/512 - 0s - loss: 0.0014 - val_loss: 5.5978e-05
Epoch 25/512
512/512 - 0s - loss: 9.3527e-04 - val_loss: 5.6049e-05
Epoch 26/512
512/512 - 0s - loss: 0.0014 - val_loss: 6.7287e-05
Epoch 27/512
512/512 - 0s - loss: 0.0015 - val_loss: 4.6274e-05
Epoch 28/512
512/512 - 0s - loss: 0.0011 - val_loss: 3.7862e-05
Epoch 29/512
512/512 - 0s - loss: 0.0011 - val_loss: 4.1838e-05
Epoch 30/512
512/512 - 0s - loss: 0.0013 - val_loss: 3.6880e-05
Epoch 31/512
512/512 - 0s - loss: 0.0012 - val_loss: 2.9535e-05
Epoch 32/512
512/512 - 0s - loss: 0.0011 - val_loss: 2.9062e-05
Epoch 33/512
512/512 - 0s - loss: 0.0012 - val_loss: 2.8100e-05
Epoch 34/512
512/512 - 0s - loss: 0.0011 - val_loss: 2.3859e-05
Epoch 35/512
512/512 - 0s - loss: 0.0010 - val_loss: 2.2150e-05
Epoch 36/512
512/512 - 0s - loss: 0.0011 - val_loss: 2.1765e-05
Epoch 37/512
512/512 - 0s - loss: 0.0011 - val_loss: 1.9934e-05
Epoch 38/512
512/512 - 0s - loss: 0.0010 - val_loss: 1.8615e-05
Epoch 39/512
512/512 - 0s - loss: 0.0010 - val_loss: 1.7562e-05
Epoch 40/512
512/512 - 0s - loss: 0.0010 - val_loss: 1.6752e-05
Epoch 41/512
512/512 - 0s - loss: 0.0010 - val_loss: 1.5930e-05
Epoch 42/512
512/512 - 0s - loss: 9.8545e-04 - val_loss: 1.5232e-05
Epoch 43/512
512/512 - 0s - loss: 9.8011e-04 - val_loss: 1.4524e-05
Epoch 44/512
512/512 - 0s - loss: 9.6063e-04 - val_loss: 1.3870e-05
Epoch 45/512
512/512 - 0s - loss: 9.4740e-04 - val_loss: 1.3358e-05
Epoch 46/512
512/512 - 0s - loss: 9.4558e-04 - val_loss: 1.2860e-05
Epoch 47/512
512/512 - 0s - loss: 9.2172e-04 - val_loss: 1.2437e-05
Epoch 48/512
512/512 - 0s - loss: 9.1794e-04 - val_loss: 1.2130e-05
Epoch 49/512
512/512 - 0s - loss: 9.1281e-04 - val_loss: 1.1604e-05
Epoch 50/512
512/512 - 0s - loss: 8.8132e-04 - val_loss: 1.1298e-05
Epoch 51/512
512/512 - 0s - loss: 8.8290e-04 - val_loss: 1.1303e-05
Epoch 52/512
512/512 - 0s - loss: 8.8989e-04 - val_loss: 1.0769e-05
Epoch 53/512
512/512 - 0s - loss: 8.5628e-04 - val_loss: 1.0360e-05
Epoch 54/512
512/512 - 0s - loss: 8.4706e-04 - val_loss: 1.0258e-05
Epoch 55/512
512/512 - 0s - loss: 8.4187e-04 - val_loss: 1.0247e-05
Epoch 56/512
512/512 - 0s - loss: 8.4631e-04 - val_loss: 9.9109e-06
Epoch 57/512
512/512 - 0s - loss: 8.2596e-04 - val_loss: 9.4340e-06
Epoch 58/512
512/512 - 0s - loss: 8.0278e-04 - val_loss: 9.4326e-06
Epoch 59/512
512/512 - 0s - loss: 8.1755e-04 - val_loss: 9.2815e-06
Epoch 60/512
512/512 - 0s - loss: 7.9615e-04 - val_loss: 9.0306e-06
Epoch 61/512
512/512 - 0s - loss: 7.8739e-04 - val_loss: 8.9124e-06
Epoch 62/512
512/512 - 0s - loss: 7.8304e-04 - val_loss: 8.6923e-06
Epoch 63/512
512/512 - 0s - loss: 7.7195e-04 - val_loss: 8.5493e-06
Epoch 64/512
512/512 - 0s - loss: 7.6473e-04 - val_loss: 8.3874e-06
Epoch 65/512
512/512 - 0s - loss: 7.5330e-04 - val_loss: 8.3018e-06
Epoch 66/512
512/512 - 0s - loss: 7.4667e-04 - val_loss: 8.2524e-06
Epoch 67/512
512/512 - 0s - loss: 7.4625e-04 - val_loss: 8.0457e-06
Epoch 68/512
512/512 - 0s - loss: 7.3096e-04 - val_loss: 7.8458e-06
Epoch 69/512
512/512 - 0s - loss: 7.2089e-04 - val_loss: 7.8018e-06
Epoch 70/512
512/512 - 0s - loss: 7.1848e-04 - val_loss: 7.7588e-06
Epoch 71/512
512/512 - 0s - loss: 7.1640e-04 - val_loss: 7.4830e-06
Epoch 72/512
512/512 - 0s - loss: 6.9239e-04 - val_loss: 7.4331e-06
Epoch 73/512
512/512 - 0s - loss: 6.9146e-04 - val_loss: 7.5359e-06
Epoch 74/512
512/512 - 0s - loss: 7.0688e-04 - val_loss: 7.1373e-06
Epoch 75/512
512/512 - 0s - loss: 6.6427e-04 - val_loss: 7.0388e-06
Epoch 76/512
512/512 - 0s - loss: 6.6846e-04 - val_loss: 7.2372e-06
Epoch 77/512
512/512 - 0s - loss: 6.7987e-04 - val_loss: 7.0623e-06
Epoch 78/512
512/512 - 0s - loss: 6.6211e-04 - val_loss: 6.6920e-06
Epoch 79/512
512/512 - 0s - loss: 6.3771e-04 - val_loss: 6.7361e-06
Epoch 80/512
512/512 - 0s - loss: 6.4521e-04 - val_loss: 6.9952e-06
Epoch 81/512
512/512 - 0s - loss: 6.5637e-04 - val_loss: 6.6965e-06
Epoch 82/512
512/512 - 0s - loss: 6.2513e-04 - val_loss: 6.4286e-06
Epoch 83/512
512/512 - 0s - loss: 6.1884e-04 - val_loss: 6.5089e-06
Epoch 84/512
512/512 - 0s - loss: 6.2226e-04 - val_loss: 6.5588e-06
Epoch 85/512
512/512 - 0s - loss: 6.2313e-04 - val_loss: 6.3001e-06
Epoch 86/512
512/512 - 0s - loss: 5.9820e-04 - val_loss: 6.1753e-06
Epoch 87/512
512/512 - 0s - loss: 5.9781e-04 - val_loss: 6.2722e-06
Epoch 88/512
512/512 - 0s - loss: 6.0181e-04 - val_loss: 6.1474e-06
Epoch 89/512
512/512 - 0s - loss: 5.8204e-04 - val_loss: 6.0738e-06
Epoch 90/512
512/512 - 0s - loss: 5.8160e-04 - val_loss: 6.0767e-06
Epoch 91/512
512/512 - 0s - loss: 5.8063e-04 - val_loss: 5.9503e-06
Epoch 92/512
512/512 - 0s - loss: 5.6912e-04 - val_loss: 5.7757e-06
Epoch 93/512
512/512 - 0s - loss: 5.6175e-04 - val_loss: 5.7195e-06
Epoch 94/512
512/512 - 0s - loss: 5.5260e-04 - val_loss: 5.7479e-06
Epoch 95/512
512/512 - 0s - loss: 5.5845e-04 - val_loss: 5.6461e-06
Epoch 96/512
512/512 - 0s - loss: 5.4564e-04 - val_loss: 5.4585e-06
Epoch 97/512
512/512 - 0s - loss: 5.2656e-04 - val_loss: 5.6085e-06
Epoch 98/512
512/512 - 0s - loss: 5.4587e-04 - val_loss: 5.5609e-06
Epoch 99/512
512/512 - 0s - loss: 5.3023e-04 - val_loss: 5.2643e-06
Epoch 100/512
512/512 - 0s - loss: 5.1145e-04 - val_loss: 5.2625e-06
Epoch 101/512
512/512 - 0s - loss: 5.1783e-04 - val_loss: 5.2909e-06
Epoch 102/512
512/512 - 0s - loss: 5.1068e-04 - val_loss: 5.2287e-06
Epoch 103/512
512/512 - 0s - loss: 5.0054e-04 - val_loss: 5.2301e-06
Epoch 104/512
512/512 - 0s - loss: 5.0336e-04 - val_loss: 5.1259e-06
Epoch 105/512
512/512 - 0s - loss: 4.9498e-04 - val_loss: 4.9579e-06
Epoch 106/512
512/512 - 0s - loss: 4.7794e-04 - val_loss: 4.9965e-06
Epoch 107/512
512/512 - 0s - loss: 4.8572e-04 - val_loss: 4.9851e-06
Epoch 108/512
512/512 - 0s - loss: 4.8378e-04 - val_loss: 4.6951e-06
Epoch 109/512
512/512 - 0s - loss: 4.5263e-04 - val_loss: 4.7886e-06
Epoch 110/512
512/512 - 0s - loss: 4.7190e-04 - val_loss: 4.8749e-06
Epoch 111/512
512/512 - 0s - loss: 4.6813e-04 - val_loss: 4.5584e-06
Epoch 112/512
512/512 - 0s - loss: 4.4411e-04 - val_loss: 4.4092e-06
Epoch 113/512
512/512 - 0s - loss: 4.4030e-04 - val_loss: 4.5590e-06
Epoch 114/512
512/512 - 0s - loss: 4.5153e-04 - val_loss: 4.5000e-06
Epoch 115/512
512/512 - 0s - loss: 4.3336e-04 - val_loss: 4.3374e-06
Epoch 116/512
512/512 - 0s - loss: 4.2444e-04 - val_loss: 4.3835e-06
Epoch 117/512
512/512 - 0s - loss: 4.2810e-04 - val_loss: 4.3725e-06
Epoch 118/512
512/512 - 0s - loss: 4.2263e-04 - val_loss: 4.2503e-06
Epoch 119/512
512/512 - 0s - loss: 4.0974e-04 - val_loss: 4.1738e-06
Epoch 120/512
512/512 - 0s - loss: 4.0831e-04 - val_loss: 4.1563e-06
Epoch 121/512
512/512 - 0s - loss: 4.0427e-04 - val_loss: 4.0780e-06
Epoch 122/512
512/512 - 0s - loss: 3.9879e-04 - val_loss: 3.9715e-06
Epoch 123/512
512/512 - 0s - loss: 3.8634e-04 - val_loss: 3.9701e-06
Epoch 124/512
512/512 - 0s - loss: 3.8830e-04 - val_loss: 3.9610e-06
Epoch 125/512
512/512 - 0s - loss: 3.8510e-04 - val_loss: 3.7973e-06
Epoch 126/512
512/512 - 0s - loss: 3.6966e-04 - val_loss: 3.7595e-06
Epoch 127/512
512/512 - 0s - loss: 3.6746e-04 - val_loss: 3.8493e-06
Epoch 128/512
512/512 - 0s - loss: 3.7428e-04 - val_loss: 3.7118e-06
Epoch 129/512
512/512 - 0s - loss: 3.5516e-04 - val_loss: 3.5579e-06
Epoch 130/512
512/512 - 0s - loss: 3.4959e-04 - val_loss: 3.6087e-06
Epoch 131/512
512/512 - 0s - loss: 3.5321e-04 - val_loss: 3.5523e-06
Epoch 132/512
512/512 - 0s - loss: 3.4204e-04 - val_loss: 3.4614e-06
Epoch 133/512
512/512 - 0s - loss: 3.3781e-04 - val_loss: 3.4340e-06
Epoch 134/512
512/512 - 0s - loss: 3.3295e-04 - val_loss: 3.3888e-06
Epoch 135/512
512/512 - 0s - loss: 3.2837e-04 - val_loss: 3.3266e-06
Epoch 136/512
512/512 - 0s - loss: 3.2248e-04 - val_loss: 3.2611e-06
Epoch 137/512
512/512 - 0s - loss: 3.1773e-04 - val_loss: 3.1802e-06
Epoch 138/512
512/512 - 0s - loss: 3.1015e-04 - val_loss: 3.1631e-06
Epoch 139/512
512/512 - 0s - loss: 3.0828e-04 - val_loss: 3.1434e-06
Epoch 140/512
512/512 - 0s - loss: 3.0209e-04 - val_loss: 3.0829e-06
Epoch 141/512
512/512 - 0s - loss: 2.9805e-04 - val_loss: 2.9980e-06
Epoch 142/512
512/512 - 0s - loss: 2.9210e-04 - val_loss: 2.9061e-06
Epoch 143/512
512/512 - 0s - loss: 2.8376e-04 - val_loss: 2.9127e-06
Epoch 144/512
512/512 - 0s - loss: 2.8459e-04 - val_loss: 2.8920e-06
Epoch 145/512
512/512 - 0s - loss: 2.7804e-04 - val_loss: 2.7941e-06
Epoch 146/512
512/512 - 0s - loss: 2.7102e-04 - val_loss: 2.7243e-06
Epoch 147/512
512/512 - 0s - loss: 2.6546e-04 - val_loss: 2.7322e-06
Epoch 148/512
512/512 - 0s - loss: 2.6447e-04 - val_loss: 2.7190e-06
Epoch 149/512
512/512 - 0s - loss: 2.6160e-04 - val_loss: 2.5871e-06
Epoch 150/512
512/512 - 0s - loss: 2.4838e-04 - val_loss: 2.5419e-06
Epoch 151/512
512/512 - 0s - loss: 2.4991e-04 - val_loss: 2.5303e-06
Epoch 152/512
512/512 - 0s - loss: 2.4504e-04 - val_loss: 2.4592e-06
Epoch 153/512
512/512 - 0s - loss: 2.3785e-04 - val_loss: 2.4087e-06
Epoch 154/512
512/512 - 0s - loss: 2.3448e-04 - val_loss: 2.3812e-06
Epoch 155/512
512/512 - 0s - loss: 2.3019e-04 - val_loss: 2.3624e-06
Epoch 156/512
512/512 - 0s - loss: 2.2839e-04 - val_loss: 2.2659e-06
Epoch 157/512
512/512 - 0s - loss: 2.1862e-04 - val_loss: 2.1975e-06
Epoch 158/512
512/512 - 0s - loss: 2.1504e-04 - val_loss: 2.2209e-06
Epoch 159/512
512/512 - 0s - loss: 2.1549e-04 - val_loss: 2.1885e-06
Epoch 160/512
512/512 - 0s - loss: 2.1026e-04 - val_loss: 2.0534e-06
Epoch 161/512
512/512 - 0s - loss: 1.9893e-04 - val_loss: 2.0432e-06
Epoch 162/512
512/512 - 0s - loss: 2.0177e-04 - val_loss: 2.0441e-06
Epoch 163/512
512/512 - 0s - loss: 1.9683e-04 - val_loss: 1.9760e-06
Epoch 164/512
512/512 - 0s - loss: 1.8897e-04 - val_loss: 1.9508e-06
Epoch 165/512
512/512 - 0s - loss: 1.8958e-04 - val_loss: 1.8983e-06
Epoch 166/512
512/512 - 0s - loss: 1.8352e-04 - val_loss: 1.8298e-06
Epoch 167/512
512/512 - 0s - loss: 1.7732e-04 - val_loss: 1.8177e-06
Epoch 168/512
512/512 - 0s - loss: 1.7582e-04 - val_loss: 1.8224e-06
Epoch 169/512
512/512 - 0s - loss: 1.7247e-04 - val_loss: 1.7758e-06
Epoch 170/512
512/512 - 0s - loss: 1.6975e-04 - val_loss: 1.6843e-06
Epoch 171/512
512/512 - 0s - loss: 1.6152e-04 - val_loss: 1.6467e-06
Epoch 172/512
512/512 - 0s - loss: 1.6060e-04 - val_loss: 1.6377e-06
Epoch 173/512
512/512 - 0s - loss: 1.5807e-04 - val_loss: 1.5881e-06
Epoch 174/512
512/512 - 0s - loss: 1.5276e-04 - val_loss: 1.5375e-06
Epoch 175/512
512/512 - 0s - loss: 1.4915e-04 - val_loss: 1.5078e-06
Epoch 176/512
512/512 - 0s - loss: 1.4655e-04 - val_loss: 1.4725e-06
Epoch 177/512
512/512 - 0s - loss: 1.4111e-04 - val_loss: 1.4589e-06
Epoch 178/512
512/512 - 0s - loss: 1.4186e-04 - val_loss: 1.4030e-06
Epoch 179/512
512/512 - 0s - loss: 1.3400e-04 - val_loss: 1.3554e-06
Epoch 180/512
512/512 - 0s - loss: 1.3189e-04 - val_loss: 1.3647e-06
Epoch 181/512
512/512 - 0s - loss: 1.3070e-04 - val_loss: 1.3364e-06
Epoch 182/512
512/512 - 0s - loss: 1.2627e-04 - val_loss: 1.2908e-06
Epoch 183/512
512/512 - 0s - loss: 1.2328e-04 - val_loss: 1.2480e-06
Epoch 184/512
512/512 - 0s - loss: 1.1988e-04 - val_loss: 1.2148e-06
Epoch 185/512
512/512 - 0s - loss: 1.1693e-04 - val_loss: 1.1906e-06
Epoch 186/512
512/512 - 0s - loss: 1.1388e-04 - val_loss: 1.1663e-06
Epoch 187/512
512/512 - 0s - loss: 1.1216e-04 - val_loss: 1.1270e-06
Epoch 188/512
512/512 - 0s - loss: 1.0755e-04 - val_loss: 1.0910e-06
Epoch 189/512
512/512 - 0s - loss: 1.0515e-04 - val_loss: 1.0797e-06
Epoch 190/512
512/512 - 0s - loss: 1.0384e-04 - val_loss: 1.0435e-06
Epoch 191/512
512/512 - 0s - loss: 9.9766e-05 - val_loss: 1.0087e-06
Epoch 192/512
512/512 - 0s - loss: 9.6349e-05 - val_loss: 1.0036e-06
Epoch 193/512
512/512 - 0s - loss: 9.5980e-05 - val_loss: 9.8009e-07
Epoch 194/512
512/512 - 0s - loss: 9.3015e-05 - val_loss: 9.2521e-07
Epoch 195/512
512/512 - 0s - loss: 8.8771e-05 - val_loss: 8.9845e-07
Epoch 196/512
512/512 - 0s - loss: 8.7085e-05 - val_loss: 8.9872e-07
Epoch 197/512
512/512 - 0s - loss: 8.5402e-05 - val_loss: 8.7799e-07
Epoch 198/512
512/512 - 0s - loss: 8.3686e-05 - val_loss: 8.3092e-07
Epoch 199/512
512/512 - 0s - loss: 7.9792e-05 - val_loss: 7.9583e-07
Epoch 200/512
512/512 - 0s - loss: 7.7518e-05 - val_loss: 7.8554e-07
Epoch 201/512
512/512 - 0s - loss: 7.5607e-05 - val_loss: 7.8712e-07
Epoch 202/512
512/512 - 0s - loss: 7.5106e-05 - val_loss: 7.5514e-07
Epoch 203/512
512/512 - 0s - loss: 7.1561e-05 - val_loss: 7.1326e-07
Epoch 204/512
512/512 - 0s - loss: 6.8451e-05 - val_loss: 7.1354e-07
Epoch 205/512
512/512 - 0s - loss: 6.8964e-05 - val_loss: 6.9320e-07
Epoch 206/512
512/512 - 0s - loss: 6.5482e-05 - val_loss: 6.5646e-07
Epoch 207/512
512/512 - 0s - loss: 6.2858e-05 - val_loss: 6.5375e-07
Epoch 208/512
512/512 - 0s - loss: 6.2833e-05 - val_loss: 6.3694e-07
Epoch 209/512
512/512 - 0s - loss: 5.9740e-05 - val_loss: 6.1566e-07
Epoch 210/512
512/512 - 0s - loss: 5.8744e-05 - val_loss: 5.9101e-07
Epoch 211/512
512/512 - 0s - loss: 5.6330e-05 - val_loss: 5.7052e-07
Epoch 212/512
512/512 - 0s - loss: 5.4450e-05 - val_loss: 5.6589e-07
Epoch 213/512
512/512 - 0s - loss: 5.4065e-05 - val_loss: 5.4717e-07
Epoch 214/512
512/512 - 0s - loss: 5.1786e-05 - val_loss: 5.1609e-07
Epoch 215/512
512/512 - 0s - loss: 4.9370e-05 - val_loss: 5.0455e-07
Epoch 216/512
512/512 - 0s - loss: 4.8369e-05 - val_loss: 5.0651e-07
Epoch 217/512
512/512 - 0s - loss: 4.7987e-05 - val_loss: 4.8302e-07
Epoch 218/512
512/512 - 0s - loss: 4.5094e-05 - val_loss: 4.5817e-07
Epoch 219/512
512/512 - 0s - loss: 4.4022e-05 - val_loss: 4.4857e-07
Epoch 220/512
512/512 - 0s - loss: 4.2506e-05 - val_loss: 4.4744e-07
Epoch 221/512
512/512 - 0s - loss: 4.2153e-05 - val_loss: 4.2961e-07
Epoch 222/512
512/512 - 0s - loss: 4.0031e-05 - val_loss: 4.0626e-07
Epoch 223/512
512/512 - 0s - loss: 3.8440e-05 - val_loss: 3.9976e-07
Epoch 224/512
512/512 - 0s - loss: 3.8127e-05 - val_loss: 3.8716e-07
Epoch 225/512
512/512 - 0s - loss: 3.6572e-05 - val_loss: 3.6382e-07
Epoch 226/512
512/512 - 0s - loss: 3.4585e-05 - val_loss: 3.6044e-07
Epoch 227/512
512/512 - 0s - loss: 3.4541e-05 - val_loss: 3.5076e-07
Epoch 228/512
512/512 - 0s - loss: 3.3165e-05 - val_loss: 3.3182e-07
Epoch 229/512
512/512 - 0s - loss: 3.1454e-05 - val_loss: 3.2858e-07
Epoch 230/512
512/512 - 0s - loss: 3.1050e-05 - val_loss: 3.2369e-07
Epoch 231/512
512/512 - 0s - loss: 3.0448e-05 - val_loss: 3.0217e-07
Epoch 232/512
512/512 - 0s - loss: 2.8349e-05 - val_loss: 2.8928e-07
Epoch 233/512
512/512 - 0s - loss: 2.7881e-05 - val_loss: 2.8749e-07
Epoch 234/512
512/512 - 0s - loss: 2.7155e-05 - val_loss: 2.7953e-07
Epoch 235/512
512/512 - 0s - loss: 2.6191e-05 - val_loss: 2.6596e-07
Epoch 236/512
512/512 - 0s - loss: 2.5131e-05 - val_loss: 2.5506e-07
Epoch 237/512
512/512 - 0s - loss: 2.4240e-05 - val_loss: 2.5111e-07
Epoch 238/512
512/512 - 0s - loss: 2.3734e-05 - val_loss: 2.4284e-07
Epoch 239/512
512/512 - 0s - loss: 2.2795e-05 - val_loss: 2.3092e-07
Epoch 240/512
512/512 - 0s - loss: 2.1762e-05 - val_loss: 2.2441e-07
Epoch 241/512
512/512 - 0s - loss: 2.1222e-05 - val_loss: 2.2019e-07
Epoch 242/512
512/512 - 0s - loss: 2.0620e-05 - val_loss: 2.1052e-07
Epoch 243/512
512/512 - 0s - loss: 1.9751e-05 - val_loss: 2.0015e-07
Epoch 244/512
512/512 - 0s - loss: 1.8913e-05 - val_loss: 1.9578e-07
Epoch 245/512
512/512 - 0s - loss: 1.8492e-05 - val_loss: 1.9127e-07
Epoch 246/512
512/512 - 0s - loss: 1.7913e-05 - val_loss: 1.8182e-07
Epoch 247/512
512/512 - 0s - loss: 1.6964e-05 - val_loss: 1.7614e-07
Epoch 248/512
512/512 - 0s - loss: 1.6464e-05 - val_loss: 1.7373e-07
Epoch 249/512
512/512 - 0s - loss: 1.6302e-05 - val_loss: 1.6398e-07
Epoch 250/512
512/512 - 0s - loss: 1.5159e-05 - val_loss: 1.5643e-07
Epoch 251/512
512/512 - 0s - loss: 1.4901e-05 - val_loss: 1.5157e-07
Epoch 252/512
512/512 - 0s - loss: 1.4208e-05 - val_loss: 1.4753e-07
Epoch 253/512
512/512 - 0s - loss: 1.3978e-05 - val_loss: 1.4135e-07
Epoch 254/512
512/512 - 0s - loss: 1.3064e-05 - val_loss: 1.3724e-07
Epoch 255/512
512/512 - 0s - loss: 1.2950e-05 - val_loss: 1.3425e-07
Epoch 256/512
512/512 - 0s - loss: 1.2481e-05 - val_loss: 1.2512e-07
Epoch 257/512
512/512 - 0s - loss: 1.1743e-05 - val_loss: 1.1996e-07
Epoch 258/512
512/512 - 0s - loss: 1.1289e-05 - val_loss: 1.2142e-07
Epoch 259/512
512/512 - 0s - loss: 1.1385e-05 - val_loss: 1.1647e-07
Epoch 260/512
512/512 - 0s - loss: 1.0563e-05 - val_loss: 1.0822e-07
Epoch 261/512
512/512 - 0s - loss: 1.0133e-05 - val_loss: 1.0563e-07
Epoch 262/512
512/512 - 0s - loss: 9.9934e-06 - val_loss: 1.0234e-07
Epoch 263/512
512/512 - 0s - loss: 9.4855e-06 - val_loss: 9.7281e-08
Epoch 264/512
512/512 - 0s - loss: 9.2011e-06 - val_loss: 9.1512e-08
Epoch 265/512
512/512 - 0s - loss: 8.5853e-06 - val_loss: 9.1197e-08
Epoch 266/512
512/512 - 0s - loss: 8.5594e-06 - val_loss: 9.1484e-08
Epoch 267/512
512/512 - 0s - loss: 8.4262e-06 - val_loss: 8.2632e-08
Epoch 268/512
512/512 - 0s - loss: 7.5820e-06 - val_loss: 7.8000e-08
Epoch 269/512
512/512 - 0s - loss: 7.4770e-06 - val_loss: 8.0643e-08
Epoch 270/512
512/512 - 0s - loss: 7.4784e-06 - val_loss: 7.6790e-08
Epoch 271/512
512/512 - 0s - loss: 6.9701e-06 - val_loss: 7.0824e-08
Epoch 272/512
512/512 - 0s - loss: 6.6185e-06 - val_loss: 6.9252e-08
Epoch 273/512
512/512 - 0s - loss: 6.4954e-06 - val_loss: 6.7888e-08
Epoch 274/512
512/512 - 0s - loss: 6.2853e-06 - val_loss: 6.4322e-08
Epoch 275/512
512/512 - 0s - loss: 5.9573e-06 - val_loss: 6.0524e-08
Epoch 276/512
512/512 - 0s - loss: 5.6275e-06 - val_loss: 6.0475e-08
Epoch 277/512
512/512 - 0s - loss: 5.6404e-06 - val_loss: 5.8614e-08
Epoch 278/512
512/512 - 0s - loss: 5.3218e-06 - val_loss: 5.4934e-08
Epoch 279/512
512/512 - 0s - loss: 5.0901e-06 - val_loss: 5.2227e-08
Epoch 280/512
512/512 - 0s - loss: 4.8538e-06 - val_loss: 5.0992e-08
Epoch 281/512
512/512 - 0s - loss: 4.7257e-06 - val_loss: 4.9964e-08
Epoch 282/512
512/512 - 0s - loss: 4.6134e-06 - val_loss: 4.6211e-08
Epoch 283/512
512/512 - 0s - loss: 4.2517e-06 - val_loss: 4.4441e-08
Epoch 284/512
512/512 - 0s - loss: 4.1644e-06 - val_loss: 4.4370e-08
Epoch 285/512
512/512 - 0s - loss: 4.0593e-06 - val_loss: 4.2470e-08
Epoch 286/512
512/512 - 0s - loss: 3.8673e-06 - val_loss: 4.0027e-08
Epoch 287/512
512/512 - 0s - loss: 3.6530e-06 - val_loss: 3.8544e-08
Epoch 288/512
512/512 - 0s - loss: 3.5826e-06 - val_loss: 3.6831e-08
Epoch 289/512
512/512 - 0s - loss: 3.4098e-06 - val_loss: 3.4932e-08
Epoch 290/512
512/512 - 0s - loss: 3.2561e-06 - val_loss: 3.3629e-08
Epoch 291/512
512/512 - 0s - loss: 3.1292e-06 - val_loss: 3.2854e-08
Epoch 292/512
512/512 - 0s - loss: 3.0387e-06 - val_loss: 3.1625e-08
Epoch 293/512
512/512 - 0s - loss: 2.9059e-06 - val_loss: 2.9480e-08
Epoch 294/512
512/512 - 0s - loss: 2.7411e-06 - val_loss: 2.8567e-08
Epoch 295/512
512/512 - 0s - loss: 2.6670e-06 - val_loss: 2.7817e-08
Epoch 296/512
512/512 - 0s - loss: 2.5647e-06 - val_loss: 2.6681e-08
Epoch 297/512
512/512 - 0s - loss: 2.4516e-06 - val_loss: 2.5354e-08
Epoch 298/512
512/512 - 0s - loss: 2.3289e-06 - val_loss: 2.4626e-08
Epoch 299/512
512/512 - 0s - loss: 2.2516e-06 - val_loss: 2.3988e-08
Epoch 300/512
512/512 - 0s - loss: 2.1802e-06 - val_loss: 2.2875e-08
Epoch 301/512
512/512 - 0s - loss: 2.0697e-06 - val_loss: 2.1574e-08
Epoch 302/512
512/512 - 0s - loss: 1.9749e-06 - val_loss: 2.0812e-08
Epoch 303/512
512/512 - 0s - loss: 1.9004e-06 - val_loss: 2.0101e-08
Epoch 304/512
512/512 - 0s - loss: 1.8397e-06 - val_loss: 1.9209e-08
Epoch 305/512
512/512 - 0s - loss: 1.7347e-06 - val_loss: 1.8307e-08
Epoch 306/512
512/512 - 0s - loss: 1.6717e-06 - val_loss: 1.7936e-08
Epoch 307/512
512/512 - 0s - loss: 1.6350e-06 - val_loss: 1.6782e-08
Epoch 308/512
512/512 - 0s - loss: 1.5274e-06 - val_loss: 1.5661e-08
Epoch 309/512
512/512 - 0s - loss: 1.4377e-06 - val_loss: 1.5724e-08
Epoch 310/512
512/512 - 0s - loss: 1.4509e-06 - val_loss: 1.5139e-08
Epoch 311/512
512/512 - 0s - loss: 1.3691e-06 - val_loss: 1.3494e-08
Epoch 312/512
512/512 - 0s - loss: 1.2433e-06 - val_loss: 1.3340e-08
Epoch 313/512
512/512 - 0s - loss: 1.2503e-06 - val_loss: 1.3536e-08
Epoch 314/512
512/512 - 0s - loss: 1.2365e-06 - val_loss: 1.2172e-08
Epoch 315/512
512/512 - 0s - loss: 1.0937e-06 - val_loss: 1.1487e-08
Epoch 316/512
512/512 - 0s - loss: 1.0722e-06 - val_loss: 1.1870e-08
Epoch 317/512
512/512 - 0s - loss: 1.0882e-06 - val_loss: 1.1182e-08
Epoch 318/512
512/512 - 0s - loss: 9.9619e-07 - val_loss: 9.9047e-09
Epoch 319/512
512/512 - 0s - loss: 9.0725e-07 - val_loss: 1.0059e-08
Epoch 320/512
512/512 - 0s - loss: 9.3994e-07 - val_loss: 1.0133e-08
Epoch 321/512
512/512 - 0s - loss: 8.9502e-07 - val_loss: 9.0823e-09
Epoch 322/512
512/512 - 0s - loss: 8.0666e-07 - val_loss: 8.7038e-09
Epoch 323/512
512/512 - 0s - loss: 8.0473e-07 - val_loss: 8.7163e-09
Epoch 324/512
512/512 - 0s - loss: 7.8649e-07 - val_loss: 8.0804e-09
Epoch 325/512
512/512 - 0s - loss: 7.2282e-07 - val_loss: 7.4726e-09
Epoch 326/512
512/512 - 0s - loss: 6.9195e-07 - val_loss: 7.4131e-09
Epoch 327/512
512/512 - 0s - loss: 6.7409e-07 - val_loss: 7.2688e-09
Epoch 328/512
512/512 - 0s - loss: 6.5027e-07 - val_loss: 6.7748e-09
Epoch 329/512
512/512 - 0s - loss: 6.0910e-07 - val_loss: 6.3388e-09
Epoch 330/512
512/512 - 0s - loss: 5.8092e-07 - val_loss: 6.2009e-09
Epoch 331/512
512/512 - 0s - loss: 5.6346e-07 - val_loss: 6.0003e-09
Epoch 332/512
512/512 - 0s - loss: 5.3899e-07 - val_loss: 5.6683e-09
Epoch 333/512
512/512 - 0s - loss: 5.1029e-07 - val_loss: 5.3694e-09
Epoch 334/512
512/512 - 0s - loss: 4.8755e-07 - val_loss: 5.1842e-09
Epoch 335/512
512/512 - 0s - loss: 4.7324e-07 - val_loss: 4.9168e-09
Epoch 336/512
512/512 - 0s - loss: 4.4095e-07 - val_loss: 4.7403e-09
Epoch 337/512
512/512 - 0s - loss: 4.3238e-07 - val_loss: 4.5602e-09
Epoch 338/512
512/512 - 0s - loss: 4.0544e-07 - val_loss: 4.3654e-09
Epoch 339/512
512/512 - 0s - loss: 3.9264e-07 - val_loss: 4.1660e-09
Epoch 340/512
512/512 - 0s - loss: 3.7540e-07 - val_loss: 3.9051e-09
Epoch 341/512
512/512 - 0s - loss: 3.5149e-07 - val_loss: 3.7601e-09
Epoch 342/512
512/512 - 0s - loss: 3.4052e-07 - val_loss: 3.6808e-09
Epoch 343/512
512/512 - 0s - loss: 3.2944e-07 - val_loss: 3.4823e-09
Epoch 344/512
512/512 - 0s - loss: 3.0726e-07 - val_loss: 3.3083e-09
Epoch 345/512
512/512 - 0s - loss: 2.9798e-07 - val_loss: 3.1933e-09
Epoch 346/512
512/512 - 0s - loss: 2.8519e-07 - val_loss: 2.9947e-09
Epoch 347/512
512/512 - 0s - loss: 2.6690e-07 - val_loss: 2.8706e-09
Epoch 348/512
512/512 - 0s - loss: 2.6005e-07 - val_loss: 2.7804e-09
Epoch 349/512
512/512 - 0s - loss: 2.4883e-07 - val_loss: 2.6096e-09
Epoch 350/512
512/512 - 0s - loss: 2.3140e-07 - val_loss: 2.5098e-09
Epoch 351/512
512/512 - 0s - loss: 2.2506e-07 - val_loss: 2.4711e-09
Epoch 352/512
512/512 - 0s - loss: 2.1991e-07 - val_loss: 2.2962e-09
Epoch 353/512
512/512 - 0s - loss: 2.0168e-07 - val_loss: 2.1643e-09
Epoch 354/512
512/512 - 0s - loss: 1.9386e-07 - val_loss: 2.1390e-09
Epoch 355/512
512/512 - 0s - loss: 1.9021e-07 - val_loss: 2.0246e-09
Epoch 356/512
512/512 - 0s - loss: 1.7864e-07 - val_loss: 1.8733e-09
Epoch 357/512
512/512 - 0s - loss: 1.6668e-07 - val_loss: 1.8272e-09
Epoch 358/512
512/512 - 0s - loss: 1.6378e-07 - val_loss: 1.7871e-09
Epoch 359/512
512/512 - 0s - loss: 1.5690e-07 - val_loss: 1.6615e-09
Epoch 360/512
512/512 - 0s - loss: 1.4603e-07 - val_loss: 1.5649e-09
Epoch 361/512
512/512 - 0s - loss: 1.4065e-07 - val_loss: 1.5317e-09
Epoch 362/512
512/512 - 0s - loss: 1.3567e-07 - val_loss: 1.4597e-09
Epoch 363/512
512/512 - 0s - loss: 1.2764e-07 - val_loss: 1.3995e-09
Epoch 364/512
512/512 - 0s - loss: 1.2363e-07 - val_loss: 1.3298e-09
Epoch 365/512
512/512 - 0s - loss: 1.1691e-07 - val_loss: 1.2514e-09
Epoch 366/512
512/512 - 0s - loss: 1.1164e-07 - val_loss: 1.1852e-09
Epoch 367/512
512/512 - 0s - loss: 1.0489e-07 - val_loss: 1.1551e-09
Epoch 368/512
512/512 - 0s - loss: 1.0263e-07 - val_loss: 1.1221e-09
Epoch 369/512
512/512 - 0s - loss: 9.7524e-08 - val_loss: 1.0499e-09
Epoch 370/512
512/512 - 0s - loss: 9.1854e-08 - val_loss: 9.9220e-10
Epoch 371/512
512/512 - 0s - loss: 8.8605e-08 - val_loss: 9.4013e-10
Epoch 372/512
512/512 - 0s - loss: 8.2472e-08 - val_loss: 9.1848e-10
Epoch 373/512
512/512 - 0s - loss: 8.0808e-08 - val_loss: 9.0384e-10
Epoch 374/512
512/512 - 0s - loss: 7.8509e-08 - val_loss: 8.3086e-10
Epoch 375/512
512/512 - 0s - loss: 7.2087e-08 - val_loss: 7.7217e-10
Epoch 376/512
512/512 - 0s - loss: 6.8638e-08 - val_loss: 7.5889e-10
Epoch 377/512
512/512 - 0s - loss: 6.7342e-08 - val_loss: 7.3776e-10
Epoch 378/512
512/512 - 0s - loss: 6.3620e-08 - val_loss: 6.9345e-10
Epoch 379/512
512/512 - 0s - loss: 6.0595e-08 - val_loss: 6.4956e-10
Epoch 380/512
512/512 - 0s - loss: 5.6960e-08 - val_loss: 6.2783e-10
Epoch 381/512
512/512 - 0s - loss: 5.5407e-08 - val_loss: 6.0441e-10
Epoch 382/512
512/512 - 0s - loss: 5.2801e-08 - val_loss: 5.7069e-10
Epoch 383/512
512/512 - 0s - loss: 4.9806e-08 - val_loss: 5.4376e-10
Epoch 384/512
512/512 - 0s - loss: 4.8194e-08 - val_loss: 5.1849e-10
Epoch 385/512
512/512 - 0s - loss: 4.5200e-08 - val_loss: 4.9496e-10
Epoch 386/512
512/512 - 0s - loss: 4.3474e-08 - val_loss: 4.8047e-10
Epoch 387/512
512/512 - 0s - loss: 4.1895e-08 - val_loss: 4.6088e-10
Epoch 388/512
512/512 - 0s - loss: 3.9755e-08 - val_loss: 4.3394e-10
Epoch 389/512
512/512 - 0s - loss: 3.7754e-08 - val_loss: 4.1210e-10
Epoch 390/512
512/512 - 0s - loss: 3.5825e-08 - val_loss: 3.9833e-10
Epoch 391/512
512/512 - 0s - loss: 3.4840e-08 - val_loss: 3.8197e-10
Epoch 392/512
512/512 - 0s - loss: 3.2917e-08 - val_loss: 3.6319e-10
Epoch 393/512
512/512 - 0s - loss: 3.1297e-08 - val_loss: 3.4523e-10
Epoch 394/512
512/512 - 0s - loss: 2.9977e-08 - val_loss: 3.3124e-10
Epoch 395/512
512/512 - 0s - loss: 2.8697e-08 - val_loss: 3.1717e-10
Epoch 396/512
512/512 - 0s - loss: 2.7565e-08 - val_loss: 3.0061e-10
Epoch 397/512
512/512 - 0s - loss: 2.5847e-08 - val_loss: 2.8942e-10
Epoch 398/512
512/512 - 0s - loss: 2.5228e-08 - val_loss: 2.7965e-10
Epoch 399/512
512/512 - 0s - loss: 2.4016e-08 - val_loss: 2.6104e-10
Epoch 400/512
512/512 - 0s - loss: 2.2419e-08 - val_loss: 2.5217e-10
Epoch 401/512
512/512 - 0s - loss: 2.1824e-08 - val_loss: 2.4560e-10
Epoch 402/512
512/512 - 0s - loss: 2.1155e-08 - val_loss: 2.3495e-10
Epoch 403/512
512/512 - 0s - loss: 1.9945e-08 - val_loss: 2.2007e-10
Epoch 404/512
512/512 - 0s - loss: 1.8794e-08 - val_loss: 2.1174e-10
Epoch 405/512
512/512 - 0s - loss: 1.8364e-08 - val_loss: 2.0318e-10
Epoch 406/512
512/512 - 0s - loss: 1.7431e-08 - val_loss: 1.9342e-10
Epoch 407/512
512/512 - 0s - loss: 1.6464e-08 - val_loss: 1.8784e-10
Epoch 408/512
512/512 - 0s - loss: 1.6093e-08 - val_loss: 1.8219e-10
Epoch 409/512
512/512 - 0s - loss: 1.5494e-08 - val_loss: 1.7076e-10
Epoch 410/512
512/512 - 0s - loss: 1.4476e-08 - val_loss: 1.6282e-10
Epoch 411/512
512/512 - 0s - loss: 1.3857e-08 - val_loss: 1.5942e-10
Epoch 412/512
512/512 - 0s - loss: 1.3495e-08 - val_loss: 1.5379e-10
Epoch 413/512
512/512 - 0s - loss: 1.3044e-08 - val_loss: 1.4573e-10
Epoch 414/512
512/512 - 0s - loss: 1.2278e-08 - val_loss: 1.3719e-10
Epoch 415/512
512/512 - 0s - loss: 1.1705e-08 - val_loss: 1.3176e-10
Epoch 416/512
512/512 - 0s - loss: 1.1231e-08 - val_loss: 1.2792e-10
Epoch 417/512
512/512 - 0s - loss: 1.0789e-08 - val_loss: 1.2652e-10
Epoch 418/512
512/512 - 0s - loss: 1.0623e-08 - val_loss: 1.2006e-10
Epoch 419/512
512/512 - 0s - loss: 1.0099e-08 - val_loss: 1.1226e-10
Epoch 420/512
512/512 - 0s - loss: 9.4275e-09 - val_loss: 1.0728e-10
Epoch 421/512
512/512 - 0s - loss: 9.0583e-09 - val_loss: 1.0594e-10
Epoch 422/512
512/512 - 0s - loss: 8.9045e-09 - val_loss: 1.0397e-10
Epoch 423/512
512/512 - 0s - loss: 8.6295e-09 - val_loss: 9.9048e-11
Epoch 424/512
512/512 - 0s - loss: 8.2416e-09 - val_loss: 9.3471e-11
Epoch 425/512
512/512 - 0s - loss: 7.7499e-09 - val_loss: 8.8883e-11
Epoch 426/512
512/512 - 0s - loss: 7.4587e-09 - val_loss: 8.6405e-11
Epoch 427/512
512/512 - 0s - loss: 7.3076e-09 - val_loss: 8.3755e-11
Epoch 428/512
512/512 - 0s - loss: 6.9307e-09 - val_loss: 8.1384e-11
Epoch 429/512
512/512 - 0s - loss: 6.8743e-09 - val_loss: 7.7276e-11
Epoch 430/512
512/512 - 0s - loss: 6.3962e-09 - val_loss: 7.3145e-11
Epoch 431/512
512/512 - 0s - loss: 6.1427e-09 - val_loss: 7.1739e-11
Epoch 432/512
512/512 - 0s - loss: 5.9886e-09 - val_loss: 7.0448e-11
Epoch 433/512
512/512 - 0s - loss: 5.9038e-09 - val_loss: 6.7080e-11
Epoch 434/512
512/512 - 0s - loss: 5.5326e-09 - val_loss: 6.3058e-11
Epoch 435/512
512/512 - 0s - loss: 5.1713e-09 - val_loss: 6.1942e-11
Epoch 436/512
512/512 - 0s - loss: 5.1782e-09 - val_loss: 6.1759e-11
Epoch 437/512
512/512 - 0s - loss: 5.0710e-09 - val_loss: 5.9645e-11
Epoch 438/512
512/512 - 0s - loss: 4.8363e-09 - val_loss: 5.7410e-11
Epoch 439/512
512/512 - 0s - loss: 4.6557e-09 - val_loss: 5.4770e-11
Epoch 440/512
512/512 - 0s - loss: 4.4846e-09 - val_loss: 5.2273e-11
Epoch 441/512
512/512 - 0s - loss: 4.3217e-09 - val_loss: 5.0885e-11
Epoch 442/512
512/512 - 0s - loss: 4.1693e-09 - val_loss: 4.9656e-11
Epoch 443/512
512/512 - 0s - loss: 4.0783e-09 - val_loss: 4.8230e-11
Epoch 444/512
512/512 - 0s - loss: 3.9282e-09 - val_loss: 4.6074e-11
Epoch 445/512
512/512 - 0s - loss: 3.7773e-09 - val_loss: 4.4013e-11
Epoch 446/512
512/512 - 0s - loss: 3.5946e-09 - val_loss: 4.2315e-11
Epoch 447/512
512/512 - 0s - loss: 3.4416e-09 - val_loss: 4.2133e-11
Epoch 448/512
512/512 - 0s - loss: 3.4662e-09 - val_loss: 4.2308e-11
Epoch 449/512
512/512 - 0s - loss: 3.4049e-09 - val_loss: 4.0294e-11
Epoch 450/512
512/512 - 0s - loss: 3.2484e-09 - val_loss: 3.7886e-11
Epoch 451/512
512/512 - 0s - loss: 3.0671e-09 - val_loss: 3.6289e-11
Epoch 452/512
512/512 - 0s - loss: 2.9190e-09 - val_loss: 3.5954e-11
Epoch 453/512
512/512 - 0s - loss: 2.9308e-09 - val_loss: 3.5901e-11
Epoch 454/512
512/512 - 0s - loss: 2.8789e-09 - val_loss: 3.5017e-11
Epoch 455/512
512/512 - 0s - loss: 2.7952e-09 - val_loss: 3.3521e-11
Epoch 456/512
512/512 - 0s - loss: 2.6795e-09 - val_loss: 3.1919e-11
Epoch 457/512
512/512 - 0s - loss: 2.5661e-09 - val_loss: 3.0825e-11
Epoch 458/512
512/512 - 0s - loss: 2.4831e-09 - val_loss: 2.9919e-11
Epoch 459/512
512/512 - 0s - loss: 2.3979e-09 - val_loss: 2.9426e-11
Epoch 460/512
512/512 - 0s - loss: 2.3585e-09 - val_loss: 2.9144e-11
Epoch 461/512
512/512 - 0s - loss: 2.3136e-09 - val_loss: 2.8694e-11
Epoch 462/512
512/512 - 0s - loss: 2.2772e-09 - val_loss: 2.7663e-11
Epoch 463/512
512/512 - 0s - loss: 2.1452e-09 - val_loss: 2.6375e-11
Epoch 464/512
512/512 - 0s - loss: 2.0964e-09 - val_loss: 2.5740e-11
Epoch 465/512
512/512 - 0s - loss: 2.0297e-09 - val_loss: 2.5307e-11
Epoch 466/512
512/512 - 0s - loss: 2.0198e-09 - val_loss: 2.4635e-11
Epoch 467/512
512/512 - 0s - loss: 1.9459e-09 - val_loss: 2.4083e-11
Epoch 468/512
512/512 - 0s - loss: 1.8868e-09 - val_loss: 2.3431e-11
Epoch 469/512
512/512 - 0s - loss: 1.8264e-09 - val_loss: 2.3022e-11
Epoch 470/512
512/512 - 0s - loss: 1.7984e-09 - val_loss: 2.2756e-11
Epoch 471/512
512/512 - 0s - loss: 1.7907e-09 - val_loss: 2.1925e-11
Epoch 472/512
512/512 - 0s - loss: 1.6793e-09 - val_loss: 2.0964e-11
Epoch 473/512
512/512 - 0s - loss: 1.6260e-09 - val_loss: 2.0680e-11
Epoch 474/512
512/512 - 0s - loss: 1.6016e-09 - val_loss: 2.0556e-11
Epoch 475/512
512/512 - 0s - loss: 1.6002e-09 - val_loss: 1.9960e-11
Epoch 476/512
512/512 - 0s - loss: 1.5346e-09 - val_loss: 1.9420e-11
Epoch 477/512
512/512 - 0s - loss: 1.5072e-09 - val_loss: 1.8970e-11
Epoch 478/512
512/512 - 0s - loss: 1.4520e-09 - val_loss: 1.8244e-11
Epoch 479/512
512/512 - 0s - loss: 1.3973e-09 - val_loss: 1.8161e-11
Epoch 480/512
512/512 - 0s - loss: 1.4114e-09 - val_loss: 1.7951e-11
Epoch 481/512
512/512 - 0s - loss: 1.3724e-09 - val_loss: 1.7433e-11
Epoch 482/512
512/512 - 0s - loss: 1.3340e-09 - val_loss: 1.7218e-11
Epoch 483/512
512/512 - 0s - loss: 1.2921e-09 - val_loss: 1.6785e-11
Epoch 484/512
512/512 - 0s - loss: 1.2767e-09 - val_loss: 1.6594e-11
Epoch 485/512
512/512 - 0s - loss: 1.2630e-09 - val_loss: 1.6058e-11
Epoch 486/512
512/512 - 0s - loss: 1.1977e-09 - val_loss: 1.5538e-11
Epoch 487/512
512/512 - 0s - loss: 1.1794e-09 - val_loss: 1.5374e-11
Epoch 488/512
512/512 - 0s - loss: 1.1633e-09 - val_loss: 1.4901e-11
Epoch 489/512
512/512 - 0s - loss: 1.1176e-09 - val_loss: 1.4581e-11
Epoch 490/512
512/512 - 0s - loss: 1.0887e-09 - val_loss: 1.4192e-11
Epoch 491/512
512/512 - 0s - loss: 1.0779e-09 - val_loss: 1.4109e-11
Epoch 492/512
512/512 - 0s - loss: 1.0730e-09 - val_loss: 1.3851e-11
Epoch 493/512
512/512 - 0s - loss: 1.0313e-09 - val_loss: 1.3691e-11
Epoch 494/512
512/512 - 0s - loss: 1.0288e-09 - val_loss: 1.3247e-11
Epoch 495/512
512/512 - 0s - loss: 9.7375e-10 - val_loss: 1.2807e-11
Epoch 496/512
512/512 - 0s - loss: 9.4747e-10 - val_loss: 1.2713e-11
Epoch 497/512
512/512 - 0s - loss: 9.5563e-10 - val_loss: 1.2598e-11
Epoch 498/512
512/512 - 0s - loss: 9.2040e-10 - val_loss: 1.2285e-11
Epoch 499/512
512/512 - 0s - loss: 9.1165e-10 - val_loss: 1.2120e-11
Epoch 500/512
512/512 - 0s - loss: 9.0158e-10 - val_loss: 1.2084e-11
Epoch 501/512
512/512 - 0s - loss: 8.8867e-10 - val_loss: 1.1689e-11
Epoch 502/512
512/512 - 0s - loss: 8.6009e-10 - val_loss: 1.1226e-11
Epoch 503/512
512/512 - 0s - loss: 8.2580e-10 - val_loss: 1.1091e-11
Epoch 504/512
512/512 - 0s - loss: 8.0627e-10 - val_loss: 1.0799e-11
Epoch 505/512
512/512 - 0s - loss: 7.8842e-10 - val_loss: 1.0718e-11
Epoch 506/512
512/512 - 0s - loss: 7.6767e-10 - val_loss: 1.0524e-11
Epoch 507/512
512/512 - 0s - loss: 7.6350e-10 - val_loss: 1.0353e-11
Epoch 508/512
512/512 - 0s - loss: 7.5570e-10 - val_loss: 1.0269e-11
Epoch 509/512
512/512 - 0s - loss: 7.3854e-10 - val_loss: 1.0062e-11
Epoch 510/512
512/512 - 0s - loss: 7.2213e-10 - val_loss: 9.9024e-12
Epoch 511/512
512/512 - 0s - loss: 7.1591e-10 - val_loss: 9.7347e-12
Epoch 512/512
512/512 - 0s - loss: 7.0350e-10 - val_loss: 9.6423e-12
2024-04-13 16:35:45.598206: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
Train on 512 samples, validate on 512 samples
Epoch 1/512

Epoch 00001: val_loss improved from inf to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.0472e-09 - val_loss: 1.6327e-09
Epoch 2/512

Epoch 00002: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6855e-09 - val_loss: 1.6916e-09
Epoch 3/512

Epoch 00003: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.4005e-09 - val_loss: 1.0749e-09
Epoch 4/512

Epoch 00004: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 8.8994e-10 - val_loss: 7.2917e-10
Epoch 5/512

Epoch 00005: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 6.6423e-10 - val_loss: 6.4099e-10
Epoch 6/512

Epoch 00006: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.4790e-10 - val_loss: 7.3699e-10
Epoch 7/512

Epoch 00007: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8938e-10 - val_loss: 9.3958e-10
Epoch 8/512

Epoch 00008: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.5916e-10 - val_loss: 1.0513e-09
Epoch 9/512

Epoch 00009: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0182e-09 - val_loss: 1.0043e-09
Epoch 10/512

Epoch 00010: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.1621e-10 - val_loss: 8.4597e-10
Epoch 11/512

Epoch 00011: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8415e-10 - val_loss: 7.4988e-10
Epoch 12/512

Epoch 00012: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.1489e-10 - val_loss: 7.2828e-10
Epoch 13/512

Epoch 00013: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.2065e-10 - val_loss: 7.6767e-10
Epoch 14/512

Epoch 00014: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.6343e-10 - val_loss: 8.0873e-10
Epoch 15/512

Epoch 00015: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.9408e-10 - val_loss: 8.2375e-10
Epoch 16/512

Epoch 00016: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8526e-10 - val_loss: 7.7587e-10
Epoch 17/512

Epoch 00017: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.3823e-10 - val_loss: 7.3206e-10
Epoch 18/512

Epoch 00018: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.0251e-10 - val_loss: 7.0595e-10
Epoch 19/512

Epoch 00019: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.8376e-10 - val_loss: 6.9295e-10
Epoch 20/512

Epoch 00020: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.6744e-10 - val_loss: 6.7534e-10
Epoch 21/512

Epoch 00021: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5497e-10 - val_loss: 6.7230e-10
Epoch 22/512

Epoch 00022: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5590e-10 - val_loss: 6.7143e-10
Epoch 23/512

Epoch 00023: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5175e-10 - val_loss: 6.7119e-10
Epoch 24/512

Epoch 00024: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.4938e-10 - val_loss: 6.6664e-10
Epoch 25/512

Epoch 00025: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.4654e-10 - val_loss: 6.6073e-10
Epoch 26/512

Epoch 00026: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 6.3525e-10 - val_loss: 6.3161e-10
Epoch 27/512

Epoch 00027: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 6.0020e-10 - val_loss: 6.0575e-10
Epoch 28/512

Epoch 00028: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 5.8166e-10 - val_loss: 5.8961e-10
Epoch 29/512

Epoch 00029: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 5.6881e-10 - val_loss: 5.8440e-10
Epoch 30/512

Epoch 00030: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 5.7437e-10 - val_loss: 5.8106e-10
Epoch 31/512

Epoch 00031: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 5.6801e-10 - val_loss: 5.7999e-10
Epoch 32/512

Epoch 00032: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 5.6075e-10 - val_loss: 5.6562e-10
Epoch 33/512

Epoch 00033: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 5.5155e-10 - val_loss: 5.5935e-10
Epoch 34/512

Epoch 00034: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 5.3795e-10 - val_loss: 5.4734e-10
Epoch 35/512

Epoch 00035: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 5.2826e-10 - val_loss: 5.3042e-10
Epoch 36/512

Epoch 00036: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1381e-10 - val_loss: 5.3254e-10
Epoch 37/512

Epoch 00037: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 5.1491e-10 - val_loss: 5.1387e-10
Epoch 38/512

Epoch 00038: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 4.9694e-10 - val_loss: 5.0368e-10
Epoch 39/512

Epoch 00039: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 4.9076e-10 - val_loss: 5.0357e-10
Epoch 40/512

Epoch 00040: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 4.8516e-10 - val_loss: 4.8721e-10
Epoch 41/512

Epoch 00041: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 4.6938e-10 - val_loss: 4.7720e-10
Epoch 42/512

Epoch 00042: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 4.6445e-10 - val_loss: 4.7399e-10
Epoch 43/512

Epoch 00043: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7032e-10 - val_loss: 4.8591e-10
Epoch 44/512

Epoch 00044: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7255e-10 - val_loss: 4.7671e-10
Epoch 45/512

Epoch 00045: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 4.5659e-10 - val_loss: 4.5590e-10
Epoch 46/512

Epoch 00046: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 4.4154e-10 - val_loss: 4.4767e-10
Epoch 47/512

Epoch 00047: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3810e-10 - val_loss: 4.4828e-10
Epoch 48/512

Epoch 00048: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3929e-10 - val_loss: 4.5359e-10
Epoch 49/512

Epoch 00049: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 4.3744e-10 - val_loss: 4.3906e-10
Epoch 50/512

Epoch 00050: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 4.1965e-10 - val_loss: 4.1664e-10
Epoch 51/512

Epoch 00051: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0913e-10 - val_loss: 4.1871e-10
Epoch 52/512

Epoch 00052: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 4.0687e-10 - val_loss: 4.1024e-10
Epoch 53/512

Epoch 00053: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.9760e-10 - val_loss: 4.0548e-10
Epoch 54/512

Epoch 00054: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.9615e-10 - val_loss: 3.9564e-10
Epoch 55/512

Epoch 00055: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.8599e-10 - val_loss: 3.9376e-10
Epoch 56/512

Epoch 00056: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.7994e-10 - val_loss: 3.7960e-10
Epoch 57/512

Epoch 00057: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.6314e-10 - val_loss: 3.6893e-10
Epoch 58/512

Epoch 00058: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6245e-10 - val_loss: 3.6978e-10
Epoch 59/512

Epoch 00059: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6249e-10 - val_loss: 3.7349e-10
Epoch 60/512

Epoch 00060: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6671e-10 - val_loss: 3.7340e-10
Epoch 61/512

Epoch 00061: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6512e-10 - val_loss: 3.7475e-10
Epoch 62/512

Epoch 00062: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.6411e-10 - val_loss: 3.6438e-10
Epoch 63/512

Epoch 00063: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.4769e-10 - val_loss: 3.4431e-10
Epoch 64/512

Epoch 00064: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.3661e-10 - val_loss: 3.3783e-10
Epoch 65/512

Epoch 00065: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.2895e-10 - val_loss: 3.3554e-10
Epoch 66/512

Epoch 00066: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.2982e-10 - val_loss: 3.3518e-10
Epoch 67/512

Epoch 00067: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.2990e-10 - val_loss: 3.3103e-10
Epoch 68/512

Epoch 00068: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.2357e-10 - val_loss: 3.2497e-10
Epoch 69/512

Epoch 00069: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.1297e-10 - val_loss: 3.1965e-10
Epoch 70/512

Epoch 00070: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.1060e-10 - val_loss: 3.1651e-10
Epoch 71/512

Epoch 00071: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.1321e-10 - val_loss: 3.2332e-10
Epoch 72/512

Epoch 00072: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.1394e-10 - val_loss: 3.1601e-10
Epoch 73/512

Epoch 00073: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.1054e-10 - val_loss: 3.1567e-10
Epoch 74/512

Epoch 00074: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.0741e-10 - val_loss: 3.0894e-10
Epoch 75/512

Epoch 00075: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.9706e-10 - val_loss: 2.9357e-10
Epoch 76/512

Epoch 00076: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.8326e-10 - val_loss: 2.8843e-10
Epoch 77/512

Epoch 00077: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.8351e-10 - val_loss: 2.8470e-10
Epoch 78/512

Epoch 00078: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.7302e-10 - val_loss: 2.7006e-10
Epoch 79/512

Epoch 00079: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6658e-10 - val_loss: 2.7939e-10
Epoch 80/512

Epoch 00080: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7277e-10 - val_loss: 2.7492e-10
Epoch 81/512

Epoch 00081: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7385e-10 - val_loss: 2.8432e-10
Epoch 82/512

Epoch 00082: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8131e-10 - val_loss: 2.8907e-10
Epoch 83/512

Epoch 00083: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7928e-10 - val_loss: 2.7692e-10
Epoch 84/512

Epoch 00084: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.6585e-10 - val_loss: 2.6027e-10
Epoch 85/512

Epoch 00085: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.5090e-10 - val_loss: 2.5010e-10
Epoch 86/512

Epoch 00086: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.4376e-10 - val_loss: 2.4777e-10
Epoch 87/512

Epoch 00087: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4210e-10 - val_loss: 2.5309e-10
Epoch 88/512

Epoch 00088: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5195e-10 - val_loss: 2.5814e-10
Epoch 89/512

Epoch 00089: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.4826e-10 - val_loss: 2.4550e-10
Epoch 90/512

Epoch 00090: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4172e-10 - val_loss: 2.5235e-10
Epoch 91/512

Epoch 00091: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4901e-10 - val_loss: 2.4961e-10
Epoch 92/512

Epoch 00092: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4411e-10 - val_loss: 2.4735e-10
Epoch 93/512

Epoch 00093: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.4009e-10 - val_loss: 2.3733e-10
Epoch 94/512

Epoch 00094: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.2893e-10 - val_loss: 2.3334e-10
Epoch 95/512

Epoch 00095: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.2909e-10 - val_loss: 2.3111e-10
Epoch 96/512

Epoch 00096: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2675e-10 - val_loss: 2.3267e-10
Epoch 97/512

Epoch 00097: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.2818e-10 - val_loss: 2.2746e-10
Epoch 98/512

Epoch 00098: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.2107e-10 - val_loss: 2.2249e-10
Epoch 99/512

Epoch 00099: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.1575e-10 - val_loss: 2.1826e-10
Epoch 100/512

Epoch 00100: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1531e-10 - val_loss: 2.2074e-10
Epoch 101/512

Epoch 00101: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1680e-10 - val_loss: 2.2006e-10
Epoch 102/512

Epoch 00102: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1662e-10 - val_loss: 2.2038e-10
Epoch 103/512

Epoch 00103: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1526e-10 - val_loss: 2.1934e-10
Epoch 104/512

Epoch 00104: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.1450e-10 - val_loss: 2.1777e-10
Epoch 105/512

Epoch 00105: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.1323e-10 - val_loss: 2.1683e-10
Epoch 106/512

Epoch 00106: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.1293e-10 - val_loss: 2.1106e-10
Epoch 107/512

Epoch 00107: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.9922e-10 - val_loss: 1.9728e-10
Epoch 108/512

Epoch 00108: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9540e-10 - val_loss: 2.0067e-10
Epoch 109/512

Epoch 00109: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9646e-10 - val_loss: 1.9788e-10
Epoch 110/512

Epoch 00110: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.9296e-10 - val_loss: 1.9355e-10
Epoch 111/512

Epoch 00111: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.8960e-10 - val_loss: 1.8884e-10
Epoch 112/512

Epoch 00112: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8566e-10 - val_loss: 1.9296e-10
Epoch 113/512

Epoch 00113: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9379e-10 - val_loss: 2.0036e-10
Epoch 114/512

Epoch 00114: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9631e-10 - val_loss: 1.9700e-10
Epoch 115/512

Epoch 00115: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.8798e-10 - val_loss: 1.8622e-10
Epoch 116/512

Epoch 00116: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8430e-10 - val_loss: 1.8629e-10
Epoch 117/512

Epoch 00117: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.7890e-10 - val_loss: 1.7645e-10
Epoch 118/512

Epoch 00118: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7366e-10 - val_loss: 1.7994e-10
Epoch 119/512

Epoch 00119: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8199e-10 - val_loss: 1.8808e-10
Epoch 120/512

Epoch 00120: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8206e-10 - val_loss: 1.7877e-10
Epoch 121/512

Epoch 00121: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.7445e-10 - val_loss: 1.7568e-10
Epoch 122/512

Epoch 00122: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.6905e-10 - val_loss: 1.7307e-10
Epoch 123/512

Epoch 00123: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7178e-10 - val_loss: 1.7661e-10
Epoch 124/512

Epoch 00124: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.7309e-10 - val_loss: 1.7098e-10
Epoch 125/512

Epoch 00125: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.6468e-10 - val_loss: 1.5928e-10
Epoch 126/512

Epoch 00126: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5652e-10 - val_loss: 1.6291e-10
Epoch 127/512

Epoch 00127: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6145e-10 - val_loss: 1.6005e-10
Epoch 128/512

Epoch 00128: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5653e-10 - val_loss: 1.6009e-10
Epoch 129/512

Epoch 00129: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6166e-10 - val_loss: 1.7133e-10
Epoch 130/512

Epoch 00130: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7146e-10 - val_loss: 1.7550e-10
Epoch 131/512

Epoch 00131: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6776e-10 - val_loss: 1.6313e-10
Epoch 132/512

Epoch 00132: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.5619e-10 - val_loss: 1.5545e-10
Epoch 133/512

Epoch 00133: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.5015e-10 - val_loss: 1.5060e-10
Epoch 134/512

Epoch 00134: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.4884e-10 - val_loss: 1.4757e-10
Epoch 135/512

Epoch 00135: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.4463e-10 - val_loss: 1.4188e-10
Epoch 136/512

Epoch 00136: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4075e-10 - val_loss: 1.4737e-10
Epoch 137/512

Epoch 00137: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4968e-10 - val_loss: 1.5957e-10
Epoch 138/512

Epoch 00138: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5804e-10 - val_loss: 1.5820e-10
Epoch 139/512

Epoch 00139: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5389e-10 - val_loss: 1.5145e-10
Epoch 140/512

Epoch 00140: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4736e-10 - val_loss: 1.4944e-10
Epoch 141/512

Epoch 00141: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4530e-10 - val_loss: 1.4469e-10
Epoch 142/512

Epoch 00142: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.3840e-10 - val_loss: 1.3733e-10
Epoch 143/512

Epoch 00143: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3441e-10 - val_loss: 1.4009e-10
Epoch 144/512

Epoch 00144: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4064e-10 - val_loss: 1.4549e-10
Epoch 145/512

Epoch 00145: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4052e-10 - val_loss: 1.4208e-10
Epoch 146/512

Epoch 00146: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.4080e-10 - val_loss: 1.3918e-10
Epoch 147/512

Epoch 00147: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3757e-10 - val_loss: 1.3856e-10
Epoch 148/512

Epoch 00148: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.3474e-10 - val_loss: 1.3068e-10
Epoch 149/512

Epoch 00149: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3028e-10 - val_loss: 1.3682e-10
Epoch 150/512

Epoch 00150: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3224e-10 - val_loss: 1.3385e-10
Epoch 151/512

Epoch 00151: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.2910e-10 - val_loss: 1.2762e-10
Epoch 152/512

Epoch 00152: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2541e-10 - val_loss: 1.2956e-10
Epoch 153/512

Epoch 00153: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2928e-10 - val_loss: 1.3114e-10
Epoch 154/512

Epoch 00154: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3118e-10 - val_loss: 1.3668e-10
Epoch 155/512

Epoch 00155: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.3107e-10 - val_loss: 1.3088e-10
Epoch 156/512

Epoch 00156: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.2765e-10 - val_loss: 1.2750e-10
Epoch 157/512

Epoch 00157: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.2162e-10 - val_loss: 1.2138e-10
Epoch 158/512

Epoch 00158: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.1922e-10 - val_loss: 1.2088e-10
Epoch 159/512

Epoch 00159: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.1773e-10 - val_loss: 1.1893e-10
Epoch 160/512

Epoch 00160: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1611e-10 - val_loss: 1.2031e-10
Epoch 161/512

Epoch 00161: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1833e-10 - val_loss: 1.2178e-10
Epoch 162/512

Epoch 00162: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2107e-10 - val_loss: 1.2182e-10
Epoch 163/512

Epoch 00163: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.2071e-10 - val_loss: 1.1944e-10
Epoch 164/512

Epoch 00164: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.1577e-10 - val_loss: 1.1507e-10
Epoch 165/512

Epoch 00165: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1534e-10 - val_loss: 1.1788e-10
Epoch 166/512

Epoch 00166: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.1641e-10 - val_loss: 1.1337e-10
Epoch 167/512

Epoch 00167: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.1095e-10 - val_loss: 1.1049e-10
Epoch 168/512

Epoch 00168: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1021e-10 - val_loss: 1.1126e-10
Epoch 169/512

Epoch 00169: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1103e-10 - val_loss: 1.1326e-10
Epoch 170/512

Epoch 00170: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1407e-10 - val_loss: 1.1915e-10
Epoch 171/512

Epoch 00171: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1749e-10 - val_loss: 1.1756e-10
Epoch 172/512

Epoch 00172: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.1173e-10 - val_loss: 1.0797e-10
Epoch 173/512

Epoch 00173: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.0725e-10 - val_loss: 1.0758e-10
Epoch 174/512

Epoch 00174: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0768e-10 - val_loss: 1.0958e-10
Epoch 175/512

Epoch 00175: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.1040e-10 - val_loss: 1.1501e-10
Epoch 176/512

Epoch 00176: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.1113e-10 - val_loss: 1.0521e-10
Epoch 177/512

Epoch 00177: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.0322e-10 - val_loss: 1.0249e-10
Epoch 178/512

Epoch 00178: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 9.9925e-11 - val_loss: 1.0138e-10
Epoch 179/512

Epoch 00179: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 9.9497e-11 - val_loss: 9.9806e-11
Epoch 180/512

Epoch 00180: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 9.7572e-11 - val_loss: 9.9046e-11
Epoch 181/512

Epoch 00181: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.7359e-11 - val_loss: 9.9436e-11
Epoch 182/512

Epoch 00182: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 9.7392e-11 - val_loss: 9.8763e-11
Epoch 183/512

Epoch 00183: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 9.6420e-11 - val_loss: 9.4144e-11
Epoch 184/512

Epoch 00184: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 9.2939e-11 - val_loss: 9.2002e-11
Epoch 185/512

Epoch 00185: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 8.7232e-11 - val_loss: 8.4464e-11
Epoch 186/512

Epoch 00186: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.5173e-11 - val_loss: 8.7781e-11
Epoch 187/512

Epoch 00187: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.7743e-11 - val_loss: 9.1457e-11
Epoch 188/512

Epoch 00188: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.1347e-11 - val_loss: 9.2641e-11
Epoch 189/512

Epoch 00189: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.4046e-11 - val_loss: 9.6011e-11
Epoch 190/512

Epoch 00190: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.4180e-11 - val_loss: 9.2401e-11
Epoch 191/512

Epoch 00191: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.1311e-11 - val_loss: 9.2548e-11
Epoch 192/512

Epoch 00192: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.1296e-11 - val_loss: 9.2982e-11
Epoch 193/512

Epoch 00193: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.1174e-11 - val_loss: 9.5070e-11
Epoch 194/512

Epoch 00194: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.2528e-11 - val_loss: 8.9057e-11
Epoch 195/512

Epoch 00195: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.7204e-11 - val_loss: 8.4549e-11
Epoch 196/512

Epoch 00196: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 8.0899e-11 - val_loss: 7.7835e-11
Epoch 197/512

Epoch 00197: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.7280e-11 - val_loss: 7.8656e-11
Epoch 198/512

Epoch 00198: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8209e-11 - val_loss: 8.3326e-11
Epoch 199/512

Epoch 00199: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.3217e-11 - val_loss: 8.6507e-11
Epoch 200/512

Epoch 00200: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.5494e-11 - val_loss: 9.0022e-11
Epoch 201/512

Epoch 00201: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.7609e-11 - val_loss: 8.7086e-11
Epoch 202/512

Epoch 00202: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.4738e-11 - val_loss: 8.2090e-11
Epoch 203/512

Epoch 00203: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.1174e-11 - val_loss: 8.0652e-11
Epoch 204/512

Epoch 00204: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.9474e-11 - val_loss: 7.8621e-11
Epoch 205/512

Epoch 00205: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.9060e-11 - val_loss: 8.2241e-11
Epoch 206/512

Epoch 00206: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.3218e-11 - val_loss: 8.6665e-11
Epoch 207/512

Epoch 00207: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.6674e-11 - val_loss: 8.6751e-11
Epoch 208/512

Epoch 00208: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.6687e-11 - val_loss: 8.6576e-11
Epoch 209/512

Epoch 00209: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.3872e-11 - val_loss: 8.5468e-11
Epoch 210/512

Epoch 00210: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.5327e-11 - val_loss: 8.9033e-11
Epoch 211/512

Epoch 00211: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.6366e-11 - val_loss: 8.5394e-11
Epoch 212/512

Epoch 00212: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.4077e-11 - val_loss: 8.3596e-11
Epoch 213/512

Epoch 00213: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.0607e-11 - val_loss: 7.9297e-11
Epoch 214/512

Epoch 00214: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 7.7234e-11 - val_loss: 7.6880e-11
Epoch 215/512

Epoch 00215: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.7564e-11 - val_loss: 7.9093e-11
Epoch 216/512

Epoch 00216: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.7202e-11 - val_loss: 8.1109e-11
Epoch 217/512

Epoch 00217: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.1004e-11 - val_loss: 8.4445e-11
Epoch 218/512

Epoch 00218: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.4013e-11 - val_loss: 8.6556e-11
Epoch 219/512

Epoch 00219: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.3452e-11 - val_loss: 8.0164e-11
Epoch 220/512

Epoch 00220: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 7.7041e-11 - val_loss: 7.6421e-11
Epoch 221/512

Epoch 00221: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 7.4334e-11 - val_loss: 7.2410e-11
Epoch 222/512

Epoch 00222: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.0553e-11 - val_loss: 7.2674e-11
Epoch 223/512

Epoch 00223: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.3545e-11 - val_loss: 7.7356e-11
Epoch 224/512

Epoch 00224: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.7434e-11 - val_loss: 8.1773e-11
Epoch 225/512

Epoch 00225: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8970e-11 - val_loss: 7.7798e-11
Epoch 226/512

Epoch 00226: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8714e-11 - val_loss: 7.9122e-11
Epoch 227/512

Epoch 00227: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.6511e-11 - val_loss: 7.6573e-11
Epoch 228/512

Epoch 00228: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 7.3800e-11 - val_loss: 7.1057e-11
Epoch 229/512

Epoch 00229: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 6.9326e-11 - val_loss: 6.9381e-11
Epoch 230/512

Epoch 00230: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 6.7999e-11 - val_loss: 6.9048e-11
Epoch 231/512

Epoch 00231: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 6.7691e-11 - val_loss: 6.8532e-11
Epoch 232/512

Epoch 00232: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 6.8104e-11 - val_loss: 6.6719e-11
Epoch 233/512

Epoch 00233: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5249e-11 - val_loss: 6.9129e-11
Epoch 234/512

Epoch 00234: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.9420e-11 - val_loss: 7.1975e-11
Epoch 235/512

Epoch 00235: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.1038e-11 - val_loss: 7.3512e-11
Epoch 236/512

Epoch 00236: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.1837e-11 - val_loss: 7.0683e-11
Epoch 237/512

Epoch 00237: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 6.6930e-11 - val_loss: 6.3018e-11
Epoch 238/512

Epoch 00238: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.4049e-11 - val_loss: 6.8403e-11
Epoch 239/512

Epoch 00239: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.8869e-11 - val_loss: 6.9269e-11
Epoch 240/512

Epoch 00240: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.8977e-11 - val_loss: 7.0445e-11
Epoch 241/512

Epoch 00241: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.8672e-11 - val_loss: 6.8208e-11
Epoch 242/512

Epoch 00242: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.8460e-11 - val_loss: 6.9123e-11
Epoch 243/512

Epoch 00243: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.8469e-11 - val_loss: 7.0351e-11
Epoch 244/512

Epoch 00244: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.8777e-11 - val_loss: 6.8135e-11
Epoch 245/512

Epoch 00245: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.6281e-11 - val_loss: 6.7112e-11
Epoch 246/512

Epoch 00246: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.7118e-11 - val_loss: 6.7168e-11
Epoch 247/512

Epoch 00247: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5259e-11 - val_loss: 6.7683e-11
Epoch 248/512

Epoch 00248: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5363e-11 - val_loss: 6.3304e-11
Epoch 249/512

Epoch 00249: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5096e-11 - val_loss: 6.5975e-11
Epoch 250/512

Epoch 00250: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.3969e-11 - val_loss: 6.5838e-11
Epoch 251/512

Epoch 00251: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 6.4793e-11 - val_loss: 6.2709e-11
Epoch 252/512

Epoch 00252: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 5.9260e-11 - val_loss: 5.6211e-11
Epoch 253/512

Epoch 00253: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 5.3855e-11 - val_loss: 5.1385e-11
Epoch 254/512

Epoch 00254: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2234e-11 - val_loss: 5.5343e-11
Epoch 255/512

Epoch 00255: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.6668e-11 - val_loss: 6.1777e-11
Epoch 256/512

Epoch 00256: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.1409e-11 - val_loss: 6.3412e-11
Epoch 257/512

Epoch 00257: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.2627e-11 - val_loss: 6.4141e-11
Epoch 258/512

Epoch 00258: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5659e-11 - val_loss: 6.6871e-11
Epoch 259/512

Epoch 00259: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.4586e-11 - val_loss: 6.5011e-11
Epoch 260/512

Epoch 00260: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.3031e-11 - val_loss: 6.1289e-11
Epoch 261/512

Epoch 00261: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8825e-11 - val_loss: 5.5524e-11
Epoch 262/512

Epoch 00262: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 5.2840e-11 - val_loss: 5.0961e-11
Epoch 263/512

Epoch 00263: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2172e-11 - val_loss: 5.5034e-11
Epoch 264/512

Epoch 00264: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4937e-11 - val_loss: 5.7060e-11
Epoch 265/512

Epoch 00265: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7092e-11 - val_loss: 5.8578e-11
Epoch 266/512

Epoch 00266: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.9942e-11 - val_loss: 6.0304e-11
Epoch 267/512

Epoch 00267: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7515e-11 - val_loss: 5.3064e-11
Epoch 268/512

Epoch 00268: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 5.0571e-11 - val_loss: 4.9724e-11
Epoch 269/512

Epoch 00269: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1580e-11 - val_loss: 5.2322e-11
Epoch 270/512

Epoch 00270: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0580e-11 - val_loss: 5.0565e-11
Epoch 271/512

Epoch 00271: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2319e-11 - val_loss: 5.2912e-11
Epoch 272/512

Epoch 00272: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2061e-11 - val_loss: 5.5510e-11
Epoch 273/512

Epoch 00273: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.5968e-11 - val_loss: 5.7239e-11
Epoch 274/512

Epoch 00274: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.9362e-11 - val_loss: 6.0884e-11
Epoch 275/512

Epoch 00275: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8985e-11 - val_loss: 6.0741e-11
Epoch 276/512

Epoch 00276: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.9168e-11 - val_loss: 5.6782e-11
Epoch 277/512

Epoch 00277: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4781e-11 - val_loss: 5.2481e-11
Epoch 278/512

Epoch 00278: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0649e-11 - val_loss: 5.2208e-11
Epoch 279/512

Epoch 00279: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1447e-11 - val_loss: 4.9798e-11
Epoch 280/512

Epoch 00280: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9181e-11 - val_loss: 5.2170e-11
Epoch 281/512

Epoch 00281: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3235e-11 - val_loss: 5.3740e-11
Epoch 282/512

Epoch 00282: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2789e-11 - val_loss: 5.5708e-11
Epoch 283/512

Epoch 00283: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.6077e-11 - val_loss: 5.9683e-11
Epoch 284/512

Epoch 00284: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8600e-11 - val_loss: 5.6920e-11
Epoch 285/512

Epoch 00285: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 5.3129e-11 - val_loss: 4.9390e-11
Epoch 286/512

Epoch 00286: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9061e-11 - val_loss: 5.2044e-11
Epoch 287/512

Epoch 00287: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0833e-11 - val_loss: 5.0014e-11
Epoch 288/512

Epoch 00288: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9364e-11 - val_loss: 5.1076e-11
Epoch 289/512

Epoch 00289: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0402e-11 - val_loss: 4.9878e-11
Epoch 290/512

Epoch 00290: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 4.8902e-11 - val_loss: 4.6614e-11
Epoch 291/512

Epoch 00291: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 4.4652e-11 - val_loss: 4.2006e-11
Epoch 292/512

Epoch 00292: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.9958e-11 - val_loss: 3.8849e-11
Epoch 293/512

Epoch 00293: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9652e-11 - val_loss: 4.2661e-11
Epoch 294/512

Epoch 00294: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3643e-11 - val_loss: 4.7399e-11
Epoch 295/512

Epoch 00295: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8964e-11 - val_loss: 5.4498e-11
Epoch 296/512

Epoch 00296: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4485e-11 - val_loss: 5.3324e-11
Epoch 297/512

Epoch 00297: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1278e-11 - val_loss: 5.2419e-11
Epoch 298/512

Epoch 00298: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1750e-11 - val_loss: 5.0492e-11
Epoch 299/512

Epoch 00299: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9093e-11 - val_loss: 4.7047e-11
Epoch 300/512

Epoch 00300: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5693e-11 - val_loss: 4.6954e-11
Epoch 301/512

Epoch 00301: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7564e-11 - val_loss: 4.6701e-11
Epoch 302/512

Epoch 00302: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4783e-11 - val_loss: 4.3556e-11
Epoch 303/512

Epoch 00303: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2221e-11 - val_loss: 3.9493e-11
Epoch 304/512

Epoch 00304: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8837e-11 - val_loss: 4.1844e-11
Epoch 305/512

Epoch 00305: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3343e-11 - val_loss: 4.7259e-11
Epoch 306/512

Epoch 00306: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8092e-11 - val_loss: 4.8324e-11
Epoch 307/512

Epoch 00307: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6148e-11 - val_loss: 4.4760e-11
Epoch 308/512

Epoch 00308: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5860e-11 - val_loss: 4.6548e-11
Epoch 309/512

Epoch 00309: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5461e-11 - val_loss: 4.3957e-11
Epoch 310/512

Epoch 00310: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2454e-11 - val_loss: 4.0802e-11
Epoch 311/512

Epoch 00311: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2070e-11 - val_loss: 4.5224e-11
Epoch 312/512

Epoch 00312: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5394e-11 - val_loss: 4.7941e-11
Epoch 313/512

Epoch 00313: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9003e-11 - val_loss: 5.0879e-11
Epoch 314/512

Epoch 00314: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2113e-11 - val_loss: 5.2463e-11
Epoch 315/512

Epoch 00315: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1071e-11 - val_loss: 5.0095e-11
Epoch 316/512

Epoch 00316: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9483e-11 - val_loss: 4.8628e-11
Epoch 317/512

Epoch 00317: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7270e-11 - val_loss: 4.5168e-11
Epoch 318/512

Epoch 00318: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3598e-11 - val_loss: 4.3040e-11
Epoch 319/512

Epoch 00319: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1391e-11 - val_loss: 3.9229e-11
Epoch 320/512

Epoch 00320: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.8480e-11 - val_loss: 3.7500e-11
Epoch 321/512

Epoch 00321: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6451e-11 - val_loss: 3.8456e-11
Epoch 322/512

Epoch 00322: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8416e-11 - val_loss: 3.9357e-11
Epoch 323/512

Epoch 00323: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0997e-11 - val_loss: 4.3577e-11
Epoch 324/512

Epoch 00324: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4118e-11 - val_loss: 4.7083e-11
Epoch 325/512

Epoch 00325: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8683e-11 - val_loss: 5.1097e-11
Epoch 326/512

Epoch 00326: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1320e-11 - val_loss: 5.0329e-11
Epoch 327/512

Epoch 00327: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8564e-11 - val_loss: 4.6121e-11
Epoch 328/512

Epoch 00328: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4050e-11 - val_loss: 4.3190e-11
Epoch 329/512

Epoch 00329: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1159e-11 - val_loss: 3.9014e-11
Epoch 330/512

Epoch 00330: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8469e-11 - val_loss: 4.0356e-11
Epoch 331/512

Epoch 00331: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9839e-11 - val_loss: 3.8892e-11
Epoch 332/512

Epoch 00332: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8504e-11 - val_loss: 3.9104e-11
Epoch 333/512

Epoch 00333: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0418e-11 - val_loss: 4.2910e-11
Epoch 334/512

Epoch 00334: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2055e-11 - val_loss: 4.0298e-11
Epoch 335/512

Epoch 00335: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.8703e-11 - val_loss: 3.6312e-11
Epoch 336/512

Epoch 00336: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.4535e-11 - val_loss: 3.3386e-11
Epoch 337/512

Epoch 00337: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 3.1832e-11 - val_loss: 2.9766e-11
Epoch 338/512

Epoch 00338: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9682e-11 - val_loss: 3.1573e-11
Epoch 339/512

Epoch 00339: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2178e-11 - val_loss: 3.3748e-11
Epoch 340/512

Epoch 00340: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4109e-11 - val_loss: 3.7434e-11
Epoch 341/512

Epoch 00341: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7853e-11 - val_loss: 3.9705e-11
Epoch 342/512

Epoch 00342: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1691e-11 - val_loss: 4.3947e-11
Epoch 343/512

Epoch 00343: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2630e-11 - val_loss: 4.0889e-11
Epoch 344/512

Epoch 00344: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0014e-11 - val_loss: 4.1540e-11
Epoch 345/512

Epoch 00345: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1422e-11 - val_loss: 4.1149e-11
Epoch 346/512

Epoch 00346: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9603e-11 - val_loss: 3.8596e-11
Epoch 347/512

Epoch 00347: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6458e-11 - val_loss: 3.3432e-11
Epoch 348/512

Epoch 00348: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2467e-11 - val_loss: 3.1487e-11
Epoch 349/512

Epoch 00349: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.9895e-11 - val_loss: 2.8696e-11
Epoch 350/512

Epoch 00350: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8881e-11 - val_loss: 3.1557e-11
Epoch 351/512

Epoch 00351: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2117e-11 - val_loss: 3.3594e-11
Epoch 352/512

Epoch 00352: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5008e-11 - val_loss: 3.6904e-11
Epoch 353/512

Epoch 00353: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7981e-11 - val_loss: 4.2386e-11
Epoch 354/512

Epoch 00354: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2676e-11 - val_loss: 4.4098e-11
Epoch 355/512

Epoch 00355: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3765e-11 - val_loss: 4.3585e-11
Epoch 356/512

Epoch 00356: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2860e-11 - val_loss: 4.2755e-11
Epoch 357/512

Epoch 00357: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0737e-11 - val_loss: 3.8698e-11
Epoch 358/512

Epoch 00358: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7530e-11 - val_loss: 3.5485e-11
Epoch 359/512

Epoch 00359: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3848e-11 - val_loss: 3.3252e-11
Epoch 360/512

Epoch 00360: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.1792e-11 - val_loss: 2.9485e-11
Epoch 361/512

Epoch 00361: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.8748e-11 - val_loss: 2.8550e-11
Epoch 362/512

Epoch 00362: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9698e-11 - val_loss: 3.1411e-11
Epoch 363/512

Epoch 00363: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2006e-11 - val_loss: 3.1327e-11
Epoch 364/512

Epoch 00364: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9908e-11 - val_loss: 2.9054e-11
Epoch 365/512

Epoch 00365: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8654e-11 - val_loss: 3.0736e-11
Epoch 366/512

Epoch 00366: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.1934e-11 - val_loss: 3.3569e-11
Epoch 367/512

Epoch 00367: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5053e-11 - val_loss: 3.7753e-11
Epoch 368/512

Epoch 00368: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.8413e-11 - val_loss: 4.1583e-11
Epoch 369/512

Epoch 00369: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2221e-11 - val_loss: 4.1630e-11
Epoch 370/512

Epoch 00370: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9622e-11 - val_loss: 3.8646e-11
Epoch 371/512

Epoch 00371: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6825e-11 - val_loss: 3.5024e-11
Epoch 372/512

Epoch 00372: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4484e-11 - val_loss: 3.6117e-11
Epoch 373/512

Epoch 00373: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6894e-11 - val_loss: 3.8297e-11
Epoch 374/512

Epoch 00374: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6583e-11 - val_loss: 3.3672e-11
Epoch 375/512

Epoch 00375: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.2551e-11 - val_loss: 3.0273e-11
Epoch 376/512

Epoch 00376: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.9024e-11 - val_loss: 2.8085e-11
Epoch 377/512

Epoch 00377: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.7832e-11 - val_loss: 2.7268e-11
Epoch 378/512

Epoch 00378: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.5811e-11 - val_loss: 2.5127e-11
Epoch 379/512

Epoch 00379: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6420e-11 - val_loss: 2.7969e-11
Epoch 380/512

Epoch 00380: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8517e-11 - val_loss: 2.9071e-11
Epoch 381/512

Epoch 00381: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8961e-11 - val_loss: 3.1268e-11
Epoch 382/512

Epoch 00382: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.1996e-11 - val_loss: 3.4380e-11
Epoch 383/512

Epoch 00383: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5822e-11 - val_loss: 3.7559e-11
Epoch 384/512

Epoch 00384: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7924e-11 - val_loss: 3.7312e-11
Epoch 385/512

Epoch 00385: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6303e-11 - val_loss: 3.7805e-11
Epoch 386/512

Epoch 00386: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.7212e-11 - val_loss: 3.6932e-11
Epoch 387/512

Epoch 00387: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.6141e-11 - val_loss: 3.5571e-11
Epoch 388/512

Epoch 00388: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.4457e-11 - val_loss: 3.3126e-11
Epoch 389/512

Epoch 00389: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.1347e-11 - val_loss: 2.8681e-11
Epoch 390/512

Epoch 00390: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7695e-11 - val_loss: 2.5959e-11
Epoch 391/512

Epoch 00391: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.5016e-11 - val_loss: 2.4030e-11
Epoch 392/512

Epoch 00392: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4529e-11 - val_loss: 2.6394e-11
Epoch 393/512

Epoch 00393: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7454e-11 - val_loss: 2.9400e-11
Epoch 394/512

Epoch 00394: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8990e-11 - val_loss: 2.9133e-11
Epoch 395/512

Epoch 00395: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.0405e-11 - val_loss: 3.1980e-11
Epoch 396/512

Epoch 00396: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.0749e-11 - val_loss: 2.9762e-11
Epoch 397/512

Epoch 00397: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8828e-11 - val_loss: 2.8411e-11
Epoch 398/512

Epoch 00398: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7087e-11 - val_loss: 2.5390e-11
Epoch 399/512

Epoch 00399: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4925e-11 - val_loss: 2.4577e-11
Epoch 400/512

Epoch 00400: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6384e-11 - val_loss: 2.9112e-11
Epoch 401/512

Epoch 00401: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.9039e-11 - val_loss: 2.9653e-11
Epoch 402/512

Epoch 00402: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.1033e-11 - val_loss: 3.3880e-11
Epoch 403/512

Epoch 00403: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3689e-11 - val_loss: 3.4609e-11
Epoch 404/512

Epoch 00404: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.5467e-11 - val_loss: 3.5169e-11
Epoch 405/512

Epoch 00405: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.3754e-11 - val_loss: 3.2588e-11
Epoch 406/512

Epoch 00406: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.1595e-11 - val_loss: 2.9644e-11
Epoch 407/512

Epoch 00407: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8496e-11 - val_loss: 2.8172e-11
Epoch 408/512

Epoch 00408: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7521e-11 - val_loss: 2.5864e-11
Epoch 409/512

Epoch 00409: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4886e-11 - val_loss: 2.4587e-11
Epoch 410/512

Epoch 00410: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4201e-11 - val_loss: 2.4498e-11
Epoch 411/512

Epoch 00411: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5831e-11 - val_loss: 2.7837e-11
Epoch 412/512

Epoch 00412: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7919e-11 - val_loss: 2.6993e-11
Epoch 413/512

Epoch 00413: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5948e-11 - val_loss: 2.5259e-11
Epoch 414/512

Epoch 00414: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5345e-11 - val_loss: 2.6953e-11
Epoch 415/512

Epoch 00415: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7659e-11 - val_loss: 2.8742e-11
Epoch 416/512

Epoch 00416: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8499e-11 - val_loss: 2.7511e-11
Epoch 417/512

Epoch 00417: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6093e-11 - val_loss: 2.4958e-11
Epoch 418/512

Epoch 00418: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.4235e-11 - val_loss: 2.3681e-11
Epoch 419/512

Epoch 00419: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.2513e-11 - val_loss: 2.0723e-11
Epoch 420/512

Epoch 00420: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.0195e-11 - val_loss: 2.0195e-11
Epoch 421/512

Epoch 00421: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0325e-11 - val_loss: 2.2042e-11
Epoch 422/512

Epoch 00422: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3250e-11 - val_loss: 2.5035e-11
Epoch 423/512

Epoch 00423: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5258e-11 - val_loss: 2.7217e-11
Epoch 424/512

Epoch 00424: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7880e-11 - val_loss: 2.8495e-11
Epoch 425/512

Epoch 00425: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.8444e-11 - val_loss: 2.7241e-11
Epoch 426/512

Epoch 00426: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6001e-11 - val_loss: 2.5174e-11
Epoch 427/512

Epoch 00427: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4974e-11 - val_loss: 2.6612e-11
Epoch 428/512

Epoch 00428: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6813e-11 - val_loss: 2.7457e-11
Epoch 429/512

Epoch 00429: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7647e-11 - val_loss: 2.7202e-11
Epoch 430/512

Epoch 00430: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5523e-11 - val_loss: 2.4265e-11
Epoch 431/512

Epoch 00431: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4204e-11 - val_loss: 2.4296e-11
Epoch 432/512

Epoch 00432: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5597e-11 - val_loss: 2.7997e-11
Epoch 433/512

Epoch 00433: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.7712e-11 - val_loss: 2.6691e-11
Epoch 434/512

Epoch 00434: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.5125e-11 - val_loss: 2.4489e-11
Epoch 435/512

Epoch 00435: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4235e-11 - val_loss: 2.2692e-11
Epoch 436/512

Epoch 00436: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1728e-11 - val_loss: 2.0575e-11
Epoch 437/512

Epoch 00437: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 2.0051e-11 - val_loss: 2.0016e-11
Epoch 438/512

Epoch 00438: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.8704e-11 - val_loss: 1.7059e-11
Epoch 439/512

Epoch 00439: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.7134e-11 - val_loss: 1.6848e-11
Epoch 440/512

Epoch 00440: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.6543e-11 - val_loss: 1.6544e-11
Epoch 441/512

Epoch 00441: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.7827e-11 - val_loss: 1.9241e-11
Epoch 442/512

Epoch 00442: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9223e-11 - val_loss: 1.9725e-11
Epoch 443/512

Epoch 00443: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0504e-11 - val_loss: 2.1591e-11
Epoch 444/512

Epoch 00444: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2913e-11 - val_loss: 2.4832e-11
Epoch 445/512

Epoch 00445: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4473e-11 - val_loss: 2.4438e-11
Epoch 446/512

Epoch 00446: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4652e-11 - val_loss: 2.6313e-11
Epoch 447/512

Epoch 00447: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6863e-11 - val_loss: 2.7699e-11
Epoch 448/512

Epoch 00448: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6258e-11 - val_loss: 2.4742e-11
Epoch 449/512

Epoch 00449: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4729e-11 - val_loss: 2.4808e-11
Epoch 450/512

Epoch 00450: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4854e-11 - val_loss: 2.6437e-11
Epoch 451/512

Epoch 00451: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6534e-11 - val_loss: 2.5763e-11
Epoch 452/512

Epoch 00452: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4809e-11 - val_loss: 2.4477e-11
Epoch 453/512

Epoch 00453: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4026e-11 - val_loss: 2.3601e-11
Epoch 454/512

Epoch 00454: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2469e-11 - val_loss: 2.1158e-11
Epoch 455/512

Epoch 00455: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1187e-11 - val_loss: 2.1919e-11
Epoch 456/512

Epoch 00456: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0983e-11 - val_loss: 2.0239e-11
Epoch 457/512

Epoch 00457: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9929e-11 - val_loss: 2.0719e-11
Epoch 458/512

Epoch 00458: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1386e-11 - val_loss: 2.2250e-11
Epoch 459/512

Epoch 00459: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1413e-11 - val_loss: 2.0340e-11
Epoch 460/512

Epoch 00460: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9986e-11 - val_loss: 1.9495e-11
Epoch 461/512

Epoch 00461: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9179e-11 - val_loss: 1.9225e-11
Epoch 462/512

Epoch 00462: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8295e-11 - val_loss: 1.7112e-11
Epoch 463/512

Epoch 00463: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6816e-11 - val_loss: 1.6631e-11
Epoch 464/512

Epoch 00464: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.6537e-11 - val_loss: 1.6414e-11
Epoch 465/512

Epoch 00465: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6576e-11 - val_loss: 1.8031e-11
Epoch 466/512

Epoch 00466: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8447e-11 - val_loss: 2.0466e-11
Epoch 467/512

Epoch 00467: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0730e-11 - val_loss: 2.1016e-11
Epoch 468/512

Epoch 00468: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2256e-11 - val_loss: 2.4099e-11
Epoch 469/512

Epoch 00469: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4178e-11 - val_loss: 2.4633e-11
Epoch 470/512

Epoch 00470: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4598e-11 - val_loss: 2.6334e-11
Epoch 471/512

Epoch 00471: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6920e-11 - val_loss: 2.7249e-11
Epoch 472/512

Epoch 00472: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6166e-11 - val_loss: 2.4705e-11
Epoch 473/512

Epoch 00473: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4193e-11 - val_loss: 2.4239e-11
Epoch 474/512

Epoch 00474: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4057e-11 - val_loss: 2.2942e-11
Epoch 475/512

Epoch 00475: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1509e-11 - val_loss: 2.0497e-11
Epoch 476/512

Epoch 00476: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0113e-11 - val_loss: 2.0179e-11
Epoch 477/512

Epoch 00477: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1461e-11 - val_loss: 2.3483e-11
Epoch 478/512

Epoch 00478: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3812e-11 - val_loss: 2.4152e-11
Epoch 479/512

Epoch 00479: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4544e-11 - val_loss: 2.6830e-11
Epoch 480/512

Epoch 00480: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.6851e-11 - val_loss: 2.5795e-11
Epoch 481/512

Epoch 00481: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4659e-11 - val_loss: 2.3616e-11
Epoch 482/512

Epoch 00482: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2511e-11 - val_loss: 2.2364e-11
Epoch 483/512

Epoch 00483: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1121e-11 - val_loss: 1.9508e-11
Epoch 484/512

Epoch 00484: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9097e-11 - val_loss: 1.9393e-11
Epoch 485/512

Epoch 00485: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9362e-11 - val_loss: 1.9391e-11
Epoch 486/512

Epoch 00486: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8241e-11 - val_loss: 1.6480e-11
Epoch 487/512

Epoch 00487: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.5948e-11 - val_loss: 1.6337e-11
Epoch 488/512

Epoch 00488: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6377e-11 - val_loss: 1.6690e-11
Epoch 489/512

Epoch 00489: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6907e-11 - val_loss: 1.8762e-11
Epoch 490/512

Epoch 00490: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9403e-11 - val_loss: 2.0474e-11
Epoch 491/512

Epoch 00491: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0722e-11 - val_loss: 2.1166e-11
Epoch 492/512

Epoch 00492: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2255e-11 - val_loss: 2.3806e-11
Epoch 493/512

Epoch 00493: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3764e-11 - val_loss: 2.4385e-11
Epoch 494/512

Epoch 00494: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.4162e-11 - val_loss: 2.3223e-11
Epoch 495/512

Epoch 00495: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1928e-11 - val_loss: 2.0852e-11
Epoch 496/512

Epoch 00496: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0537e-11 - val_loss: 2.0644e-11
Epoch 497/512

Epoch 00497: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1684e-11 - val_loss: 2.2898e-11
Epoch 498/512

Epoch 00498: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3412e-11 - val_loss: 2.4154e-11
Epoch 499/512

Epoch 00499: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2721e-11 - val_loss: 2.1025e-11
Epoch 500/512

Epoch 00500: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0477e-11 - val_loss: 2.0498e-11
Epoch 501/512

Epoch 00501: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.0166e-11 - val_loss: 2.0472e-11
Epoch 502/512

Epoch 00502: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.1611e-11 - val_loss: 2.2865e-11
Epoch 503/512

Epoch 00503: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.3134e-11 - val_loss: 2.4031e-11
Epoch 504/512

Epoch 00504: val_loss did not improve from 0.00000
512/512 - 0s - loss: 2.2921e-11 - val_loss: 2.0808e-11
Epoch 505/512

Epoch 00505: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9495e-11 - val_loss: 1.8566e-11
Epoch 506/512

Epoch 00506: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8681e-11 - val_loss: 1.7901e-11
Epoch 507/512

Epoch 00507: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/addition_weights.h5
512/512 - 0s - loss: 1.6710e-11 - val_loss: 1.5601e-11
Epoch 508/512

Epoch 00508: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5413e-11 - val_loss: 1.5809e-11
Epoch 509/512

Epoch 00509: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.5603e-11 - val_loss: 1.5953e-11
Epoch 510/512

Epoch 00510: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.6443e-11 - val_loss: 1.8159e-11
Epoch 511/512

Epoch 00511: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.8448e-11 - val_loss: 1.9252e-11
Epoch 512/512

Epoch 00512: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.9291e-11 - val_loss: 2.0209e-11
Train on 512 samples, validate on 512 samples
Epoch 1/512
512/512 - 1s - loss: 27.4954 - val_loss: 0.7240
Epoch 2/512
512/512 - 0s - loss: 0.6864 - val_loss: 0.4208
Epoch 3/512
512/512 - 0s - loss: 0.3983 - val_loss: 0.3175
Epoch 4/512
512/512 - 0s - loss: 0.2743 - val_loss: 0.2593
Epoch 5/512
512/512 - 0s - loss: 0.2062 - val_loss: 0.2210
Epoch 6/512
512/512 - 0s - loss: 0.1643 - val_loss: 0.1935
Epoch 7/512
512/512 - 0s - loss: 0.1368 - val_loss: 0.1726
Epoch 8/512
512/512 - 0s - loss: 0.1179 - val_loss: 0.1560
Epoch 9/512
512/512 - 0s - loss: 0.1044 - val_loss: 0.1424
Epoch 10/512
512/512 - 0s - loss: 0.0944 - val_loss: 0.1309
Epoch 11/512
512/512 - 0s - loss: 0.0867 - val_loss: 0.1210
Epoch 12/512
512/512 - 0s - loss: 0.0806 - val_loss: 0.1121
Epoch 13/512
512/512 - 0s - loss: 0.0755 - val_loss: 0.1041
Epoch 14/512
512/512 - 0s - loss: 0.0711 - val_loss: 0.0968
Epoch 15/512
512/512 - 0s - loss: 0.0669 - val_loss: 0.0898
Epoch 16/512
512/512 - 0s - loss: 0.0629 - val_loss: 0.0832
Epoch 17/512
512/512 - 0s - loss: 0.0588 - val_loss: 0.0769
Epoch 18/512
512/512 - 0s - loss: 0.0547 - val_loss: 0.0708
Epoch 19/512
512/512 - 0s - loss: 0.0504 - val_loss: 0.0650
Epoch 20/512
512/512 - 0s - loss: 0.0461 - val_loss: 0.0595
Epoch 21/512
512/512 - 0s - loss: 0.0419 - val_loss: 0.0546
Epoch 22/512
512/512 - 0s - loss: 0.0378 - val_loss: 0.0501
Epoch 23/512
512/512 - 0s - loss: 0.0340 - val_loss: 0.0462
Epoch 24/512
512/512 - 0s - loss: 0.0306 - val_loss: 0.0426
Epoch 25/512
512/512 - 0s - loss: 0.0274 - val_loss: 0.0396
Epoch 26/512
512/512 - 0s - loss: 0.0246 - val_loss: 0.0368
Epoch 27/512
512/512 - 0s - loss: 0.0222 - val_loss: 0.0345
Epoch 28/512
512/512 - 0s - loss: 0.0200 - val_loss: 0.0323
Epoch 29/512
512/512 - 0s - loss: 0.0181 - val_loss: 0.0302
Epoch 30/512
512/512 - 0s - loss: 0.0166 - val_loss: 0.0273
Epoch 31/512
512/512 - 0s - loss: 0.0246 - val_loss: 0.0298
Epoch 32/512
512/512 - 0s - loss: 0.0199 - val_loss: 0.0260
Epoch 33/512
512/512 - 0s - loss: 0.0154 - val_loss: 0.0341
Epoch 34/512
512/512 - 0s - loss: 0.0260 - val_loss: 0.0221
Epoch 35/512
512/512 - 0s - loss: 0.0110 - val_loss: 0.0235
Epoch 36/512
512/512 - 0s - loss: 0.0247 - val_loss: 0.0169
Epoch 37/512
512/512 - 0s - loss: 0.0146 - val_loss: 0.0134
Epoch 38/512
512/512 - 0s - loss: 0.0127 - val_loss: 0.0072
Epoch 39/512
512/512 - 0s - loss: 0.0146 - val_loss: 0.0060
Epoch 40/512
512/512 - 0s - loss: 0.0069 - val_loss: 0.0076
Epoch 41/512
512/512 - 0s - loss: 0.0175 - val_loss: 0.0019
Epoch 42/512
512/512 - 0s - loss: 0.0093 - val_loss: 0.0014
Epoch 43/512
512/512 - 0s - loss: 0.0094 - val_loss: 0.0019
Epoch 44/512
512/512 - 0s - loss: 0.0085 - val_loss: 0.0021
Epoch 45/512
512/512 - 0s - loss: 0.0079 - val_loss: 0.0021
Epoch 46/512
512/512 - 0s - loss: 0.0071 - val_loss: 0.0032
Epoch 47/512
512/512 - 0s - loss: 0.0067 - val_loss: 0.0013
Epoch 48/512
512/512 - 0s - loss: 0.0068 - val_loss: 0.0011
Epoch 49/512
512/512 - 0s - loss: 0.0057 - val_loss: 0.0030
Epoch 50/512
512/512 - 0s - loss: 0.0060 - val_loss: 3.8665e-04
Epoch 51/512
512/512 - 0s - loss: 0.0059 - val_loss: 0.0015
Epoch 52/512
512/512 - 0s - loss: 0.0049 - val_loss: 3.9265e-04
Epoch 53/512
512/512 - 0s - loss: 0.0055 - val_loss: 4.2108e-04
Epoch 54/512
512/512 - 0s - loss: 0.0043 - val_loss: 4.3146e-04
Epoch 55/512
512/512 - 0s - loss: 0.0047 - val_loss: 2.3761e-04
Epoch 56/512
512/512 - 0s - loss: 0.0042 - val_loss: 2.7986e-04
Epoch 57/512
512/512 - 0s - loss: 0.0039 - val_loss: 1.8905e-04
Epoch 58/512
512/512 - 0s - loss: 0.0037 - val_loss: 1.8310e-04
Epoch 59/512
512/512 - 0s - loss: 0.0032 - val_loss: 1.6601e-04
Epoch 60/512
512/512 - 0s - loss: 0.0032 - val_loss: 1.5148e-04
Epoch 61/512
512/512 - 0s - loss: 0.0028 - val_loss: 1.4748e-04
Epoch 62/512
512/512 - 0s - loss: 0.0028 - val_loss: 1.3602e-04
Epoch 63/512
512/512 - 0s - loss: 0.0024 - val_loss: 1.2722e-04
Epoch 64/512
512/512 - 0s - loss: 0.0023 - val_loss: 1.2108e-04
Epoch 65/512
512/512 - 0s - loss: 0.0021 - val_loss: 1.1114e-04
Epoch 66/512
512/512 - 0s - loss: 0.0021 - val_loss: 1.0813e-04
Epoch 67/512
512/512 - 0s - loss: 0.0018 - val_loss: 1.0161e-04
Epoch 68/512
512/512 - 0s - loss: 0.0019 - val_loss: 1.0186e-04
Epoch 69/512
512/512 - 0s - loss: 0.0016 - val_loss: 9.9600e-05
Epoch 70/512
512/512 - 0s - loss: 0.0016 - val_loss: 9.9902e-05
Epoch 71/512
512/512 - 0s - loss: 0.0015 - val_loss: 1.0066e-04
Epoch 72/512
512/512 - 0s - loss: 0.0014 - val_loss: 1.0189e-04
Epoch 73/512
512/512 - 0s - loss: 0.0013 - val_loss: 1.0225e-04
Epoch 74/512
512/512 - 0s - loss: 0.0013 - val_loss: 1.0450e-04
Epoch 75/512
512/512 - 0s - loss: 0.0012 - val_loss: 1.0634e-04
Epoch 76/512
512/512 - 0s - loss: 0.0011 - val_loss: 1.0720e-04
Epoch 77/512
512/512 - 0s - loss: 0.0011 - val_loss: 1.0901e-04
Epoch 78/512
512/512 - 0s - loss: 0.0010 - val_loss: 1.1086e-04
Epoch 79/512
512/512 - 0s - loss: 0.0010 - val_loss: 1.1391e-04
Epoch 80/512
512/512 - 0s - loss: 8.8132e-04 - val_loss: 1.1306e-04
Epoch 81/512
512/512 - 0s - loss: 9.0308e-04 - val_loss: 1.1685e-04
Epoch 82/512
512/512 - 0s - loss: 8.5968e-04 - val_loss: 1.1889e-04
Epoch 83/512
512/512 - 0s - loss: 7.9463e-04 - val_loss: 1.1962e-04
Epoch 84/512
512/512 - 0s - loss: 7.9111e-04 - val_loss: 1.2274e-04
Epoch 85/512
512/512 - 0s - loss: 7.4310e-04 - val_loss: 1.2302e-04
Epoch 86/512
512/512 - 0s - loss: 6.7193e-04 - val_loss: 1.2358e-04
Epoch 87/512
512/512 - 0s - loss: 6.9532e-04 - val_loss: 1.2617e-04
Epoch 88/512
512/512 - 0s - loss: 6.6866e-04 - val_loss: 1.2746e-04
Epoch 89/512
512/512 - 0s - loss: 5.8782e-04 - val_loss: 1.2659e-04
Epoch 90/512
512/512 - 0s - loss: 6.0032e-04 - val_loss: 1.2912e-04
Epoch 91/512
512/512 - 0s - loss: 5.6428e-04 - val_loss: 1.2899e-04
Epoch 92/512
512/512 - 0s - loss: 5.4440e-04 - val_loss: 1.2953e-04
Epoch 93/512
512/512 - 0s - loss: 5.0941e-04 - val_loss: 1.2944e-04
Epoch 94/512
512/512 - 0s - loss: 4.9857e-04 - val_loss: 1.3017e-04
Epoch 95/512
512/512 - 0s - loss: 4.8706e-04 - val_loss: 1.3021e-04
Epoch 96/512
512/512 - 0s - loss: 4.3630e-04 - val_loss: 1.2862e-04
Epoch 97/512
512/512 - 0s - loss: 4.4756e-04 - val_loss: 1.2949e-04
Epoch 98/512
512/512 - 0s - loss: 4.2285e-04 - val_loss: 1.2827e-04
Epoch 99/512
512/512 - 0s - loss: 3.9546e-04 - val_loss: 1.2737e-04
Epoch 100/512
512/512 - 0s - loss: 3.7947e-04 - val_loss: 1.2661e-04
Epoch 101/512
512/512 - 0s - loss: 3.7984e-04 - val_loss: 1.2610e-04
Epoch 102/512
512/512 - 0s - loss: 3.5496e-04 - val_loss: 1.2443e-04
Epoch 103/512
512/512 - 0s - loss: 3.3776e-04 - val_loss: 1.2305e-04
Epoch 104/512
512/512 - 0s - loss: 3.3399e-04 - val_loss: 1.2209e-04
Epoch 105/512
512/512 - 0s - loss: 3.1112e-04 - val_loss: 1.1996e-04
Epoch 106/512
512/512 - 0s - loss: 3.0799e-04 - val_loss: 1.1858e-04
Epoch 107/512
512/512 - 0s - loss: 2.8930e-04 - val_loss: 1.1629e-04
Epoch 108/512
512/512 - 0s - loss: 2.7558e-04 - val_loss: 1.1444e-04
Epoch 109/512
512/512 - 0s - loss: 2.7537e-04 - val_loss: 1.1305e-04
Epoch 110/512
512/512 - 0s - loss: 2.6149e-04 - val_loss: 1.1061e-04
Epoch 111/512
512/512 - 0s - loss: 2.5102e-04 - val_loss: 1.0842e-04
Epoch 112/512
512/512 - 0s - loss: 2.3530e-04 - val_loss: 1.0642e-04
Epoch 113/512
512/512 - 0s - loss: 2.3315e-04 - val_loss: 1.0448e-04
Epoch 114/512
512/512 - 0s - loss: 2.2396e-04 - val_loss: 1.0249e-04
Epoch 115/512
512/512 - 0s - loss: 2.1693e-04 - val_loss: 1.0035e-04
Epoch 116/512
512/512 - 0s - loss: 2.0888e-04 - val_loss: 9.8014e-05
Epoch 117/512
512/512 - 0s - loss: 1.9367e-04 - val_loss: 9.5799e-05
Epoch 118/512
512/512 - 0s - loss: 1.9493e-04 - val_loss: 9.3884e-05
Epoch 119/512
512/512 - 0s - loss: 1.9160e-04 - val_loss: 9.1934e-05
Epoch 120/512
512/512 - 0s - loss: 1.7207e-04 - val_loss: 8.9357e-05
Epoch 121/512
512/512 - 0s - loss: 1.7349e-04 - val_loss: 8.7678e-05
Epoch 122/512
512/512 - 0s - loss: 1.6935e-04 - val_loss: 8.5655e-05
Epoch 123/512
512/512 - 0s - loss: 1.6366e-04 - val_loss: 8.3460e-05
Epoch 124/512
512/512 - 0s - loss: 1.4804e-04 - val_loss: 8.1338e-05
Epoch 125/512
512/512 - 0s - loss: 1.4952e-04 - val_loss: 7.9862e-05
Epoch 126/512
512/512 - 0s - loss: 1.5041e-04 - val_loss: 7.8171e-05
Epoch 127/512
512/512 - 0s - loss: 1.3671e-04 - val_loss: 7.6044e-05
Epoch 128/512
512/512 - 0s - loss: 1.3350e-04 - val_loss: 7.4377e-05
Epoch 129/512
512/512 - 0s - loss: 1.3183e-04 - val_loss: 7.2935e-05
Epoch 130/512
512/512 - 0s - loss: 1.2334e-04 - val_loss: 7.1160e-05
Epoch 131/512
512/512 - 0s - loss: 1.2299e-04 - val_loss: 6.9651e-05
Epoch 132/512
512/512 - 0s - loss: 1.1739e-04 - val_loss: 6.8043e-05
Epoch 133/512
512/512 - 0s - loss: 1.1297e-04 - val_loss: 6.6670e-05
Epoch 134/512
512/512 - 0s - loss: 1.0700e-04 - val_loss: 6.5251e-05
Epoch 135/512
512/512 - 0s - loss: 1.0918e-04 - val_loss: 6.3950e-05
Epoch 136/512
512/512 - 0s - loss: 9.9173e-05 - val_loss: 6.2385e-05
Epoch 137/512
512/512 - 0s - loss: 9.8635e-05 - val_loss: 6.1225e-05
Epoch 138/512
512/512 - 0s - loss: 9.7190e-05 - val_loss: 6.0011e-05
Epoch 139/512
512/512 - 0s - loss: 9.1864e-05 - val_loss: 5.8734e-05
Epoch 140/512
512/512 - 0s - loss: 9.0183e-05 - val_loss: 5.7528e-05
Epoch 141/512
512/512 - 0s - loss: 8.4972e-05 - val_loss: 5.6381e-05
Epoch 142/512
512/512 - 0s - loss: 8.3659e-05 - val_loss: 5.5332e-05
Epoch 143/512
512/512 - 0s - loss: 8.0700e-05 - val_loss: 5.4272e-05
Epoch 144/512
512/512 - 0s - loss: 7.9606e-05 - val_loss: 5.3236e-05
Epoch 145/512
512/512 - 0s - loss: 7.3023e-05 - val_loss: 5.2132e-05
Epoch 146/512
512/512 - 0s - loss: 7.5765e-05 - val_loss: 5.1336e-05
Epoch 147/512
512/512 - 0s - loss: 6.8817e-05 - val_loss: 5.0199e-05
Epoch 148/512
512/512 - 0s - loss: 6.9672e-05 - val_loss: 4.9496e-05
Epoch 149/512
512/512 - 0s - loss: 6.5873e-05 - val_loss: 4.8549e-05
Epoch 150/512
512/512 - 0s - loss: 6.3750e-05 - val_loss: 4.7751e-05
Epoch 151/512
512/512 - 0s - loss: 6.1282e-05 - val_loss: 4.6936e-05
Epoch 152/512
512/512 - 0s - loss: 6.1628e-05 - val_loss: 4.6201e-05
Epoch 153/512
512/512 - 0s - loss: 5.7736e-05 - val_loss: 4.5311e-05
Epoch 154/512
512/512 - 0s - loss: 5.6417e-05 - val_loss: 4.4563e-05
Epoch 155/512
512/512 - 0s - loss: 5.4362e-05 - val_loss: 4.3863e-05
Epoch 156/512
512/512 - 0s - loss: 5.2564e-05 - val_loss: 4.3162e-05
Epoch 157/512
512/512 - 0s - loss: 5.2726e-05 - val_loss: 4.2485e-05
Epoch 158/512
512/512 - 0s - loss: 4.7727e-05 - val_loss: 4.1761e-05
Epoch 159/512
512/512 - 0s - loss: 4.8250e-05 - val_loss: 4.1280e-05
Epoch 160/512
512/512 - 0s - loss: 4.8489e-05 - val_loss: 4.0598e-05
Epoch 161/512
512/512 - 0s - loss: 4.2596e-05 - val_loss: 3.9809e-05
Epoch 162/512
512/512 - 0s - loss: 4.4636e-05 - val_loss: 3.9386e-05
Epoch 163/512
512/512 - 0s - loss: 4.2362e-05 - val_loss: 3.8774e-05
Epoch 164/512
512/512 - 0s - loss: 4.0671e-05 - val_loss: 3.8254e-05
Epoch 165/512
512/512 - 0s - loss: 4.0103e-05 - val_loss: 3.7654e-05
Epoch 166/512
512/512 - 0s - loss: 3.7972e-05 - val_loss: 3.7154e-05
Epoch 167/512
512/512 - 0s - loss: 3.7695e-05 - val_loss: 3.6648e-05
Epoch 168/512
512/512 - 0s - loss: 3.5905e-05 - val_loss: 3.6163e-05
Epoch 169/512
512/512 - 0s - loss: 3.4774e-05 - val_loss: 3.5679e-05
Epoch 170/512
512/512 - 0s - loss: 3.4965e-05 - val_loss: 3.5218e-05
Epoch 171/512
512/512 - 0s - loss: 3.1894e-05 - val_loss: 3.4666e-05
Epoch 172/512
512/512 - 0s - loss: 3.1500e-05 - val_loss: 3.4277e-05
Epoch 173/512
512/512 - 0s - loss: 3.2452e-05 - val_loss: 3.3886e-05
Epoch 174/512
512/512 - 0s - loss: 2.9061e-05 - val_loss: 3.3345e-05
Epoch 175/512
512/512 - 0s - loss: 2.8244e-05 - val_loss: 3.2966e-05
Epoch 176/512
512/512 - 0s - loss: 2.9201e-05 - val_loss: 3.2637e-05
Epoch 177/512
512/512 - 0s - loss: 2.7427e-05 - val_loss: 3.2136e-05
Epoch 178/512
512/512 - 0s - loss: 2.4992e-05 - val_loss: 3.1743e-05
Epoch 179/512
512/512 - 0s - loss: 2.7126e-05 - val_loss: 3.1462e-05
Epoch 180/512
512/512 - 0s - loss: 2.4549e-05 - val_loss: 3.0996e-05
Epoch 181/512
512/512 - 0s - loss: 2.3624e-05 - val_loss: 3.0635e-05
Epoch 182/512
512/512 - 0s - loss: 2.3775e-05 - val_loss: 3.0381e-05
Epoch 183/512
512/512 - 0s - loss: 2.3078e-05 - val_loss: 2.9953e-05
Epoch 184/512
512/512 - 0s - loss: 2.1093e-05 - val_loss: 2.9538e-05
Epoch 185/512
512/512 - 0s - loss: 2.1528e-05 - val_loss: 2.9325e-05
Epoch 186/512
512/512 - 0s - loss: 2.1349e-05 - val_loss: 2.8960e-05
Epoch 187/512
512/512 - 0s - loss: 1.9895e-05 - val_loss: 2.8613e-05
Epoch 188/512
512/512 - 0s - loss: 1.8659e-05 - val_loss: 2.8328e-05
Epoch 189/512
512/512 - 0s - loss: 1.9758e-05 - val_loss: 2.8031e-05
Epoch 190/512
512/512 - 0s - loss: 1.8456e-05 - val_loss: 2.7706e-05
Epoch 191/512
512/512 - 0s - loss: 1.6428e-05 - val_loss: 2.7327e-05
Epoch 192/512
512/512 - 0s - loss: 1.8115e-05 - val_loss: 2.7239e-05
Epoch 193/512
512/512 - 0s - loss: 1.7090e-05 - val_loss: 2.6834e-05
Epoch 194/512
512/512 - 0s - loss: 1.5060e-05 - val_loss: 2.6390e-05
Epoch 195/512
512/512 - 0s - loss: 1.6182e-05 - val_loss: 2.6331e-05
Epoch 196/512
512/512 - 0s - loss: 1.6042e-05 - val_loss: 2.6085e-05
Epoch 197/512
512/512 - 0s - loss: 1.3940e-05 - val_loss: 2.5694e-05
Epoch 198/512
512/512 - 0s - loss: 1.4206e-05 - val_loss: 2.5544e-05
Epoch 199/512
512/512 - 0s - loss: 1.4091e-05 - val_loss: 2.5397e-05
Epoch 200/512
512/512 - 0s - loss: 1.3912e-05 - val_loss: 2.4964e-05
Epoch 201/512
512/512 - 0s - loss: 1.2513e-05 - val_loss: 2.4619e-05
Epoch 202/512
512/512 - 0s - loss: 1.2891e-05 - val_loss: 2.4578e-05
Epoch 203/512
512/512 - 0s - loss: 1.2401e-05 - val_loss: 2.4287e-05
Epoch 204/512
512/512 - 0s - loss: 1.1928e-05 - val_loss: 2.3978e-05
Epoch 205/512
512/512 - 0s - loss: 1.1655e-05 - val_loss: 2.3832e-05
Epoch 206/512
512/512 - 0s - loss: 1.1078e-05 - val_loss: 2.3591e-05
Epoch 207/512
512/512 - 0s - loss: 1.0805e-05 - val_loss: 2.3363e-05
Epoch 208/512
512/512 - 0s - loss: 1.0972e-05 - val_loss: 2.3227e-05
Epoch 209/512
512/512 - 0s - loss: 9.9878e-06 - val_loss: 2.2944e-05
Epoch 210/512
512/512 - 0s - loss: 9.9742e-06 - val_loss: 2.2699e-05
Epoch 211/512
512/512 - 0s - loss: 9.7483e-06 - val_loss: 2.2638e-05
Epoch 212/512
512/512 - 0s - loss: 9.2854e-06 - val_loss: 2.2394e-05
Epoch 213/512
512/512 - 0s - loss: 9.0632e-06 - val_loss: 2.2064e-05
Epoch 214/512
512/512 - 0s - loss: 9.0374e-06 - val_loss: 2.1805e-05
Epoch 215/512
512/512 - 0s - loss: 8.3890e-06 - val_loss: 2.1619e-05
Epoch 216/512
512/512 - 0s - loss: 8.2628e-06 - val_loss: 2.1460e-05
Epoch 217/512
512/512 - 0s - loss: 8.2661e-06 - val_loss: 2.1348e-05
Epoch 218/512
512/512 - 0s - loss: 7.6408e-06 - val_loss: 2.1014e-05
Epoch 219/512
512/512 - 0s - loss: 7.5909e-06 - val_loss: 2.0878e-05
Epoch 220/512
512/512 - 0s - loss: 7.5743e-06 - val_loss: 2.0817e-05
Epoch 221/512
512/512 - 0s - loss: 7.0199e-06 - val_loss: 2.0594e-05
Epoch 222/512
512/512 - 0s - loss: 6.8110e-06 - val_loss: 2.0328e-05
Epoch 223/512
512/512 - 0s - loss: 6.8619e-06 - val_loss: 2.0351e-05
Epoch 224/512
512/512 - 0s - loss: 6.7018e-06 - val_loss: 2.0064e-05
Epoch 225/512
512/512 - 0s - loss: 6.0009e-06 - val_loss: 1.9924e-05
Epoch 226/512
512/512 - 0s - loss: 6.2740e-06 - val_loss: 1.9905e-05
Epoch 227/512
512/512 - 0s - loss: 6.1791e-06 - val_loss: 1.9528e-05
Epoch 228/512
512/512 - 0s - loss: 5.5399e-06 - val_loss: 1.9288e-05
Epoch 229/512
512/512 - 0s - loss: 5.6626e-06 - val_loss: 1.9297e-05
Epoch 230/512
512/512 - 0s - loss: 5.5252e-06 - val_loss: 1.9201e-05
Epoch 231/512
512/512 - 0s - loss: 5.3250e-06 - val_loss: 1.8827e-05
Epoch 232/512
512/512 - 0s - loss: 5.0789e-06 - val_loss: 1.8719e-05
Epoch 233/512
512/512 - 0s - loss: 4.9954e-06 - val_loss: 1.8959e-05
Epoch 234/512
512/512 - 0s - loss: 4.8159e-06 - val_loss: 1.8675e-05
Epoch 235/512
512/512 - 0s - loss: 4.7643e-06 - val_loss: 1.8468e-05
Epoch 236/512
512/512 - 0s - loss: 4.5065e-06 - val_loss: 1.8253e-05
Epoch 237/512
512/512 - 0s - loss: 4.4234e-06 - val_loss: 1.7926e-05
Epoch 238/512
512/512 - 0s - loss: 4.3347e-06 - val_loss: 1.7919e-05
Epoch 239/512
512/512 - 0s - loss: 4.1891e-06 - val_loss: 1.7917e-05
Epoch 240/512
512/512 - 0s - loss: 3.9692e-06 - val_loss: 1.7592e-05
Epoch 241/512
512/512 - 0s - loss: 3.9381e-06 - val_loss: 1.7606e-05
Epoch 242/512
512/512 - 0s - loss: 3.9049e-06 - val_loss: 1.7508e-05
Epoch 243/512
512/512 - 0s - loss: 3.6802e-06 - val_loss: 1.7056e-05
Epoch 244/512
512/512 - 0s - loss: 3.4515e-06 - val_loss: 1.6977e-05
Epoch 245/512
512/512 - 0s - loss: 3.6199e-06 - val_loss: 1.7195e-05
Epoch 246/512
512/512 - 0s - loss: 3.3824e-06 - val_loss: 1.6681e-05
Epoch 247/512
512/512 - 0s - loss: 3.1566e-06 - val_loss: 1.6522e-05
Epoch 248/512
512/512 - 0s - loss: 3.2772e-06 - val_loss: 1.6456e-05
Epoch 249/512
512/512 - 0s - loss: 3.2209e-06 - val_loss: 1.6538e-05
Epoch 250/512
512/512 - 0s - loss: 2.9014e-06 - val_loss: 1.6252e-05
Epoch 251/512
512/512 - 0s - loss: 2.8116e-06 - val_loss: 1.6312e-05
Epoch 252/512
512/512 - 0s - loss: 3.0222e-06 - val_loss: 1.6441e-05
Epoch 253/512
512/512 - 0s - loss: 2.7128e-06 - val_loss: 1.5841e-05
Epoch 254/512
512/512 - 0s - loss: 2.6125e-06 - val_loss: 1.6061e-05
Epoch 255/512
512/512 - 0s - loss: 2.5983e-06 - val_loss: 1.5899e-05
Epoch 256/512
512/512 - 0s - loss: 2.6269e-06 - val_loss: 1.5505e-05
Epoch 257/512
512/512 - 0s - loss: 2.3826e-06 - val_loss: 1.5278e-05
Epoch 258/512
512/512 - 0s - loss: 2.3391e-06 - val_loss: 1.5587e-05
Epoch 259/512
512/512 - 0s - loss: 2.3649e-06 - val_loss: 1.5452e-05
Epoch 260/512
512/512 - 0s - loss: 2.2647e-06 - val_loss: 1.5048e-05
Epoch 261/512
512/512 - 0s - loss: 2.1380e-06 - val_loss: 1.4763e-05
Epoch 262/512
512/512 - 0s - loss: 2.1432e-06 - val_loss: 1.4930e-05
Epoch 263/512
512/512 - 0s - loss: 2.0673e-06 - val_loss: 1.5253e-05
Epoch 264/512
512/512 - 0s - loss: 1.9705e-06 - val_loss: 1.4770e-05
Epoch 265/512
512/512 - 0s - loss: 1.9228e-06 - val_loss: 1.4895e-05
Epoch 266/512
512/512 - 0s - loss: 1.9327e-06 - val_loss: 1.4551e-05
Epoch 267/512
512/512 - 0s - loss: 1.8017e-06 - val_loss: 1.4379e-05
Epoch 268/512
512/512 - 0s - loss: 1.7774e-06 - val_loss: 1.4427e-05
Epoch 269/512
512/512 - 0s - loss: 1.7651e-06 - val_loss: 1.4696e-05
Epoch 270/512
512/512 - 0s - loss: 1.6708e-06 - val_loss: 1.4342e-05
Epoch 271/512
512/512 - 0s - loss: 1.6111e-06 - val_loss: 1.4194e-05
Epoch 272/512
512/512 - 0s - loss: 1.6052e-06 - val_loss: 1.3744e-05
Epoch 273/512
512/512 - 0s - loss: 1.5468e-06 - val_loss: 1.3946e-05
Epoch 274/512
512/512 - 0s - loss: 1.5118e-06 - val_loss: 1.3869e-05
Epoch 275/512
512/512 - 0s - loss: 1.4254e-06 - val_loss: 1.3925e-05
Epoch 276/512
512/512 - 0s - loss: 1.4205e-06 - val_loss: 1.4090e-05
Epoch 277/512
512/512 - 0s - loss: 1.4110e-06 - val_loss: 1.3688e-05
Epoch 278/512
512/512 - 0s - loss: 1.3365e-06 - val_loss: 1.3389e-05
Epoch 279/512
512/512 - 0s - loss: 1.2653e-06 - val_loss: 1.3588e-05
Epoch 280/512
512/512 - 0s - loss: 1.2952e-06 - val_loss: 1.3082e-05
Epoch 281/512
512/512 - 0s - loss: 1.2352e-06 - val_loss: 1.2999e-05
Epoch 282/512
512/512 - 0s - loss: 1.1724e-06 - val_loss: 1.2924e-05
Epoch 283/512
512/512 - 0s - loss: 1.1914e-06 - val_loss: 1.3559e-05
Epoch 284/512
512/512 - 0s - loss: 1.1317e-06 - val_loss: 1.2851e-05
Epoch 285/512
512/512 - 0s - loss: 1.0871e-06 - val_loss: 1.2620e-05
Epoch 286/512
512/512 - 0s - loss: 1.0668e-06 - val_loss: 1.2739e-05
Epoch 287/512
512/512 - 0s - loss: 1.0873e-06 - val_loss: 1.1909e-05
Epoch 288/512
512/512 - 0s - loss: 9.8224e-07 - val_loss: 1.2222e-05
Epoch 289/512
512/512 - 0s - loss: 9.7891e-07 - val_loss: 1.2859e-05
Epoch 290/512
512/512 - 0s - loss: 9.9574e-07 - val_loss: 1.2282e-05
Epoch 291/512
512/512 - 0s - loss: 9.3508e-07 - val_loss: 1.2669e-05
Epoch 292/512
512/512 - 0s - loss: 8.5898e-07 - val_loss: 1.2213e-05
Epoch 293/512
512/512 - 0s - loss: 9.3446e-07 - val_loss: 1.1906e-05
Epoch 294/512
512/512 - 0s - loss: 8.7559e-07 - val_loss: 1.2419e-05
Epoch 295/512
512/512 - 0s - loss: 7.8637e-07 - val_loss: 1.1581e-05
Epoch 296/512
512/512 - 0s - loss: 8.3555e-07 - val_loss: 1.2769e-05
Epoch 297/512
512/512 - 0s - loss: 8.4107e-07 - val_loss: 1.2517e-05
Epoch 298/512
512/512 - 0s - loss: 7.4688e-07 - val_loss: 1.2121e-05
Epoch 299/512
512/512 - 0s - loss: 7.2333e-07 - val_loss: 1.1785e-05
Epoch 300/512
512/512 - 0s - loss: 7.6617e-07 - val_loss: 1.1703e-05
Epoch 301/512
512/512 - 0s - loss: 7.3674e-07 - val_loss: 1.1687e-05
Epoch 302/512
512/512 - 0s - loss: 6.8592e-07 - val_loss: 1.0667e-05
Epoch 303/512
512/512 - 0s - loss: 6.5921e-07 - val_loss: 1.1210e-05
Epoch 304/512
512/512 - 0s - loss: 6.8291e-07 - val_loss: 1.1764e-05
Epoch 305/512
512/512 - 0s - loss: 6.6203e-07 - val_loss: 1.1724e-05
Epoch 306/512
512/512 - 0s - loss: 6.0956e-07 - val_loss: 1.1317e-05
Epoch 307/512
512/512 - 0s - loss: 6.1252e-07 - val_loss: 1.1032e-05
Epoch 308/512
512/512 - 0s - loss: 6.2147e-07 - val_loss: 1.0733e-05
Epoch 309/512
512/512 - 0s - loss: 5.6210e-07 - val_loss: 1.0975e-05
Epoch 310/512
512/512 - 0s - loss: 5.7937e-07 - val_loss: 1.0786e-05
Epoch 311/512
512/512 - 0s - loss: 5.5505e-07 - val_loss: 1.1057e-05
Epoch 312/512
512/512 - 0s - loss: 5.4949e-07 - val_loss: 1.0688e-05
Epoch 313/512
512/512 - 0s - loss: 5.2324e-07 - val_loss: 1.0507e-05
Epoch 314/512
512/512 - 0s - loss: 5.1510e-07 - val_loss: 1.0808e-05
Epoch 315/512
512/512 - 0s - loss: 5.0450e-07 - val_loss: 1.1049e-05
Epoch 316/512
512/512 - 0s - loss: 5.0173e-07 - val_loss: 1.1160e-05
Epoch 317/512
512/512 - 0s - loss: 4.8082e-07 - val_loss: 1.0369e-05
Epoch 318/512
512/512 - 0s - loss: 4.6390e-07 - val_loss: 9.6584e-06
Epoch 319/512
512/512 - 0s - loss: 4.5634e-07 - val_loss: 1.1192e-05
Epoch 320/512
512/512 - 0s - loss: 4.5832e-07 - val_loss: 9.6825e-06
Epoch 321/512
512/512 - 0s - loss: 4.3155e-07 - val_loss: 1.0435e-05
Epoch 322/512
512/512 - 0s - loss: 4.1918e-07 - val_loss: 1.0666e-05
Epoch 323/512
512/512 - 0s - loss: 4.2784e-07 - val_loss: 1.0332e-05
Epoch 324/512
512/512 - 0s - loss: 4.1627e-07 - val_loss: 1.0699e-05
Epoch 325/512
512/512 - 0s - loss: 3.8675e-07 - val_loss: 9.2070e-06
Epoch 326/512
512/512 - 0s - loss: 3.8653e-07 - val_loss: 9.7507e-06
Epoch 327/512
512/512 - 0s - loss: 3.9186e-07 - val_loss: 1.0018e-05
Epoch 328/512
512/512 - 0s - loss: 3.7182e-07 - val_loss: 9.5700e-06
Epoch 329/512
512/512 - 0s - loss: 3.5963e-07 - val_loss: 9.4851e-06
Epoch 330/512
512/512 - 0s - loss: 3.5494e-07 - val_loss: 1.0279e-05
Epoch 331/512
512/512 - 0s - loss: 3.5891e-07 - val_loss: 9.2628e-06
Epoch 332/512
512/512 - 0s - loss: 3.3400e-07 - val_loss: 1.0020e-05
Epoch 333/512
512/512 - 0s - loss: 3.3059e-07 - val_loss: 8.6751e-06
Epoch 334/512
512/512 - 0s - loss: 3.3412e-07 - val_loss: 9.8027e-06
Epoch 335/512
512/512 - 0s - loss: 3.2051e-07 - val_loss: 8.5640e-06
Epoch 336/512
512/512 - 0s - loss: 3.0637e-07 - val_loss: 9.3229e-06
Epoch 337/512
512/512 - 0s - loss: 3.1087e-07 - val_loss: 8.8943e-06
Epoch 338/512
512/512 - 0s - loss: 3.0506e-07 - val_loss: 9.9655e-06
Epoch 339/512
512/512 - 0s - loss: 2.9126e-07 - val_loss: 9.3803e-06
Epoch 340/512
512/512 - 0s - loss: 2.8979e-07 - val_loss: 9.8949e-06
Epoch 341/512
512/512 - 0s - loss: 2.8776e-07 - val_loss: 8.6807e-06
Epoch 342/512
512/512 - 0s - loss: 2.7550e-07 - val_loss: 9.2627e-06
Epoch 343/512
512/512 - 0s - loss: 2.7402e-07 - val_loss: 8.1617e-06
Epoch 344/512
512/512 - 0s - loss: 2.6694e-07 - val_loss: 9.7478e-06
Epoch 345/512
512/512 - 0s - loss: 2.6664e-07 - val_loss: 9.1824e-06
Epoch 346/512
512/512 - 0s - loss: 2.4759e-07 - val_loss: 7.8045e-06
Epoch 347/512
512/512 - 0s - loss: 2.5938e-07 - val_loss: 9.6560e-06
Epoch 348/512
512/512 - 0s - loss: 2.5398e-07 - val_loss: 8.7339e-06
Epoch 349/512
512/512 - 0s - loss: 2.3585e-07 - val_loss: 8.4625e-06
Epoch 350/512
512/512 - 0s - loss: 2.3850e-07 - val_loss: 9.4296e-06
Epoch 351/512
512/512 - 0s - loss: 2.4003e-07 - val_loss: 8.2465e-06
Epoch 352/512
512/512 - 0s - loss: 2.3152e-07 - val_loss: 9.2012e-06
Epoch 353/512
512/512 - 0s - loss: 2.2444e-07 - val_loss: 7.7639e-06
Epoch 354/512
512/512 - 0s - loss: 2.1861e-07 - val_loss: 6.9777e-06
Epoch 355/512
512/512 - 0s - loss: 2.1938e-07 - val_loss: 8.4153e-06
Epoch 356/512
512/512 - 0s - loss: 2.1583e-07 - val_loss: 8.8897e-06
Epoch 357/512
512/512 - 0s - loss: 2.1345e-07 - val_loss: 8.2248e-06
Epoch 358/512
512/512 - 0s - loss: 2.0746e-07 - val_loss: 8.7302e-06
Epoch 359/512
512/512 - 0s - loss: 2.0479e-07 - val_loss: 8.6790e-06
Epoch 360/512
512/512 - 0s - loss: 2.0133e-07 - val_loss: 8.0422e-06
Epoch 361/512
512/512 - 0s - loss: 1.9654e-07 - val_loss: 9.3029e-06
Epoch 362/512
512/512 - 0s - loss: 1.9659e-07 - val_loss: 9.0682e-06
Epoch 363/512
512/512 - 0s - loss: 1.9541e-07 - val_loss: 8.5016e-06
Epoch 364/512
512/512 - 0s - loss: 1.8543e-07 - val_loss: 8.4469e-06
Epoch 365/512
512/512 - 0s - loss: 1.8548e-07 - val_loss: 8.3157e-06
Epoch 366/512
512/512 - 0s - loss: 1.8401e-07 - val_loss: 7.2616e-06
Epoch 367/512
512/512 - 0s - loss: 1.7994e-07 - val_loss: 8.1277e-06
Epoch 368/512
512/512 - 0s - loss: 1.7939e-07 - val_loss: 8.5160e-06
Epoch 369/512
512/512 - 0s - loss: 1.7505e-07 - val_loss: 7.5258e-06
Epoch 370/512
512/512 - 0s - loss: 1.7317e-07 - val_loss: 7.8355e-06
Epoch 371/512
512/512 - 0s - loss: 1.6920e-07 - val_loss: 7.2150e-06
Epoch 372/512
512/512 - 0s - loss: 1.6704e-07 - val_loss: 8.2852e-06
Epoch 373/512
512/512 - 0s - loss: 1.6649e-07 - val_loss: 7.5410e-06
Epoch 374/512
512/512 - 0s - loss: 1.6133e-07 - val_loss: 7.5227e-06
Epoch 375/512
512/512 - 0s - loss: 1.6249e-07 - val_loss: 8.2098e-06
Epoch 376/512
512/512 - 0s - loss: 1.5928e-07 - val_loss: 6.9932e-06
Epoch 377/512
512/512 - 0s - loss: 1.5563e-07 - val_loss: 8.5311e-06
Epoch 378/512
512/512 - 0s - loss: 1.5424e-07 - val_loss: 7.4878e-06
Epoch 379/512
512/512 - 0s - loss: 1.5403e-07 - val_loss: 7.8999e-06
Epoch 380/512
512/512 - 0s - loss: 1.4915e-07 - val_loss: 6.9758e-06
Epoch 381/512
512/512 - 0s - loss: 1.4803e-07 - val_loss: 9.4899e-06
Epoch 382/512
512/512 - 0s - loss: 1.5022e-07 - val_loss: 5.9889e-06
Epoch 383/512
512/512 - 0s - loss: 1.4160e-07 - val_loss: 7.7953e-06
Epoch 384/512
512/512 - 0s - loss: 1.4469e-07 - val_loss: 7.6397e-06
Epoch 385/512
512/512 - 0s - loss: 1.4300e-07 - val_loss: 7.9750e-06
Epoch 386/512
512/512 - 0s - loss: 1.3954e-07 - val_loss: 6.7018e-06
Epoch 387/512
512/512 - 0s - loss: 1.3539e-07 - val_loss: 7.1313e-06
Epoch 388/512
512/512 - 0s - loss: 1.3703e-07 - val_loss: 8.6745e-06
Epoch 389/512
512/512 - 0s - loss: 1.3911e-07 - val_loss: 7.0788e-06
Epoch 390/512
512/512 - 0s - loss: 1.3488e-07 - val_loss: 7.8285e-06
Epoch 391/512
512/512 - 0s - loss: 1.2995e-07 - val_loss: 6.7703e-06
Epoch 392/512
512/512 - 0s - loss: 1.3191e-07 - val_loss: 7.3945e-06
Epoch 393/512
512/512 - 0s - loss: 1.3501e-07 - val_loss: 7.6950e-06
Epoch 394/512
512/512 - 0s - loss: 1.2925e-07 - val_loss: 7.0279e-06
Epoch 395/512
512/512 - 0s - loss: 1.2550e-07 - val_loss: 6.7329e-06
Epoch 396/512
512/512 - 0s - loss: 1.2386e-07 - val_loss: 6.4782e-06
Epoch 397/512
512/512 - 0s - loss: 1.2450e-07 - val_loss: 6.4895e-06
Epoch 398/512
512/512 - 0s - loss: 1.2123e-07 - val_loss: 6.7172e-06
Epoch 399/512
512/512 - 0s - loss: 1.2259e-07 - val_loss: 6.3658e-06
Epoch 400/512
512/512 - 0s - loss: 1.2078e-07 - val_loss: 7.2084e-06
Epoch 401/512
512/512 - 0s - loss: 1.1957e-07 - val_loss: 6.9455e-06
Epoch 402/512
512/512 - 0s - loss: 1.1918e-07 - val_loss: 6.2312e-06
Epoch 403/512
512/512 - 0s - loss: 1.1593e-07 - val_loss: 7.5060e-06
Epoch 404/512
512/512 - 0s - loss: 1.1598e-07 - val_loss: 6.8515e-06
Epoch 405/512
512/512 - 0s - loss: 1.1534e-07 - val_loss: 6.5257e-06
Epoch 406/512
512/512 - 0s - loss: 1.1527e-07 - val_loss: 8.0724e-06
Epoch 407/512
512/512 - 0s - loss: 1.1473e-07 - val_loss: 6.2102e-06
Epoch 408/512
512/512 - 0s - loss: 1.1160e-07 - val_loss: 7.5189e-06
Epoch 409/512
512/512 - 0s - loss: 1.1166e-07 - val_loss: 6.7379e-06
Epoch 410/512
512/512 - 0s - loss: 1.1159e-07 - val_loss: 6.6952e-06
Epoch 411/512
512/512 - 0s - loss: 1.0961e-07 - val_loss: 7.0443e-06
Epoch 412/512
512/512 - 0s - loss: 1.1014e-07 - val_loss: 6.3577e-06
Epoch 413/512
512/512 - 0s - loss: 1.0570e-07 - val_loss: 4.8455e-06
Epoch 414/512
512/512 - 0s - loss: 1.0465e-07 - val_loss: 4.4871e-06
Epoch 415/512
512/512 - 0s - loss: 1.0460e-07 - val_loss: 4.7736e-06
Epoch 416/512
512/512 - 0s - loss: 1.0646e-07 - val_loss: 4.0632e-06
Epoch 417/512
512/512 - 0s - loss: 1.0632e-07 - val_loss: 4.6666e-06
Epoch 418/512
512/512 - 0s - loss: 1.0222e-07 - val_loss: 5.0545e-06
Epoch 419/512
512/512 - 0s - loss: 1.0121e-07 - val_loss: 5.5428e-06
Epoch 420/512
512/512 - 0s - loss: 1.0155e-07 - val_loss: 6.4391e-06
Epoch 421/512
512/512 - 0s - loss: 1.0437e-07 - val_loss: 5.9577e-06
Epoch 422/512
512/512 - 0s - loss: 9.8203e-08 - val_loss: 5.2586e-06
Epoch 423/512
512/512 - 0s - loss: 9.7605e-08 - val_loss: 5.2032e-06
Epoch 424/512
512/512 - 0s - loss: 9.7571e-08 - val_loss: 6.2120e-06
Epoch 425/512
512/512 - 0s - loss: 1.0271e-07 - val_loss: 6.3247e-06
Epoch 426/512
512/512 - 0s - loss: 9.8846e-08 - val_loss: 7.1454e-06
Epoch 427/512
512/512 - 0s - loss: 9.7295e-08 - val_loss: 6.3162e-06
Epoch 428/512
512/512 - 0s - loss: 9.5368e-08 - val_loss: 5.9808e-06
Epoch 429/512
512/512 - 0s - loss: 9.5571e-08 - val_loss: 6.0187e-06
Epoch 430/512
512/512 - 0s - loss: 9.4584e-08 - val_loss: 5.8275e-06
Epoch 431/512
512/512 - 0s - loss: 9.4557e-08 - val_loss: 5.2692e-06
Epoch 432/512
512/512 - 0s - loss: 9.3518e-08 - val_loss: 6.5275e-06
Epoch 433/512
512/512 - 0s - loss: 9.6114e-08 - val_loss: 6.0211e-06
Epoch 434/512
512/512 - 0s - loss: 9.2253e-08 - val_loss: 5.4573e-06
Epoch 435/512
512/512 - 0s - loss: 9.0545e-08 - val_loss: 5.9452e-06
Epoch 436/512
512/512 - 0s - loss: 9.2685e-08 - val_loss: 6.4838e-06
Epoch 437/512
512/512 - 0s - loss: 9.3073e-08 - val_loss: 6.1657e-06
Epoch 438/512
512/512 - 0s - loss: 9.0846e-08 - val_loss: 4.6956e-06
Epoch 439/512
512/512 - 0s - loss: 8.7548e-08 - val_loss: 5.5082e-06
Epoch 440/512
512/512 - 0s - loss: 8.8300e-08 - val_loss: 6.6071e-06
Epoch 441/512
512/512 - 0s - loss: 9.0627e-08 - val_loss: 6.2717e-06
Epoch 442/512
512/512 - 0s - loss: 8.8941e-08 - val_loss: 6.4650e-06
Epoch 443/512
512/512 - 0s - loss: 8.7201e-08 - val_loss: 5.0553e-06
Epoch 444/512
512/512 - 0s - loss: 8.5752e-08 - val_loss: 6.5848e-06
Epoch 445/512
512/512 - 0s - loss: 8.6627e-08 - val_loss: 5.9505e-06
Epoch 446/512
512/512 - 0s - loss: 9.0585e-08 - val_loss: 5.2566e-06
Epoch 447/512
512/512 - 0s - loss: 8.4719e-08 - val_loss: 5.4954e-06
Epoch 448/512
512/512 - 0s - loss: 8.5452e-08 - val_loss: 6.6862e-06
Epoch 449/512
512/512 - 0s - loss: 8.7888e-08 - val_loss: 6.0845e-06
Epoch 450/512
512/512 - 0s - loss: 8.6844e-08 - val_loss: 6.5969e-06
Epoch 451/512
512/512 - 0s - loss: 8.5666e-08 - val_loss: 5.7705e-06
Epoch 452/512
512/512 - 0s - loss: 8.2041e-08 - val_loss: 5.0393e-06
Epoch 453/512
512/512 - 0s - loss: 8.1963e-08 - val_loss: 5.5505e-06
Epoch 454/512
512/512 - 0s - loss: 8.4310e-08 - val_loss: 5.2453e-06
Epoch 455/512
512/512 - 0s - loss: 8.1257e-08 - val_loss: 4.3650e-06
Epoch 456/512
512/512 - 0s - loss: 8.1451e-08 - val_loss: 3.5380e-06
Epoch 457/512
512/512 - 0s - loss: 8.3917e-08 - val_loss: 3.7676e-06
Epoch 458/512
512/512 - 0s - loss: 8.0924e-08 - val_loss: 4.1433e-06
Epoch 459/512
512/512 - 0s - loss: 7.9788e-08 - val_loss: 4.6983e-06
Epoch 460/512
512/512 - 0s - loss: 8.1458e-08 - val_loss: 6.5841e-06
Epoch 461/512
512/512 - 0s - loss: 7.9864e-08 - val_loss: 4.0670e-06
Epoch 462/512
512/512 - 0s - loss: 7.7647e-08 - val_loss: 3.7218e-06
Epoch 463/512
512/512 - 0s - loss: 8.2295e-08 - val_loss: 4.4013e-06
Epoch 464/512
512/512 - 0s - loss: 7.7585e-08 - val_loss: 3.5480e-06
Epoch 465/512
512/512 - 0s - loss: 7.8659e-08 - val_loss: 4.1305e-06
Epoch 466/512
512/512 - 0s - loss: 7.6690e-08 - val_loss: 4.2884e-06
Epoch 467/512
512/512 - 0s - loss: 7.6162e-08 - val_loss: 4.0270e-06
Epoch 468/512
512/512 - 0s - loss: 7.5865e-08 - val_loss: 4.2694e-06
Epoch 469/512
512/512 - 0s - loss: 7.6864e-08 - val_loss: 6.9875e-06
Epoch 470/512
512/512 - 0s - loss: 8.1544e-08 - val_loss: 6.4287e-06
Epoch 471/512
512/512 - 0s - loss: 7.9507e-08 - val_loss: 5.0144e-06
Epoch 472/512
512/512 - 0s - loss: 7.5630e-08 - val_loss: 4.9225e-06
Epoch 473/512
512/512 - 0s - loss: 7.5952e-08 - val_loss: 6.2116e-06
Epoch 474/512
512/512 - 0s - loss: 7.5805e-08 - val_loss: 4.7586e-06
Epoch 475/512
512/512 - 0s - loss: 7.4561e-08 - val_loss: 4.7790e-06
Epoch 476/512
512/512 - 0s - loss: 7.6005e-08 - val_loss: 6.1183e-06
Epoch 477/512
512/512 - 0s - loss: 7.5773e-08 - val_loss: 4.9487e-06
Epoch 478/512
512/512 - 0s - loss: 7.4909e-08 - val_loss: 4.9197e-06
Epoch 479/512
512/512 - 0s - loss: 7.4029e-08 - val_loss: 4.4422e-06
Epoch 480/512
512/512 - 0s - loss: 7.1994e-08 - val_loss: 3.8795e-06
Epoch 481/512
512/512 - 0s - loss: 7.5119e-08 - val_loss: 3.7056e-06
Epoch 482/512
512/512 - 0s - loss: 7.2646e-08 - val_loss: 3.3793e-06
Epoch 483/512
512/512 - 0s - loss: 7.3235e-08 - val_loss: 3.3073e-06
Epoch 484/512
512/512 - 0s - loss: 7.2712e-08 - val_loss: 3.4981e-06
Epoch 485/512
512/512 - 0s - loss: 7.5008e-08 - val_loss: 3.5535e-06
Epoch 486/512
512/512 - 0s - loss: 7.0397e-08 - val_loss: 4.1494e-06
Epoch 487/512
512/512 - 0s - loss: 7.1023e-08 - val_loss: 5.5546e-06
Epoch 488/512
512/512 - 0s - loss: 7.3708e-08 - val_loss: 5.0341e-06
Epoch 489/512
512/512 - 0s - loss: 7.2307e-08 - val_loss: 4.7219e-06
Epoch 490/512
512/512 - 0s - loss: 7.1231e-08 - val_loss: 5.1737e-06
Epoch 491/512
512/512 - 0s - loss: 7.2950e-08 - val_loss: 4.7034e-06
Epoch 492/512
512/512 - 0s - loss: 6.8865e-08 - val_loss: 4.2045e-06
Epoch 493/512
512/512 - 0s - loss: 7.0490e-08 - val_loss: 5.8623e-06
Epoch 494/512
512/512 - 0s - loss: 7.2030e-08 - val_loss: 5.5171e-06
Epoch 495/512
512/512 - 0s - loss: 6.9136e-08 - val_loss: 3.6533e-06
Epoch 496/512
512/512 - 0s - loss: 6.7502e-08 - val_loss: 3.7583e-06
Epoch 497/512
512/512 - 0s - loss: 6.7195e-08 - val_loss: 4.3270e-06
Epoch 498/512
512/512 - 0s - loss: 6.8419e-08 - val_loss: 5.3643e-06
Epoch 499/512
512/512 - 0s - loss: 7.3528e-08 - val_loss: 3.9562e-06
Epoch 500/512
512/512 - 0s - loss: 6.7688e-08 - val_loss: 5.2311e-06
Epoch 501/512
512/512 - 0s - loss: 6.9314e-08 - val_loss: 4.9635e-06
Epoch 502/512
512/512 - 0s - loss: 6.7227e-08 - val_loss: 4.7382e-06
Epoch 503/512
512/512 - 0s - loss: 6.7659e-08 - val_loss: 3.8888e-06
Epoch 504/512
512/512 - 0s - loss: 6.6818e-08 - val_loss: 4.7340e-06
Epoch 505/512
512/512 - 0s - loss: 6.9451e-08 - val_loss: 4.8483e-06
Epoch 506/512
512/512 - 0s - loss: 6.6506e-08 - val_loss: 4.3897e-06
Epoch 507/512
512/512 - 0s - loss: 6.6275e-08 - val_loss: 4.5185e-06
Epoch 508/512
512/512 - 0s - loss: 6.7749e-08 - val_loss: 5.2403e-06
Epoch 509/512
512/512 - 0s - loss: 6.6237e-08 - val_loss: 4.1016e-06
Epoch 510/512
512/512 - 0s - loss: 6.5686e-08 - val_loss: 5.2826e-06
Epoch 511/512
512/512 - 0s - loss: 6.6522e-08 - val_loss: 5.1579e-06
Epoch 512/512
512/512 - 0s - loss: 6.7617e-08 - val_loss: 5.4073e-06
Train on 512 samples, validate on 512 samples
Epoch 1/512

Epoch 00001: val_loss improved from inf to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 1.1566e-09 - val_loss: 7.1270e-11
Epoch 2/512

Epoch 00002: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 6.9443e-11 - val_loss: 6.8534e-11
Epoch 3/512

Epoch 00003: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 6.8591e-11 - val_loss: 6.8488e-11
Epoch 4/512

Epoch 00004: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.8794e-11 - val_loss: 6.8856e-11
Epoch 5/512

Epoch 00005: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 6.8677e-11 - val_loss: 6.8317e-11
Epoch 6/512

Epoch 00006: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.8323e-11 - val_loss: 6.8371e-11
Epoch 7/512

Epoch 00007: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 6.8265e-11 - val_loss: 6.8183e-11
Epoch 8/512

Epoch 00008: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 6.8203e-11 - val_loss: 6.8131e-11
Epoch 9/512

Epoch 00009: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 6.8151e-11 - val_loss: 6.8041e-11
Epoch 10/512

Epoch 00010: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 6.8090e-11 - val_loss: 6.7960e-11
Epoch 11/512

Epoch 00011: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.8220e-11 - val_loss: 6.9058e-11
Epoch 12/512

Epoch 00012: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.9959e-11 - val_loss: 7.1856e-11
Epoch 13/512

Epoch 00013: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.1470e-11 - val_loss: 7.1750e-11
Epoch 14/512

Epoch 00014: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.2475e-11 - val_loss: 7.2578e-11
Epoch 15/512

Epoch 00015: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.4276e-11 - val_loss: 7.6609e-11
Epoch 16/512

Epoch 00016: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8926e-11 - val_loss: 8.3404e-11
Epoch 17/512

Epoch 00017: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.7337e-11 - val_loss: 9.1359e-11
Epoch 18/512

Epoch 00018: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.1520e-11 - val_loss: 9.5665e-11
Epoch 19/512

Epoch 00019: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.8802e-11 - val_loss: 1.0106e-10
Epoch 20/512

Epoch 00020: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0207e-10 - val_loss: 1.0344e-10
Epoch 21/512

Epoch 00021: val_loss did not improve from 0.00000
512/512 - 0s - loss: 1.0255e-10 - val_loss: 9.7264e-11
Epoch 22/512

Epoch 00022: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.1554e-11 - val_loss: 8.5786e-11
Epoch 23/512

Epoch 00023: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.3613e-11 - val_loss: 7.8335e-11
Epoch 24/512

Epoch 00024: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8968e-11 - val_loss: 8.2526e-11
Epoch 25/512

Epoch 00025: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.2526e-11 - val_loss: 7.9390e-11
Epoch 26/512

Epoch 00026: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.9294e-11 - val_loss: 7.9632e-11
Epoch 27/512

Epoch 00027: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.9292e-11 - val_loss: 7.7278e-11
Epoch 28/512

Epoch 00028: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.5951e-11 - val_loss: 7.7035e-11
Epoch 29/512

Epoch 00029: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.0237e-11 - val_loss: 8.2672e-11
Epoch 30/512

Epoch 00030: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.3861e-11 - val_loss: 8.3894e-11
Epoch 31/512

Epoch 00031: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.5154e-11 - val_loss: 8.7345e-11
Epoch 32/512

Epoch 00032: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.8035e-11 - val_loss: 8.9324e-11
Epoch 33/512

Epoch 00033: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.9256e-11 - val_loss: 9.2952e-11
Epoch 34/512

Epoch 00034: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.8804e-11 - val_loss: 8.2147e-11
Epoch 35/512

Epoch 00035: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.0451e-11 - val_loss: 7.9518e-11
Epoch 36/512

Epoch 00036: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.7633e-11 - val_loss: 7.6093e-11
Epoch 37/512

Epoch 00037: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.7176e-11 - val_loss: 7.6377e-11
Epoch 38/512

Epoch 00038: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.6820e-11 - val_loss: 7.8295e-11
Epoch 39/512

Epoch 00039: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.1003e-11 - val_loss: 8.3247e-11
Epoch 40/512

Epoch 00040: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.5784e-11 - val_loss: 9.0216e-11
Epoch 41/512

Epoch 00041: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.9037e-11 - val_loss: 8.8703e-11
Epoch 42/512

Epoch 00042: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.5844e-11 - val_loss: 8.1805e-11
Epoch 43/512

Epoch 00043: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8285e-11 - val_loss: 7.4873e-11
Epoch 44/512

Epoch 00044: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.5171e-11 - val_loss: 7.5556e-11
Epoch 45/512

Epoch 00045: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.4058e-11 - val_loss: 7.4731e-11
Epoch 46/512

Epoch 00046: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.6004e-11 - val_loss: 7.8441e-11
Epoch 47/512

Epoch 00047: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.4171e-11 - val_loss: 9.2358e-11
Epoch 48/512

Epoch 00048: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.3543e-11 - val_loss: 9.0680e-11
Epoch 49/512

Epoch 00049: val_loss did not improve from 0.00000
512/512 - 0s - loss: 9.2796e-11 - val_loss: 9.1600e-11
Epoch 50/512

Epoch 00050: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.9518e-11 - val_loss: 8.4884e-11
Epoch 51/512

Epoch 00051: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.6884e-11 - val_loss: 9.0987e-11
Epoch 52/512

Epoch 00052: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.4374e-11 - val_loss: 7.8524e-11
Epoch 53/512

Epoch 00053: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.6352e-11 - val_loss: 7.5445e-11
Epoch 54/512

Epoch 00054: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.6418e-11 - val_loss: 7.7547e-11
Epoch 55/512

Epoch 00055: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.3696e-11 - val_loss: 7.1455e-11
Epoch 56/512

Epoch 00056: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.1547e-11 - val_loss: 7.3548e-11
Epoch 57/512

Epoch 00057: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.4528e-11 - val_loss: 7.6994e-11
Epoch 58/512

Epoch 00058: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.7491e-11 - val_loss: 7.8436e-11
Epoch 59/512

Epoch 00059: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.6562e-11 - val_loss: 7.6267e-11
Epoch 60/512

Epoch 00060: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.6002e-11 - val_loss: 7.5170e-11
Epoch 61/512

Epoch 00061: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.7080e-11 - val_loss: 7.8572e-11
Epoch 62/512

Epoch 00062: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.9144e-11 - val_loss: 8.2822e-11
Epoch 63/512

Epoch 00063: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.4408e-11 - val_loss: 8.9128e-11
Epoch 64/512

Epoch 00064: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.9494e-11 - val_loss: 8.6122e-11
Epoch 65/512

Epoch 00065: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.7537e-11 - val_loss: 8.8045e-11
Epoch 66/512

Epoch 00066: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.8669e-11 - val_loss: 8.4807e-11
Epoch 67/512

Epoch 00067: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.2415e-11 - val_loss: 8.1589e-11
Epoch 68/512

Epoch 00068: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.2746e-11 - val_loss: 8.5808e-11
Epoch 69/512

Epoch 00069: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.3410e-11 - val_loss: 8.2700e-11
Epoch 70/512

Epoch 00070: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.1444e-11 - val_loss: 7.9216e-11
Epoch 71/512

Epoch 00071: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8060e-11 - val_loss: 7.5401e-11
Epoch 72/512

Epoch 00072: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.4043e-11 - val_loss: 7.2164e-11
Epoch 73/512

Epoch 00073: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.2418e-11 - val_loss: 7.4683e-11
Epoch 74/512

Epoch 00074: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.2981e-11 - val_loss: 7.2082e-11
Epoch 75/512

Epoch 00075: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.1730e-11 - val_loss: 6.9715e-11
Epoch 76/512

Epoch 00076: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.2173e-11 - val_loss: 7.5589e-11
Epoch 77/512

Epoch 00077: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.6019e-11 - val_loss: 7.4596e-11
Epoch 78/512

Epoch 00078: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.4947e-11 - val_loss: 7.7271e-11
Epoch 79/512

Epoch 00079: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.0775e-11 - val_loss: 8.2998e-11
Epoch 80/512

Epoch 00080: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.2799e-11 - val_loss: 8.2877e-11
Epoch 81/512

Epoch 00081: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.2368e-11 - val_loss: 8.1221e-11
Epoch 82/512

Epoch 00082: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.0771e-11 - val_loss: 8.0664e-11
Epoch 83/512

Epoch 00083: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.4023e-11 - val_loss: 8.5293e-11
Epoch 84/512

Epoch 00084: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.2872e-11 - val_loss: 8.2792e-11
Epoch 85/512

Epoch 00085: val_loss did not improve from 0.00000
512/512 - 0s - loss: 8.3207e-11 - val_loss: 7.9546e-11
Epoch 86/512

Epoch 00086: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.5753e-11 - val_loss: 7.0957e-11
Epoch 87/512

Epoch 00087: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 6.8202e-11 - val_loss: 6.5678e-11
Epoch 88/512

Epoch 00088: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5694e-11 - val_loss: 6.6768e-11
Epoch 89/512

Epoch 00089: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 6.6072e-11 - val_loss: 6.4438e-11
Epoch 90/512

Epoch 00090: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 6.2849e-11 - val_loss: 6.1521e-11
Epoch 91/512

Epoch 00091: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 6.1146e-11 - val_loss: 6.0824e-11
Epoch 92/512

Epoch 00092: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 6.0876e-11 - val_loss: 6.0807e-11
Epoch 93/512

Epoch 00093: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.1316e-11 - val_loss: 6.1553e-11
Epoch 94/512

Epoch 00094: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.2303e-11 - val_loss: 6.2769e-11
Epoch 95/512

Epoch 00095: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.2259e-11 - val_loss: 6.2981e-11
Epoch 96/512

Epoch 00096: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.4025e-11 - val_loss: 6.5584e-11
Epoch 97/512

Epoch 00097: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.4960e-11 - val_loss: 6.6151e-11
Epoch 98/512

Epoch 00098: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5987e-11 - val_loss: 6.6854e-11
Epoch 99/512

Epoch 00099: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.7708e-11 - val_loss: 7.0662e-11
Epoch 100/512

Epoch 00100: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.2536e-11 - val_loss: 7.4905e-11
Epoch 101/512

Epoch 00101: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.2840e-11 - val_loss: 7.0198e-11
Epoch 102/512

Epoch 00102: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.1959e-11 - val_loss: 7.6241e-11
Epoch 103/512

Epoch 00103: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.7208e-11 - val_loss: 7.7368e-11
Epoch 104/512

Epoch 00104: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.4755e-11 - val_loss: 7.3663e-11
Epoch 105/512

Epoch 00105: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.1163e-11 - val_loss: 6.8917e-11
Epoch 106/512

Epoch 00106: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.6067e-11 - val_loss: 6.4079e-11
Epoch 107/512

Epoch 00107: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5217e-11 - val_loss: 6.4548e-11
Epoch 108/512

Epoch 00108: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5262e-11 - val_loss: 6.4633e-11
Epoch 109/512

Epoch 00109: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.2745e-11 - val_loss: 6.2111e-11
Epoch 110/512

Epoch 00110: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.1587e-11 - val_loss: 6.1318e-11
Epoch 111/512

Epoch 00111: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 6.0788e-11 - val_loss: 6.0797e-11
Epoch 112/512

Epoch 00112: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.1024e-11 - val_loss: 6.0887e-11
Epoch 113/512

Epoch 00113: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 6.0472e-11 - val_loss: 6.0578e-11
Epoch 114/512

Epoch 00114: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.9977e-11 - val_loss: 6.0170e-11
Epoch 115/512

Epoch 00115: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.9937e-11 - val_loss: 5.9809e-11
Epoch 116/512

Epoch 00116: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.9430e-11 - val_loss: 5.9238e-11
Epoch 117/512

Epoch 00117: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.9174e-11 - val_loss: 5.9048e-11
Epoch 118/512

Epoch 00118: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.9085e-11 - val_loss: 5.8805e-11
Epoch 119/512

Epoch 00119: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8983e-11 - val_loss: 5.9563e-11
Epoch 120/512

Epoch 00120: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.9537e-11 - val_loss: 5.9969e-11
Epoch 121/512

Epoch 00121: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.1060e-11 - val_loss: 6.1638e-11
Epoch 122/512

Epoch 00122: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.2865e-11 - val_loss: 6.4670e-11
Epoch 123/512

Epoch 00123: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5579e-11 - val_loss: 6.7552e-11
Epoch 124/512

Epoch 00124: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.6497e-11 - val_loss: 6.5375e-11
Epoch 125/512

Epoch 00125: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5778e-11 - val_loss: 6.6369e-11
Epoch 126/512

Epoch 00126: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.4876e-11 - val_loss: 6.6090e-11
Epoch 127/512

Epoch 00127: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.8186e-11 - val_loss: 6.8980e-11
Epoch 128/512

Epoch 00128: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.9199e-11 - val_loss: 7.4264e-11
Epoch 129/512

Epoch 00129: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.7906e-11 - val_loss: 7.9541e-11
Epoch 130/512

Epoch 00130: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.8293e-11 - val_loss: 7.3754e-11
Epoch 131/512

Epoch 00131: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.5620e-11 - val_loss: 7.6636e-11
Epoch 132/512

Epoch 00132: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.4596e-11 - val_loss: 7.2234e-11
Epoch 133/512

Epoch 00133: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.2965e-11 - val_loss: 7.4574e-11
Epoch 134/512

Epoch 00134: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.5961e-11 - val_loss: 7.7616e-11
Epoch 135/512

Epoch 00135: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.7790e-11 - val_loss: 7.5208e-11
Epoch 136/512

Epoch 00136: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.1418e-11 - val_loss: 6.7601e-11
Epoch 137/512

Epoch 00137: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.7636e-11 - val_loss: 6.7606e-11
Epoch 138/512

Epoch 00138: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.6994e-11 - val_loss: 6.4205e-11
Epoch 139/512

Epoch 00139: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.3755e-11 - val_loss: 6.2594e-11
Epoch 140/512

Epoch 00140: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.3975e-11 - val_loss: 6.3937e-11
Epoch 141/512

Epoch 00141: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.3905e-11 - val_loss: 6.3062e-11
Epoch 142/512

Epoch 00142: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.2899e-11 - val_loss: 6.3102e-11
Epoch 143/512

Epoch 00143: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.2489e-11 - val_loss: 6.3754e-11
Epoch 144/512

Epoch 00144: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.4361e-11 - val_loss: 6.6080e-11
Epoch 145/512

Epoch 00145: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.6020e-11 - val_loss: 6.8007e-11
Epoch 146/512

Epoch 00146: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.1276e-11 - val_loss: 7.3830e-11
Epoch 147/512

Epoch 00147: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.2114e-11 - val_loss: 7.0524e-11
Epoch 148/512

Epoch 00148: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.0131e-11 - val_loss: 6.6219e-11
Epoch 149/512

Epoch 00149: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5057e-11 - val_loss: 6.5913e-11
Epoch 150/512

Epoch 00150: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5512e-11 - val_loss: 6.4374e-11
Epoch 151/512

Epoch 00151: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.4078e-11 - val_loss: 6.3594e-11
Epoch 152/512

Epoch 00152: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.3973e-11 - val_loss: 6.2442e-11
Epoch 153/512

Epoch 00153: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.2221e-11 - val_loss: 6.1265e-11
Epoch 154/512

Epoch 00154: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.1015e-11 - val_loss: 5.9492e-11
Epoch 155/512

Epoch 00155: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.1686e-11 - val_loss: 6.2991e-11
Epoch 156/512

Epoch 00156: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.4081e-11 - val_loss: 6.5080e-11
Epoch 157/512

Epoch 00157: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.7881e-11 - val_loss: 7.2494e-11
Epoch 158/512

Epoch 00158: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.4086e-11 - val_loss: 7.5161e-11
Epoch 159/512

Epoch 00159: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.4158e-11 - val_loss: 6.9875e-11
Epoch 160/512

Epoch 00160: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.7198e-11 - val_loss: 6.6301e-11
Epoch 161/512

Epoch 00161: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.6443e-11 - val_loss: 6.6178e-11
Epoch 162/512

Epoch 00162: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.6586e-11 - val_loss: 6.8345e-11
Epoch 163/512

Epoch 00163: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.8090e-11 - val_loss: 6.5201e-11
Epoch 164/512

Epoch 00164: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.3760e-11 - val_loss: 6.2320e-11
Epoch 165/512

Epoch 00165: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.1676e-11 - val_loss: 5.9649e-11
Epoch 166/512

Epoch 00166: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.9317e-11 - val_loss: 5.8779e-11
Epoch 167/512

Epoch 00167: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.9108e-11 - val_loss: 5.7569e-11
Epoch 168/512

Epoch 00168: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7726e-11 - val_loss: 5.8800e-11
Epoch 169/512

Epoch 00169: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8303e-11 - val_loss: 5.7683e-11
Epoch 170/512

Epoch 00170: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7610e-11 - val_loss: 5.8475e-11
Epoch 171/512

Epoch 00171: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.0705e-11 - val_loss: 6.2573e-11
Epoch 172/512

Epoch 00172: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.4533e-11 - val_loss: 6.9202e-11
Epoch 173/512

Epoch 00173: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.0525e-11 - val_loss: 7.3893e-11
Epoch 174/512

Epoch 00174: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.3220e-11 - val_loss: 7.0735e-11
Epoch 175/512

Epoch 00175: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.1313e-11 - val_loss: 6.9584e-11
Epoch 176/512

Epoch 00176: val_loss did not improve from 0.00000
512/512 - 0s - loss: 7.0479e-11 - val_loss: 6.8455e-11
Epoch 177/512

Epoch 00177: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.8322e-11 - val_loss: 6.8181e-11
Epoch 178/512

Epoch 00178: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.7003e-11 - val_loss: 6.5858e-11
Epoch 179/512

Epoch 00179: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.4777e-11 - val_loss: 6.1486e-11
Epoch 180/512

Epoch 00180: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.0900e-11 - val_loss: 6.1055e-11
Epoch 181/512

Epoch 00181: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.2537e-11 - val_loss: 6.5655e-11
Epoch 182/512

Epoch 00182: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.7578e-11 - val_loss: 6.5503e-11
Epoch 183/512

Epoch 00183: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5077e-11 - val_loss: 6.3923e-11
Epoch 184/512

Epoch 00184: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.2586e-11 - val_loss: 6.0882e-11
Epoch 185/512

Epoch 00185: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.1747e-11 - val_loss: 6.3130e-11
Epoch 186/512

Epoch 00186: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5723e-11 - val_loss: 6.7138e-11
Epoch 187/512

Epoch 00187: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5001e-11 - val_loss: 6.2664e-11
Epoch 188/512

Epoch 00188: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.1409e-11 - val_loss: 6.0556e-11
Epoch 189/512

Epoch 00189: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.8535e-11 - val_loss: 5.6354e-11
Epoch 190/512

Epoch 00190: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.6157e-11 - val_loss: 5.5152e-11
Epoch 191/512

Epoch 00191: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.4553e-11 - val_loss: 5.3922e-11
Epoch 192/512

Epoch 00192: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3939e-11 - val_loss: 5.4085e-11
Epoch 193/512

Epoch 00193: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4725e-11 - val_loss: 5.5341e-11
Epoch 194/512

Epoch 00194: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.6828e-11 - val_loss: 5.9116e-11
Epoch 195/512

Epoch 00195: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.9352e-11 - val_loss: 6.1467e-11
Epoch 196/512

Epoch 00196: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.1440e-11 - val_loss: 6.0854e-11
Epoch 197/512

Epoch 00197: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.0427e-11 - val_loss: 5.8921e-11
Epoch 198/512

Epoch 00198: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.9660e-11 - val_loss: 5.8442e-11
Epoch 199/512

Epoch 00199: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8315e-11 - val_loss: 6.0109e-11
Epoch 200/512

Epoch 00200: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.0219e-11 - val_loss: 5.9094e-11
Epoch 201/512

Epoch 00201: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.9905e-11 - val_loss: 5.9135e-11
Epoch 202/512

Epoch 00202: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.9084e-11 - val_loss: 5.7012e-11
Epoch 203/512

Epoch 00203: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8467e-11 - val_loss: 6.0984e-11
Epoch 204/512

Epoch 00204: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.2134e-11 - val_loss: 6.2419e-11
Epoch 205/512

Epoch 00205: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5769e-11 - val_loss: 6.8609e-11
Epoch 206/512

Epoch 00206: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.6639e-11 - val_loss: 6.3329e-11
Epoch 207/512

Epoch 00207: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.3414e-11 - val_loss: 6.1526e-11
Epoch 208/512

Epoch 00208: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.1844e-11 - val_loss: 6.3884e-11
Epoch 209/512

Epoch 00209: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.5657e-11 - val_loss: 6.7373e-11
Epoch 210/512

Epoch 00210: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.8916e-11 - val_loss: 6.9901e-11
Epoch 211/512

Epoch 00211: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.6739e-11 - val_loss: 6.5110e-11
Epoch 212/512

Epoch 00212: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.2779e-11 - val_loss: 5.9540e-11
Epoch 213/512

Epoch 00213: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8365e-11 - val_loss: 5.5526e-11
Epoch 214/512

Epoch 00214: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.6436e-11 - val_loss: 5.7499e-11
Epoch 215/512

Epoch 00215: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8180e-11 - val_loss: 5.8297e-11
Epoch 216/512

Epoch 00216: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8944e-11 - val_loss: 5.8794e-11
Epoch 217/512

Epoch 00217: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.0282e-11 - val_loss: 5.8753e-11
Epoch 218/512

Epoch 00218: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7354e-11 - val_loss: 5.6400e-11
Epoch 219/512

Epoch 00219: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.6529e-11 - val_loss: 5.6944e-11
Epoch 220/512

Epoch 00220: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7619e-11 - val_loss: 5.9430e-11
Epoch 221/512

Epoch 00221: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8355e-11 - val_loss: 5.6708e-11
Epoch 222/512

Epoch 00222: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7152e-11 - val_loss: 5.6783e-11
Epoch 223/512

Epoch 00223: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.6717e-11 - val_loss: 5.6546e-11
Epoch 224/512

Epoch 00224: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.6789e-11 - val_loss: 5.7075e-11
Epoch 225/512

Epoch 00225: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7988e-11 - val_loss: 5.7852e-11
Epoch 226/512

Epoch 00226: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7156e-11 - val_loss: 5.6431e-11
Epoch 227/512

Epoch 00227: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.6532e-11 - val_loss: 5.7587e-11
Epoch 228/512

Epoch 00228: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.9011e-11 - val_loss: 6.0142e-11
Epoch 229/512

Epoch 00229: val_loss did not improve from 0.00000
512/512 - 0s - loss: 6.2437e-11 - val_loss: 6.0394e-11
Epoch 230/512

Epoch 00230: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8249e-11 - val_loss: 5.5754e-11
Epoch 231/512

Epoch 00231: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.6888e-11 - val_loss: 5.9284e-11
Epoch 232/512

Epoch 00232: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8850e-11 - val_loss: 5.7964e-11
Epoch 233/512

Epoch 00233: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7647e-11 - val_loss: 5.5948e-11
Epoch 234/512

Epoch 00234: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7196e-11 - val_loss: 5.6573e-11
Epoch 235/512

Epoch 00235: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.6723e-11 - val_loss: 5.7190e-11
Epoch 236/512

Epoch 00236: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7758e-11 - val_loss: 5.8424e-11
Epoch 237/512

Epoch 00237: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.5611e-11 - val_loss: 5.4810e-11
Epoch 238/512

Epoch 00238: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.4332e-11 - val_loss: 5.3234e-11
Epoch 239/512

Epoch 00239: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3413e-11 - val_loss: 5.3725e-11
Epoch 240/512

Epoch 00240: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3552e-11 - val_loss: 5.3623e-11
Epoch 241/512

Epoch 00241: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.3554e-11 - val_loss: 5.2448e-11
Epoch 242/512

Epoch 00242: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.2183e-11 - val_loss: 5.1800e-11
Epoch 243/512

Epoch 00243: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.1619e-11 - val_loss: 5.1409e-11
Epoch 244/512

Epoch 00244: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1752e-11 - val_loss: 5.1841e-11
Epoch 245/512

Epoch 00245: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2407e-11 - val_loss: 5.2854e-11
Epoch 246/512

Epoch 00246: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2259e-11 - val_loss: 5.1876e-11
Epoch 247/512

Epoch 00247: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.1690e-11 - val_loss: 5.1247e-11
Epoch 248/512

Epoch 00248: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.0948e-11 - val_loss: 5.0342e-11
Epoch 249/512

Epoch 00249: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0479e-11 - val_loss: 5.0690e-11
Epoch 250/512

Epoch 00250: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1317e-11 - val_loss: 5.1685e-11
Epoch 251/512

Epoch 00251: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1628e-11 - val_loss: 5.1149e-11
Epoch 252/512

Epoch 00252: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1263e-11 - val_loss: 5.0772e-11
Epoch 253/512

Epoch 00253: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.0458e-11 - val_loss: 5.0215e-11
Epoch 254/512

Epoch 00254: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0458e-11 - val_loss: 5.0224e-11
Epoch 255/512

Epoch 00255: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.0202e-11 - val_loss: 5.0107e-11
Epoch 256/512

Epoch 00256: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0172e-11 - val_loss: 5.0523e-11
Epoch 257/512

Epoch 00257: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1155e-11 - val_loss: 5.2506e-11
Epoch 258/512

Epoch 00258: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3993e-11 - val_loss: 5.5389e-11
Epoch 259/512

Epoch 00259: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.6555e-11 - val_loss: 5.7877e-11
Epoch 260/512

Epoch 00260: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7578e-11 - val_loss: 5.7332e-11
Epoch 261/512

Epoch 00261: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7223e-11 - val_loss: 5.7136e-11
Epoch 262/512

Epoch 00262: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.6509e-11 - val_loss: 5.6453e-11
Epoch 263/512

Epoch 00263: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.9122e-11 - val_loss: 5.9384e-11
Epoch 264/512

Epoch 00264: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8934e-11 - val_loss: 5.8066e-11
Epoch 265/512

Epoch 00265: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8097e-11 - val_loss: 5.6194e-11
Epoch 266/512

Epoch 00266: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.5887e-11 - val_loss: 5.4954e-11
Epoch 267/512

Epoch 00267: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.5982e-11 - val_loss: 5.5059e-11
Epoch 268/512

Epoch 00268: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4678e-11 - val_loss: 5.4783e-11
Epoch 269/512

Epoch 00269: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4683e-11 - val_loss: 5.3921e-11
Epoch 270/512

Epoch 00270: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4681e-11 - val_loss: 5.6421e-11
Epoch 271/512

Epoch 00271: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.6739e-11 - val_loss: 5.4704e-11
Epoch 272/512

Epoch 00272: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3644e-11 - val_loss: 5.2482e-11
Epoch 273/512

Epoch 00273: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2867e-11 - val_loss: 5.3274e-11
Epoch 274/512

Epoch 00274: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2332e-11 - val_loss: 5.1338e-11
Epoch 275/512

Epoch 00275: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1847e-11 - val_loss: 5.3287e-11
Epoch 276/512

Epoch 00276: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.5678e-11 - val_loss: 5.8018e-11
Epoch 277/512

Epoch 00277: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7711e-11 - val_loss: 5.5813e-11
Epoch 278/512

Epoch 00278: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4654e-11 - val_loss: 5.3569e-11
Epoch 279/512

Epoch 00279: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4021e-11 - val_loss: 5.4079e-11
Epoch 280/512

Epoch 00280: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4912e-11 - val_loss: 5.5975e-11
Epoch 281/512

Epoch 00281: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.5196e-11 - val_loss: 5.4155e-11
Epoch 282/512

Epoch 00282: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3598e-11 - val_loss: 5.3239e-11
Epoch 283/512

Epoch 00283: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3845e-11 - val_loss: 5.5879e-11
Epoch 284/512

Epoch 00284: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.5320e-11 - val_loss: 5.4439e-11
Epoch 285/512

Epoch 00285: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2529e-11 - val_loss: 5.2491e-11
Epoch 286/512

Epoch 00286: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3574e-11 - val_loss: 5.3091e-11
Epoch 287/512

Epoch 00287: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4060e-11 - val_loss: 5.3066e-11
Epoch 288/512

Epoch 00288: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2892e-11 - val_loss: 5.4151e-11
Epoch 289/512

Epoch 00289: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4412e-11 - val_loss: 5.6900e-11
Epoch 290/512

Epoch 00290: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.9352e-11 - val_loss: 6.1363e-11
Epoch 291/512

Epoch 00291: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.9609e-11 - val_loss: 5.6662e-11
Epoch 292/512

Epoch 00292: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.6443e-11 - val_loss: 5.8045e-11
Epoch 293/512

Epoch 00293: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8114e-11 - val_loss: 5.6423e-11
Epoch 294/512

Epoch 00294: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4929e-11 - val_loss: 5.4505e-11
Epoch 295/512

Epoch 00295: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3443e-11 - val_loss: 5.2075e-11
Epoch 296/512

Epoch 00296: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3165e-11 - val_loss: 5.4027e-11
Epoch 297/512

Epoch 00297: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2904e-11 - val_loss: 5.2008e-11
Epoch 298/512

Epoch 00298: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3103e-11 - val_loss: 5.2669e-11
Epoch 299/512

Epoch 00299: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 5.1425e-11 - val_loss: 5.0099e-11
Epoch 300/512

Epoch 00300: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0471e-11 - val_loss: 5.1061e-11
Epoch 301/512

Epoch 00301: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1416e-11 - val_loss: 5.1987e-11
Epoch 302/512

Epoch 00302: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.5484e-11 - val_loss: 5.7864e-11
Epoch 303/512

Epoch 00303: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7555e-11 - val_loss: 5.8028e-11
Epoch 304/512

Epoch 00304: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7964e-11 - val_loss: 5.8530e-11
Epoch 305/512

Epoch 00305: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8981e-11 - val_loss: 5.9531e-11
Epoch 306/512

Epoch 00306: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.9104e-11 - val_loss: 5.8883e-11
Epoch 307/512

Epoch 00307: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.8496e-11 - val_loss: 5.8933e-11
Epoch 308/512

Epoch 00308: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.9225e-11 - val_loss: 5.9781e-11
Epoch 309/512

Epoch 00309: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.7531e-11 - val_loss: 5.5641e-11
Epoch 310/512

Epoch 00310: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3626e-11 - val_loss: 5.0748e-11
Epoch 311/512

Epoch 00311: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.9656e-11 - val_loss: 4.8269e-11
Epoch 312/512

Epoch 00312: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8858e-11 - val_loss: 5.0282e-11
Epoch 313/512

Epoch 00313: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0762e-11 - val_loss: 5.0197e-11
Epoch 314/512

Epoch 00314: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9794e-11 - val_loss: 5.0959e-11
Epoch 315/512

Epoch 00315: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0810e-11 - val_loss: 4.9382e-11
Epoch 316/512

Epoch 00316: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.8885e-11 - val_loss: 4.7824e-11
Epoch 317/512

Epoch 00317: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8240e-11 - val_loss: 4.8728e-11
Epoch 318/512

Epoch 00318: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8123e-11 - val_loss: 4.7999e-11
Epoch 319/512

Epoch 00319: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.7968e-11 - val_loss: 4.7673e-11
Epoch 320/512

Epoch 00320: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.7109e-11 - val_loss: 4.6590e-11
Epoch 321/512

Epoch 00321: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6843e-11 - val_loss: 4.6926e-11
Epoch 322/512

Epoch 00322: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.6690e-11 - val_loss: 4.6420e-11
Epoch 323/512

Epoch 00323: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.6478e-11 - val_loss: 4.6377e-11
Epoch 324/512

Epoch 00324: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.6424e-11 - val_loss: 4.6302e-11
Epoch 325/512

Epoch 00325: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.6346e-11 - val_loss: 4.6222e-11
Epoch 326/512

Epoch 00326: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6355e-11 - val_loss: 4.6282e-11
Epoch 327/512

Epoch 00327: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.6295e-11 - val_loss: 4.6200e-11
Epoch 328/512

Epoch 00328: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.6236e-11 - val_loss: 4.6150e-11
Epoch 329/512

Epoch 00329: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.6204e-11 - val_loss: 4.6087e-11
Epoch 330/512

Epoch 00330: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6173e-11 - val_loss: 4.6410e-11
Epoch 331/512

Epoch 00331: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6426e-11 - val_loss: 4.6118e-11
Epoch 332/512

Epoch 00332: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.6088e-11 - val_loss: 4.5980e-11
Epoch 333/512

Epoch 00333: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.5969e-11 - val_loss: 4.5900e-11
Epoch 334/512

Epoch 00334: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6004e-11 - val_loss: 4.6391e-11
Epoch 335/512

Epoch 00335: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6771e-11 - val_loss: 4.6423e-11
Epoch 336/512

Epoch 00336: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6443e-11 - val_loss: 4.7054e-11
Epoch 337/512

Epoch 00337: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7428e-11 - val_loss: 4.7378e-11
Epoch 338/512

Epoch 00338: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.6542e-11 - val_loss: 4.5802e-11
Epoch 339/512

Epoch 00339: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.5797e-11 - val_loss: 4.5715e-11
Epoch 340/512

Epoch 00340: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.5702e-11 - val_loss: 4.5498e-11
Epoch 341/512

Epoch 00341: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5779e-11 - val_loss: 4.6590e-11
Epoch 342/512

Epoch 00342: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7377e-11 - val_loss: 4.7575e-11
Epoch 343/512

Epoch 00343: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8596e-11 - val_loss: 5.2174e-11
Epoch 344/512

Epoch 00344: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3068e-11 - val_loss: 5.2777e-11
Epoch 345/512

Epoch 00345: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.4135e-11 - val_loss: 5.5792e-11
Epoch 346/512

Epoch 00346: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.5224e-11 - val_loss: 5.4686e-11
Epoch 347/512

Epoch 00347: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2739e-11 - val_loss: 5.0938e-11
Epoch 348/512

Epoch 00348: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0663e-11 - val_loss: 4.8751e-11
Epoch 349/512

Epoch 00349: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7479e-11 - val_loss: 4.6267e-11
Epoch 350/512

Epoch 00350: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6613e-11 - val_loss: 4.7376e-11
Epoch 351/512

Epoch 00351: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8037e-11 - val_loss: 4.7044e-11
Epoch 352/512

Epoch 00352: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6523e-11 - val_loss: 4.6785e-11
Epoch 353/512

Epoch 00353: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6341e-11 - val_loss: 4.5673e-11
Epoch 354/512

Epoch 00354: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.5382e-11 - val_loss: 4.4850e-11
Epoch 355/512

Epoch 00355: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.4890e-11 - val_loss: 4.4787e-11
Epoch 356/512

Epoch 00356: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.4879e-11 - val_loss: 4.4775e-11
Epoch 357/512

Epoch 00357: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5084e-11 - val_loss: 4.5996e-11
Epoch 358/512

Epoch 00358: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5983e-11 - val_loss: 4.6518e-11
Epoch 359/512

Epoch 00359: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8863e-11 - val_loss: 5.2162e-11
Epoch 360/512

Epoch 00360: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1265e-11 - val_loss: 5.0447e-11
Epoch 361/512

Epoch 00361: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0664e-11 - val_loss: 5.1786e-11
Epoch 362/512

Epoch 00362: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3509e-11 - val_loss: 5.6311e-11
Epoch 363/512

Epoch 00363: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.6216e-11 - val_loss: 5.2820e-11
Epoch 364/512

Epoch 00364: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2006e-11 - val_loss: 5.0796e-11
Epoch 365/512

Epoch 00365: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0539e-11 - val_loss: 5.0251e-11
Epoch 366/512

Epoch 00366: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0859e-11 - val_loss: 5.0855e-11
Epoch 367/512

Epoch 00367: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0334e-11 - val_loss: 4.7809e-11
Epoch 368/512

Epoch 00368: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6155e-11 - val_loss: 4.5230e-11
Epoch 369/512

Epoch 00369: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.5248e-11 - val_loss: 4.4563e-11
Epoch 370/512

Epoch 00370: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4641e-11 - val_loss: 4.4886e-11
Epoch 371/512

Epoch 00371: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.5176e-11 - val_loss: 4.4450e-11
Epoch 372/512

Epoch 00372: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4862e-11 - val_loss: 4.6040e-11
Epoch 373/512

Epoch 00373: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7182e-11 - val_loss: 4.7518e-11
Epoch 374/512

Epoch 00374: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6430e-11 - val_loss: 4.4557e-11
Epoch 375/512

Epoch 00375: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4788e-11 - val_loss: 4.5464e-11
Epoch 376/512

Epoch 00376: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.5438e-11 - val_loss: 4.4427e-11
Epoch 377/512

Epoch 00377: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4620e-11 - val_loss: 4.4605e-11
Epoch 378/512

Epoch 00378: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5024e-11 - val_loss: 4.6871e-11
Epoch 379/512

Epoch 00379: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8096e-11 - val_loss: 4.8542e-11
Epoch 380/512

Epoch 00380: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.6587e-11 - val_loss: 4.4311e-11
Epoch 381/512

Epoch 00381: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4311e-11 - val_loss: 4.4384e-11
Epoch 382/512

Epoch 00382: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4887e-11 - val_loss: 4.6372e-11
Epoch 383/512

Epoch 00383: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6615e-11 - val_loss: 4.5230e-11
Epoch 384/512

Epoch 00384: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5766e-11 - val_loss: 4.6319e-11
Epoch 385/512

Epoch 00385: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6159e-11 - val_loss: 4.5863e-11
Epoch 386/512

Epoch 00386: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6383e-11 - val_loss: 4.6161e-11
Epoch 387/512

Epoch 00387: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6159e-11 - val_loss: 4.6283e-11
Epoch 388/512

Epoch 00388: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7168e-11 - val_loss: 4.6150e-11
Epoch 389/512

Epoch 00389: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5882e-11 - val_loss: 4.4992e-11
Epoch 390/512

Epoch 00390: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.4678e-11 - val_loss: 4.4252e-11
Epoch 391/512

Epoch 00391: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.4205e-11 - val_loss: 4.4068e-11
Epoch 392/512

Epoch 00392: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5896e-11 - val_loss: 4.9153e-11
Epoch 393/512

Epoch 00393: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9553e-11 - val_loss: 5.0913e-11
Epoch 394/512

Epoch 00394: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0891e-11 - val_loss: 5.0307e-11
Epoch 395/512

Epoch 00395: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0903e-11 - val_loss: 4.8207e-11
Epoch 396/512

Epoch 00396: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7146e-11 - val_loss: 4.5907e-11
Epoch 397/512

Epoch 00397: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6624e-11 - val_loss: 4.8216e-11
Epoch 398/512

Epoch 00398: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9239e-11 - val_loss: 5.0117e-11
Epoch 399/512

Epoch 00399: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0519e-11 - val_loss: 5.1192e-11
Epoch 400/512

Epoch 00400: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.2256e-11 - val_loss: 4.9700e-11
Epoch 401/512

Epoch 00401: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9046e-11 - val_loss: 4.5502e-11
Epoch 402/512

Epoch 00402: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5322e-11 - val_loss: 4.5018e-11
Epoch 403/512

Epoch 00403: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5163e-11 - val_loss: 4.6164e-11
Epoch 404/512

Epoch 00404: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7091e-11 - val_loss: 4.7838e-11
Epoch 405/512

Epoch 00405: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7683e-11 - val_loss: 4.9171e-11
Epoch 406/512

Epoch 00406: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8880e-11 - val_loss: 4.6696e-11
Epoch 407/512

Epoch 00407: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6588e-11 - val_loss: 4.5762e-11
Epoch 408/512

Epoch 00408: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6475e-11 - val_loss: 4.7069e-11
Epoch 409/512

Epoch 00409: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7282e-11 - val_loss: 4.7150e-11
Epoch 410/512

Epoch 00410: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7642e-11 - val_loss: 4.7024e-11
Epoch 411/512

Epoch 00411: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6853e-11 - val_loss: 4.5561e-11
Epoch 412/512

Epoch 00412: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6521e-11 - val_loss: 4.8628e-11
Epoch 413/512

Epoch 00413: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.0998e-11 - val_loss: 5.4156e-11
Epoch 414/512

Epoch 00414: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.3288e-11 - val_loss: 5.2145e-11
Epoch 415/512

Epoch 00415: val_loss did not improve from 0.00000
512/512 - 0s - loss: 5.1238e-11 - val_loss: 4.8691e-11
Epoch 416/512

Epoch 00416: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8620e-11 - val_loss: 4.7985e-11
Epoch 417/512

Epoch 00417: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8419e-11 - val_loss: 4.9723e-11
Epoch 418/512

Epoch 00418: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8566e-11 - val_loss: 4.7269e-11
Epoch 419/512

Epoch 00419: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.6901e-11 - val_loss: 4.5543e-11
Epoch 420/512

Epoch 00420: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4818e-11 - val_loss: 4.6417e-11
Epoch 421/512

Epoch 00421: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7942e-11 - val_loss: 4.9754e-11
Epoch 422/512

Epoch 00422: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9791e-11 - val_loss: 4.9593e-11
Epoch 423/512

Epoch 00423: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9455e-11 - val_loss: 5.0354e-11
Epoch 424/512

Epoch 00424: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.9463e-11 - val_loss: 5.0010e-11
Epoch 425/512

Epoch 00425: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8743e-11 - val_loss: 4.8108e-11
Epoch 426/512

Epoch 00426: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7887e-11 - val_loss: 4.7963e-11
Epoch 427/512

Epoch 00427: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7269e-11 - val_loss: 4.5557e-11
Epoch 428/512

Epoch 00428: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.4441e-11 - val_loss: 4.2408e-11
Epoch 429/512

Epoch 00429: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.2155e-11 - val_loss: 4.1825e-11
Epoch 430/512

Epoch 00430: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.1693e-11 - val_loss: 4.1482e-11
Epoch 431/512

Epoch 00431: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.1525e-11 - val_loss: 4.1476e-11
Epoch 432/512

Epoch 00432: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1942e-11 - val_loss: 4.2155e-11
Epoch 433/512

Epoch 00433: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1762e-11 - val_loss: 4.1940e-11
Epoch 434/512

Epoch 00434: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1663e-11 - val_loss: 4.1712e-11
Epoch 435/512

Epoch 00435: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.1656e-11 - val_loss: 4.1406e-11
Epoch 436/512

Epoch 00436: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1507e-11 - val_loss: 4.1781e-11
Epoch 437/512

Epoch 00437: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.1924e-11 - val_loss: 4.1360e-11
Epoch 438/512

Epoch 00438: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1630e-11 - val_loss: 4.2452e-11
Epoch 439/512

Epoch 00439: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2852e-11 - val_loss: 4.3187e-11
Epoch 440/512

Epoch 00440: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3233e-11 - val_loss: 4.3898e-11
Epoch 441/512

Epoch 00441: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5251e-11 - val_loss: 4.4241e-11
Epoch 442/512

Epoch 00442: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4360e-11 - val_loss: 4.3047e-11
Epoch 443/512

Epoch 00443: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2477e-11 - val_loss: 4.2832e-11
Epoch 444/512

Epoch 00444: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2739e-11 - val_loss: 4.2602e-11
Epoch 445/512

Epoch 00445: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2923e-11 - val_loss: 4.3007e-11
Epoch 446/512

Epoch 00446: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2987e-11 - val_loss: 4.2589e-11
Epoch 447/512

Epoch 00447: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2722e-11 - val_loss: 4.1893e-11
Epoch 448/512

Epoch 00448: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1462e-11 - val_loss: 4.1490e-11
Epoch 449/512

Epoch 00449: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.1329e-11 - val_loss: 4.0880e-11
Epoch 450/512

Epoch 00450: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1103e-11 - val_loss: 4.1052e-11
Epoch 451/512

Epoch 00451: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1489e-11 - val_loss: 4.1464e-11
Epoch 452/512

Epoch 00452: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2275e-11 - val_loss: 4.2986e-11
Epoch 453/512

Epoch 00453: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3446e-11 - val_loss: 4.3776e-11
Epoch 454/512

Epoch 00454: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4212e-11 - val_loss: 4.4668e-11
Epoch 455/512

Epoch 00455: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4597e-11 - val_loss: 4.5285e-11
Epoch 456/512

Epoch 00456: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5171e-11 - val_loss: 4.5204e-11
Epoch 457/512

Epoch 00457: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4806e-11 - val_loss: 4.2906e-11
Epoch 458/512

Epoch 00458: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2780e-11 - val_loss: 4.2804e-11
Epoch 459/512

Epoch 00459: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2897e-11 - val_loss: 4.3583e-11
Epoch 460/512

Epoch 00460: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3240e-11 - val_loss: 4.4407e-11
Epoch 461/512

Epoch 00461: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4008e-11 - val_loss: 4.4928e-11
Epoch 462/512

Epoch 00462: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4672e-11 - val_loss: 4.2978e-11
Epoch 463/512

Epoch 00463: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2340e-11 - val_loss: 4.2101e-11
Epoch 464/512

Epoch 00464: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2035e-11 - val_loss: 4.2818e-11
Epoch 465/512

Epoch 00465: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2308e-11 - val_loss: 4.2040e-11
Epoch 466/512

Epoch 00466: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2084e-11 - val_loss: 4.2043e-11
Epoch 467/512

Epoch 00467: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2559e-11 - val_loss: 4.2358e-11
Epoch 468/512

Epoch 00468: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.1597e-11 - val_loss: 4.0868e-11
Epoch 469/512

Epoch 00469: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0863e-11 - val_loss: 4.2205e-11
Epoch 470/512

Epoch 00470: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3089e-11 - val_loss: 4.6041e-11
Epoch 471/512

Epoch 00471: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4517e-11 - val_loss: 4.1246e-11
Epoch 472/512

Epoch 00472: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.0876e-11 - val_loss: 4.0815e-11
Epoch 473/512

Epoch 00473: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1586e-11 - val_loss: 4.3485e-11
Epoch 474/512

Epoch 00474: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3064e-11 - val_loss: 4.2173e-11
Epoch 475/512

Epoch 00475: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2196e-11 - val_loss: 4.2550e-11
Epoch 476/512

Epoch 00476: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3330e-11 - val_loss: 4.6262e-11
Epoch 477/512

Epoch 00477: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8119e-11 - val_loss: 5.1413e-11
Epoch 478/512

Epoch 00478: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8410e-11 - val_loss: 4.6056e-11
Epoch 479/512

Epoch 00479: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4914e-11 - val_loss: 4.3675e-11
Epoch 480/512

Epoch 00480: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.2895e-11 - val_loss: 4.1204e-11
Epoch 481/512

Epoch 00481: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 4.0540e-11 - val_loss: 3.9720e-11
Epoch 482/512

Epoch 00482: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 3.9539e-11 - val_loss: 3.9388e-11
Epoch 483/512

Epoch 00483: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9457e-11 - val_loss: 3.9584e-11
Epoch 484/512

Epoch 00484: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9902e-11 - val_loss: 3.9494e-11
Epoch 485/512

Epoch 00485: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9962e-11 - val_loss: 3.9728e-11
Epoch 486/512

Epoch 00486: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 3.9513e-11 - val_loss: 3.9252e-11
Epoch 487/512

Epoch 00487: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-ma-rate-0.1-cuvre-secp224r1-0.00005-switch-47/multiplication_weights.h5
512/512 - 0s - loss: 3.9284e-11 - val_loss: 3.9178e-11
Epoch 488/512

Epoch 00488: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9233e-11 - val_loss: 3.9179e-11
Epoch 489/512

Epoch 00489: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9575e-11 - val_loss: 3.9494e-11
Epoch 490/512

Epoch 00490: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0067e-11 - val_loss: 4.0756e-11
Epoch 491/512

Epoch 00491: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9924e-11 - val_loss: 3.9191e-11
Epoch 492/512

Epoch 00492: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9413e-11 - val_loss: 3.9912e-11
Epoch 493/512

Epoch 00493: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9938e-11 - val_loss: 3.9994e-11
Epoch 494/512

Epoch 00494: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0578e-11 - val_loss: 4.0973e-11
Epoch 495/512

Epoch 00495: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1211e-11 - val_loss: 4.3205e-11
Epoch 496/512

Epoch 00496: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4188e-11 - val_loss: 4.5224e-11
Epoch 497/512

Epoch 00497: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3353e-11 - val_loss: 4.0809e-11
Epoch 498/512

Epoch 00498: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0114e-11 - val_loss: 3.9421e-11
Epoch 499/512

Epoch 00499: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9839e-11 - val_loss: 3.9395e-11
Epoch 500/512

Epoch 00500: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9447e-11 - val_loss: 4.0004e-11
Epoch 501/512

Epoch 00501: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9997e-11 - val_loss: 3.9318e-11
Epoch 502/512

Epoch 00502: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9428e-11 - val_loss: 3.9242e-11
Epoch 503/512

Epoch 00503: val_loss did not improve from 0.00000
512/512 - 0s - loss: 3.9655e-11 - val_loss: 4.0238e-11
Epoch 504/512

Epoch 00504: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.0539e-11 - val_loss: 4.1477e-11
Epoch 505/512

Epoch 00505: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.1615e-11 - val_loss: 4.2648e-11
Epoch 506/512

Epoch 00506: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3270e-11 - val_loss: 4.4298e-11
Epoch 507/512

Epoch 00507: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4535e-11 - val_loss: 4.5003e-11
Epoch 508/512

Epoch 00508: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.4764e-11 - val_loss: 4.2511e-11
Epoch 509/512

Epoch 00509: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.3485e-11 - val_loss: 4.4862e-11
Epoch 510/512

Epoch 00510: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.5328e-11 - val_loss: 4.6269e-11
Epoch 511/512

Epoch 00511: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.7849e-11 - val_loss: 4.8455e-11
Epoch 512/512

Epoch 00512: val_loss did not improve from 0.00000
512/512 - 0s - loss: 4.8178e-11 - val_loss: 5.0074e-11
WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?
WARNING:tensorflow:From /home/stud/minawoi/miniconda3/envs/conda-venv/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?
Epoch   0:   0% | abe: 9.697 | eve: 10.865 | bob: 9.565Epoch   0:   0% | abe: 9.656 | eve: 10.862 | bob: 9.534Epoch   0:   1% | abe: 9.614 | eve: 10.857 | bob: 9.500Epoch   0:   2% | abe: 9.585 | eve: 10.867 | bob: 9.478Epoch   0:   3% | abe: 9.539 | eve: 10.867 | bob: 9.439Epoch   0:   3% | abe: 9.510 | eve: 10.867 | bob: 9.418Epoch   0:   4% | abe: 9.472 | eve: 10.862 | bob: 9.385Epoch   0:   5% | abe: 9.451 | eve: 10.865 | bob: 9.370Epoch   0:   6% | abe: 9.434 | eve: 10.872 | bob: 9.357Epoch   0:   7% | abe: 9.414 | eve: 10.883 | bob: 9.341Epoch   0:   7% | abe: 9.402 | eve: 10.886 | bob: 9.332Epoch   0:   8% | abe: 9.384 | eve: 10.883 | bob: 9.315Epoch   0:   9% | abe: 9.364 | eve: 10.887 | bob: 9.297Epoch   0:  10% | abe: 9.348 | eve: 10.885 | bob: 9.284Epoch   0:  10% | abe: 9.333 | eve: 10.892 | bob: 9.271Epoch   0:  11% | abe: 9.318 | eve: 10.887 | bob: 9.257Epoch   0:  12% | abe: 9.304 | eve: 10.884 | bob: 9.245Epoch   0:  13% | abe: 9.293 | eve: 10.884 | bob: 9.237Epoch   0:  14% | abe: 9.284 | eve: 10.882 | bob: 9.230Epoch   0:  14% | abe: 9.272 | eve: 10.883 | bob: 9.220Epoch   0:  15% | abe: 9.264 | eve: 10.886 | bob: 9.214Epoch   0:  16% | abe: 9.253 | eve: 10.886 | bob: 9.204Epoch   0:  17% | abe: 9.243 | eve: 10.884 | bob: 9.196Epoch   0:  17% | abe: 9.234 | eve: 10.884 | bob: 9.189Epoch   0:  18% | abe: 9.228 | eve: 10.883 | bob: 9.184Epoch   0:  19% | abe: 9.222 | eve: 10.886 | bob: 9.179Epoch   0:  20% | abe: 9.216 | eve: 10.885 | bob: 9.175Epoch   0:  21% | abe: 9.210 | eve: 10.885 | bob: 9.170Epoch   0:  21% | abe: 9.205 | eve: 10.884 | bob: 9.166Epoch   0:  22% | abe: 9.200 | eve: 10.885 | bob: 9.161Epoch   0:  23% | abe: 9.195 | eve: 10.889 | bob: 9.157Epoch   0:  24% | abe: 9.191 | eve: 10.888 | bob: 9.154Epoch   0:  25% | abe: 9.188 | eve: 10.889 | bob: 9.152Epoch   0:  25% | abe: 9.184 | eve: 10.892 | bob: 9.149Epoch   0:  26% | abe: 9.179 | eve: 10.893 | bob: 9.144Epoch   0:  27% | abe: 9.175 | eve: 10.893 | bob: 9.141Epoch   0:  28% | abe: 9.171 | eve: 10.893 | bob: 9.138Epoch   0:  28% | abe: 9.169 | eve: 10.895 | bob: 9.136Epoch   0:  29% | abe: 9.166 | eve: 10.896 | bob: 9.133Epoch   0:  30% | abe: 9.162 | eve: 10.896 | bob: 9.130Epoch   0:  31% | abe: 9.159 | eve: 10.897 | bob: 9.128Epoch   0:  32% | abe: 9.157 | eve: 10.897 | bob: 9.126Epoch   0:  32% | abe: 9.155 | eve: 10.899 | bob: 9.125Epoch   0:  33% | abe: 9.153 | eve: 10.900 | bob: 9.123Epoch   0:  34% | abe: 9.150 | eve: 10.901 | bob: 9.120Epoch   0:  35% | abe: 9.146 | eve: 10.902 | bob: 9.117Epoch   0:  35% | abe: 9.145 | eve: 10.903 | bob: 9.116Epoch   0:  36% | abe: 9.142 | eve: 10.903 | bob: 9.113Epoch   0:  37% | abe: 9.140 | eve: 10.906 | bob: 9.112Epoch   0:  38% | abe: 9.139 | eve: 10.905 | bob: 9.111Epoch   0:  39% | abe: 9.136 | eve: 10.906 | bob: 9.109Epoch   0:  39% | abe: 9.135 | eve: 10.907 | bob: 9.108Epoch   0:  40% | abe: 9.133 | eve: 10.908 | bob: 9.106Epoch   0:  41% | abe: 9.133 | eve: 10.907 | bob: 9.106Epoch   0:  42% | abe: 9.132 | eve: 10.908 | bob: 9.105Epoch   0:  42% | abe: 9.131 | eve: 10.910 | bob: 9.104Epoch   0:  43% | abe: 9.129 | eve: 10.910 | bob: 9.103Epoch   0:  44% | abe: 9.127 | eve: 10.910 | bob: 9.102Epoch   0:  45% | abe: 9.126 | eve: 10.911 | bob: 9.100Epoch   0:  46% | abe: 9.124 | eve: 10.913 | bob: 9.098Epoch   0:  46% | abe: 9.123 | eve: 10.913 | bob: 9.098Epoch   0:  47% | abe: 9.121 | eve: 10.915 | bob: 9.096Epoch   0:  48% | abe: 9.120 | eve: 10.915 | bob: 9.095Epoch   0:  49% | abe: 9.119 | eve: 10.915 | bob: 9.095Epoch   0:  50% | abe: 9.118 | eve: 10.916 | bob: 9.093Epoch   0:  50% | abe: 9.117 | eve: 10.916 | bob: 9.093Epoch   0:  51% | abe: 9.116 | eve: 10.916 | bob: 9.091Epoch   0:  52% | abe: 9.114 | eve: 10.917 | bob: 9.090Epoch   0:  53% | abe: 9.113 | eve: 10.916 | bob: 9.089Epoch   0:  53% | abe: 9.113 | eve: 10.918 | bob: 9.089Epoch   0:  54% | abe: 9.113 | eve: 10.917 | bob: 9.089Epoch   0:  55% | abe: 9.111 | eve: 10.918 | bob: 9.088Epoch   0:  56% | abe: 9.110 | eve: 10.918 | bob: 9.086Epoch   0:  57% | abe: 9.109 | eve: 10.920 | bob: 9.085Epoch   0:  57% | abe: 9.107 | eve: 10.921 | bob: 9.084Epoch   0:  58% | abe: 9.107 | eve: 10.922 | bob: 9.084Epoch   0:  59% | abe: 9.106 | eve: 10.922 | bob: 9.083Epoch   0:  60% | abe: 9.105 | eve: 10.923 | bob: 9.082Epoch   0:  60% | abe: 9.105 | eve: 10.923 | bob: 9.082Epoch   0:  61% | abe: 9.104 | eve: 10.924 | bob: 9.082Epoch   0:  62% | abe: 9.103 | eve: 10.924 | bob: 9.081Epoch   0:  63% | abe: 9.102 | eve: 10.923 | bob: 9.080Epoch   0:  64% | abe: 9.102 | eve: 10.923 | bob: 9.080Epoch   0:  64% | abe: 9.101 | eve: 10.923 | bob: 9.079Epoch   0:  65% | abe: 9.101 | eve: 10.924 | bob: 9.079Epoch   0:  66% | abe: 9.100 | eve: 10.924 | bob: 9.078Epoch   0:  67% | abe: 9.099 | eve: 10.925 | bob: 9.078Epoch   0:  67% | abe: 9.098 | eve: 10.925 | bob: 9.077Epoch   0:  68% | abe: 9.098 | eve: 10.926 | bob: 9.077Epoch   0:  69% | abe: 9.097 | eve: 10.926 | bob: 9.076