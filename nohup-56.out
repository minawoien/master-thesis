WARNING:tensorflow:From /home/stud/minawoi/miniconda3/envs/conda-venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2024-04-04 18:11:01.941240: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-04-04 18:11:02.232873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:8a:00.0
2024-04-04 18:11:02.233681: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-04 18:11:02.236621: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-04-04 18:11:02.238824: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-04-04 18:11:02.239471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-04-04 18:11:02.241904: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-04-04 18:11:02.244287: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-04-04 18:11:02.249734: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-04-04 18:11:02.260563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-04-04 18:11:02.260999: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2024-04-04 18:11:02.277606: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199835000 Hz
2024-04-04 18:11:02.282953: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4c9ad50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-04-04 18:11:02.283046: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-04-04 18:11:02.842350: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4663e00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-04-04 18:11:02.842423: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-04-04 18:11:02.846556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:8a:00.0
2024-04-04 18:11:02.846670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-04 18:11:02.846710: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2024-04-04 18:11:02.846742: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2024-04-04 18:11:02.846774: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2024-04-04 18:11:02.846805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2024-04-04 18:11:02.846836: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2024-04-04 18:11:02.846868: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2024-04-04 18:11:02.858346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2024-04-04 18:11:02.858535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2024-04-04 18:11:02.862664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-04-04 18:11:02.862714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-04-04 18:11:02.862740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2024-04-04 18:11:02.867595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30593 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0)
WARNING:tensorflow:Output bob missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to bob.
WARNING:tensorflow:Output eve missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to eve.
2024-04-04 18:11:07.344789: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
Train on 1024 samples, validate on 1024 samples
Epoch 1/2000
1024/1024 - 1s - loss: 16133.9888 - val_loss: 3.7965
Epoch 2/2000
1024/1024 - 0s - loss: 0.7275 - val_loss: 0.1462
Epoch 3/2000
1024/1024 - 0s - loss: 0.1349 - val_loss: 0.1139
Epoch 4/2000
1024/1024 - 0s - loss: 0.1254 - val_loss: 0.1069
Epoch 5/2000
1024/1024 - 0s - loss: 0.1183 - val_loss: 0.1037
Epoch 6/2000
1024/1024 - 0s - loss: 0.1150 - val_loss: 0.1017
Epoch 7/2000
1024/1024 - 0s - loss: 0.1133 - val_loss: 0.1004
Epoch 8/2000
1024/1024 - 0s - loss: 0.1122 - val_loss: 0.0994
Epoch 9/2000
1024/1024 - 0s - loss: 0.1115 - val_loss: 0.0986
Epoch 10/2000
1024/1024 - 0s - loss: 0.1108 - val_loss: 0.0982
Epoch 11/2000
1024/1024 - 0s - loss: 0.1103 - val_loss: 0.0979
Epoch 12/2000
1024/1024 - 0s - loss: 0.1098 - val_loss: 0.0977
Epoch 13/2000
1024/1024 - 0s - loss: 0.1094 - val_loss: 0.0976
Epoch 14/2000
1024/1024 - 0s - loss: 0.1090 - val_loss: 0.0977
Epoch 15/2000
1024/1024 - 0s - loss: 0.1086 - val_loss: 0.0978
Epoch 16/2000
1024/1024 - 0s - loss: 0.1082 - val_loss: 0.0980
Epoch 17/2000
1024/1024 - 0s - loss: 0.1078 - val_loss: 0.0982
Epoch 18/2000
1024/1024 - 0s - loss: 0.1075 - val_loss: 0.0985
Epoch 19/2000
1024/1024 - 0s - loss: 0.1071 - val_loss: 0.0989
Epoch 20/2000
1024/1024 - 0s - loss: 0.1067 - val_loss: 0.0993
Epoch 21/2000
1024/1024 - 0s - loss: 0.1064 - val_loss: 0.0997
Epoch 22/2000
1024/1024 - 0s - loss: 0.1060 - val_loss: 0.1001
Epoch 23/2000
1024/1024 - 0s - loss: 0.1056 - val_loss: 0.1005
Epoch 24/2000
1024/1024 - 0s - loss: 0.1053 - val_loss: 0.1010
Epoch 25/2000
1024/1024 - 0s - loss: 0.1049 - val_loss: 0.1015
Epoch 26/2000
1024/1024 - 0s - loss: 0.1045 - val_loss: 0.1020
Epoch 27/2000
1024/1024 - 0s - loss: 0.1042 - val_loss: 0.1025
Epoch 28/2000
1024/1024 - 0s - loss: 0.1038 - val_loss: 0.1031
Epoch 29/2000
1024/1024 - 0s - loss: 0.1034 - val_loss: 0.1036
Epoch 30/2000
1024/1024 - 0s - loss: 0.1031 - val_loss: 0.1042
Epoch 31/2000
1024/1024 - 0s - loss: 0.1027 - val_loss: 0.1047
Epoch 32/2000
1024/1024 - 0s - loss: 0.1024 - val_loss: 0.1053
Epoch 33/2000
1024/1024 - 0s - loss: 0.1020 - val_loss: 0.1058
Epoch 34/2000
1024/1024 - 0s - loss: 0.1017 - val_loss: 0.1064
Epoch 35/2000
1024/1024 - 0s - loss: 0.1013 - val_loss: 0.1070
Epoch 36/2000
1024/1024 - 0s - loss: 0.1010 - val_loss: 0.1076
Epoch 37/2000
1024/1024 - 0s - loss: 0.1006 - val_loss: 0.1082
Epoch 38/2000
1024/1024 - 0s - loss: 0.1003 - val_loss: 0.1088
Epoch 39/2000
1024/1024 - 0s - loss: 0.1000 - val_loss: 0.1094
Epoch 40/2000
1024/1024 - 0s - loss: 0.0997 - val_loss: 0.1100
Epoch 41/2000
1024/1024 - 0s - loss: 0.0993 - val_loss: 0.1106
Epoch 42/2000
1024/1024 - 0s - loss: 0.0990 - val_loss: 0.1112
Epoch 43/2000
1024/1024 - 0s - loss: 0.0987 - val_loss: 0.1118
Epoch 44/2000
1024/1024 - 0s - loss: 0.0984 - val_loss: 0.1124
Epoch 45/2000
1024/1024 - 0s - loss: 0.0981 - val_loss: 0.1130
Epoch 46/2000
1024/1024 - 0s - loss: 0.0977 - val_loss: 0.1136
Epoch 47/2000
1024/1024 - 0s - loss: 0.0974 - val_loss: 0.1141
Epoch 48/2000
1024/1024 - 0s - loss: 0.0971 - val_loss: 0.1147
Epoch 49/2000
1024/1024 - 0s - loss: 0.0968 - val_loss: 0.1153
Epoch 50/2000
1024/1024 - 0s - loss: 0.0965 - val_loss: 0.1159
Epoch 51/2000
1024/1024 - 0s - loss: 0.0962 - val_loss: 0.1165
Epoch 52/2000
1024/1024 - 0s - loss: 0.0960 - val_loss: 0.1171
Epoch 53/2000
1024/1024 - 0s - loss: 0.0957 - val_loss: 0.1176
Epoch 54/2000
1024/1024 - 0s - loss: 0.0954 - val_loss: 0.1182
Epoch 55/2000
1024/1024 - 0s - loss: 0.0951 - val_loss: 0.1188
Epoch 56/2000
1024/1024 - 0s - loss: 0.0948 - val_loss: 0.1194
Epoch 57/2000
1024/1024 - 0s - loss: 0.0946 - val_loss: 0.1200
Epoch 58/2000
1024/1024 - 0s - loss: 0.0943 - val_loss: 0.1206
Epoch 59/2000
1024/1024 - 0s - loss: 0.0940 - val_loss: 0.1212
Epoch 60/2000
1024/1024 - 0s - loss: 0.0937 - val_loss: 0.1217
Epoch 61/2000
1024/1024 - 0s - loss: 0.0934 - val_loss: 0.1222
Epoch 62/2000
1024/1024 - 0s - loss: 0.0931 - val_loss: 0.1228
Epoch 63/2000
1024/1024 - 0s - loss: 0.0929 - val_loss: 0.1233
Epoch 64/2000
1024/1024 - 0s - loss: 0.0926 - val_loss: 0.1239
Epoch 65/2000
1024/1024 - 0s - loss: 0.0923 - val_loss: 0.1244
Epoch 66/2000
1024/1024 - 0s - loss: 0.0920 - val_loss: 0.1249
Epoch 67/2000
1024/1024 - 0s - loss: 0.0917 - val_loss: 0.1255
Epoch 68/2000
1024/1024 - 0s - loss: 0.0914 - val_loss: 0.1260
Epoch 69/2000
1024/1024 - 0s - loss: 0.0911 - val_loss: 0.1265
Epoch 70/2000
1024/1024 - 0s - loss: 0.0907 - val_loss: 0.1271
Epoch 71/2000
1024/1024 - 0s - loss: 0.0904 - val_loss: 0.1276
Epoch 72/2000
1024/1024 - 0s - loss: 0.0901 - val_loss: 0.1282
Epoch 73/2000
1024/1024 - 0s - loss: 0.0898 - val_loss: 0.1287
Epoch 74/2000
1024/1024 - 0s - loss: 0.0895 - val_loss: 0.1292
Epoch 75/2000
1024/1024 - 0s - loss: 0.0892 - val_loss: 0.1297
Epoch 76/2000
1024/1024 - 0s - loss: 0.0888 - val_loss: 0.1302
Epoch 77/2000
1024/1024 - 0s - loss: 0.0885 - val_loss: 0.1307
Epoch 78/2000
1024/1024 - 0s - loss: 0.0882 - val_loss: 0.1312
Epoch 79/2000
1024/1024 - 0s - loss: 0.0879 - val_loss: 0.1317
Epoch 80/2000
1024/1024 - 0s - loss: 0.0876 - val_loss: 0.1322
Epoch 81/2000
1024/1024 - 0s - loss: 0.0873 - val_loss: 0.1326
Epoch 82/2000
1024/1024 - 0s - loss: 0.0870 - val_loss: 0.1330
Epoch 83/2000
1024/1024 - 0s - loss: 0.0867 - val_loss: 0.1335
Epoch 84/2000
1024/1024 - 0s - loss: 0.0864 - val_loss: 0.1339
Epoch 85/2000
1024/1024 - 0s - loss: 0.0861 - val_loss: 0.1343
Epoch 86/2000
1024/1024 - 0s - loss: 0.0858 - val_loss: 0.1346
Epoch 87/2000
1024/1024 - 0s - loss: 0.0855 - val_loss: 0.1350
Epoch 88/2000
1024/1024 - 0s - loss: 0.0853 - val_loss: 0.1353
Epoch 89/2000
1024/1024 - 0s - loss: 0.0850 - val_loss: 0.1356
Epoch 90/2000
1024/1024 - 0s - loss: 0.0847 - val_loss: 0.1359
Epoch 91/2000
1024/1024 - 0s - loss: 0.0844 - val_loss: 0.1362
Epoch 92/2000
1024/1024 - 0s - loss: 0.0842 - val_loss: 0.1365
Epoch 93/2000
1024/1024 - 0s - loss: 0.0839 - val_loss: 0.1367
Epoch 94/2000
1024/1024 - 0s - loss: 0.0837 - val_loss: 0.1369
Epoch 95/2000
1024/1024 - 0s - loss: 0.0834 - val_loss: 0.1370
Epoch 96/2000
1024/1024 - 0s - loss: 0.0831 - val_loss: 0.1372
Epoch 97/2000
1024/1024 - 0s - loss: 0.0829 - val_loss: 0.1373
Epoch 98/2000
1024/1024 - 0s - loss: 0.0826 - val_loss: 0.1375
Epoch 99/2000
1024/1024 - 0s - loss: 0.0824 - val_loss: 0.1376
Epoch 100/2000
1024/1024 - 0s - loss: 0.0822 - val_loss: 0.1377
Epoch 101/2000
1024/1024 - 0s - loss: 0.0819 - val_loss: 0.1378
Epoch 102/2000
1024/1024 - 0s - loss: 0.0817 - val_loss: 0.1379
Epoch 103/2000
1024/1024 - 0s - loss: 0.0814 - val_loss: 0.1379
Epoch 104/2000
1024/1024 - 0s - loss: 0.0812 - val_loss: 0.1380
Epoch 105/2000
1024/1024 - 0s - loss: 0.0810 - val_loss: 0.1380
Epoch 106/2000
1024/1024 - 0s - loss: 0.0808 - val_loss: 0.1380
Epoch 107/2000
1024/1024 - 0s - loss: 0.0805 - val_loss: 0.1380
Epoch 108/2000
1024/1024 - 0s - loss: 0.0803 - val_loss: 0.1380
Epoch 109/2000
1024/1024 - 0s - loss: 0.0801 - val_loss: 0.1379
Epoch 110/2000
1024/1024 - 0s - loss: 0.0799 - val_loss: 0.1379
Epoch 111/2000
1024/1024 - 0s - loss: 0.0796 - val_loss: 0.1378
Epoch 112/2000
1024/1024 - 0s - loss: 0.0794 - val_loss: 0.1378
Epoch 113/2000
1024/1024 - 0s - loss: 0.0792 - val_loss: 0.1377
Epoch 114/2000
1024/1024 - 0s - loss: 0.0790 - val_loss: 0.1376
Epoch 115/2000
1024/1024 - 0s - loss: 0.0788 - val_loss: 0.1376
Epoch 116/2000
1024/1024 - 0s - loss: 0.0786 - val_loss: 0.1375
Epoch 117/2000
1024/1024 - 0s - loss: 0.0784 - val_loss: 0.1374
Epoch 118/2000
1024/1024 - 0s - loss: 0.0782 - val_loss: 0.1373
Epoch 119/2000
1024/1024 - 0s - loss: 0.0780 - val_loss: 0.1372
Epoch 120/2000
1024/1024 - 0s - loss: 0.0778 - val_loss: 0.1371
Epoch 121/2000
1024/1024 - 0s - loss: 0.0776 - val_loss: 0.1369
Epoch 122/2000
1024/1024 - 0s - loss: 0.0774 - val_loss: 0.1368
Epoch 123/2000
1024/1024 - 0s - loss: 0.0772 - val_loss: 0.1367
Epoch 124/2000
1024/1024 - 0s - loss: 0.0771 - val_loss: 0.1366
Epoch 125/2000
1024/1024 - 0s - loss: 0.0769 - val_loss: 0.1364
Epoch 126/2000
1024/1024 - 0s - loss: 0.0767 - val_loss: 0.1363
Epoch 127/2000
1024/1024 - 0s - loss: 0.0765 - val_loss: 0.1362
Epoch 128/2000
1024/1024 - 0s - loss: 0.0763 - val_loss: 0.1360
Epoch 129/2000
1024/1024 - 0s - loss: 0.0762 - val_loss: 0.1359
Epoch 130/2000
1024/1024 - 0s - loss: 0.0760 - val_loss: 0.1357
Epoch 131/2000
1024/1024 - 0s - loss: 0.0758 - val_loss: 0.1356
Epoch 132/2000
1024/1024 - 0s - loss: 0.0757 - val_loss: 0.1354
Epoch 133/2000
1024/1024 - 0s - loss: 0.0755 - val_loss: 0.1353
Epoch 134/2000
1024/1024 - 0s - loss: 0.0753 - val_loss: 0.1351
Epoch 135/2000
1024/1024 - 0s - loss: 0.0752 - val_loss: 0.1350
Epoch 136/2000
1024/1024 - 0s - loss: 0.0750 - val_loss: 0.1348
Epoch 137/2000
1024/1024 - 0s - loss: 0.0749 - val_loss: 0.1347
Epoch 138/2000
1024/1024 - 0s - loss: 0.0747 - val_loss: 0.1345
Epoch 139/2000
1024/1024 - 0s - loss: 0.0746 - val_loss: 0.1344
Epoch 140/2000
1024/1024 - 0s - loss: 0.0744 - val_loss: 0.1342
Epoch 141/2000
1024/1024 - 0s - loss: 0.0743 - val_loss: 0.1341
Epoch 142/2000
1024/1024 - 0s - loss: 0.0741 - val_loss: 0.1339
Epoch 143/2000
1024/1024 - 0s - loss: 0.0740 - val_loss: 0.1338
Epoch 144/2000
1024/1024 - 0s - loss: 0.0738 - val_loss: 0.1336
Epoch 145/2000
1024/1024 - 0s - loss: 0.0737 - val_loss: 0.1335
Epoch 146/2000
1024/1024 - 0s - loss: 0.0736 - val_loss: 0.1333
Epoch 147/2000
1024/1024 - 0s - loss: 0.0734 - val_loss: 0.1332
Epoch 148/2000
1024/1024 - 0s - loss: 0.0733 - val_loss: 0.1330
Epoch 149/2000
1024/1024 - 0s - loss: 0.0732 - val_loss: 0.1329
Epoch 150/2000
1024/1024 - 0s - loss: 0.0730 - val_loss: 0.1327
Epoch 151/2000
1024/1024 - 0s - loss: 0.0729 - val_loss: 0.1326
Epoch 152/2000
1024/1024 - 0s - loss: 0.0728 - val_loss: 0.1324
Epoch 153/2000
1024/1024 - 0s - loss: 0.0727 - val_loss: 0.1323
Epoch 154/2000
1024/1024 - 0s - loss: 0.0725 - val_loss: 0.1321
Epoch 155/2000
1024/1024 - 0s - loss: 0.0724 - val_loss: 0.1319
Epoch 156/2000
1024/1024 - 0s - loss: 0.0723 - val_loss: 0.1318
Epoch 157/2000
1024/1024 - 0s - loss: 0.0722 - val_loss: 0.1316
Epoch 158/2000
1024/1024 - 0s - loss: 0.0721 - val_loss: 0.1315
Epoch 159/2000
1024/1024 - 0s - loss: 0.0720 - val_loss: 0.1313
Epoch 160/2000
1024/1024 - 0s - loss: 0.0718 - val_loss: 0.1312
Epoch 161/2000
1024/1024 - 0s - loss: 0.0717 - val_loss: 0.1310
Epoch 162/2000
1024/1024 - 0s - loss: 0.0716 - val_loss: 0.1308
Epoch 163/2000
1024/1024 - 0s - loss: 0.0715 - val_loss: 0.1307
Epoch 164/2000
1024/1024 - 0s - loss: 0.0714 - val_loss: 0.1305
Epoch 165/2000
1024/1024 - 0s - loss: 0.0713 - val_loss: 0.1304
Epoch 166/2000
1024/1024 - 0s - loss: 0.0712 - val_loss: 0.1302
Epoch 167/2000
1024/1024 - 0s - loss: 0.0711 - val_loss: 0.1301
Epoch 168/2000
1024/1024 - 0s - loss: 0.0710 - val_loss: 0.1299
Epoch 169/2000
1024/1024 - 0s - loss: 0.0709 - val_loss: 0.1297
Epoch 170/2000
1024/1024 - 0s - loss: 0.0708 - val_loss: 0.1296
Epoch 171/2000
1024/1024 - 0s - loss: 0.0707 - val_loss: 0.1294
Epoch 172/2000
1024/1024 - 0s - loss: 0.0706 - val_loss: 0.1292
Epoch 173/2000
1024/1024 - 0s - loss: 0.0705 - val_loss: 0.1291
Epoch 174/2000
1024/1024 - 0s - loss: 0.0704 - val_loss: 0.1289
Epoch 175/2000
1024/1024 - 0s - loss: 0.0703 - val_loss: 0.1288
Epoch 176/2000
1024/1024 - 0s - loss: 0.0702 - val_loss: 0.1286
Epoch 177/2000
1024/1024 - 0s - loss: 0.0701 - val_loss: 0.1284
Epoch 178/2000
1024/1024 - 0s - loss: 0.0700 - val_loss: 0.1283
Epoch 179/2000
1024/1024 - 0s - loss: 0.0699 - val_loss: 0.1280
Epoch 180/2000
1024/1024 - 0s - loss: 0.0698 - val_loss: 0.1279
Epoch 181/2000
1024/1024 - 0s - loss: 0.0697 - val_loss: 0.1277
Epoch 182/2000
1024/1024 - 0s - loss: 0.0696 - val_loss: 0.1275
Epoch 183/2000
1024/1024 - 0s - loss: 0.0695 - val_loss: 0.1273
Epoch 184/2000
1024/1024 - 0s - loss: 0.0694 - val_loss: 0.1272
Epoch 185/2000
1024/1024 - 0s - loss: 0.0693 - val_loss: 0.1270
Epoch 186/2000
1024/1024 - 0s - loss: 0.0692 - val_loss: 0.1268
Epoch 187/2000
1024/1024 - 0s - loss: 0.0691 - val_loss: 0.1266
Epoch 188/2000
1024/1024 - 0s - loss: 0.0690 - val_loss: 0.1264
Epoch 189/2000
1024/1024 - 0s - loss: 0.0689 - val_loss: 0.1262
Epoch 190/2000
1024/1024 - 0s - loss: 0.0688 - val_loss: 0.1260
Epoch 191/2000
1024/1024 - 0s - loss: 0.0687 - val_loss: 0.1258
Epoch 192/2000
1024/1024 - 0s - loss: 0.0687 - val_loss: 0.1256
Epoch 193/2000
1024/1024 - 0s - loss: 0.0686 - val_loss: 0.1254
Epoch 194/2000
1024/1024 - 0s - loss: 0.0685 - val_loss: 0.1252
Epoch 195/2000
1024/1024 - 0s - loss: 0.0684 - val_loss: 0.1250
Epoch 196/2000
1024/1024 - 0s - loss: 0.0683 - val_loss: 0.1248
Epoch 197/2000
1024/1024 - 0s - loss: 0.0682 - val_loss: 0.1246
Epoch 198/2000
1024/1024 - 0s - loss: 0.0681 - val_loss: 0.1244
Epoch 199/2000
1024/1024 - 0s - loss: 0.0680 - val_loss: 0.1242
Epoch 200/2000
1024/1024 - 0s - loss: 0.0679 - val_loss: 0.1239
Epoch 201/2000
1024/1024 - 0s - loss: 0.0678 - val_loss: 0.1237
Epoch 202/2000
1024/1024 - 0s - loss: 0.0677 - val_loss: 0.1234
Epoch 203/2000
1024/1024 - 0s - loss: 0.0675 - val_loss: 0.1232
Epoch 204/2000
1024/1024 - 0s - loss: 0.0674 - val_loss: 0.1230
Epoch 205/2000
1024/1024 - 0s - loss: 0.0673 - val_loss: 0.1227
Epoch 206/2000
1024/1024 - 0s - loss: 0.0672 - val_loss: 0.1225
Epoch 207/2000
1024/1024 - 0s - loss: 0.0671 - val_loss: 0.1223
Epoch 208/2000
1024/1024 - 0s - loss: 0.0670 - val_loss: 0.1220
Epoch 209/2000
1024/1024 - 0s - loss: 0.0669 - val_loss: 0.1218
Epoch 210/2000
1024/1024 - 0s - loss: 0.0668 - val_loss: 0.1215
Epoch 211/2000
1024/1024 - 0s - loss: 0.0667 - val_loss: 0.1213
Epoch 212/2000
1024/1024 - 0s - loss: 0.0666 - val_loss: 0.1210
Epoch 213/2000
1024/1024 - 0s - loss: 0.0665 - val_loss: 0.1207
Epoch 214/2000
1024/1024 - 0s - loss: 0.0664 - val_loss: 0.1205
Epoch 215/2000
1024/1024 - 0s - loss: 0.0662 - val_loss: 0.1202
Epoch 216/2000
1024/1024 - 0s - loss: 0.0661 - val_loss: 0.1199
Epoch 217/2000
1024/1024 - 0s - loss: 0.0660 - val_loss: 0.1196
Epoch 218/2000
1024/1024 - 0s - loss: 0.0659 - val_loss: 0.1193
Epoch 219/2000
1024/1024 - 0s - loss: 0.0658 - val_loss: 0.1190
Epoch 220/2000
1024/1024 - 0s - loss: 0.0656 - val_loss: 0.1187
Epoch 221/2000
1024/1024 - 0s - loss: 0.0655 - val_loss: 0.1184
Epoch 222/2000
1024/1024 - 0s - loss: 0.0654 - val_loss: 0.1181
Epoch 223/2000
1024/1024 - 0s - loss: 0.0653 - val_loss: 0.1178
Epoch 224/2000
1024/1024 - 0s - loss: 0.0651 - val_loss: 0.1174
Epoch 225/2000
1024/1024 - 0s - loss: 0.0650 - val_loss: 0.1170
Epoch 226/2000
1024/1024 - 0s - loss: 0.0648 - val_loss: 0.1166
Epoch 227/2000
1024/1024 - 0s - loss: 0.0647 - val_loss: 0.1161
Epoch 228/2000
1024/1024 - 0s - loss: 0.0645 - val_loss: 0.1156
Epoch 229/2000
1024/1024 - 0s - loss: 0.0644 - val_loss: 0.1151
Epoch 230/2000
1024/1024 - 0s - loss: 0.0642 - val_loss: 0.1146
Epoch 231/2000
1024/1024 - 0s - loss: 0.0640 - val_loss: 0.1139
Epoch 232/2000
1024/1024 - 0s - loss: 0.0638 - val_loss: 0.1133
Epoch 233/2000
1024/1024 - 0s - loss: 0.0636 - val_loss: 0.1127
Epoch 234/2000
1024/1024 - 0s - loss: 0.0634 - val_loss: 0.1119
Epoch 235/2000
1024/1024 - 0s - loss: 0.0631 - val_loss: 0.1112
Epoch 236/2000
1024/1024 - 0s - loss: 0.0629 - val_loss: 0.1104
Epoch 237/2000
1024/1024 - 0s - loss: 0.0626 - val_loss: 0.1097
Epoch 238/2000
1024/1024 - 0s - loss: 0.0623 - val_loss: 0.1091
Epoch 239/2000
1024/1024 - 0s - loss: 0.0621 - val_loss: 0.1086
Epoch 240/2000
1024/1024 - 0s - loss: 0.0618 - val_loss: 0.1080
Epoch 241/2000
1024/1024 - 0s - loss: 0.0615 - val_loss: 0.1074
Epoch 242/2000
1024/1024 - 0s - loss: 0.0612 - val_loss: 0.1070
Epoch 243/2000
1024/1024 - 0s - loss: 0.0609 - val_loss: 0.1064
Epoch 244/2000
1024/1024 - 0s - loss: 0.0606 - val_loss: 0.1059
Epoch 245/2000
1024/1024 - 0s - loss: 0.0604 - val_loss: 0.1054
Epoch 246/2000
1024/1024 - 0s - loss: 0.0601 - val_loss: 0.1049
Epoch 247/2000
1024/1024 - 0s - loss: 0.0598 - val_loss: 0.1044
Epoch 248/2000
1024/1024 - 0s - loss: 0.0596 - val_loss: 0.1040
Epoch 249/2000
1024/1024 - 0s - loss: 0.0593 - val_loss: 0.1036
Epoch 250/2000
1024/1024 - 0s - loss: 0.0591 - val_loss: 0.1031
Epoch 251/2000
1024/1024 - 0s - loss: 0.0588 - val_loss: 0.1026
Epoch 252/2000
1024/1024 - 0s - loss: 0.0586 - val_loss: 0.1022
Epoch 253/2000
1024/1024 - 0s - loss: 0.0583 - val_loss: 0.1017
Epoch 254/2000
1024/1024 - 0s - loss: 0.0581 - val_loss: 0.1012
Epoch 255/2000
1024/1024 - 0s - loss: 0.0579 - val_loss: 0.1008
Epoch 256/2000
1024/1024 - 0s - loss: 0.0576 - val_loss: 0.1003
Epoch 257/2000
1024/1024 - 0s - loss: 0.0574 - val_loss: 0.0998
Epoch 258/2000
1024/1024 - 0s - loss: 0.0572 - val_loss: 0.0994
Epoch 259/2000
1024/1024 - 0s - loss: 0.0570 - val_loss: 0.0989
Epoch 260/2000
1024/1024 - 0s - loss: 0.0567 - val_loss: 0.0985
Epoch 261/2000
1024/1024 - 0s - loss: 0.0565 - val_loss: 0.0980
Epoch 262/2000
1024/1024 - 0s - loss: 0.0563 - val_loss: 0.0975
Epoch 263/2000
1024/1024 - 0s - loss: 0.0561 - val_loss: 0.0971
Epoch 264/2000
1024/1024 - 0s - loss: 0.0559 - val_loss: 0.0966
Epoch 265/2000
1024/1024 - 0s - loss: 0.0556 - val_loss: 0.0961
Epoch 266/2000
1024/1024 - 0s - loss: 0.0554 - val_loss: 0.0955
Epoch 267/2000
1024/1024 - 0s - loss: 0.0552 - val_loss: 0.0950
Epoch 268/2000
1024/1024 - 0s - loss: 0.0550 - val_loss: 0.0946
Epoch 269/2000
1024/1024 - 0s - loss: 0.0548 - val_loss: 0.0941
Epoch 270/2000
1024/1024 - 0s - loss: 0.0545 - val_loss: 0.0935
Epoch 271/2000
1024/1024 - 0s - loss: 0.0543 - val_loss: 0.0931
Epoch 272/2000
1024/1024 - 0s - loss: 0.0541 - val_loss: 0.0926
Epoch 273/2000
1024/1024 - 0s - loss: 0.0539 - val_loss: 0.0921
Epoch 274/2000
1024/1024 - 0s - loss: 0.0536 - val_loss: 0.0914
Epoch 275/2000
1024/1024 - 0s - loss: 0.0534 - val_loss: 0.0909
Epoch 276/2000
1024/1024 - 0s - loss: 0.0532 - val_loss: 0.0904
Epoch 277/2000
1024/1024 - 0s - loss: 0.0530 - val_loss: 0.0899
Epoch 278/2000
1024/1024 - 0s - loss: 0.0527 - val_loss: 0.0893
Epoch 279/2000
1024/1024 - 0s - loss: 0.0525 - val_loss: 0.0886
Epoch 280/2000
1024/1024 - 0s - loss: 0.0523 - val_loss: 0.0883
Epoch 281/2000
1024/1024 - 0s - loss: 0.0520 - val_loss: 0.0876
Epoch 282/2000
1024/1024 - 0s - loss: 0.0518 - val_loss: 0.0870
Epoch 283/2000
1024/1024 - 0s - loss: 0.0515 - val_loss: 0.0864
Epoch 284/2000
1024/1024 - 0s - loss: 0.0513 - val_loss: 0.0855
Epoch 285/2000
1024/1024 - 0s - loss: 0.0510 - val_loss: 0.0853
Epoch 286/2000
1024/1024 - 0s - loss: 0.0508 - val_loss: 0.0846
Epoch 287/2000
1024/1024 - 0s - loss: 0.0505 - val_loss: 0.0840
Epoch 288/2000
1024/1024 - 0s - loss: 0.0503 - val_loss: 0.0833
Epoch 289/2000
1024/1024 - 0s - loss: 0.0500 - val_loss: 0.0826
Epoch 290/2000
1024/1024 - 0s - loss: 0.0498 - val_loss: 0.0821
Epoch 291/2000
1024/1024 - 0s - loss: 0.0495 - val_loss: 0.0817
Epoch 292/2000
1024/1024 - 0s - loss: 0.0493 - val_loss: 0.0808
Epoch 293/2000
1024/1024 - 0s - loss: 0.0490 - val_loss: 0.0801
Epoch 294/2000
1024/1024 - 0s - loss: 0.0488 - val_loss: 0.0795
Epoch 295/2000
1024/1024 - 0s - loss: 0.0485 - val_loss: 0.0790
Epoch 296/2000
1024/1024 - 0s - loss: 0.0482 - val_loss: 0.0778
Epoch 297/2000
1024/1024 - 0s - loss: 0.0480 - val_loss: 0.0773
Epoch 298/2000
1024/1024 - 0s - loss: 0.0477 - val_loss: 0.0769
Epoch 299/2000
1024/1024 - 0s - loss: 0.0474 - val_loss: 0.0760
Epoch 300/2000
1024/1024 - 0s - loss: 0.0471 - val_loss: 0.0752
Epoch 301/2000
1024/1024 - 0s - loss: 0.0468 - val_loss: 0.0748
Epoch 302/2000
1024/1024 - 0s - loss: 0.0466 - val_loss: 0.0741
Epoch 303/2000
1024/1024 - 0s - loss: 0.0463 - val_loss: 0.0731
Epoch 304/2000
1024/1024 - 0s - loss: 0.0460 - val_loss: 0.0723
Epoch 305/2000
1024/1024 - 0s - loss: 0.0457 - val_loss: 0.0716
Epoch 306/2000
1024/1024 - 0s - loss: 0.0454 - val_loss: 0.0710
Epoch 307/2000
1024/1024 - 0s - loss: 0.0452 - val_loss: 0.0705
Epoch 308/2000
1024/1024 - 0s - loss: 0.0449 - val_loss: 0.0697
Epoch 309/2000
1024/1024 - 0s - loss: 0.0446 - val_loss: 0.0687
Epoch 310/2000
1024/1024 - 0s - loss: 0.0443 - val_loss: 0.0680
Epoch 311/2000
1024/1024 - 0s - loss: 0.0440 - val_loss: 0.0675
Epoch 312/2000
1024/1024 - 0s - loss: 0.0437 - val_loss: 0.0667
Epoch 313/2000
1024/1024 - 0s - loss: 0.0435 - val_loss: 0.0660
Epoch 314/2000
1024/1024 - 0s - loss: 0.0432 - val_loss: 0.0647
Epoch 315/2000
1024/1024 - 0s - loss: 0.0429 - val_loss: 0.0641
Epoch 316/2000
1024/1024 - 0s - loss: 0.0426 - val_loss: 0.0638
Epoch 317/2000
1024/1024 - 0s - loss: 0.0423 - val_loss: 0.0625
Epoch 318/2000
1024/1024 - 0s - loss: 0.0420 - val_loss: 0.0618
Epoch 319/2000
1024/1024 - 0s - loss: 0.0418 - val_loss: 0.0613
Epoch 320/2000
1024/1024 - 0s - loss: 0.0415 - val_loss: 0.0607
Epoch 321/2000
1024/1024 - 0s - loss: 0.0412 - val_loss: 0.0599
Epoch 322/2000
1024/1024 - 0s - loss: 0.0409 - val_loss: 0.0590
Epoch 323/2000
1024/1024 - 0s - loss: 0.0406 - val_loss: 0.0580
Epoch 324/2000
1024/1024 - 0s - loss: 0.0403 - val_loss: 0.0572
Epoch 325/2000
1024/1024 - 0s - loss: 0.0401 - val_loss: 0.0567
Epoch 326/2000
1024/1024 - 0s - loss: 0.0398 - val_loss: 0.0562
Epoch 327/2000
1024/1024 - 0s - loss: 0.0395 - val_loss: 0.0550
Epoch 328/2000
1024/1024 - 0s - loss: 0.0392 - val_loss: 0.0543
Epoch 329/2000
1024/1024 - 0s - loss: 0.0389 - val_loss: 0.0537
Epoch 330/2000
1024/1024 - 0s - loss: 0.0387 - val_loss: 0.0527
Epoch 331/2000
1024/1024 - 0s - loss: 0.0384 - val_loss: 0.0521
Epoch 332/2000
1024/1024 - 0s - loss: 0.0381 - val_loss: 0.0511
Epoch 333/2000
1024/1024 - 0s - loss: 0.0378 - val_loss: 0.0507
Epoch 334/2000
1024/1024 - 0s - loss: 0.0376 - val_loss: 0.0500
Epoch 335/2000
1024/1024 - 0s - loss: 0.0373 - val_loss: 0.0491
Epoch 336/2000
1024/1024 - 0s - loss: 0.0370 - val_loss: 0.0482
Epoch 337/2000
1024/1024 - 0s - loss: 0.0367 - val_loss: 0.0476
Epoch 338/2000
1024/1024 - 0s - loss: 0.0365 - val_loss: 0.0470
Epoch 339/2000
1024/1024 - 0s - loss: 0.0362 - val_loss: 0.0463
Epoch 340/2000
1024/1024 - 0s - loss: 0.0360 - val_loss: 0.0455
Epoch 341/2000
1024/1024 - 0s - loss: 0.0357 - val_loss: 0.0447
Epoch 342/2000
1024/1024 - 0s - loss: 0.0354 - val_loss: 0.0441
Epoch 343/2000
1024/1024 - 0s - loss: 0.0352 - val_loss: 0.0435
Epoch 344/2000
1024/1024 - 0s - loss: 0.0349 - val_loss: 0.0425
Epoch 345/2000
1024/1024 - 0s - loss: 0.0347 - val_loss: 0.0419
Epoch 346/2000
1024/1024 - 0s - loss: 0.0345 - val_loss: 0.0411
Epoch 347/2000
1024/1024 - 0s - loss: 0.0342 - val_loss: 0.0405
Epoch 348/2000
1024/1024 - 0s - loss: 0.0340 - val_loss: 0.0399
Epoch 349/2000
1024/1024 - 0s - loss: 0.0337 - val_loss: 0.0393
Epoch 350/2000
1024/1024 - 0s - loss: 0.0335 - val_loss: 0.0387
Epoch 351/2000
1024/1024 - 0s - loss: 0.0333 - val_loss: 0.0380
Epoch 352/2000
1024/1024 - 0s - loss: 0.0331 - val_loss: 0.0371
Epoch 353/2000
1024/1024 - 0s - loss: 0.0328 - val_loss: 0.0368
Epoch 354/2000
1024/1024 - 0s - loss: 0.0326 - val_loss: 0.0361
Epoch 355/2000
1024/1024 - 0s - loss: 0.0324 - val_loss: 0.0357
Epoch 356/2000
1024/1024 - 0s - loss: 0.0322 - val_loss: 0.0349
Epoch 357/2000
1024/1024 - 0s - loss: 0.0320 - val_loss: 0.0346
Epoch 358/2000
1024/1024 - 0s - loss: 0.0318 - val_loss: 0.0338
Epoch 359/2000
1024/1024 - 0s - loss: 0.0316 - val_loss: 0.0332
Epoch 360/2000
1024/1024 - 0s - loss: 0.0314 - val_loss: 0.0327
Epoch 361/2000
1024/1024 - 0s - loss: 0.0312 - val_loss: 0.0320
Epoch 362/2000
1024/1024 - 0s - loss: 0.0310 - val_loss: 0.0318
Epoch 363/2000
1024/1024 - 0s - loss: 0.0308 - val_loss: 0.0312
Epoch 364/2000
1024/1024 - 0s - loss: 0.0306 - val_loss: 0.0306
Epoch 365/2000
1024/1024 - 0s - loss: 0.0304 - val_loss: 0.0300
Epoch 366/2000
1024/1024 - 0s - loss: 0.0302 - val_loss: 0.0296
Epoch 367/2000
1024/1024 - 0s - loss: 0.0300 - val_loss: 0.0290
Epoch 368/2000
1024/1024 - 0s - loss: 0.0299 - val_loss: 0.0284
Epoch 369/2000
1024/1024 - 0s - loss: 0.0297 - val_loss: 0.0282
Epoch 370/2000
1024/1024 - 0s - loss: 0.0295 - val_loss: 0.0276
Epoch 371/2000
1024/1024 - 0s - loss: 0.0294 - val_loss: 0.0274
Epoch 372/2000
1024/1024 - 0s - loss: 0.0292 - val_loss: 0.0266
Epoch 373/2000
1024/1024 - 0s - loss: 0.0290 - val_loss: 0.0263
Epoch 374/2000
1024/1024 - 0s - loss: 0.0289 - val_loss: 0.0259
Epoch 375/2000
1024/1024 - 0s - loss: 0.0287 - val_loss: 0.0255
Epoch 376/2000
1024/1024 - 0s - loss: 0.0286 - val_loss: 0.0249
Epoch 377/2000
1024/1024 - 0s - loss: 0.0284 - val_loss: 0.0247
Epoch 378/2000
1024/1024 - 0s - loss: 0.0283 - val_loss: 0.0240
Epoch 379/2000
1024/1024 - 0s - loss: 0.0281 - val_loss: 0.0238
Epoch 380/2000
1024/1024 - 0s - loss: 0.0280 - val_loss: 0.0234
Epoch 381/2000
1024/1024 - 0s - loss: 0.0278 - val_loss: 0.0230
Epoch 382/2000
1024/1024 - 0s - loss: 0.0277 - val_loss: 0.0225
Epoch 383/2000
1024/1024 - 0s - loss: 0.0276 - val_loss: 0.0224
Epoch 384/2000
1024/1024 - 0s - loss: 0.0274 - val_loss: 0.0219
Epoch 385/2000
1024/1024 - 0s - loss: 0.0273 - val_loss: 0.0216
Epoch 386/2000
1024/1024 - 0s - loss: 0.0272 - val_loss: 0.0211
Epoch 387/2000
1024/1024 - 0s - loss: 0.0270 - val_loss: 0.0211
Epoch 388/2000
1024/1024 - 0s - loss: 0.0269 - val_loss: 0.0205
Epoch 389/2000
1024/1024 - 0s - loss: 0.0268 - val_loss: 0.0202
Epoch 390/2000
1024/1024 - 0s - loss: 0.0266 - val_loss: 0.0201
Epoch 391/2000
1024/1024 - 0s - loss: 0.0265 - val_loss: 0.0196
Epoch 392/2000
1024/1024 - 0s - loss: 0.0264 - val_loss: 0.0196
Epoch 393/2000
1024/1024 - 0s - loss: 0.0263 - val_loss: 0.0191
Epoch 394/2000
1024/1024 - 0s - loss: 0.0262 - val_loss: 0.0187
Epoch 395/2000
1024/1024 - 0s - loss: 0.0260 - val_loss: 0.0185
Epoch 396/2000
1024/1024 - 0s - loss: 0.0259 - val_loss: 0.0183
Epoch 397/2000
1024/1024 - 0s - loss: 0.0258 - val_loss: 0.0178
Epoch 398/2000
1024/1024 - 0s - loss: 0.0257 - val_loss: 0.0176
Epoch 399/2000
1024/1024 - 0s - loss: 0.0256 - val_loss: 0.0176
Epoch 400/2000
1024/1024 - 0s - loss: 0.0255 - val_loss: 0.0172
Epoch 401/2000
1024/1024 - 0s - loss: 0.0254 - val_loss: 0.0171
Epoch 402/2000
1024/1024 - 0s - loss: 0.0253 - val_loss: 0.0164
Epoch 403/2000
1024/1024 - 0s - loss: 0.0251 - val_loss: 0.0165
Epoch 404/2000
1024/1024 - 0s - loss: 0.0250 - val_loss: 0.0162
Epoch 405/2000
1024/1024 - 0s - loss: 0.0249 - val_loss: 0.0160
Epoch 406/2000
1024/1024 - 0s - loss: 0.0248 - val_loss: 0.0159
Epoch 407/2000
1024/1024 - 0s - loss: 0.0247 - val_loss: 0.0155
Epoch 408/2000
1024/1024 - 0s - loss: 0.0246 - val_loss: 0.0153
Epoch 409/2000
1024/1024 - 0s - loss: 0.0245 - val_loss: 0.0151
Epoch 410/2000
1024/1024 - 0s - loss: 0.0245 - val_loss: 0.0150
Epoch 411/2000
1024/1024 - 0s - loss: 0.0244 - val_loss: 0.0147
Epoch 412/2000
1024/1024 - 0s - loss: 0.0243 - val_loss: 0.0145
Epoch 413/2000
1024/1024 - 0s - loss: 0.0242 - val_loss: 0.0141
Epoch 414/2000
1024/1024 - 0s - loss: 0.0241 - val_loss: 0.0141
Epoch 415/2000
1024/1024 - 0s - loss: 0.0240 - val_loss: 0.0138
Epoch 416/2000
1024/1024 - 0s - loss: 0.0239 - val_loss: 0.0138
Epoch 417/2000
1024/1024 - 0s - loss: 0.0239 - val_loss: 0.0133
Epoch 418/2000
1024/1024 - 0s - loss: 0.0238 - val_loss: 0.0133
Epoch 419/2000
1024/1024 - 0s - loss: 0.0237 - val_loss: 0.0133
Epoch 420/2000
1024/1024 - 0s - loss: 0.0236 - val_loss: 0.0131
Epoch 421/2000
1024/1024 - 0s - loss: 0.0236 - val_loss: 0.0125
Epoch 422/2000
1024/1024 - 0s - loss: 0.0235 - val_loss: 0.0127
Epoch 423/2000
1024/1024 - 0s - loss: 0.0234 - val_loss: 0.0125
Epoch 424/2000
1024/1024 - 0s - loss: 0.0233 - val_loss: 0.0124
Epoch 425/2000
1024/1024 - 0s - loss: 0.0232 - val_loss: 0.0124
Epoch 426/2000
1024/1024 - 0s - loss: 0.0231 - val_loss: 0.0121
Epoch 427/2000
1024/1024 - 0s - loss: 0.0231 - val_loss: 0.0117
Epoch 428/2000
1024/1024 - 0s - loss: 0.0230 - val_loss: 0.0118
Epoch 429/2000
1024/1024 - 0s - loss: 0.0229 - val_loss: 0.0116
Epoch 430/2000
1024/1024 - 0s - loss: 0.0228 - val_loss: 0.0115
Epoch 431/2000
1024/1024 - 0s - loss: 0.0228 - val_loss: 0.0114
Epoch 432/2000
1024/1024 - 0s - loss: 0.0227 - val_loss: 0.0112
Epoch 433/2000
1024/1024 - 0s - loss: 0.0226 - val_loss: 0.0110
Epoch 434/2000
1024/1024 - 0s - loss: 0.0225 - val_loss: 0.0109
Epoch 435/2000
1024/1024 - 0s - loss: 0.0225 - val_loss: 0.0107
Epoch 436/2000
1024/1024 - 0s - loss: 0.0224 - val_loss: 0.0107
Epoch 437/2000
1024/1024 - 0s - loss: 0.0223 - val_loss: 0.0106
Epoch 438/2000
1024/1024 - 0s - loss: 0.0223 - val_loss: 0.0105
Epoch 439/2000
1024/1024 - 0s - loss: 0.0222 - val_loss: 0.0105
Epoch 440/2000
1024/1024 - 0s - loss: 0.0221 - val_loss: 0.0101
Epoch 441/2000
1024/1024 - 0s - loss: 0.0221 - val_loss: 0.0101
Epoch 442/2000
1024/1024 - 0s - loss: 0.0220 - val_loss: 0.0101
Epoch 443/2000
1024/1024 - 0s - loss: 0.0219 - val_loss: 0.0098
Epoch 444/2000
1024/1024 - 0s - loss: 0.0219 - val_loss: 0.0099
Epoch 445/2000
1024/1024 - 0s - loss: 0.0218 - val_loss: 0.0096
Epoch 446/2000
1024/1024 - 0s - loss: 0.0218 - val_loss: 0.0095
Epoch 447/2000
1024/1024 - 0s - loss: 0.0217 - val_loss: 0.0095
Epoch 448/2000
1024/1024 - 0s - loss: 0.0216 - val_loss: 0.0093
Epoch 449/2000
1024/1024 - 0s - loss: 0.0216 - val_loss: 0.0093
Epoch 450/2000
1024/1024 - 0s - loss: 0.0215 - val_loss: 0.0091
Epoch 451/2000
1024/1024 - 0s - loss: 0.0214 - val_loss: 0.0090
Epoch 452/2000
1024/1024 - 0s - loss: 0.0214 - val_loss: 0.0090
Epoch 453/2000
1024/1024 - 0s - loss: 0.0213 - val_loss: 0.0090
Epoch 454/2000
1024/1024 - 0s - loss: 0.0213 - val_loss: 0.0087
Epoch 455/2000
1024/1024 - 0s - loss: 0.0213 - val_loss: 0.0086
Epoch 456/2000
1024/1024 - 0s - loss: 0.0212 - val_loss: 0.0088
Epoch 457/2000
1024/1024 - 0s - loss: 0.0211 - val_loss: 0.0085
Epoch 458/2000
1024/1024 - 0s - loss: 0.0210 - val_loss: 0.0084
Epoch 459/2000
1024/1024 - 0s - loss: 0.0210 - val_loss: 0.0083
Epoch 460/2000
1024/1024 - 0s - loss: 0.0210 - val_loss: 0.0083
Epoch 461/2000
1024/1024 - 0s - loss: 0.0209 - val_loss: 0.0081
Epoch 462/2000
1024/1024 - 0s - loss: 0.0208 - val_loss: 0.0082
Epoch 463/2000
1024/1024 - 0s - loss: 0.0208 - val_loss: 0.0081
Epoch 464/2000
1024/1024 - 0s - loss: 0.0207 - val_loss: 0.0081
Epoch 465/2000
1024/1024 - 0s - loss: 0.0207 - val_loss: 0.0079
Epoch 466/2000
1024/1024 - 0s - loss: 0.0206 - val_loss: 0.0079
Epoch 467/2000
1024/1024 - 0s - loss: 0.0206 - val_loss: 0.0078
Epoch 468/2000
1024/1024 - 0s - loss: 0.0205 - val_loss: 0.0078
Epoch 469/2000
1024/1024 - 0s - loss: 0.0205 - val_loss: 0.0077
Epoch 470/2000
1024/1024 - 0s - loss: 0.0204 - val_loss: 0.0074
Epoch 471/2000
1024/1024 - 0s - loss: 0.0203 - val_loss: 0.0074
Epoch 472/2000
1024/1024 - 0s - loss: 0.0203 - val_loss: 0.0075
Epoch 473/2000
1024/1024 - 0s - loss: 0.0202 - val_loss: 0.0072
Epoch 474/2000
1024/1024 - 0s - loss: 0.0202 - val_loss: 0.0073
Epoch 475/2000
1024/1024 - 0s - loss: 0.0202 - val_loss: 0.0070
Epoch 476/2000
1024/1024 - 0s - loss: 0.0201 - val_loss: 0.0073
Epoch 477/2000
1024/1024 - 0s - loss: 0.0201 - val_loss: 0.0072
Epoch 478/2000
1024/1024 - 0s - loss: 0.0200 - val_loss: 0.0071
Epoch 479/2000
1024/1024 - 0s - loss: 0.0199 - val_loss: 0.0070
Epoch 480/2000
1024/1024 - 0s - loss: 0.0198 - val_loss: 0.0070
Epoch 481/2000
1024/1024 - 0s - loss: 0.0197 - val_loss: 0.0068
Epoch 482/2000
1024/1024 - 0s - loss: 0.0197 - val_loss: 0.0068
Epoch 483/2000
1024/1024 - 0s - loss: 0.0197 - val_loss: 0.0069
Epoch 484/2000
1024/1024 - 0s - loss: 0.0196 - val_loss: 0.0067
Epoch 485/2000
1024/1024 - 0s - loss: 0.0195 - val_loss: 0.0066
Epoch 486/2000
1024/1024 - 0s - loss: 0.0195 - val_loss: 0.0067
Epoch 487/2000
1024/1024 - 0s - loss: 0.0195 - val_loss: 0.0066
Epoch 488/2000
1024/1024 - 0s - loss: 0.0195 - val_loss: 0.0065
Epoch 489/2000
1024/1024 - 0s - loss: 0.0197 - val_loss: 0.0065
Epoch 490/2000
1024/1024 - 0s - loss: 0.0194 - val_loss: 0.0065
Epoch 491/2000
1024/1024 - 0s - loss: 0.0193 - val_loss: 0.0062
Epoch 492/2000
1024/1024 - 0s - loss: 0.0192 - val_loss: 0.0063
Epoch 493/2000
1024/1024 - 0s - loss: 0.0191 - val_loss: 0.0063
Epoch 494/2000
1024/1024 - 0s - loss: 0.0191 - val_loss: 0.0062
Epoch 495/2000
1024/1024 - 0s - loss: 0.0190 - val_loss: 0.0062
Epoch 496/2000
1024/1024 - 0s - loss: 0.0190 - val_loss: 0.0062
Epoch 497/2000
1024/1024 - 0s - loss: 0.0190 - val_loss: 0.0060
Epoch 498/2000
1024/1024 - 0s - loss: 0.0189 - val_loss: 0.0061
Epoch 499/2000
1024/1024 - 0s - loss: 0.0189 - val_loss: 0.0059
Epoch 500/2000
1024/1024 - 0s - loss: 0.0188 - val_loss: 0.0059
Epoch 501/2000
1024/1024 - 0s - loss: 0.0189 - val_loss: 0.0060
Epoch 502/2000
1024/1024 - 0s - loss: 0.0188 - val_loss: 0.0057
Epoch 503/2000
1024/1024 - 0s - loss: 0.0187 - val_loss: 0.0057
Epoch 504/2000
1024/1024 - 0s - loss: 0.0186 - val_loss: 0.0057
Epoch 505/2000
1024/1024 - 0s - loss: 0.0186 - val_loss: 0.0059
Epoch 506/2000
1024/1024 - 0s - loss: 0.0185 - val_loss: 0.0057
Epoch 507/2000
1024/1024 - 0s - loss: 0.0186 - val_loss: 0.0056
Epoch 508/2000
1024/1024 - 0s - loss: 0.0185 - val_loss: 0.0056
Epoch 509/2000
1024/1024 - 0s - loss: 0.0185 - val_loss: 0.0058
Epoch 510/2000
1024/1024 - 0s - loss: 0.0184 - val_loss: 0.0054
Epoch 511/2000
1024/1024 - 0s - loss: 0.0183 - val_loss: 0.0055
Epoch 512/2000
1024/1024 - 0s - loss: 0.0183 - val_loss: 0.0054
Epoch 513/2000
1024/1024 - 0s - loss: 0.0182 - val_loss: 0.0053
Epoch 514/2000
1024/1024 - 0s - loss: 0.0183 - val_loss: 0.0053
Epoch 515/2000
1024/1024 - 0s - loss: 0.0181 - val_loss: 0.0054
Epoch 516/2000
1024/1024 - 0s - loss: 0.0181 - val_loss: 0.0052
Epoch 517/2000
1024/1024 - 0s - loss: 0.0181 - val_loss: 0.0053
Epoch 518/2000
1024/1024 - 0s - loss: 0.0180 - val_loss: 0.0054
Epoch 519/2000
1024/1024 - 0s - loss: 0.0180 - val_loss: 0.0054
Epoch 520/2000
1024/1024 - 0s - loss: 0.0179 - val_loss: 0.0051
Epoch 521/2000
1024/1024 - 0s - loss: 0.0178 - val_loss: 0.0052
Epoch 522/2000
1024/1024 - 0s - loss: 0.0178 - val_loss: 0.0051
Epoch 523/2000
1024/1024 - 0s - loss: 0.0177 - val_loss: 0.0050
Epoch 524/2000
1024/1024 - 0s - loss: 0.0177 - val_loss: 0.0050
Epoch 525/2000
1024/1024 - 0s - loss: 0.0177 - val_loss: 0.0050
Epoch 526/2000
1024/1024 - 0s - loss: 0.0176 - val_loss: 0.0047
Epoch 527/2000
1024/1024 - 0s - loss: 0.0175 - val_loss: 0.0047
Epoch 528/2000
1024/1024 - 0s - loss: 0.0174 - val_loss: 0.0049
Epoch 529/2000
1024/1024 - 0s - loss: 0.0175 - val_loss: 0.0048
Epoch 530/2000
1024/1024 - 0s - loss: 0.0175 - val_loss: 0.0048
Epoch 531/2000
1024/1024 - 0s - loss: 0.0173 - val_loss: 0.0047
Epoch 532/2000
1024/1024 - 0s - loss: 0.0173 - val_loss: 0.0047
Epoch 533/2000
1024/1024 - 0s - loss: 0.0172 - val_loss: 0.0046
Epoch 534/2000
1024/1024 - 0s - loss: 0.0172 - val_loss: 0.0047
Epoch 535/2000
1024/1024 - 0s - loss: 0.0171 - val_loss: 0.0046
Epoch 536/2000
1024/1024 - 0s - loss: 0.0171 - val_loss: 0.0047
Epoch 537/2000
1024/1024 - 0s - loss: 0.0171 - val_loss: 0.0044
Epoch 538/2000
1024/1024 - 0s - loss: 0.0169 - val_loss: 0.0045
Epoch 539/2000
1024/1024 - 0s - loss: 0.0169 - val_loss: 0.0044
Epoch 540/2000
1024/1024 - 0s - loss: 0.0168 - val_loss: 0.0044
Epoch 541/2000
1024/1024 - 0s - loss: 0.0168 - val_loss: 0.0044
Epoch 542/2000
1024/1024 - 0s - loss: 0.0167 - val_loss: 0.0044
Epoch 543/2000
1024/1024 - 0s - loss: 0.0167 - val_loss: 0.0043
Epoch 544/2000
1024/1024 - 0s - loss: 0.0166 - val_loss: 0.0043
Epoch 545/2000
1024/1024 - 0s - loss: 0.0166 - val_loss: 0.0044
Epoch 546/2000
1024/1024 - 0s - loss: 0.0166 - val_loss: 0.0043
Epoch 547/2000
1024/1024 - 0s - loss: 0.0165 - val_loss: 0.0043
Epoch 548/2000
1024/1024 - 0s - loss: 0.0164 - val_loss: 0.0041
Epoch 549/2000
1024/1024 - 0s - loss: 0.0164 - val_loss: 0.0043
Epoch 550/2000
1024/1024 - 0s - loss: 0.0164 - val_loss: 0.0042
Epoch 551/2000
1024/1024 - 0s - loss: 0.0163 - val_loss: 0.0042
Epoch 552/2000
1024/1024 - 0s - loss: 0.0162 - val_loss: 0.0041
Epoch 553/2000
1024/1024 - 0s - loss: 0.0165 - val_loss: 0.0039
Epoch 554/2000
1024/1024 - 0s - loss: 0.0163 - val_loss: 0.0042
Epoch 555/2000
1024/1024 - 0s - loss: 0.0162 - val_loss: 0.0041
Epoch 556/2000
1024/1024 - 0s - loss: 0.0161 - val_loss: 0.0040
Epoch 557/2000
1024/1024 - 0s - loss: 0.0161 - val_loss: 0.0041
Epoch 558/2000
1024/1024 - 0s - loss: 0.0160 - val_loss: 0.0041
Epoch 559/2000
1024/1024 - 0s - loss: 0.0160 - val_loss: 0.0040
Epoch 560/2000
1024/1024 - 0s - loss: 0.0160 - val_loss: 0.0039
Epoch 561/2000
1024/1024 - 0s - loss: 0.0159 - val_loss: 0.0040
Epoch 562/2000
1024/1024 - 0s - loss: 0.0159 - val_loss: 0.0038
Epoch 563/2000
1024/1024 - 0s - loss: 0.0159 - val_loss: 0.0039
Epoch 564/2000
1024/1024 - 0s - loss: 0.0158 - val_loss: 0.0038
Epoch 565/2000
1024/1024 - 0s - loss: 0.0158 - val_loss: 0.0039
Epoch 566/2000
1024/1024 - 0s - loss: 0.0158 - val_loss: 0.0040
Epoch 567/2000
1024/1024 - 0s - loss: 0.0158 - val_loss: 0.0038
Epoch 568/2000
1024/1024 - 0s - loss: 0.0157 - val_loss: 0.0038
Epoch 569/2000
1024/1024 - 0s - loss: 0.0156 - val_loss: 0.0038
Epoch 570/2000
1024/1024 - 0s - loss: 0.0156 - val_loss: 0.0037
Epoch 571/2000
1024/1024 - 0s - loss: 0.0155 - val_loss: 0.0036
Epoch 572/2000
1024/1024 - 0s - loss: 0.0156 - val_loss: 0.0037
Epoch 573/2000
1024/1024 - 0s - loss: 0.0155 - val_loss: 0.0036
Epoch 574/2000
1024/1024 - 0s - loss: 0.0154 - val_loss: 0.0037
Epoch 575/2000
1024/1024 - 0s - loss: 0.0154 - val_loss: 0.0036
Epoch 576/2000
1024/1024 - 0s - loss: 0.0154 - val_loss: 0.0035
Epoch 577/2000
1024/1024 - 0s - loss: 0.0154 - val_loss: 0.0038
Epoch 578/2000
1024/1024 - 0s - loss: 0.0153 - val_loss: 0.0035
Epoch 579/2000
1024/1024 - 0s - loss: 0.0153 - val_loss: 0.0035
Epoch 580/2000
1024/1024 - 0s - loss: 0.0152 - val_loss: 0.0037
Epoch 581/2000
1024/1024 - 0s - loss: 0.0152 - val_loss: 0.0034
Epoch 582/2000
1024/1024 - 0s - loss: 0.0152 - val_loss: 0.0037
Epoch 583/2000
1024/1024 - 0s - loss: 0.0151 - val_loss: 0.0034
Epoch 584/2000
1024/1024 - 0s - loss: 0.0150 - val_loss: 0.0034
Epoch 585/2000
1024/1024 - 0s - loss: 0.0150 - val_loss: 0.0035
Epoch 586/2000
1024/1024 - 0s - loss: 0.0150 - val_loss: 0.0036
Epoch 587/2000
1024/1024 - 0s - loss: 0.0150 - val_loss: 0.0034
Epoch 588/2000
1024/1024 - 0s - loss: 0.0149 - val_loss: 0.0034
Epoch 589/2000
1024/1024 - 0s - loss: 0.0148 - val_loss: 0.0034
Epoch 590/2000
1024/1024 - 0s - loss: 0.0148 - val_loss: 0.0034
Epoch 591/2000
1024/1024 - 0s - loss: 0.0148 - val_loss: 0.0034
Epoch 592/2000
1024/1024 - 0s - loss: 0.0153 - val_loss: 0.0033
Epoch 593/2000
1024/1024 - 0s - loss: 0.0148 - val_loss: 0.0034
Epoch 594/2000
1024/1024 - 0s - loss: 0.0147 - val_loss: 0.0033
Epoch 595/2000
1024/1024 - 0s - loss: 0.0147 - val_loss: 0.0033
Epoch 596/2000
1024/1024 - 0s - loss: 0.0146 - val_loss: 0.0034
Epoch 597/2000
1024/1024 - 0s - loss: 0.0146 - val_loss: 0.0033
Epoch 598/2000
1024/1024 - 0s - loss: 0.0146 - val_loss: 0.0035
Epoch 599/2000
1024/1024 - 0s - loss: 0.0145 - val_loss: 0.0033
Epoch 600/2000
1024/1024 - 0s - loss: 0.0145 - val_loss: 0.0033
Epoch 601/2000
1024/1024 - 0s - loss: 0.0145 - val_loss: 0.0034
Epoch 602/2000
1024/1024 - 0s - loss: 0.0144 - val_loss: 0.0033
Epoch 603/2000
1024/1024 - 0s - loss: 0.0144 - val_loss: 0.0033
Epoch 604/2000
1024/1024 - 0s - loss: 0.0143 - val_loss: 0.0033
Epoch 605/2000
1024/1024 - 0s - loss: 0.0143 - val_loss: 0.0032
Epoch 606/2000
1024/1024 - 0s - loss: 0.0145 - val_loss: 0.0033
Epoch 607/2000
1024/1024 - 0s - loss: 0.0143 - val_loss: 0.0033
Epoch 608/2000
1024/1024 - 0s - loss: 0.0142 - val_loss: 0.0032
Epoch 609/2000
1024/1024 - 0s - loss: 0.0142 - val_loss: 0.0032
Epoch 610/2000
1024/1024 - 0s - loss: 0.0141 - val_loss: 0.0033
Epoch 611/2000
1024/1024 - 0s - loss: 0.0141 - val_loss: 0.0032
Epoch 612/2000
1024/1024 - 0s - loss: 0.0140 - val_loss: 0.0032
Epoch 613/2000
1024/1024 - 0s - loss: 0.0140 - val_loss: 0.0032
Epoch 614/2000
1024/1024 - 0s - loss: 0.0140 - val_loss: 0.0031
Epoch 615/2000
1024/1024 - 0s - loss: 0.0140 - val_loss: 0.0032
Epoch 616/2000
1024/1024 - 0s - loss: 0.0140 - val_loss: 0.0032
Epoch 617/2000
1024/1024 - 0s - loss: 0.0139 - val_loss: 0.0032
Epoch 618/2000
1024/1024 - 0s - loss: 0.0139 - val_loss: 0.0032
Epoch 619/2000
1024/1024 - 0s - loss: 0.0139 - val_loss: 0.0031
Epoch 620/2000
1024/1024 - 0s - loss: 0.0138 - val_loss: 0.0032
Epoch 621/2000
1024/1024 - 0s - loss: 0.0138 - val_loss: 0.0032
Epoch 622/2000
1024/1024 - 0s - loss: 0.0138 - val_loss: 0.0032
Epoch 623/2000
1024/1024 - 0s - loss: 0.0137 - val_loss: 0.0032
Epoch 624/2000
1024/1024 - 0s - loss: 0.0136 - val_loss: 0.0032
Epoch 625/2000
1024/1024 - 0s - loss: 0.0136 - val_loss: 0.0031
Epoch 626/2000
1024/1024 - 0s - loss: 0.0136 - val_loss: 0.0031
Epoch 627/2000
1024/1024 - 0s - loss: 0.0136 - val_loss: 0.0032
Epoch 628/2000
1024/1024 - 0s - loss: 0.0136 - val_loss: 0.0032
Epoch 629/2000
1024/1024 - 0s - loss: 0.0135 - val_loss: 0.0032
Epoch 630/2000
1024/1024 - 0s - loss: 0.0135 - val_loss: 0.0031
Epoch 631/2000
1024/1024 - 0s - loss: 0.0134 - val_loss: 0.0031
Epoch 632/2000
1024/1024 - 0s - loss: 0.0134 - val_loss: 0.0031
Epoch 633/2000
1024/1024 - 0s - loss: 0.0134 - val_loss: 0.0031
Epoch 634/2000
1024/1024 - 0s - loss: 0.0134 - val_loss: 0.0031
Epoch 635/2000
1024/1024 - 0s - loss: 0.0134 - val_loss: 0.0032
Epoch 636/2000
1024/1024 - 0s - loss: 0.0135 - val_loss: 0.0032
Epoch 637/2000
1024/1024 - 0s - loss: 0.0134 - val_loss: 0.0031
Epoch 638/2000
1024/1024 - 0s - loss: 0.0134 - val_loss: 0.0031
Epoch 639/2000
1024/1024 - 0s - loss: 0.0132 - val_loss: 0.0031
Epoch 640/2000
1024/1024 - 0s - loss: 0.0131 - val_loss: 0.0031
Epoch 641/2000
1024/1024 - 0s - loss: 0.0131 - val_loss: 0.0031
Epoch 642/2000
1024/1024 - 0s - loss: 0.0130 - val_loss: 0.0031
Epoch 643/2000
1024/1024 - 0s - loss: 0.0130 - val_loss: 0.0031
Epoch 644/2000
1024/1024 - 0s - loss: 0.0131 - val_loss: 0.0030
Epoch 645/2000
1024/1024 - 0s - loss: 0.0130 - val_loss: 0.0031
Epoch 646/2000
1024/1024 - 0s - loss: 0.0129 - val_loss: 0.0032
Epoch 647/2000
1024/1024 - 0s - loss: 0.0129 - val_loss: 0.0031
Epoch 648/2000
1024/1024 - 0s - loss: 0.0129 - val_loss: 0.0030
Epoch 649/2000
1024/1024 - 0s - loss: 0.0127 - val_loss: 0.0031
Epoch 650/2000
1024/1024 - 0s - loss: 0.0127 - val_loss: 0.0031
Epoch 651/2000
1024/1024 - 0s - loss: 0.0126 - val_loss: 0.0032
Epoch 652/2000
1024/1024 - 0s - loss: 0.0126 - val_loss: 0.0031
Epoch 653/2000
1024/1024 - 0s - loss: 0.0126 - val_loss: 0.0032
Epoch 654/2000
1024/1024 - 0s - loss: 0.0130 - val_loss: 0.0030
Epoch 655/2000
1024/1024 - 0s - loss: 0.0127 - val_loss: 0.0031
Epoch 656/2000
1024/1024 - 0s - loss: 0.0125 - val_loss: 0.0031
Epoch 657/2000
1024/1024 - 0s - loss: 0.0124 - val_loss: 0.0032
Epoch 658/2000
1024/1024 - 0s - loss: 0.0125 - val_loss: 0.0031
Epoch 659/2000
1024/1024 - 0s - loss: 0.0125 - val_loss: 0.0031
Epoch 660/2000
1024/1024 - 0s - loss: 0.0125 - val_loss: 0.0032
Epoch 661/2000
1024/1024 - 0s - loss: 0.0124 - val_loss: 0.0031
Epoch 662/2000
1024/1024 - 0s - loss: 0.0124 - val_loss: 0.0031
Epoch 663/2000
1024/1024 - 0s - loss: 0.0129 - val_loss: 0.0031
Epoch 664/2000
1024/1024 - 0s - loss: 0.0130 - val_loss: 0.0032
Epoch 665/2000
1024/1024 - 0s - loss: 0.0124 - val_loss: 0.0031
Epoch 666/2000
1024/1024 - 0s - loss: 0.0124 - val_loss: 0.0029
Epoch 667/2000
1024/1024 - 0s - loss: 0.0123 - val_loss: 0.0031
Epoch 668/2000
1024/1024 - 0s - loss: 0.0122 - val_loss: 0.0032
Epoch 669/2000
1024/1024 - 0s - loss: 0.0121 - val_loss: 0.0032
Epoch 670/2000
1024/1024 - 0s - loss: 0.0120 - val_loss: 0.0031
Epoch 671/2000
1024/1024 - 0s - loss: 0.0120 - val_loss: 0.0030
Epoch 672/2000
1024/1024 - 0s - loss: 0.0119 - val_loss: 0.0031
Epoch 673/2000
1024/1024 - 0s - loss: 0.0119 - val_loss: 0.0031
Epoch 674/2000
1024/1024 - 0s - loss: 0.0119 - val_loss: 0.0031
Epoch 675/2000
1024/1024 - 0s - loss: 0.0118 - val_loss: 0.0031
Epoch 676/2000
1024/1024 - 0s - loss: 0.0118 - val_loss: 0.0032
Epoch 677/2000
1024/1024 - 0s - loss: 0.0118 - val_loss: 0.0032
Epoch 678/2000
1024/1024 - 0s - loss: 0.0122 - val_loss: 0.0031
Epoch 679/2000
1024/1024 - 0s - loss: 0.0119 - val_loss: 0.0031
Epoch 680/2000
1024/1024 - 0s - loss: 0.0117 - val_loss: 0.0031
Epoch 681/2000
1024/1024 - 0s - loss: 0.0117 - val_loss: 0.0032
Epoch 682/2000
1024/1024 - 0s - loss: 0.0117 - val_loss: 0.0031
Epoch 683/2000
1024/1024 - 0s - loss: 0.0117 - val_loss: 0.0031
Epoch 684/2000
1024/1024 - 0s - loss: 0.0116 - val_loss: 0.0031
Epoch 685/2000
1024/1024 - 0s - loss: 0.0115 - val_loss: 0.0031
Epoch 686/2000
1024/1024 - 0s - loss: 0.0115 - val_loss: 0.0031
Epoch 687/2000
1024/1024 - 0s - loss: 0.0115 - val_loss: 0.0032
Epoch 688/2000
1024/1024 - 0s - loss: 0.0115 - val_loss: 0.0032
Epoch 689/2000
1024/1024 - 0s - loss: 0.0115 - val_loss: 0.0031
Epoch 690/2000
1024/1024 - 0s - loss: 0.0115 - val_loss: 0.0031
Epoch 691/2000
1024/1024 - 0s - loss: 0.0115 - val_loss: 0.0031
Epoch 692/2000
1024/1024 - 0s - loss: 0.0115 - val_loss: 0.0031
Epoch 693/2000
1024/1024 - 0s - loss: 0.0114 - val_loss: 0.0031
Epoch 694/2000
1024/1024 - 0s - loss: 0.0114 - val_loss: 0.0031
Epoch 695/2000
1024/1024 - 0s - loss: 0.0113 - val_loss: 0.0032
Epoch 696/2000
1024/1024 - 0s - loss: 0.0113 - val_loss: 0.0032
Epoch 697/2000
1024/1024 - 0s - loss: 0.0113 - val_loss: 0.0031
Epoch 698/2000
1024/1024 - 0s - loss: 0.0112 - val_loss: 0.0031
Epoch 699/2000
1024/1024 - 0s - loss: 0.0112 - val_loss: 0.0031
Epoch 700/2000
1024/1024 - 0s - loss: 0.0111 - val_loss: 0.0031
Epoch 701/2000
1024/1024 - 0s - loss: 0.0112 - val_loss: 0.0031
Epoch 702/2000
1024/1024 - 0s - loss: 0.0111 - val_loss: 0.0031
Epoch 703/2000
1024/1024 - 0s - loss: 0.0110 - val_loss: 0.0032
Epoch 704/2000
1024/1024 - 0s - loss: 0.0110 - val_loss: 0.0031
Epoch 705/2000
1024/1024 - 0s - loss: 0.0110 - val_loss: 0.0031
Epoch 706/2000
1024/1024 - 0s - loss: 0.0110 - val_loss: 0.0032
Epoch 707/2000
1024/1024 - 0s - loss: 0.0109 - val_loss: 0.0032
Epoch 708/2000
1024/1024 - 0s - loss: 0.0109 - val_loss: 0.0031
Epoch 709/2000
1024/1024 - 0s - loss: 0.0110 - val_loss: 0.0031
Epoch 710/2000
1024/1024 - 0s - loss: 0.0110 - val_loss: 0.0032
Epoch 711/2000
1024/1024 - 0s - loss: 0.0109 - val_loss: 0.0032
Epoch 712/2000
1024/1024 - 0s - loss: 0.0108 - val_loss: 0.0032
Epoch 713/2000
1024/1024 - 0s - loss: 0.0107 - val_loss: 0.0031
Epoch 714/2000
1024/1024 - 0s - loss: 0.0107 - val_loss: 0.0031
Epoch 715/2000
1024/1024 - 0s - loss: 0.0107 - val_loss: 0.0031
Epoch 716/2000
1024/1024 - 0s - loss: 0.0109 - val_loss: 0.0031
Epoch 717/2000
1024/1024 - 0s - loss: 0.0107 - val_loss: 0.0032
Epoch 718/2000
1024/1024 - 0s - loss: 0.0106 - val_loss: 0.0032
Epoch 719/2000
1024/1024 - 0s - loss: 0.0106 - val_loss: 0.0032
Epoch 720/2000
1024/1024 - 0s - loss: 0.0106 - val_loss: 0.0031
Epoch 721/2000
1024/1024 - 0s - loss: 0.0106 - val_loss: 0.0032
Epoch 722/2000
1024/1024 - 0s - loss: 0.0106 - val_loss: 0.0032
Epoch 723/2000
1024/1024 - 0s - loss: 0.0105 - val_loss: 0.0032
Epoch 724/2000
1024/1024 - 0s - loss: 0.0105 - val_loss: 0.0031
Epoch 725/2000
1024/1024 - 0s - loss: 0.0105 - val_loss: 0.0031
Epoch 726/2000
1024/1024 - 0s - loss: 0.0105 - val_loss: 0.0031
Epoch 727/2000
1024/1024 - 0s - loss: 0.0105 - val_loss: 0.0032
Epoch 728/2000
1024/1024 - 0s - loss: 0.0105 - val_loss: 0.0033
Epoch 729/2000
1024/1024 - 0s - loss: 0.0104 - val_loss: 0.0031
Epoch 730/2000
1024/1024 - 0s - loss: 0.0102 - val_loss: 0.0031
Epoch 731/2000
1024/1024 - 0s - loss: 0.0102 - val_loss: 0.0031
Epoch 732/2000
1024/1024 - 0s - loss: 0.0102 - val_loss: 0.0032
Epoch 733/2000
1024/1024 - 0s - loss: 0.0102 - val_loss: 0.0032
Epoch 734/2000
1024/1024 - 0s - loss: 0.0102 - val_loss: 0.0031
Epoch 735/2000
1024/1024 - 0s - loss: 0.0102 - val_loss: 0.0031
Epoch 736/2000
1024/1024 - 0s - loss: 0.0101 - val_loss: 0.0031
Epoch 737/2000
1024/1024 - 0s - loss: 0.0101 - val_loss: 0.0031
Epoch 738/2000
1024/1024 - 0s - loss: 0.0101 - val_loss: 0.0031
Epoch 739/2000
1024/1024 - 0s - loss: 0.0102 - val_loss: 0.0031
Epoch 740/2000
1024/1024 - 0s - loss: 0.0102 - val_loss: 0.0031
Epoch 741/2000
1024/1024 - 0s - loss: 0.0101 - val_loss: 0.0031
Epoch 742/2000
1024/1024 - 0s - loss: 0.0100 - val_loss: 0.0031
Epoch 743/2000
1024/1024 - 0s - loss: 0.0100 - val_loss: 0.0031
Epoch 744/2000
1024/1024 - 0s - loss: 0.0100 - val_loss: 0.0031
Epoch 745/2000
1024/1024 - 0s - loss: 0.0100 - val_loss: 0.0031
Epoch 746/2000
1024/1024 - 0s - loss: 0.0100 - val_loss: 0.0031
Epoch 747/2000
1024/1024 - 0s - loss: 0.0102 - val_loss: 0.0031
Epoch 748/2000
1024/1024 - 0s - loss: 0.0100 - val_loss: 0.0030
Epoch 749/2000
1024/1024 - 0s - loss: 0.0099 - val_loss: 0.0031
Epoch 750/2000
1024/1024 - 0s - loss: 0.0099 - val_loss: 0.0031
Epoch 751/2000
1024/1024 - 0s - loss: 0.0099 - val_loss: 0.0031
Epoch 752/2000
1024/1024 - 0s - loss: 0.0099 - val_loss: 0.0031
Epoch 753/2000
1024/1024 - 0s - loss: 0.0099 - val_loss: 0.0030
Epoch 754/2000
1024/1024 - 0s - loss: 0.0099 - val_loss: 0.0031
Epoch 755/2000
1024/1024 - 0s - loss: 0.0098 - val_loss: 0.0031
Epoch 756/2000
1024/1024 - 0s - loss: 0.0098 - val_loss: 0.0030
Epoch 757/2000
1024/1024 - 0s - loss: 0.0098 - val_loss: 0.0031
Epoch 758/2000
1024/1024 - 0s - loss: 0.0099 - val_loss: 0.0031
Epoch 759/2000
1024/1024 - 0s - loss: 0.0099 - val_loss: 0.0031
Epoch 760/2000
1024/1024 - 0s - loss: 0.0098 - val_loss: 0.0031
Epoch 761/2000
1024/1024 - 0s - loss: 0.0097 - val_loss: 0.0031
Epoch 762/2000
1024/1024 - 0s - loss: 0.0096 - val_loss: 0.0031
Epoch 763/2000
1024/1024 - 0s - loss: 0.0097 - val_loss: 0.0030
Epoch 764/2000
1024/1024 - 0s - loss: 0.0096 - val_loss: 0.0030
Epoch 765/2000
1024/1024 - 0s - loss: 0.0096 - val_loss: 0.0030
Epoch 766/2000
1024/1024 - 0s - loss: 0.0096 - val_loss: 0.0030
Epoch 767/2000
1024/1024 - 0s - loss: 0.0095 - val_loss: 0.0030
Epoch 768/2000
1024/1024 - 0s - loss: 0.0095 - val_loss: 0.0030
Epoch 769/2000
1024/1024 - 0s - loss: 0.0094 - val_loss: 0.0030
Epoch 770/2000
1024/1024 - 0s - loss: 0.0094 - val_loss: 0.0030
Epoch 771/2000
1024/1024 - 0s - loss: 0.0094 - val_loss: 0.0029
Epoch 772/2000
1024/1024 - 0s - loss: 0.0095 - val_loss: 0.0030
Epoch 773/2000
1024/1024 - 0s - loss: 0.0095 - val_loss: 0.0030
Epoch 774/2000
1024/1024 - 0s - loss: 0.0094 - val_loss: 0.0030
Epoch 775/2000
1024/1024 - 0s - loss: 0.0094 - val_loss: 0.0030
Epoch 776/2000
1024/1024 - 0s - loss: 0.0094 - val_loss: 0.0030
Epoch 777/2000
1024/1024 - 0s - loss: 0.0096 - val_loss: 0.0029
Epoch 778/2000
1024/1024 - 0s - loss: 0.0096 - val_loss: 0.0029
Epoch 779/2000
1024/1024 - 0s - loss: 0.0094 - val_loss: 0.0028
Epoch 780/2000
1024/1024 - 0s - loss: 0.0093 - val_loss: 0.0029
Epoch 781/2000
1024/1024 - 0s - loss: 0.0093 - val_loss: 0.0030
Epoch 782/2000
1024/1024 - 0s - loss: 0.0092 - val_loss: 0.0029
Epoch 783/2000
1024/1024 - 0s - loss: 0.0093 - val_loss: 0.0029
Epoch 784/2000
1024/1024 - 0s - loss: 0.0092 - val_loss: 0.0029
Epoch 785/2000
1024/1024 - 0s - loss: 0.0092 - val_loss: 0.0029
Epoch 786/2000
1024/1024 - 0s - loss: 0.0091 - val_loss: 0.0029
Epoch 787/2000
1024/1024 - 0s - loss: 0.0091 - val_loss: 0.0029
Epoch 788/2000
1024/1024 - 0s - loss: 0.0091 - val_loss: 0.0029
Epoch 789/2000
1024/1024 - 0s - loss: 0.0090 - val_loss: 0.0028
Epoch 790/2000
1024/1024 - 0s - loss: 0.0090 - val_loss: 0.0029
Epoch 791/2000
1024/1024 - 0s - loss: 0.0089 - val_loss: 0.0028
Epoch 792/2000
1024/1024 - 0s - loss: 0.0089 - val_loss: 0.0028
Epoch 793/2000
1024/1024 - 0s - loss: 0.0088 - val_loss: 0.0027
Epoch 794/2000
1024/1024 - 0s - loss: 0.0088 - val_loss: 0.0028
Epoch 795/2000
1024/1024 - 0s - loss: 0.0088 - val_loss: 0.0028
Epoch 796/2000
1024/1024 - 0s - loss: 0.0088 - val_loss: 0.0028
Epoch 797/2000
1024/1024 - 0s - loss: 0.0087 - val_loss: 0.0028
Epoch 798/2000
1024/1024 - 0s - loss: 0.0088 - val_loss: 0.0027
Epoch 799/2000
1024/1024 - 0s - loss: 0.0088 - val_loss: 0.0027
Epoch 800/2000
1024/1024 - 0s - loss: 0.0087 - val_loss: 0.0026
Epoch 801/2000
1024/1024 - 0s - loss: 0.0087 - val_loss: 0.0027
Epoch 802/2000
1024/1024 - 0s - loss: 0.0087 - val_loss: 0.0027
Epoch 803/2000
1024/1024 - 0s - loss: 0.0087 - val_loss: 0.0027
Epoch 804/2000
1024/1024 - 0s - loss: 0.0086 - val_loss: 0.0027
Epoch 805/2000
1024/1024 - 0s - loss: 0.0087 - val_loss: 0.0027
Epoch 806/2000
1024/1024 - 0s - loss: 0.0086 - val_loss: 0.0026
Epoch 807/2000
1024/1024 - 0s - loss: 0.0086 - val_loss: 0.0026
Epoch 808/2000
1024/1024 - 0s - loss: 0.0086 - val_loss: 0.0026
Epoch 809/2000
1024/1024 - 0s - loss: 0.0085 - val_loss: 0.0026
Epoch 810/2000
1024/1024 - 0s - loss: 0.0087 - val_loss: 0.0027
Epoch 811/2000
1024/1024 - 0s - loss: 0.0086 - val_loss: 0.0026
Epoch 812/2000
1024/1024 - 0s - loss: 0.0085 - val_loss: 0.0026
Epoch 813/2000
1024/1024 - 0s - loss: 0.0085 - val_loss: 0.0025
Epoch 814/2000
1024/1024 - 0s - loss: 0.0084 - val_loss: 0.0025
Epoch 815/2000
1024/1024 - 0s - loss: 0.0085 - val_loss: 0.0024
Epoch 816/2000
1024/1024 - 0s - loss: 0.0087 - val_loss: 0.0026
Epoch 817/2000
1024/1024 - 0s - loss: 0.0085 - val_loss: 0.0026
Epoch 818/2000
1024/1024 - 0s - loss: 0.0084 - val_loss: 0.0025
Epoch 819/2000
1024/1024 - 0s - loss: 0.0083 - val_loss: 0.0025
Epoch 820/2000
1024/1024 - 0s - loss: 0.0083 - val_loss: 0.0025
Epoch 821/2000
1024/1024 - 0s - loss: 0.0083 - val_loss: 0.0024
Epoch 822/2000
1024/1024 - 0s - loss: 0.0085 - val_loss: 0.0024
Epoch 823/2000
1024/1024 - 0s - loss: 0.0083 - val_loss: 0.0025
Epoch 824/2000
1024/1024 - 0s - loss: 0.0082 - val_loss: 0.0025
Epoch 825/2000
1024/1024 - 0s - loss: 0.0082 - val_loss: 0.0024
Epoch 826/2000
1024/1024 - 0s - loss: 0.0081 - val_loss: 0.0025
Epoch 827/2000
1024/1024 - 0s - loss: 0.0080 - val_loss: 0.0024
Epoch 828/2000
1024/1024 - 0s - loss: 0.0080 - val_loss: 0.0024
Epoch 829/2000
1024/1024 - 0s - loss: 0.0082 - val_loss: 0.0024
Epoch 830/2000
1024/1024 - 0s - loss: 0.0080 - val_loss: 0.0025
Epoch 831/2000
1024/1024 - 0s - loss: 0.0079 - val_loss: 0.0025
Epoch 832/2000
1024/1024 - 0s - loss: 0.0080 - val_loss: 0.0025
Epoch 833/2000
1024/1024 - 0s - loss: 0.0081 - val_loss: 0.0025
Epoch 834/2000
1024/1024 - 0s - loss: 0.0081 - val_loss: 0.0026
Epoch 835/2000
1024/1024 - 0s - loss: 0.0081 - val_loss: 0.0025
Epoch 836/2000
1024/1024 - 0s - loss: 0.0080 - val_loss: 0.0025
Epoch 837/2000
1024/1024 - 0s - loss: 0.0081 - val_loss: 0.0025
Epoch 838/2000
1024/1024 - 0s - loss: 0.0079 - val_loss: 0.0025
Epoch 839/2000
1024/1024 - 0s - loss: 0.0079 - val_loss: 0.0025
Epoch 840/2000
1024/1024 - 0s - loss: 0.0079 - val_loss: 0.0024
Epoch 841/2000
1024/1024 - 0s - loss: 0.0081 - val_loss: 0.0024
Epoch 842/2000
1024/1024 - 0s - loss: 0.0080 - val_loss: 0.0025
Epoch 843/2000
1024/1024 - 0s - loss: 0.0079 - val_loss: 0.0024
Epoch 844/2000
1024/1024 - 0s - loss: 0.0079 - val_loss: 0.0024
Epoch 845/2000
1024/1024 - 0s - loss: 0.0078 - val_loss: 0.0025
Epoch 846/2000
1024/1024 - 0s - loss: 0.0078 - val_loss: 0.0023
Epoch 847/2000
1024/1024 - 0s - loss: 0.0079 - val_loss: 0.0025
Epoch 848/2000
1024/1024 - 0s - loss: 0.0077 - val_loss: 0.0024
Epoch 849/2000
1024/1024 - 0s - loss: 0.0076 - val_loss: 0.0023
Epoch 850/2000
1024/1024 - 0s - loss: 0.0075 - val_loss: 0.0024
Epoch 851/2000
1024/1024 - 0s - loss: 0.0074 - val_loss: 0.0023
Epoch 852/2000
1024/1024 - 0s - loss: 0.0074 - val_loss: 0.0024
Epoch 853/2000
1024/1024 - 0s - loss: 0.0076 - val_loss: 0.0027
Epoch 854/2000
1024/1024 - 0s - loss: 0.0083 - val_loss: 0.0022
Epoch 855/2000
1024/1024 - 0s - loss: 0.0076 - val_loss: 0.0023
Epoch 856/2000
1024/1024 - 0s - loss: 0.0075 - val_loss: 0.0024
Epoch 857/2000
1024/1024 - 0s - loss: 0.0076 - val_loss: 0.0023
Epoch 858/2000
1024/1024 - 0s - loss: 0.0075 - val_loss: 0.0023
Epoch 859/2000
1024/1024 - 0s - loss: 0.0074 - val_loss: 0.0023
Epoch 860/2000
1024/1024 - 0s - loss: 0.0074 - val_loss: 0.0022
Epoch 861/2000
1024/1024 - 0s - loss: 0.0079 - val_loss: 0.0022
Epoch 862/2000
1024/1024 - 0s - loss: 0.0075 - val_loss: 0.0024
Epoch 863/2000
1024/1024 - 0s - loss: 0.0075 - val_loss: 0.0023
Epoch 864/2000
1024/1024 - 0s - loss: 0.0074 - val_loss: 0.0022
Epoch 865/2000
1024/1024 - 0s - loss: 0.0075 - val_loss: 0.0023
Epoch 866/2000
1024/1024 - 0s - loss: 0.0074 - val_loss: 0.0023
Epoch 867/2000
1024/1024 - 0s - loss: 0.0075 - val_loss: 0.0023
Epoch 868/2000
1024/1024 - 0s - loss: 0.0075 - val_loss: 0.0022
Epoch 869/2000
1024/1024 - 0s - loss: 0.0073 - val_loss: 0.0023
Epoch 870/2000
1024/1024 - 0s - loss: 0.0075 - val_loss: 0.0021
Epoch 871/2000
1024/1024 - 0s - loss: 0.0073 - val_loss: 0.0021
Epoch 872/2000
1024/1024 - 0s - loss: 0.0074 - val_loss: 0.0022
Epoch 873/2000
1024/1024 - 0s - loss: 0.0073 - val_loss: 0.0021
Epoch 874/2000
1024/1024 - 0s - loss: 0.0074 - val_loss: 0.0022
Epoch 875/2000
1024/1024 - 0s - loss: 0.0071 - val_loss: 0.0021
Epoch 876/2000
1024/1024 - 0s - loss: 0.0071 - val_loss: 0.0021
Epoch 877/2000
1024/1024 - 0s - loss: 0.0071 - val_loss: 0.0022
Epoch 878/2000
1024/1024 - 0s - loss: 0.0075 - val_loss: 0.0019
Epoch 879/2000
1024/1024 - 0s - loss: 0.0073 - val_loss: 0.0021
Epoch 880/2000
1024/1024 - 0s - loss: 0.0071 - val_loss: 0.0021
Epoch 881/2000
1024/1024 - 0s - loss: 0.0071 - val_loss: 0.0020
Epoch 882/2000
1024/1024 - 0s - loss: 0.0070 - val_loss: 0.0020
Epoch 883/2000
1024/1024 - 0s - loss: 0.0069 - val_loss: 0.0021
Epoch 884/2000
1024/1024 - 0s - loss: 0.0070 - val_loss: 0.0020
Epoch 885/2000
1024/1024 - 0s - loss: 0.0069 - val_loss: 0.0021
Epoch 886/2000
1024/1024 - 0s - loss: 0.0069 - val_loss: 0.0020
Epoch 887/2000
1024/1024 - 0s - loss: 0.0068 - val_loss: 0.0020
Epoch 888/2000
1024/1024 - 0s - loss: 0.0068 - val_loss: 0.0020
Epoch 889/2000
1024/1024 - 0s - loss: 0.0069 - val_loss: 0.0019
Epoch 890/2000
1024/1024 - 0s - loss: 0.0068 - val_loss: 0.0020
Epoch 891/2000
1024/1024 - 0s - loss: 0.0067 - val_loss: 0.0020
Epoch 892/2000
1024/1024 - 0s - loss: 0.0067 - val_loss: 0.0019
Epoch 893/2000
1024/1024 - 0s - loss: 0.0073 - val_loss: 0.0020
Epoch 894/2000
1024/1024 - 0s - loss: 0.0070 - val_loss: 0.0018
Epoch 895/2000
1024/1024 - 0s - loss: 0.0068 - val_loss: 0.0020
Epoch 896/2000
1024/1024 - 0s - loss: 0.0067 - val_loss: 0.0019
Epoch 897/2000
1024/1024 - 0s - loss: 0.0067 - val_loss: 0.0020
Epoch 898/2000
1024/1024 - 0s - loss: 0.0068 - val_loss: 0.0018
Epoch 899/2000
1024/1024 - 0s - loss: 0.0066 - val_loss: 0.0019
Epoch 900/2000
1024/1024 - 0s - loss: 0.0065 - val_loss: 0.0018
Epoch 901/2000
1024/1024 - 0s - loss: 0.0065 - val_loss: 0.0019
Epoch 902/2000
1024/1024 - 0s - loss: 0.0065 - val_loss: 0.0019
Epoch 903/2000
1024/1024 - 0s - loss: 0.0065 - val_loss: 0.0018
Epoch 904/2000
1024/1024 - 0s - loss: 0.0065 - val_loss: 0.0018
Epoch 905/2000
1024/1024 - 0s - loss: 0.0064 - val_loss: 0.0018
Epoch 906/2000
1024/1024 - 0s - loss: 0.0064 - val_loss: 0.0019
Epoch 907/2000
1024/1024 - 0s - loss: 0.0065 - val_loss: 0.0019
Epoch 908/2000
1024/1024 - 0s - loss: 0.0065 - val_loss: 0.0018
Epoch 909/2000
1024/1024 - 0s - loss: 0.0065 - val_loss: 0.0018
Epoch 910/2000
1024/1024 - 0s - loss: 0.0067 - val_loss: 0.0019
Epoch 911/2000
1024/1024 - 0s - loss: 0.0066 - val_loss: 0.0019
Epoch 912/2000
1024/1024 - 0s - loss: 0.0068 - val_loss: 0.0017
Epoch 913/2000
1024/1024 - 0s - loss: 0.0066 - val_loss: 0.0018
Epoch 914/2000
1024/1024 - 0s - loss: 0.0066 - val_loss: 0.0017
Epoch 915/2000
1024/1024 - 0s - loss: 0.0064 - val_loss: 0.0018
Epoch 916/2000
1024/1024 - 0s - loss: 0.0064 - val_loss: 0.0016
Epoch 917/2000
1024/1024 - 0s - loss: 0.0064 - val_loss: 0.0018
Epoch 918/2000
1024/1024 - 0s - loss: 0.0064 - val_loss: 0.0017
Epoch 919/2000
1024/1024 - 0s - loss: 0.0065 - val_loss: 0.0017
Epoch 920/2000
1024/1024 - 0s - loss: 0.0064 - val_loss: 0.0018
Epoch 921/2000
1024/1024 - 0s - loss: 0.0064 - val_loss: 0.0017
Epoch 922/2000
1024/1024 - 0s - loss: 0.0063 - val_loss: 0.0017
Epoch 923/2000
1024/1024 - 0s - loss: 0.0066 - val_loss: 0.0017
Epoch 924/2000
1024/1024 - 0s - loss: 0.0066 - val_loss: 0.0018
Epoch 925/2000
1024/1024 - 0s - loss: 0.0066 - val_loss: 0.0017
Epoch 926/2000
1024/1024 - 0s - loss: 0.0066 - val_loss: 0.0017
Epoch 927/2000
1024/1024 - 0s - loss: 0.0066 - val_loss: 0.0018
Epoch 928/2000
1024/1024 - 0s - loss: 0.0065 - val_loss: 0.0015
Epoch 929/2000
1024/1024 - 0s - loss: 0.0064 - val_loss: 0.0015
Epoch 930/2000
1024/1024 - 0s - loss: 0.0061 - val_loss: 0.0014
Epoch 931/2000
1024/1024 - 0s - loss: 0.0059 - val_loss: 0.0014
Epoch 932/2000
1024/1024 - 0s - loss: 0.0058 - val_loss: 0.0014
Epoch 933/2000
1024/1024 - 0s - loss: 0.0057 - val_loss: 0.0014
Epoch 934/2000
1024/1024 - 0s - loss: 0.0056 - val_loss: 0.0014
Epoch 935/2000
1024/1024 - 0s - loss: 0.0056 - val_loss: 0.0014
Epoch 936/2000
1024/1024 - 0s - loss: 0.0055 - val_loss: 0.0013
Epoch 937/2000
1024/1024 - 0s - loss: 0.0055 - val_loss: 0.0014
Epoch 938/2000
1024/1024 - 0s - loss: 0.0054 - val_loss: 0.0014
Epoch 939/2000
1024/1024 - 0s - loss: 0.0054 - val_loss: 0.0014
Epoch 940/2000
1024/1024 - 0s - loss: 0.0056 - val_loss: 0.0014
Epoch 941/2000
1024/1024 - 0s - loss: 0.0055 - val_loss: 0.0014
Epoch 942/2000
1024/1024 - 0s - loss: 0.0054 - val_loss: 0.0013
Epoch 943/2000
1024/1024 - 0s - loss: 0.0055 - val_loss: 0.0014
Epoch 944/2000
1024/1024 - 0s - loss: 0.0058 - val_loss: 0.0016
Epoch 945/2000
1024/1024 - 0s - loss: 0.0060 - val_loss: 0.0014
Epoch 946/2000
1024/1024 - 0s - loss: 0.0057 - val_loss: 0.0015
Epoch 947/2000
1024/1024 - 0s - loss: 0.0062 - val_loss: 0.0015
Epoch 948/2000
1024/1024 - 0s - loss: 0.0063 - val_loss: 0.0014
Epoch 949/2000
1024/1024 - 0s - loss: 0.0061 - val_loss: 0.0014
Epoch 950/2000
1024/1024 - 0s - loss: 0.0062 - val_loss: 0.0014
Epoch 951/2000
1024/1024 - 0s - loss: 0.0061 - val_loss: 0.0014
Epoch 952/2000
1024/1024 - 0s - loss: 0.0058 - val_loss: 0.0013
Epoch 953/2000
1024/1024 - 0s - loss: 0.0057 - val_loss: 0.0014
Epoch 954/2000
1024/1024 - 0s - loss: 0.0061 - val_loss: 0.0013
Epoch 955/2000
1024/1024 - 0s - loss: 0.0061 - val_loss: 0.0016
Epoch 956/2000
1024/1024 - 0s - loss: 0.0062 - val_loss: 0.0014
Epoch 957/2000
1024/1024 - 0s - loss: 0.0059 - val_loss: 0.0014
Epoch 958/2000
1024/1024 - 0s - loss: 0.0058 - val_loss: 0.0014
Epoch 959/2000
1024/1024 - 0s - loss: 0.0058 - val_loss: 0.0014
Epoch 960/2000
1024/1024 - 0s - loss: 0.0058 - val_loss: 0.0014
Epoch 961/2000
1024/1024 - 0s - loss: 0.0058 - val_loss: 0.0014
Epoch 962/2000
1024/1024 - 0s - loss: 0.0059 - val_loss: 0.0013
Epoch 963/2000
1024/1024 - 0s - loss: 0.0058 - val_loss: 0.0014
Epoch 964/2000
1024/1024 - 0s - loss: 0.0058 - val_loss: 0.0012
Epoch 965/2000
1024/1024 - 0s - loss: 0.0057 - val_loss: 0.0015
Epoch 966/2000
1024/1024 - 0s - loss: 0.0062 - val_loss: 0.0013
Epoch 967/2000
1024/1024 - 0s - loss: 0.0061 - val_loss: 0.0016
Epoch 968/2000
1024/1024 - 0s - loss: 0.0064 - val_loss: 0.0012
Epoch 969/2000
1024/1024 - 0s - loss: 0.0058 - val_loss: 0.0013
Epoch 970/2000
1024/1024 - 0s - loss: 0.0057 - val_loss: 0.0012
Epoch 971/2000
1024/1024 - 0s - loss: 0.0057 - val_loss: 0.0012
Epoch 972/2000
1024/1024 - 0s - loss: 0.0056 - val_loss: 0.0012
Epoch 973/2000
1024/1024 - 0s - loss: 0.0055 - val_loss: 0.0011
Epoch 974/2000
1024/1024 - 0s - loss: 0.0054 - val_loss: 0.0011
Epoch 975/2000
1024/1024 - 0s - loss: 0.0055 - val_loss: 8.9732e-04
Epoch 976/2000
1024/1024 - 0s - loss: 0.0066 - val_loss: 8.3943e-04
Epoch 977/2000
1024/1024 - 0s - loss: 0.0065 - val_loss: 9.0040e-04
Epoch 978/2000
1024/1024 - 0s - loss: 0.0067 - val_loss: 9.3255e-04
Epoch 979/2000
1024/1024 - 0s - loss: 0.0067 - val_loss: 0.0010
Epoch 980/2000
1024/1024 - 0s - loss: 0.0065 - val_loss: 0.0010
Epoch 981/2000
1024/1024 - 0s - loss: 0.0063 - val_loss: 9.7945e-04
Epoch 982/2000
1024/1024 - 0s - loss: 0.0061 - val_loss: 9.8152e-04
Epoch 983/2000
1024/1024 - 0s - loss: 0.0059 - val_loss: 9.4002e-04
Epoch 984/2000
1024/1024 - 0s - loss: 0.0055 - val_loss: 9.9475e-04
Epoch 985/2000
1024/1024 - 0s - loss: 0.0049 - val_loss: 0.0011
Epoch 986/2000
1024/1024 - 0s - loss: 0.0046 - val_loss: 0.0012
Epoch 987/2000
1024/1024 - 0s - loss: 0.0045 - val_loss: 0.0012
Epoch 988/2000
1024/1024 - 0s - loss: 0.0044 - val_loss: 0.0012
Epoch 989/2000
1024/1024 - 0s - loss: 0.0043 - val_loss: 0.0012
Epoch 990/2000
1024/1024 - 0s - loss: 0.0042 - val_loss: 0.0012
Epoch 991/2000
1024/1024 - 0s - loss: 0.0042 - val_loss: 0.0012
Epoch 992/2000
1024/1024 - 0s - loss: 0.0041 - val_loss: 0.0012
Epoch 993/2000
1024/1024 - 0s - loss: 0.0040 - val_loss: 0.0011
Epoch 994/2000
1024/1024 - 0s - loss: 0.0040 - val_loss: 0.0011
Epoch 995/2000
1024/1024 - 0s - loss: 0.0039 - val_loss: 0.0011
Epoch 996/2000
1024/1024 - 0s - loss: 0.0038 - val_loss: 0.0011
Epoch 997/2000
1024/1024 - 0s - loss: 0.0037 - val_loss: 0.0011
Epoch 998/2000
1024/1024 - 0s - loss: 0.0037 - val_loss: 0.0011
Epoch 999/2000
1024/1024 - 0s - loss: 0.0036 - val_loss: 0.0011
Epoch 1000/2000
1024/1024 - 0s - loss: 0.0035 - val_loss: 0.0011
Epoch 1001/2000
1024/1024 - 0s - loss: 0.0035 - val_loss: 0.0011
Epoch 1002/2000
1024/1024 - 0s - loss: 0.0034 - val_loss: 0.0011
Epoch 1003/2000
1024/1024 - 0s - loss: 0.0033 - val_loss: 0.0010
Epoch 1004/2000
1024/1024 - 0s - loss: 0.0033 - val_loss: 0.0010
Epoch 1005/2000
1024/1024 - 0s - loss: 0.0032 - val_loss: 0.0010
Epoch 1006/2000
1024/1024 - 0s - loss: 0.0031 - val_loss: 0.0010
Epoch 1007/2000
1024/1024 - 0s - loss: 0.0031 - val_loss: 9.9946e-04
Epoch 1008/2000
1024/1024 - 0s - loss: 0.0030 - val_loss: 9.8891e-04
Epoch 1009/2000
1024/1024 - 0s - loss: 0.0030 - val_loss: 9.7829e-04
Epoch 1010/2000
1024/1024 - 0s - loss: 0.0029 - val_loss: 9.6816e-04
Epoch 1011/2000
1024/1024 - 0s - loss: 0.0029 - val_loss: 9.5785e-04
Epoch 1012/2000
1024/1024 - 0s - loss: 0.0029 - val_loss: 9.4773e-04
Epoch 1013/2000
1024/1024 - 0s - loss: 0.0028 - val_loss: 9.3770e-04
Epoch 1014/2000
1024/1024 - 0s - loss: 0.0028 - val_loss: 9.2766e-04
Epoch 1015/2000
1024/1024 - 0s - loss: 0.0027 - val_loss: 9.1820e-04
Epoch 1016/2000
1024/1024 - 0s - loss: 0.0027 - val_loss: 9.0849e-04
Epoch 1017/2000
1024/1024 - 0s - loss: 0.0026 - val_loss: 8.9893e-04
Epoch 1018/2000
1024/1024 - 0s - loss: 0.0026 - val_loss: 8.8955e-04
Epoch 1019/2000
1024/1024 - 0s - loss: 0.0026 - val_loss: 8.8042e-04
Epoch 1020/2000
1024/1024 - 0s - loss: 0.0025 - val_loss: 8.7139e-04
Epoch 1021/2000
1024/1024 - 0s - loss: 0.0025 - val_loss: 8.6246e-04
Epoch 1022/2000
1024/1024 - 0s - loss: 0.0025 - val_loss: 8.5350e-04
Epoch 1023/2000
1024/1024 - 0s - loss: 0.0024 - val_loss: 8.4472e-04
Epoch 1024/2000
1024/1024 - 0s - loss: 0.0024 - val_loss: 8.3595e-04
Epoch 1025/2000
1024/1024 - 0s - loss: 0.0024 - val_loss: 8.2746e-04
Epoch 1026/2000
1024/1024 - 0s - loss: 0.0023 - val_loss: 8.1892e-04
Epoch 1027/2000
1024/1024 - 0s - loss: 0.0023 - val_loss: 8.1039e-04
Epoch 1028/2000
1024/1024 - 0s - loss: 0.0023 - val_loss: 8.0199e-04
Epoch 1029/2000
1024/1024 - 0s - loss: 0.0023 - val_loss: 7.9401e-04
Epoch 1030/2000
1024/1024 - 0s - loss: 0.0022 - val_loss: 7.8582e-04
Epoch 1031/2000
1024/1024 - 0s - loss: 0.0022 - val_loss: 7.7767e-04
Epoch 1032/2000
1024/1024 - 0s - loss: 0.0022 - val_loss: 7.6978e-04
Epoch 1033/2000
1024/1024 - 0s - loss: 0.0021 - val_loss: 7.6183e-04
Epoch 1034/2000
1024/1024 - 0s - loss: 0.0021 - val_loss: 7.5388e-04
Epoch 1035/2000
1024/1024 - 0s - loss: 0.0021 - val_loss: 7.4624e-04
Epoch 1036/2000
1024/1024 - 0s - loss: 0.0021 - val_loss: 7.3881e-04
Epoch 1037/2000
1024/1024 - 0s - loss: 0.0020 - val_loss: 7.3101e-04
Epoch 1038/2000
1024/1024 - 0s - loss: 0.0020 - val_loss: 7.2317e-04
Epoch 1039/2000
1024/1024 - 0s - loss: 0.0020 - val_loss: 7.1612e-04
Epoch 1040/2000
1024/1024 - 0s - loss: 0.0020 - val_loss: 7.0875e-04
Epoch 1041/2000
1024/1024 - 0s - loss: 0.0019 - val_loss: 7.0141e-04
Epoch 1042/2000
1024/1024 - 0s - loss: 0.0019 - val_loss: 6.9411e-04
Epoch 1043/2000
1024/1024 - 0s - loss: 0.0019 - val_loss: 6.8713e-04
Epoch 1044/2000
1024/1024 - 0s - loss: 0.0019 - val_loss: 6.8004e-04
Epoch 1045/2000
1024/1024 - 0s - loss: 0.0019 - val_loss: 6.7306e-04
Epoch 1046/2000
1024/1024 - 0s - loss: 0.0018 - val_loss: 6.6600e-04
Epoch 1047/2000
1024/1024 - 0s - loss: 0.0018 - val_loss: 6.5914e-04
Epoch 1048/2000
1024/1024 - 0s - loss: 0.0018 - val_loss: 6.5231e-04
Epoch 1049/2000
1024/1024 - 0s - loss: 0.0018 - val_loss: 6.4538e-04
Epoch 1050/2000
1024/1024 - 0s - loss: 0.0017 - val_loss: 6.3885e-04
Epoch 1051/2000
1024/1024 - 0s - loss: 0.0017 - val_loss: 6.3208e-04
Epoch 1052/2000
1024/1024 - 0s - loss: 0.0017 - val_loss: 6.2538e-04
Epoch 1053/2000
1024/1024 - 0s - loss: 0.0017 - val_loss: 6.1906e-04
Epoch 1054/2000
1024/1024 - 0s - loss: 0.0017 - val_loss: 6.1231e-04
Epoch 1055/2000
1024/1024 - 0s - loss: 0.0016 - val_loss: 6.0601e-04
Epoch 1056/2000
1024/1024 - 0s - loss: 0.0016 - val_loss: 5.9945e-04
Epoch 1057/2000
1024/1024 - 0s - loss: 0.0016 - val_loss: 5.9321e-04
Epoch 1058/2000
1024/1024 - 0s - loss: 0.0016 - val_loss: 5.8677e-04
Epoch 1059/2000
1024/1024 - 0s - loss: 0.0016 - val_loss: 5.8024e-04
Epoch 1060/2000
1024/1024 - 0s - loss: 0.0015 - val_loss: 5.7414e-04
Epoch 1061/2000
1024/1024 - 0s - loss: 0.0015 - val_loss: 5.6789e-04
Epoch 1062/2000
1024/1024 - 0s - loss: 0.0015 - val_loss: 5.6160e-04
Epoch 1063/2000
1024/1024 - 0s - loss: 0.0015 - val_loss: 5.5534e-04
Epoch 1064/2000
1024/1024 - 0s - loss: 0.0015 - val_loss: 5.4905e-04
Epoch 1065/2000
1024/1024 - 0s - loss: 0.0015 - val_loss: 5.4286e-04
Epoch 1066/2000
1024/1024 - 0s - loss: 0.0014 - val_loss: 5.3645e-04
Epoch 1067/2000
1024/1024 - 0s - loss: 0.0014 - val_loss: 5.2995e-04
Epoch 1068/2000
1024/1024 - 0s - loss: 0.0014 - val_loss: 5.2358e-04
Epoch 1069/2000
1024/1024 - 0s - loss: 0.0014 - val_loss: 5.1693e-04
Epoch 1070/2000
1024/1024 - 0s - loss: 0.0014 - val_loss: 5.1014e-04
Epoch 1071/2000
1024/1024 - 0s - loss: 0.0014 - val_loss: 5.0290e-04
Epoch 1072/2000
1024/1024 - 0s - loss: 0.0013 - val_loss: 4.9509e-04
Epoch 1073/2000
1024/1024 - 0s - loss: 0.0013 - val_loss: 4.8657e-04
Epoch 1074/2000
1024/1024 - 0s - loss: 0.0013 - val_loss: 4.7637e-04
Epoch 1075/2000
1024/1024 - 0s - loss: 0.0013 - val_loss: 4.6263e-04
Epoch 1076/2000
1024/1024 - 0s - loss: 0.0013 - val_loss: 4.3885e-04
Epoch 1077/2000
1024/1024 - 0s - loss: 0.0012 - val_loss: 3.5148e-04
Epoch 1078/2000
1024/1024 - 0s - loss: 8.7139e-04 - val_loss: 2.9154e-04
Epoch 1079/2000
1024/1024 - 0s - loss: 4.9927e-04 - val_loss: 3.3361e-04
Epoch 1080/2000
1024/1024 - 0s - loss: 4.2467e-04 - val_loss: 3.3531e-04
Epoch 1081/2000
1024/1024 - 0s - loss: 3.6532e-04 - val_loss: 3.2664e-04
Epoch 1082/2000
1024/1024 - 0s - loss: 3.0950e-04 - val_loss: 3.0844e-04
Epoch 1083/2000
1024/1024 - 0s - loss: 2.7729e-04 - val_loss: 3.0129e-04
Epoch 1084/2000
1024/1024 - 0s - loss: 2.5765e-04 - val_loss: 3.1133e-04
Epoch 1085/2000
1024/1024 - 0s - loss: 2.4273e-04 - val_loss: 3.1518e-04
Epoch 1086/2000
1024/1024 - 0s - loss: 2.3103e-04 - val_loss: 3.1569e-04
Epoch 1087/2000
1024/1024 - 0s - loss: 2.2134e-04 - val_loss: 3.1707e-04
Epoch 1088/2000
1024/1024 - 0s - loss: 2.1322e-04 - val_loss: 3.1900e-04
Epoch 1089/2000
1024/1024 - 0s - loss: 2.0627e-04 - val_loss: 3.1985e-04
Epoch 1090/2000
1024/1024 - 0s - loss: 2.0014e-04 - val_loss: 3.2089e-04
Epoch 1091/2000
1024/1024 - 0s - loss: 1.9473e-04 - val_loss: 3.2184e-04
Epoch 1092/2000
1024/1024 - 0s - loss: 1.8986e-04 - val_loss: 3.2212e-04
Epoch 1093/2000
1024/1024 - 0s - loss: 1.8547e-04 - val_loss: 3.2198e-04
Epoch 1094/2000
1024/1024 - 0s - loss: 1.8138e-04 - val_loss: 3.2265e-04
Epoch 1095/2000
1024/1024 - 0s - loss: 1.7765e-04 - val_loss: 3.2291e-04
Epoch 1096/2000
1024/1024 - 0s - loss: 1.7420e-04 - val_loss: 3.2245e-04
Epoch 1097/2000
1024/1024 - 0s - loss: 1.7095e-04 - val_loss: 3.2287e-04
Epoch 1098/2000
1024/1024 - 0s - loss: 1.6796e-04 - val_loss: 3.2271e-04
Epoch 1099/2000
1024/1024 - 0s - loss: 1.6513e-04 - val_loss: 3.2238e-04
Epoch 1100/2000
1024/1024 - 0s - loss: 1.6247e-04 - val_loss: 3.2258e-04
Epoch 1101/2000
1024/1024 - 0s - loss: 1.5996e-04 - val_loss: 3.2202e-04
Epoch 1102/2000
1024/1024 - 0s - loss: 1.5757e-04 - val_loss: 3.2177e-04
Epoch 1103/2000
1024/1024 - 0s - loss: 1.5531e-04 - val_loss: 3.2136e-04
Epoch 1104/2000
1024/1024 - 0s - loss: 1.5315e-04 - val_loss: 3.2097e-04
Epoch 1105/2000
1024/1024 - 0s - loss: 1.5108e-04 - val_loss: 3.2049e-04
Epoch 1106/2000
1024/1024 - 0s - loss: 1.4911e-04 - val_loss: 3.2032e-04
Epoch 1107/2000
1024/1024 - 0s - loss: 1.4723e-04 - val_loss: 3.1935e-04
Epoch 1108/2000
1024/1024 - 0s - loss: 1.4540e-04 - val_loss: 3.1879e-04
Epoch 1109/2000
1024/1024 - 0s - loss: 1.4365e-04 - val_loss: 3.1877e-04
Epoch 1110/2000
1024/1024 - 0s - loss: 1.4198e-04 - val_loss: 3.1794e-04
Epoch 1111/2000
1024/1024 - 0s - loss: 1.4036e-04 - val_loss: 3.1743e-04
Epoch 1112/2000
1024/1024 - 0s - loss: 1.3880e-04 - val_loss: 3.1684e-04
Epoch 1113/2000
1024/1024 - 0s - loss: 1.3729e-04 - val_loss: 3.1625e-04
Epoch 1114/2000
1024/1024 - 0s - loss: 1.3582e-04 - val_loss: 3.1554e-04
Epoch 1115/2000
1024/1024 - 0s - loss: 1.3440e-04 - val_loss: 3.1479e-04
Epoch 1116/2000
1024/1024 - 0s - loss: 1.3302e-04 - val_loss: 3.1416e-04
Epoch 1117/2000
1024/1024 - 0s - loss: 1.3168e-04 - val_loss: 3.1359e-04
Epoch 1118/2000
1024/1024 - 0s - loss: 1.3036e-04 - val_loss: 3.1269e-04
Epoch 1119/2000
1024/1024 - 0s - loss: 1.2908e-04 - val_loss: 3.1203e-04
Epoch 1120/2000
1024/1024 - 0s - loss: 1.2785e-04 - val_loss: 3.1165e-04
Epoch 1121/2000
1024/1024 - 0s - loss: 1.2664e-04 - val_loss: 3.1074e-04
Epoch 1122/2000
1024/1024 - 0s - loss: 1.2548e-04 - val_loss: 3.0993e-04
Epoch 1123/2000
1024/1024 - 0s - loss: 1.2433e-04 - val_loss: 3.0903e-04
Epoch 1124/2000
1024/1024 - 0s - loss: 1.2321e-04 - val_loss: 3.0888e-04
Epoch 1125/2000
1024/1024 - 0s - loss: 1.2212e-04 - val_loss: 3.0797e-04
Epoch 1126/2000
1024/1024 - 0s - loss: 1.2106e-04 - val_loss: 3.0738e-04
Epoch 1127/2000
1024/1024 - 0s - loss: 1.2003e-04 - val_loss: 3.0599e-04
Epoch 1128/2000
1024/1024 - 0s - loss: 1.1901e-04 - val_loss: 3.0561e-04
Epoch 1129/2000
1024/1024 - 0s - loss: 1.1802e-04 - val_loss: 3.0487e-04
Epoch 1130/2000
1024/1024 - 0s - loss: 1.1704e-04 - val_loss: 3.0410e-04
Epoch 1131/2000
1024/1024 - 0s - loss: 1.1608e-04 - val_loss: 3.0341e-04
Epoch 1132/2000
1024/1024 - 0s - loss: 1.1514e-04 - val_loss: 3.0251e-04
Epoch 1133/2000
1024/1024 - 0s - loss: 1.1422e-04 - val_loss: 3.0215e-04
Epoch 1134/2000
1024/1024 - 0s - loss: 1.1332e-04 - val_loss: 3.0131e-04
Epoch 1135/2000
1024/1024 - 0s - loss: 1.1243e-04 - val_loss: 3.0028e-04
Epoch 1136/2000
1024/1024 - 0s - loss: 1.1156e-04 - val_loss: 2.9928e-04
Epoch 1137/2000
1024/1024 - 0s - loss: 1.1070e-04 - val_loss: 2.9875e-04
Epoch 1138/2000
1024/1024 - 0s - loss: 1.0986e-04 - val_loss: 2.9789e-04
Epoch 1139/2000
1024/1024 - 0s - loss: 1.0902e-04 - val_loss: 2.9711e-04
Epoch 1140/2000
1024/1024 - 0s - loss: 1.0822e-04 - val_loss: 2.9679e-04
Epoch 1141/2000
1024/1024 - 0s - loss: 1.0742e-04 - val_loss: 2.9578e-04
Epoch 1142/2000
1024/1024 - 0s - loss: 1.0664e-04 - val_loss: 2.9493e-04
Epoch 1143/2000
1024/1024 - 0s - loss: 1.0585e-04 - val_loss: 2.9408e-04
Epoch 1144/2000
1024/1024 - 0s - loss: 1.0508e-04 - val_loss: 2.9346e-04
Epoch 1145/2000
1024/1024 - 0s - loss: 1.0433e-04 - val_loss: 2.9287e-04
Epoch 1146/2000
1024/1024 - 0s - loss: 1.0360e-04 - val_loss: 2.9192e-04
Epoch 1147/2000
1024/1024 - 0s - loss: 1.0287e-04 - val_loss: 2.9098e-04
Epoch 1148/2000
1024/1024 - 0s - loss: 1.0214e-04 - val_loss: 2.9063e-04
Epoch 1149/2000
1024/1024 - 0s - loss: 1.0142e-04 - val_loss: 2.8967e-04
Epoch 1150/2000
1024/1024 - 0s - loss: 1.0073e-04 - val_loss: 2.8867e-04
Epoch 1151/2000
1024/1024 - 0s - loss: 1.0004e-04 - val_loss: 2.8786e-04
Epoch 1152/2000
1024/1024 - 0s - loss: 9.9341e-05 - val_loss: 2.8700e-04
Epoch 1153/2000
1024/1024 - 0s - loss: 9.8642e-05 - val_loss: 2.8656e-04
Epoch 1154/2000
1024/1024 - 0s - loss: 9.7972e-05 - val_loss: 2.8546e-04
Epoch 1155/2000
1024/1024 - 0s - loss: 9.7310e-05 - val_loss: 2.8468e-04
Epoch 1156/2000
1024/1024 - 0s - loss: 9.6664e-05 - val_loss: 2.8397e-04
Epoch 1157/2000
1024/1024 - 0s - loss: 9.6029e-05 - val_loss: 2.8311e-04
Epoch 1158/2000
1024/1024 - 0s - loss: 9.5391e-05 - val_loss: 2.8219e-04
Epoch 1159/2000
1024/1024 - 0s - loss: 9.4780e-05 - val_loss: 2.8182e-04
Epoch 1160/2000
1024/1024 - 0s - loss: 9.4173e-05 - val_loss: 2.8092e-04
Epoch 1161/2000
1024/1024 - 0s - loss: 9.3565e-05 - val_loss: 2.8013e-04
Epoch 1162/2000
1024/1024 - 0s - loss: 9.2970e-05 - val_loss: 2.7909e-04
Epoch 1163/2000
1024/1024 - 0s - loss: 9.2375e-05 - val_loss: 2.7853e-04
Epoch 1164/2000
1024/1024 - 0s - loss: 9.1790e-05 - val_loss: 2.7776e-04
Epoch 1165/2000
1024/1024 - 0s - loss: 9.1219e-05 - val_loss: 2.7609e-04
Epoch 1166/2000
1024/1024 - 0s - loss: 9.0625e-05 - val_loss: 2.7594e-04
Epoch 1167/2000
1024/1024 - 0s - loss: 9.0047e-05 - val_loss: 2.7478e-04
Epoch 1168/2000
1024/1024 - 0s - loss: 8.9484e-05 - val_loss: 2.7444e-04
Epoch 1169/2000
1024/1024 - 0s - loss: 8.8931e-05 - val_loss: 2.7319e-04
Epoch 1170/2000
1024/1024 - 0s - loss: 8.8393e-05 - val_loss: 2.7242e-04
Epoch 1171/2000
1024/1024 - 0s - loss: 8.7857e-05 - val_loss: 2.7159e-04
Epoch 1172/2000
1024/1024 - 0s - loss: 8.7321e-05 - val_loss: 2.7139e-04
Epoch 1173/2000
1024/1024 - 0s - loss: 8.6802e-05 - val_loss: 2.7032e-04
Epoch 1174/2000
1024/1024 - 0s - loss: 8.6282e-05 - val_loss: 2.6953e-04
Epoch 1175/2000
1024/1024 - 0s - loss: 8.5791e-05 - val_loss: 2.6865e-04
Epoch 1176/2000
1024/1024 - 0s - loss: 8.5302e-05 - val_loss: 2.6743e-04
Epoch 1177/2000
1024/1024 - 0s - loss: 8.4812e-05 - val_loss: 2.6674e-04
Epoch 1178/2000
1024/1024 - 0s - loss: 8.4324e-05 - val_loss: 2.6644e-04
Epoch 1179/2000
1024/1024 - 0s - loss: 8.3843e-05 - val_loss: 2.6567e-04
Epoch 1180/2000
1024/1024 - 0s - loss: 8.3370e-05 - val_loss: 2.6491e-04
Epoch 1181/2000
1024/1024 - 0s - loss: 8.2890e-05 - val_loss: 2.6402e-04
Epoch 1182/2000
1024/1024 - 0s - loss: 8.2432e-05 - val_loss: 2.6340e-04
Epoch 1183/2000
1024/1024 - 0s - loss: 8.1984e-05 - val_loss: 2.6270e-04
Epoch 1184/2000
1024/1024 - 0s - loss: 8.1539e-05 - val_loss: 2.6185e-04
Epoch 1185/2000
1024/1024 - 0s - loss: 8.1095e-05 - val_loss: 2.6088e-04
Epoch 1186/2000
1024/1024 - 0s - loss: 8.0658e-05 - val_loss: 2.6056e-04
Epoch 1187/2000
1024/1024 - 0s - loss: 8.0226e-05 - val_loss: 2.5994e-04
Epoch 1188/2000
1024/1024 - 0s - loss: 7.9800e-05 - val_loss: 2.5898e-04
Epoch 1189/2000
1024/1024 - 0s - loss: 7.9378e-05 - val_loss: 2.5817e-04
Epoch 1190/2000
1024/1024 - 0s - loss: 7.8962e-05 - val_loss: 2.5766e-04
Epoch 1191/2000
1024/1024 - 0s - loss: 7.8542e-05 - val_loss: 2.5674e-04
Epoch 1192/2000
1024/1024 - 0s - loss: 7.8129e-05 - val_loss: 2.5579e-04
Epoch 1193/2000
1024/1024 - 0s - loss: 7.7731e-05 - val_loss: 2.5541e-04
Epoch 1194/2000
1024/1024 - 0s - loss: 7.7330e-05 - val_loss: 2.5464e-04
Epoch 1195/2000
1024/1024 - 0s - loss: 7.6932e-05 - val_loss: 2.5422e-04
Epoch 1196/2000
1024/1024 - 0s - loss: 7.6543e-05 - val_loss: 2.5345e-04
Epoch 1197/2000
1024/1024 - 0s - loss: 7.6158e-05 - val_loss: 2.5236e-04
Epoch 1198/2000
1024/1024 - 0s - loss: 7.5764e-05 - val_loss: 2.5173e-04
Epoch 1199/2000
1024/1024 - 0s - loss: 7.5380e-05 - val_loss: 2.5119e-04
Epoch 1200/2000
1024/1024 - 0s - loss: 7.5005e-05 - val_loss: 2.5036e-04
Epoch 1201/2000
1024/1024 - 0s - loss: 7.4638e-05 - val_loss: 2.4967e-04
Epoch 1202/2000
1024/1024 - 0s - loss: 7.4276e-05 - val_loss: 2.4884e-04
Epoch 1203/2000
1024/1024 - 0s - loss: 7.3915e-05 - val_loss: 2.4807e-04
Epoch 1204/2000
1024/1024 - 0s - loss: 7.3552e-05 - val_loss: 2.4765e-04
Epoch 1205/2000
1024/1024 - 0s - loss: 7.3195e-05 - val_loss: 2.4692e-04
Epoch 1206/2000
1024/1024 - 0s - loss: 7.2841e-05 - val_loss: 2.4621e-04
Epoch 1207/2000
1024/1024 - 0s - loss: 7.2498e-05 - val_loss: 2.4546e-04
Epoch 1208/2000
1024/1024 - 0s - loss: 7.2159e-05 - val_loss: 2.4469e-04
Epoch 1209/2000
1024/1024 - 0s - loss: 7.1820e-05 - val_loss: 2.4427e-04
Epoch 1210/2000
1024/1024 - 0s - loss: 7.1480e-05 - val_loss: 2.4351e-04
Epoch 1211/2000
1024/1024 - 0s - loss: 7.1140e-05 - val_loss: 2.4270e-04
Epoch 1212/2000
1024/1024 - 0s - loss: 7.0795e-05 - val_loss: 2.4205e-04
Epoch 1213/2000
1024/1024 - 0s - loss: 7.0470e-05 - val_loss: 2.4130e-04
Epoch 1214/2000
1024/1024 - 0s - loss: 7.0149e-05 - val_loss: 2.4079e-04
Epoch 1215/2000
1024/1024 - 0s - loss: 6.9829e-05 - val_loss: 2.4032e-04
Epoch 1216/2000
1024/1024 - 0s - loss: 6.9476e-05 - val_loss: 2.3904e-04
Epoch 1217/2000
1024/1024 - 0s - loss: 6.9145e-05 - val_loss: 2.3865e-04
Epoch 1218/2000
1024/1024 - 0s - loss: 6.8835e-05 - val_loss: 2.3792e-04
Epoch 1219/2000
1024/1024 - 0s - loss: 6.8526e-05 - val_loss: 2.3731e-04
Epoch 1220/2000
1024/1024 - 0s - loss: 6.8215e-05 - val_loss: 2.3630e-04
Epoch 1221/2000
1024/1024 - 0s - loss: 6.7900e-05 - val_loss: 2.3557e-04
Epoch 1222/2000
1024/1024 - 0s - loss: 6.7604e-05 - val_loss: 2.3510e-04
Epoch 1223/2000
1024/1024 - 0s - loss: 6.7311e-05 - val_loss: 2.3419e-04
Epoch 1224/2000
1024/1024 - 0s - loss: 6.7030e-05 - val_loss: 2.3393e-04
Epoch 1225/2000
1024/1024 - 0s - loss: 6.6762e-05 - val_loss: 2.3298e-04
Epoch 1226/2000
1024/1024 - 0s - loss: 6.6548e-05 - val_loss: 2.3332e-04
Epoch 1227/2000
1024/1024 - 0s - loss: 6.6282e-05 - val_loss: 2.3237e-04
Epoch 1228/2000
1024/1024 - 0s - loss: 6.6009e-05 - val_loss: 2.3150e-04
Epoch 1229/2000
1024/1024 - 0s - loss: 6.5729e-05 - val_loss: 2.3145e-04
Epoch 1230/2000
1024/1024 - 0s - loss: 6.5443e-05 - val_loss: 2.3071e-04
Epoch 1231/2000
1024/1024 - 0s - loss: 6.5167e-05 - val_loss: 2.2977e-04
Epoch 1232/2000
1024/1024 - 0s - loss: 6.4892e-05 - val_loss: 2.2980e-04
Epoch 1233/2000
1024/1024 - 0s - loss: 6.4622e-05 - val_loss: 2.2890e-04
Epoch 1234/2000
1024/1024 - 0s - loss: 6.4350e-05 - val_loss: 2.2837e-04
Epoch 1235/2000
1024/1024 - 0s - loss: 6.4078e-05 - val_loss: 2.2793e-04
Epoch 1236/2000
1024/1024 - 0s - loss: 6.3814e-05 - val_loss: 2.2739e-04
Epoch 1237/2000
1024/1024 - 0s - loss: 6.3547e-05 - val_loss: 2.2664e-04
Epoch 1238/2000
1024/1024 - 0s - loss: 6.3280e-05 - val_loss: 2.2598e-04
Epoch 1239/2000
1024/1024 - 0s - loss: 6.3004e-05 - val_loss: 2.2564e-04
Epoch 1240/2000
1024/1024 - 0s - loss: 6.2736e-05 - val_loss: 2.2489e-04
Epoch 1241/2000
1024/1024 - 0s - loss: 6.2484e-05 - val_loss: 2.2430e-04
Epoch 1242/2000
1024/1024 - 0s - loss: 6.2222e-05 - val_loss: 2.2384e-04
Epoch 1243/2000
1024/1024 - 0s - loss: 6.1969e-05 - val_loss: 2.2322e-04
Epoch 1244/2000
1024/1024 - 0s - loss: 6.1717e-05 - val_loss: 2.2240e-04
Epoch 1245/2000
1024/1024 - 0s - loss: 6.1469e-05 - val_loss: 2.2241e-04
Epoch 1246/2000
1024/1024 - 0s - loss: 6.1211e-05 - val_loss: 2.2179e-04
Epoch 1247/2000
1024/1024 - 0s - loss: 6.0961e-05 - val_loss: 2.2104e-04
Epoch 1248/2000
1024/1024 - 0s - loss: 6.0721e-05 - val_loss: 2.2060e-04
Epoch 1249/2000
1024/1024 - 0s - loss: 6.0473e-05 - val_loss: 2.2023e-04
Epoch 1250/2000
1024/1024 - 0s - loss: 6.0239e-05 - val_loss: 2.1990e-04
Epoch 1251/2000
1024/1024 - 0s - loss: 6.0004e-05 - val_loss: 2.1899e-04
Epoch 1252/2000
1024/1024 - 0s - loss: 5.9761e-05 - val_loss: 2.1883e-04
Epoch 1253/2000
1024/1024 - 0s - loss: 5.9521e-05 - val_loss: 2.1832e-04
Epoch 1254/2000
1024/1024 - 0s - loss: 5.9285e-05 - val_loss: 2.1745e-04
Epoch 1255/2000
1024/1024 - 0s - loss: 5.9057e-05 - val_loss: 2.1700e-04
Epoch 1256/2000
1024/1024 - 0s - loss: 5.8827e-05 - val_loss: 2.1604e-04
Epoch 1257/2000
1024/1024 - 0s - loss: 5.8602e-05 - val_loss: 2.1562e-04
Epoch 1258/2000
1024/1024 - 0s - loss: 5.8357e-05 - val_loss: 2.1516e-04
Epoch 1259/2000
1024/1024 - 0s - loss: 5.8114e-05 - val_loss: 2.1481e-04
Epoch 1260/2000
1024/1024 - 0s - loss: 5.7889e-05 - val_loss: 2.1393e-04
Epoch 1261/2000
1024/1024 - 0s - loss: 5.7669e-05 - val_loss: 2.1384e-04
Epoch 1262/2000
1024/1024 - 0s - loss: 5.7455e-05 - val_loss: 2.1304e-04
Epoch 1263/2000
1024/1024 - 0s - loss: 5.7258e-05 - val_loss: 2.1238e-04
Epoch 1264/2000
1024/1024 - 0s - loss: 5.7051e-05 - val_loss: 2.1185e-04
Epoch 1265/2000
1024/1024 - 0s - loss: 5.6833e-05 - val_loss: 2.1149e-04
Epoch 1266/2000
1024/1024 - 0s - loss: 5.6627e-05 - val_loss: 2.1074e-04
Epoch 1267/2000
1024/1024 - 0s - loss: 5.6421e-05 - val_loss: 2.1059e-04
Epoch 1268/2000
1024/1024 - 0s - loss: 5.6210e-05 - val_loss: 2.1003e-04
Epoch 1269/2000
1024/1024 - 0s - loss: 5.5998e-05 - val_loss: 2.0962e-04
Epoch 1270/2000
1024/1024 - 0s - loss: 5.5788e-05 - val_loss: 2.0860e-04
Epoch 1271/2000
1024/1024 - 0s - loss: 5.5580e-05 - val_loss: 2.0854e-04
Epoch 1272/2000
1024/1024 - 0s - loss: 5.5374e-05 - val_loss: 2.0794e-04
Epoch 1273/2000
1024/1024 - 0s - loss: 5.5159e-05 - val_loss: 2.0802e-04
Epoch 1274/2000
1024/1024 - 0s - loss: 5.4934e-05 - val_loss: 2.0706e-04
Epoch 1275/2000
1024/1024 - 0s - loss: 5.4728e-05 - val_loss: 2.0662e-04
Epoch 1276/2000
1024/1024 - 0s - loss: 5.4516e-05 - val_loss: 2.0627e-04
Epoch 1277/2000
1024/1024 - 0s - loss: 5.4310e-05 - val_loss: 2.0577e-04
Epoch 1278/2000
1024/1024 - 0s - loss: 5.4107e-05 - val_loss: 2.0512e-04
Epoch 1279/2000
1024/1024 - 0s - loss: 5.3913e-05 - val_loss: 2.0458e-04
Epoch 1280/2000
1024/1024 - 0s - loss: 5.3708e-05 - val_loss: 2.0444e-04
Epoch 1281/2000
1024/1024 - 0s - loss: 5.3484e-05 - val_loss: 2.0399e-04
Epoch 1282/2000
1024/1024 - 0s - loss: 5.3267e-05 - val_loss: 2.0357e-04
Epoch 1283/2000
1024/1024 - 0s - loss: 5.3071e-05 - val_loss: 2.0276e-04
Epoch 1284/2000
1024/1024 - 0s - loss: 5.2871e-05 - val_loss: 2.0276e-04
Epoch 1285/2000
1024/1024 - 0s - loss: 5.2678e-05 - val_loss: 2.0204e-04
Epoch 1286/2000
1024/1024 - 0s - loss: 5.2502e-05 - val_loss: 2.0149e-04
Epoch 1287/2000
1024/1024 - 0s - loss: 5.2274e-05 - val_loss: 2.0108e-04
Epoch 1288/2000
1024/1024 - 0s - loss: 5.2001e-05 - val_loss: 2.0115e-04
Epoch 1289/2000
1024/1024 - 0s - loss: 5.1779e-05 - val_loss: 2.0021e-04
Epoch 1290/2000
1024/1024 - 0s - loss: 5.1583e-05 - val_loss: 2.0029e-04
Epoch 1291/2000
1024/1024 - 0s - loss: 5.1390e-05 - val_loss: 1.9969e-04
Epoch 1292/2000
1024/1024 - 0s - loss: 5.1207e-05 - val_loss: 1.9954e-04
Epoch 1293/2000
1024/1024 - 0s - loss: 5.1035e-05 - val_loss: 1.9862e-04
Epoch 1294/2000
1024/1024 - 0s - loss: 5.0852e-05 - val_loss: 1.9915e-04
Epoch 1295/2000
1024/1024 - 0s - loss: 5.0673e-05 - val_loss: 1.9782e-04
Epoch 1296/2000
1024/1024 - 0s - loss: 5.0464e-05 - val_loss: 1.9751e-04
Epoch 1297/2000
1024/1024 - 0s - loss: 5.0307e-05 - val_loss: 1.9802e-04
Epoch 1298/2000
1024/1024 - 0s - loss: 5.0130e-05 - val_loss: 1.9693e-04
Epoch 1299/2000
1024/1024 - 0s - loss: 4.9934e-05 - val_loss: 1.9690e-04
Epoch 1300/2000
1024/1024 - 0s - loss: 4.9742e-05 - val_loss: 1.9655e-04
Epoch 1301/2000
1024/1024 - 0s - loss: 4.9585e-05 - val_loss: 1.9587e-04
Epoch 1302/2000
1024/1024 - 0s - loss: 4.9442e-05 - val_loss: 1.9523e-04
Epoch 1303/2000
1024/1024 - 0s - loss: 4.9282e-05 - val_loss: 1.9531e-04
Epoch 1304/2000
1024/1024 - 0s - loss: 4.9099e-05 - val_loss: 1.9501e-04
Epoch 1305/2000
1024/1024 - 0s - loss: 4.8900e-05 - val_loss: 1.9461e-04
Epoch 1306/2000
1024/1024 - 0s - loss: 4.8717e-05 - val_loss: 1.9398e-04
Epoch 1307/2000
1024/1024 - 0s - loss: 4.8530e-05 - val_loss: 1.9411e-04
Epoch 1308/2000
1024/1024 - 0s - loss: 4.8328e-05 - val_loss: 1.9419e-04
Epoch 1309/2000
1024/1024 - 0s - loss: 4.8098e-05 - val_loss: 1.9239e-04
Epoch 1310/2000
1024/1024 - 0s - loss: 4.7890e-05 - val_loss: 1.9265e-04
Epoch 1311/2000
1024/1024 - 0s - loss: 4.7707e-05 - val_loss: 1.9182e-04
Epoch 1312/2000
1024/1024 - 0s - loss: 4.7535e-05 - val_loss: 1.9149e-04
Epoch 1313/2000
1024/1024 - 0s - loss: 4.7360e-05 - val_loss: 1.9223e-04
Epoch 1314/2000
1024/1024 - 0s - loss: 4.7176e-05 - val_loss: 1.9176e-04
Epoch 1315/2000
1024/1024 - 0s - loss: 4.6986e-05 - val_loss: 1.9112e-04
Epoch 1316/2000
1024/1024 - 0s - loss: 4.6779e-05 - val_loss: 1.9153e-04
Epoch 1317/2000
1024/1024 - 0s - loss: 4.6573e-05 - val_loss: 1.8965e-04
Epoch 1318/2000
1024/1024 - 0s - loss: 4.6369e-05 - val_loss: 1.9016e-04
Epoch 1319/2000
1024/1024 - 0s - loss: 4.6161e-05 - val_loss: 1.8994e-04
Epoch 1320/2000
1024/1024 - 0s - loss: 4.5923e-05 - val_loss: 1.9067e-04
Epoch 1321/2000
1024/1024 - 0s - loss: 4.5675e-05 - val_loss: 1.9111e-04
Epoch 1322/2000
1024/1024 - 0s - loss: 4.5408e-05 - val_loss: 1.9367e-04
Epoch 1323/2000
1024/1024 - 0s - loss: 4.5141e-05 - val_loss: 1.9444e-04
Epoch 1324/2000
1024/1024 - 0s - loss: 4.4948e-05 - val_loss: 1.9087e-04
Epoch 1325/2000
1024/1024 - 0s - loss: 4.4761e-05 - val_loss: 1.9898e-04
Epoch 1326/2000
1024/1024 - 0s - loss: 4.4533e-05 - val_loss: 1.9543e-04
Epoch 1327/2000
1024/1024 - 0s - loss: 4.4312e-05 - val_loss: 1.9459e-04
Epoch 1328/2000
1024/1024 - 0s - loss: 4.4142e-05 - val_loss: 1.9426e-04
Epoch 1329/2000
1024/1024 - 0s - loss: 4.3965e-05 - val_loss: 1.9203e-04
Epoch 1330/2000
1024/1024 - 0s - loss: 4.3768e-05 - val_loss: 1.9381e-04
Epoch 1331/2000
1024/1024 - 0s - loss: 4.3566e-05 - val_loss: 1.9379e-04
Epoch 1332/2000
1024/1024 - 0s - loss: 4.3434e-05 - val_loss: 1.9600e-04
Epoch 1333/2000
1024/1024 - 0s - loss: 4.3283e-05 - val_loss: 1.9647e-04
Epoch 1334/2000
1024/1024 - 0s - loss: 4.3602e-05 - val_loss: 2.0539e-04
Epoch 1335/2000
1024/1024 - 0s - loss: 4.2855e-05 - val_loss: 1.9151e-04
Epoch 1336/2000
1024/1024 - 0s - loss: 4.2567e-05 - val_loss: 1.9314e-04
Epoch 1337/2000
1024/1024 - 0s - loss: 4.2343e-05 - val_loss: 1.9343e-04
Epoch 1338/2000
1024/1024 - 0s - loss: 4.2150e-05 - val_loss: 1.9389e-04
Epoch 1339/2000
1024/1024 - 0s - loss: 4.2097e-05 - val_loss: 1.8976e-04
Epoch 1340/2000
1024/1024 - 0s - loss: 4.2581e-05 - val_loss: 2.0622e-04
Epoch 1341/2000
1024/1024 - 0s - loss: 4.1607e-05 - val_loss: 1.8509e-04
Epoch 1342/2000
1024/1024 - 0s - loss: 4.1319e-05 - val_loss: 1.9245e-04
Epoch 1343/2000
1024/1024 - 0s - loss: 4.1112e-05 - val_loss: 1.9216e-04
Epoch 1344/2000
1024/1024 - 0s - loss: 4.0911e-05 - val_loss: 1.9021e-04
Epoch 1345/2000
1024/1024 - 0s - loss: 4.0710e-05 - val_loss: 1.8950e-04
Epoch 1346/2000
1024/1024 - 0s - loss: 4.0509e-05 - val_loss: 1.8861e-04
Epoch 1347/2000
1024/1024 - 0s - loss: 4.0313e-05 - val_loss: 1.8646e-04
Epoch 1348/2000
1024/1024 - 0s - loss: 4.0205e-05 - val_loss: 1.8435e-04
Epoch 1349/2000
1024/1024 - 0s - loss: 4.0014e-05 - val_loss: 1.8342e-04
Epoch 1350/2000
1024/1024 - 0s - loss: 3.9793e-05 - val_loss: 1.8307e-04
Epoch 1351/2000
1024/1024 - 0s - loss: 3.9554e-05 - val_loss: 1.8366e-04
Epoch 1352/2000
1024/1024 - 0s - loss: 3.9364e-05 - val_loss: 1.8580e-04
Epoch 1353/2000
1024/1024 - 0s - loss: 3.9176e-05 - val_loss: 1.8435e-04
Epoch 1354/2000
1024/1024 - 0s - loss: 3.8982e-05 - val_loss: 1.8290e-04
Epoch 1355/2000
1024/1024 - 0s - loss: 3.8812e-05 - val_loss: 1.8438e-04
Epoch 1356/2000
1024/1024 - 0s - loss: 3.8656e-05 - val_loss: 1.8461e-04
Epoch 1357/2000
1024/1024 - 0s - loss: 3.8474e-05 - val_loss: 1.8471e-04
Epoch 1358/2000
1024/1024 - 0s - loss: 3.8298e-05 - val_loss: 1.8110e-04
Epoch 1359/2000
1024/1024 - 0s - loss: 3.8115e-05 - val_loss: 1.8038e-04
Epoch 1360/2000
1024/1024 - 0s - loss: 3.8168e-05 - val_loss: 1.8793e-04
Epoch 1361/2000
1024/1024 - 0s - loss: 3.7882e-05 - val_loss: 1.8342e-04
Epoch 1362/2000
1024/1024 - 0s - loss: 3.7541e-05 - val_loss: 1.8119e-04
Epoch 1363/2000
1024/1024 - 0s - loss: 3.7350e-05 - val_loss: 1.8121e-04
Epoch 1364/2000
1024/1024 - 0s - loss: 3.7175e-05 - val_loss: 1.7913e-04
Epoch 1365/2000
1024/1024 - 0s - loss: 3.7168e-05 - val_loss: 1.8404e-04
Epoch 1366/2000
1024/1024 - 0s - loss: 3.6993e-05 - val_loss: 1.7394e-04
Epoch 1367/2000
1024/1024 - 0s - loss: 3.6963e-05 - val_loss: 1.7438e-04
Epoch 1368/2000
1024/1024 - 0s - loss: 3.6784e-05 - val_loss: 1.7168e-04
Epoch 1369/2000
1024/1024 - 0s - loss: 3.6372e-05 - val_loss: 1.7801e-04
Epoch 1370/2000
1024/1024 - 0s - loss: 3.6182e-05 - val_loss: 1.7497e-04
Epoch 1371/2000
1024/1024 - 0s - loss: 3.5995e-05 - val_loss: 1.7660e-04
Epoch 1372/2000
1024/1024 - 0s - loss: 3.5829e-05 - val_loss: 1.7606e-04
Epoch 1373/2000
1024/1024 - 0s - loss: 3.5689e-05 - val_loss: 1.7616e-04
Epoch 1374/2000
1024/1024 - 0s - loss: 3.5652e-05 - val_loss: 1.6911e-04
Epoch 1375/2000
1024/1024 - 0s - loss: 3.5357e-05 - val_loss: 1.7764e-04
Epoch 1376/2000
1024/1024 - 0s - loss: 3.5170e-05 - val_loss: 1.7522e-04
Epoch 1377/2000
1024/1024 - 0s - loss: 3.5014e-05 - val_loss: 1.7101e-04
Epoch 1378/2000
1024/1024 - 0s - loss: 3.4838e-05 - val_loss: 1.7288e-04
Epoch 1379/2000
1024/1024 - 0s - loss: 3.4764e-05 - val_loss: 1.6885e-04
Epoch 1380/2000
1024/1024 - 0s - loss: 3.4563e-05 - val_loss: 1.7237e-04
Epoch 1381/2000
1024/1024 - 0s - loss: 3.4359e-05 - val_loss: 1.7244e-04
Epoch 1382/2000
1024/1024 - 0s - loss: 3.4186e-05 - val_loss: 1.6995e-04
Epoch 1383/2000
1024/1024 - 0s - loss: 3.4046e-05 - val_loss: 1.6969e-04
Epoch 1384/2000
1024/1024 - 0s - loss: 3.3882e-05 - val_loss: 1.7216e-04
Epoch 1385/2000
1024/1024 - 0s - loss: 3.3737e-05 - val_loss: 1.6821e-04
Epoch 1386/2000
1024/1024 - 0s - loss: 3.3568e-05 - val_loss: 1.7224e-04
Epoch 1387/2000
1024/1024 - 0s - loss: 3.3382e-05 - val_loss: 1.6965e-04
Epoch 1388/2000
1024/1024 - 0s - loss: 3.3225e-05 - val_loss: 1.7033e-04
Epoch 1389/2000
1024/1024 - 0s - loss: 3.3075e-05 - val_loss: 1.6664e-04
Epoch 1390/2000
1024/1024 - 0s - loss: 3.3512e-05 - val_loss: 1.5802e-04
Epoch 1391/2000
1024/1024 - 0s - loss: 3.3121e-05 - val_loss: 1.6373e-04
Epoch 1392/2000
1024/1024 - 0s - loss: 3.2628e-05 - val_loss: 1.6476e-04
Epoch 1393/2000
1024/1024 - 0s - loss: 3.2405e-05 - val_loss: 1.6681e-04
Epoch 1394/2000
1024/1024 - 0s - loss: 3.2204e-05 - val_loss: 1.6551e-04
Epoch 1395/2000
1024/1024 - 0s - loss: 3.2025e-05 - val_loss: 1.6591e-04
Epoch 1396/2000
1024/1024 - 0s - loss: 3.1847e-05 - val_loss: 1.6558e-04
Epoch 1397/2000
1024/1024 - 0s - loss: 3.1750e-05 - val_loss: 1.6165e-04
Epoch 1398/2000
1024/1024 - 0s - loss: 3.1527e-05 - val_loss: 1.6624e-04
Epoch 1399/2000
1024/1024 - 0s - loss: 3.1346e-05 - val_loss: 1.6428e-04
Epoch 1400/2000
1024/1024 - 0s - loss: 3.1586e-05 - val_loss: 1.7021e-04
Epoch 1401/2000
1024/1024 - 0s - loss: 3.1417e-05 - val_loss: 1.6808e-04
Epoch 1402/2000
1024/1024 - 0s - loss: 3.0957e-05 - val_loss: 1.6322e-04
Epoch 1403/2000
1024/1024 - 0s - loss: 3.0837e-05 - val_loss: 1.6171e-04
Epoch 1404/2000
1024/1024 - 0s - loss: 3.0636e-05 - val_loss: 1.6404e-04
Epoch 1405/2000
1024/1024 - 0s - loss: 3.0461e-05 - val_loss: 1.6219e-04
Epoch 1406/2000
1024/1024 - 0s - loss: 3.0294e-05 - val_loss: 1.6336e-04
Epoch 1407/2000
1024/1024 - 0s - loss: 3.0138e-05 - val_loss: 1.6241e-04
Epoch 1408/2000
1024/1024 - 0s - loss: 3.1253e-05 - val_loss: 1.5051e-04
Epoch 1409/2000
1024/1024 - 0s - loss: 3.2195e-05 - val_loss: 1.4611e-04
Epoch 1410/2000
1024/1024 - 0s - loss: 3.0305e-05 - val_loss: 1.5293e-04
Epoch 1411/2000
1024/1024 - 0s - loss: 2.9757e-05 - val_loss: 1.5629e-04
Epoch 1412/2000
1024/1024 - 0s - loss: 2.9417e-05 - val_loss: 1.5639e-04
Epoch 1413/2000
1024/1024 - 0s - loss: 2.9152e-05 - val_loss: 1.5931e-04
Epoch 1414/2000
1024/1024 - 0s - loss: 2.9011e-05 - val_loss: 1.5531e-04
Epoch 1415/2000
1024/1024 - 0s - loss: 2.8849e-05 - val_loss: 1.5694e-04
Epoch 1416/2000
1024/1024 - 0s - loss: 2.8637e-05 - val_loss: 1.5925e-04
Epoch 1417/2000
1024/1024 - 0s - loss: 2.8453e-05 - val_loss: 1.5701e-04
Epoch 1418/2000
1024/1024 - 0s - loss: 2.8315e-05 - val_loss: 1.5593e-04
Epoch 1419/2000
1024/1024 - 0s - loss: 2.8176e-05 - val_loss: 1.5529e-04
Epoch 1420/2000
1024/1024 - 0s - loss: 2.7991e-05 - val_loss: 1.5563e-04
Epoch 1421/2000
1024/1024 - 0s - loss: 2.7824e-05 - val_loss: 1.5550e-04
Epoch 1422/2000
1024/1024 - 0s - loss: 2.7661e-05 - val_loss: 1.5526e-04
Epoch 1423/2000
1024/1024 - 0s - loss: 2.7498e-05 - val_loss: 1.5517e-04
Epoch 1424/2000
1024/1024 - 0s - loss: 2.7351e-05 - val_loss: 1.5434e-04
Epoch 1425/2000
1024/1024 - 0s - loss: 2.7192e-05 - val_loss: 1.5417e-04
Epoch 1426/2000
1024/1024 - 0s - loss: 2.7035e-05 - val_loss: 1.5330e-04
Epoch 1427/2000
1024/1024 - 0s - loss: 2.6892e-05 - val_loss: 1.5473e-04
Epoch 1428/2000
1024/1024 - 0s - loss: 2.6717e-05 - val_loss: 1.5416e-04
Epoch 1429/2000
1024/1024 - 0s - loss: 2.6642e-05 - val_loss: 1.4752e-04
Epoch 1430/2000
1024/1024 - 0s - loss: 2.6389e-05 - val_loss: 1.5178e-04
Epoch 1431/2000
1024/1024 - 0s - loss: 2.6204e-05 - val_loss: 1.5444e-04
Epoch 1432/2000
1024/1024 - 0s - loss: 2.6015e-05 - val_loss: 1.5028e-04
Epoch 1433/2000
1024/1024 - 0s - loss: 2.5848e-05 - val_loss: 1.5125e-04
Epoch 1434/2000
1024/1024 - 0s - loss: 2.5692e-05 - val_loss: 1.5054e-04
Epoch 1435/2000
1024/1024 - 0s - loss: 2.5534e-05 - val_loss: 1.5019e-04
Epoch 1436/2000
1024/1024 - 0s - loss: 2.5379e-05 - val_loss: 1.5070e-04
Epoch 1437/2000
1024/1024 - 0s - loss: 2.5217e-05 - val_loss: 1.4916e-04
Epoch 1438/2000
1024/1024 - 0s - loss: 2.5059e-05 - val_loss: 1.5115e-04
Epoch 1439/2000
1024/1024 - 0s - loss: 2.4899e-05 - val_loss: 1.4892e-04
Epoch 1440/2000
1024/1024 - 0s - loss: 2.4748e-05 - val_loss: 1.4911e-04
Epoch 1441/2000
1024/1024 - 0s - loss: 2.4660e-05 - val_loss: 1.5062e-04
Epoch 1442/2000
1024/1024 - 0s - loss: 2.4568e-05 - val_loss: 1.5004e-04
Epoch 1443/2000
1024/1024 - 0s - loss: 2.4317e-05 - val_loss: 1.4669e-04
Epoch 1444/2000
1024/1024 - 0s - loss: 2.4145e-05 - val_loss: 1.4845e-04
Epoch 1445/2000
1024/1024 - 0s - loss: 2.3991e-05 - val_loss: 1.4601e-04
Epoch 1446/2000
1024/1024 - 0s - loss: 2.3819e-05 - val_loss: 1.4728e-04
Epoch 1447/2000
1024/1024 - 0s - loss: 2.3657e-05 - val_loss: 1.4625e-04
Epoch 1448/2000
1024/1024 - 0s - loss: 2.3501e-05 - val_loss: 1.4557e-04
Epoch 1449/2000
1024/1024 - 0s - loss: 2.3337e-05 - val_loss: 1.4614e-04
Epoch 1450/2000
1024/1024 - 0s - loss: 2.3195e-05 - val_loss: 1.4656e-04
Epoch 1451/2000
1024/1024 - 0s - loss: 2.3015e-05 - val_loss: 1.4340e-04
Epoch 1452/2000
1024/1024 - 0s - loss: 2.2849e-05 - val_loss: 1.4543e-04
Epoch 1453/2000
1024/1024 - 0s - loss: 2.2680e-05 - val_loss: 1.4335e-04
Epoch 1454/2000
1024/1024 - 0s - loss: 2.2521e-05 - val_loss: 1.4450e-04
Epoch 1455/2000
1024/1024 - 0s - loss: 2.2364e-05 - val_loss: 1.4333e-04
Epoch 1456/2000
1024/1024 - 0s - loss: 2.2210e-05 - val_loss: 1.4254e-04
Epoch 1457/2000
1024/1024 - 0s - loss: 2.2054e-05 - val_loss: 1.4302e-04
Epoch 1458/2000
1024/1024 - 0s - loss: 2.1962e-05 - val_loss: 1.3986e-04
Epoch 1459/2000
1024/1024 - 0s - loss: 2.1779e-05 - val_loss: 1.4212e-04
Epoch 1460/2000
1024/1024 - 0s - loss: 2.1602e-05 - val_loss: 1.4084e-04
Epoch 1461/2000
1024/1024 - 0s - loss: 2.1451e-05 - val_loss: 1.4121e-04
Epoch 1462/2000
1024/1024 - 0s - loss: 2.1324e-05 - val_loss: 1.4155e-04
Epoch 1463/2000
1024/1024 - 0s - loss: 2.1149e-05 - val_loss: 1.3914e-04
Epoch 1464/2000
1024/1024 - 0s - loss: 2.1004e-05 - val_loss: 1.3998e-04
Epoch 1465/2000
1024/1024 - 0s - loss: 2.0882e-05 - val_loss: 1.3774e-04
Epoch 1466/2000
1024/1024 - 0s - loss: 2.0694e-05 - val_loss: 1.4052e-04
Epoch 1467/2000
1024/1024 - 0s - loss: 2.0606e-05 - val_loss: 1.3459e-04
Epoch 1468/2000
1024/1024 - 0s - loss: 2.0380e-05 - val_loss: 1.4092e-04
Epoch 1469/2000
1024/1024 - 0s - loss: 2.0233e-05 - val_loss: 1.3807e-04
Epoch 1470/2000
1024/1024 - 0s - loss: 2.0083e-05 - val_loss: 1.3746e-04
Epoch 1471/2000
1024/1024 - 0s - loss: 1.9961e-05 - val_loss: 1.3612e-04
Epoch 1472/2000
1024/1024 - 0s - loss: 1.9811e-05 - val_loss: 1.3805e-04
Epoch 1473/2000
1024/1024 - 0s - loss: 1.9671e-05 - val_loss: 1.3615e-04
Epoch 1474/2000
1024/1024 - 0s - loss: 1.9531e-05 - val_loss: 1.3566e-04
Epoch 1475/2000
1024/1024 - 0s - loss: 1.9392e-05 - val_loss: 1.3587e-04
Epoch 1476/2000
1024/1024 - 0s - loss: 1.9254e-05 - val_loss: 1.3500e-04
Epoch 1477/2000
1024/1024 - 0s - loss: 1.9117e-05 - val_loss: 1.3514e-04
Epoch 1478/2000
1024/1024 - 0s - loss: 1.8984e-05 - val_loss: 1.3482e-04
Epoch 1479/2000
1024/1024 - 0s - loss: 1.8846e-05 - val_loss: 1.3408e-04
Epoch 1480/2000
1024/1024 - 0s - loss: 1.8717e-05 - val_loss: 1.3394e-04
Epoch 1481/2000
1024/1024 - 0s - loss: 1.8589e-05 - val_loss: 1.3365e-04
Epoch 1482/2000
1024/1024 - 0s - loss: 1.8463e-05 - val_loss: 1.3277e-04
Epoch 1483/2000
1024/1024 - 0s - loss: 1.8337e-05 - val_loss: 1.3246e-04
Epoch 1484/2000
1024/1024 - 0s - loss: 1.8204e-05 - val_loss: 1.3308e-04
Epoch 1485/2000
1024/1024 - 0s - loss: 1.8087e-05 - val_loss: 1.3076e-04
Epoch 1486/2000
1024/1024 - 0s - loss: 1.7949e-05 - val_loss: 1.3232e-04
Epoch 1487/2000
1024/1024 - 0s - loss: 1.7828e-05 - val_loss: 1.3171e-04
Epoch 1488/2000
1024/1024 - 0s - loss: 1.7714e-05 - val_loss: 1.3029e-04
Epoch 1489/2000
1024/1024 - 0s - loss: 1.7608e-05 - val_loss: 1.3027e-04
Epoch 1490/2000
1024/1024 - 0s - loss: 1.7487e-05 - val_loss: 1.3015e-04
Epoch 1491/2000
1024/1024 - 0s - loss: 1.7370e-05 - val_loss: 1.3032e-04
Epoch 1492/2000
1024/1024 - 0s - loss: 1.7257e-05 - val_loss: 1.2935e-04
Epoch 1493/2000
1024/1024 - 0s - loss: 1.7146e-05 - val_loss: 1.2899e-04
Epoch 1494/2000
1024/1024 - 0s - loss: 1.7036e-05 - val_loss: 1.2827e-04
Epoch 1495/2000
1024/1024 - 0s - loss: 1.6926e-05 - val_loss: 1.2842e-04
Epoch 1496/2000
1024/1024 - 0s - loss: 1.6816e-05 - val_loss: 1.2861e-04
Epoch 1497/2000
1024/1024 - 0s - loss: 1.6712e-05 - val_loss: 1.2732e-04
Epoch 1498/2000
1024/1024 - 0s - loss: 1.6607e-05 - val_loss: 1.2714e-04
Epoch 1499/2000
1024/1024 - 0s - loss: 1.6503e-05 - val_loss: 1.2715e-04
Epoch 1500/2000
1024/1024 - 0s - loss: 1.6397e-05 - val_loss: 1.2619e-04
Epoch 1501/2000
1024/1024 - 0s - loss: 1.6298e-05 - val_loss: 1.2565e-04
Epoch 1502/2000
1024/1024 - 0s - loss: 1.6205e-05 - val_loss: 1.2561e-04
Epoch 1503/2000
1024/1024 - 0s - loss: 1.6136e-05 - val_loss: 1.2451e-04
Epoch 1504/2000
1024/1024 - 0s - loss: 1.6031e-05 - val_loss: 1.2463e-04
Epoch 1505/2000
1024/1024 - 0s - loss: 1.5936e-05 - val_loss: 1.2492e-04
Epoch 1506/2000
1024/1024 - 0s - loss: 1.5841e-05 - val_loss: 1.2391e-04
Epoch 1507/2000
1024/1024 - 0s - loss: 1.5745e-05 - val_loss: 1.2381e-04
Epoch 1508/2000
1024/1024 - 0s - loss: 1.5648e-05 - val_loss: 1.2331e-04
Epoch 1509/2000
1024/1024 - 0s - loss: 1.5556e-05 - val_loss: 1.2247e-04
Epoch 1510/2000
1024/1024 - 0s - loss: 1.5463e-05 - val_loss: 1.2252e-04
Epoch 1511/2000
1024/1024 - 0s - loss: 1.5372e-05 - val_loss: 1.2210e-04
Epoch 1512/2000
1024/1024 - 0s - loss: 1.5282e-05 - val_loss: 1.2166e-04
Epoch 1513/2000
1024/1024 - 0s - loss: 1.5192e-05 - val_loss: 1.2106e-04
Epoch 1514/2000
1024/1024 - 0s - loss: 1.5103e-05 - val_loss: 1.2088e-04
Epoch 1515/2000
1024/1024 - 0s - loss: 1.5015e-05 - val_loss: 1.2046e-04
Epoch 1516/2000
1024/1024 - 0s - loss: 1.4925e-05 - val_loss: 1.2019e-04
Epoch 1517/2000
1024/1024 - 0s - loss: 1.4838e-05 - val_loss: 1.1983e-04
Epoch 1518/2000
1024/1024 - 0s - loss: 1.4753e-05 - val_loss: 1.1941e-04
Epoch 1519/2000
1024/1024 - 0s - loss: 1.4663e-05 - val_loss: 1.1857e-04
Epoch 1520/2000
1024/1024 - 0s - loss: 1.4577e-05 - val_loss: 1.1863e-04
Epoch 1521/2000
1024/1024 - 0s - loss: 1.4492e-05 - val_loss: 1.1790e-04
Epoch 1522/2000
1024/1024 - 0s - loss: 1.4404e-05 - val_loss: 1.1784e-04
Epoch 1523/2000
1024/1024 - 0s - loss: 1.4347e-05 - val_loss: 1.1613e-04
Epoch 1524/2000
1024/1024 - 0s - loss: 1.4237e-05 - val_loss: 1.1645e-04
Epoch 1525/2000
1024/1024 - 0s - loss: 1.4100e-05 - val_loss: 1.1676e-04
Epoch 1526/2000
1024/1024 - 0s - loss: 1.4014e-05 - val_loss: 1.1655e-04
Epoch 1527/2000
1024/1024 - 0s - loss: 1.3927e-05 - val_loss: 1.1600e-04
Epoch 1528/2000
1024/1024 - 0s - loss: 1.3856e-05 - val_loss: 1.1449e-04
Epoch 1529/2000
1024/1024 - 0s - loss: 1.3784e-05 - val_loss: 1.1498e-04
Epoch 1530/2000
1024/1024 - 0s - loss: 1.3703e-05 - val_loss: 1.1407e-04
Epoch 1531/2000
1024/1024 - 0s - loss: 1.3627e-05 - val_loss: 1.1444e-04
Epoch 1532/2000
1024/1024 - 0s - loss: 1.3546e-05 - val_loss: 1.1368e-04
Epoch 1533/2000
1024/1024 - 0s - loss: 1.3467e-05 - val_loss: 1.1353e-04
Epoch 1534/2000
1024/1024 - 0s - loss: 1.3388e-05 - val_loss: 1.1267e-04
Epoch 1535/2000
1024/1024 - 0s - loss: 1.3309e-05 - val_loss: 1.1255e-04
Epoch 1536/2000
1024/1024 - 0s - loss: 1.3232e-05 - val_loss: 1.1180e-04
Epoch 1537/2000
1024/1024 - 0s - loss: 1.3155e-05 - val_loss: 1.1192e-04
Epoch 1538/2000
1024/1024 - 0s - loss: 1.3079e-05 - val_loss: 1.1129e-04
Epoch 1539/2000
1024/1024 - 0s - loss: 1.3001e-05 - val_loss: 1.1091e-04
Epoch 1540/2000
1024/1024 - 0s - loss: 1.2926e-05 - val_loss: 1.1077e-04
Epoch 1541/2000
1024/1024 - 0s - loss: 1.2889e-05 - val_loss: 1.1112e-04
Epoch 1542/2000
1024/1024 - 0s - loss: 1.2815e-05 - val_loss: 1.0946e-04
Epoch 1543/2000
1024/1024 - 0s - loss: 1.2742e-05 - val_loss: 1.0938e-04
Epoch 1544/2000
1024/1024 - 0s - loss: 1.2662e-05 - val_loss: 1.0852e-04
Epoch 1545/2000
1024/1024 - 0s - loss: 1.2584e-05 - val_loss: 1.0880e-04
Epoch 1546/2000
1024/1024 - 0s - loss: 1.2509e-05 - val_loss: 1.0866e-04
Epoch 1547/2000
1024/1024 - 0s - loss: 1.2436e-05 - val_loss: 1.0806e-04
Epoch 1548/2000
1024/1024 - 0s - loss: 1.2359e-05 - val_loss: 1.0729e-04
Epoch 1549/2000
1024/1024 - 0s - loss: 1.2289e-05 - val_loss: 1.0753e-04
Epoch 1550/2000
1024/1024 - 0s - loss: 1.2218e-05 - val_loss: 1.0639e-04
Epoch 1551/2000
1024/1024 - 0s - loss: 1.2143e-05 - val_loss: 1.0688e-04
Epoch 1552/2000
1024/1024 - 0s - loss: 1.2072e-05 - val_loss: 1.0608e-04
Epoch 1553/2000
1024/1024 - 0s - loss: 1.2000e-05 - val_loss: 1.0621e-04
Epoch 1554/2000
1024/1024 - 0s - loss: 1.1927e-05 - val_loss: 1.0517e-04
Epoch 1555/2000
1024/1024 - 0s - loss: 1.1853e-05 - val_loss: 1.0481e-04
Epoch 1556/2000
1024/1024 - 0s - loss: 1.1779e-05 - val_loss: 1.0559e-04
Epoch 1557/2000
1024/1024 - 0s - loss: 1.1715e-05 - val_loss: 1.0457e-04
Epoch 1558/2000
1024/1024 - 0s - loss: 1.1644e-05 - val_loss: 1.0359e-04
Epoch 1559/2000
1024/1024 - 0s - loss: 1.1575e-05 - val_loss: 1.0394e-04
Epoch 1560/2000
1024/1024 - 0s - loss: 1.1503e-05 - val_loss: 1.0353e-04
Epoch 1561/2000
1024/1024 - 0s - loss: 1.1451e-05 - val_loss: 1.0353e-04
Epoch 1562/2000
1024/1024 - 0s - loss: 1.1393e-05 - val_loss: 1.0270e-04
Epoch 1563/2000
1024/1024 - 0s - loss: 1.1318e-05 - val_loss: 1.0189e-04
Epoch 1564/2000
1024/1024 - 0s - loss: 1.1249e-05 - val_loss: 1.0171e-04
Epoch 1565/2000
1024/1024 - 0s - loss: 1.1179e-05 - val_loss: 1.0164e-04
Epoch 1566/2000
1024/1024 - 0s - loss: 1.1111e-05 - val_loss: 1.0083e-04
Epoch 1567/2000
1024/1024 - 0s - loss: 1.1041e-05 - val_loss: 1.0079e-04
Epoch 1568/2000
1024/1024 - 0s - loss: 1.0971e-05 - val_loss: 1.0029e-04
Epoch 1569/2000
1024/1024 - 0s - loss: 1.0903e-05 - val_loss: 9.9780e-05
Epoch 1570/2000
1024/1024 - 0s - loss: 1.0836e-05 - val_loss: 9.9141e-05
Epoch 1571/2000
1024/1024 - 0s - loss: 1.0764e-05 - val_loss: 9.9868e-05
Epoch 1572/2000
1024/1024 - 0s - loss: 1.0696e-05 - val_loss: 9.8757e-05
Epoch 1573/2000
1024/1024 - 0s - loss: 1.0628e-05 - val_loss: 9.8733e-05
Epoch 1574/2000
1024/1024 - 0s - loss: 1.0553e-05 - val_loss: 9.8208e-05
Epoch 1575/2000
1024/1024 - 0s - loss: 1.0476e-05 - val_loss: 9.8449e-05
Epoch 1576/2000
1024/1024 - 0s - loss: 1.0407e-05 - val_loss: 9.7824e-05
Epoch 1577/2000
1024/1024 - 0s - loss: 1.0342e-05 - val_loss: 9.7388e-05
Epoch 1578/2000
1024/1024 - 0s - loss: 1.0276e-05 - val_loss: 9.7472e-05
Epoch 1579/2000
1024/1024 - 0s - loss: 1.0209e-05 - val_loss: 9.6644e-05
Epoch 1580/2000
1024/1024 - 0s - loss: 1.0142e-05 - val_loss: 9.6714e-05
Epoch 1581/2000
1024/1024 - 0s - loss: 1.0076e-05 - val_loss: 9.6262e-05
Epoch 1582/2000
1024/1024 - 0s - loss: 1.0010e-05 - val_loss: 9.5779e-05
Epoch 1583/2000
1024/1024 - 0s - loss: 9.9458e-06 - val_loss: 9.5877e-05
Epoch 1584/2000
1024/1024 - 0s - loss: 9.8833e-06 - val_loss: 9.5042e-05
Epoch 1585/2000
1024/1024 - 0s - loss: 9.8224e-06 - val_loss: 9.4429e-05
Epoch 1586/2000
1024/1024 - 0s - loss: 9.7602e-06 - val_loss: 9.4947e-05
Epoch 1587/2000
1024/1024 - 0s - loss: 9.6973e-06 - val_loss: 9.3683e-05
Epoch 1588/2000
1024/1024 - 0s - loss: 9.6349e-06 - val_loss: 9.4475e-05
Epoch 1589/2000
1024/1024 - 0s - loss: 9.5741e-06 - val_loss: 9.3714e-05
Epoch 1590/2000
1024/1024 - 0s - loss: 9.5137e-06 - val_loss: 9.2998e-05
Epoch 1591/2000
1024/1024 - 0s - loss: 9.4510e-06 - val_loss: 9.2852e-05
Epoch 1592/2000
1024/1024 - 0s - loss: 9.3860e-06 - val_loss: 9.2604e-05
Epoch 1593/2000
1024/1024 - 0s - loss: 9.3248e-06 - val_loss: 9.1854e-05
Epoch 1594/2000
1024/1024 - 0s - loss: 9.2608e-06 - val_loss: 9.1889e-05
Epoch 1595/2000
1024/1024 - 0s - loss: 9.2002e-06 - val_loss: 9.1434e-05
Epoch 1596/2000
1024/1024 - 0s - loss: 9.1342e-06 - val_loss: 9.1790e-05
Epoch 1597/2000
1024/1024 - 0s - loss: 9.0707e-06 - val_loss: 9.1336e-05
Epoch 1598/2000
1024/1024 - 0s - loss: 9.0290e-06 - val_loss: 9.0729e-05
Epoch 1599/2000
1024/1024 - 0s - loss: 8.9720e-06 - val_loss: 9.0471e-05
Epoch 1600/2000
1024/1024 - 0s - loss: 8.9200e-06 - val_loss: 8.9368e-05
Epoch 1601/2000
1024/1024 - 0s - loss: 8.8649e-06 - val_loss: 9.0520e-05
Epoch 1602/2000
1024/1024 - 0s - loss: 8.8074e-06 - val_loss: 8.9181e-05
Epoch 1603/2000
1024/1024 - 0s - loss: 8.7525e-06 - val_loss: 9.0031e-05
Epoch 1604/2000
1024/1024 - 0s - loss: 8.6871e-06 - val_loss: 8.8935e-05
Epoch 1605/2000
1024/1024 - 0s - loss: 8.6270e-06 - val_loss: 8.8315e-05
Epoch 1606/2000
1024/1024 - 0s - loss: 8.5689e-06 - val_loss: 8.8662e-05
Epoch 1607/2000
1024/1024 - 0s - loss: 8.5132e-06 - val_loss: 8.8028e-05
Epoch 1608/2000
1024/1024 - 0s - loss: 8.4575e-06 - val_loss: 8.7220e-05
Epoch 1609/2000
1024/1024 - 0s - loss: 8.4008e-06 - val_loss: 8.7586e-05
Epoch 1610/2000
1024/1024 - 0s - loss: 8.3447e-06 - val_loss: 8.7166e-05
Epoch 1611/2000
1024/1024 - 0s - loss: 8.2891e-06 - val_loss: 8.6507e-05
Epoch 1612/2000
1024/1024 - 0s - loss: 8.2330e-06 - val_loss: 8.6844e-05
Epoch 1613/2000
1024/1024 - 0s - loss: 8.1771e-06 - val_loss: 8.6493e-05
Epoch 1614/2000
1024/1024 - 0s - loss: 8.1218e-06 - val_loss: 8.5533e-05
Epoch 1615/2000
1024/1024 - 0s - loss: 8.0677e-06 - val_loss: 8.6202e-05
Epoch 1616/2000
1024/1024 - 0s - loss: 8.0160e-06 - val_loss: 8.4970e-05
Epoch 1617/2000
1024/1024 - 0s - loss: 7.9617e-06 - val_loss: 8.5709e-05
Epoch 1618/2000
1024/1024 - 0s - loss: 7.9076e-06 - val_loss: 8.3960e-05
Epoch 1619/2000
1024/1024 - 0s - loss: 7.8528e-06 - val_loss: 8.5155e-05
Epoch 1620/2000
1024/1024 - 0s - loss: 7.8002e-06 - val_loss: 8.3656e-05
Epoch 1621/2000
1024/1024 - 0s - loss: 7.7476e-06 - val_loss: 8.4464e-05
Epoch 1622/2000
1024/1024 - 0s - loss: 7.6956e-06 - val_loss: 8.3339e-05
Epoch 1623/2000
1024/1024 - 0s - loss: 7.6440e-06 - val_loss: 8.3639e-05
Epoch 1624/2000
1024/1024 - 0s - loss: 7.5911e-06 - val_loss: 8.3249e-05
Epoch 1625/2000
1024/1024 - 0s - loss: 7.5396e-06 - val_loss: 8.2529e-05
Epoch 1626/2000
1024/1024 - 0s - loss: 7.4878e-06 - val_loss: 8.2777e-05
Epoch 1627/2000
1024/1024 - 0s - loss: 7.4354e-06 - val_loss: 8.2952e-05
Epoch 1628/2000
1024/1024 - 0s - loss: 7.3825e-06 - val_loss: 8.1223e-05
Epoch 1629/2000
1024/1024 - 0s - loss: 7.3304e-06 - val_loss: 8.2117e-05
Epoch 1630/2000
1024/1024 - 0s - loss: 7.2783e-06 - val_loss: 8.0954e-05
Epoch 1631/2000
1024/1024 - 0s - loss: 7.2259e-06 - val_loss: 8.1252e-05
Epoch 1632/2000
1024/1024 - 0s - loss: 7.1743e-06 - val_loss: 8.0977e-05
Epoch 1633/2000
1024/1024 - 0s - loss: 7.1240e-06 - val_loss: 8.0811e-05
Epoch 1634/2000
1024/1024 - 0s - loss: 7.0740e-06 - val_loss: 8.0163e-05
Epoch 1635/2000
1024/1024 - 0s - loss: 7.0228e-06 - val_loss: 8.0197e-05
Epoch 1636/2000
1024/1024 - 0s - loss: 6.9737e-06 - val_loss: 7.9438e-05
Epoch 1637/2000
1024/1024 - 0s - loss: 6.9228e-06 - val_loss: 7.9882e-05
Epoch 1638/2000
1024/1024 - 0s - loss: 6.8733e-06 - val_loss: 7.8860e-05
Epoch 1639/2000
1024/1024 - 0s - loss: 6.8308e-06 - val_loss: 7.8989e-05
Epoch 1640/2000
1024/1024 - 0s - loss: 6.7901e-06 - val_loss: 7.8678e-05
Epoch 1641/2000
1024/1024 - 0s - loss: 6.7439e-06 - val_loss: 7.7762e-05
Epoch 1642/2000
1024/1024 - 0s - loss: 6.6950e-06 - val_loss: 7.7909e-05
Epoch 1643/2000
1024/1024 - 0s - loss: 6.6457e-06 - val_loss: 7.7910e-05
Epoch 1644/2000
1024/1024 - 0s - loss: 6.5969e-06 - val_loss: 7.7108e-05
Epoch 1645/2000
1024/1024 - 0s - loss: 6.5498e-06 - val_loss: 7.7610e-05
Epoch 1646/2000
1024/1024 - 0s - loss: 6.5025e-06 - val_loss: 7.7061e-05
Epoch 1647/2000
1024/1024 - 0s - loss: 6.4558e-06 - val_loss: 7.6913e-05
Epoch 1648/2000
1024/1024 - 0s - loss: 6.4167e-06 - val_loss: 7.6547e-05
Epoch 1649/2000
1024/1024 - 0s - loss: 6.3646e-06 - val_loss: 7.6641e-05
Epoch 1650/2000
1024/1024 - 0s - loss: 6.3165e-06 - val_loss: 7.5624e-05
Epoch 1651/2000
1024/1024 - 0s - loss: 6.2692e-06 - val_loss: 7.6049e-05
Epoch 1652/2000
1024/1024 - 0s - loss: 6.2228e-06 - val_loss: 7.5289e-05
Epoch 1653/2000
1024/1024 - 0s - loss: 6.1768e-06 - val_loss: 7.5174e-05
Epoch 1654/2000
1024/1024 - 0s - loss: 6.1311e-06 - val_loss: 7.5443e-05
Epoch 1655/2000
1024/1024 - 0s - loss: 6.0847e-06 - val_loss: 7.4618e-05
Epoch 1656/2000
1024/1024 - 0s - loss: 6.0398e-06 - val_loss: 7.5001e-05
Epoch 1657/2000
1024/1024 - 0s - loss: 5.9930e-06 - val_loss: 7.4202e-05
Epoch 1658/2000
1024/1024 - 0s - loss: 5.9459e-06 - val_loss: 7.4563e-05
Epoch 1659/2000
1024/1024 - 0s - loss: 5.8995e-06 - val_loss: 7.3819e-05
Epoch 1660/2000
1024/1024 - 0s - loss: 5.8542e-06 - val_loss: 7.3527e-05
Epoch 1661/2000
1024/1024 - 0s - loss: 5.8091e-06 - val_loss: 7.3336e-05
Epoch 1662/2000
1024/1024 - 0s - loss: 5.7647e-06 - val_loss: 7.3370e-05
Epoch 1663/2000
1024/1024 - 0s - loss: 5.7212e-06 - val_loss: 7.2746e-05
Epoch 1664/2000
1024/1024 - 0s - loss: 5.6773e-06 - val_loss: 7.2429e-05
Epoch 1665/2000
1024/1024 - 0s - loss: 5.6350e-06 - val_loss: 7.2966e-05
Epoch 1666/2000
1024/1024 - 0s - loss: 5.5925e-06 - val_loss: 7.2128e-05
Epoch 1667/2000
1024/1024 - 0s - loss: 5.5498e-06 - val_loss: 7.1940e-05
Epoch 1668/2000
1024/1024 - 0s - loss: 5.5064e-06 - val_loss: 7.1939e-05
Epoch 1669/2000
1024/1024 - 0s - loss: 5.4635e-06 - val_loss: 7.0998e-05
Epoch 1670/2000
1024/1024 - 0s - loss: 5.4198e-06 - val_loss: 7.1936e-05
Epoch 1671/2000
1024/1024 - 0s - loss: 5.3782e-06 - val_loss: 7.0286e-05
Epoch 1672/2000
1024/1024 - 0s - loss: 5.3374e-06 - val_loss: 7.1241e-05
Epoch 1673/2000
1024/1024 - 0s - loss: 5.2964e-06 - val_loss: 7.0173e-05
Epoch 1674/2000
1024/1024 - 0s - loss: 5.2553e-06 - val_loss: 7.0531e-05
Epoch 1675/2000
1024/1024 - 0s - loss: 5.2155e-06 - val_loss: 6.9395e-05
Epoch 1676/2000
1024/1024 - 0s - loss: 5.1728e-06 - val_loss: 7.0705e-05
Epoch 1677/2000
1024/1024 - 0s - loss: 5.1329e-06 - val_loss: 6.9124e-05
Epoch 1678/2000
1024/1024 - 0s - loss: 5.0919e-06 - val_loss: 6.9831e-05
Epoch 1679/2000
1024/1024 - 0s - loss: 5.0507e-06 - val_loss: 6.9638e-05
Epoch 1680/2000
1024/1024 - 0s - loss: 5.0054e-06 - val_loss: 6.8580e-05
Epoch 1681/2000
1024/1024 - 0s - loss: 4.9657e-06 - val_loss: 6.9179e-05
Epoch 1682/2000
1024/1024 - 0s - loss: 4.9258e-06 - val_loss: 6.7825e-05
Epoch 1683/2000
1024/1024 - 0s - loss: 4.8857e-06 - val_loss: 6.8543e-05
Epoch 1684/2000
1024/1024 - 0s - loss: 4.8467e-06 - val_loss: 6.8593e-05
Epoch 1685/2000
1024/1024 - 0s - loss: 4.8081e-06 - val_loss: 6.7369e-05
Epoch 1686/2000
1024/1024 - 0s - loss: 4.7712e-06 - val_loss: 6.7839e-05
Epoch 1687/2000
1024/1024 - 0s - loss: 4.7349e-06 - val_loss: 6.7187e-05
Epoch 1688/2000
1024/1024 - 0s - loss: 4.6969e-06 - val_loss: 6.7212e-05
Epoch 1689/2000
1024/1024 - 0s - loss: 4.6587e-06 - val_loss: 6.7259e-05
Epoch 1690/2000
1024/1024 - 0s - loss: 4.6207e-06 - val_loss: 6.6202e-05
Epoch 1691/2000
1024/1024 - 0s - loss: 4.5825e-06 - val_loss: 6.7151e-05
Epoch 1692/2000
1024/1024 - 0s - loss: 4.5440e-06 - val_loss: 6.6310e-05
Epoch 1693/2000
1024/1024 - 0s - loss: 4.5065e-06 - val_loss: 6.6307e-05
Epoch 1694/2000
1024/1024 - 0s - loss: 4.4694e-06 - val_loss: 6.6026e-05
Epoch 1695/2000
1024/1024 - 0s - loss: 4.4308e-06 - val_loss: 6.5194e-05
Epoch 1696/2000
1024/1024 - 0s - loss: 4.3903e-06 - val_loss: 6.6132e-05
Epoch 1697/2000
1024/1024 - 0s - loss: 4.3542e-06 - val_loss: 6.4719e-05
Epoch 1698/2000
1024/1024 - 0s - loss: 4.3188e-06 - val_loss: 6.5564e-05
Epoch 1699/2000
1024/1024 - 0s - loss: 4.2827e-06 - val_loss: 6.4714e-05
Epoch 1700/2000
1024/1024 - 0s - loss: 4.2465e-06 - val_loss: 6.4695e-05
Epoch 1701/2000
1024/1024 - 0s - loss: 4.2115e-06 - val_loss: 6.5003e-05
Epoch 1702/2000
1024/1024 - 0s - loss: 4.1765e-06 - val_loss: 6.3925e-05
Epoch 1703/2000
1024/1024 - 0s - loss: 4.1401e-06 - val_loss: 6.4149e-05
Epoch 1704/2000
1024/1024 - 0s - loss: 4.1052e-06 - val_loss: 6.3992e-05
Epoch 1705/2000
1024/1024 - 0s - loss: 4.0709e-06 - val_loss: 6.3279e-05
Epoch 1706/2000
1024/1024 - 0s - loss: 4.0369e-06 - val_loss: 6.3578e-05
Epoch 1707/2000
1024/1024 - 0s - loss: 4.0033e-06 - val_loss: 6.3729e-05
Epoch 1708/2000
1024/1024 - 0s - loss: 3.9695e-06 - val_loss: 6.3072e-05
Epoch 1709/2000
1024/1024 - 0s - loss: 3.9361e-06 - val_loss: 6.2995e-05
Epoch 1710/2000
1024/1024 - 0s - loss: 3.9031e-06 - val_loss: 6.2536e-05
Epoch 1711/2000
1024/1024 - 0s - loss: 3.8703e-06 - val_loss: 6.2448e-05
Epoch 1712/2000
1024/1024 - 0s - loss: 3.8372e-06 - val_loss: 6.2138e-05
Epoch 1713/2000
1024/1024 - 0s - loss: 3.8046e-06 - val_loss: 6.1701e-05
Epoch 1714/2000
1024/1024 - 0s - loss: 3.7722e-06 - val_loss: 6.1866e-05
Epoch 1715/2000
1024/1024 - 0s - loss: 3.7400e-06 - val_loss: 6.1652e-05
Epoch 1716/2000
1024/1024 - 0s - loss: 3.7081e-06 - val_loss: 6.1860e-05
Epoch 1717/2000
1024/1024 - 0s - loss: 3.6769e-06 - val_loss: 6.1133e-05
Epoch 1718/2000
1024/1024 - 0s - loss: 3.6449e-06 - val_loss: 6.1020e-05
Epoch 1719/2000
1024/1024 - 0s - loss: 3.6135e-06 - val_loss: 6.0777e-05
Epoch 1720/2000
1024/1024 - 0s - loss: 3.5821e-06 - val_loss: 6.0568e-05
Epoch 1721/2000
1024/1024 - 0s - loss: 3.5517e-06 - val_loss: 6.0665e-05
Epoch 1722/2000
1024/1024 - 0s - loss: 3.5204e-06 - val_loss: 6.0303e-05
Epoch 1723/2000
1024/1024 - 0s - loss: 3.4905e-06 - val_loss: 6.0059e-05
Epoch 1724/2000
1024/1024 - 0s - loss: 3.4606e-06 - val_loss: 6.0035e-05
Epoch 1725/2000
1024/1024 - 0s - loss: 3.4310e-06 - val_loss: 5.9764e-05
Epoch 1726/2000
1024/1024 - 0s - loss: 3.4013e-06 - val_loss: 5.9354e-05
Epoch 1727/2000
1024/1024 - 0s - loss: 3.3720e-06 - val_loss: 5.9542e-05
Epoch 1728/2000
1024/1024 - 0s - loss: 3.3424e-06 - val_loss: 5.8625e-05
Epoch 1729/2000
1024/1024 - 0s - loss: 3.3135e-06 - val_loss: 5.9501e-05
Epoch 1730/2000
1024/1024 - 0s - loss: 3.2843e-06 - val_loss: 5.8815e-05
Epoch 1731/2000
1024/1024 - 0s - loss: 3.2554e-06 - val_loss: 5.8665e-05
Epoch 1732/2000
1024/1024 - 0s - loss: 3.2272e-06 - val_loss: 5.7777e-05
Epoch 1733/2000
1024/1024 - 0s - loss: 3.1992e-06 - val_loss: 5.8489e-05
Epoch 1734/2000
1024/1024 - 0s - loss: 3.1705e-06 - val_loss: 5.7868e-05
Epoch 1735/2000
1024/1024 - 0s - loss: 3.1432e-06 - val_loss: 5.7515e-05
Epoch 1736/2000
1024/1024 - 0s - loss: 3.1160e-06 - val_loss: 5.7814e-05
Epoch 1737/2000
1024/1024 - 0s - loss: 3.0889e-06 - val_loss: 5.7128e-05
Epoch 1738/2000
1024/1024 - 0s - loss: 3.0613e-06 - val_loss: 5.7496e-05
Epoch 1739/2000
1024/1024 - 0s - loss: 3.0343e-06 - val_loss: 5.6572e-05
Epoch 1740/2000
1024/1024 - 0s - loss: 3.0059e-06 - val_loss: 5.6885e-05
Epoch 1741/2000
1024/1024 - 0s - loss: 2.9747e-06 - val_loss: 5.6662e-05
Epoch 1742/2000
1024/1024 - 0s - loss: 2.9478e-06 - val_loss: 5.6287e-05
Epoch 1743/2000
1024/1024 - 0s - loss: 2.9213e-06 - val_loss: 5.7016e-05
Epoch 1744/2000
1024/1024 - 0s - loss: 2.8957e-06 - val_loss: 5.5433e-05
Epoch 1745/2000
1024/1024 - 0s - loss: 2.8692e-06 - val_loss: 5.6415e-05
Epoch 1746/2000
1024/1024 - 0s - loss: 2.8432e-06 - val_loss: 5.5453e-05
Epoch 1747/2000
1024/1024 - 0s - loss: 2.8179e-06 - val_loss: 5.5665e-05
Epoch 1748/2000
1024/1024 - 0s - loss: 2.7930e-06 - val_loss: 5.5373e-05
Epoch 1749/2000
1024/1024 - 0s - loss: 2.7677e-06 - val_loss: 5.5444e-05
Epoch 1750/2000
1024/1024 - 0s - loss: 2.7430e-06 - val_loss: 5.5187e-05
Epoch 1751/2000
1024/1024 - 0s - loss: 2.7183e-06 - val_loss: 5.4878e-05
Epoch 1752/2000
1024/1024 - 0s - loss: 2.6942e-06 - val_loss: 5.4521e-05
Epoch 1753/2000
1024/1024 - 0s - loss: 2.6699e-06 - val_loss: 5.4368e-05
Epoch 1754/2000
1024/1024 - 0s - loss: 2.6464e-06 - val_loss: 5.4895e-05
Epoch 1755/2000
1024/1024 - 0s - loss: 2.6224e-06 - val_loss: 5.4237e-05
Epoch 1756/2000
1024/1024 - 0s - loss: 2.5990e-06 - val_loss: 5.3411e-05
Epoch 1757/2000
1024/1024 - 0s - loss: 2.5757e-06 - val_loss: 5.4663e-05
Epoch 1758/2000
1024/1024 - 0s - loss: 2.5529e-06 - val_loss: 5.3205e-05
Epoch 1759/2000
1024/1024 - 0s - loss: 2.5296e-06 - val_loss: 5.3541e-05
Epoch 1760/2000
1024/1024 - 0s - loss: 2.5068e-06 - val_loss: 5.3052e-05
Epoch 1761/2000
1024/1024 - 0s - loss: 2.4843e-06 - val_loss: 5.3257e-05
Epoch 1762/2000
1024/1024 - 0s - loss: 2.4619e-06 - val_loss: 5.3032e-05
Epoch 1763/2000
1024/1024 - 0s - loss: 2.4393e-06 - val_loss: 5.2449e-05
Epoch 1764/2000
1024/1024 - 0s - loss: 2.4173e-06 - val_loss: 5.2932e-05
Epoch 1765/2000
1024/1024 - 0s - loss: 2.3954e-06 - val_loss: 5.2773e-05
Epoch 1766/2000
1024/1024 - 0s - loss: 2.3742e-06 - val_loss: 5.2534e-05
Epoch 1767/2000
1024/1024 - 0s - loss: 2.3549e-06 - val_loss: 5.1520e-05
Epoch 1768/2000
1024/1024 - 0s - loss: 2.3364e-06 - val_loss: 5.1870e-05
Epoch 1769/2000
1024/1024 - 0s - loss: 2.3098e-06 - val_loss: 5.2022e-05
Epoch 1770/2000
1024/1024 - 0s - loss: 2.2886e-06 - val_loss: 5.1995e-05
Epoch 1771/2000
1024/1024 - 0s - loss: 2.2676e-06 - val_loss: 5.0874e-05
Epoch 1772/2000
1024/1024 - 0s - loss: 2.2470e-06 - val_loss: 5.1521e-05
Epoch 1773/2000
1024/1024 - 0s - loss: 2.2266e-06 - val_loss: 5.1610e-05
Epoch 1774/2000
1024/1024 - 0s - loss: 2.2066e-06 - val_loss: 5.0357e-05
Epoch 1775/2000
1024/1024 - 0s - loss: 2.1871e-06 - val_loss: 5.1231e-05
Epoch 1776/2000
1024/1024 - 0s - loss: 2.1675e-06 - val_loss: 5.0941e-05
Epoch 1777/2000
1024/1024 - 0s - loss: 2.1486e-06 - val_loss: 5.0525e-05
Epoch 1778/2000
1024/1024 - 0s - loss: 2.1291e-06 - val_loss: 5.0269e-05
Epoch 1779/2000
1024/1024 - 0s - loss: 2.1103e-06 - val_loss: 4.9913e-05
Epoch 1780/2000
1024/1024 - 0s - loss: 2.0951e-06 - val_loss: 5.0632e-05
Epoch 1781/2000
1024/1024 - 0s - loss: 2.0752e-06 - val_loss: 4.9318e-05
Epoch 1782/2000
1024/1024 - 0s - loss: 2.0559e-06 - val_loss: 4.9610e-05
Epoch 1783/2000
1024/1024 - 0s - loss: 2.0376e-06 - val_loss: 4.9327e-05
Epoch 1784/2000
1024/1024 - 0s - loss: 2.0197e-06 - val_loss: 4.9750e-05
Epoch 1785/2000
1024/1024 - 0s - loss: 2.0018e-06 - val_loss: 4.9234e-05
Epoch 1786/2000
1024/1024 - 0s - loss: 1.9840e-06 - val_loss: 4.8922e-05
Epoch 1787/2000
1024/1024 - 0s - loss: 1.9668e-06 - val_loss: 4.8750e-05
Epoch 1788/2000
1024/1024 - 0s - loss: 1.9495e-06 - val_loss: 4.8271e-05
Epoch 1789/2000
1024/1024 - 0s - loss: 1.9326e-06 - val_loss: 4.9025e-05
Epoch 1790/2000
1024/1024 - 0s - loss: 1.9169e-06 - val_loss: 4.8485e-05
Epoch 1791/2000
1024/1024 - 0s - loss: 1.8990e-06 - val_loss: 4.8562e-05
Epoch 1792/2000
1024/1024 - 0s - loss: 1.8823e-06 - val_loss: 4.7431e-05
Epoch 1793/2000
1024/1024 - 0s - loss: 1.8662e-06 - val_loss: 4.8376e-05
Epoch 1794/2000
1024/1024 - 0s - loss: 1.8494e-06 - val_loss: 4.7536e-05
Epoch 1795/2000
1024/1024 - 0s - loss: 1.8336e-06 - val_loss: 4.7932e-05
Epoch 1796/2000
1024/1024 - 0s - loss: 1.8179e-06 - val_loss: 4.7808e-05
Epoch 1797/2000
1024/1024 - 0s - loss: 1.8022e-06 - val_loss: 4.7005e-05
Epoch 1798/2000
1024/1024 - 0s - loss: 1.7865e-06 - val_loss: 4.7428e-05
Epoch 1799/2000
1024/1024 - 0s - loss: 1.7708e-06 - val_loss: 4.6988e-05
Epoch 1800/2000
1024/1024 - 0s - loss: 1.7555e-06 - val_loss: 4.6818e-05
Epoch 1801/2000
1024/1024 - 0s - loss: 1.7405e-06 - val_loss: 4.6793e-05
Epoch 1802/2000
1024/1024 - 0s - loss: 1.7254e-06 - val_loss: 4.6424e-05
Epoch 1803/2000
1024/1024 - 0s - loss: 1.7109e-06 - val_loss: 4.6394e-05
Epoch 1804/2000
1024/1024 - 0s - loss: 1.6984e-06 - val_loss: 4.6520e-05
Epoch 1805/2000
1024/1024 - 0s - loss: 1.6844e-06 - val_loss: 4.5964e-05
Epoch 1806/2000
1024/1024 - 0s - loss: 1.6690e-06 - val_loss: 4.6197e-05
Epoch 1807/2000
1024/1024 - 0s - loss: 1.6547e-06 - val_loss: 4.5501e-05
Epoch 1808/2000
1024/1024 - 0s - loss: 1.6407e-06 - val_loss: 4.5667e-05
Epoch 1809/2000
1024/1024 - 0s - loss: 1.6270e-06 - val_loss: 4.4858e-05
Epoch 1810/2000
1024/1024 - 0s - loss: 1.6133e-06 - val_loss: 4.5644e-05
Epoch 1811/2000
1024/1024 - 0s - loss: 1.6000e-06 - val_loss: 4.5638e-05
Epoch 1812/2000
1024/1024 - 0s - loss: 1.5863e-06 - val_loss: 4.4781e-05
Epoch 1813/2000
1024/1024 - 0s - loss: 1.5731e-06 - val_loss: 4.4584e-05
Epoch 1814/2000
1024/1024 - 0s - loss: 1.5600e-06 - val_loss: 4.4444e-05
Epoch 1815/2000
1024/1024 - 0s - loss: 1.5470e-06 - val_loss: 4.4449e-05
Epoch 1816/2000
1024/1024 - 0s - loss: 1.5340e-06 - val_loss: 4.4137e-05
Epoch 1817/2000
1024/1024 - 0s - loss: 1.5217e-06 - val_loss: 4.4771e-05
Epoch 1818/2000
1024/1024 - 0s - loss: 1.5090e-06 - val_loss: 4.3852e-05
Epoch 1819/2000
1024/1024 - 0s - loss: 1.4968e-06 - val_loss: 4.3981e-05
Epoch 1820/2000
1024/1024 - 0s - loss: 1.4844e-06 - val_loss: 4.3988e-05
Epoch 1821/2000
1024/1024 - 0s - loss: 1.4723e-06 - val_loss: 4.3843e-05
Epoch 1822/2000
1024/1024 - 0s - loss: 1.4604e-06 - val_loss: 4.3638e-05
Epoch 1823/2000
1024/1024 - 0s - loss: 1.4487e-06 - val_loss: 4.3782e-05
Epoch 1824/2000
1024/1024 - 0s - loss: 1.4370e-06 - val_loss: 4.3659e-05
Epoch 1825/2000
1024/1024 - 0s - loss: 1.4252e-06 - val_loss: 4.2943e-05
Epoch 1826/2000
1024/1024 - 0s - loss: 1.4138e-06 - val_loss: 4.3454e-05
Epoch 1827/2000
1024/1024 - 0s - loss: 1.4025e-06 - val_loss: 4.2598e-05
Epoch 1828/2000
1024/1024 - 0s - loss: 1.3914e-06 - val_loss: 4.2955e-05
Epoch 1829/2000
1024/1024 - 0s - loss: 1.3802e-06 - val_loss: 4.2548e-05
Epoch 1830/2000
1024/1024 - 0s - loss: 1.3694e-06 - val_loss: 4.2478e-05
Epoch 1831/2000
1024/1024 - 0s - loss: 1.3585e-06 - val_loss: 4.2272e-05
Epoch 1832/2000
1024/1024 - 0s - loss: 1.3478e-06 - val_loss: 4.2130e-05
Epoch 1833/2000
1024/1024 - 0s - loss: 1.3375e-06 - val_loss: 4.2484e-05
Epoch 1834/2000
1024/1024 - 0s - loss: 1.3273e-06 - val_loss: 4.2095e-05
Epoch 1835/2000
1024/1024 - 0s - loss: 1.3167e-06 - val_loss: 4.1906e-05
Epoch 1836/2000
1024/1024 - 0s - loss: 1.3065e-06 - val_loss: 4.1543e-05
Epoch 1837/2000
1024/1024 - 0s - loss: 1.2964e-06 - val_loss: 4.1526e-05
Epoch 1838/2000
1024/1024 - 0s - loss: 1.2868e-06 - val_loss: 4.1398e-05
Epoch 1839/2000
1024/1024 - 0s - loss: 1.2768e-06 - val_loss: 4.0812e-05
Epoch 1840/2000
1024/1024 - 0s - loss: 1.2671e-06 - val_loss: 4.1049e-05
Epoch 1841/2000
1024/1024 - 0s - loss: 1.2577e-06 - val_loss: 4.1143e-05
Epoch 1842/2000
1024/1024 - 0s - loss: 1.2479e-06 - val_loss: 4.0995e-05
Epoch 1843/2000
1024/1024 - 0s - loss: 1.2384e-06 - val_loss: 4.0266e-05
Epoch 1844/2000
1024/1024 - 0s - loss: 1.2291e-06 - val_loss: 4.0925e-05
Epoch 1845/2000
1024/1024 - 0s - loss: 1.2202e-06 - val_loss: 4.0156e-05
Epoch 1846/2000
1024/1024 - 0s - loss: 1.2110e-06 - val_loss: 3.9832e-05
Epoch 1847/2000
1024/1024 - 0s - loss: 1.2023e-06 - val_loss: 4.0293e-05
Epoch 1848/2000
1024/1024 - 0s - loss: 1.1934e-06 - val_loss: 4.0088e-05
Epoch 1849/2000
1024/1024 - 0s - loss: 1.1845e-06 - val_loss: 3.9494e-05
Epoch 1850/2000
1024/1024 - 0s - loss: 1.1758e-06 - val_loss: 4.0203e-05
Epoch 1851/2000
1024/1024 - 0s - loss: 1.1677e-06 - val_loss: 3.9479e-05
Epoch 1852/2000
1024/1024 - 0s - loss: 1.1589e-06 - val_loss: 3.9121e-05
Epoch 1853/2000
1024/1024 - 0s - loss: 1.1505e-06 - val_loss: 3.9049e-05
Epoch 1854/2000
1024/1024 - 0s - loss: 1.1422e-06 - val_loss: 3.9160e-05
Epoch 1855/2000
1024/1024 - 0s - loss: 1.1341e-06 - val_loss: 3.8920e-05
Epoch 1856/2000
1024/1024 - 0s - loss: 1.1260e-06 - val_loss: 3.8649e-05
Epoch 1857/2000
1024/1024 - 0s - loss: 1.1185e-06 - val_loss: 3.9325e-05
Epoch 1858/2000
1024/1024 - 0s - loss: 1.1104e-06 - val_loss: 3.8257e-05
Epoch 1859/2000
1024/1024 - 0s - loss: 1.1026e-06 - val_loss: 3.8258e-05
Epoch 1860/2000
1024/1024 - 0s - loss: 1.0948e-06 - val_loss: 3.8621e-05
Epoch 1861/2000
1024/1024 - 0s - loss: 1.0872e-06 - val_loss: 3.7912e-05
Epoch 1862/2000
1024/1024 - 0s - loss: 1.0797e-06 - val_loss: 3.7710e-05
Epoch 1863/2000
1024/1024 - 0s - loss: 1.0722e-06 - val_loss: 3.7667e-05
Epoch 1864/2000
1024/1024 - 0s - loss: 1.0648e-06 - val_loss: 3.8006e-05
Epoch 1865/2000
1024/1024 - 0s - loss: 1.0575e-06 - val_loss: 3.7315e-05
Epoch 1866/2000
1024/1024 - 0s - loss: 1.0503e-06 - val_loss: 3.7357e-05
Epoch 1867/2000
1024/1024 - 0s - loss: 1.0431e-06 - val_loss: 3.7581e-05
Epoch 1868/2000
1024/1024 - 0s - loss: 1.0363e-06 - val_loss: 3.6945e-05
Epoch 1869/2000
1024/1024 - 0s - loss: 1.0291e-06 - val_loss: 3.6982e-05
Epoch 1870/2000
1024/1024 - 0s - loss: 1.0221e-06 - val_loss: 3.7601e-05
Epoch 1871/2000
1024/1024 - 0s - loss: 1.0154e-06 - val_loss: 3.6271e-05
Epoch 1872/2000
1024/1024 - 0s - loss: 1.0088e-06 - val_loss: 3.7060e-05
Epoch 1873/2000
1024/1024 - 0s - loss: 1.0018e-06 - val_loss: 3.6442e-05
Epoch 1874/2000
1024/1024 - 0s - loss: 9.9512e-07 - val_loss: 3.6397e-05
Epoch 1875/2000
1024/1024 - 0s - loss: 9.8858e-07 - val_loss: 3.6358e-05
Epoch 1876/2000
1024/1024 - 0s - loss: 9.8212e-07 - val_loss: 3.6165e-05
Epoch 1877/2000
1024/1024 - 0s - loss: 9.7576e-07 - val_loss: 3.6112e-05
Epoch 1878/2000
1024/1024 - 0s - loss: 9.6926e-07 - val_loss: 3.5774e-05
Epoch 1879/2000
1024/1024 - 0s - loss: 9.6307e-07 - val_loss: 3.5797e-05
Epoch 1880/2000
1024/1024 - 0s - loss: 9.5692e-07 - val_loss: 3.5452e-05
Epoch 1881/2000
1024/1024 - 0s - loss: 9.5112e-07 - val_loss: 3.5107e-05
Epoch 1882/2000
1024/1024 - 0s - loss: 9.4446e-07 - val_loss: 3.5485e-05
Epoch 1883/2000
1024/1024 - 0s - loss: 9.3841e-07 - val_loss: 3.5471e-05
Epoch 1884/2000
1024/1024 - 0s - loss: 9.3248e-07 - val_loss: 3.5240e-05
Epoch 1885/2000
1024/1024 - 0s - loss: 9.2656e-07 - val_loss: 3.4597e-05
Epoch 1886/2000
1024/1024 - 0s - loss: 9.2074e-07 - val_loss: 3.5059e-05
Epoch 1887/2000
1024/1024 - 0s - loss: 9.1473e-07 - val_loss: 3.4895e-05
Epoch 1888/2000
1024/1024 - 0s - loss: 9.0907e-07 - val_loss: 3.4049e-05
Epoch 1889/2000
1024/1024 - 0s - loss: 9.0410e-07 - val_loss: 3.4759e-05
Epoch 1890/2000
1024/1024 - 0s - loss: 8.9764e-07 - val_loss: 3.4428e-05
Epoch 1891/2000
1024/1024 - 0s - loss: 8.9206e-07 - val_loss: 3.4573e-05
Epoch 1892/2000
1024/1024 - 0s - loss: 8.8657e-07 - val_loss: 3.4433e-05
Epoch 1893/2000
1024/1024 - 0s - loss: 8.8103e-07 - val_loss: 3.4234e-05
Epoch 1894/2000
1024/1024 - 0s - loss: 8.7545e-07 - val_loss: 3.3770e-05
Epoch 1895/2000
1024/1024 - 0s - loss: 8.6996e-07 - val_loss: 3.3753e-05
Epoch 1896/2000
1024/1024 - 0s - loss: 8.6469e-07 - val_loss: 3.4009e-05
Epoch 1897/2000
1024/1024 - 0s - loss: 8.5946e-07 - val_loss: 3.3570e-05
Epoch 1898/2000
1024/1024 - 0s - loss: 8.5410e-07 - val_loss: 3.3511e-05
Epoch 1899/2000
1024/1024 - 0s - loss: 8.4940e-07 - val_loss: 3.2910e-05
Epoch 1900/2000
1024/1024 - 0s - loss: 8.4390e-07 - val_loss: 3.2989e-05
Epoch 1901/2000
1024/1024 - 0s - loss: 8.3848e-07 - val_loss: 3.3083e-05
Epoch 1902/2000
1024/1024 - 0s - loss: 8.3339e-07 - val_loss: 3.2936e-05
Epoch 1903/2000
1024/1024 - 0s - loss: 8.2845e-07 - val_loss: 3.2541e-05
Epoch 1904/2000
1024/1024 - 0s - loss: 8.2356e-07 - val_loss: 3.2401e-05
Epoch 1905/2000
1024/1024 - 0s - loss: 8.1882e-07 - val_loss: 3.3393e-05
Epoch 1906/2000
1024/1024 - 0s - loss: 8.1366e-07 - val_loss: 3.2398e-05
Epoch 1907/2000
1024/1024 - 0s - loss: 8.0867e-07 - val_loss: 3.2189e-05
Epoch 1908/2000
1024/1024 - 0s - loss: 8.0373e-07 - val_loss: 3.2211e-05
Epoch 1909/2000
1024/1024 - 0s - loss: 7.9891e-07 - val_loss: 3.2288e-05
Epoch 1910/2000
1024/1024 - 0s - loss: 7.9426e-07 - val_loss: 3.1666e-05
Epoch 1911/2000
1024/1024 - 0s - loss: 7.8968e-07 - val_loss: 3.1616e-05
Epoch 1912/2000
1024/1024 - 0s - loss: 7.8481e-07 - val_loss: 3.1858e-05
Epoch 1913/2000
1024/1024 - 0s - loss: 7.8010e-07 - val_loss: 3.1376e-05
Epoch 1914/2000
1024/1024 - 0s - loss: 7.7575e-07 - val_loss: 3.1616e-05
Epoch 1915/2000
1024/1024 - 0s - loss: 7.7091e-07 - val_loss: 3.1646e-05
Epoch 1916/2000
1024/1024 - 0s - loss: 7.6633e-07 - val_loss: 3.0998e-05
Epoch 1917/2000
1024/1024 - 0s - loss: 7.6192e-07 - val_loss: 3.1839e-05
Epoch 1918/2000
1024/1024 - 0s - loss: 7.5774e-07 - val_loss: 3.1264e-05
Epoch 1919/2000
1024/1024 - 0s - loss: 7.5299e-07 - val_loss: 3.0847e-05
Epoch 1920/2000
1024/1024 - 0s - loss: 7.4849e-07 - val_loss: 3.1005e-05
Epoch 1921/2000
1024/1024 - 0s - loss: 7.4416e-07 - val_loss: 3.0798e-05
Epoch 1922/2000
1024/1024 - 0s - loss: 7.3990e-07 - val_loss: 3.0663e-05
Epoch 1923/2000
1024/1024 - 0s - loss: 7.3577e-07 - val_loss: 3.0318e-05
Epoch 1924/2000
1024/1024 - 0s - loss: 7.3138e-07 - val_loss: 3.0223e-05
Epoch 1925/2000
1024/1024 - 0s - loss: 7.2704e-07 - val_loss: 3.0107e-05
Epoch 1926/2000
1024/1024 - 0s - loss: 7.2282e-07 - val_loss: 3.0001e-05
Epoch 1927/2000
1024/1024 - 0s - loss: 7.1861e-07 - val_loss: 3.0056e-05
Epoch 1928/2000
1024/1024 - 0s - loss: 7.1447e-07 - val_loss: 3.0151e-05
Epoch 1929/2000
1024/1024 - 0s - loss: 7.1051e-07 - val_loss: 2.9813e-05
Epoch 1930/2000
1024/1024 - 0s - loss: 7.0631e-07 - val_loss: 2.9850e-05
Epoch 1931/2000
1024/1024 - 0s - loss: 7.0234e-07 - val_loss: 2.9903e-05
Epoch 1932/2000
1024/1024 - 0s - loss: 6.9813e-07 - val_loss: 2.9436e-05
Epoch 1933/2000
1024/1024 - 0s - loss: 6.9414e-07 - val_loss: 2.9453e-05
Epoch 1934/2000
1024/1024 - 0s - loss: 6.9022e-07 - val_loss: 2.8891e-05
Epoch 1935/2000
1024/1024 - 0s - loss: 6.8663e-07 - val_loss: 2.9634e-05
Epoch 1936/2000
1024/1024 - 0s - loss: 6.8233e-07 - val_loss: 2.9126e-05
Epoch 1937/2000
1024/1024 - 0s - loss: 6.7842e-07 - val_loss: 2.9093e-05
Epoch 1938/2000
1024/1024 - 0s - loss: 6.7453e-07 - val_loss: 2.8858e-05
Epoch 1939/2000
1024/1024 - 0s - loss: 6.7072e-07 - val_loss: 2.9110e-05
Epoch 1940/2000
1024/1024 - 0s - loss: 6.6725e-07 - val_loss: 2.8736e-05
Epoch 1941/2000
1024/1024 - 0s - loss: 6.6317e-07 - val_loss: 2.8307e-05
Epoch 1942/2000
1024/1024 - 0s - loss: 6.5949e-07 - val_loss: 2.8633e-05
Epoch 1943/2000
1024/1024 - 0s - loss: 6.5569e-07 - val_loss: 2.8508e-05
Epoch 1944/2000
1024/1024 - 0s - loss: 6.5190e-07 - val_loss: 2.8335e-05
Epoch 1945/2000
1024/1024 - 0s - loss: 6.4829e-07 - val_loss: 2.8356e-05
Epoch 1946/2000
1024/1024 - 0s - loss: 6.4459e-07 - val_loss: 2.8081e-05
Epoch 1947/2000
1024/1024 - 0s - loss: 6.4092e-07 - val_loss: 2.7844e-05
Epoch 1948/2000
1024/1024 - 0s - loss: 6.3734e-07 - val_loss: 2.8025e-05
Epoch 1949/2000
1024/1024 - 0s - loss: 6.3382e-07 - val_loss: 2.7850e-05
Epoch 1950/2000
1024/1024 - 0s - loss: 6.3036e-07 - val_loss: 2.7494e-05
Epoch 1951/2000
1024/1024 - 0s - loss: 6.2683e-07 - val_loss: 2.7398e-05
Epoch 1952/2000
1024/1024 - 0s - loss: 6.2328e-07 - val_loss: 2.7808e-05
Epoch 1953/2000
1024/1024 - 0s - loss: 6.1979e-07 - val_loss: 2.7542e-05
Epoch 1954/2000
1024/1024 - 0s - loss: 6.1619e-07 - val_loss: 2.7260e-05
Epoch 1955/2000
1024/1024 - 0s - loss: 6.1270e-07 - val_loss: 2.7376e-05
Epoch 1956/2000
1024/1024 - 0s - loss: 6.0941e-07 - val_loss: 2.6733e-05
Epoch 1957/2000
1024/1024 - 0s - loss: 6.0594e-07 - val_loss: 2.7165e-05
Epoch 1958/2000
1024/1024 - 0s - loss: 6.0256e-07 - val_loss: 2.6925e-05
Epoch 1959/2000
1024/1024 - 0s - loss: 5.9913e-07 - val_loss: 2.6525e-05
Epoch 1960/2000
1024/1024 - 0s - loss: 5.9596e-07 - val_loss: 2.7339e-05
Epoch 1961/2000
1024/1024 - 0s - loss: 5.9271e-07 - val_loss: 2.6503e-05
Epoch 1962/2000
1024/1024 - 0s - loss: 5.8922e-07 - val_loss: 2.6286e-05
Epoch 1963/2000
1024/1024 - 0s - loss: 5.8596e-07 - val_loss: 2.6454e-05
Epoch 1964/2000
1024/1024 - 0s - loss: 5.8271e-07 - val_loss: 2.6293e-05
Epoch 1965/2000
1024/1024 - 0s - loss: 5.7952e-07 - val_loss: 2.5898e-05
Epoch 1966/2000
1024/1024 - 0s - loss: 5.7624e-07 - val_loss: 2.6074e-05
Epoch 1967/2000
1024/1024 - 0s - loss: 5.7311e-07 - val_loss: 2.6174e-05
Epoch 1968/2000
1024/1024 - 0s - loss: 5.6995e-07 - val_loss: 2.5998e-05
Epoch 1969/2000
1024/1024 - 0s - loss: 5.6672e-07 - val_loss: 2.5549e-05
Epoch 1970/2000
1024/1024 - 0s - loss: 5.6371e-07 - val_loss: 2.6243e-05
Epoch 1971/2000
1024/1024 - 0s - loss: 5.6075e-07 - val_loss: 2.5472e-05
Epoch 1972/2000
1024/1024 - 0s - loss: 5.5747e-07 - val_loss: 2.5553e-05
Epoch 1973/2000
1024/1024 - 0s - loss: 5.5441e-07 - val_loss: 2.5299e-05
Epoch 1974/2000
1024/1024 - 0s - loss: 5.5132e-07 - val_loss: 2.5158e-05
Epoch 1975/2000
1024/1024 - 0s - loss: 5.4834e-07 - val_loss: 2.5409e-05
Epoch 1976/2000
1024/1024 - 0s - loss: 5.4526e-07 - val_loss: 2.4871e-05
Epoch 1977/2000
1024/1024 - 0s - loss: 5.4239e-07 - val_loss: 2.4897e-05
Epoch 1978/2000
1024/1024 - 0s - loss: 5.3956e-07 - val_loss: 2.5498e-05
Epoch 1979/2000
1024/1024 - 0s - loss: 5.3658e-07 - val_loss: 2.5024e-05
Epoch 1980/2000
1024/1024 - 0s - loss: 5.3340e-07 - val_loss: 2.4451e-05
Epoch 1981/2000
1024/1024 - 0s - loss: 5.3060e-07 - val_loss: 2.4729e-05
Epoch 1982/2000
1024/1024 - 0s - loss: 5.2765e-07 - val_loss: 2.4782e-05
Epoch 1983/2000
1024/1024 - 0s - loss: 5.2478e-07 - val_loss: 2.4850e-05
Epoch 1984/2000
1024/1024 - 0s - loss: 5.2197e-07 - val_loss: 2.4637e-05
Epoch 1985/2000
1024/1024 - 0s - loss: 5.1897e-07 - val_loss: 2.3930e-05
Epoch 1986/2000
1024/1024 - 0s - loss: 5.1638e-07 - val_loss: 2.3932e-05
Epoch 1987/2000
1024/1024 - 0s - loss: 5.1351e-07 - val_loss: 2.3857e-05
Epoch 1988/2000
1024/1024 - 0s - loss: 5.1063e-07 - val_loss: 2.3949e-05
Epoch 1989/2000
1024/1024 - 0s - loss: 5.0788e-07 - val_loss: 2.3796e-05
Epoch 1990/2000
1024/1024 - 0s - loss: 5.0500e-07 - val_loss: 2.3743e-05
Epoch 1991/2000
1024/1024 - 0s - loss: 5.0217e-07 - val_loss: 2.4170e-05
Epoch 1992/2000
1024/1024 - 0s - loss: 4.9979e-07 - val_loss: 2.3680e-05
Epoch 1993/2000
1024/1024 - 0s - loss: 4.9695e-07 - val_loss: 2.3643e-05
Epoch 1994/2000
1024/1024 - 0s - loss: 4.9424e-07 - val_loss: 2.3128e-05
Epoch 1995/2000
1024/1024 - 0s - loss: 4.9143e-07 - val_loss: 2.3617e-05
Epoch 1996/2000
1024/1024 - 0s - loss: 4.8880e-07 - val_loss: 2.3018e-05
Epoch 1997/2000
1024/1024 - 0s - loss: 4.8616e-07 - val_loss: 2.3176e-05
Epoch 1998/2000
1024/1024 - 0s - loss: 4.8353e-07 - val_loss: 2.3425e-05
Epoch 1999/2000
1024/1024 - 0s - loss: 4.8089e-07 - val_loss: 2.2890e-05
Epoch 2000/2000
1024/1024 - 0s - loss: 4.7855e-07 - val_loss: 2.2796e-05
2024-04-04 18:15:16.933796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
Train on 1024 samples, validate on 1024 samples
Epoch 1/1000

Epoch 00001: val_loss improved from inf to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.2920e-08 - val_loss: 2.1928e-08
Epoch 2/1000

Epoch 00002: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1706e-08 - val_loss: 2.1601e-08
Epoch 3/1000

Epoch 00003: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1426e-08 - val_loss: 2.1261e-08
Epoch 4/1000

Epoch 00004: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1110e-08 - val_loss: 2.0983e-08
Epoch 5/1000

Epoch 00005: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0837e-08 - val_loss: 2.0716e-08
Epoch 6/1000

Epoch 00006: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0567e-08 - val_loss: 2.0454e-08
Epoch 7/1000

Epoch 00007: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0309e-08 - val_loss: 2.0193e-08
Epoch 8/1000

Epoch 00008: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0053e-08 - val_loss: 1.9938e-08
Epoch 9/1000

Epoch 00009: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9803e-08 - val_loss: 1.9687e-08
Epoch 10/1000

Epoch 00010: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9557e-08 - val_loss: 1.9452e-08
Epoch 11/1000

Epoch 00011: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9322e-08 - val_loss: 1.9210e-08
Epoch 12/1000

Epoch 00012: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9084e-08 - val_loss: 1.8982e-08
Epoch 13/1000

Epoch 00013: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8859e-08 - val_loss: 1.8750e-08
Epoch 14/1000

Epoch 00014: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8635e-08 - val_loss: 1.8533e-08
Epoch 15/1000

Epoch 00015: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8411e-08 - val_loss: 1.8320e-08
Epoch 16/1000

Epoch 00016: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8199e-08 - val_loss: 1.8105e-08
Epoch 17/1000

Epoch 00017: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7991e-08 - val_loss: 1.7890e-08
Epoch 18/1000

Epoch 00018: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7782e-08 - val_loss: 1.7690e-08
Epoch 19/1000

Epoch 00019: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7580e-08 - val_loss: 1.7488e-08
Epoch 20/1000

Epoch 00020: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7381e-08 - val_loss: 1.7290e-08
Epoch 21/1000

Epoch 00021: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7188e-08 - val_loss: 1.7103e-08
Epoch 22/1000

Epoch 00022: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6996e-08 - val_loss: 1.6909e-08
Epoch 23/1000

Epoch 00023: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6809e-08 - val_loss: 1.6721e-08
Epoch 24/1000

Epoch 00024: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6623e-08 - val_loss: 1.6546e-08
Epoch 25/1000

Epoch 00025: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6444e-08 - val_loss: 1.6367e-08
Epoch 26/1000

Epoch 00026: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6268e-08 - val_loss: 1.6188e-08
Epoch 27/1000

Epoch 00027: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6095e-08 - val_loss: 1.6016e-08
Epoch 28/1000

Epoch 00028: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5922e-08 - val_loss: 1.5845e-08
Epoch 29/1000

Epoch 00029: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5753e-08 - val_loss: 1.5676e-08
Epoch 30/1000

Epoch 00030: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5589e-08 - val_loss: 1.5515e-08
Epoch 31/1000

Epoch 00031: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5427e-08 - val_loss: 1.5353e-08
Epoch 32/1000

Epoch 00032: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5265e-08 - val_loss: 1.5200e-08
Epoch 33/1000

Epoch 00033: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5111e-08 - val_loss: 1.5038e-08
Epoch 34/1000

Epoch 00034: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4954e-08 - val_loss: 1.4880e-08
Epoch 35/1000

Epoch 00035: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4800e-08 - val_loss: 1.4739e-08
Epoch 36/1000

Epoch 00036: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4653e-08 - val_loss: 1.4581e-08
Epoch 37/1000

Epoch 00037: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4505e-08 - val_loss: 1.4441e-08
Epoch 38/1000

Epoch 00038: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4358e-08 - val_loss: 1.4296e-08
Epoch 39/1000

Epoch 00039: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4218e-08 - val_loss: 1.4158e-08
Epoch 40/1000

Epoch 00040: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4076e-08 - val_loss: 1.4013e-08
Epoch 41/1000

Epoch 00041: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3937e-08 - val_loss: 1.3874e-08
Epoch 42/1000

Epoch 00042: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3800e-08 - val_loss: 1.3743e-08
Epoch 43/1000

Epoch 00043: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3668e-08 - val_loss: 1.3601e-08
Epoch 44/1000

Epoch 00044: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3532e-08 - val_loss: 1.3479e-08
Epoch 45/1000

Epoch 00045: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3404e-08 - val_loss: 1.3342e-08
Epoch 46/1000

Epoch 00046: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3273e-08 - val_loss: 1.3220e-08
Epoch 47/1000

Epoch 00047: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3148e-08 - val_loss: 1.3091e-08
Epoch 48/1000

Epoch 00048: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3021e-08 - val_loss: 1.2969e-08
Epoch 49/1000

Epoch 00049: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2900e-08 - val_loss: 1.2843e-08
Epoch 50/1000

Epoch 00050: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2777e-08 - val_loss: 1.2724e-08
Epoch 51/1000

Epoch 00051: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2658e-08 - val_loss: 1.2600e-08
Epoch 52/1000

Epoch 00052: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2539e-08 - val_loss: 1.2488e-08
Epoch 53/1000

Epoch 00053: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2423e-08 - val_loss: 1.2367e-08
Epoch 54/1000

Epoch 00054: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2307e-08 - val_loss: 1.2256e-08
Epoch 55/1000

Epoch 00055: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2193e-08 - val_loss: 1.2146e-08
Epoch 56/1000

Epoch 00056: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2081e-08 - val_loss: 1.2033e-08
Epoch 57/1000

Epoch 00057: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1972e-08 - val_loss: 1.1925e-08
Epoch 58/1000

Epoch 00058: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1860e-08 - val_loss: 1.1812e-08
Epoch 59/1000

Epoch 00059: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1755e-08 - val_loss: 1.1708e-08
Epoch 60/1000

Epoch 00060: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1648e-08 - val_loss: 1.1596e-08
Epoch 61/1000

Epoch 00061: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1540e-08 - val_loss: 1.1497e-08
Epoch 62/1000

Epoch 00062: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1439e-08 - val_loss: 1.1390e-08
Epoch 63/1000

Epoch 00063: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1335e-08 - val_loss: 1.1290e-08
Epoch 64/1000

Epoch 00064: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1234e-08 - val_loss: 1.1196e-08
Epoch 65/1000

Epoch 00065: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1136e-08 - val_loss: 1.1093e-08
Epoch 66/1000

Epoch 00066: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1038e-08 - val_loss: 1.0997e-08
Epoch 67/1000

Epoch 00067: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0940e-08 - val_loss: 1.0899e-08
Epoch 68/1000

Epoch 00068: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0844e-08 - val_loss: 1.0802e-08
Epoch 69/1000

Epoch 00069: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0750e-08 - val_loss: 1.0709e-08
Epoch 70/1000

Epoch 00070: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0654e-08 - val_loss: 1.0613e-08
Epoch 71/1000

Epoch 00071: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0563e-08 - val_loss: 1.0522e-08
Epoch 72/1000

Epoch 00072: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0470e-08 - val_loss: 1.0431e-08
Epoch 73/1000

Epoch 00073: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0379e-08 - val_loss: 1.0337e-08
Epoch 74/1000

Epoch 00074: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0289e-08 - val_loss: 1.0254e-08
Epoch 75/1000

Epoch 00075: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0201e-08 - val_loss: 1.0169e-08
Epoch 76/1000

Epoch 00076: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0114e-08 - val_loss: 1.0074e-08
Epoch 77/1000

Epoch 00077: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0028e-08 - val_loss: 9.9918e-09
Epoch 78/1000

Epoch 00078: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.9429e-09 - val_loss: 9.9072e-09
Epoch 79/1000

Epoch 00079: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.8592e-09 - val_loss: 9.8189e-09
Epoch 80/1000

Epoch 00080: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.7755e-09 - val_loss: 9.7413e-09
Epoch 81/1000

Epoch 00081: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.6933e-09 - val_loss: 9.6594e-09
Epoch 82/1000

Epoch 00082: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.6115e-09 - val_loss: 9.5758e-09
Epoch 83/1000

Epoch 00083: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.5322e-09 - val_loss: 9.5002e-09
Epoch 84/1000

Epoch 00084: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.4537e-09 - val_loss: 9.4199e-09
Epoch 85/1000

Epoch 00085: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.3742e-09 - val_loss: 9.3367e-09
Epoch 86/1000

Epoch 00086: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.2965e-09 - val_loss: 9.2620e-09
Epoch 87/1000

Epoch 00087: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.2200e-09 - val_loss: 9.1863e-09
Epoch 88/1000

Epoch 00088: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.1468e-09 - val_loss: 9.1115e-09
Epoch 89/1000

Epoch 00089: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.0695e-09 - val_loss: 9.0366e-09
Epoch 90/1000

Epoch 00090: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.9967e-09 - val_loss: 8.9637e-09
Epoch 91/1000

Epoch 00091: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.9239e-09 - val_loss: 8.8917e-09
Epoch 92/1000

Epoch 00092: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.8522e-09 - val_loss: 8.8220e-09
Epoch 93/1000

Epoch 00093: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.7807e-09 - val_loss: 8.7468e-09
Epoch 94/1000

Epoch 00094: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.7097e-09 - val_loss: 8.6809e-09
Epoch 95/1000

Epoch 00095: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.6409e-09 - val_loss: 8.6155e-09
Epoch 96/1000

Epoch 00096: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.5727e-09 - val_loss: 8.5448e-09
Epoch 97/1000

Epoch 00097: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.5050e-09 - val_loss: 8.4714e-09
Epoch 98/1000

Epoch 00098: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.4361e-09 - val_loss: 8.4081e-09
Epoch 99/1000

Epoch 00099: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.3704e-09 - val_loss: 8.3428e-09
Epoch 100/1000

Epoch 00100: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.3057e-09 - val_loss: 8.2769e-09
Epoch 101/1000

Epoch 00101: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.2397e-09 - val_loss: 8.2147e-09
Epoch 102/1000

Epoch 00102: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.1761e-09 - val_loss: 8.1466e-09
Epoch 103/1000

Epoch 00103: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.1114e-09 - val_loss: 8.0851e-09
Epoch 104/1000

Epoch 00104: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.0493e-09 - val_loss: 8.0259e-09
Epoch 105/1000

Epoch 00105: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.9869e-09 - val_loss: 7.9620e-09
Epoch 106/1000

Epoch 00106: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.9265e-09 - val_loss: 7.9002e-09
Epoch 107/1000

Epoch 00107: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.8648e-09 - val_loss: 7.8381e-09
Epoch 108/1000

Epoch 00108: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.8044e-09 - val_loss: 7.7781e-09
Epoch 109/1000

Epoch 00109: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.7455e-09 - val_loss: 7.7208e-09
Epoch 110/1000

Epoch 00110: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.6861e-09 - val_loss: 7.6637e-09
Epoch 111/1000

Epoch 00111: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.6279e-09 - val_loss: 7.6055e-09
Epoch 112/1000

Epoch 00112: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.5707e-09 - val_loss: 7.5464e-09
Epoch 113/1000

Epoch 00113: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.5133e-09 - val_loss: 7.4880e-09
Epoch 114/1000

Epoch 00114: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.4566e-09 - val_loss: 7.4308e-09
Epoch 115/1000

Epoch 00115: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.4008e-09 - val_loss: 7.3763e-09
Epoch 116/1000

Epoch 00116: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.3455e-09 - val_loss: 7.3230e-09
Epoch 117/1000

Epoch 00117: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.2905e-09 - val_loss: 7.2707e-09
Epoch 118/1000

Epoch 00118: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.2369e-09 - val_loss: 7.2155e-09
Epoch 119/1000

Epoch 00119: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.1830e-09 - val_loss: 7.1607e-09
Epoch 120/1000

Epoch 00120: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.1291e-09 - val_loss: 7.1055e-09
Epoch 121/1000

Epoch 00121: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.0763e-09 - val_loss: 7.0530e-09
Epoch 122/1000

Epoch 00122: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.0236e-09 - val_loss: 7.0004e-09
Epoch 123/1000

Epoch 00123: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.9722e-09 - val_loss: 6.9521e-09
Epoch 124/1000

Epoch 00124: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.9209e-09 - val_loss: 6.9001e-09
Epoch 125/1000

Epoch 00125: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.8699e-09 - val_loss: 6.8484e-09
Epoch 126/1000

Epoch 00126: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.8194e-09 - val_loss: 6.8004e-09
Epoch 127/1000

Epoch 00127: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.7695e-09 - val_loss: 6.7491e-09
Epoch 128/1000

Epoch 00128: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.7200e-09 - val_loss: 6.6990e-09
Epoch 129/1000

Epoch 00129: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.6711e-09 - val_loss: 6.6555e-09
Epoch 130/1000

Epoch 00130: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.6219e-09 - val_loss: 6.6012e-09
Epoch 131/1000

Epoch 00131: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.5740e-09 - val_loss: 6.5524e-09
Epoch 132/1000

Epoch 00132: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.5262e-09 - val_loss: 6.5044e-09
Epoch 133/1000

Epoch 00133: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.4784e-09 - val_loss: 6.4578e-09
Epoch 134/1000

Epoch 00134: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.4313e-09 - val_loss: 6.4120e-09
Epoch 135/1000

Epoch 00135: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.3852e-09 - val_loss: 6.3644e-09
Epoch 136/1000

Epoch 00136: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.3390e-09 - val_loss: 6.3211e-09
Epoch 137/1000

Epoch 00137: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.2936e-09 - val_loss: 6.2762e-09
Epoch 138/1000

Epoch 00138: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.2481e-09 - val_loss: 6.2301e-09
Epoch 139/1000

Epoch 00139: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.2035e-09 - val_loss: 6.1855e-09
Epoch 140/1000

Epoch 00140: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.1580e-09 - val_loss: 6.1402e-09
Epoch 141/1000

Epoch 00141: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.1136e-09 - val_loss: 6.0967e-09
Epoch 142/1000

Epoch 00142: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.0702e-09 - val_loss: 6.0533e-09
Epoch 143/1000

Epoch 00143: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.0263e-09 - val_loss: 6.0107e-09
Epoch 144/1000

Epoch 00144: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.9831e-09 - val_loss: 5.9661e-09
Epoch 145/1000

Epoch 00145: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.9405e-09 - val_loss: 5.9233e-09
Epoch 146/1000

Epoch 00146: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.8980e-09 - val_loss: 5.8780e-09
Epoch 147/1000

Epoch 00147: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.8561e-09 - val_loss: 5.8364e-09
Epoch 148/1000

Epoch 00148: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.8140e-09 - val_loss: 5.7934e-09
Epoch 149/1000

Epoch 00149: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.7722e-09 - val_loss: 5.7539e-09
Epoch 150/1000

Epoch 00150: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.7313e-09 - val_loss: 5.7134e-09
Epoch 151/1000

Epoch 00151: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.6907e-09 - val_loss: 5.6719e-09
Epoch 152/1000

Epoch 00152: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.6501e-09 - val_loss: 5.6319e-09
Epoch 153/1000

Epoch 00153: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.6096e-09 - val_loss: 5.5927e-09
Epoch 154/1000

Epoch 00154: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.5702e-09 - val_loss: 5.5536e-09
Epoch 155/1000

Epoch 00155: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.5313e-09 - val_loss: 5.5119e-09
Epoch 156/1000

Epoch 00156: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.4917e-09 - val_loss: 5.4750e-09
Epoch 157/1000

Epoch 00157: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.4534e-09 - val_loss: 5.4338e-09
Epoch 158/1000

Epoch 00158: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.4142e-09 - val_loss: 5.3952e-09
Epoch 159/1000

Epoch 00159: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.3760e-09 - val_loss: 5.3585e-09
Epoch 160/1000

Epoch 00160: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.3377e-09 - val_loss: 5.3202e-09
Epoch 161/1000

Epoch 00161: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.2998e-09 - val_loss: 5.2829e-09
Epoch 162/1000

Epoch 00162: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.2629e-09 - val_loss: 5.2447e-09
Epoch 163/1000

Epoch 00163: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.2256e-09 - val_loss: 5.2098e-09
Epoch 164/1000

Epoch 00164: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.1888e-09 - val_loss: 5.1731e-09
Epoch 165/1000

Epoch 00165: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.1529e-09 - val_loss: 5.1342e-09
Epoch 166/1000

Epoch 00166: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.1164e-09 - val_loss: 5.1004e-09
Epoch 167/1000

Epoch 00167: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.0803e-09 - val_loss: 5.0641e-09
Epoch 168/1000

Epoch 00168: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.0439e-09 - val_loss: 5.0312e-09
Epoch 169/1000

Epoch 00169: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.0089e-09 - val_loss: 4.9959e-09
Epoch 170/1000

Epoch 00170: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.9738e-09 - val_loss: 4.9616e-09
Epoch 171/1000

Epoch 00171: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.9389e-09 - val_loss: 4.9246e-09
Epoch 172/1000

Epoch 00172: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.9041e-09 - val_loss: 4.8913e-09
Epoch 173/1000

Epoch 00173: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.8705e-09 - val_loss: 4.8577e-09
Epoch 174/1000

Epoch 00174: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.8362e-09 - val_loss: 4.8217e-09
Epoch 175/1000

Epoch 00175: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.8022e-09 - val_loss: 4.7886e-09
Epoch 176/1000

Epoch 00176: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.7688e-09 - val_loss: 4.7541e-09
Epoch 177/1000

Epoch 00177: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.7352e-09 - val_loss: 4.7218e-09
Epoch 178/1000

Epoch 00178: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.7022e-09 - val_loss: 4.6877e-09
Epoch 179/1000

Epoch 00179: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.6699e-09 - val_loss: 4.6551e-09
Epoch 180/1000

Epoch 00180: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.6371e-09 - val_loss: 4.6232e-09
Epoch 181/1000

Epoch 00181: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.6048e-09 - val_loss: 4.5893e-09
Epoch 182/1000

Epoch 00182: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.5725e-09 - val_loss: 4.5571e-09
Epoch 183/1000

Epoch 00183: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.5411e-09 - val_loss: 4.5269e-09
Epoch 184/1000

Epoch 00184: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.5093e-09 - val_loss: 4.4949e-09
Epoch 185/1000

Epoch 00185: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.4777e-09 - val_loss: 4.4662e-09
Epoch 186/1000

Epoch 00186: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.4463e-09 - val_loss: 4.4333e-09
Epoch 187/1000

Epoch 00187: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.4155e-09 - val_loss: 4.4036e-09
Epoch 188/1000

Epoch 00188: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.3850e-09 - val_loss: 4.3729e-09
Epoch 189/1000

Epoch 00189: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.3544e-09 - val_loss: 4.3409e-09
Epoch 190/1000

Epoch 00190: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.3246e-09 - val_loss: 4.3109e-09
Epoch 191/1000

Epoch 00191: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.2940e-09 - val_loss: 4.2816e-09
Epoch 192/1000

Epoch 00192: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.2644e-09 - val_loss: 4.2510e-09
Epoch 193/1000

Epoch 00193: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.2350e-09 - val_loss: 4.2226e-09
Epoch 194/1000

Epoch 00194: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.2057e-09 - val_loss: 4.1924e-09
Epoch 195/1000

Epoch 00195: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.1762e-09 - val_loss: 4.1641e-09
Epoch 196/1000

Epoch 00196: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.1467e-09 - val_loss: 4.1373e-09
Epoch 197/1000

Epoch 00197: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.1183e-09 - val_loss: 4.1078e-09
Epoch 198/1000

Epoch 00198: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.0901e-09 - val_loss: 4.0780e-09
Epoch 199/1000

Epoch 00199: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.0619e-09 - val_loss: 4.0503e-09
Epoch 200/1000

Epoch 00200: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.0337e-09 - val_loss: 4.0221e-09
Epoch 201/1000

Epoch 00201: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.0064e-09 - val_loss: 3.9916e-09
Epoch 202/1000

Epoch 00202: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.9785e-09 - val_loss: 3.9644e-09
Epoch 203/1000

Epoch 00203: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.9503e-09 - val_loss: 3.9405e-09
Epoch 204/1000

Epoch 00204: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.9229e-09 - val_loss: 3.9121e-09
Epoch 205/1000

Epoch 00205: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.8958e-09 - val_loss: 3.8850e-09
Epoch 206/1000

Epoch 00206: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.8691e-09 - val_loss: 3.8586e-09
Epoch 207/1000

Epoch 00207: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.8423e-09 - val_loss: 3.8311e-09
Epoch 208/1000

Epoch 00208: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.8161e-09 - val_loss: 3.8036e-09
Epoch 209/1000

Epoch 00209: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.7900e-09 - val_loss: 3.7757e-09
Epoch 210/1000

Epoch 00210: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.7632e-09 - val_loss: 3.7530e-09
Epoch 211/1000

Epoch 00211: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.7372e-09 - val_loss: 3.7276e-09
Epoch 212/1000

Epoch 00212: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.7120e-09 - val_loss: 3.7013e-09
Epoch 213/1000

Epoch 00213: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.6861e-09 - val_loss: 3.6743e-09
Epoch 214/1000

Epoch 00214: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.6609e-09 - val_loss: 3.6506e-09
Epoch 215/1000

Epoch 00215: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.6356e-09 - val_loss: 3.6244e-09
Epoch 216/1000

Epoch 00216: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.6108e-09 - val_loss: 3.5995e-09
Epoch 217/1000

Epoch 00217: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.5855e-09 - val_loss: 3.5760e-09
Epoch 218/1000

Epoch 00218: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.5609e-09 - val_loss: 3.5495e-09
Epoch 219/1000

Epoch 00219: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.5362e-09 - val_loss: 3.5250e-09
Epoch 220/1000

Epoch 00220: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.5126e-09 - val_loss: 3.5007e-09
Epoch 221/1000

Epoch 00221: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.4879e-09 - val_loss: 3.4762e-09
Epoch 222/1000

Epoch 00222: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.4637e-09 - val_loss: 3.4545e-09
Epoch 223/1000

Epoch 00223: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.4399e-09 - val_loss: 3.4300e-09
Epoch 224/1000

Epoch 00224: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.4162e-09 - val_loss: 3.4059e-09
Epoch 225/1000

Epoch 00225: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.3931e-09 - val_loss: 3.3836e-09
Epoch 226/1000

Epoch 00226: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.3701e-09 - val_loss: 3.3586e-09
Epoch 227/1000

Epoch 00227: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.3465e-09 - val_loss: 3.3378e-09
Epoch 228/1000

Epoch 00228: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.3233e-09 - val_loss: 3.3146e-09
Epoch 229/1000

Epoch 00229: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.3010e-09 - val_loss: 3.2915e-09
Epoch 230/1000

Epoch 00230: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.2780e-09 - val_loss: 3.2674e-09
Epoch 231/1000

Epoch 00231: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.2560e-09 - val_loss: 3.2457e-09
Epoch 232/1000

Epoch 00232: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.2329e-09 - val_loss: 3.2238e-09
Epoch 233/1000

Epoch 00233: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.2107e-09 - val_loss: 3.2022e-09
Epoch 234/1000

Epoch 00234: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.1891e-09 - val_loss: 3.1784e-09
Epoch 235/1000

Epoch 00235: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.1674e-09 - val_loss: 3.1558e-09
Epoch 236/1000

Epoch 00236: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.1459e-09 - val_loss: 3.1374e-09
Epoch 237/1000

Epoch 00237: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.1236e-09 - val_loss: 3.1145e-09
Epoch 238/1000

Epoch 00238: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.1027e-09 - val_loss: 3.0926e-09
Epoch 239/1000

Epoch 00239: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.0812e-09 - val_loss: 3.0709e-09
Epoch 240/1000

Epoch 00240: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.0602e-09 - val_loss: 3.0499e-09
Epoch 241/1000

Epoch 00241: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.0386e-09 - val_loss: 3.0316e-09
Epoch 242/1000

Epoch 00242: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.0185e-09 - val_loss: 3.0085e-09
Epoch 243/1000

Epoch 00243: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.9977e-09 - val_loss: 2.9887e-09
Epoch 244/1000

Epoch 00244: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.9773e-09 - val_loss: 2.9661e-09
Epoch 245/1000

Epoch 00245: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.9565e-09 - val_loss: 2.9482e-09
Epoch 246/1000

Epoch 00246: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.9361e-09 - val_loss: 2.9270e-09
Epoch 247/1000

Epoch 00247: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.9166e-09 - val_loss: 2.9071e-09
Epoch 248/1000

Epoch 00248: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.8966e-09 - val_loss: 2.8855e-09
Epoch 249/1000

Epoch 00249: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.8765e-09 - val_loss: 2.8669e-09
Epoch 250/1000

Epoch 00250: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.8568e-09 - val_loss: 2.8485e-09
Epoch 251/1000

Epoch 00251: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.8374e-09 - val_loss: 2.8277e-09
Epoch 252/1000

Epoch 00252: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.8183e-09 - val_loss: 2.8081e-09
Epoch 253/1000

Epoch 00253: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.7982e-09 - val_loss: 2.7897e-09
Epoch 254/1000

Epoch 00254: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.7794e-09 - val_loss: 2.7707e-09
Epoch 255/1000

Epoch 00255: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.7608e-09 - val_loss: 2.7503e-09
Epoch 256/1000

Epoch 00256: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.7418e-09 - val_loss: 2.7350e-09
Epoch 257/1000

Epoch 00257: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.7226e-09 - val_loss: 2.7152e-09
Epoch 258/1000

Epoch 00258: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.7045e-09 - val_loss: 2.6965e-09
Epoch 259/1000

Epoch 00259: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.6863e-09 - val_loss: 2.6758e-09
Epoch 260/1000

Epoch 00260: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.6673e-09 - val_loss: 2.6600e-09
Epoch 261/1000

Epoch 00261: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.6493e-09 - val_loss: 2.6423e-09
Epoch 262/1000

Epoch 00262: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.6314e-09 - val_loss: 2.6233e-09
Epoch 263/1000

Epoch 00263: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.6134e-09 - val_loss: 2.6067e-09
Epoch 264/1000

Epoch 00264: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.5955e-09 - val_loss: 2.5878e-09
Epoch 265/1000

Epoch 00265: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.5780e-09 - val_loss: 2.5685e-09
Epoch 266/1000

Epoch 00266: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.5606e-09 - val_loss: 2.5544e-09
Epoch 267/1000

Epoch 00267: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.5423e-09 - val_loss: 2.5352e-09
Epoch 268/1000

Epoch 00268: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.5254e-09 - val_loss: 2.5177e-09
Epoch 269/1000

Epoch 00269: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.5086e-09 - val_loss: 2.4982e-09
Epoch 270/1000

Epoch 00270: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.4909e-09 - val_loss: 2.4847e-09
Epoch 271/1000

Epoch 00271: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.4739e-09 - val_loss: 2.4659e-09
Epoch 272/1000

Epoch 00272: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.4581e-09 - val_loss: 2.4492e-09
Epoch 273/1000

Epoch 00273: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.4406e-09 - val_loss: 2.4321e-09
Epoch 274/1000

Epoch 00274: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.4239e-09 - val_loss: 2.4166e-09
Epoch 275/1000

Epoch 00275: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.4079e-09 - val_loss: 2.3975e-09
Epoch 276/1000

Epoch 00276: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.3909e-09 - val_loss: 2.3835e-09
Epoch 277/1000

Epoch 00277: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.3747e-09 - val_loss: 2.3683e-09
Epoch 278/1000

Epoch 00278: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.3591e-09 - val_loss: 2.3502e-09
Epoch 279/1000

Epoch 00279: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.3424e-09 - val_loss: 2.3363e-09
Epoch 280/1000

Epoch 00280: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.3267e-09 - val_loss: 2.3198e-09
Epoch 281/1000

Epoch 00281: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.3110e-09 - val_loss: 2.3031e-09
Epoch 282/1000

Epoch 00282: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.2952e-09 - val_loss: 2.2884e-09
Epoch 283/1000

Epoch 00283: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.2795e-09 - val_loss: 2.2718e-09
Epoch 284/1000

Epoch 00284: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.2645e-09 - val_loss: 2.2564e-09
Epoch 285/1000

Epoch 00285: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.2483e-09 - val_loss: 2.2415e-09
Epoch 286/1000

Epoch 00286: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.2334e-09 - val_loss: 2.2255e-09
Epoch 287/1000

Epoch 00287: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.2191e-09 - val_loss: 2.2089e-09
Epoch 288/1000

Epoch 00288: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.2026e-09 - val_loss: 2.1960e-09
Epoch 289/1000

Epoch 00289: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1884e-09 - val_loss: 2.1826e-09
Epoch 290/1000

Epoch 00290: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1739e-09 - val_loss: 2.1674e-09
Epoch 291/1000

Epoch 00291: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1584e-09 - val_loss: 2.1517e-09
Epoch 292/1000

Epoch 00292: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1444e-09 - val_loss: 2.1377e-09
Epoch 293/1000

Epoch 00293: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1296e-09 - val_loss: 2.1236e-09
Epoch 294/1000

Epoch 00294: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1152e-09 - val_loss: 2.1076e-09
Epoch 295/1000

Epoch 00295: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1011e-09 - val_loss: 2.0924e-09
Epoch 296/1000

Epoch 00296: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0865e-09 - val_loss: 2.0806e-09
Epoch 297/1000

Epoch 00297: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0725e-09 - val_loss: 2.0664e-09
Epoch 298/1000

Epoch 00298: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0588e-09 - val_loss: 2.0521e-09
Epoch 299/1000

Epoch 00299: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0443e-09 - val_loss: 2.0367e-09
Epoch 300/1000

Epoch 00300: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0309e-09 - val_loss: 2.0232e-09
Epoch 301/1000

Epoch 00301: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0170e-09 - val_loss: 2.0099e-09
Epoch 302/1000

Epoch 00302: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0030e-09 - val_loss: 1.9971e-09
Epoch 303/1000

Epoch 00303: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9901e-09 - val_loss: 1.9821e-09
Epoch 304/1000

Epoch 00304: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9761e-09 - val_loss: 1.9697e-09
Epoch 305/1000

Epoch 00305: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9630e-09 - val_loss: 1.9562e-09
Epoch 306/1000

Epoch 00306: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9502e-09 - val_loss: 1.9435e-09
Epoch 307/1000

Epoch 00307: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9367e-09 - val_loss: 1.9305e-09
Epoch 308/1000

Epoch 00308: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9238e-09 - val_loss: 1.9175e-09
Epoch 309/1000

Epoch 00309: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9099e-09 - val_loss: 1.9048e-09
Epoch 310/1000

Epoch 00310: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8980e-09 - val_loss: 1.8906e-09
Epoch 311/1000

Epoch 00311: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8849e-09 - val_loss: 1.8800e-09
Epoch 312/1000

Epoch 00312: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8720e-09 - val_loss: 1.8654e-09
Epoch 313/1000

Epoch 00313: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8599e-09 - val_loss: 1.8547e-09
Epoch 314/1000

Epoch 00314: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8467e-09 - val_loss: 1.8411e-09
Epoch 315/1000

Epoch 00315: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8351e-09 - val_loss: 1.8275e-09
Epoch 316/1000

Epoch 00316: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8218e-09 - val_loss: 1.8167e-09
Epoch 317/1000

Epoch 00317: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8101e-09 - val_loss: 1.8034e-09
Epoch 318/1000

Epoch 00318: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7980e-09 - val_loss: 1.7923e-09
Epoch 319/1000

Epoch 00319: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7854e-09 - val_loss: 1.7793e-09
Epoch 320/1000

Epoch 00320: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7737e-09 - val_loss: 1.7686e-09
Epoch 321/1000

Epoch 00321: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7615e-09 - val_loss: 1.7564e-09
Epoch 322/1000

Epoch 00322: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7503e-09 - val_loss: 1.7431e-09
Epoch 323/1000

Epoch 00323: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7377e-09 - val_loss: 1.7322e-09
Epoch 324/1000

Epoch 00324: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7267e-09 - val_loss: 1.7186e-09
Epoch 325/1000

Epoch 00325: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7146e-09 - val_loss: 1.7092e-09
Epoch 326/1000

Epoch 00326: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7035e-09 - val_loss: 1.6984e-09
Epoch 327/1000

Epoch 00327: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6922e-09 - val_loss: 1.6874e-09
Epoch 328/1000

Epoch 00328: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6805e-09 - val_loss: 1.6746e-09
Epoch 329/1000

Epoch 00329: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6696e-09 - val_loss: 1.6644e-09
Epoch 330/1000

Epoch 00330: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6579e-09 - val_loss: 1.6526e-09
Epoch 331/1000

Epoch 00331: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6476e-09 - val_loss: 1.6419e-09
Epoch 332/1000

Epoch 00332: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6355e-09 - val_loss: 1.6312e-09
Epoch 333/1000

Epoch 00333: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6257e-09 - val_loss: 1.6184e-09
Epoch 334/1000

Epoch 00334: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6136e-09 - val_loss: 1.6080e-09
Epoch 335/1000

Epoch 00335: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6035e-09 - val_loss: 1.5974e-09
Epoch 336/1000

Epoch 00336: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5924e-09 - val_loss: 1.5873e-09
Epoch 337/1000

Epoch 00337: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5825e-09 - val_loss: 1.5764e-09
Epoch 338/1000

Epoch 00338: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5713e-09 - val_loss: 1.5667e-09
Epoch 339/1000

Epoch 00339: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5610e-09 - val_loss: 1.5557e-09
Epoch 340/1000

Epoch 00340: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5506e-09 - val_loss: 1.5472e-09
Epoch 341/1000

Epoch 00341: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5402e-09 - val_loss: 1.5339e-09
Epoch 342/1000

Epoch 00342: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5299e-09 - val_loss: 1.5260e-09
Epoch 343/1000

Epoch 00343: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5194e-09 - val_loss: 1.5142e-09
Epoch 344/1000

Epoch 00344: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5098e-09 - val_loss: 1.5046e-09
Epoch 345/1000

Epoch 00345: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4996e-09 - val_loss: 1.4945e-09
Epoch 346/1000

Epoch 00346: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4899e-09 - val_loss: 1.4852e-09
Epoch 347/1000

Epoch 00347: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4792e-09 - val_loss: 1.4748e-09
Epoch 348/1000

Epoch 00348: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4699e-09 - val_loss: 1.4658e-09
Epoch 349/1000

Epoch 00349: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4601e-09 - val_loss: 1.4562e-09
Epoch 350/1000

Epoch 00350: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4506e-09 - val_loss: 1.4467e-09
Epoch 351/1000

Epoch 00351: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4407e-09 - val_loss: 1.4352e-09
Epoch 352/1000

Epoch 00352: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4314e-09 - val_loss: 1.4272e-09
Epoch 353/1000

Epoch 00353: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4219e-09 - val_loss: 1.4157e-09
Epoch 354/1000

Epoch 00354: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4124e-09 - val_loss: 1.4082e-09
Epoch 355/1000

Epoch 00355: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4031e-09 - val_loss: 1.3978e-09
Epoch 356/1000

Epoch 00356: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3937e-09 - val_loss: 1.3890e-09
Epoch 357/1000

Epoch 00357: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3844e-09 - val_loss: 1.3789e-09
Epoch 358/1000

Epoch 00358: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3754e-09 - val_loss: 1.3713e-09
Epoch 359/1000

Epoch 00359: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3663e-09 - val_loss: 1.3606e-09
Epoch 360/1000

Epoch 00360: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3572e-09 - val_loss: 1.3525e-09
Epoch 361/1000

Epoch 00361: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3485e-09 - val_loss: 1.3430e-09
Epoch 362/1000

Epoch 00362: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3390e-09 - val_loss: 1.3353e-09
Epoch 363/1000

Epoch 00363: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3307e-09 - val_loss: 1.3251e-09
Epoch 364/1000

Epoch 00364: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3215e-09 - val_loss: 1.3168e-09
Epoch 365/1000

Epoch 00365: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3133e-09 - val_loss: 1.3083e-09
Epoch 366/1000

Epoch 00366: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3042e-09 - val_loss: 1.2998e-09
Epoch 367/1000

Epoch 00367: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2962e-09 - val_loss: 1.2900e-09
Epoch 368/1000

Epoch 00368: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2866e-09 - val_loss: 1.2818e-09
Epoch 369/1000

Epoch 00369: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2790e-09 - val_loss: 1.2750e-09
Epoch 370/1000

Epoch 00370: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2701e-09 - val_loss: 1.2663e-09
Epoch 371/1000

Epoch 00371: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2623e-09 - val_loss: 1.2573e-09
Epoch 372/1000

Epoch 00372: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2535e-09 - val_loss: 1.2487e-09
Epoch 373/1000

Epoch 00373: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2456e-09 - val_loss: 1.2410e-09
Epoch 374/1000

Epoch 00374: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2373e-09 - val_loss: 1.2337e-09
Epoch 375/1000

Epoch 00375: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2291e-09 - val_loss: 1.2252e-09
Epoch 376/1000

Epoch 00376: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2212e-09 - val_loss: 1.2166e-09
Epoch 377/1000

Epoch 00377: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2129e-09 - val_loss: 1.2091e-09
Epoch 378/1000

Epoch 00378: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2056e-09 - val_loss: 1.2021e-09
Epoch 379/1000

Epoch 00379: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1973e-09 - val_loss: 1.1931e-09
Epoch 380/1000

Epoch 00380: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1897e-09 - val_loss: 1.1856e-09
Epoch 381/1000

Epoch 00381: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1816e-09 - val_loss: 1.1764e-09
Epoch 382/1000

Epoch 00382: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1739e-09 - val_loss: 1.1699e-09
Epoch 383/1000

Epoch 00383: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1667e-09 - val_loss: 1.1615e-09
Epoch 384/1000

Epoch 00384: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1588e-09 - val_loss: 1.1538e-09
Epoch 385/1000

Epoch 00385: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1517e-09 - val_loss: 1.1470e-09
Epoch 386/1000

Epoch 00386: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1432e-09 - val_loss: 1.1395e-09
Epoch 387/1000

Epoch 00387: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1364e-09 - val_loss: 1.1326e-09
Epoch 388/1000

Epoch 00388: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1287e-09 - val_loss: 1.1246e-09
Epoch 389/1000

Epoch 00389: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1217e-09 - val_loss: 1.1180e-09
Epoch 390/1000

Epoch 00390: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1146e-09 - val_loss: 1.1090e-09
Epoch 391/1000

Epoch 00391: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1069e-09 - val_loss: 1.1026e-09
Epoch 392/1000

Epoch 00392: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1001e-09 - val_loss: 1.0974e-09
Epoch 393/1000

Epoch 00393: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0924e-09 - val_loss: 1.0888e-09
Epoch 394/1000

Epoch 00394: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0859e-09 - val_loss: 1.0820e-09
Epoch 395/1000

Epoch 00395: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0789e-09 - val_loss: 1.0743e-09
Epoch 396/1000

Epoch 00396: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0716e-09 - val_loss: 1.0680e-09
Epoch 397/1000

Epoch 00397: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0653e-09 - val_loss: 1.0614e-09
Epoch 398/1000

Epoch 00398: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0574e-09 - val_loss: 1.0541e-09
Epoch 399/1000

Epoch 00399: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0513e-09 - val_loss: 1.0482e-09
Epoch 400/1000

Epoch 00400: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0445e-09 - val_loss: 1.0403e-09
Epoch 401/1000

Epoch 00401: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0376e-09 - val_loss: 1.0344e-09
Epoch 402/1000

Epoch 00402: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0316e-09 - val_loss: 1.0262e-09
Epoch 403/1000

Epoch 00403: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0238e-09 - val_loss: 1.0203e-09
Epoch 404/1000

Epoch 00404: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0180e-09 - val_loss: 1.0141e-09
Epoch 405/1000

Epoch 00405: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0112e-09 - val_loss: 1.0067e-09
Epoch 406/1000

Epoch 00406: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0046e-09 - val_loss: 1.0019e-09
Epoch 407/1000

Epoch 00407: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.9869e-10 - val_loss: 9.9568e-10
Epoch 408/1000

Epoch 00408: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.9158e-10 - val_loss: 9.8834e-10
Epoch 409/1000

Epoch 00409: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.8567e-10 - val_loss: 9.8209e-10
Epoch 410/1000

Epoch 00410: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.7938e-10 - val_loss: 9.7539e-10
Epoch 411/1000

Epoch 00411: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.7281e-10 - val_loss: 9.6973e-10
Epoch 412/1000

Epoch 00412: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.6725e-10 - val_loss: 9.6415e-10
Epoch 413/1000

Epoch 00413: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.6053e-10 - val_loss: 9.5677e-10
Epoch 414/1000

Epoch 00414: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.5463e-10 - val_loss: 9.5146e-10
Epoch 415/1000

Epoch 00415: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.4904e-10 - val_loss: 9.4468e-10
Epoch 416/1000

Epoch 00416: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.4208e-10 - val_loss: 9.3963e-10
Epoch 417/1000

Epoch 00417: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.3684e-10 - val_loss: 9.3432e-10
Epoch 418/1000

Epoch 00418: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.3090e-10 - val_loss: 9.2643e-10
Epoch 419/1000

Epoch 00419: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.2450e-10 - val_loss: 9.2082e-10
Epoch 420/1000

Epoch 00420: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.1904e-10 - val_loss: 9.1653e-10
Epoch 421/1000

Epoch 00421: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.1291e-10 - val_loss: 9.0914e-10
Epoch 422/1000

Epoch 00422: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.0726e-10 - val_loss: 9.0329e-10
Epoch 423/1000

Epoch 00423: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.0179e-10 - val_loss: 8.9904e-10
Epoch 424/1000

Epoch 00424: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.9526e-10 - val_loss: 8.9189e-10
Epoch 425/1000

Epoch 00425: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.9032e-10 - val_loss: 8.8686e-10
Epoch 426/1000

Epoch 00426: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.8492e-10 - val_loss: 8.8036e-10
Epoch 427/1000

Epoch 00427: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.7857e-10 - val_loss: 8.7528e-10
Epoch 428/1000

Epoch 00428: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.7352e-10 - val_loss: 8.6966e-10
Epoch 429/1000

Epoch 00429: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.6790e-10 - val_loss: 8.6428e-10
Epoch 430/1000

Epoch 00430: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.6210e-10 - val_loss: 8.5859e-10
Epoch 431/1000

Epoch 00431: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.5744e-10 - val_loss: 8.5440e-10
Epoch 432/1000

Epoch 00432: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.5202e-10 - val_loss: 8.4858e-10
Epoch 433/1000

Epoch 00433: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.4654e-10 - val_loss: 8.4358e-10
Epoch 434/1000

Epoch 00434: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.4151e-10 - val_loss: 8.4015e-10
Epoch 435/1000

Epoch 00435: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.3609e-10 - val_loss: 8.3196e-10
Epoch 436/1000

Epoch 00436: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.3033e-10 - val_loss: 8.2789e-10
Epoch 437/1000

Epoch 00437: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.2553e-10 - val_loss: 8.2302e-10
Epoch 438/1000

Epoch 00438: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.2007e-10 - val_loss: 8.1720e-10
Epoch 439/1000

Epoch 00439: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.1507e-10 - val_loss: 8.1246e-10
Epoch 440/1000

Epoch 00440: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.1047e-10 - val_loss: 8.0788e-10
Epoch 441/1000

Epoch 00441: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 8.0526e-10 - val_loss: 8.0184e-10
Epoch 442/1000

Epoch 00442: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.9995e-10 - val_loss: 7.9696e-10
Epoch 443/1000

Epoch 00443: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.9532e-10 - val_loss: 7.9276e-10
Epoch 444/1000

Epoch 00444: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.8989e-10 - val_loss: 7.8617e-10
Epoch 445/1000

Epoch 00445: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.8512e-10 - val_loss: 7.8237e-10
Epoch 446/1000

Epoch 00446: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.8071e-10 - val_loss: 7.7796e-10
Epoch 447/1000

Epoch 00447: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.7569e-10 - val_loss: 7.7243e-10
Epoch 448/1000

Epoch 00448: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.7058e-10 - val_loss: 7.6742e-10
Epoch 449/1000

Epoch 00449: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.6627e-10 - val_loss: 7.6429e-10
Epoch 450/1000

Epoch 00450: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.6142e-10 - val_loss: 7.5825e-10
Epoch 451/1000

Epoch 00451: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.5642e-10 - val_loss: 7.5419e-10
Epoch 452/1000

Epoch 00452: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.5220e-10 - val_loss: 7.4948e-10
Epoch 453/1000

Epoch 00453: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.4756e-10 - val_loss: 7.4448e-10
Epoch 454/1000

Epoch 00454: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.4271e-10 - val_loss: 7.3996e-10
Epoch 455/1000

Epoch 00455: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.3843e-10 - val_loss: 7.3604e-10
Epoch 456/1000

Epoch 00456: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.3422e-10 - val_loss: 7.3001e-10
Epoch 457/1000

Epoch 00457: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.2902e-10 - val_loss: 7.2629e-10
Epoch 458/1000

Epoch 00458: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.2494e-10 - val_loss: 7.2184e-10
Epoch 459/1000

Epoch 00459: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.2091e-10 - val_loss: 7.1910e-10
Epoch 460/1000

Epoch 00460: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.1601e-10 - val_loss: 7.1284e-10
Epoch 461/1000

Epoch 00461: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.1156e-10 - val_loss: 7.0906e-10
Epoch 462/1000

Epoch 00462: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.0781e-10 - val_loss: 7.0489e-10
Epoch 463/1000

Epoch 00463: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 7.0296e-10 - val_loss: 6.9973e-10
Epoch 464/1000

Epoch 00464: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.9864e-10 - val_loss: 6.9577e-10
Epoch 465/1000

Epoch 00465: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.9475e-10 - val_loss: 6.9266e-10
Epoch 466/1000

Epoch 00466: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.9051e-10 - val_loss: 6.8735e-10
Epoch 467/1000

Epoch 00467: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.8592e-10 - val_loss: 6.8314e-10
Epoch 468/1000

Epoch 00468: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.8223e-10 - val_loss: 6.7950e-10
Epoch 469/1000

Epoch 00469: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.7838e-10 - val_loss: 6.7638e-10
Epoch 470/1000

Epoch 00470: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.7375e-10 - val_loss: 6.7090e-10
Epoch 471/1000

Epoch 00471: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.6999e-10 - val_loss: 6.6782e-10
Epoch 472/1000

Epoch 00472: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.6638e-10 - val_loss: 6.6425e-10
Epoch 473/1000

Epoch 00473: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.6204e-10 - val_loss: 6.5874e-10
Epoch 474/1000

Epoch 00474: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.5760e-10 - val_loss: 6.5533e-10
Epoch 475/1000

Epoch 00475: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.5387e-10 - val_loss: 6.5139e-10
Epoch 476/1000

Epoch 00476: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.5054e-10 - val_loss: 6.4790e-10
Epoch 477/1000

Epoch 00477: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.4576e-10 - val_loss: 6.4317e-10
Epoch 478/1000

Epoch 00478: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.4203e-10 - val_loss: 6.4002e-10
Epoch 479/1000

Epoch 00479: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.3868e-10 - val_loss: 6.3649e-10
Epoch 480/1000

Epoch 00480: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.3500e-10 - val_loss: 6.3125e-10
Epoch 481/1000

Epoch 00481: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.3074e-10 - val_loss: 6.2836e-10
Epoch 482/1000

Epoch 00482: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.2714e-10 - val_loss: 6.2520e-10
Epoch 483/1000

Epoch 00483: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.2366e-10 - val_loss: 6.2121e-10
Epoch 484/1000

Epoch 00484: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.1956e-10 - val_loss: 6.1657e-10
Epoch 485/1000

Epoch 00485: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.1605e-10 - val_loss: 6.1414e-10
Epoch 486/1000

Epoch 00486: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.1284e-10 - val_loss: 6.1066e-10
Epoch 487/1000

Epoch 00487: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.0915e-10 - val_loss: 6.0572e-10
Epoch 488/1000

Epoch 00488: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.0499e-10 - val_loss: 6.0302e-10
Epoch 489/1000

Epoch 00489: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 6.0215e-10 - val_loss: 5.9960e-10
Epoch 490/1000

Epoch 00490: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.9850e-10 - val_loss: 5.9544e-10
Epoch 491/1000

Epoch 00491: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.9472e-10 - val_loss: 5.9226e-10
Epoch 492/1000

Epoch 00492: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.9084e-10 - val_loss: 5.8944e-10
Epoch 493/1000

Epoch 00493: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.8787e-10 - val_loss: 5.8499e-10
Epoch 494/1000

Epoch 00494: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.8456e-10 - val_loss: 5.8229e-10
Epoch 495/1000

Epoch 00495: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.8082e-10 - val_loss: 5.7850e-10
Epoch 496/1000

Epoch 00496: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.7737e-10 - val_loss: 5.7554e-10
Epoch 497/1000

Epoch 00497: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.7423e-10 - val_loss: 5.7171e-10
Epoch 498/1000

Epoch 00498: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.7120e-10 - val_loss: 5.6883e-10
Epoch 499/1000

Epoch 00499: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.6750e-10 - val_loss: 5.6513e-10
Epoch 500/1000

Epoch 00500: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.6401e-10 - val_loss: 5.6219e-10
Epoch 501/1000

Epoch 00501: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.6138e-10 - val_loss: 5.5908e-10
Epoch 502/1000

Epoch 00502: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.5814e-10 - val_loss: 5.5658e-10
Epoch 503/1000

Epoch 00503: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.5425e-10 - val_loss: 5.5253e-10
Epoch 504/1000

Epoch 00504: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.5115e-10 - val_loss: 5.4904e-10
Epoch 505/1000

Epoch 00505: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.4835e-10 - val_loss: 5.4564e-10
Epoch 506/1000

Epoch 00506: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.4536e-10 - val_loss: 5.4324e-10
Epoch 507/1000

Epoch 00507: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.4179e-10 - val_loss: 5.3961e-10
Epoch 508/1000

Epoch 00508: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.3869e-10 - val_loss: 5.3623e-10
Epoch 509/1000

Epoch 00509: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.3589e-10 - val_loss: 5.3425e-10
Epoch 510/1000

Epoch 00510: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.3288e-10 - val_loss: 5.3069e-10
Epoch 511/1000

Epoch 00511: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.2954e-10 - val_loss: 5.2685e-10
Epoch 512/1000

Epoch 00512: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.2651e-10 - val_loss: 5.2455e-10
Epoch 513/1000

Epoch 00513: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.2391e-10 - val_loss: 5.2202e-10
Epoch 514/1000

Epoch 00514: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.2097e-10 - val_loss: 5.1920e-10
Epoch 515/1000

Epoch 00515: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.1797e-10 - val_loss: 5.1483e-10
Epoch 516/1000

Epoch 00516: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.1430e-10 - val_loss: 5.1235e-10
Epoch 517/1000

Epoch 00517: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.1188e-10 - val_loss: 5.0956e-10
Epoch 518/1000

Epoch 00518: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.0949e-10 - val_loss: 5.0735e-10
Epoch 519/1000

Epoch 00519: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.0667e-10 - val_loss: 5.0382e-10
Epoch 520/1000

Epoch 00520: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.0277e-10 - val_loss: 5.0106e-10
Epoch 521/1000

Epoch 00521: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 5.0038e-10 - val_loss: 4.9861e-10
Epoch 522/1000

Epoch 00522: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.9783e-10 - val_loss: 4.9574e-10
Epoch 523/1000

Epoch 00523: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.9534e-10 - val_loss: 4.9301e-10
Epoch 524/1000

Epoch 00524: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.9187e-10 - val_loss: 4.8942e-10
Epoch 525/1000

Epoch 00525: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.8914e-10 - val_loss: 4.8729e-10
Epoch 526/1000

Epoch 00526: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.8663e-10 - val_loss: 4.8486e-10
Epoch 527/1000

Epoch 00527: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.8436e-10 - val_loss: 4.8271e-10
Epoch 528/1000

Epoch 00528: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.8127e-10 - val_loss: 4.7942e-10
Epoch 529/1000

Epoch 00529: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.7851e-10 - val_loss: 4.7680e-10
Epoch 530/1000

Epoch 00530: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.7604e-10 - val_loss: 4.7421e-10
Epoch 531/1000

Epoch 00531: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.7347e-10 - val_loss: 4.7134e-10
Epoch 532/1000

Epoch 00532: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.7113e-10 - val_loss: 4.6873e-10
Epoch 533/1000

Epoch 00533: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.6770e-10 - val_loss: 4.6596e-10
Epoch 534/1000

Epoch 00534: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.6543e-10 - val_loss: 4.6433e-10
Epoch 535/1000

Epoch 00535: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.6317e-10 - val_loss: 4.6095e-10
Epoch 536/1000

Epoch 00536: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.6075e-10 - val_loss: 4.5933e-10
Epoch 537/1000

Epoch 00537: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.5818e-10 - val_loss: 4.5527e-10
Epoch 538/1000

Epoch 00538: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.5525e-10 - val_loss: 4.5317e-10
Epoch 539/1000

Epoch 00539: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.5284e-10 - val_loss: 4.5159e-10
Epoch 540/1000

Epoch 00540: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.5101e-10 - val_loss: 4.4918e-10
Epoch 541/1000

Epoch 00541: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.4859e-10 - val_loss: 4.4695e-10
Epoch 542/1000

Epoch 00542: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.4555e-10 - val_loss: 4.4375e-10
Epoch 543/1000

Epoch 00543: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.4310e-10 - val_loss: 4.4114e-10
Epoch 544/1000

Epoch 00544: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.4075e-10 - val_loss: 4.4005e-10
Epoch 545/1000

Epoch 00545: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.3883e-10 - val_loss: 4.3628e-10
Epoch 546/1000

Epoch 00546: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.3664e-10 - val_loss: 4.3461e-10
Epoch 547/1000

Epoch 00547: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.3351e-10 - val_loss: 4.3196e-10
Epoch 548/1000

Epoch 00548: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.3174e-10 - val_loss: 4.2944e-10
Epoch 549/1000

Epoch 00549: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.2928e-10 - val_loss: 4.2704e-10
Epoch 550/1000

Epoch 00550: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.2719e-10 - val_loss: 4.2524e-10
Epoch 551/1000

Epoch 00551: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.2504e-10 - val_loss: 4.2279e-10
Epoch 552/1000

Epoch 00552: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.2185e-10 - val_loss: 4.1961e-10
Epoch 553/1000

Epoch 00553: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.1996e-10 - val_loss: 4.1811e-10
Epoch 554/1000

Epoch 00554: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.1792e-10 - val_loss: 4.1558e-10
Epoch 555/1000

Epoch 00555: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.1597e-10 - val_loss: 4.1348e-10
Epoch 556/1000

Epoch 00556: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.1372e-10 - val_loss: 4.1191e-10
Epoch 557/1000

Epoch 00557: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.1090e-10 - val_loss: 4.0906e-10
Epoch 558/1000

Epoch 00558: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.0905e-10 - val_loss: 4.0750e-10
Epoch 559/1000

Epoch 00559: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.0720e-10 - val_loss: 4.0509e-10
Epoch 560/1000

Epoch 00560: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.0513e-10 - val_loss: 4.0344e-10
Epoch 561/1000

Epoch 00561: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.0305e-10 - val_loss: 4.0089e-10
Epoch 562/1000

Epoch 00562: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 4.0061e-10 - val_loss: 3.9819e-10
Epoch 563/1000

Epoch 00563: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.9831e-10 - val_loss: 3.9733e-10
Epoch 564/1000

Epoch 00564: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.9669e-10 - val_loss: 3.9495e-10
Epoch 565/1000

Epoch 00565: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.9429e-10 - val_loss: 3.9332e-10
Epoch 566/1000

Epoch 00566: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.9271e-10 - val_loss: 3.9098e-10
Epoch 567/1000

Epoch 00567: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.9041e-10 - val_loss: 3.8898e-10
Epoch 568/1000

Epoch 00568: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.8825e-10 - val_loss: 3.8627e-10
Epoch 569/1000

Epoch 00569: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.8612e-10 - val_loss: 3.8465e-10
Epoch 570/1000

Epoch 00570: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.8437e-10 - val_loss: 3.8288e-10
Epoch 571/1000

Epoch 00571: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.8264e-10 - val_loss: 3.8141e-10
Epoch 572/1000

Epoch 00572: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.8052e-10 - val_loss: 3.7850e-10
Epoch 573/1000

Epoch 00573: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.7809e-10 - val_loss: 3.7614e-10
Epoch 574/1000

Epoch 00574: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.7615e-10 - val_loss: 3.7429e-10
Epoch 575/1000

Epoch 00575: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.7503e-10 - val_loss: 3.7263e-10
Epoch 576/1000

Epoch 00576: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.7278e-10 - val_loss: 3.7105e-10
Epoch 577/1000

Epoch 00577: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.7123e-10 - val_loss: 3.6938e-10
Epoch 578/1000

Epoch 00578: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.6859e-10 - val_loss: 3.6732e-10
Epoch 579/1000

Epoch 00579: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.6698e-10 - val_loss: 3.6482e-10
Epoch 580/1000

Epoch 00580: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.6483e-10 - val_loss: 3.6338e-10
Epoch 581/1000

Epoch 00581: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.6329e-10 - val_loss: 3.6160e-10
Epoch 582/1000

Epoch 00582: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.6166e-10 - val_loss: 3.6048e-10
Epoch 583/1000

Epoch 00583: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.6015e-10 - val_loss: 3.5734e-10
Epoch 584/1000

Epoch 00584: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.5735e-10 - val_loss: 3.5589e-10
Epoch 585/1000

Epoch 00585: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.5593e-10 - val_loss: 3.5398e-10
Epoch 586/1000

Epoch 00586: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.5414e-10 - val_loss: 3.5307e-10
Epoch 587/1000

Epoch 00587: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.5271e-10 - val_loss: 3.5101e-10
Epoch 588/1000

Epoch 00588: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.5096e-10 - val_loss: 3.4959e-10
Epoch 589/1000

Epoch 00589: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.4925e-10 - val_loss: 3.4714e-10
Epoch 590/1000

Epoch 00590: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.4672e-10 - val_loss: 3.4543e-10
Epoch 591/1000

Epoch 00591: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.4535e-10 - val_loss: 3.4356e-10
Epoch 592/1000

Epoch 00592: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.4382e-10 - val_loss: 3.4213e-10
Epoch 593/1000

Epoch 00593: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.4252e-10 - val_loss: 3.4072e-10
Epoch 594/1000

Epoch 00594: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.4057e-10 - val_loss: 3.3922e-10
Epoch 595/1000

Epoch 00595: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.3880e-10 - val_loss: 3.3703e-10
Epoch 596/1000

Epoch 00596: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.3697e-10 - val_loss: 3.3575e-10
Epoch 597/1000

Epoch 00597: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.3558e-10 - val_loss: 3.3351e-10
Epoch 598/1000

Epoch 00598: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.3375e-10 - val_loss: 3.3232e-10
Epoch 599/1000

Epoch 00599: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.3247e-10 - val_loss: 3.3125e-10
Epoch 600/1000

Epoch 00600: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.3089e-10 - val_loss: 3.3020e-10
Epoch 601/1000

Epoch 00601: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.2951e-10 - val_loss: 3.2773e-10
Epoch 602/1000

Epoch 00602: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.2719e-10 - val_loss: 3.2574e-10
Epoch 603/1000

Epoch 00603: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.2563e-10 - val_loss: 3.2407e-10
Epoch 604/1000

Epoch 00604: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.2403e-10 - val_loss: 3.2264e-10
Epoch 605/1000

Epoch 00605: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.2299e-10 - val_loss: 3.2176e-10
Epoch 606/1000

Epoch 00606: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.2172e-10 - val_loss: 3.1959e-10
Epoch 607/1000

Epoch 00607: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.1974e-10 - val_loss: 3.1781e-10
Epoch 608/1000

Epoch 00608: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.1786e-10 - val_loss: 3.1582e-10
Epoch 609/1000

Epoch 00609: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.1616e-10 - val_loss: 3.1445e-10
Epoch 610/1000

Epoch 00610: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 3.1497e-10 - val_loss: 3.1513e-10
Epoch 611/1000

Epoch 00611: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.1389e-10 - val_loss: 3.1275e-10
Epoch 612/1000

Epoch 00612: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.1260e-10 - val_loss: 3.1095e-10
Epoch 613/1000

Epoch 00613: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.1117e-10 - val_loss: 3.0952e-10
Epoch 614/1000

Epoch 00614: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.0902e-10 - val_loss: 3.0759e-10
Epoch 615/1000

Epoch 00615: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.0734e-10 - val_loss: 3.0596e-10
Epoch 616/1000

Epoch 00616: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.0614e-10 - val_loss: 3.0494e-10
Epoch 617/1000

Epoch 00617: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.0521e-10 - val_loss: 3.0440e-10
Epoch 618/1000

Epoch 00618: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.0369e-10 - val_loss: 3.0219e-10
Epoch 619/1000

Epoch 00619: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.0229e-10 - val_loss: 3.0193e-10
Epoch 620/1000

Epoch 00620: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 3.0080e-10 - val_loss: 2.9872e-10
Epoch 621/1000

Epoch 00621: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.9863e-10 - val_loss: 2.9721e-10
Epoch 622/1000

Epoch 00622: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.9749e-10 - val_loss: 2.9555e-10
Epoch 623/1000

Epoch 00623: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.9608e-10 - val_loss: 2.9506e-10
Epoch 624/1000

Epoch 00624: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.9513e-10 - val_loss: 2.9333e-10
Epoch 625/1000

Epoch 00625: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.9394e-10 - val_loss: 2.9239e-10
Epoch 626/1000

Epoch 00626: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.9284e-10 - val_loss: 2.9128e-10
Epoch 627/1000

Epoch 00627: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.9104e-10 - val_loss: 2.8942e-10
Epoch 628/1000

Epoch 00628: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.8951e-10 - val_loss: 2.8867e-10
Epoch 629/1000

Epoch 00629: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.8823e-10 - val_loss: 2.8663e-10
Epoch 630/1000

Epoch 00630: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.8701e-10 - val_loss: 2.8557e-10
Epoch 631/1000

Epoch 00631: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.8565e-10 - val_loss: 2.8468e-10
Epoch 632/1000

Epoch 00632: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.8450e-10 - val_loss: 2.8304e-10
Epoch 633/1000

Epoch 00633: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.8345e-10 - val_loss: 2.8179e-10
Epoch 634/1000

Epoch 00634: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.8169e-10 - val_loss: 2.8011e-10
Epoch 635/1000

Epoch 00635: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.8016e-10 - val_loss: 2.7911e-10
Epoch 636/1000

Epoch 00636: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.7935e-10 - val_loss: 2.7853e-10
Epoch 637/1000

Epoch 00637: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.7824e-10 - val_loss: 2.7684e-10
Epoch 638/1000

Epoch 00638: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.7695e-10 - val_loss: 2.7607e-10
Epoch 639/1000

Epoch 00639: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.7581e-10 - val_loss: 2.7401e-10
Epoch 640/1000

Epoch 00640: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.7447e-10 - val_loss: 2.7352e-10
Epoch 641/1000

Epoch 00641: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.7325e-10 - val_loss: 2.7223e-10
Epoch 642/1000

Epoch 00642: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.7199e-10 - val_loss: 2.7020e-10
Epoch 643/1000

Epoch 00643: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.7062e-10 - val_loss: 2.6898e-10
Epoch 644/1000

Epoch 00644: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.6938e-10 - val_loss: 2.6776e-10
Epoch 645/1000

Epoch 00645: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.6820e-10 - val_loss: 2.6681e-10
Epoch 646/1000

Epoch 00646: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.6754e-10 - val_loss: 2.6615e-10
Epoch 647/1000

Epoch 00647: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.6617e-10 - val_loss: 2.6481e-10
Epoch 648/1000

Epoch 00648: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.6479e-10 - val_loss: 2.6427e-10
Epoch 649/1000

Epoch 00649: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.6363e-10 - val_loss: 2.6162e-10
Epoch 650/1000

Epoch 00650: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.6203e-10 - val_loss: 2.6064e-10
Epoch 651/1000

Epoch 00651: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.6098e-10 - val_loss: 2.5995e-10
Epoch 652/1000

Epoch 00652: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.6042e-10 - val_loss: 2.5832e-10
Epoch 653/1000

Epoch 00653: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.5887e-10 - val_loss: 2.5760e-10
Epoch 654/1000

Epoch 00654: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.5796e-10 - val_loss: 2.5679e-10
Epoch 655/1000

Epoch 00655: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.5711e-10 - val_loss: 2.5561e-10
Epoch 656/1000

Epoch 00656: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.5565e-10 - val_loss: 2.5622e-10
Epoch 657/1000

Epoch 00657: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.5452e-10 - val_loss: 2.5304e-10
Epoch 658/1000

Epoch 00658: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.5325e-10 - val_loss: 2.5198e-10
Epoch 659/1000

Epoch 00659: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.5311e-10 - val_loss: 2.5127e-10
Epoch 660/1000

Epoch 00660: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.5219e-10 - val_loss: 2.5135e-10
Epoch 661/1000

Epoch 00661: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.5077e-10 - val_loss: 2.4898e-10
Epoch 662/1000

Epoch 00662: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.4972e-10 - val_loss: 2.4823e-10
Epoch 663/1000

Epoch 00663: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.4873e-10 - val_loss: 2.4719e-10
Epoch 664/1000

Epoch 00664: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.4673e-10 - val_loss: 2.4555e-10
Epoch 665/1000

Epoch 00665: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.4593e-10 - val_loss: 2.4468e-10
Epoch 666/1000

Epoch 00666: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.4524e-10 - val_loss: 2.4355e-10
Epoch 667/1000

Epoch 00667: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.4387e-10 - val_loss: 2.4272e-10
Epoch 668/1000

Epoch 00668: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.4298e-10 - val_loss: 2.4154e-10
Epoch 669/1000

Epoch 00669: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.4209e-10 - val_loss: 2.4053e-10
Epoch 670/1000

Epoch 00670: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.4082e-10 - val_loss: 2.3992e-10
Epoch 671/1000

Epoch 00671: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.4033e-10 - val_loss: 2.3887e-10
Epoch 672/1000

Epoch 00672: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.3910e-10 - val_loss: 2.3711e-10
Epoch 673/1000

Epoch 00673: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.3770e-10 - val_loss: 2.3622e-10
Epoch 674/1000

Epoch 00674: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.3713e-10 - val_loss: 2.3575e-10
Epoch 675/1000

Epoch 00675: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.3627e-10 - val_loss: 2.3505e-10
Epoch 676/1000

Epoch 00676: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.3508e-10 - val_loss: 2.3367e-10
Epoch 677/1000

Epoch 00677: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.3417e-10 - val_loss: 2.3355e-10
Epoch 678/1000

Epoch 00678: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.3345e-10 - val_loss: 2.3210e-10
Epoch 679/1000

Epoch 00679: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.3252e-10 - val_loss: 2.3137e-10
Epoch 680/1000

Epoch 00680: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.3113e-10 - val_loss: 2.2943e-10
Epoch 681/1000

Epoch 00681: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.2999e-10 - val_loss: 2.2864e-10
Epoch 682/1000

Epoch 00682: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.2881e-10 - val_loss: 2.2785e-10
Epoch 683/1000

Epoch 00683: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.2814e-10 - val_loss: 2.2682e-10
Epoch 684/1000

Epoch 00684: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.2745e-10 - val_loss: 2.2612e-10
Epoch 685/1000

Epoch 00685: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.2651e-10 - val_loss: 2.2567e-10
Epoch 686/1000

Epoch 00686: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.2581e-10 - val_loss: 2.2498e-10
Epoch 687/1000

Epoch 00687: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.2493e-10 - val_loss: 2.2398e-10
Epoch 688/1000

Epoch 00688: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.2414e-10 - val_loss: 2.2172e-10
Epoch 689/1000

Epoch 00689: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.2241e-10 - val_loss: 2.2161e-10
Epoch 690/1000

Epoch 00690: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.2209e-10 - val_loss: 2.2197e-10
Epoch 691/1000

Epoch 00691: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.2120e-10 - val_loss: 2.1964e-10
Epoch 692/1000

Epoch 00692: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.2101e-10 - val_loss: 2.2007e-10
Epoch 693/1000

Epoch 00693: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1965e-10 - val_loss: 2.1846e-10
Epoch 694/1000

Epoch 00694: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1887e-10 - val_loss: 2.1714e-10
Epoch 695/1000

Epoch 00695: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1803e-10 - val_loss: 2.1704e-10
Epoch 696/1000

Epoch 00696: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1732e-10 - val_loss: 2.1581e-10
Epoch 697/1000

Epoch 00697: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1633e-10 - val_loss: 2.1434e-10
Epoch 698/1000

Epoch 00698: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1464e-10 - val_loss: 2.1343e-10
Epoch 699/1000

Epoch 00699: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1405e-10 - val_loss: 2.1307e-10
Epoch 700/1000

Epoch 00700: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1333e-10 - val_loss: 2.1273e-10
Epoch 701/1000

Epoch 00701: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1305e-10 - val_loss: 2.1160e-10
Epoch 702/1000

Epoch 00702: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1260e-10 - val_loss: 2.1106e-10
Epoch 703/1000

Epoch 00703: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1204e-10 - val_loss: 2.1016e-10
Epoch 704/1000

Epoch 00704: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1053e-10 - val_loss: 2.0910e-10
Epoch 705/1000

Epoch 00705: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0939e-10 - val_loss: 2.0813e-10
Epoch 706/1000

Epoch 00706: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0917e-10 - val_loss: 2.0713e-10
Epoch 707/1000

Epoch 00707: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0753e-10 - val_loss: 2.0654e-10
Epoch 708/1000

Epoch 00708: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0691e-10 - val_loss: 2.0547e-10
Epoch 709/1000

Epoch 00709: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0610e-10 - val_loss: 2.0487e-10
Epoch 710/1000

Epoch 00710: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0542e-10 - val_loss: 2.0435e-10
Epoch 711/1000

Epoch 00711: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0467e-10 - val_loss: 2.0310e-10
Epoch 712/1000

Epoch 00712: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.0399e-10 - val_loss: 2.0391e-10
Epoch 713/1000

Epoch 00713: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0350e-10 - val_loss: 2.0221e-10
Epoch 714/1000

Epoch 00714: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0371e-10 - val_loss: 2.0155e-10
Epoch 715/1000

Epoch 00715: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.0191e-10 - val_loss: 2.0162e-10
Epoch 716/1000

Epoch 00716: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0107e-10 - val_loss: 1.9955e-10
Epoch 717/1000

Epoch 00717: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.0002e-10 - val_loss: 1.9891e-10
Epoch 718/1000

Epoch 00718: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9967e-10 - val_loss: 1.9848e-10
Epoch 719/1000

Epoch 00719: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9859e-10 - val_loss: 1.9831e-10
Epoch 720/1000

Epoch 00720: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9801e-10 - val_loss: 1.9692e-10
Epoch 721/1000

Epoch 00721: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9700e-10 - val_loss: 1.9617e-10
Epoch 722/1000

Epoch 00722: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9660e-10 - val_loss: 1.9532e-10
Epoch 723/1000

Epoch 00723: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.9575e-10 - val_loss: 1.9537e-10
Epoch 724/1000

Epoch 00724: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.9589e-10 - val_loss: 1.9806e-10
Epoch 725/1000

Epoch 00725: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9581e-10 - val_loss: 1.9338e-10
Epoch 726/1000

Epoch 00726: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9407e-10 - val_loss: 1.9303e-10
Epoch 727/1000

Epoch 00727: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.9314e-10 - val_loss: 1.9337e-10
Epoch 728/1000

Epoch 00728: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9420e-10 - val_loss: 1.9118e-10
Epoch 729/1000

Epoch 00729: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9141e-10 - val_loss: 1.9015e-10
Epoch 730/1000

Epoch 00730: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.9056e-10 - val_loss: 1.8962e-10
Epoch 731/1000

Epoch 00731: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8994e-10 - val_loss: 1.8889e-10
Epoch 732/1000

Epoch 00732: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8939e-10 - val_loss: 1.8861e-10
Epoch 733/1000

Epoch 00733: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8969e-10 - val_loss: 1.8770e-10
Epoch 734/1000

Epoch 00734: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8875e-10 - val_loss: 1.8707e-10
Epoch 735/1000

Epoch 00735: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.8839e-10 - val_loss: 1.9030e-10
Epoch 736/1000

Epoch 00736: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8882e-10 - val_loss: 1.8544e-10
Epoch 737/1000

Epoch 00737: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8653e-10 - val_loss: 1.8513e-10
Epoch 738/1000

Epoch 00738: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8548e-10 - val_loss: 1.8441e-10
Epoch 739/1000

Epoch 00739: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8445e-10 - val_loss: 1.8356e-10
Epoch 740/1000

Epoch 00740: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.8437e-10 - val_loss: 1.8392e-10
Epoch 741/1000

Epoch 00741: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8368e-10 - val_loss: 1.8272e-10
Epoch 742/1000

Epoch 00742: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8268e-10 - val_loss: 1.8165e-10
Epoch 743/1000

Epoch 00743: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8252e-10 - val_loss: 1.8159e-10
Epoch 744/1000

Epoch 00744: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.8169e-10 - val_loss: 1.8190e-10
Epoch 745/1000

Epoch 00745: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8161e-10 - val_loss: 1.8120e-10
Epoch 746/1000

Epoch 00746: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.8158e-10 - val_loss: 1.8013e-10
Epoch 747/1000

Epoch 00747: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7994e-10 - val_loss: 1.7817e-10
Epoch 748/1000

Epoch 00748: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.7883e-10 - val_loss: 1.7914e-10
Epoch 749/1000

Epoch 00749: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7851e-10 - val_loss: 1.7699e-10
Epoch 750/1000

Epoch 00750: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7765e-10 - val_loss: 1.7601e-10
Epoch 751/1000

Epoch 00751: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7686e-10 - val_loss: 1.7574e-10
Epoch 752/1000

Epoch 00752: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.7657e-10 - val_loss: 1.7615e-10
Epoch 753/1000

Epoch 00753: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7596e-10 - val_loss: 1.7484e-10
Epoch 754/1000

Epoch 00754: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7544e-10 - val_loss: 1.7431e-10
Epoch 755/1000

Epoch 00755: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.7603e-10 - val_loss: 1.7487e-10
Epoch 756/1000

Epoch 00756: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.7488e-10 - val_loss: 1.7675e-10
Epoch 757/1000

Epoch 00757: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7479e-10 - val_loss: 1.7252e-10
Epoch 758/1000

Epoch 00758: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7261e-10 - val_loss: 1.7171e-10
Epoch 759/1000

Epoch 00759: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7218e-10 - val_loss: 1.7101e-10
Epoch 760/1000

Epoch 00760: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7170e-10 - val_loss: 1.7083e-10
Epoch 761/1000

Epoch 00761: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7167e-10 - val_loss: 1.7005e-10
Epoch 762/1000

Epoch 00762: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.7098e-10 - val_loss: 1.7175e-10
Epoch 763/1000

Epoch 00763: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.7049e-10 - val_loss: 1.6872e-10
Epoch 764/1000

Epoch 00764: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6952e-10 - val_loss: 1.6812e-10
Epoch 765/1000

Epoch 00765: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.6923e-10 - val_loss: 1.6812e-10
Epoch 766/1000

Epoch 00766: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6870e-10 - val_loss: 1.6756e-10
Epoch 767/1000

Epoch 00767: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.6799e-10 - val_loss: 1.6768e-10
Epoch 768/1000

Epoch 00768: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6732e-10 - val_loss: 1.6583e-10
Epoch 769/1000

Epoch 00769: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6701e-10 - val_loss: 1.6509e-10
Epoch 770/1000

Epoch 00770: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.6570e-10 - val_loss: 1.6538e-10
Epoch 771/1000

Epoch 00771: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.6555e-10 - val_loss: 1.6604e-10
Epoch 772/1000

Epoch 00772: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6559e-10 - val_loss: 1.6352e-10
Epoch 773/1000

Epoch 00773: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.6537e-10 - val_loss: 1.6563e-10
Epoch 774/1000

Epoch 00774: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6462e-10 - val_loss: 1.6295e-10
Epoch 775/1000

Epoch 00775: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.6374e-10 - val_loss: 1.6339e-10
Epoch 776/1000

Epoch 00776: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.6431e-10 - val_loss: 1.6308e-10
Epoch 777/1000

Epoch 00777: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6384e-10 - val_loss: 1.6110e-10
Epoch 778/1000

Epoch 00778: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.6240e-10 - val_loss: 1.6213e-10
Epoch 779/1000

Epoch 00779: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.6316e-10 - val_loss: 1.6271e-10
Epoch 780/1000

Epoch 00780: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.6467e-10 - val_loss: 1.6538e-10
Epoch 781/1000

Epoch 00781: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.6353e-10 - val_loss: 1.6305e-10
Epoch 782/1000

Epoch 00782: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.6152e-10 - val_loss: 1.6739e-10
Epoch 783/1000

Epoch 00783: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.6207e-10 - val_loss: 1.6239e-10
Epoch 784/1000

Epoch 00784: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5992e-10 - val_loss: 1.5818e-10
Epoch 785/1000

Epoch 00785: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5862e-10 - val_loss: 1.5683e-10
Epoch 786/1000

Epoch 00786: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.5877e-10 - val_loss: 1.5718e-10
Epoch 787/1000

Epoch 00787: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5713e-10 - val_loss: 1.5591e-10
Epoch 788/1000

Epoch 00788: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5687e-10 - val_loss: 1.5586e-10
Epoch 789/1000

Epoch 00789: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.5662e-10 - val_loss: 1.5608e-10
Epoch 790/1000

Epoch 00790: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5593e-10 - val_loss: 1.5505e-10
Epoch 791/1000

Epoch 00791: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5601e-10 - val_loss: 1.5458e-10
Epoch 792/1000

Epoch 00792: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5491e-10 - val_loss: 1.5325e-10
Epoch 793/1000

Epoch 00793: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.5397e-10 - val_loss: 1.5445e-10
Epoch 794/1000

Epoch 00794: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5413e-10 - val_loss: 1.5268e-10
Epoch 795/1000

Epoch 00795: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.5330e-10 - val_loss: 1.5360e-10
Epoch 796/1000

Epoch 00796: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.5699e-10 - val_loss: 1.5411e-10
Epoch 797/1000

Epoch 00797: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.5587e-10 - val_loss: 1.5525e-10
Epoch 798/1000

Epoch 00798: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5218e-10 - val_loss: 1.5052e-10
Epoch 799/1000

Epoch 00799: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.5266e-10 - val_loss: 1.5295e-10
Epoch 800/1000

Epoch 00800: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5398e-10 - val_loss: 1.4987e-10
Epoch 801/1000

Epoch 00801: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5140e-10 - val_loss: 1.4978e-10
Epoch 802/1000

Epoch 00802: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.5252e-10 - val_loss: 1.4998e-10
Epoch 803/1000

Epoch 00803: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5037e-10 - val_loss: 1.4929e-10
Epoch 804/1000

Epoch 00804: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5010e-10 - val_loss: 1.4860e-10
Epoch 805/1000

Epoch 00805: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4872e-10 - val_loss: 1.4961e-10
Epoch 806/1000

Epoch 00806: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4898e-10 - val_loss: 1.4691e-10
Epoch 807/1000

Epoch 00807: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4788e-10 - val_loss: 1.4699e-10
Epoch 808/1000

Epoch 00808: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4733e-10 - val_loss: 1.4736e-10
Epoch 809/1000

Epoch 00809: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5011e-10 - val_loss: 1.4561e-10
Epoch 810/1000

Epoch 00810: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.5001e-10 - val_loss: 1.4667e-10
Epoch 811/1000

Epoch 00811: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4687e-10 - val_loss: 1.5021e-10
Epoch 812/1000

Epoch 00812: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4653e-10 - val_loss: 1.4466e-10
Epoch 813/1000

Epoch 00813: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4532e-10 - val_loss: 1.4423e-10
Epoch 814/1000

Epoch 00814: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4557e-10 - val_loss: 1.5053e-10
Epoch 815/1000

Epoch 00815: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4803e-10 - val_loss: 1.4365e-10
Epoch 816/1000

Epoch 00816: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4564e-10 - val_loss: 1.4355e-10
Epoch 817/1000

Epoch 00817: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4585e-10 - val_loss: 1.5075e-10
Epoch 818/1000

Epoch 00818: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4555e-10 - val_loss: 1.5045e-10
Epoch 819/1000

Epoch 00819: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4902e-10 - val_loss: 1.7162e-10
Epoch 820/1000

Epoch 00820: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6028e-10 - val_loss: 1.4243e-10
Epoch 821/1000

Epoch 00821: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4212e-10 - val_loss: 1.4181e-10
Epoch 822/1000

Epoch 00822: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4203e-10 - val_loss: 1.4188e-10
Epoch 823/1000

Epoch 00823: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4272e-10 - val_loss: 1.4134e-10
Epoch 824/1000

Epoch 00824: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4774e-10 - val_loss: 1.4593e-10
Epoch 825/1000

Epoch 00825: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4392e-10 - val_loss: 1.5107e-10
Epoch 826/1000

Epoch 00826: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4763e-10 - val_loss: 1.4535e-10
Epoch 827/1000

Epoch 00827: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4393e-10 - val_loss: 1.4711e-10
Epoch 828/1000

Epoch 00828: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4516e-10 - val_loss: 1.5814e-10
Epoch 829/1000

Epoch 00829: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.5696e-10 - val_loss: 1.5316e-10
Epoch 830/1000

Epoch 00830: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.5921e-10 - val_loss: 1.4540e-10
Epoch 831/1000

Epoch 00831: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4066e-10 - val_loss: 1.3675e-10
Epoch 832/1000

Epoch 00832: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3806e-10 - val_loss: 1.3569e-10
Epoch 833/1000

Epoch 00833: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4032e-10 - val_loss: 1.3585e-10
Epoch 834/1000

Epoch 00834: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3997e-10 - val_loss: 1.3534e-10
Epoch 835/1000

Epoch 00835: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.3628e-10 - val_loss: 1.3548e-10
Epoch 836/1000

Epoch 00836: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3983e-10 - val_loss: 1.3442e-10
Epoch 837/1000

Epoch 00837: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.3844e-10 - val_loss: 1.3878e-10
Epoch 838/1000

Epoch 00838: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.3713e-10 - val_loss: 1.4818e-10
Epoch 839/1000

Epoch 00839: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6232e-10 - val_loss: 1.3369e-10
Epoch 840/1000

Epoch 00840: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4273e-10 - val_loss: 1.5305e-10
Epoch 841/1000

Epoch 00841: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.6477e-10 - val_loss: 1.3484e-10
Epoch 842/1000

Epoch 00842: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.2005e-10 - val_loss: 1.9465e-10
Epoch 843/1000

Epoch 00843: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.5997e-10 - val_loss: 1.3271e-10
Epoch 844/1000

Epoch 00844: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.5538e-10 - val_loss: 1.5205e-10
Epoch 845/1000

Epoch 00845: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.3832e-10 - val_loss: 1.4094e-10
Epoch 846/1000

Epoch 00846: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.4017e-10 - val_loss: 1.3116e-10
Epoch 847/1000

Epoch 00847: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.3418e-10 - val_loss: 1.4598e-10
Epoch 848/1000

Epoch 00848: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.3416e-10 - val_loss: 1.3156e-10
Epoch 849/1000

Epoch 00849: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.3176e-10 - val_loss: 1.4413e-10
Epoch 850/1000

Epoch 00850: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.3542e-10 - val_loss: 1.3131e-10
Epoch 851/1000

Epoch 00851: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3525e-10 - val_loss: 1.3005e-10
Epoch 852/1000

Epoch 00852: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4703e-10 - val_loss: 1.5694e-10
Epoch 853/1000

Epoch 00853: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3997e-10 - val_loss: 1.2892e-10
Epoch 854/1000

Epoch 00854: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3774e-10 - val_loss: 1.2866e-10
Epoch 855/1000

Epoch 00855: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.3430e-10 - val_loss: 1.3421e-10
Epoch 856/1000

Epoch 00856: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.6021e-10 - val_loss: 1.2822e-10
Epoch 857/1000

Epoch 00857: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3693e-10 - val_loss: 1.2721e-10
Epoch 858/1000

Epoch 00858: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4760e-10 - val_loss: 1.7634e-10
Epoch 859/1000

Epoch 00859: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4019e-10 - val_loss: 2.0535e-10
Epoch 860/1000

Epoch 00860: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 3.2058e-10 - val_loss: 5.0086e-10
Epoch 861/1000

Epoch 00861: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.5686e-10 - val_loss: 4.8926e-10
Epoch 862/1000

Epoch 00862: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 7.7376e-10 - val_loss: 1.1074e-09
Epoch 863/1000

Epoch 00863: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 3.9752e-09 - val_loss: 2.1380e-10
Epoch 864/1000

Epoch 00864: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.0536e-09 - val_loss: 3.1496e-09
Epoch 865/1000

Epoch 00865: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 7.8060e-10 - val_loss: 4.0508e-10
Epoch 866/1000

Epoch 00866: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 4.1180e-10 - val_loss: 1.4292e-10
Epoch 867/1000

Epoch 00867: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.0199e-10 - val_loss: 2.6311e-10
Epoch 868/1000

Epoch 00868: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 2.1059e-10 - val_loss: 1.2615e-10
Epoch 869/1000

Epoch 00869: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4484e-10 - val_loss: 1.5165e-10
Epoch 870/1000

Epoch 00870: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.3450e-10 - val_loss: 1.4609e-10
Epoch 871/1000

Epoch 00871: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.5400e-10 - val_loss: 1.3743e-10
Epoch 872/1000

Epoch 00872: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.3859e-10 - val_loss: 1.5581e-10
Epoch 873/1000

Epoch 00873: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.1802e-10 - val_loss: 1.3219e-10
Epoch 874/1000

Epoch 00874: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4326e-10 - val_loss: 1.6564e-10
Epoch 875/1000

Epoch 00875: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.5552e-10 - val_loss: 1.4846e-10
Epoch 876/1000

Epoch 00876: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 9.5430e-10 - val_loss: 1.5788e-09
Epoch 877/1000

Epoch 00877: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 4.2264e-09 - val_loss: 1.0926e-08
Epoch 878/1000

Epoch 00878: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 3.9752e-09 - val_loss: 3.1851e-09
Epoch 879/1000

Epoch 00879: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.4364e-09 - val_loss: 1.9466e-10
Epoch 880/1000

Epoch 00880: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 7.3810e-10 - val_loss: 1.6024e-10
Epoch 881/1000

Epoch 00881: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 5.8966e-10 - val_loss: 1.3859e-10
Epoch 882/1000

Epoch 00882: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.8171e-10 - val_loss: 1.3548e-10
Epoch 883/1000

Epoch 00883: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.3523e-10 - val_loss: 1.3472e-10
Epoch 884/1000

Epoch 00884: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3018e-10 - val_loss: 1.2485e-10
Epoch 885/1000

Epoch 00885: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2558e-10 - val_loss: 1.2455e-10
Epoch 886/1000

Epoch 00886: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2547e-10 - val_loss: 1.2402e-10
Epoch 887/1000

Epoch 00887: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.2579e-10 - val_loss: 1.2432e-10
Epoch 888/1000

Epoch 00888: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.2588e-10 - val_loss: 1.2535e-10
Epoch 889/1000

Epoch 00889: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2378e-10 - val_loss: 1.2234e-10
Epoch 890/1000

Epoch 00890: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2282e-10 - val_loss: 1.2207e-10
Epoch 891/1000

Epoch 00891: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2342e-10 - val_loss: 1.2125e-10
Epoch 892/1000

Epoch 00892: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.2711e-10 - val_loss: 1.3301e-10
Epoch 893/1000

Epoch 00893: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.3267e-10 - val_loss: 1.2324e-10
Epoch 894/1000

Epoch 00894: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3260e-10 - val_loss: 1.2010e-10
Epoch 895/1000

Epoch 00895: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.2890e-10 - val_loss: 1.4113e-10
Epoch 896/1000

Epoch 00896: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4036e-10 - val_loss: 1.3778e-10
Epoch 897/1000

Epoch 00897: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.2991e-10 - val_loss: 1.2305e-10
Epoch 898/1000

Epoch 00898: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.2247e-10 - val_loss: 1.2292e-10
Epoch 899/1000

Epoch 00899: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.2133e-10 - val_loss: 1.2046e-10
Epoch 900/1000

Epoch 00900: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2292e-10 - val_loss: 1.1756e-10
Epoch 901/1000

Epoch 00901: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.2146e-10 - val_loss: 1.2800e-10
Epoch 902/1000

Epoch 00902: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.2166e-10 - val_loss: 1.2254e-10
Epoch 903/1000

Epoch 00903: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.2207e-10 - val_loss: 1.2588e-10
Epoch 904/1000

Epoch 00904: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.2516e-10 - val_loss: 1.2049e-10
Epoch 905/1000

Epoch 00905: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1832e-10 - val_loss: 1.1761e-10
Epoch 906/1000

Epoch 00906: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.2401e-10 - val_loss: 1.1785e-10
Epoch 907/1000

Epoch 00907: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1715e-10 - val_loss: 1.1805e-10
Epoch 908/1000

Epoch 00908: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.3066e-10 - val_loss: 1.3466e-10
Epoch 909/1000

Epoch 00909: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.8201e-10 - val_loss: 3.1391e-10
Epoch 910/1000

Epoch 00910: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.1509e-10 - val_loss: 1.2993e-10
Epoch 911/1000

Epoch 00911: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 6.8039e-10 - val_loss: 3.2949e-09
Epoch 912/1000

Epoch 00912: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.3615e-09 - val_loss: 1.9529e-10
Epoch 913/1000

Epoch 00913: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.8926e-09 - val_loss: 3.1009e-09
Epoch 914/1000

Epoch 00914: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4770e-09 - val_loss: 6.7802e-10
Epoch 915/1000

Epoch 00915: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 6.6164e-10 - val_loss: 4.2229e-10
Epoch 916/1000

Epoch 00916: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 3.0201e-10 - val_loss: 6.8271e-10
Epoch 917/1000

Epoch 00917: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.5854e-10 - val_loss: 1.3222e-10
Epoch 918/1000

Epoch 00918: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.8764e-10 - val_loss: 1.3818e-10
Epoch 919/1000

Epoch 00919: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.3623e-10 - val_loss: 1.2693e-10
Epoch 920/1000

Epoch 00920: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1816e-10 - val_loss: 1.1465e-10
Epoch 921/1000

Epoch 00921: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1676e-10 - val_loss: 1.1307e-10
Epoch 922/1000

Epoch 00922: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1430e-10 - val_loss: 1.1136e-10
Epoch 923/1000

Epoch 00923: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1232e-10 - val_loss: 1.1135e-10
Epoch 924/1000

Epoch 00924: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1258e-10 - val_loss: 1.1090e-10
Epoch 925/1000

Epoch 00925: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1163e-10 - val_loss: 1.1015e-10
Epoch 926/1000

Epoch 00926: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1143e-10 - val_loss: 1.1224e-10
Epoch 927/1000

Epoch 00927: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1117e-10 - val_loss: 1.0972e-10
Epoch 928/1000

Epoch 00928: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1999e-10 - val_loss: 1.2375e-10
Epoch 929/1000

Epoch 00929: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4099e-10 - val_loss: 1.1346e-10
Epoch 930/1000

Epoch 00930: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.9917e-10 - val_loss: 2.3863e-10
Epoch 931/1000

Epoch 00931: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 3.3729e-10 - val_loss: 4.1158e-10
Epoch 932/1000

Epoch 00932: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.6970e-10 - val_loss: 2.5358e-10
Epoch 933/1000

Epoch 00933: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.9020e-10 - val_loss: 2.0135e-10
Epoch 934/1000

Epoch 00934: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.3163e-10 - val_loss: 1.0765e-10
Epoch 935/1000

Epoch 00935: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.5050e-10 - val_loss: 2.7152e-10
Epoch 936/1000

Epoch 00936: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.0585e-10 - val_loss: 1.7296e-10
Epoch 937/1000

Epoch 00937: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 3.5820e-10 - val_loss: 2.7760e-10
Epoch 938/1000

Epoch 00938: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 5.8670e-09 - val_loss: 2.7188e-08
Epoch 939/1000

Epoch 00939: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 7.4841e-09 - val_loss: 6.5493e-09
Epoch 940/1000

Epoch 00940: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.8544e-09 - val_loss: 1.3401e-09
Epoch 941/1000

Epoch 00941: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 6.7609e-10 - val_loss: 5.4765e-10
Epoch 942/1000

Epoch 00942: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.4595e-10 - val_loss: 1.4286e-10
Epoch 943/1000

Epoch 00943: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.4118e-10 - val_loss: 1.2833e-10
Epoch 944/1000

Epoch 00944: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1798e-10 - val_loss: 1.1310e-10
Epoch 945/1000

Epoch 00945: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1571e-10 - val_loss: 1.1602e-10
Epoch 946/1000

Epoch 00946: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1622e-10 - val_loss: 1.1450e-10
Epoch 947/1000

Epoch 00947: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1503e-10 - val_loss: 1.2546e-10
Epoch 948/1000

Epoch 00948: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1683e-10 - val_loss: 1.1755e-10
Epoch 949/1000

Epoch 00949: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1348e-10 - val_loss: 1.1363e-10
Epoch 950/1000

Epoch 00950: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1211e-10 - val_loss: 1.1065e-10
Epoch 951/1000

Epoch 00951: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1192e-10 - val_loss: 1.0976e-10
Epoch 952/1000

Epoch 00952: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1044e-10 - val_loss: 1.1054e-10
Epoch 953/1000

Epoch 00953: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1789e-10 - val_loss: 1.1208e-10
Epoch 954/1000

Epoch 00954: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1279e-10 - val_loss: 1.0975e-10
Epoch 955/1000

Epoch 00955: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1437e-10 - val_loss: 1.0699e-10
Epoch 956/1000

Epoch 00956: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1059e-10 - val_loss: 1.1044e-10
Epoch 957/1000

Epoch 00957: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1030e-10 - val_loss: 1.1222e-10
Epoch 958/1000

Epoch 00958: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1777e-10 - val_loss: 1.0879e-10
Epoch 959/1000

Epoch 00959: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0866e-10 - val_loss: 1.0514e-10
Epoch 960/1000

Epoch 00960: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.0564e-10 - val_loss: 1.0705e-10
Epoch 961/1000

Epoch 00961: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0545e-10 - val_loss: 1.0357e-10
Epoch 962/1000

Epoch 00962: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0488e-10 - val_loss: 1.0351e-10
Epoch 963/1000

Epoch 00963: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0537e-10 - val_loss: 1.0351e-10
Epoch 964/1000

Epoch 00964: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.1337e-10 - val_loss: 1.0436e-10
Epoch 965/1000

Epoch 00965: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.0427e-10 - val_loss: 1.0723e-10
Epoch 966/1000

Epoch 00966: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0612e-10 - val_loss: 1.0256e-10
Epoch 967/1000

Epoch 00967: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0395e-10 - val_loss: 1.0152e-10
Epoch 968/1000

Epoch 00968: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.0386e-10 - val_loss: 1.1020e-10
Epoch 969/1000

Epoch 00969: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.1798e-10 - val_loss: 1.0072e-10
Epoch 970/1000

Epoch 00970: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.0752e-10 - val_loss: 1.0731e-10
Epoch 971/1000

Epoch 00971: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0353e-10 - val_loss: 1.0028e-10
Epoch 972/1000

Epoch 00972: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0141e-10 - val_loss: 9.9145e-11
Epoch 973/1000

Epoch 00973: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0179e-10 - val_loss: 9.8655e-11
Epoch 974/1000

Epoch 00974: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 9.9719e-11 - val_loss: 9.8778e-11
Epoch 975/1000

Epoch 00975: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.0254e-10 - val_loss: 9.7879e-11
Epoch 976/1000

Epoch 00976: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.8925e-11 - val_loss: 9.7239e-11
Epoch 977/1000

Epoch 00977: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 9.9126e-11 - val_loss: 9.6933e-11
Epoch 978/1000

Epoch 00978: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.0048e-10 - val_loss: 9.7683e-11
Epoch 979/1000

Epoch 00979: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.0471e-10 - val_loss: 1.0453e-10
Epoch 980/1000

Epoch 00980: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 9.8722e-11 - val_loss: 1.0285e-10
Epoch 981/1000

Epoch 00981: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 9.8360e-11 - val_loss: 1.0946e-10
Epoch 982/1000

Epoch 00982: val_loss improved from 0.00000 to 0.00000, saving model to weights/weights-multiplication-addition-test-56-512b-0.1dr-new-dataset-con-sigmoid-aloss-more-add/multiplication_weights.h5
1024/1024 - 0s - loss: 1.2299e-10 - val_loss: 9.6003e-11
Epoch 983/1000

Epoch 00983: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.9141e-10 - val_loss: 2.5073e-10
Epoch 984/1000

Epoch 00984: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.6090e-10 - val_loss: 9.7768e-11
Epoch 985/1000

Epoch 00985: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.0629e-10 - val_loss: 9.6696e-11
Epoch 986/1000

Epoch 00986: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 9.9628e-11 - val_loss: 1.2503e-10
Epoch 987/1000

Epoch 00987: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.2708e-10 - val_loss: 1.1513e-10
Epoch 988/1000

Epoch 00988: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.3114e-10 - val_loss: 9.8695e-11
Epoch 989/1000

Epoch 00989: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.0586e-10 - val_loss: 1.6622e-10
Epoch 990/1000

Epoch 00990: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.6529e-10 - val_loss: 2.0555e-10
Epoch 991/1000

Epoch 00991: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.4729e-09 - val_loss: 2.0903e-08
Epoch 992/1000

Epoch 00992: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 8.0098e-09 - val_loss: 3.9455e-09
Epoch 993/1000

Epoch 00993: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.8025e-09 - val_loss: 1.2033e-10
Epoch 994/1000

Epoch 00994: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 4.5468e-10 - val_loss: 3.3471e-10
Epoch 995/1000

Epoch 00995: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 2.2659e-10 - val_loss: 1.6403e-10
Epoch 996/1000

Epoch 00996: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.2370e-10 - val_loss: 1.0901e-10
Epoch 997/1000

Epoch 00997: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.0769e-10 - val_loss: 1.0712e-10
Epoch 998/1000

Epoch 00998: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.0631e-10 - val_loss: 1.0382e-10
Epoch 999/1000

Epoch 00999: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.0444e-10 - val_loss: 1.0697e-10
Epoch 1000/1000

Epoch 01000: val_loss did not improve from 0.00000
1024/1024 - 0s - loss: 1.0428e-10 - val_loss: 1.0358e-10
WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?
WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?
Epoch   0:   0% | abe: 10.011 | eve: 9.536 | bob: 9.676Epoch   0:   0% | abe: 9.888 | eve: 9.541 | bob: 9.595Epoch   0:   1% | abe: 9.794 | eve: 9.534 | bob: 9.528Epoch   0:   2% | abe: 9.698 | eve: 9.530 | bob: 9.464Epoch   0:   3% | abe: 9.613 | eve: 9.531 | bob: 9.407Epoch   0:   3% | abe: 9.540 | eve: 9.540 | bob: 9.360Epoch   0:   4% | abe: 9.479 | eve: 9.540 | bob: 9.320Epoch   0:   5% | abe: 9.434 | eve: 9.546 | bob: 9.292Epoch   0:   6% | abe: 9.395 | eve: 9.546 | bob: 9.267Epoch   0:   7% | abe: 9.363 | eve: 9.547 | bob: 9.247Epoch   0:   7% | abe: 9.336 | eve: 9.548 | bob: 9.230Epoch   0:   8% | abe: 9.315 | eve: 9.553 | bob: 9.215Epoch   0:   9% | abe: 9.297 | eve: 9.554 | bob: 9.203Epoch   0:  10% | abe: 9.281 | eve: 9.555 | bob: 9.195Epoch   0:  10% | abe: 9.268 | eve: 9.556 | bob: 9.186Epoch   0:  11% | abe: 9.257 | eve: 9.559 | bob: 9.180Epoch   0:  12% | abe: 9.247 | eve: 9.563 | bob: 9.174Epoch   0:  13% | abe: 9.238 | eve: 9.566 | bob: 9.168Epoch   0:  14% | abe: 9.229 | eve: 9.569 | bob: 9.162Epoch   0:  14% | abe: 9.221 | eve: 9.575 | bob: 9.157Epoch   0:  15% | abe: 9.215 | eve: 9.579 | bob: 9.153Epoch   0:  16% | abe: 9.208 | eve: 9.581 | bob: 9.147Epoch   0:  17% | abe: 9.202 | eve: 9.588 | bob: 9.143Epoch   0:  17% | abe: 9.197 | eve: 9.591 | bob: 9.138Epoch   0:  18% | abe: 9.192 | eve: 9.594 | bob: 9.133Epoch   0:  19% | abe: 9.187 | eve: 9.597 | bob: 9.130Epoch   0:  20% | abe: 9.183 | eve: 9.600 | bob: 9.127Epoch   0:  21% | abe: 9.178 | eve: 9.602 | bob: 9.124Epoch   0:  21% | abe: 9.175 | eve: 9.606 | bob: 9.121Epoch   0:  22% | abe: 9.170 | eve: 9.609 | bob: 9.118Epoch   0:  23% | abe: 9.167 | eve: 9.612 | bob: 9.115Epoch   0:  24% | abe: 9.164 | eve: 9.614 | bob: 9.114Epoch   0:  25% | abe: 9.161 | eve: 9.617 | bob: 9.111Epoch   0:  25% | abe: 9.159 | eve: 9.620 | bob: 9.109Epoch   0:  26% | abe: 9.156 | eve: 9.624 | bob: 9.106Epoch   0:  27% | abe: 9.153 | eve: 9.628 | bob: 9.104Epoch   0:  28% | abe: 9.151 | eve: 9.631 | bob: 9.102Epoch   0:  28% | abe: 9.148 | eve: 9.634 | bob: 9.100Epoch   0:  29% | abe: 9.146 | eve: 9.638 | bob: 9.098Epoch   0:  30% | abe: 9.144 | eve: 9.642 | bob: 9.096Epoch   0:  31% | abe: 9.142 | eve: 9.646 | bob: 9.095Epoch   0:  32% | abe: 9.140 | eve: 9.649 | bob: 9.093Epoch   0:  32% | abe: 9.139 | eve: 9.652 | bob: 9.092Epoch   0:  33% | abe: 9.137 | eve: 9.656 | bob: 9.090Epoch   0:  34% | abe: 9.136 | eve: 9.659 | bob: 9.089Epoch   0:  35% | abe: 9.134 | eve: 9.662 | bob: 9.087Epoch   0:  35% | abe: 9.133 | eve: 9.665 | bob: 9.086Epoch   0:  36% | abe: 9.131 | eve: 9.668 | bob: 9.086Epoch   0:  37% | abe: 9.130 | eve: 9.670 | bob: 9.084Epoch   0:  38% | abe: 9.128 | eve: 9.673 | bob: 9.083Epoch   0:  39% | abe: 9.128 | eve: 9.677 | bob: 9.083Epoch   0:  39% | abe: 9.126 | eve: 9.682 | bob: 9.081Epoch   0:  40% | abe: 9.125 | eve: 9.685 | bob: 9.081Epoch   0:  41% | abe: 9.124 | eve: 9.688 | bob: 9.080Epoch   0:  42% | abe: 9.123 | eve: 9.691 | bob: 9.079Epoch   0:  42% | abe: 9.122 | eve: 9.694 | bob: 9.078Epoch   0:  43% | abe: 9.121 | eve: 9.697 | bob: 9.077Epoch   0:  44% | abe: 9.120 | eve: 9.700 | bob: 9.076Epoch   0:  45% | abe: 9.119 | eve: 9.703 | bob: 9.075Epoch   0:  46% | abe: 9.118 | eve: 9.706 | bob: 9.075Epoch   0:  46% | abe: 9.117 | eve: 9.710 | bob: 9.074Epoch   0:  47% | abe: 9.116 | eve: 9.713 | bob: 9.073Epoch   0:  48% | abe: 9.116 | eve: 9.715 | bob: 9.073Epoch   0:  49% | abe: 9.115 | eve: 9.717 | bob: 9.072Epoch   0:  50% | abe: 9.114 | eve: 9.721 | bob: 9.071Epoch   0:  50% | abe: 9.113 | eve: 9.724 | bob: 9.071Epoch   0:  51% | abe: 9.112 | eve: 9.727 | bob: 9.070Epoch   0:  52% | abe: 9.112 | eve: 9.730 | bob: 9.070Epoch   0:  53% | abe: 9.112 | eve: 9.733 | bob: 9.070Epoch   0:  53% | abe: 9.111 | eve: 9.736 | bob: 9.069Epoch   0:  54% | abe: 9.110 | eve: 9.738 | bob: 9.068Epoch   0:  55% | abe: 9.109 | eve: 9.741 | bob: 9.068Epoch   0:  56% | abe: 9.108 | eve: 9.744 | bob: 9.067Epoch   0:  57% | abe: 9.108 | eve: 9.747 | bob: 9.066Epoch   0:  57% | abe: 9.107 | eve: 9.750 | bob: 9.066Epoch   0:  58% | abe: 9.106 | eve: 9.752 | bob: 9.065Epoch   0:  59% | abe: 9.106 | eve: 9.754 | bob: 9.064Epoch   0:  60% | abe: 9.105 | eve: 9.756 | bob: 9.064Epoch   0:  60% | abe: 9.104 | eve: 9.759 | bob: 9.064Epoch   0:  61% | abe: 9.104 | eve: 9.760 | bob: 9.063Epoch   0:  62% | abe: 9.103 | eve: 9.762 | bob: 9.063Epoch   0:  63% | abe: 9.103 | eve: 9.764 | bob: 9.063Epoch   0:  64% | abe: 9.103 | eve: 9.766 | bob: 9.062Epoch   0:  64% | abe: 9.102 | eve: 9.769 | bob: 9.062Epoch   0:  65% | abe: 9.102 | eve: 9.771 | bob: 9.062Epoch   0:  66% | abe: 9.101 | eve: 9.773 | bob: 9.061Epoch   0:  67% | abe: 9.101 | eve: 9.775 | bob: 9.061Epoch   0:  67% | abe: 9.100 | eve: 9.777 | bob: 9.060Epoch   0:  68% | abe: 9.100 | eve: 9.779 | bob: 9.060Epoch   0:  69% | abe: 9.099 | eve: 9.780 | bob: 9.060Epoch   0:  70% | abe: 9.099 | eve: 9.782 | bob: 9.059Epoch   0:  71% | abe: 9.099 | eve: 9.784 | bob: 9.059Epoch   0:  71% | abe: 9.098 | eve: 9.786 | bob: 9.059Epoch   0:  72% | abe: 9.098 | eve: 9.788 | bob: 9.058Epoch   0:  73% | abe: 9.097 | eve: 9.790 | bob: 9.058Epoch   0:  74% | abe: 9.097 | eve: 9.791 | bob: 9.057Epoch   0:  75% | abe: 9.096 | eve: 9.793 | bob: 9.057Epoch   0:  75% | abe: 9.096 | eve: 9.795 | bob: 9.057Epoch   0:  76% | abe: 9.095 | eve: 9.796 | bob: 9.057Epoch   0:  77% | abe: 9.095 | eve: 9.798 | bob: 9.056Epoch   0:  78% | abe: 9.094 | eve: 9.799 | bob: 9.056Epoch   0:  78% | abe: 9.094 | eve: 9.801 | bob: 9.056Epoch   0:  79% | abe: 9.093 | eve: 9.802 | bob: 9.055Epoch   0:  80% | abe: 9.093 | eve: 9.803 | bob: 9.055Epoch   0:  81% | abe: 9.093 | eve: 9.805 | bob: 9.055Epoch   0:  82% | abe: 9.092 | eve: 9.806 | bob: 9.054Epoch   0:  82% | abe: 9.092 | eve: 9.807 | bob: 9.054Epoch   0:  83% | abe: 9.092 | eve: 9.808 | bob: 9.054Epoch   0:  84% | abe: 9.091 | eve: 9.809 | bob: 9.053Epoch   0:  85% | abe: 9.091 | eve: 9.811 | bob: 9.052Epoch   0:  85% | abe: 9.090 | eve: 9.812 | bob: 9.052Epoch   0:  86% | abe: 9.090 | eve: 9.814 | bob: 9.052Epoch   0:  87% | abe: 9.090 | eve: 9.815 | bob: 9.052Epoch   0:  88% | abe: 9.090 | eve: 9.817 | bob: 9.052Epoch   0:  89% | abe: 9.089 | eve: 9.818 | bob: 9.051Epoch   0:  89% | abe: 9.089 | eve: 9.819 | bob: 9.051Epoch   0:  90% | abe: 9.089 | eve: 9.820 | bob: 9.051Epoch   0:  91% | abe: 9.089 | eve: 9.821 | bob: 9.051Epoch   0:  92% | abe: 9.089 | eve: 9.822 | bob: 9.051Epoch   0:  92% | abe: 9.088 | eve: 9.823 | bob: 9.051Epoch   0:  93% | abe: 9.088 | eve: 9.824 | bob: 9.051Epoch   0:  94% | abe: 9.087 | eve: 9.825 | bob: 9.050Epoch   0:  95% | abe: 9.087 | eve: 9.826 | bob: 9.050Epoch   0:  96% | abe: 9.087 | eve: 9.827 | bob: 9.050Epoch   0:  96% | abe: 9.086 | eve: 9.828 | bob: 9.049Epoch   0:  97% | abe: 9.086 | eve: 9.828 | bob: 9.049Epoch   0:  98% | abe: 9.086 | eve: 9.830 | bob: 9.048Epoch   0:  99% | abe: 9.086 | eve: 9.831 | bob: 9.049
New best Bob loss 9.048503552515967 at epoch 0
Epoch   1:   0% | abe: 9.073 | eve: 9.948 | bob: 9.047Epoch   1:   0% | abe: 9.064 | eve: 9.951 | bob: 9.029Epoch   1:   1% | abe: 9.052 | eve: 9.946 | bob: 9.016Epoch   1:   2% | abe: 9.048 | eve: 9.948 | bob: 9.016Epoch   1:   3% | abe: 9.052 | eve: 9.951 | bob: 9.019Epoch   1:   3% | abe: 9.053 | eve: 9.956 | bob: 9.024Epoch   1:   4% | abe: 9.055 | eve: 9.959 | bob: 9.026Epoch   1:   5% | abe: 9.051 | eve: 9.962 | bob: 9.022Epoch   1:   6% | abe: 9.054 | eve: 9.963 | bob: 9.026Epoch   1:   7% | abe: 9.054 | eve: 9.971 | bob: 9.024Epoch   1:   7% | abe: 9.051 | eve: 9.966 | bob: 9.024Epoch   1:   8% | abe: 9.051 | eve: 9.968 | bob: 9.023Epoch   1:   9% | abe: 9.049 | eve: 9.974 | bob: 9.023Epoch   1:  10% | abe: 9.050 | eve: 9.975 | bob: 9.025Epoch   1:  10% | abe: 9.050 | eve: 9.976 | bob: 9.024Epoch   1:  11% | abe: 9.050 | eve: 9.975 | bob: 9.024Epoch   1:  12% | abe: 9.048 | eve: 9.976 | bob: 9.024Epoch   1:  13% | abe: 9.048 | eve: 9.975 | bob: 9.022Epoch   1:  14% | abe: 9.047 | eve: 9.974 | bob: 9.020Epoch   1:  14% | abe: 9.047 | eve: 9.973 | bob: 9.021Epoch   1:  15% | abe: 9.047 | eve: 9.972 | bob: 9.019Epoch   1:  16% | abe: 9.047 | eve: 9.973 | bob: 9.019Epoch   1:  17% | abe: 9.047 | eve: 9.976 | bob: 9.018Epoch   1:  17% | abe: 9.047 | eve: 9.976 | bob: 9.019Epoch   1:  18% | abe: 9.046 | eve: 9.977 | bob: 9.017Epoch   1:  19% | abe: 9.047 | eve: 9.976 | bob: 9.017Epoch   1:  20% | abe: 9.046 | eve: 9.976 | bob: 9.016Epoch   1:  21% | abe: 9.045 | eve: 9.973 | bob: 9.015Epoch   1:  21% | abe: 9.046 | eve: 9.973 | bob: 9.015Epoch   1:  22% | abe: 9.045 | eve: 9.973 | bob: 9.015Epoch   1:  23% | abe: 9.045 | eve: 9.972 | bob: 9.014Epoch   1:  24% | abe: 9.044 | eve: 9.972 | bob: 9.013Epoch   1:  25% | abe: 9.044 | eve: 9.971 | bob: 9.014Epoch   1:  25% | abe: 9.043 | eve: 9.971 | bob: 9.013Epoch   1:  26% | abe: 9.043 | eve: 9.972 | bob: 9.013Epoch   1:  27% | abe: 9.042 | eve: 9.971 | bob: 9.012Epoch   1:  28% | abe: 9.042 | eve: 9.971 | bob: 9.011Epoch   1:  28% | abe: 9.042 | eve: 9.970 | bob: 9.011Epoch   1:  29% | abe: 9.041 | eve: 9.969 | bob: 9.010Epoch   1:  30% | abe: 9.041 | eve: 9.968 | bob: 9.010Epoch   1:  31% | abe: 9.041 | eve: 9.967 | bob: 9.009Epoch   1:  32% | abe: 9.040 | eve: 9.966 | bob: 9.009Epoch   1:  32% | abe: 9.040 | eve: 9.965 | bob: 9.008Epoch   1:  33% | abe: 9.040 | eve: 9.965 | bob: 9.008Epoch   1:  34% | abe: 9.039 | eve: 9.967 | bob: 9.007Epoch   1:  35% | abe: 9.038 | eve: 9.965 | bob: 9.006Epoch   1:  35% | abe: 9.039 | eve: 9.965 | bob: 9.006Epoch   1:  36% | abe: 9.038 | eve: 9.965 | bob: 9.006Epoch   1:  37% | abe: 9.038 | eve: 9.964 | bob: 9.005Epoch   1:  38% | abe: 9.038 | eve: 9.964 | bob: 9.004Epoch   1:  39% | abe: 9.037 | eve: 9.964 | bob: 9.004Epoch   1:  39% | abe: 9.037 | eve: 9.964 | bob: 9.004Epoch   1:  40% | abe: 9.037 | eve: 9.965 | bob: 9.003Epoch   1:  41% | abe: 9.036 | eve: 9.965 | bob: 9.002Epoch   1:  42% | abe: 9.036 | eve: 9.964 | bob: 9.002Epoch   1:  42% | abe: 9.036 | eve: 9.963 | bob: 9.001Epoch   1:  43% | abe: 9.035 | eve: 9.963 | bob: 9.001Epoch   1:  44% | abe: 9.035 | eve: 9.963 | bob: 9.000Epoch   1:  45% | abe: 9.035 | eve: 9.962 | bob: 9.000Epoch   1:  46% | abe: 9.035 | eve: 9.961 | bob: 9.000Epoch   1:  46% | abe: 9.034 | eve: 9.961 | bob: 9.000Epoch   1:  47% | abe: 9.034 | eve: 9.960 | bob: 8.999Epoch   1:  48% | abe: 9.033 | eve: 9.960 | bob: 8.998Epoch   1:  49% | abe: 9.033 | eve: 9.959 | bob: 8.998Epoch   1:  50% | abe: 9.032 | eve: 9.959 | bob: 8.997Epoch   1:  50% | abe: 9.032 | eve: 9.959 | bob: 8.997Epoch   1:  51% | abe: 9.032 | eve: 9.959 | bob: 8.996Epoch   1:  52% | abe: 9.032 | eve: 9.958 | bob: 8.996Epoch   1:  53% | abe: 9.031 | eve: 9.958 | bob: 8.995Epoch   1:  53% | abe: 9.031 | eve: 9.959 | bob: 8.995Epoch   1:  54% | abe: 9.030 | eve: 9.958 | bob: 8.994Epoch   1:  55% | abe: 9.030 | eve: 9.958 | bob: 8.994Epoch   1:  56% | abe: 9.029 | eve: 9.957 | bob: 8.993Epoch   1:  57% | abe: 9.029 | eve: 9.957 | bob: 8.992Epoch   1:  57% | abe: 9.028 | eve: 9.956 | bob: 8.992Epoch   1:  58% | abe: 9.028 | eve: 9.957 | bob: 8.991Epoch   1:  59% | abe: 9.028 | eve: 9.956 | bob: 8.991Epoch   1:  60% | abe: 9.028 | eve: 9.955 | bob: 8.991Epoch   1:  60% | abe: 9.027 | eve: 9.955 | bob: 8.990Epoch   1:  61% | abe: 9.027 | eve: 9.954 | bob: 8.990Epoch   1:  62% | abe: 9.027 | eve: 9.954 | bob: 8.989Epoch   1:  63% | abe: 9.026 | eve: 9.953 | bob: 8.989Epoch   1:  64% | abe: 9.026 | eve: 9.953 | bob: 8.989Epoch   1:  64% | abe: 9.026 | eve: 9.952 | bob: 8.989Epoch   1:  65% | abe: 9.026 | eve: 9.952 | bob: 8.988Epoch   1:  66% | abe: 9.025 | eve: 9.951 | bob: 8.987Epoch   1:  67% | abe: 9.024 | eve: 9.951 | bob: 8.987Epoch   1:  67% | abe: 9.024 | eve: 9.950 | bob: 8.986Epoch   1:  68% | abe: 9.023 | eve: 9.950 | bob: 8.985Epoch   1:  69% | abe: 9.023 | eve: 9.949 | bob: 8.984Epoch   1:  70% | abe: 9.023 | eve: 9.949 | bob: 8.984Epoch   1:  71% | abe: 9.022 | eve: 9.948 | bob: 8.983Epoch   1:  71% | abe: 9.022 | eve: 9.948 | bob: 8.982Epoch   1:  72% | abe: 9.021 | eve: 9.947 | bob: 8.981Epoch   1:  73% | abe: 9.021 | eve: 9.947 | bob: 8.981Epoch   1:  74% | abe: 9.020 | eve: 9.947 | bob: 8.981Epoch   1:  75% | abe: 9.019 | eve: 9.946 | bob: 8.980Epoch   1:  75% | abe: 9.018 | eve: 9.946 | bob: 8.978Epoch   1:  76% | abe: 9.018 | eve: 9.945 | bob: 8.978Epoch   1:  77% | abe: 9.017 | eve: 9.945 | bob: 8.977Epoch   1:  78% | abe: 9.016 | eve: 9.944 | bob: 8.976Epoch   1:  78% | abe: 9.016 | eve: 9.944 | bob: 8.975Epoch   1:  79% | abe: 9.015 | eve: 9.943 | bob: 8.974Epoch   1:  80% | abe: 9.014 | eve: 9.943 | bob: 8.973Epoch   1:  81% | abe: 9.014 | eve: 9.943 | bob: 8.972Epoch   1:  82% | abe: 9.013 | eve: 9.943 | bob: 8.972Epoch   1:  82% | abe: 9.013 | eve: 9.943 | bob: 8.971Epoch   1:  83% | abe: 9.012 | eve: 9.942 | bob: 8.970Epoch   1:  84% | abe: 9.012 | eve: 9.942 | bob: 8.970Epoch   1:  85% | abe: 9.011 | eve: 9.942 | bob: 8.969Epoch   1:  85% | abe: 9.011 | eve: 9.942 | bob: 8.969Epoch   1:  86% | abe: 9.010 | eve: 9.941 | bob: 8.968Epoch   1:  87% | abe: 9.009 | eve: 9.941 | bob: 8.967Epoch   1:  88% | abe: 9.009 | eve: 9.941 | bob: 8.967Epoch   1:  89% | abe: 9.008 | eve: 9.941 | bob: 8.966Epoch   1:  89% | abe: 9.008 | eve: 9.941 | bob: 8.965Epoch   1:  90% | abe: 9.007 | eve: 9.941 | bob: 8.965Epoch   1:  91% | abe: 9.006 | eve: 9.941 | bob: 8.964Epoch   1:  92% | abe: 9.006 | eve: 9.940 | bob: 8.963Epoch   1:  92% | abe: 9.005 | eve: 9.941 | bob: 8.963Epoch   1:  93% | abe: 9.004 | eve: 9.940 | bob: 8.962Epoch   1:  94% | abe: 9.004 | eve: 9.941 | bob: 8.961Epoch   1:  95% | abe: 9.003 | eve: 9.940 | bob: 8.961Epoch   1:  96% | abe: 9.003 | eve: 9.940 | bob: 8.960Epoch   1:  96% | abe: 9.002 | eve: 9.940 | bob: 8.960Epoch   1:  97% | abe: 9.002 | eve: 9.939 | bob: 8.959Epoch   1:  98% | abe: 9.001 | eve: 9.939 | bob: 8.958Epoch   1:  99% | abe: 9.001 | eve: 9.939 | bob: 8.958
New best Bob loss 8.957570876336376 at epoch 1
Epoch   2:   0% | abe: 8.902 | eve: 9.917 | bob: 8.842Epoch   2:   0% | abe: 8.911 | eve: 9.927 | bob: 8.863Epoch   2:   1% | abe: 8.906 | eve: 9.909 | bob: 8.850Epoch   2:   2% | abe: 8.909 | eve: 9.926 | bob: 8.846Epoch   2:   3% | abe: 8.907 | eve: 9.926 | bob: 8.843Epoch   2:   3% | abe: 8.909 | eve: 9.915 | bob: 8.849Epoch   2:   4% | abe: 8.912 | eve: 9.914 | bob: 8.853Epoch   2:   5% | abe: 8.909 | eve: 9.912 | bob: 8.853Epoch   2:   6% | abe: 8.906 | eve: 9.912 | bob: 8.849Epoch   2:   7% | abe: 8.906 | eve: 9.915 | bob: 8.849Epoch   2:   7% | abe: 8.903 | eve: 9.913 | bob: 8.846Epoch   2:   8% | abe: 8.903 | eve: 9.913 | bob: 8.845Epoch   2:   9% | abe: 8.902 | eve: 9.914 | bob: 8.845Epoch   2:  10% | abe: 8.901 | eve: 9.913 | bob: 8.843Epoch   2:  10% | abe: 8.899 | eve: 9.911 | bob: 8.841Epoch   2:  11% | abe: 8.898 | eve: 9.913 | bob: 8.839Epoch   2:  12% | abe: 8.899 | eve: 9.910 | bob: 8.840Epoch   2:  13% | abe: 8.898 | eve: 9.910 | bob: 8.838Epoch   2:  14% | abe: 8.896 | eve: 9.909 | bob: 8.836Epoch   2:  14% | abe: 8.895 | eve: 9.911 | bob: 8.834Epoch   2:  15% | abe: 8.894 | eve: 9.908 | bob: 8.833Epoch   2:  16% | abe: 8.892 | eve: 9.909 | bob: 8.832Epoch   2:  17% | abe: 8.891 | eve: 9.909 | bob: 8.829Epoch   2:  17% | abe: 8.889 | eve: 9.907 | bob: 8.828Epoch   2:  18% | abe: 8.887 | eve: 9.908 | bob: 8.825Epoch   2:  19% | abe: 8.886 | eve: 9.907 | bob: 8.824Epoch   2:  20% | abe: 8.884 | eve: 9.907 | bob: 8.822Epoch   2:  21% | abe: 8.883 | eve: 9.907 | bob: 8.822Epoch   2:  21% | abe: 8.883 | eve: 9.907 | bob: 8.822Epoch   2:  22% | abe: 8.881 | eve: 9.904 | bob: 8.820Epoch   2:  23% | abe: 8.879 | eve: 9.901 | bob: 8.817Epoch   2:  24% | abe: 8.877 | eve: 9.899 | bob: 8.815Epoch   2:  25% | abe: 8.876 | eve: 9.898 | bob: 8.812Epoch   2:  25% | abe: 8.875 | eve: 9.898 | bob: 8.812Epoch   2:  26% | abe: 8.873 | eve: 9.897 | bob: 8.809Epoch   2:  27% | abe: 8.872 | eve: 9.896 | bob: 8.808Epoch   2:  28% | abe: 8.870 | eve: 9.896 | bob: 8.805Epoch   2:  28% | abe: 8.868 | eve: 9.896 | bob: 8.804Epoch   2:  29% | abe: 8.867 | eve: 9.895 | bob: 8.802Epoch   2:  30% | abe: 8.866 | eve: 9.895 | bob: 8.800Epoch   2:  31% | abe: 8.864 | eve: 9.895 | bob: 8.798Epoch   2:  32% | abe: 8.862 | eve: 9.893 | bob: 8.796Epoch   2:  32% | abe: 8.860 | eve: 9.893 | bob: 8.794Epoch   2:  33% | abe: 8.858 | eve: 9.892 | bob: 8.792Epoch   2:  34% | abe: 8.857 | eve: 9.892 | bob: 8.791Epoch   2:  35% | abe: 8.855 | eve: 9.892 | bob: 8.789Epoch   2:  35% | abe: 8.854 | eve: 9.892 | bob: 8.787Epoch   2:  36% | abe: 8.853 | eve: 9.892 | bob: 8.787Epoch   2:  37% | abe: 8.851 | eve: 9.892 | bob: 8.785Epoch   2:  38% | abe: 8.849 | eve: 9.893 | bob: 8.783Epoch   2:  39% | abe: 8.848 | eve: 9.893 | bob: 8.781Epoch   2:  39% | abe: 8.846 | eve: 9.894 | bob: 8.779Epoch   2:  40% | abe: 8.844 | eve: 9.894 | bob: 8.777Epoch   2:  41% | abe: 8.843 | eve: 9.894 | bob: 8.775Epoch   2:  42% | abe: 8.841 | eve: 9.894 | bob: 8.773Epoch   2:  42% | abe: 8.839 | eve: 9.894 | bob: 8.771Epoch   2:  43% | abe: 8.837 | eve: 9.895 | bob: 8.769Epoch   2:  44% | abe: 8.836 | eve: 9.896 | bob: 8.768Epoch   2:  45% | abe: 8.834 | eve: 9.895 | bob: 8.765Epoch   2:  46% | abe: 8.832 | eve: 9.895 | bob: 8.764Epoch   2:  46% | abe: 8.831 | eve: 9.894 | bob: 8.762Epoch   2:  47% | abe: 8.829 | eve: 9.894 | bob: 8.759Epoch   2:  48% | abe: 8.826 | eve: 9.894 | bob: 8.757Epoch   2:  49% | abe: 8.825 | eve: 9.893 | bob: 8.756Epoch   2:  50% | abe: 8.823 | eve: 9.893 | bob: 8.753Epoch   2:  50% | abe: 8.821 | eve: 9.894 | bob: 8.752Epoch   2:  51% | abe: 8.820 | eve: 9.893 | bob: 8.751Epoch   2:  52% | abe: 8.818 | eve: 9.893 | bob: 8.749Epoch   2:  53% | abe: 8.815 | eve: 9.893 | bob: 8.746Epoch   2:  53% | abe: 8.814 | eve: 9.893 | bob: 8.744Epoch   2:  54% | abe: 8.812 | eve: 9.893 | bob: 8.743Epoch   2:  55% | abe: 8.810 | eve: 9.893 | bob: 8.740Epoch   2:  56% | abe: 8.808 | eve: 9.893 | bob: 8.738Epoch   2:  57% | abe: 8.806 | eve: 9.893 | bob: 8.736Epoch   2:  57% | abe: 8.804 | eve: 9.892 | bob: 8.734Epoch   2:  58% | abe: 8.802 | eve: 9.893 | bob: 8.732Epoch   2:  59% | abe: 8.800 | eve: 9.892 | bob: 8.730Epoch   2:  60% | abe: 8.797 | eve: 9.893 | bob: 8.727Epoch   2:  60% | abe: 8.796 | eve: 9.892 | bob: 8.726Epoch   2:  61% | abe: 8.793 | eve: 9.892 | bob: 8.724Epoch   2:  62% | abe: 8.792 | eve: 9.892 | bob: 8.722Epoch   2:  63% | abe: 8.789 | eve: 9.892 | bob: 8.719Epoch   2:  64% | abe: 8.787 | eve: 9.892 | bob: 8.717Epoch   2:  64% | abe: 8.785 | eve: 9.891 | bob: 8.715Epoch   2:  65% | abe: 8.783 | eve: 9.891 | bob: 8.713Epoch   2:  66% | abe: 8.781 | eve: 9.890 | bob: 8.710Epoch   2:  67% | abe: 8.779 | eve: 9.890 | bob: 8.708Epoch   2:  67% | abe: 8.777 | eve: 9.890 | bob: 8.706Epoch   2:  68% | abe: 8.775 | eve: 9.890 | bob: 8.704Epoch   2:  69% | abe: 8.772 | eve: 9.890 | bob: 8.701Epoch   2:  70% | abe: 8.770 | eve: 9.890 | bob: 8.699Epoch   2:  71% | abe: 8.768 | eve: 9.889 | bob: 8.697Epoch   2:  71% | abe: 8.765 | eve: 9.889 | bob: 8.694Epoch   2:  72% | abe: 8.763 | eve: 9.889 | bob: 8.692Epoch   2:  73% | abe: 8.761 | eve: 9.889 | bob: 8.690Epoch   2:  74% | abe: 8.759 | eve: 9.889 | bob: 8.687Epoch   2:  75% | abe: 8.756 | eve: 9.889 | bob: 8.685Epoch   2:  75% | abe: 8.754 | eve: 9.889 | bob: 8.682Epoch   2:  76% | abe: 8.751 | eve: 9.888 | bob: 8.680Epoch   2:  77% | abe: 8.749 | eve: 9.888 | bob: 8.678Epoch   2:  78% | abe: 8.746 | eve: 9.887 | bob: 8.675Epoch   2:  78% | abe: 8.743 | eve: 9.887 | bob: 8.672Epoch   2:  79% | abe: 8.741 | eve: 9.886 | bob: 8.670Epoch   2:  80% | abe: 8.738 | eve: 9.887 | bob: 8.667Epoch   2:  81% | abe: 8.736 | eve: 9.886 | bob: 8.665Epoch   2:  82% | abe: 8.733 | eve: 9.887 | bob: 8.662Epoch   2:  82% | abe: 8.731 | eve: 9.886 | bob: 8.660Epoch   2:  83% | abe: 8.728 | eve: 9.886 | bob: 8.657Epoch   2:  84% | abe: 8.726 | eve: 9.886 | bob: 8.655Epoch   2:  85% | abe: 8.723 | eve: 9.886 | bob: 8.652Epoch   2:  85% | abe: 8.720 | eve: 9.886 | bob: 8.649Epoch   2:  86% | abe: 8.718 | eve: 9.885 | bob: 8.647Epoch   2:  87% | abe: 8.715 | eve: 9.886 | bob: 8.644Epoch   2:  88% | abe: 8.712 | eve: 9.886 | bob: 8.641Epoch   2:  89% | abe: 8.710 | eve: 9.885 | bob: 8.638Epoch   2:  89% | abe: 8.707 | eve: 9.885 | bob: 8.636Epoch   2:  90% | abe: 8.704 | eve: 9.885 | bob: 8.633Epoch   2:  91% | abe: 8.701 | eve: 9.885 | bob: 8.630Epoch   2:  92% | abe: 8.698 | eve: 9.885 | bob: 8.627Epoch   2:  92% | abe: 8.696 | eve: 9.886 | bob: 8.624Epoch   2:  93% | abe: 8.693 | eve: 9.886 | bob: 8.622Epoch   2:  94% | abe: 8.690 | eve: 9.885 | bob: 8.619Epoch   2:  95% | abe: 8.688 | eve: 9.885 | bob: 8.617Epoch   2:  96% | abe: 8.685 | eve: 9.885 | bob: 8.614Epoch   2:  96% | abe: 8.682 | eve: 9.885 | bob: 8.611Epoch   2:  97% | abe: 8.680 | eve: 9.885 | bob: 8.609Epoch   2:  98% | abe: 8.677 | eve: 9.885 | bob: 8.606Epoch   2:  99% | abe: 8.674 | eve: 9.884 | bob: 8.603
New best Bob loss 8.602817321029534 at epoch 2
Epoch   3:   0% | abe: 8.292 | eve: 9.870 | bob: 8.219Epoch   3:   0% | abe: 8.292 | eve: 9.878 | bob: 8.216Epoch   3:   1% | abe: 8.283 | eve: 9.855 | bob: 8.205Epoch   3:   2% | abe: 8.284 | eve: 9.853 | bob: 8.208Epoch   3:   3% | abe: 8.277 | eve: 9.864 | bob: 8.205Epoch   3:   3% | abe: 8.271 | eve: 9.864 | bob: 8.201Epoch   3:   4% | abe: 8.269 | eve: 9.860 | bob: 8.197Epoch   3:   5% | abe: 8.262 | eve: 9.864 | bob: 8.189Epoch   3:   6% | abe: 8.258 | eve: 9.863 | bob: 8.187Epoch   3:   7% | abe: 8.255 | eve: 9.866 | bob: 8.186Epoch   3:   7% | abe: 8.252 | eve: 9.872 | bob: 8.183Epoch   3:   8% | abe: 8.252 | eve: 9.873 | bob: 8.185Epoch   3:   9% | abe: 8.246 | eve: 9.874 | bob: 8.180Epoch   3:  10% | abe: 8.242 | eve: 9.876 | bob: 8.175Epoch   3:  10% | abe: 8.238 | eve: 9.878 | bob: 8.171Epoch   3:  11% | abe: 8.234 | eve: 9.875 | bob: 8.169Epoch   3:  12% | abe: 8.229 | eve: 9.877 | bob: 8.165Epoch   3:  13% | abe: 8.224 | eve: 9.878 | bob: 8.159Epoch   3:  14% | abe: 8.220 | eve: 9.880 | bob: 8.155Epoch   3:  14% | abe: 8.215 | eve: 9.876 | bob: 8.150Epoch   3:  15% | abe: 8.211 | eve: 9.874 | bob: 8.146Epoch   3:  16% | abe: 8.207 | eve: 9.875 | bob: 8.142Epoch   3:  17% | abe: 8.202 | eve: 9.875 | bob: 8.138Epoch   3:  17% | abe: 8.198 | eve: 9.876 | bob: 8.136Epoch   3:  18% | abe: 8.193 | eve: 9.874 | bob: 8.130Epoch   3:  19% | abe: 8.189 | eve: 9.876 | bob: 8.125Epoch   3:  20% | abe: 8.184 | eve: 9.878 | bob: 8.120Epoch   3:  21% | abe: 8.180 | eve: 9.876 | bob: 8.116Epoch   3:  21% | abe: 8.176 | eve: 9.874 | bob: 8.113Epoch   3:  22% | abe: 8.171 | eve: 9.874 | bob: 8.108Epoch   3:  23% | abe: 8.166 | eve: 9.874 | bob: 8.104Epoch   3:  24% | abe: 8.161 | eve: 9.874 | bob: 8.098Epoch   3:  25% | abe: 8.157 | eve: 9.872 | bob: 8.095Epoch   3:  25% | abe: 8.151 | eve: 9.873 | bob: 8.090Epoch   3:  26% | abe: 8.147 | eve: 9.872 | bob: 8.085Epoch   3:  27% | abe: 8.142 | eve: 9.871 | bob: 8.080Epoch   3:  28% | abe: 8.137 | eve: 9.872 | bob: 8.075Epoch   3:  28% | abe: 8.133 | eve: 9.870 | bob: 8.071Epoch   3:  29% | abe: 8.128 | eve: 9.869 | bob: 8.066Epoch   3:  30% | abe: 8.123 | eve: 9.870 | bob: 8.061Epoch   3:  31% | abe: 8.118 | eve: 9.870 | bob: 8.056Epoch   3:  32% | abe: 8.114 | eve: 9.872 | bob: 8.052Epoch   3:  32% | abe: 8.109 | eve: 9.872 | bob: 8.048Epoch   3:  33% | abe: 8.104 | eve: 9.872 | bob: 8.043Epoch   3:  34% | abe: 8.100 | eve: 9.873 | bob: 8.039Epoch   3:  35% | abe: 8.095 | eve: 9.873 | bob: 8.035Epoch   3:  35% | abe: 8.090 | eve: 9.873 | bob: 8.030Epoch   3:  36% | abe: 8.086 | eve: 9.873 | bob: 8.026Epoch   3:  37% | abe: 8.081 | eve: 9.873 | bob: 8.021Epoch   3:  38% | abe: 8.076 | eve: 9.873 | bob: 8.017Epoch   3:  39% | abe: 8.071 | eve: 9.874 | bob: 8.011Epoch   3:  39% | abe: 8.066 | eve: 9.873 | bob: 8.007Epoch   3:  40% | abe: 8.061 | eve: 9.873 | bob: 8.002Epoch   3:  41% | abe: 8.057 | eve: 9.874 | bob: 7.997Epoch   3:  42% | abe: 8.052 | eve: 9.874 | bob: 7.993Epoch   3:  42% | abe: 8.047 | eve: 9.874 | bob: 7.989Epoch   3:  43% | abe: 8.042 | eve: 9.873 | bob: 7.984Epoch   3:  44% | abe: 8.038 | eve: 9.873 | bob: 7.979Epoch   3:  45% | abe: 8.033 | eve: 9.873 | bob: 7.974Epoch   3:  46% | abe: 8.028 | eve: 9.872 | bob: 7.969Epoch   3:  46% | abe: 8.023 | eve: 9.872 | bob: 7.965Epoch   3:  47% | abe: 8.018 | eve: 9.872 | bob: 7.960Epoch   3:  48% | abe: 8.013 | eve: 9.872 | bob: 7.955Epoch   3:  49% | abe: 8.008 | eve: 9.873 | bob: 7.951Epoch   3:  50% | abe: 8.003 | eve: 9.873 | bob: 7.946Epoch   3:  50% | abe: 7.998 | eve: 9.874 | bob: 7.941Epoch   3:  51% | abe: 7.993 | eve: 9.873 | bob: 7.936Epoch   3:  52% | abe: 7.988 | eve: 9.874 | bob: 7.931Epoch   3:  53% | abe: 7.984 | eve: 9.873 | bob: 7.927Epoch   3:  53% | abe: 7.979 | eve: 9.872 | bob: 7.922Epoch   3:  54% | abe: 7.974 | eve: 9.872 | bob: 7.917Epoch   3:  55% | abe: 7.968 | eve: 9.873 | bob: 7.912Epoch   3:  56% | abe: 7.963 | eve: 9.872 | bob: 7.908Epoch   3:  57% | abe: 7.959 | eve: 9.873 | bob: 7.903Epoch   3:  57% | abe: 7.954 | eve: 9.873 | bob: 7.899Epoch   3:  58% | abe: 7.948 | eve: 9.874 | bob: 7.893Epoch   3:  59% | abe: 7.943 | eve: 9.874 | bob: 7.888Epoch   3:  60% | abe: 7.938 | eve: 9.875 | bob: 7.884Epoch   3:  60% | abe: 7.933 | eve: 9.875 | bob: 7.879Epoch   3:  61% | abe: 7.928 | eve: 9.875 | bob: 7.874Epoch   3:  62% | abe: 7.923 | eve: 9.876 | bob: 7.869Epoch   3:  63% | abe: 7.918 | eve: 9.876 | bob: 7.864Epoch   3:  64% | abe: 7.912 | eve: 9.876 | bob: 7.859Epoch   3:  64% | abe: 7.907 | eve: 9.877 | bob: 7.854Epoch   3:  65% | abe: 7.902 | eve: 9.876 | bob: 7.849Epoch   3:  66% | abe: 7.897 | eve: 9.876 | bob: 7.844Epoch   3:  67% | abe: 7.892 | eve: 9.876 | bob: 7.839Epoch   3:  67% | abe: 7.887 | eve: 9.876 | bob: 7.833Epoch   3:  68% | abe: 7.881 | eve: 9.876 | bob: 7.828Epoch   3:  69% | abe: 7.876 | eve: 9.876 | bob: 7.823Epoch   3:  70% | abe: 7.871 | eve: 9.876 | bob: 7.819Epoch   3:  71% | abe: 7.866 | eve: 9.876 | bob: 7.814Epoch   3:  71% | abe: 7.861 | eve: 9.877 | bob: 7.809Epoch   3:  72% | abe: 7.856 | eve: 9.877 | bob: 7.804Epoch   3:  73% | abe: 7.850 | eve: 9.877 | bob: 7.799Epoch   3:  74% | abe: 7.845 | eve: 9.876 | bob: 7.794Epoch   3:  75% | abe: 7.840 | eve: 9.876 | bob: 7.789Epoch   3:  75% | abe: 7.835 | eve: 9.876 | bob: 7.784Epoch   3:  76% | abe: 7.829 | eve: 9.877 | bob: 7.779Epoch   3:  77% | abe: 7.824 | eve: 9.877 | bob: 7.774Epoch   3:  78% | abe: 7.819 | eve: 9.877 | bob: 7.769Epoch   3:  78% | abe: 7.814 | eve: 9.876 | bob: 7.764Epoch   3:  79% | abe: 7.808 | eve: 9.877 | bob: 7.759Epoch   3:  80% | abe: 7.803 | eve: 9.877 | bob: 7.753Epoch   3:  81% | abe: 7.798 | eve: 9.876 | bob: 7.749Epoch   3:  82% | abe: 7.793 | eve: 9.877 | bob: 7.744Epoch   3:  82% | abe: 7.788 | eve: 9.876 | bob: 7.739Epoch   3:  83% | abe: 7.782 | eve: 9.876 | bob: 7.734Epoch   3:  84% | abe: 7.777 | eve: 9.876 | bob: 7.729Epoch   3:  85% | abe: 7.772 | eve: 9.876 | bob: 7.724Epoch   3:  85% | abe: 7.766 | eve: 9.876 | bob: 7.718Epoch   3:  86% | abe: 7.761 | eve: 9.876 | bob: 7.713Epoch   3:  87% | abe: 7.756 | eve: 9.876 | bob: 7.708Epoch   3:  88% | abe: 7.750 | eve: 9.875 | bob: 7.703Epoch   3:  89% | abe: 7.745 | eve: 9.876 | bob: 7.698Epoch   3:  89% | abe: 7.740 | eve: 9.875 | bob: 7.693Epoch   3:  90% | abe: 7.735 | eve: 9.876 | bob: 7.688Epoch   3:  91% | abe: 7.729 | eve: 9.875 | bob: 7.683Epoch   3:  92% | abe: 7.724 | eve: 9.875 | bob: 7.678Epoch   3:  92% | abe: 7.719 | eve: 9.875 | bob: 7.673Epoch   3:  93% | abe: 7.714 | eve: 9.875 | bob: 7.668Epoch   3:  94% | abe: 7.709 | eve: 9.875 | bob: 7.663Epoch   3:  95% | abe: 7.703 | eve: 9.875 | bob: 7.658Epoch   3:  96% | abe: 7.698 | eve: 9.874 | bob: 7.652Epoch   3:  96% | abe: 7.692 | eve: 9.874 | bob: 7.647Epoch   3:  97% | abe: 7.687 | eve: 9.874 | bob: 7.642Epoch   3:  98% | abe: 7.682 | eve: 9.874 | bob: 7.637Epoch   3:  99% | abe: 7.677 | eve: 9.874 | bob: 7.632
New best Bob loss 7.631949454542109 at epoch 3
Epoch   4:   0% | abe: 6.992 | eve: 9.889 | bob: 6.960Epoch   4:   0% | abe: 6.995 | eve: 9.902 | bob: 6.966Epoch   4:   1% | abe: 6.984 | eve: 9.911 | bob: 6.956Epoch   4:   2% | abe: 6.977 | eve: 9.902 | bob: 6.951Epoch   4:   3% | abe: 6.974 | eve: 9.899 | bob: 6.949Epoch   4:   3% | abe: 6.969 | eve: 9.906 | bob: 6.946Epoch   4:   4% | abe: 6.962 | eve: 9.894 | bob: 6.939Epoch   4:   5% | abe: 6.956 | eve: 9.891 | bob: 6.934Epoch   4:   6% | abe: 6.950 | eve: 9.888 | bob: 6.931Epoch   4:   7% | abe: 6.944 | eve: 9.887 | bob: 6.923Epoch   4:   7% | abe: 6.938 | eve: 9.883 | bob: 6.917Epoch   4:   8% | abe: 6.934 | eve: 9.883 | bob: 6.913Epoch   4:   9% | abe: 6.928 | eve: 9.882 | bob: 6.909Epoch   4:  10% | abe: 6.923 | eve: 9.881 | bob: 6.902Epoch   4:  10% | abe: 6.917 | eve: 9.883 | bob: 6.897Epoch   4:  11% | abe: 6.912 | eve: 9.881 | bob: 6.892Epoch   4:  12% | abe: 6.907 | eve: 9.883 | bob: 6.886Epoch   4:  13% | abe: 6.901 | eve: 9.883 | bob: 6.882Epoch   4:  14% | abe: 6.896 | eve: 9.883 | bob: 6.876Epoch   4:  14% | abe: 6.891 | eve: 9.883 | bob: 6.871Epoch   4:  15% | abe: 6.886 | eve: 9.887 | bob: 6.867Epoch   4:  16% | abe: 6.881 | eve: 9.890 | bob: 6.861Epoch   4:  17% | abe: 6.876 | eve: 9.888 | bob: 6.856Epoch   4:  17% | abe: 6.870 | eve: 9.886 | bob: 6.851Epoch   4:  18% | abe: 6.865 | eve: 9.887 | bob: 6.847Epoch   4:  19% | abe: 6.859 | eve: 9.888 | bob: 6.841Epoch   4:  20% | abe: 6.855 | eve: 9.888 | bob: 6.835Epoch   4:  21% | abe: 6.849 | eve: 9.887 | bob: 6.831Epoch   4:  21% | abe: 6.844 | eve: 9.889 | bob: 6.826Epoch   4:  22% | abe: 6.839 | eve: 9.889 | bob: 6.820Epoch   4:  23% | abe: 6.834 | eve: 9.889 | bob: 6.815Epoch   4:  24% | abe: 6.829 | eve: 9.888 | bob: 6.810Epoch   4:  25% | abe: 6.823 | eve: 9.890 | bob: 6.805Epoch   4:  25% | abe: 6.818 | eve: 9.891 | bob: 6.800Epoch   4:  26% | abe: 6.813 | eve: 9.890 | bob: 6.795Epoch   4:  27% | abe: 6.808 | eve: 9.889 | bob: 6.790Epoch   4:  28% | abe: 6.803 | eve: 9.889 | bob: 6.785Epoch   4:  28% | abe: 6.798 | eve: 9.889 | bob: 6.780Epoch   4:  29% | abe: 6.793 | eve: 9.889 | bob: 6.775Epoch   4:  30% | abe: 6.788 | eve: 9.889 | bob: 6.770Epoch   4:  31% | abe: 6.783 | eve: 9.889 | bob: 6.765Epoch   4:  32% | abe: 6.778 | eve: 9.889 | bob: 6.761Epoch   4:  32% | abe: 6.772 | eve: 9.889 | bob: 6.756Epoch   4:  33% | abe: 6.768 | eve: 9.889 | bob: 6.752Epoch   4:  34% | abe: 6.763 | eve: 9.889 | bob: 6.747Epoch   4:  35% | abe: 6.758 | eve: 9.889 | bob: 6.741Epoch   4:  35% | abe: 6.753 | eve: 9.889 | bob: 6.737Epoch   4:  36% | abe: 6.747 | eve: 9.889 | bob: 6.732Epoch   4:  37% | abe: 6.742 | eve: 9.889 | bob: 6.726Epoch   4:  38% | abe: 6.737 | eve: 9.888 | bob: 6.721Epoch   4:  39% | abe: 6.733 | eve: 9.888 | bob: 6.717Epoch   4:  39% | abe: 6.727 | eve: 9.888 | bob: 6.712Epoch   4:  40% | abe: 6.723 | eve: 9.888 | bob: 6.707Epoch   4:  41% | abe: 6.718 | eve: 9.888 | bob: 6.703Epoch   4:  42% | abe: 6.713 | eve: 9.888 | bob: 6.698Epoch   4:  42% | abe: 6.708 | eve: 9.888 | bob: 6.693Epoch   4:  43% | abe: 6.703 | eve: 9.888 | bob: 6.688Epoch   4:  44% | abe: 6.698 | eve: 9.888 | bob: 6.684Epoch   4:  45% | abe: 6.693 | eve: 9.889 | bob: 6.679Epoch   4:  46% | abe: 6.689 | eve: 9.888 | bob: 6.674Epoch   4:  46% | abe: 6.684 | eve: 9.888 | bob: 6.669Epoch   4:  47% | abe: 6.679 | eve: 9.888 | bob: 6.665Epoch   4:  48% | abe: 6.674 | eve: 9.889 | bob: 6.660Epoch   4:  49% | abe: 6.669 | eve: 9.888 | bob: 6.655Epoch   4:  50% | abe: 6.664 | eve: 9.888 | bob: 6.651Epoch   4:  50% | abe: 6.659 | eve: 9.889 | bob: 6.647Epoch   4:  51% | abe: 6.655 | eve: 9.889 | bob: 6.642Epoch   4:  52% | abe: 6.650 | eve: 9.889 | bob: 6.637Epoch   4:  53% | abe: 6.645 | eve: 9.889 | bob: 6.633Epoch   4:  53% | abe: 6.640 | eve: 9.889 | bob: 6.628Epoch   4:  54% | abe: 6.636 | eve: 9.889 | bob: 6.623Epoch   4:  55% | abe: 6.631 | eve: 9.889 | bob: 6.619Epoch   4:  56% | abe: 6.626 | eve: 9.889 | bob: 6.614Epoch   4:  57% | abe: 6.621 | eve: 9.889 | bob: 6.609Epoch   4:  57% | abe: 6.616 | eve: 9.889 | bob: 6.604Epoch   4:  58% | abe: 6.612 | eve: 9.889 | bob: 6.600Epoch   4:  59% | abe: 6.607 | eve: 9.890 | bob: 6.595Epoch   4:  60% | abe: 6.602 | eve: 9.890 | bob: 6.591Epoch   4:  60% | abe: 6.597 | eve: 9.891 | bob: 6.586Epoch   4:  61% | abe: 6.593 | eve: 9.890 | bob: 6.581Epoch   4:  62% | abe: 6.588 | eve: 9.890 | bob: 6.577Epoch   4:  63% | abe: 6.583 | eve: 9.891 | bob: 6.572Epoch   4:  64% | abe: 6.579 | eve: 9.891 | bob: 6.568Epoch   4:  64% | abe: 6.574 | eve: 9.891 | bob: 6.563Epoch   4:  65% | abe: 6.569 | eve: 9.890 | bob: 6.559Epoch   4:  66% | abe: 6.564 | eve: 9.890 | bob: 6.554Epoch   4:  67% | abe: 6.560 | eve: 9.891 | bob: 6.550Epoch   4:  67% | abe: 6.555 | eve: 9.891 | bob: 6.545Epoch   4:  68% | abe: 6.551 | eve: 9.891 | bob: 6.541Epoch   4:  69% | abe: 6.546 | eve: 9.891 | bob: 6.536Epoch   4:  70% | abe: 6.541 | eve: 9.890 | bob: 6.531Epoch   4:  71% | abe: 6.537 | eve: 9.890 | bob: 6.527Epoch   4:  71% | abe: 6.532 | eve: 9.890 | bob: 6.523Epoch   4:  72% | abe: 6.528 | eve: 9.890 | bob: 6.518Epoch   4:  73% | abe: 6.523 | eve: 9.890 | bob: 6.514Epoch   4:  74% | abe: 6.519 | eve: 9.890 | bob: 6.509Epoch   4:  75% | abe: 6.514 | eve: 9.890 | bob: 6.505Epoch   4:  75% | abe: 6.510 | eve: 9.890 | bob: 6.501Epoch   4:  76% | abe: 6.505 | eve: 9.890 | bob: 6.496Epoch   4:  77% | abe: 6.501 | eve: 9.890 | bob: 6.492Epoch   4:  78% | abe: 6.496 | eve: 9.889 | bob: 6.488Epoch   4:  78% | abe: 6.492 | eve: 9.890 | bob: 6.484Epoch   4:  79% | abe: 6.487 | eve: 9.890 | bob: 6.479Epoch   4:  80% | abe: 6.483 | eve: 9.889 | bob: 6.475Epoch   4:  81% | abe: 6.478 | eve: 9.889 | bob: 6.471Epoch   4:  82% | abe: 6.474 | eve: 9.889 | bob: 6.466Epoch   4:  82% | abe: 6.469 | eve: 9.889 | bob: 6.462Epoch   4:  83% | abe: 6.465 | eve: 9.889 | bob: 6.458Epoch   4:  84% | abe: 6.461 | eve: 9.889 | bob: 6.454Epoch   4:  85% | abe: 6.456 | eve: 9.889 | bob: 6.449Epoch   4:  85% | abe: 6.452 | eve: 9.889 | bob: 6.445Epoch   4:  86% | abe: 6.447 | eve: 9.889 | bob: 6.441Epoch   4:  87% | abe: 6.443 | eve: 9.889 | bob: 6.437Epoch   4:  88% | abe: 6.439 | eve: 9.890 | bob: 6.432Epoch   4:  89% | abe: 6.434 | eve: 9.890 | bob: 6.428Epoch   4:  89% | abe: 6.430 | eve: 9.891 | bob: 6.424Epoch   4:  90% | abe: 6.426 | eve: 9.890 | bob: 6.420Epoch   4:  91% | abe: 6.422 | eve: 9.890 | bob: 6.416Epoch   4:  92% | abe: 6.417 | eve: 9.890 | bob: 6.412Epoch   4:  92% | abe: 6.413 | eve: 9.891 | bob: 6.408Epoch   4:  93% | abe: 6.409 | eve: 9.890 | bob: 6.404Epoch   4:  94% | abe: 6.404 | eve: 9.890 | bob: 6.400Epoch   4:  95% | abe: 6.400 | eve: 9.890 | bob: 6.396Epoch   4:  96% | abe: 6.396 | eve: 9.890 | bob: 6.392Epoch   4:  96% | abe: 6.391 | eve: 9.889 | bob: 6.388Epoch   4:  97% | abe: 6.387 | eve: 9.889 | bob: 6.384Epoch   4:  98% | abe: 6.383 | eve: 9.889 | bob: 6.380Epoch   4:  99% | abe: 6.379 | eve: 9.889 | bob: 6.376
New best Bob loss 6.375623825468892 at epoch 4
Epoch   5:   0% | abe: 5.841 | eve: 9.858 | bob: 5.867Epoch   5:   0% | abe: 5.841 | eve: 9.879 | bob: 5.870Epoch   5:   1% | abe: 5.834 | eve: 9.881 | bob: 5.866Epoch   5:   2% | abe: 5.832 | eve: 9.896 | bob: 5.853Epoch   5:   3% | abe: 5.827 | eve: 9.878 | bob: 5.856Epoch   5:   3% | abe: 5.824 | eve: 9.876 | bob: 5.850Epoch   5:   4% | abe: 5.820 | eve: 9.875 | bob: 5.844Epoch   5:   5% | abe: 5.816 | eve: 9.878 | bob: 5.839Epoch   5:   6% | abe: 5.812 | eve: 9.885 | bob: 5.833Epoch   5:   7% | abe: 5.808 | eve: 9.881 | bob: 5.829Epoch   5:   7% | abe: 5.805 | eve: 9.885 | bob: 5.827Epoch   5:   8% | abe: 5.802 | eve: 9.888 | bob: 5.823Epoch   5:   9% | abe: 5.798 | eve: 9.890 | bob: 5.819Epoch   5:  10% | abe: 5.794 | eve: 9.892 | bob: 5.816Epoch   5:  10% | abe: 5.791 | eve: 9.890 | bob: 5.814Epoch   5:  11% | abe: 5.787 | eve: 9.888 | bob: 5.809Epoch   5:  12% | abe: 5.784 | eve: 9.887 | bob: 5.807Epoch   5:  13% | abe: 5.781 | eve: 9.888 | bob: 5.804Epoch   5:  14% | abe: 5.777 | eve: 9.886 | bob: 5.799Epoch   5:  14% | abe: 5.774 | eve: 9.885 | bob: 5.795Epoch   5:  15% | abe: 5.771 | eve: 9.887 | bob: 5.793Epoch   5:  16% | abe: 5.768 | eve: 9.887 | bob: 5.791Epoch   5:  17% | abe: 5.764 | eve: 9.885 | bob: 5.788Epoch   5:  17% | abe: 5.760 | eve: 9.885 | bob: 5.784Epoch   5:  18% | abe: 5.757 | eve: 9.886 | bob: 5.781Epoch   5:  19% | abe: 5.753 | eve: 9.887 | bob: 5.778Epoch   5:  20% | abe: 5.750 | eve: 9.886 | bob: 5.775Epoch   5:  21% | abe: 5.746 | eve: 9.886 | bob: 5.772Epoch   5:  21% | abe: 5.743 | eve: 9.885 | bob: 5.769Epoch   5:  22% | abe: 5.740 | eve: 9.884 | bob: 5.766Epoch   5:  23% | abe: 5.736 | eve: 9.885 | bob: 5.762Epoch   5:  24% | abe: 5.733 | eve: 9.884 | bob: 5.759Epoch   5:  25% | abe: 5.730 | eve: 9.886 | bob: 5.757Epoch   5:  25% | abe: 5.727 | eve: 9.887 | bob: 5.753Epoch   5:  26% | abe: 5.723 | eve: 9.889 | bob: 5.750Epoch   5:  27% | abe: 5.720 | eve: 9.890 | bob: 5.747Epoch   5:  28% | abe: 5.717 | eve: 9.892 | bob: 5.744Epoch   5:  28% | abe: 5.714 | eve: 9.893 | bob: 5.741Epoch   5:  29% | abe: 5.711 | eve: 9.892 | bob: 5.738Epoch   5:  30% | abe: 5.707 | eve: 9.893 | bob: 5.735Epoch   5:  31% | abe: 5.704 | eve: 9.892 | bob: 5.732Epoch   5:  32% | abe: 5.701 | eve: 9.891 | bob: 5.729Epoch   5:  32% | abe: 5.698 | eve: 9.891 | bob: 5.726Epoch   5:  33% | abe: 5.695 | eve: 9.890 | bob: 5.723Epoch   5:  34% | abe: 5.692 | eve: 9.891 | bob: 5.720Epoch   5:  35% | abe: 5.689 | eve: 9.891 | bob: 5.717Epoch   5:  35% | abe: 5.685 | eve: 9.891 | bob: 5.714Epoch   5:  36% | abe: 5.682 | eve: 9.890 | bob: 5.712Epoch   5:  37% | abe: 5.679 | eve: 9.889 | bob: 5.708Epoch   5:  38% | abe: 5.676 | eve: 9.889 | bob: 5.706Epoch   5:  39% | abe: 5.673 | eve: 9.888 | bob: 5.702Epoch   5:  39% | abe: 5.670 | eve: 9.889 | bob: 5.699Epoch   5:  40% | abe: 5.667 | eve: 9.889 | bob: 5.696Epoch   5:  41% | abe: 5.664 | eve: 9.889 | bob: 5.694Epoch   5:  42% | abe: 5.661 | eve: 9.889 | bob: 5.691Epoch   5:  42% | abe: 5.658 | eve: 9.889 | bob: 5.688Epoch   5:  43% | abe: 5.655 | eve: 9.890 | bob: 5.685Epoch   5:  44% | abe: 5.652 | eve: 9.890 | bob: 5.682Epoch   5:  45% | abe: 5.649 | eve: 9.890 | bob: 5.680Epoch   5:  46% | abe: 5.646 | eve: 9.889 | bob: 5.677Epoch   5:  46% | abe: 5.643 | eve: 9.889 | bob: 5.674Epoch   5:  47% | abe: 5.640 | eve: 9.889 | bob: 5.671Epoch   5:  48% | abe: 5.637 | eve: 9.889 | bob: 5.668Epoch   5:  49% | abe: 5.634 | eve: 9.889 | bob: 5.665Epoch   5:  50% | abe: 5.632 | eve: 9.889 | bob: 5.662Epoch   5:  50% | abe: 5.628 | eve: 9.889 | bob: 5.660Epoch   5:  51% | abe: 5.626 | eve: 9.890 | bob: 5.657Epoch   5:  52% | abe: 5.623 | eve: 9.890 | bob: 5.654Epoch   5:  53% | abe: 5.620 | eve: 9.891 | bob: 5.651Epoch   5:  53% | abe: 5.617 | eve: 9.892 | bob: 5.648Epoch   5:  54% | abe: 5.614 | eve: 9.892 | bob: 5.646Epoch   5:  55% | abe: 5.611 | eve: 9.892 | bob: 5.643Epoch   5:  56% | abe: 5.608 | eve: 9.894 | bob: 5.640Epoch   5:  57% | abe: 5.605 | eve: 9.893 | bob: 5.637Epoch   5:  57% | abe: 5.603 | eve: 9.894 | bob: 5.635Epoch   5:  58% | abe: 5.600 | eve: 9.894 | bob: 5.632Epoch   5:  59% | abe: 5.597 | eve: 9.893 | bob: 5.629Epoch   5:  60% | abe: 5.594 | eve: 9.893 | bob: 5.627Epoch   5:  60% | abe: 5.591 | eve: 9.893 | bob: 5.624Epoch   5:  61% | abe: 5.588 | eve: 9.894 | bob: 5.621Epoch   5:  62% | abe: 5.585 | eve: 9.895 | bob: 5.618Epoch   5:  63% | abe: 5.583 | eve: 9.894 | bob: 5.616Epoch   5:  64% | abe: 5.580 | eve: 9.894 | bob: 5.613Epoch   5:  64% | abe: 5.577 | eve: 9.894 | bob: 5.611Epoch   5:  65% | abe: 5.574 | eve: 9.895 | bob: 5.608Epoch   5:  66% | abe: 5.572 | eve: 9.895 | bob: 5.606Epoch   5:  67% | abe: 5.569 | eve: 9.894 | bob: 5.603Epoch   5:  67% | abe: 5.566 | eve: 9.894 | bob: 5.600Epoch   5:  68% | abe: 5.563 | eve: 9.895 | bob: 5.597Epoch   5:  69% | abe: 5.561 | eve: 9.894 | bob: 5.595Epoch   5:  70% | abe: 5.558 | eve: 9.894 | bob: 5.592Epoch   5:  71% | abe: 5.555 | eve: 9.894 | bob: 5.589Epoch   5:  71% | abe: 5.552 | eve: 9.895 | bob: 5.587Epoch   5:  72% | abe: 5.549 | eve: 9.895 | bob: 5.584Epoch   5:  73% | abe: 5.547 | eve: 9.895 | bob: 5.582Epoch   5:  74% | abe: 5.544 | eve: 9.894 | bob: 5.579Epoch   5:  75% | abe: 5.541 | eve: 9.895 | bob: 5.577Epoch   5:  75% | abe: 5.539 | eve: 9.894 | bob: 5.574Epoch   5:  76% | abe: 5.536 | eve: 9.895 | bob: 5.572Epoch   5:  77% | abe: 5.533 | eve: 9.895 | bob: 5.569Epoch   5:  78% | abe: 5.531 | eve: 9.895 | bob: 5.567Epoch   5:  78% | abe: 5.528 | eve: 9.895 | bob: 5.564Epoch   5:  79% | abe: 5.526 | eve: 9.895 | bob: 5.562Epoch   5:  80% | abe: 5.523 | eve: 9.896 | bob: 5.559Epoch   5:  81% | abe: 5.521 | eve: 9.896 | bob: 5.557Epoch   5:  82% | abe: 5.518 | eve: 9.896 | bob: 5.554Epoch   5:  82% | abe: 5.515 | eve: 9.897 | bob: 5.552Epoch   5:  83% | abe: 5.513 | eve: 9.897 | bob: 5.550Epoch   5:  84% | abe: 5.510 | eve: 9.898 | bob: 5.547Epoch   5:  85% | abe: 5.508 | eve: 9.898 | bob: 5.545Epoch   5:  85% | abe: 5.505 | eve: 9.897 | bob: 5.542Epoch   5:  86% | abe: 5.502 | eve: 9.897 | bob: 5.540Epoch   5:  87% | abe: 5.500 | eve: 9.897 | bob: 5.538Epoch   5:  88% | abe: 5.497 | eve: 9.897 | bob: 5.535Epoch   5:  89% | abe: 5.495 | eve: 9.898 | bob: 5.533Epoch   5:  89% | abe: 5.492 | eve: 9.898 | bob: 5.530Epoch   5:  90% | abe: 5.490 | eve: 9.898 | bob: 5.528Epoch   5:  91% | abe: 5.487 | eve: 9.899 | bob: 5.525Epoch   5:  92% | abe: 5.485 | eve: 9.899 | bob: 5.523Epoch   5:  92% | abe: 5.482 | eve: 9.899 | bob: 5.520Epoch   5:  93% | abe: 5.479 | eve: 9.899 | bob: 5.518Epoch   5:  94% | abe: 5.477 | eve: 9.899 | bob: 5.516Epoch   5:  95% | abe: 5.474 | eve: 9.899 | bob: 5.513Epoch   5:  96% | abe: 5.472 | eve: 9.899 | bob: 5.511Epoch   5:  96% | abe: 5.470 | eve: 9.900 | bob: 5.509Epoch   5:  97% | abe: 5.467 | eve: 9.899 | bob: 5.507Epoch   5:  98% | abe: 5.465 | eve: 9.901 | bob: 5.504Epoch   5:  99% | abe: 5.462 | eve: 9.900 | bob: 5.502
New best Bob loss 5.501850955264217 at epoch 5
Epoch   6:   0% | abe: 5.140 | eve: 9.915 | bob: 5.194Epoch   6:   0% | abe: 5.141 | eve: 9.945 | bob: 5.197Epoch   6:   1% | abe: 5.141 | eve: 9.939 | bob: 5.205Epoch   6:   2% | abe: 5.140 | eve: 9.942 | bob: 5.201Epoch   6:   3% | abe: 5.136 | eve: 9.927 | bob: 5.199Epoch   6:   3% | abe: 5.135 | eve: 9.928 | bob: 5.196Epoch   6:   4% | abe: 5.134 | eve: 9.919 | bob: 5.196Epoch   6:   5% | abe: 5.133 | eve: 9.920 | bob: 5.193Epoch   6:   6% | abe: 5.131 | eve: 9.923 | bob: 5.190Epoch   6:   7% | abe: 5.129 | eve: 9.917 | bob: 5.187Epoch   6:   7% | abe: 5.127 | eve: 9.916 | bob: 5.184Epoch   6:   8% | abe: 5.125 | eve: 9.919 | bob: 5.184Epoch   6:   9% | abe: 5.124 | eve: 9.916 | bob: 5.182Epoch   6:  10% | abe: 5.121 | eve: 9.919 | bob: 5.179Epoch   6:  10% | abe: 5.119 | eve: 9.919 | bob: 5.177Epoch   6:  11% | abe: 5.117 | eve: 9.921 | bob: 5.174Epoch   6:  12% | abe: 5.115 | eve: 9.920 | bob: 5.172Epoch   6:  13% | abe: 5.113 | eve: 9.921 | bob: 5.170Epoch   6:  14% | abe: 5.110 | eve: 9.920 | bob: 5.168Epoch   6:  14% | abe: 5.108 | eve: 9.922 | bob: 5.166Epoch   6:  15% | abe: 5.107 | eve: 9.923 | bob: 5.163Epoch   6:  16% | abe: 5.105 | eve: 9.922 | bob: 5.162Epoch   6:  17% | abe: 5.103 | eve: 9.922 | bob: 5.160Epoch   6:  17% | abe: 5.101 | eve: 9.921 | bob: 5.159Epoch   6:  18% | abe: 5.099 | eve: 9.920 | bob: 5.157Epoch   6:  19% | abe: 5.097 | eve: 9.920 | bob: 5.155Epoch   6:  20% | abe: 5.096 | eve: 9.919 | bob: 5.153Epoch   6:  21% | abe: 5.094 | eve: 9.919 | bob: 5.151Epoch   6:  21% | abe: 5.092 | eve: 9.917 | bob: 5.149Epoch   6:  22% | abe: 5.090 | eve: 9.918 | bob: 5.147Epoch   6:  23% | abe: 5.088 | eve: 9.918 | bob: 5.146Epoch   6:  24% | abe: 5.086 | eve: 9.918 | bob: 5.144Epoch   6:  25% | abe: 5.084 | eve: 9.920 | bob: 5.143Epoch   6:  25% | abe: 5.082 | eve: 9.919 | bob: 5.141Epoch   6:  26% | abe: 5.080 | eve: 9.921 | bob: 5.139Epoch   6:  27% | abe: 5.078 | eve: 9.921 | bob: 5.137Epoch   6:  28% | abe: 5.077 | eve: 9.922 | bob: 5.135Epoch   6:  28% | abe: 5.075 | eve: 9.923 | bob: 5.133Epoch   6:  29% | abe: 5.073 | eve: 9.922 | bob: 5.131Epoch   6:  30% | abe: 5.071 | eve: 9.922 | bob: 5.130Epoch   6:  31% | abe: 5.069 | eve: 9.921 | bob: 5.127Epoch   6:  32% | abe: 5.068 | eve: 9.922 | bob: 5.126Epoch   6:  32% | abe: 5.066 | eve: 9.922 | bob: 5.124Epoch   6:  33% | abe: 5.064 | eve: 9.920 | bob: 5.123Epoch   6:  34% | abe: 5.062 | eve: 9.920 | bob: 5.121Epoch   6:  35% | abe: 5.061 | eve: 9.921 | bob: 5.119Epoch   6:  35% | abe: 5.059 | eve: 9.921 | bob: 5.118Epoch   6:  36% | abe: 5.057 | eve: 9.920 | bob: 5.116Epoch   6:  37% | abe: 5.055 | eve: 9.922 | bob: 5.114Epoch   6:  38% | abe: 5.054 | eve: 9.922 | bob: 5.112Epoch   6:  39% | abe: 5.052 | eve: 9.922 | bob: 5.111Epoch   6:  39% | abe: 5.050 | eve: 9.921 | bob: 5.109Epoch   6:  40% | abe: 5.049 | eve: 9.921 | bob: 5.107Epoch   6:  41% | abe: 5.047 | eve: 9.921 | bob: 5.105Epoch   6:  42% | abe: 5.045 | eve: 9.921 | bob: 5.103Epoch   6:  42% | abe: 5.043 | eve: 9.922 | bob: 5.102Epoch   6:  43% | abe: 5.042 | eve: 9.921 | bob: 5.101Epoch   6:  44% | abe: 5.040 | eve: 9.920 | bob: 5.099Epoch   6:  45% | abe: 5.038 | eve: 9.921 | bob: 5.098Epoch   6:  46% | abe: 5.037 | eve: 9.921 | bob: 5.096Epoch   6:  46% | abe: 5.035 | eve: 9.922 | bob: 5.094Epoch   6:  47% | abe: 5.033 | eve: 9.921 | bob: 5.093Epoch   6:  48% | abe: 5.032 | eve: 9.921 | bob: 5.091Epoch   6:  49% | abe: 5.030 | eve: 9.921 | bob: 5.090Epoch   6:  50% | abe: 5.029 | eve: 9.921 | bob: 5.088Epoch   6:  50% | abe: 5.027 | eve: 9.921 | bob: 5.086Epoch   6:  51% | abe: 5.025 | eve: 9.921 | bob: 5.085Epoch   6:  52% | abe: 5.024 | eve: 9.921 | bob: 5.083Epoch   6:  53% | abe: 5.022 | eve: 9.920 | bob: 5.081Epoch   6:  53% | abe: 5.020 | eve: 9.921 | bob: 5.080Epoch   6:  54% | abe: 5.019 | eve: 9.920 | bob: 5.079Epoch   6:  55% | abe: 5.017 | eve: 9.920 | bob: 5.077Epoch   6:  56% | abe: 5.016 | eve: 9.920 | bob: 5.076Epoch   6:  57% | abe: 5.014 | eve: 9.921 | bob: 5.074Epoch   6:  57% | abe: 5.013 | eve: 9.921 | bob: 5.073Epoch   6:  58% | abe: 5.011 | eve: 9.921 | bob: 5.071Epoch   6:  59% | abe: 5.009 | eve: 9.921 | bob: 5.070Epoch   6:  60% | abe: 5.008 | eve: 9.921 | bob: 5.068Epoch   6:  60% | abe: 5.006 | eve: 9.920 | bob: 5.067Epoch   6:  61% | abe: 5.004 | eve: 9.920 | bob: 5.065Epoch   6:  62% | abe: 5.002 | eve: 9.920 | bob: 5.063Epoch   6:  63% | abe: 5.001 | eve: 9.920 | bob: 5.062Epoch   6:  64% | abe: 4.999 | eve: 9.920 | bob: 5.060Epoch   6:  64% | abe: 4.998 | eve: 9.920 | bob: 5.058Epoch   6:  65% | abe: 4.996 | eve: 9.920 | bob: 5.057Epoch   6:  66% | abe: 4.994 | eve: 9.921 | bob: 5.055Epoch   6:  67% | abe: 4.993 | eve: 9.921 | bob: 5.054Epoch   6:  67% | abe: 4.991 | eve: 9.921 | bob: 5.052Epoch   6:  68% | abe: 4.990 | eve: 9.920 | bob: 5.050Epoch   6:  69% | abe: 4.988 | eve: 9.920 | bob: 5.049Epoch   6:  70% | abe: 4.986 | eve: 9.920 | bob: 5.047Epoch   6:  71% | abe: 4.985 | eve: 9.920 | bob: 5.046Epoch   6:  71% | abe: 4.983 | eve: 9.920 | bob: 5.044Epoch   6:  72% | abe: 4.982 | eve: 9.920 | bob: 5.043Epoch   6:  73% | abe: 4.980 | eve: 9.920 | bob: 5.041Epoch   6:  74% | abe: 4.979 | eve: 9.920 | bob: 5.040Epoch   6:  75% | abe: 4.977 | eve: 9.921 | bob: 5.038Epoch   6:  75% | abe: 4.975 | eve: 9.920 | bob: 5.037Epoch   6:  76% | abe: 4.974 | eve: 9.920 | bob: 5.035Epoch   6:  77% | abe: 4.972 | eve: 9.921 | bob: 5.034Epoch   6:  78% | abe: 4.971 | eve: 9.921 | bob: 5.032Epoch   6:  78% | abe: 4.969 | eve: 9.921 | bob: 5.031Epoch   6:  79% | abe: 4.968 | eve: 9.921 | bob: 5.029Epoch   6:  80% | abe: 4.966 | eve: 9.920 | bob: 5.028Epoch   6:  81% | abe: 4.965 | eve: 9.921 | bob: 5.026Epoch   6:  82% | abe: 4.964 | eve: 9.920 | bob: 5.025Epoch   6:  82% | abe: 4.962 | eve: 9.921 | bob: 5.024Epoch   6:  83% | abe: 4.961 | eve: 9.921 | bob: 5.022Epoch   6:  84% | abe: 4.959 | eve: 9.921 | bob: 5.021Epoch   6:  85% | abe: 4.958 | eve: 9.921 | bob: 5.019Epoch   6:  85% | abe: 4.956 | eve: 9.921 | bob: 5.018Epoch   6:  86% | abe: 4.955 | eve: 9.921 | bob: 5.017Epoch   6:  87% | abe: 4.953 | eve: 9.920 | bob: 5.015Epoch   6:  88% | abe: 4.952 | eve: 9.921 | bob: 5.014Epoch   6:  89% | abe: 4.951 | eve: 9.921 | bob: 5.013Epoch   6:  89% | abe: 4.949 | eve: 9.921 | bob: 5.011Epoch   6:  90% | abe: 4.948 | eve: 9.921 | bob: 5.010Epoch   6:  91% | abe: 4.946 | eve: 9.921 | bob: 5.008Epoch   6:  92% | abe: 4.945 | eve: 9.921 | bob: 5.007Epoch   6:  92% | abe: 4.944 | eve: 9.922 | bob: 5.006Epoch   6:  93% | abe: 4.942 | eve: 9.922 | bob: 5.004Epoch   6:  94% | abe: 4.941 | eve: 9.922 | bob: 5.003Epoch   6:  95% | abe: 4.939 | eve: 9.922 | bob: 5.002Epoch   6:  96% | abe: 4.938 | eve: 9.922 | bob: 5.000Epoch   6:  96% | abe: 4.937 | eve: 9.922 | bob: 4.999Epoch   6:  97% | abe: 4.935 | eve: 9.922 | bob: 4.997Epoch   6:  98% | abe: 4.934 | eve: 9.922 | bob: 4.996Epoch   6:  99% | abe: 4.932 | eve: 9.922 | bob: 4.995
New best Bob loss 4.994707659732626 at epoch 6
Epoch   7:   0% | abe: 4.741 | eve: 9.946 | bob: 4.822Epoch   7:   0% | abe: 4.744 | eve: 9.940 | bob: 4.815Epoch   7:   1% | abe: 4.742 | eve: 9.923 | bob: 4.810Epoch   7:   2% | abe: 4.745 | eve: 9.914 | bob: 4.812Epoch   7:   3% | abe: 4.744 | eve: 9.917 | bob: 4.811Epoch   7:   3% | abe: 4.744 | eve: 9.914 | bob: 4.809Epoch   7:   4% | abe: 4.743 | eve: 9.914 | bob: 4.806Epoch   7:   5% | abe: 4.743 | eve: 9.910 | bob: 4.806Epoch   7:   6% | abe: 4.741 | eve: 9.913 | bob: 4.804Epoch   7:   7% | abe: 4.740 | eve: 9.912 | bob: 4.802Epoch   7:   7% | abe: 4.738 | eve: 9.912 | bob: 4.799Epoch   7:   8% | abe: 4.737 | eve: 9.913 | bob: 4.799Epoch   7:   9% | abe: 4.737 | eve: 9.912 | bob: 4.798Epoch   7:  10% | abe: 4.736 | eve: 9.916 | bob: 4.797Epoch   7:  10% | abe: 4.735 | eve: 9.916 | bob: 4.796Epoch   7:  11% | abe: 4.734 | eve: 9.914 | bob: 4.796Epoch   7:  12% | abe: 4.732 | eve: 9.919 | bob: 4.794Epoch   7:  13% | abe: 4.731 | eve: 9.917 | bob: 4.793Epoch   7:  14% | abe: 4.730 | eve: 9.919 | bob: 4.791Epoch   7:  14% | abe: 4.729 | eve: 9.920 | bob: 4.791Epoch   7:  15% | abe: 4.727 | eve: 9.922 | bob: 4.790Epoch   7:  16% | abe: 4.726 | eve: 9.920 | bob: 4.787Epoch   7:  17% | abe: 4.725 | eve: 9.922 | bob: 4.786Epoch   7:  17% | abe: 4.724 | eve: 9.922 | bob: 4.785Epoch   7:  18% | abe: 4.723 | eve: 9.920 | bob: 4.784Epoch   7:  19% | abe: 4.722 | eve: 9.923 | bob: 4.784Epoch   7:  20% | abe: 4.721 | eve: 9.923 | bob: 4.783Epoch   7:  21% | abe: 4.720 | eve: 9.926 | bob: 4.782Epoch   7:  21% | abe: 4.720 | eve: 9.926 | bob: 4.781Epoch   7:  22% | abe: 4.718 | eve: 9.927 | bob: 4.779Epoch   7:  23% | abe: 4.717 | eve: 9.928 | bob: 4.778Epoch   7:  24% | abe: 4.716 | eve: 9.926 | bob: 4.777Epoch   7:  25% | abe: 4.715 | eve: 9.926 | bob: 4.777Epoch   7:  25% | abe: 4.714 | eve: 9.928 | bob: 4.776Epoch   7:  26% | abe: 4.713 | eve: 9.927 | bob: 4.775Epoch   7:  27% | abe: 4.712 | eve: 9.928 | bob: 4.773Epoch   7:  28% | abe: 4.711 | eve: 9.927 | bob: 4.772Epoch   7:  28% | abe: 4.709 | eve: 9.926 | bob: 4.770Epoch   7:  29% | abe: 4.708 | eve: 9.926 | bob: 4.769Epoch   7:  30% | abe: 4.707 | eve: 9.925 | bob: 4.768Epoch   7:  31% | abe: 4.707 | eve: 9.925 | bob: 4.767Epoch   7:  32% | abe: 4.706 | eve: 9.926 | bob: 4.766Epoch   7:  32% | abe: 4.705 | eve: 9.927 | bob: 4.765Epoch   7:  33% | abe: 4.704 | eve: 9.926 | bob: 4.764Epoch   7:  34% | abe: 4.702 | eve: 9.927 | bob: 4.762Epoch   7:  35% | abe: 4.701 | eve: 9.929 | bob: 4.761Epoch   7:  35% | abe: 4.700 | eve: 9.928 | bob: 4.760Epoch   7:  36% | abe: 4.699 | eve: 9.928 | bob: 4.759Epoch   7:  37% | abe: 4.698 | eve: 9.929 | bob: 4.758Epoch   7:  38% | abe: 4.697 | eve: 9.930 | bob: 4.757Epoch   7:  39% | abe: 4.695 | eve: 9.929 | bob: 4.756Epoch   7:  39% | abe: 4.694 | eve: 9.929 | bob: 4.755Epoch   7:  40% | abe: 4.693 | eve: 9.930 | bob: 4.754Epoch   7:  41% | abe: 4.692 | eve: 9.931 | bob: 4.752Epoch   7:  42% | abe: 4.691 | eve: 9.929 | bob: 4.752Epoch   7:  42% | abe: 4.690 | eve: 9.930 | bob: 4.751Epoch   7:  43% | abe: 4.689 | eve: 9.931 | bob: 4.750Epoch   7:  44% | abe: 4.688 | eve: 9.932 | bob: 4.749Epoch   7:  45% | abe: 4.687 | eve: 9.932 | bob: 4.748Epoch   7:  46% | abe: 4.686 | eve: 9.932 | bob: 4.747Epoch   7:  46% | abe: 4.685 | eve: 9.931 | bob: 4.745Epoch   7:  47% | abe: 4.684 | eve: 9.932 | bob: 4.744Epoch   7:  48% | abe: 4.683 | eve: 9.933 | bob: 4.743Epoch   7:  49% | abe: 4.682 | eve: 9.933 | bob: 4.742Epoch   7:  50% | abe: 4.681 | eve: 9.933 | bob: 4.741Epoch   7:  50% | abe: 4.679 | eve: 9.933 | bob: 4.739Epoch   7:  51% | abe: 4.678 | eve: 9.934 | bob: 4.738Epoch   7:  52% | abe: 4.678 | eve: 9.934 | bob: 4.737Epoch   7:  53% | abe: 4.677 | eve: 9.935 | bob: 4.736Epoch   7:  53% | abe: 4.676 | eve: 9.936 | bob: 4.735Epoch   7:  54% | abe: 4.675 | eve: 9.935 | bob: 4.734Epoch   7:  55% | abe: 4.673 | eve: 9.936 | bob: 4.733Epoch   7:  56% | abe: 4.672 | eve: 9.936 | bob: 4.732Epoch   7:  57% | abe: 4.671 | eve: 9.937 | bob: 4.731Epoch   7:  57% | abe: 4.671 | eve: 9.938 | bob: 4.730Epoch   7:  58% | abe: 4.670 | eve: 9.938 | bob: 4.728Epoch   7:  59% | abe: 4.669 | eve: 9.938 | bob: 4.728Epoch   7:  60% | abe: 4.668 | eve: 9.938 | bob: 4.727Epoch   7:  60% | abe: 4.667 | eve: 9.939 | bob: 4.726Epoch   7:  61% | abe: 4.666 | eve: 9.938 | bob: 4.724Epoch   7:  62% | abe: 4.665 | eve: 9.938 | bob: 4.723Epoch   7:  63% | abe: 4.664 | eve: 9.938 | bob: 4.722Epoch   7:  64% | abe: 4.663 | eve: 9.938 | bob: 4.722Epoch   7:  64% | abe: 4.662 | eve: 9.938 | bob: 4.721Epoch   7:  65% | abe: 4.661 | eve: 9.938 | bob: 4.720Epoch   7:  66% | abe: 4.660 | eve: 9.938 | bob: 4.719Epoch   7:  67% | abe: 4.659 | eve: 9.938 | bob: 4.717Epoch   7:  67% | abe: 4.657 | eve: 9.937 | bob: 4.716Epoch   7:  68% | abe: 4.656 | eve: 9.937 | bob: 4.715Epoch   7:  69% | abe: 4.656 | eve: 9.937 | bob: 4.714Epoch   7:  70% | abe: 4.654 | eve: 9.937 | bob: 4.713Epoch   7:  71% | abe: 4.654 | eve: 9.938 | bob: 4.712Epoch   7:  71% | abe: 4.653 | eve: 9.938 | bob: 4.711Epoch   7:  72% | abe: 4.652 | eve: 9.938 | bob: 4.710Epoch   7:  73% | abe: 4.651 | eve: 9.937 | bob: 4.709Epoch   7:  74% | abe: 4.650 | eve: 9.937 | bob: 4.708Epoch   7:  75% | abe: 4.649 | eve: 9.937 | bob: 4.707Epoch   7:  75% | abe: 4.648 | eve: 9.938 | bob: 4.705Epoch   7:  76% | abe: 4.647 | eve: 9.938 | bob: 4.704Epoch   7:  77% | abe: 4.646 | eve: 9.938 | bob: 4.703Epoch   7:  78% | abe: 4.645 | eve: 9.938 | bob: 4.702Epoch   7:  78% | abe: 4.644 | eve: 9.938 | bob: 4.701Epoch   7:  79% | abe: 4.643 | eve: 9.938 | bob: 4.700Epoch   7:  80% | abe: 4.642 | eve: 9.938 | bob: 4.699Epoch   7:  81% | abe: 4.641 | eve: 9.938 | bob: 4.698Epoch   7:  82% | abe: 4.640 | eve: 9.938 | bob: 4.697Epoch   7:  82% | abe: 4.640 | eve: 9.938 | bob: 4.696Epoch   7:  83% | abe: 4.639 | eve: 9.939 | bob: 4.695Epoch   7:  84% | abe: 4.638 | eve: 9.939 | bob: 4.694Epoch   7:  85% | abe: 4.637 | eve: 9.938 | bob: 4.694Epoch   7:  85% | abe: 4.636 | eve: 9.939 | bob: 4.693Epoch   7:  86% | abe: 4.635 | eve: 9.939 | bob: 4.692Epoch   7:  87% | abe: 4.634 | eve: 9.938 | bob: 4.691Epoch   7:  88% | abe: 4.634 | eve: 9.938 | bob: 4.690Epoch   7:  89% | abe: 4.633 | eve: 9.939 | bob: 4.689Epoch   7:  89% | abe: 4.632 | eve: 9.939 | bob: 4.688Epoch   7:  90% | abe: 4.631 | eve: 9.939 | bob: 4.687Epoch   7:  91% | abe: 4.630 | eve: 9.939 | bob: 4.686Epoch   7:  92% | abe: 4.629 | eve: 9.939 | bob: 4.685Epoch   7:  92% | abe: 4.628 | eve: 9.939 | bob: 4.684Epoch   7:  93% | abe: 4.627 | eve: 9.939 | bob: 4.683Epoch   7:  94% | abe: 4.627 | eve: 9.939 | bob: 4.682Epoch   7:  95% | abe: 4.626 | eve: 9.939 | bob: 4.681Epoch   7:  96% | abe: 4.625 | eve: 9.939 | bob: 4.680Epoch   7:  96% | abe: 4.624 | eve: 9.939 | bob: 4.679Epoch   7:  97% | abe: 4.623 | eve: 9.939 | bob: 4.678Epoch   7:  98% | abe: 4.622 | eve: 9.939 | bob: 4.677Epoch   7:  99% | abe: 4.621 | eve: 9.939 | bob: 4.676
New best Bob loss 4.675778136592044 at epoch 7
Epoch   8:   0% | abe: 4.508 | eve: 9.912 | bob: 4.553Epoch   8:   0% | abe: 4.505 | eve: 9.929 | bob: 4.552Epoch   8:   1% | abe: 4.501 | eve: 9.949 | bob: 4.545Epoch   8:   2% | abe: 4.503 | eve: 9.951 | bob: 4.547Epoch   8:   3% | abe: 4.503 | eve: 9.970 | bob: 4.545Epoch   8:   3% | abe: 4.501 | eve: 9.968 | bob: 4.543Epoch   8:   4% | abe: 4.500 | eve: 9.969 | bob: 4.540Epoch   8:   5% | abe: 4.499 | eve: 9.973 | bob: 4.540Epoch   8:   6% | abe: 4.498 | eve: 9.971 | bob: 4.539Epoch   8:   7% | abe: 4.497 | eve: 9.971 | bob: 4.537Epoch   8:   7% | abe: 4.497 | eve: 9.970 | bob: 4.536Epoch   8:   8% | abe: 4.496 | eve: 9.967 | bob: 4.536Epoch   8:   9% | abe: 4.496 | eve: 9.971 | bob: 4.536Epoch   8:  10% | abe: 4.494 | eve: 9.968 | bob: 4.535Epoch   8:  10% | abe: 4.494 | eve: 9.964 | bob: 4.535Epoch   8:  11% | abe: 4.495 | eve: 9.966 | bob: 4.535Epoch   8:  12% | abe: 4.494 | eve: 9.968 | bob: 4.535Epoch   8:  13% | abe: 4.493 | eve: 9.970 | bob: 4.535Epoch   8:  14% | abe: 4.493 | eve: 9.969 | bob: 4.534Epoch   8:  14% | abe: 4.492 | eve: 9.968 | bob: 4.534Epoch   8:  15% | abe: 4.491 | eve: 9.967 | bob: 4.533Epoch   8:  16% | abe: 4.490 | eve: 9.964 | bob: 4.532Epoch   8:  17% | abe: 4.489 | eve: 9.963 | bob: 4.532Epoch   8:  17% | abe: 4.488 | eve: 9.961 | bob: 4.531Epoch   8:  18% | abe: 4.488 | eve: 9.960 | bob: 4.530Epoch   8:  19% | abe: 4.487 | eve: 9.962 | bob: 4.530Epoch   8:  20% | abe: 4.486 | eve: 9.963 | bob: 4.528Epoch   8:  21% | abe: 4.485 | eve: 9.961 | bob: 4.528Epoch   8:  21% | abe: 4.484 | eve: 9.961 | bob: 4.527Epoch   8:  22% | abe: 4.484 | eve: 9.962 | bob: 4.526Epoch   8:  23% | abe: 4.483 | eve: 9.959 | bob: 4.526Epoch   8:  24% | abe: 4.483 | eve: 9.959 | bob: 4.525Epoch   8:  25% | abe: 4.481 | eve: 9.959 | bob: 4.523Epoch   8:  25% | abe: 4.481 | eve: 9.958 | bob: 4.522Epoch   8:  26% | abe: 4.480 | eve: 9.959 | bob: 4.521Epoch   8:  27% | abe: 4.479 | eve: 9.957 | bob: 4.521Epoch   8:  28% | abe: 4.479 | eve: 9.956 | bob: 4.520Epoch   8:  28% | abe: 4.478 | eve: 9.955 | bob: 4.519Epoch   8:  29% | abe: 4.477 | eve: 9.956 | bob: 4.518Epoch   8:  30% | abe: 4.476 | eve: 9.956 | bob: 4.517Epoch   8:  31% | abe: 4.476 | eve: 9.956 | bob: 4.517Epoch   8:  32% | abe: 4.475 | eve: 9.955 | bob: 4.516Epoch   8:  32% | abe: 4.475 | eve: 9.957 | bob: 4.515Epoch   8:  33% | abe: 4.474 | eve: 9.957 | bob: 4.514Epoch   8:  34% | abe: 4.473 | eve: 9.956 | bob: 4.513Epoch   8:  35% | abe: 4.472 | eve: 9.956 | bob: 4.512Epoch   8:  35% | abe: 4.471 | eve: 9.955 | bob: 4.512Epoch   8:  36% | abe: 4.470 | eve: 9.956 | bob: 4.511Epoch   8:  37% | abe: 4.469 | eve: 9.955 | bob: 4.510Epoch   8:  38% | abe: 4.468 | eve: 9.955 | bob: 4.509Epoch   8:  39% | abe: 4.468 | eve: 9.956 | bob: 4.508Epoch   8:  39% | abe: 4.467 | eve: 9.956 | bob: 4.507Epoch   8:  40% | abe: 4.466 | eve: 9.955 | bob: 4.506Epoch   8:  41% | abe: 4.465 | eve: 9.956 | bob: 4.505Epoch   8:  42% | abe: 4.465 | eve: 9.955 | bob: 4.504Epoch   8:  42% | abe: 4.464 | eve: 9.956 | bob: 4.504Epoch   8:  43% | abe: 4.464 | eve: 9.956 | bob: 4.503Epoch   8:  44% | abe: 4.463 | eve: 9.956 | bob: 4.503Epoch   8:  45% | abe: 4.462 | eve: 9.954 | bob: 4.502Epoch   8:  46% | abe: 4.461 | eve: 9.955 | bob: 4.501Epoch   8:  46% | abe: 4.461 | eve: 9.954 | bob: 4.500Epoch   8:  47% | abe: 4.460 | eve: 9.953 | bob: 4.500Epoch   8:  48% | abe: 4.459 | eve: 9.953 | bob: 4.499Epoch   8:  49% | abe: 4.458 | eve: 9.954 | bob: 4.498Epoch   8:  50% | abe: 4.458 | eve: 9.953 | bob: 4.497Epoch   8:  50% | abe: 4.457 | eve: 9.952 | bob: 4.497Epoch   8:  51% | abe: 4.456 | eve: 9.952 | bob: 4.496Epoch   8:  52% | abe: 4.455 | eve: 9.952 | bob: 4.495Epoch   8:  53% | abe: 4.455 | eve: 9.952 | bob: 4.495Epoch   8:  53% | abe: 4.454 | eve: 9.953 | bob: 4.494Epoch   8:  54% | abe: 4.453 | eve: 9.954 | bob: 4.493Epoch   8:  55% | abe: 4.452 | eve: 9.953 | bob: 4.492Epoch   8:  56% | abe: 4.452 | eve: 9.952 | bob: 4.492Epoch   8:  57% | abe: 4.451 | eve: 9.952 | bob: 4.491Epoch   8:  57% | abe: 4.450 | eve: 9.951 | bob: 4.490Epoch   8:  58% | abe: 4.450 | eve: 9.951 | bob: 4.489Epoch   8:  59% | abe: 4.449 | eve: 9.952 | bob: 4.488Epoch   8:  60% | abe: 4.448 | eve: 9.952 | bob: 4.488Epoch   8:  60% | abe: 4.448 | eve: 9.952 | bob: 4.487Epoch   8:  61% | abe: 4.447 | eve: 9.951 | bob: 4.486Epoch   8:  62% | abe: 4.446 | eve: 9.951 | bob: 4.486Epoch   8:  63% | abe: 4.446 | eve: 9.951 | bob: 4.485Epoch   8:  64% | abe: 4.445 | eve: 9.951 | bob: 4.485Epoch   8:  64% | abe: 4.445 | eve: 9.950 | bob: 4.484Epoch   8:  65% | abe: 4.444 | eve: 9.950 | bob: 4.483Epoch   8:  66% | abe: 4.443 | eve: 9.950 | bob: 4.482Epoch   8:  67% | abe: 4.442 | eve: 9.951 | bob: 4.482Epoch   8:  67% | abe: 4.442 | eve: 9.951 | bob: 4.481Epoch   8:  68% | abe: 4.441 | eve: 9.951 | bob: 4.480Epoch   8:  69% | abe: 4.440 | eve: 9.951 | bob: 4.480Epoch   8:  70% | abe: 4.440 | eve: 9.951 | bob: 4.479Epoch   8:  71% | abe: 4.439 | eve: 9.951 | bob: 4.478Epoch   8:  71% | abe: 4.438 | eve: 9.951 | bob: 4.478Epoch   8:  72% | abe: 4.438 | eve: 9.950 | bob: 4.477Epoch   8:  73% | abe: 4.437 | eve: 9.951 | bob: 4.476Epoch   8:  74% | abe: 4.437 | eve: 9.950 | bob: 4.475Epoch   8:  75% | abe: 4.436 | eve: 9.951 | bob: 4.475Epoch   8:  75% | abe: 4.436 | eve: 9.951 | bob: 4.474Epoch   8:  76% | abe: 4.435 | eve: 9.951 | bob: 4.474Epoch   8:  77% | abe: 4.434 | eve: 9.950 | bob: 4.473Epoch   8:  78% | abe: 4.434 | eve: 9.951 | bob: 4.472Epoch   8:  78% | abe: 4.433 | eve: 9.950 | bob: 4.472Epoch   8:  79% | abe: 4.433 | eve: 9.950 | bob: 4.471Epoch   8:  80% | abe: 4.432 | eve: 9.951 | bob: 4.470Epoch   8:  81% | abe: 4.431 | eve: 9.950 | bob: 4.469Epoch   8:  82% | abe: 4.431 | eve: 9.950 | bob: 4.469Epoch   8:  82% | abe: 4.430 | eve: 9.951 | bob: 4.468Epoch   8:  83% | abe: 4.429 | eve: 9.950 | bob: 4.467Epoch   8:  84% | abe: 4.429 | eve: 9.951 | bob: 4.466Epoch   8:  85% | abe: 4.428 | eve: 9.951 | bob: 4.466Epoch   8:  85% | abe: 4.427 | eve: 9.951 | bob: 4.465Epoch   8:  86% | abe: 4.427 | eve: 9.950 | bob: 4.464Epoch   8:  87% | abe: 4.426 | eve: 9.951 | bob: 4.464Epoch   8:  88% | abe: 4.426 | eve: 9.951 | bob: 4.463Epoch   8:  89% | abe: 4.425 | eve: 9.951 | bob: 4.462Epoch   8:  89% | abe: 4.424 | eve: 9.951 | bob: 4.461Epoch   8:  90% | abe: 4.424 | eve: 9.951 | bob: 4.461Epoch   8:  91% | abe: 4.423 | eve: 9.951 | bob: 4.460Epoch   8:  92% | abe: 4.422 | eve: 9.951 | bob: 4.459Epoch   8:  92% | abe: 4.422 | eve: 9.951 | bob: 4.459Epoch   8:  93% | abe: 4.421 | eve: 9.950 | bob: 4.458Epoch   8:  94% | abe: 4.420 | eve: 9.951 | bob: 4.457Epoch   8:  95% | abe: 4.420 | eve: 9.950 | bob: 4.457Epoch   8:  96% | abe: 4.419 | eve: 9.950 | bob: 4.456Epoch   8:  96% | abe: 4.418 | eve: 9.951 | bob: 4.455Epoch   8:  97% | abe: 4.418 | eve: 9.951 | bob: 4.454Epoch   8:  98% | abe: 4.417 | eve: 9.951 | bob: 4.454Epoch   8:  99% | abe: 4.416 | eve: 9.950 | bob: 4.453
New best Bob loss 4.452940710016833 at epoch 8
Epoch   9:   0% | abe: 4.344 | eve: 9.906 | bob: 4.373Epoch   9:   0% | abe: 4.340 | eve: 9.926 | bob: 4.371Epoch   9:   1% | abe: 4.338 | eve: 9.946 | bob: 4.370Epoch   9:   2% | abe: 4.338 | eve: 9.955 | bob: 4.368Epoch   9:   3% | abe: 4.336 | eve: 9.953 | bob: 4.367Epoch   9:   3% | abe: 4.336 | eve: 9.948 | bob: 4.366Epoch   9:   4% | abe: 4.335 | eve: 9.953 | bob: 4.362Epoch   9:   5% | abe: 4.334 | eve: 9.955 | bob: 4.363Epoch   9:   6% | abe: 4.335 | eve: 9.963 | bob: 4.363Epoch   9:   7% | abe: 4.333 | eve: 9.964 | bob: 4.362Epoch   9:   7% | abe: 4.332 | eve: 9.963 | bob: 4.361Epoch   9:   8% | abe: 4.332 | eve: 9.961 | bob: 4.360Epoch   9:   9% | abe: 4.331 | eve: 9.960 | bob: 4.361Epoch   9:  10% | abe: 4.330 | eve: 9.958 | bob: 4.360Epoch   9:  10% | abe: 4.329 | eve: 9.958 | bob: 4.358Epoch   9:  11% | abe: 4.327 | eve: 9.957 | bob: 4.356Epoch   9:  12% | abe: 4.326 | eve: 9.956 | bob: 4.355Epoch   9:  13% | abe: 4.325 | eve: 9.953 | bob: 4.354Epoch   9:  14% | abe: 4.325 | eve: 9.956 | bob: 4.354Epoch   9:  14% | abe: 4.325 | eve: 9.955 | bob: 4.354Epoch   9:  15% | abe: 4.324 | eve: 9.955 | bob: 4.353Epoch   9:  16% | abe: 4.324 | eve: 9.956 | bob: 4.352Epoch   9:  17% | abe: 4.324 | eve: 9.954 | bob: 4.351Epoch   9:  17% | abe: 4.323 | eve: 9.953 | bob: 4.350Epoch   9:  18% | abe: 4.322 | eve: 9.955 | bob: 4.349Epoch   9:  19% | abe: 4.322 | eve: 9.953 | bob: 4.348Epoch   9:  20% | abe: 4.322 | eve: 9.953 | bob: 4.348Epoch   9:  21% | abe: 4.321 | eve: 9.952 | bob: 4.347Epoch   9:  21% | abe: 4.321 | eve: 9.951 | bob: 4.347Epoch   9:  22% | abe: 4.320 | eve: 9.952 | bob: 4.346Epoch   9:  23% | abe: 4.320 | eve: 9.955 | bob: 4.346Epoch   9:  24% | abe: 4.319 | eve: 9.955 | bob: 4.345Epoch   9:  25% | abe: 4.318 | eve: 9.956 | bob: 4.344Epoch   9:  25% | abe: 4.318 | eve: 9.955 | bob: 4.344Epoch   9:  26% | abe: 4.317 | eve: 9.954 | bob: 4.343Epoch   9:  27% | abe: 4.316 | eve: 9.954 | bob: 4.342Epoch   9:  28% | abe: 4.316 | eve: 9.956 | bob: 4.341Epoch   9:  28% | abe: 4.315 | eve: 9.955 | bob: 4.341Epoch   9:  29% | abe: 4.315 | eve: 9.954 | bob: 4.340Epoch   9:  30% | abe: 4.314 | eve: 9.954 | bob: 4.339Epoch   9:  31% | abe: 4.313 | eve: 9.954 | bob: 4.338Epoch   9:  32% | abe: 4.312 | eve: 9.952 | bob: 4.337Epoch   9:  32% | abe: 4.311 | eve: 9.952 | bob: 4.336Epoch   9:  33% | abe: 4.311 | eve: 9.952 | bob: 4.336Epoch   9:  34% | abe: 4.311 | eve: 9.953 | bob: 4.335Epoch   9:  35% | abe: 4.310 | eve: 9.953 | bob: 4.335Epoch   9:  35% | abe: 4.310 | eve: 9.954 | bob: 4.334Epoch   9:  36% | abe: 4.309 | eve: 9.954 | bob: 4.333Epoch   9:  37% | abe: 4.308 | eve: 9.954 | bob: 4.333Epoch   9:  38% | abe: 4.308 | eve: 9.953 | bob: 4.332Epoch   9:  39% | abe: 4.307 | eve: 9.953 | bob: 4.331Epoch   9:  39% | abe: 4.307 | eve: 9.953 | bob: 4.331Epoch   9:  40% | abe: 4.306 | eve: 9.952 | bob: 4.330Epoch   9:  41% | abe: 4.305 | eve: 9.953 | bob: 4.329Epoch   9:  42% | abe: 4.304 | eve: 9.953 | bob: 4.328Epoch   9:  42% | abe: 4.304 | eve: 9.952 | bob: 4.328Epoch   9:  43% | abe: 4.304 | eve: 9.953 | bob: 4.327Epoch   9:  44% | abe: 4.303 | eve: 9.954 | bob: 4.327Epoch   9:  45% | abe: 4.303 | eve: 9.955 | bob: 4.326Epoch   9:  46% | abe: 4.302 | eve: 9.954 | bob: 4.326Epoch   9:  46% | abe: 4.301 | eve: 9.954 | bob: 4.325Epoch   9:  47% | abe: 4.301 | eve: 9.953 | bob: 4.325Epoch   9:  48% | abe: 4.300 | eve: 9.953 | bob: 4.324Epoch   9:  49% | abe: 4.300 | eve: 9.953 | bob: 4.323Epoch   9:  50% | abe: 4.299 | eve: 9.954 | bob: 4.323Epoch   9:  50% | abe: 4.299 | eve: 9.953 | bob: 4.322Epoch   9:  51% | abe: 4.298 | eve: 9.953 | bob: 4.322Epoch   9:  52% | abe: 4.298 | eve: 9.953 | bob: 4.321Epoch   9:  53% | abe: 4.297 | eve: 9.953 | bob: 4.320Epoch   9:  53% | abe: 4.297 | eve: 9.953 | bob: 4.320Epoch   9:  54% | abe: 4.296 | eve: 9.952 | bob: 4.319Epoch   9:  55% | abe: 4.296 | eve: 9.952 | bob: 4.319Epoch   9:  56% | abe: 4.295 | eve: 9.952 | bob: 4.318Epoch   9:  57% | abe: 4.295 | eve: 9.951 | bob: 4.317Epoch   9:  57% | abe: 4.294 | eve: 9.951 | bob: 4.317Epoch   9:  58% | abe: 4.294 | eve: 9.951 | bob: 4.316Epoch   9:  59% | abe: 4.293 | eve: 9.950 | bob: 4.316Epoch   9:  60% | abe: 4.293 | eve: 9.950 | bob: 4.315Epoch   9:  60% | abe: 4.292 | eve: 9.950 | bob: 4.314Epoch   9:  61% | abe: 4.292 | eve: 9.950 | bob: 4.314Epoch   9:  62% | abe: 4.291 | eve: 9.949 | bob: 4.313Epoch   9:  63% | abe: 4.291 | eve: 9.949 | bob: 4.313Epoch   9:  64% | abe: 4.290 | eve: 9.948 | bob: 4.312Epoch   9:  64% | abe: 4.290 | eve: 9.948 | bob: 4.311Epoch   9:  65% | abe: 4.289 | eve: 9.948 | bob: 4.311Epoch   9:  66% | abe: 4.289 | eve: 9.948 | bob: 4.310Epoch   9:  67% | abe: 4.288 | eve: 9.948 | bob: 4.310Epoch   9:  67% | abe: 4.288 | eve: 9.948 | bob: 4.309Epoch   9:  68% | abe: 4.287 | eve: 9.947 | bob: 4.309Epoch   9:  69% | abe: 4.287 | eve: 9.947 | bob: 4.308Epoch   9:  70% | abe: 4.286 | eve: 9.947 | bob: 4.307Epoch   9:  71% | abe: 4.286 | eve: 9.946 | bob: 4.307Epoch   9:  71% | abe: 4.285 | eve: 9.946 | bob: 4.306Epoch   9:  72% | abe: 4.285 | eve: 9.946 | bob: 4.305Epoch   9:  73% | abe: 4.284 | eve: 9.945 | bob: 4.305Epoch   9:  74% | abe: 4.283 | eve: 9.945 | bob: 4.304Epoch   9:  75% | abe: 4.283 | eve: 9.946 | bob: 4.304Epoch   9:  75% | abe: 4.282 | eve: 9.946 | bob: 4.303Epoch   9:  76% | abe: 4.282 | eve: 9.945 | bob: 4.302Epoch   9:  77% | abe: 4.282 | eve: 9.945 | bob: 4.302Epoch   9:  78% | abe: 4.281 | eve: 9.945 | bob: 4.301Epoch   9:  78% | abe: 4.281 | eve: 9.946 | bob: 4.301Epoch   9:  79% | abe: 4.280 | eve: 9.945 | bob: 4.300Epoch   9:  80% | abe: 4.280 | eve: 9.945 | bob: 4.300Epoch   9:  81% | abe: 4.279 | eve: 9.945 | bob: 4.299Epoch   9:  82% | abe: 4.279 | eve: 9.945 | bob: 4.299Epoch   9:  82% | abe: 4.278 | eve: 9.946 | bob: 4.298Epoch   9:  83% | abe: 4.278 | eve: 9.946 | bob: 4.298Epoch   9:  84% | abe: 4.277 | eve: 9.946 | bob: 4.297Epoch   9:  85% | abe: 4.277 | eve: 9.946 | bob: 4.297Epoch   9:  85% | abe: 4.276 | eve: 9.946 | bob: 4.296Epoch   9:  86% | abe: 4.276 | eve: 9.946 | bob: 4.296Epoch   9:  87% | abe: 4.276 | eve: 9.946 | bob: 4.295Epoch   9:  88% | abe: 4.275 | eve: 9.946 | bob: 4.295Epoch   9:  89% | abe: 4.275 | eve: 9.946 | bob: 4.294Epoch   9:  89% | abe: 4.274 | eve: 9.946 | bob: 4.294Epoch   9:  90% | abe: 4.273 | eve: 9.946 | bob: 4.293Epoch   9:  91% | abe: 4.273 | eve: 9.946 | bob: 4.292Epoch   9:  92% | abe: 4.272 | eve: 9.946 | bob: 4.292Epoch   9:  92% | abe: 4.272 | eve: 9.946 | bob: 4.291Epoch   9:  93% | abe: 4.272 | eve: 9.946 | bob: 4.291Epoch   9:  94% | abe: 4.271 | eve: 9.946 | bob: 4.290Epoch   9:  95% | abe: 4.271 | eve: 9.947 | bob: 4.290Epoch   9:  96% | abe: 4.270 | eve: 9.946 | bob: 4.290Epoch   9:  96% | abe: 4.270 | eve: 9.946 | bob: 4.289Epoch   9:  97% | abe: 4.269 | eve: 9.946 | bob: 4.288Epoch   9:  98% | abe: 4.269 | eve: 9.946 | bob: 4.288Epoch   9:  99% | abe: 4.268 | eve: 9.947 | bob: 4.287
New best Bob loss 4.287270428429451 at epoch 9
Epoch  10:   0% | abe: 4.208 | eve: 9.992 | bob: 4.217Epoch  10:   0% | abe: 4.207 | eve: 9.932 | bob: 4.222Epoch  10:   1% | abe: 4.209 | eve: 9.946 | bob: 4.221Epoch  10:   2% | abe: 4.210 | eve: 9.959 | bob: 4.224Epoch  10:   3% | abe: 4.207 | eve: 9.948 | bob: 4.219Epoch  10:   3% | abe: 4.206 | eve: 9.941 | bob: 4.217Epoch  10:   4% | abe: 4.207 | eve: 9.937 | bob: 4.217Epoch  10:   5% | abe: 4.206 | eve: 9.941 | bob: 4.216Epoch  10:   6% | abe: 4.206 | eve: 9.939 | bob: 4.217Epoch  10:   7% | abe: 4.205 | eve: 9.943 | bob: 4.216Epoch  10:   7% | abe: 4.203 | eve: 9.947 | bob: 4.214Epoch  10:   8% | abe: 4.202 | eve: 9.952 | bob: 4.214Epoch  10:   9% | abe: 4.202 | eve: 9.951 | bob: 4.214Epoch  10:  10% | abe: 4.201 | eve: 9.950 | bob: 4.213Epoch  10:  10% | abe: 4.201 | eve: 9.949 | bob: 4.213Epoch  10:  11% | abe: 4.201 | eve: 9.952 | bob: 4.213Epoch  10:  12% | abe: 4.201 | eve: 9.950 | bob: 4.213Epoch  10:  13% | abe: 4.199 | eve: 9.947 | bob: 4.212Epoch  10:  14% | abe: 4.200 | eve: 9.950 | bob: 4.213Epoch  10:  14% | abe: 4.199 | eve: 9.947 | bob: 4.212Epoch  10:  15% | abe: 4.199 | eve: 9.945 | bob: 4.211Epoch  10:  16% | abe: 4.198 | eve: 9.944 | bob: 4.211Epoch  10:  17% | abe: 4.198 | eve: 9.944 | bob: 4.211Epoch  10:  17% | abe: 4.199 | eve: 9.945 | bob: 4.211Epoch  10:  18% | abe: 4.198 | eve: 9.946 | bob: 4.211Epoch  10:  19% | abe: 4.198 | eve: 9.948 | bob: 4.210Epoch  10:  20% | abe: 4.197 | eve: 9.947 | bob: 4.210Epoch  10:  21% | abe: 4.197 | eve: 9.946 | bob: 4.209Epoch  10:  21% | abe: 4.197 | eve: 9.946 | bob: 4.209Epoch  10:  22% | abe: 4.197 | eve: 9.946 | bob: 4.209Epoch  10:  23% | abe: 4.196 | eve: 9.945 | bob: 4.208Epoch  10:  24% | abe: 4.196 | eve: 9.945 | bob: 4.208Epoch  10:  25% | abe: 4.195 | eve: 9.944 | bob: 4.206Epoch  10:  25% | abe: 4.194 | eve: 9.944 | bob: 4.205Epoch  10:  26% | abe: 4.193 | eve: 9.944 | bob: 4.205Epoch  10:  27% | abe: 4.193 | eve: 9.946 | bob: 4.204Epoch  10:  28% | abe: 4.192 | eve: 9.946 | bob: 4.204Epoch  10:  28% | abe: 4.192 | eve: 9.947 | bob: 4.203Epoch  10:  29% | abe: 4.191 | eve: 9.946 | bob: 4.203Epoch  10:  30% | abe: 4.191 | eve: 9.945 | bob: 4.202Epoch  10:  31% | abe: 4.191 | eve: 9.944 | bob: 4.202Epoch  10:  32% | abe: 4.190 | eve: 9.945 | bob: 4.201Epoch  10:  32% | abe: 4.190 | eve: 9.945 | bob: 4.201Epoch  10:  33% | abe: 4.190 | eve: 9.945 | bob: 4.200Epoch  10:  34% | abe: 4.189 | eve: 9.944 | bob: 4.200Epoch  10:  35% | abe: 4.189 | eve: 9.943 | bob: 4.200Epoch  10:  35% | abe: 4.189 | eve: 9.943 | bob: 4.200Epoch  10:  36% | abe: 4.188 | eve: 9.943 | bob: 4.199Epoch  10:  37% | abe: 4.188 | eve: 9.944 | bob: 4.199Epoch  10:  38% | abe: 4.188 | eve: 9.944 | bob: 4.199Epoch  10:  39% | abe: 4.187 | eve: 9.944 | bob: 4.198Epoch  10:  39% | abe: 4.187 | eve: 9.944 | bob: 4.198Epoch  10:  40% | abe: 4.187 | eve: 9.943 | bob: 4.197Epoch  10:  41% | abe: 4.186 | eve: 9.944 | bob: 4.197Epoch  10:  42% | abe: 4.186 | eve: 9.944 | bob: 4.197Epoch  10:  42% | abe: 4.186 | eve: 9.943 | bob: 4.196Epoch  10:  43% | abe: 4.185 | eve: 9.943 | bob: 4.196Epoch  10:  44% | abe: 4.185 | eve: 9.942 | bob: 4.195Epoch  10:  45% | abe: 4.184 | eve: 9.942 | bob: 4.195Epoch  10:  46% | abe: 4.184 | eve: 9.941 | bob: 4.194Epoch  10:  46% | abe: 4.183 | eve: 9.940 | bob: 4.193Epoch  10:  47% | abe: 4.183 | eve: 9.940 | bob: 4.193Epoch  10:  48% | abe: 4.182 | eve: 9.940 | bob: 4.192Epoch  10:  49% | abe: 4.182 | eve: 9.940 | bob: 4.192Epoch  10:  50% | abe: 4.181 | eve: 9.939 | bob: 4.191Epoch  10:  50% | abe: 4.181 | eve: 9.939 | bob: 4.191Epoch  10:  51% | abe: 4.180 | eve: 9.938 | bob: 4.190Epoch  10:  52% | abe: 4.180 | eve: 9.938 | bob: 4.190Epoch  10:  53% | abe: 4.179 | eve: 9.937 | bob: 4.189Epoch  10:  53% | abe: 4.179 | eve: 9.937 | bob: 4.189Epoch  10:  54% | abe: 4.178 | eve: 9.937 | bob: 4.188Epoch  10:  55% | abe: 4.178 | eve: 9.937 | bob: 4.187Epoch  10:  56% | abe: 4.177 | eve: 9.936 | bob: 4.187Epoch  10:  57% | abe: 4.176 | eve: 9.936 | bob: 4.186Epoch  10:  57% | abe: 4.176 | eve: 9.935 | bob: 4.186Epoch  10:  58% | abe: 4.175 | eve: 9.935 | bob: 4.185Epoch  10:  59% | abe: 4.175 | eve: 9.935 | bob: 4.185Epoch  10:  60% | abe: 4.175 | eve: 9.934 | bob: 4.184Epoch  10:  60% | abe: 4.174 | eve: 9.934 | bob: 4.184Epoch  10:  61% | abe: 4.174 | eve: 9.934 | bob: 4.183Epoch  10:  62% | abe: 4.173 | eve: 9.935 | bob: 4.183Epoch  10:  63% | abe: 4.173 | eve: 9.935 | bob: 4.182Epoch  10:  64% | abe: 4.172 | eve: 9.935 | bob: 4.182Epoch  10:  64% | abe: 4.172 | eve: 9.935 | bob: 4.181Epoch  10:  65% | abe: 4.172 | eve: 9.935 | bob: 4.181Epoch  10:  66% | abe: 4.171 | eve: 9.936 | bob: 4.180Epoch  10:  67% | abe: 4.171 | eve: 9.935 | bob: 4.180Epoch  10:  67% | abe: 4.170 | eve: 9.935 | bob: 4.180Epoch  10:  68% | abe: 4.170 | eve: 9.936 | bob: 4.179Epoch  10:  69% | abe: 4.169 | eve: 9.936 | bob: 4.178Epoch  10:  70% | abe: 4.169 | eve: 9.936 | bob: 4.178Epoch  10:  71% | abe: 4.168 | eve: 9.935 | bob: 4.178Epoch  10:  71% | abe: 4.168 | eve: 9.935 | bob: 4.177Epoch  10:  72% | abe: 4.167 | eve: 9.934 | bob: 4.176Epoch  10:  73% | abe: 4.167 | eve: 9.934 | bob: 4.176Epoch  10:  74% | abe: 4.166 | eve: 9.934 | bob: 4.175Epoch  10:  75% | abe: 4.166 | eve: 9.934 | bob: 4.175Epoch  10:  75% | abe: 4.165 | eve: 9.934 | bob: 4.174Epoch  10:  76% | abe: 4.165 | eve: 9.934 | bob: 4.174Epoch  10:  77% | abe: 4.165 | eve: 9.934 | bob: 4.173Epoch  10:  78% | abe: 4.164 | eve: 9.934 | bob: 4.173Epoch  10:  78% | abe: 4.164 | eve: 9.934 | bob: 4.173Epoch  10:  79% | abe: 4.163 | eve: 9.934 | bob: 4.172Epoch  10:  80% | abe: 4.163 | eve: 9.934 | bob: 4.172Epoch  10:  81% | abe: 4.163 | eve: 9.934 | bob: 4.171Epoch  10:  82% | abe: 4.162 | eve: 9.934 | bob: 4.171Epoch  10:  82% | abe: 4.162 | eve: 9.934 | bob: 4.171Epoch  10:  83% | abe: 4.161 | eve: 9.934 | bob: 4.170Epoch  10:  84% | abe: 4.161 | eve: 9.933 | bob: 4.170Epoch  10:  85% | abe: 4.161 | eve: 9.933 | bob: 4.170Epoch  10:  85% | abe: 4.160 | eve: 9.933 | bob: 4.169Epoch  10:  86% | abe: 4.160 | eve: 9.933 | bob: 4.169Epoch  10:  87% | abe: 4.160 | eve: 9.933 | bob: 4.168Epoch  10:  88% | abe: 4.159 | eve: 9.933 | bob: 4.168Epoch  10:  89% | abe: 4.159 | eve: 9.933 | bob: 4.167Epoch  10:  89% | abe: 4.158 | eve: 9.933 | bob: 4.167Epoch  10:  90% | abe: 4.158 | eve: 9.933 | bob: 4.166Epoch  10:  91% | abe: 4.157 | eve: 9.933 | bob: 4.166Epoch  10:  92% | abe: 4.157 | eve: 9.933 | bob: 4.166Epoch  10:  92% | abe: 4.157 | eve: 9.933 | bob: 4.165Epoch  10:  93% | abe: 4.156 | eve: 9.933 | bob: 4.165Epoch  10:  94% | abe: 4.156 | eve: 9.932 | bob: 4.164Epoch  10:  95% | abe: 4.155 | eve: 9.933 | bob: 4.164Epoch  10:  96% | abe: 4.155 | eve: 9.933 | bob: 4.163Epoch  10:  96% | abe: 4.155 | eve: 9.933 | bob: 4.163Epoch  10:  97% | abe: 4.154 | eve: 9.933 | bob: 4.163Epoch  10:  98% | abe: 4.154 | eve: 9.932 | bob: 4.162Epoch  10:  99% | abe: 4.153 | eve: 9.932 | bob: 4.162
New best Bob loss 4.161595481817926 at epoch 10
Epoch  11:   0% | abe: 4.106 | eve: 9.923 | bob: 4.106Epoch  11:   0% | abe: 4.105 | eve: 9.962 | bob: 4.109Epoch  11:   1% | abe: 4.106 | eve: 9.955 | bob: 4.109Epoch  11:   2% | abe: 4.106 | eve: 9.945 | bob: 4.109Epoch  11:   3% | abe: 4.105 | eve: 9.941 | bob: 4.110Epoch  11:   3% | abe: 4.106 | eve: 9.950 | bob: 4.111Epoch  11:   4% | abe: 4.107 | eve: 9.947 | bob: 4.112Epoch  11:   5% | abe: 4.105 | eve: 9.944 | bob: 4.111Epoch  11:   6% | abe: 4.105 | eve: 9.943 | bob: 4.109Epoch  11:   7% | abe: 4.104 | eve: 9.942 | bob: 4.109Epoch  11:   7% | abe: 4.106 | eve: 9.941 | bob: 4.110Epoch  11:   8% | abe: 4.105 | eve: 9.938 | bob: 4.109Epoch  11:   9% | abe: 4.104 | eve: 9.943 | bob: 4.107Epoch  11:  10% | abe: 4.103 | eve: 9.942 | bob: 4.107Epoch  11:  10% | abe: 4.102 | eve: 9.941 | bob: 4.106Epoch  11:  11% | abe: 4.102 | eve: 9.940 | bob: 4.106Epoch  11:  12% | abe: 4.102 | eve: 9.940 | bob: 4.105Epoch  11:  13% | abe: 4.101 | eve: 9.940 | bob: 4.105Epoch  11:  14% | abe: 4.100 | eve: 9.937 | bob: 4.104Epoch  11:  14% | abe: 4.099 | eve: 9.936 | bob: 4.103Epoch  11:  15% | abe: 4.100 | eve: 9.937 | bob: 4.103Epoch  11:  16% | abe: 4.099 | eve: 9.935 | bob: 4.103Epoch  11:  17% | abe: 4.099 | eve: 9.936 | bob: 4.102Epoch  11:  17% | abe: 4.098 | eve: 9.936 | bob: 4.102Epoch  11:  18% | abe: 4.097 | eve: 9.938 | bob: 4.101Epoch  11:  19% | abe: 4.096 | eve: 9.937 | bob: 4.100Epoch  11:  20% | abe: 4.096 | eve: 9.939 | bob: 4.100Epoch  11:  21% | abe: 4.096 | eve: 9.938 | bob: 4.100Epoch  11:  21% | abe: 4.095 | eve: 9.939 | bob: 4.100Epoch  11:  22% | abe: 4.095 | eve: 9.939 | bob: 4.099Epoch  11:  23% | abe: 4.095 | eve: 9.939 | bob: 4.098Epoch  11:  24% | abe: 4.095 | eve: 9.938 | bob: 4.098Epoch  11:  25% | abe: 4.094 | eve: 9.938 | bob: 4.097Epoch  11:  25% | abe: 4.094 | eve: 9.938 | bob: 4.097Epoch  11:  26% | abe: 4.095 | eve: 9.936 | bob: 4.097Epoch  11:  27% | abe: 4.094 | eve: 9.933 | bob: 4.096Epoch  11:  28% | abe: 4.094 | eve: 9.935 | bob: 4.096Epoch  11:  28% | abe: 4.093 | eve: 9.934 | bob: 4.095Epoch  11:  29% | abe: 4.093 | eve: 9.934 | bob: 4.095Epoch  11:  30% | abe: 4.093 | eve: 9.933 | bob: 4.094Epoch  11:  31% | abe: 4.092 | eve: 9.934 | bob: 4.094Epoch  11:  32% | abe: 4.092 | eve: 9.934 | bob: 4.093Epoch  11:  32% | abe: 4.091 | eve: 9.933 | bob: 4.092Epoch  11:  33% | abe: 4.091 | eve: 9.933 | bob: 4.092Epoch  11:  34% | abe: 4.090 | eve: 9.933 | bob: 4.091Epoch  11:  35% | abe: 4.090 | eve: 9.934 | bob: 4.091Epoch  11:  35% | abe: 4.089 | eve: 9.934 | bob: 4.090Epoch  11:  36% | abe: 4.088 | eve: 9.934 | bob: 4.089Epoch  11:  37% | abe: 4.088 | eve: 9.934 | bob: 4.089Epoch  11:  38% | abe: 4.087 | eve: 9.935 | bob: 4.088Epoch  11:  39% | abe: 4.087 | eve: 9.935 | bob: 4.088Epoch  11:  39% | abe: 4.087 | eve: 9.934 | bob: 4.088Epoch  11:  40% | abe: 4.086 | eve: 9.935 | bob: 4.087Epoch  11:  41% | abe: 4.086 | eve: 9.934 | bob: 4.087Epoch  11:  42% | abe: 4.086 | eve: 9.934 | bob: 4.086Epoch  11:  42% | abe: 4.086 | eve: 9.935 | bob: 4.086Epoch  11:  43% | abe: 4.086 | eve: 9.935 | bob: 4.086Epoch  11:  44% | abe: 4.085 | eve: 9.934 | bob: 4.086Epoch  11:  45% | abe: 4.085 | eve: 9.935 | bob: 4.085Epoch  11:  46% | abe: 4.085 | eve: 9.936 | bob: 4.085Epoch  11:  46% | abe: 4.084 | eve: 9.936 | bob: 4.084Epoch  11:  47% | abe: 4.084 | eve: 9.936 | bob: 4.084Epoch  11:  48% | abe: 4.084 | eve: 9.936 | bob: 4.084Epoch  11:  49% | abe: 4.083 | eve: 9.936 | bob: 4.083Epoch  11:  50% | abe: 4.083 | eve: 9.936 | bob: 4.083Epoch  11:  50% | abe: 4.082 | eve: 9.937 | bob: 4.082Epoch  11:  51% | abe: 4.082 | eve: 9.936 | bob: 4.082Epoch  11:  52% | abe: 4.082 | eve: 9.936 | bob: 4.082Epoch  11:  53% | abe: 4.081 | eve: 9.936 | bob: 4.081Epoch  11:  53% | abe: 4.081 | eve: 9.936 | bob: 4.081Epoch  11:  54% | abe: 4.081 | eve: 9.936 | bob: 4.080Epoch  11:  55% | abe: 4.080 | eve: 9.937 | bob: 4.080Epoch  11:  56% | abe: 4.080 | eve: 9.936 | bob: 4.080Epoch  11:  57% | abe: 4.079 | eve: 9.936 | bob: 4.079Epoch  11:  57% | abe: 4.079 | eve: 9.936 | bob: 4.079Epoch  11:  58% | abe: 4.078 | eve: 9.936 | bob: 4.078Epoch  11:  59% | abe: 4.078 | eve: 9.936 | bob: 4.078Epoch  11:  60% | abe: 4.078 | eve: 9.936 | bob: 4.077Epoch  11:  60% | abe: 4.077 | eve: 9.936 | bob: 4.077Epoch  11:  61% | abe: 4.077 | eve: 9.936 | bob: 4.077Epoch  11:  62% | abe: 4.076 | eve: 9.936 | bob: 4.076Epoch  11:  63% | abe: 4.076 | eve: 9.936 | bob: 4.076Epoch  11:  64% | abe: 4.075 | eve: 9.936 | bob: 4.075Epoch  11:  64% | abe: 4.075 | eve: 9.936 | bob: 4.075Epoch  11:  65% | abe: 4.075 | eve: 9.935 | bob: 4.074Epoch  11:  66% | abe: 4.074 | eve: 9.935 | bob: 4.074Epoch  11:  67% | abe: 4.074 | eve: 9.935 | bob: 4.074Epoch  11:  67% | abe: 4.074 | eve: 9.935 | bob: 4.073Epoch  11:  68% | abe: 4.074 | eve: 9.935 | bob: 4.073Epoch  11:  69% | abe: 4.073 | eve: 9.935 | bob: 4.073Epoch  11:  70% | abe: 4.073 | eve: 9.935 | bob: 4.072Epoch  11:  71% | abe: 4.072 | eve: 9.935 | bob: 4.072Epoch  11:  71% | abe: 4.072 | eve: 9.935 | bob: 4.072Epoch  11:  72% | abe: 4.072 | eve: 9.934 | bob: 4.071Epoch  11:  73% | abe: 4.071 | eve: 9.933 | bob: 4.071Epoch  11:  74% | abe: 4.071 | eve: 9.933 | bob: 4.071Epoch  11:  75% | abe: 4.071 | eve: 9.934 | bob: 4.070Epoch  11:  75% | abe: 4.070 | eve: 9.933 | bob: 4.070Epoch  11:  76% | abe: 4.070 | eve: 9.933 | bob: 4.069Epoch  11:  77% | abe: 4.070 | eve: 9.933 | bob: 4.069Epoch  11:  78% | abe: 4.069 | eve: 9.933 | bob: 4.069Epoch  11:  78% | abe: 4.069 | eve: 9.933 | bob: 4.068Epoch  11:  79% | abe: 4.069 | eve: 9.933 | bob: 4.068Epoch  11:  80% | abe: 4.068 | eve: 9.932 | bob: 4.068Epoch  11:  81% | abe: 4.068 | eve: 9.933 | bob: 4.067Epoch  11:  82% | abe: 4.068 | eve: 9.933 | bob: 4.067Epoch  11:  82% | abe: 4.067 | eve: 9.933 | bob: 4.066Epoch  11:  83% | abe: 4.067 | eve: 9.933 | bob: 4.066Epoch  11:  84% | abe: 4.066 | eve: 9.933 | bob: 4.066Epoch  11:  85% | abe: 4.066 | eve: 9.933 | bob: 4.065Epoch  11:  85% | abe: 4.066 | eve: 9.934 | bob: 4.065Epoch  11:  86% | abe: 4.066 | eve: 9.934 | bob: 4.065Epoch  11:  87% | abe: 4.065 | eve: 9.934 | bob: 4.064Epoch  11:  88% | abe: 4.065 | eve: 9.934 | bob: 4.064Epoch  11:  89% | abe: 4.065 | eve: 9.934 | bob: 4.064Epoch  11:  89% | abe: 4.065 | eve: 9.934 | bob: 4.064Epoch  11:  90% | abe: 4.064 | eve: 9.934 | bob: 4.063Epoch  11:  91% | abe: 4.064 | eve: 9.934 | bob: 4.063Epoch  11:  92% | abe: 4.064 | eve: 9.934 | bob: 4.063Epoch  11:  92% | abe: 4.063 | eve: 9.935 | bob: 4.062Epoch  11:  93% | abe: 4.063 | eve: 9.934 | bob: 4.062Epoch  11:  94% | abe: 4.063 | eve: 9.933 | bob: 4.062Epoch  11:  95% | abe: 4.062 | eve: 9.933 | bob: 4.061Epoch  11:  96% | abe: 4.062 | eve: 9.933 | bob: 4.061Epoch  11:  96% | abe: 4.062 | eve: 9.934 | bob: 4.060Epoch  11:  97% | abe: 4.061 | eve: 9.933 | bob: 4.060Epoch  11:  98% | abe: 4.061 | eve: 9.934 | bob: 4.060Epoch  11:  99% | abe: 4.061 | eve: 9.934 | bob: 4.059
New best Bob loss 4.059222322086271 at epoch 11
Epoch  12:   0% | abe: 4.016 | eve: 9.958 | bob: 4.017Epoch  12:   0% | abe: 4.012 | eve: 9.932 | bob: 4.012Epoch  12:   1% | abe: 4.017 | eve: 9.931 | bob: 4.016Epoch  12:   2% | abe: 4.014 | eve: 9.920 | bob: 4.011Epoch  12:   3% | abe: 4.015 | eve: 9.925 | bob: 4.013Epoch  12:   3% | abe: 4.014 | eve: 9.923 | bob: 4.012Epoch  12:   4% | abe: 4.016 | eve: 9.919 | bob: 4.013Epoch  12:   5% | abe: 4.016 | eve: 9.918 | bob: 4.013Epoch  12:   6% | abe: 4.017 | eve: 9.916 | bob: 4.013Epoch  12:   7% | abe: 4.016 | eve: 9.924 | bob: 4.013Epoch  12:   7% | abe: 4.016 | eve: 9.922 | bob: 4.013Epoch  12:   8% | abe: 4.014 | eve: 9.925 | bob: 4.010Epoch  12:   9% | abe: 4.014 | eve: 9.926 | bob: 4.010Epoch  12:  10% | abe: 4.013 | eve: 9.929 | bob: 4.008Epoch  12:  10% | abe: 4.013 | eve: 9.928 | bob: 4.009Epoch  12:  11% | abe: 4.012 | eve: 9.927 | bob: 4.009Epoch  12:  12% | abe: 4.012 | eve: 9.928 | bob: 4.007Epoch  12:  13% | abe: 4.011 | eve: 9.928 | bob: 4.007Epoch  12:  14% | abe: 4.011 | eve: 9.927 | bob: 4.007Epoch  12:  14% | abe: 4.011 | eve: 9.928 | bob: 4.007Epoch  12:  15% | abe: 4.010 | eve: 9.927 | bob: 4.007Epoch  12:  16% | abe: 4.011 | eve: 9.927 | bob: 4.007Epoch  12:  17% | abe: 4.010 | eve: 9.928 | bob: 4.006Epoch  12:  17% | abe: 4.009 | eve: 9.929 | bob: 4.005Epoch  12:  18% | abe: 4.009 | eve: 9.929 | bob: 4.005Epoch  12:  19% | abe: 4.009 | eve: 9.929 | bob: 4.005Epoch  12:  20% | abe: 4.008 | eve: 9.928 | bob: 4.005Epoch  12:  21% | abe: 4.008 | eve: 9.929 | bob: 4.005Epoch  12:  21% | abe: 4.008 | eve: 9.930 | bob: 4.004Epoch  12:  22% | abe: 4.008 | eve: 9.932 | bob: 4.004Epoch  12:  23% | abe: 4.007 | eve: 9.932 | bob: 4.003Epoch  12:  24% | abe: 4.007 | eve: 9.932 | bob: 4.003Epoch  12:  25% | abe: 4.007 | eve: 9.931 | bob: 4.003Epoch  12:  25% | abe: 4.007 | eve: 9.930 | bob: 4.004Epoch  12:  26% | abe: 4.007 | eve: 9.928 | bob: 4.003Epoch  12:  27% | abe: 4.007 | eve: 9.928 | bob: 4.003Epoch  12:  28% | abe: 4.006 | eve: 9.928 | bob: 4.003Epoch  12:  28% | abe: 4.006 | eve: 9.928 | bob: 4.002Epoch  12:  29% | abe: 4.006 | eve: 9.927 | bob: 4.002Epoch  12:  30% | abe: 4.006 | eve: 9.927 | bob: 4.002Epoch  12:  31% | abe: 4.006 | eve: 9.926 | bob: 4.002Epoch  12:  32% | abe: 4.006 | eve: 9.925 | bob: 4.002Epoch  12:  32% | abe: 4.006 | eve: 9.924 | bob: 4.002Epoch  12:  33% | abe: 4.006 | eve: 9.924 | bob: 4.002Epoch  12:  34% | abe: 4.005 | eve: 9.925 | bob: 4.002Epoch  12:  35% | abe: 4.005 | eve: 9.924 | bob: 4.001Epoch  12:  35% | abe: 4.004 | eve: 9.924 | bob: 4.001Epoch  12:  36% | abe: 4.004 | eve: 9.924 | bob: 4.001Epoch  12:  37% | abe: 4.004 | eve: 9.925 | bob: 4.000Epoch  12:  38% | abe: 4.004 | eve: 9.925 | bob: 4.000Epoch  12:  39% | abe: 4.003 | eve: 9.926 | bob: 3.999Epoch  12:  39% | abe: 4.003 | eve: 9.926 | bob: 3.999Epoch  12:  40% | abe: 4.003 | eve: 9.925 | bob: 3.999Epoch  12:  41% | abe: 4.003 | eve: 9.925 | bob: 3.999Epoch  12:  42% | abe: 4.002 | eve: 9.925 | bob: 3.998Epoch  12:  42% | abe: 4.002 | eve: 9.925 | bob: 3.998Epoch  12:  43% | abe: 4.001 | eve: 9.925 | bob: 3.997Epoch  12:  44% | abe: 4.001 | eve: 9.925 | bob: 3.997Epoch  12:  45% | abe: 4.001 | eve: 9.925 | bob: 3.996Epoch  12:  46% | abe: 4.000 | eve: 9.925 | bob: 3.996Epoch  12:  46% | abe: 4.000 | eve: 9.925 | bob: 3.996Epoch  12:  47% | abe: 3.999 | eve: 9.924 | bob: 3.995Epoch  12:  48% | abe: 3.999 | eve: 9.924 | bob: 3.995Epoch  12:  49% | abe: 3.999 | eve: 9.924 | bob: 3.994Epoch  12:  50% | abe: 3.998 | eve: 9.923 | bob: 3.994Epoch  12:  50% | abe: 3.998 | eve: 9.923 | bob: 3.994Epoch  12:  51% | abe: 3.998 | eve: 9.923 | bob: 3.994Epoch  12:  52% | abe: 3.997 | eve: 9.923 | bob: 3.993Epoch  12:  53% | abe: 3.997 | eve: 9.923 | bob: 3.993Epoch  12:  53% | abe: 3.997 | eve: 9.923 | bob: 3.992Epoch  12:  54% | abe: 3.996 | eve: 9.923 | bob: 3.992Epoch  12:  55% | abe: 3.996 | eve: 9.924 | bob: 3.992Epoch  12:  56% | abe: 3.996 | eve: 9.924 | bob: 3.992Epoch  12:  57% | abe: 3.996 | eve: 9.923 | bob: 3.992Epoch  12:  57% | abe: 3.995 | eve: 9.924 | bob: 3.991Epoch  12:  58% | abe: 3.995 | eve: 9.923 | bob: 3.991Epoch  12:  59% | abe: 3.994 | eve: 9.923 | bob: 3.990Epoch  12:  60% | abe: 3.994 | eve: 9.924 | bob: 3.990Epoch  12:  60% | abe: 3.994 | eve: 9.924 | bob: 3.990Epoch  12:  61% | abe: 3.994 | eve: 9.924 | bob: 3.990Epoch  12:  62% | abe: 3.993 | eve: 9.923 | bob: 3.989Epoch  12:  63% | abe: 3.993 | eve: 9.924 | bob: 3.989Epoch  12:  64% | abe: 3.993 | eve: 9.924 | bob: 3.989Epoch  12:  64% | abe: 3.993 | eve: 9.924 | bob: 3.989Epoch  12:  65% | abe: 3.993 | eve: 9.924 | bob: 3.988Epoch  12:  66% | abe: 3.992 | eve: 9.924 | bob: 3.988Epoch  12:  67% | abe: 3.992 | eve: 9.923 | bob: 3.988Epoch  12:  67% | abe: 3.992 | eve: 9.923 | bob: 3.988Epoch  12:  68% | abe: 3.992 | eve: 9.923 | bob: 3.988Epoch  12:  69% | abe: 3.991 | eve: 9.923 | bob: 3.987Epoch  12:  70% | abe: 3.991 | eve: 9.923 | bob: 3.987Epoch  12:  71% | abe: 3.991 | eve: 9.924 | bob: 3.986Epoch  12:  71% | abe: 3.990 | eve: 9.924 | bob: 3.986Epoch  12:  72% | abe: 3.990 | eve: 9.924 | bob: 3.986Epoch  12:  73% | abe: 3.990 | eve: 9.924 | bob: 3.985Epoch  12:  74% | abe: 3.989 | eve: 9.923 | bob: 3.985Epoch  12:  75% | abe: 3.989 | eve: 9.923 | bob: 3.985Epoch  12:  75% | abe: 3.989 | eve: 9.923 | bob: 3.985Epoch  12:  76% | abe: 3.989 | eve: 9.924 | bob: 3.984Epoch  12:  77% | abe: 3.988 | eve: 9.924 | bob: 3.984Epoch  12:  78% | abe: 3.988 | eve: 9.924 | bob: 3.984Epoch  12:  78% | abe: 3.988 | eve: 9.924 | bob: 3.983Epoch  12:  79% | abe: 3.987 | eve: 9.924 | bob: 3.983Epoch  12:  80% | abe: 3.987 | eve: 9.924 | bob: 3.983Epoch  12:  81% | abe: 3.987 | eve: 9.924 | bob: 3.982Epoch  12:  82% | abe: 3.986 | eve: 9.923 | bob: 3.982Epoch  12:  82% | abe: 3.986 | eve: 9.922 | bob: 3.982Epoch  12:  83% | abe: 3.986 | eve: 9.923 | bob: 3.982Epoch  12:  84% | abe: 3.986 | eve: 9.922 | bob: 3.981Epoch  12:  85% | abe: 3.986 | eve: 9.922 | bob: 3.981Epoch  12:  85% | abe: 3.985 | eve: 9.923 | bob: 3.981Epoch  12:  86% | abe: 3.985 | eve: 9.922 | bob: 3.981Epoch  12:  87% | abe: 3.985 | eve: 9.922 | bob: 3.980Epoch  12:  88% | abe: 3.984 | eve: 9.922 | bob: 3.980Epoch  12:  89% | abe: 3.984 | eve: 9.922 | bob: 3.979Epoch  12:  89% | abe: 3.983 | eve: 9.922 | bob: 3.979Epoch  12:  90% | abe: 3.983 | eve: 9.922 | bob: 3.979Epoch  12:  91% | abe: 3.983 | eve: 9.921 | bob: 3.979Epoch  12:  92% | abe: 3.983 | eve: 9.922 | bob: 3.979Epoch  12:  92% | abe: 3.983 | eve: 9.921 | bob: 3.978Epoch  12:  93% | abe: 3.982 | eve: 9.922 | bob: 3.978Epoch  12:  94% | abe: 3.982 | eve: 9.922 | bob: 3.978Epoch  12:  95% | abe: 3.982 | eve: 9.922 | bob: 3.977Epoch  12:  96% | abe: 3.981 | eve: 9.922 | bob: 3.977Epoch  12:  96% | abe: 3.981 | eve: 9.922 | bob: 3.977Epoch  12:  97% | abe: 3.981 | eve: 9.922 | bob: 3.976Epoch  12:  98% | abe: 3.981 | eve: 9.922 | bob: 3.976Epoch  12:  99% | abe: 3.980 | eve: 9.922 | bob: 3.976
New best Bob loss 3.9757877078718593 at epoch 12
Epoch  13:   0% | abe: 3.948 | eve: 9.940 | bob: 3.944Epoch  13:   0% | abe: 3.940 | eve: 9.953 | bob: 3.936Epoch  13:   1% | abe: 3.939 | eve: 9.947 | bob: 3.934Epoch  13:   2% | abe: 3.936 | eve: 9.949 | bob: 3.933Epoch  13:   3% | abe: 3.937 | eve: 9.953 | bob: 3.934Epoch  13:   3% | abe: 3.938 | eve: 9.949 | bob: 3.936Epoch  13:   4% | abe: 3.937 | eve: 9.941 | bob: 3.936Epoch  13:   5% | abe: 3.937 | eve: 9.938 | bob: 3.935Epoch  13:   6% | abe: 3.937 | eve: 9.939 | bob: 3.936Epoch  13:   7% | abe: 3.939 | eve: 9.938 | bob: 3.935Epoch  13:   7% | abe: 3.938 | eve: 9.937 | bob: 3.936Epoch  13:   8% | abe: 3.937 | eve: 9.934 | bob: 3.936Epoch  13:   9% | abe: 3.938 | eve: 9.931 | bob: 3.936Epoch  13:  10% | abe: 3.939 | eve: 9.930 | bob: 3.936Epoch  13:  10% | abe: 3.939 | eve: 9.933 | bob: 3.937Epoch  13:  11% | abe: 3.939 | eve: 9.935 | bob: 3.937Epoch  13:  12% | abe: 3.939 | eve: 9.932 | bob: 3.936Epoch  13:  13% | abe: 3.939 | eve: 9.932 | bob: 3.937Epoch  13:  14% | abe: 3.938 | eve: 9.931 | bob: 3.936Epoch  13:  14% | abe: 3.938 | eve: 9.931 | bob: 3.936Epoch  13:  15% | abe: 3.937 | eve: 9.933 | bob: 3.935Epoch  13:  16% | abe: 3.937 | eve: 9.935 | bob: 3.934Epoch  13:  17% | abe: 3.936 | eve: 9.935 | bob: 3.933Epoch  13:  17% | abe: 3.936 | eve: 9.936 | bob: 3.933Epoch  13:  18% | abe: 3.936 | eve: 9.935 | bob: 3.932Epoch  13:  19% | abe: 3.935 | eve: 9.936 | bob: 3.931Epoch  13:  20% | abe: 3.935 | eve: 9.938 | bob: 3.931Epoch  13:  21% | abe: 3.934 | eve: 9.937 | bob: 3.931Epoch  13:  21% | abe: 3.934 | eve: 9.936 | bob: 3.931Epoch  13:  22% | abe: 3.934 | eve: 9.937 | bob: 3.930Epoch  13:  23% | abe: 3.934 | eve: 9.936 | bob: 3.930Epoch  13:  24% | abe: 3.934 | eve: 9.934 | bob: 3.931Epoch  13:  25% | abe: 3.934 | eve: 9.935 | bob: 3.931Epoch  13:  25% | abe: 3.933 | eve: 9.933 | bob: 3.930Epoch  13:  26% | abe: 3.933 | eve: 9.933 | bob: 3.930Epoch  13:  27% | abe: 3.933 | eve: 9.931 | bob: 3.929Epoch  13:  28% | abe: 3.932 | eve: 9.931 | bob: 3.929Epoch  13:  28% | abe: 3.932 | eve: 9.931 | bob: 3.928Epoch  13:  29% | abe: 3.932 | eve: 9.932 | bob: 3.928Epoch  13:  30% | abe: 3.932 | eve: 9.933 | bob: 3.928Epoch  13:  31% | abe: 3.932 | eve: 9.933 | bob: 3.928Epoch  13:  32% | abe: 3.932 | eve: 9.933 | bob: 3.928Epoch  13:  32% | abe: 3.932 | eve: 9.933 | bob: 3.927Epoch  13:  33% | abe: 3.931 | eve: 9.934 | bob: 3.927Epoch  13:  34% | abe: 3.931 | eve: 9.934 | bob: 3.927Epoch  13:  35% | abe: 3.931 | eve: 9.932 | bob: 3.926Epoch  13:  35% | abe: 3.931 | eve: 9.932 | bob: 3.926Epoch  13:  36% | abe: 3.931 | eve: 9.933 | bob: 3.926Epoch  13:  37% | abe: 3.931 | eve: 9.932 | bob: 3.926Epoch  13:  38% | abe: 3.930 | eve: 9.932 | bob: 3.925Epoch  13:  39% | abe: 3.930 | eve: 9.931 | bob: 3.925Epoch  13:  39% | abe: 3.930 | eve: 9.931 | bob: 3.925Epoch  13:  40% | abe: 3.929 | eve: 9.932 | bob: 3.925Epoch  13:  41% | abe: 3.929 | eve: 9.931 | bob: 3.924Epoch  13:  42% | abe: 3.929 | eve: 9.930 | bob: 3.924Epoch  13:  42% | abe: 3.928 | eve: 9.931 | bob: 3.923Epoch  13:  43% | abe: 3.928 | eve: 9.930 | bob: 3.923Epoch  13:  44% | abe: 3.928 | eve: 9.931 | bob: 3.922Epoch  13:  45% | abe: 3.928 | eve: 9.931 | bob: 3.922Epoch  13:  46% | abe: 3.928 | eve: 9.931 | bob: 3.922Epoch  13:  46% | abe: 3.928 | eve: 9.932 | bob: 3.922Epoch  13:  47% | abe: 3.927 | eve: 9.932 | bob: 3.921Epoch  13:  48% | abe: 3.927 | eve: 9.932 | bob: 3.921Epoch  13:  49% | abe: 3.926 | eve: 9.931 | bob: 3.920Epoch  13:  50% | abe: 3.926 | eve: 9.931 | bob: 3.920Epoch  13:  50% | abe: 3.926 | eve: 9.931 | bob: 3.919Epoch  13:  51% | abe: 3.925 | eve: 9.931 | bob: 3.919Epoch  13:  52% | abe: 3.925 | eve: 9.931 | bob: 3.919Epoch  13:  53% | abe: 3.925 | eve: 9.931 | bob: 3.918Epoch  13:  53% | abe: 3.924 | eve: 9.931 | bob: 3.918Epoch  13:  54% | abe: 3.924 | eve: 9.932 | bob: 3.918Epoch  13:  55% | abe: 3.924 | eve: 9.931 | bob: 3.917Epoch  13:  56% | abe: 3.923 | eve: 9.932 | bob: 3.917Epoch  13:  57% | abe: 3.923 | eve: 9.932 | bob: 3.916Epoch  13:  57% | abe: 3.923 | eve: 9.932 | bob: 3.916Epoch  13:  58% | abe: 3.922 | eve: 9.931 | bob: 3.916Epoch  13:  59% | abe: 3.922 | eve: 9.932 | bob: 3.915Epoch  13:  60% | abe: 3.922 | eve: 9.932 | bob: 3.916Epoch  13:  60% | abe: 3.922 | eve: 9.932 | bob: 3.916Epoch  13:  61% | abe: 3.922 | eve: 9.933 | bob: 3.915Epoch  13:  62% | abe: 3.921 | eve: 9.932 | bob: 3.915Epoch  13:  63% | abe: 3.921 | eve: 9.932 | bob: 3.915Epoch  13:  64% | abe: 3.921 | eve: 9.933 | bob: 3.915Epoch  13:  64% | abe: 3.921 | eve: 9.932 | bob: 3.914Epoch  13:  65% | abe: 3.920 | eve: 9.932 | bob: 3.914Epoch  13:  66% | abe: 3.920 | eve: 9.932 | bob: 3.914Epoch  13:  67% | abe: 3.920 | eve: 9.932 | bob: 3.913Epoch  13:  67% | abe: 3.920 | eve: 9.932 | bob: 3.913Epoch  13:  68% | abe: 3.919 | eve: 9.932 | bob: 3.913Epoch  13:  69% | abe: 3.919 | eve: 9.932 | bob: 3.912Epoch  13:  70% | abe: 3.919 | eve: 9.932 | bob: 3.912Epoch  13:  71% | abe: 3.918 | eve: 9.932 | bob: 3.912Epoch  13:  71% | abe: 3.918 | eve: 9.932 | bob: 3.912Epoch  13:  72% | abe: 3.918 | eve: 9.933 | bob: 3.911Epoch  13:  73% | abe: 3.918 | eve: 9.933 | bob: 3.911Epoch  13:  74% | abe: 3.918 | eve: 9.933 | bob: 3.911Epoch  13:  75% | abe: 3.917 | eve: 9.933 | bob: 3.911Epoch  13:  75% | abe: 3.917 | eve: 9.933 | bob: 3.910Epoch  13:  76% | abe: 3.917 | eve: 9.933 | bob: 3.910Epoch  13:  77% | abe: 3.917 | eve: 9.934 | bob: 3.910Epoch  13:  78% | abe: 3.916 | eve: 9.934 | bob: 3.909Epoch  13:  78% | abe: 3.916 | eve: 9.934 | bob: 3.909Epoch  13:  79% | abe: 3.916 | eve: 9.934 | bob: 3.909Epoch  13:  80% | abe: 3.915 | eve: 9.934 | bob: 3.908Epoch  13:  81% | abe: 3.915 | eve: 9.934 | bob: 3.908Epoch  13:  82% | abe: 3.915 | eve: 9.934 | bob: 3.908Epoch  13:  82% | abe: 3.915 | eve: 9.934 | bob: 3.908Epoch  13:  83% | abe: 3.915 | eve: 9.934 | bob: 3.908Epoch  13:  84% | abe: 3.915 | eve: 9.934 | bob: 3.907Epoch  13:  85% | abe: 3.914 | eve: 9.934 | bob: 3.907Epoch  13:  85% | abe: 3.914 | eve: 9.934 | bob: 3.907Epoch  13:  86% | abe: 3.914 | eve: 9.933 | bob: 3.907Epoch  13:  87% | abe: 3.914 | eve: 9.933 | bob: 3.906Epoch  13:  88% | abe: 3.913 | eve: 9.933 | bob: 3.906Epoch  13:  89% | abe: 3.913 | eve: 9.933 | bob: 3.906Epoch  13:  89% | abe: 3.913 | eve: 9.933 | bob: 3.905Epoch  13:  90% | abe: 3.913 | eve: 9.934 | bob: 3.905Epoch  13:  91% | abe: 3.912 | eve: 9.934 | bob: 3.905Epoch  13:  92% | abe: 3.912 | eve: 9.933 | bob: 3.904Epoch  13:  92% | abe: 3.912 | eve: 9.933 | bob: 3.904Epoch  13:  93% | abe: 3.912 | eve: 9.933 | bob: 3.904Epoch  13:  94% | abe: 3.912 | eve: 9.933 | bob: 3.904Epoch  13:  95% | abe: 3.911 | eve: 9.933 | bob: 3.904Epoch  13:  96% | abe: 3.911 | eve: 9.933 | bob: 3.903Epoch  13:  96% | abe: 3.911 | eve: 9.932 | bob: 3.903Epoch  13:  97% | abe: 3.911 | eve: 9.933 | bob: 3.903Epoch  13:  98% | abe: 3.910 | eve: 9.932 | bob: 3.902Epoch  13:  99% | abe: 3.910 | eve: 9.932 | bob: 3.902
New best Bob loss 3.9023389973476696 at epoch 13
Epoch  14:   0% | abe: 3.866 | eve: 9.986 | bob: 3.852Epoch  14:   0% | abe: 3.872 | eve: 9.947 | bob: 3.855Epoch  14:   1% | abe: 3.871 | eve: 9.947 | bob: 3.857Epoch  14:   2% | abe: 3.873 | eve: 9.942 | bob: 3.861Epoch  14:   3% | abe: 3.875 | eve: 9.941 | bob: 3.864Epoch  14:   3% | abe: 3.877 | eve: 9.945 | bob: 3.866Epoch  14:   4% | abe: 3.878 | eve: 9.947 | bob: 3.869Epoch  14:   5% | abe: 3.879 | eve: 9.949 | bob: 3.870Epoch  14:   6% | abe: 3.879 | eve: 9.944 | bob: 3.869Epoch  14:   7% | abe: 3.879 | eve: 9.945 | bob: 3.869Epoch  14:   7% | abe: 3.879 | eve: 9.947 | bob: 3.869Epoch  14:   8% | abe: 3.878 | eve: 9.948 | bob: 3.867Epoch  14:   9% | abe: 3.876 | eve: 9.951 | bob: 3.865Epoch  14:  10% | abe: 3.876 | eve: 9.946 | bob: 3.865Epoch  14:  10% | abe: 3.877 | eve: 9.944 | bob: 3.865Epoch  14:  11% | abe: 3.876 | eve: 9.945 | bob: 3.865Epoch  14:  12% | abe: 3.877 | eve: 9.945 | bob: 3.866Epoch  14:  13% | abe: 3.877 | eve: 9.947 | bob: 3.866Epoch  14:  14% | abe: 3.877 | eve: 9.948 | bob: 3.866Epoch  14:  14% | abe: 3.876 | eve: 9.946 | bob: 3.865Epoch  14:  15% | abe: 3.877 | eve: 9.945 | bob: 3.866Epoch  14:  16% | abe: 3.877 | eve: 9.944 | bob: 3.866Epoch  14:  17% | abe: 3.877 | eve: 9.943 | bob: 3.867Epoch  14:  17% | abe: 3.877 | eve: 9.942 | bob: 3.867Epoch  14:  18% | abe: 3.877 | eve: 9.942 | bob: 3.867Epoch  14:  19% | abe: 3.876 | eve: 9.942 | bob: 3.867Epoch  14:  20% | abe: 3.876 | eve: 9.941 | bob: 3.867Epoch  14:  21% | abe: 3.876 | eve: 9.939 | bob: 3.867Epoch  14:  21% | abe: 3.876 | eve: 9.938 | bob: 3.867Epoch  14:  22% | abe: 3.876 | eve: 9.939 | bob: 3.866Epoch  14:  23% | abe: 3.875 | eve: 9.938 | bob: 3.865Epoch  14:  24% | abe: 3.874 | eve: 9.937 | bob: 3.865Epoch  14:  25% | abe: 3.874 | eve: 9.936 | bob: 3.864Epoch  14:  25% | abe: 3.873 | eve: 9.934 | bob: 3.864Epoch  14:  26% | abe: 3.873 | eve: 9.937 | bob: 3.863Epoch  14:  27% | abe: 3.873 | eve: 9.936 | bob: 3.863Epoch  14:  28% | abe: 3.872 | eve: 9.936 | bob: 3.863Epoch  14:  28% | abe: 3.872 | eve: 9.935 | bob: 3.863Epoch  14:  29% | abe: 3.872 | eve: 9.935 | bob: 3.862Epoch  14:  30% | abe: 3.872 | eve: 9.936 | bob: 3.862Epoch  14:  31% | abe: 3.871 | eve: 9.935 | bob: 3.862Epoch  14:  32% | abe: 3.871 | eve: 9.934 | bob: 3.862Epoch  14:  32% | abe: 3.871 | eve: 9.934 | bob: 3.862Epoch  14:  33% | abe: 3.871 | eve: 9.934 | bob: 3.861Epoch  14:  34% | abe: 3.871 | eve: 9.933 | bob: 3.861Epoch  14:  35% | abe: 3.870 | eve: 9.934 | bob: 3.861Epoch  14:  35% | abe: 3.870 | eve: 9.934 | bob: 3.861Epoch  14:  36% | abe: 3.870 | eve: 9.934 | bob: 3.860Epoch  14:  37% | abe: 3.869 | eve: 9.933 | bob: 3.860Epoch  14:  38% | abe: 3.869 | eve: 9.933 | bob: 3.859Epoch  14:  39% | abe: 3.868 | eve: 9.932 | bob: 3.858Epoch  14:  39% | abe: 3.868 | eve: 9.933 | bob: 3.858Epoch  14:  40% | abe: 3.868 | eve: 9.932 | bob: 3.858Epoch  14:  41% | abe: 3.867 | eve: 9.933 | bob: 3.857Epoch  14:  42% | abe: 3.867 | eve: 9.935 | bob: 3.857Epoch  14:  42% | abe: 3.867 | eve: 9.935 | bob: 3.857Epoch  14:  43% | abe: 3.866 | eve: 9.935 | bob: 3.856Epoch  14:  44% | abe: 3.866 | eve: 9.936 | bob: 3.856Epoch  14:  45% | abe: 3.866 | eve: 9.936 | bob: 3.856Epoch  14:  46% | abe: 3.866 | eve: 9.937 | bob: 3.855Epoch  14:  46% | abe: 3.865 | eve: 9.936 | bob: 3.855Epoch  14:  47% | abe: 3.865 | eve: 9.936 | bob: 3.855Epoch  14:  48% | abe: 3.865 | eve: 9.936 | bob: 3.855Epoch  14:  49% | abe: 3.865 | eve: 9.936 | bob: 3.854Epoch  14:  50% | abe: 3.864 | eve: 9.936 | bob: 3.854Epoch  14:  50% | abe: 3.864 | eve: 9.936 | bob: 3.854Epoch  14:  51% | abe: 3.864 | eve: 9.937 | bob: 3.854Epoch  14:  52% | abe: 3.864 | eve: 9.937 | bob: 3.854Epoch  14:  53% | abe: 3.864 | eve: 9.936 | bob: 3.854Epoch  14:  53% | abe: 3.864 | eve: 9.936 | bob: 3.854Epoch  14:  54% | abe: 3.864 | eve: 9.935 | bob: 3.854Epoch  14:  55% | abe: 3.864 | eve: 9.935 | bob: 3.854Epoch  14:  56% | abe: 3.864 | eve: 9.936 | bob: 3.854Epoch  14:  57% | abe: 3.864 | eve: 9.936 | bob: 3.853Epoch  14:  57% | abe: 3.863 | eve: 9.935 | bob: 3.853Epoch  14:  58% | abe: 3.863 | eve: 9.935 | bob: 3.853Epoch  14:  59% | abe: 3.863 | eve: 9.935 | bob: 3.853Epoch  14:  60% | abe: 3.863 | eve: 9.934 | bob: 3.853Epoch  14:  60% | abe: 3.863 | eve: 9.934 | bob: 3.853Epoch  14:  61% | abe: 3.863 | eve: 9.934 | bob: 3.852Epoch  14:  62% | abe: 3.862 | eve: 9.934 | bob: 3.852Epoch  14:  63% | abe: 3.862 | eve: 9.934 | bob: 3.852Epoch  14:  64% | abe: 3.862 | eve: 9.934 | bob: 3.851Epoch  14:  64% | abe: 3.861 | eve: 9.933 | bob: 3.851Epoch  14:  65% | abe: 3.861 | eve: 9.933 | bob: 3.851Epoch  14:  66% | abe: 3.861 | eve: 9.934 | bob: 3.850Epoch  14:  67% | abe: 3.861 | eve: 9.934 | bob: 3.850Epoch  14:  67% | abe: 3.860 | eve: 9.934 | bob: 3.850Epoch  14:  68% | abe: 3.860 | eve: 9.934 | bob: 3.849Epoch  14:  69% | abe: 3.860 | eve: 9.933 | bob: 3.849Epoch  14:  70% | abe: 3.860 | eve: 9.934 | bob: 3.849Epoch  14:  71% | abe: 3.859 | eve: 9.934 | bob: 3.849Epoch  14:  71% | abe: 3.859 | eve: 9.934 | bob: 3.848Epoch  14:  72% | abe: 3.859 | eve: 9.934 | bob: 3.848Epoch  14:  73% | abe: 3.859 | eve: 9.934 | bob: 3.848Epoch  14:  74% | abe: 3.858 | eve: 9.933 | bob: 3.848Epoch  14:  75% | abe: 3.858 | eve: 9.933 | bob: 3.847Epoch  14:  75% | abe: 3.858 | eve: 9.934 | bob: 3.847Epoch  14:  76% | abe: 3.858 | eve: 9.934 | bob: 3.847Epoch  14:  77% | abe: 3.857 | eve: 9.934 | bob: 3.847Epoch  14:  78% | abe: 3.857 | eve: 9.934 | bob: 3.846Epoch  14:  78% | abe: 3.857 | eve: 9.933 | bob: 3.846Epoch  14:  79% | abe: 3.857 | eve: 9.933 | bob: 3.846Epoch  14:  80% | abe: 3.857 | eve: 9.933 | bob: 3.846Epoch  14:  81% | abe: 3.856 | eve: 9.933 | bob: 3.845Epoch  14:  82% | abe: 3.856 | eve: 9.933 | bob: 3.845Epoch  14:  82% | abe: 3.856 | eve: 9.933 | bob: 3.845Epoch  14:  83% | abe: 3.856 | eve: 9.933 | bob: 3.844Epoch  14:  84% | abe: 3.856 | eve: 9.932 | bob: 3.844Epoch  14:  85% | abe: 3.855 | eve: 9.932 | bob: 3.844Epoch  14:  85% | abe: 3.855 | eve: 9.932 | bob: 3.843Epoch  14:  86% | abe: 3.855 | eve: 9.932 | bob: 3.843Epoch  14:  87% | abe: 3.854 | eve: 9.932 | bob: 3.843Epoch  14:  88% | abe: 3.854 | eve: 9.932 | bob: 3.842Epoch  14:  89% | abe: 3.854 | eve: 9.933 | bob: 3.842Epoch  14:  89% | abe: 3.853 | eve: 9.933 | bob: 3.842Epoch  14:  90% | abe: 3.853 | eve: 9.932 | bob: 3.842Epoch  14:  91% | abe: 3.853 | eve: 9.932 | bob: 3.841Epoch  14:  92% | abe: 3.853 | eve: 9.933 | bob: 3.841Epoch  14:  92% | abe: 3.852 | eve: 9.932 | bob: 3.841Epoch  14:  93% | abe: 3.852 | eve: 9.933 | bob: 3.840Epoch  14:  94% | abe: 3.852 | eve: 9.933 | bob: 3.840Epoch  14:  95% | abe: 3.852 | eve: 9.932 | bob: 3.840Epoch  14:  96% | abe: 3.851 | eve: 9.932 | bob: 3.840Epoch  14:  96% | abe: 3.851 | eve: 9.932 | bob: 3.840Epoch  14:  97% | abe: 3.851 | eve: 9.933 | bob: 3.839Epoch  14:  98% | abe: 3.851 | eve: 9.933 | bob: 3.839Epoch  14:  99% | abe: 3.850 | eve: 9.933 | bob: 3.839
New best Bob loss 3.8387964906376055 at epoch 14
Epoch  15:   0% | abe: 3.818 | eve: 9.975 | bob: 3.798Epoch  15:   0% | abe: 3.818 | eve: 9.977 | bob: 3.800Epoch  15:   1% | abe: 3.822 | eve: 9.963 | bob: 3.802Epoch  15:   2% | abe: 3.820 | eve: 9.952 | bob: 3.801Epoch  15:   3% | abe: 3.823 | eve: 9.956 | bob: 3.803Epoch  15:   3% | abe: 3.821 | eve: 9.966 | bob: 3.801Epoch  15:   4% | abe: 3.821 | eve: 9.961 | bob: 3.800Epoch  15:   5% | abe: 3.822 | eve: 9.959 | bob: 3.802Epoch  15:   6% | abe: 3.820 | eve: 9.958 | bob: 3.801Epoch  15:   7% | abe: 3.821 | eve: 9.959 | bob: 3.801Epoch  15:   7% | abe: 3.823 | eve: 9.962 | bob: 3.802Epoch  15:   8% | abe: 3.822 | eve: 9.954 | bob: 3.802Epoch  15:   9% | abe: 3.821 | eve: 9.953 | bob: 3.802Epoch  15:  10% | abe: 3.820 | eve: 9.951 | bob: 3.800Epoch  15:  10% | abe: 3.820 | eve: 9.950 | bob: 3.801Epoch  15:  11% | abe: 3.820 | eve: 9.948 | bob: 3.801Epoch  15:  12% | abe: 3.818 | eve: 9.946 | bob: 3.800Epoch  15:  13% | abe: 3.818 | eve: 9.946 | bob: 3.800Epoch  15:  14% | abe: 3.818 | eve: 9.943 | bob: 3.800Epoch  15:  14% | abe: 3.818 | eve: 9.944 | bob: 3.799Epoch  15:  15% | abe: 3.818 | eve: 9.942 | bob: 3.800Epoch  15:  16% | abe: 3.817 | eve: 9.940 | bob: 3.800Epoch  15:  17% | abe: 3.817 | eve: 9.939 | bob: 3.800Epoch  15:  17% | abe: 3.817 | eve: 9.938 | bob: 3.800Epoch  15:  18% | abe: 3.816 | eve: 9.938 | bob: 3.800Epoch  15:  19% | abe: 3.816 | eve: 9.941 | bob: 3.800Epoch  15:  20% | abe: 3.816 | eve: 9.940 | bob: 3.799Epoch  15:  21% | abe: 3.815 | eve: 9.939 | bob: 3.799Epoch  15:  21% | abe: 3.814 | eve: 9.939 | bob: 3.798Epoch  15:  22% | abe: 3.815 | eve: 9.940 | bob: 3.798Epoch  15:  23% | abe: 3.814 | eve: 9.941 | bob: 3.798Epoch  15:  24% | abe: 3.815 | eve: 9.942 | bob: 3.799Epoch  15:  25% | abe: 3.816 | eve: 9.941 | bob: 3.799Epoch  15:  25% | abe: 3.815 | eve: 9.941 | bob: 3.799Epoch  15:  26% | abe: 3.815 | eve: 9.941 | bob: 3.799Epoch  15:  27% | abe: 3.816 | eve: 9.941 | bob: 3.800Epoch  15:  28% | abe: 3.816 | eve: 9.940 | bob: 3.800Epoch  15:  28% | abe: 3.815 | eve: 9.940 | bob: 3.799Epoch  15:  29% | abe: 3.815 | eve: 9.937 | bob: 3.799Epoch  15:  30% | abe: 3.815 | eve: 9.936 | bob: 3.798Epoch  15:  31% | abe: 3.814 | eve: 9.937 | bob: 3.798Epoch  15:  32% | abe: 3.814 | eve: 9.937 | bob: 3.798Epoch  15:  32% | abe: 3.814 | eve: 9.937 | bob: 3.798Epoch  15:  33% | abe: 3.814 | eve: 9.938 | bob: 3.798Epoch  15:  34% | abe: 3.813 | eve: 9.938 | bob: 3.797Epoch  15:  35% | abe: 3.813 | eve: 9.939 | bob: 3.798Epoch  15:  35% | abe: 3.813 | eve: 9.937 | bob: 3.797Epoch  15:  36% | abe: 3.812 | eve: 9.937 | bob: 3.796Epoch  15:  37% | abe: 3.812 | eve: 9.938 | bob: 3.796Epoch  15:  38% | abe: 3.812 | eve: 9.938 | bob: 3.796Epoch  15:  39% | abe: 3.811 | eve: 9.938 | bob: 3.795Epoch  15:  39% | abe: 3.811 | eve: 9.938 | bob: 3.795Epoch  15:  40% | abe: 3.811 | eve: 9.937 | bob: 3.795Epoch  15:  41% | abe: 3.811 | eve: 9.937 | bob: 3.795Epoch  15:  42% | abe: 3.811 | eve: 9.936 | bob: 3.795Epoch  15:  42% | abe: 3.811 | eve: 9.938 | bob: 3.795Epoch  15:  43% | abe: 3.811 | eve: 9.937 | bob: 3.795Epoch  15:  44% | abe: 3.810 | eve: 9.938 | bob: 3.794Epoch  15:  45% | abe: 3.810 | eve: 9.939 | bob: 3.794Epoch  15:  46% | abe: 3.809 | eve: 9.939 | bob: 3.793Epoch  15:  46% | abe: 3.809 | eve: 9.938 | bob: 3.793Epoch  15:  47% | abe: 3.809 | eve: 9.938 | bob: 3.793Epoch  15:  48% | abe: 3.809 | eve: 9.939 | bob: 3.793Epoch  15:  49% | abe: 3.809 | eve: 9.938 | bob: 3.793Epoch  15:  50% | abe: 3.809 | eve: 9.938 | bob: 3.793Epoch  15:  50% | abe: 3.808 | eve: 9.937 | bob: 3.792Epoch  15:  51% | abe: 3.808 | eve: 9.937 | bob: 3.792Epoch  15:  52% | abe: 3.808 | eve: 9.937 | bob: 3.792Epoch  15:  53% | abe: 3.807 | eve: 9.938 | bob: 3.791Epoch  15:  53% | abe: 3.807 | eve: 9.937 | bob: 3.791Epoch  15:  54% | abe: 3.807 | eve: 9.936 | bob: 3.791Epoch  15:  55% | abe: 3.807 | eve: 9.937 | bob: 3.791Epoch  15:  56% | abe: 3.807 | eve: 9.937 | bob: 3.791Epoch  15:  57% | abe: 3.807 | eve: 9.936 | bob: 3.791Epoch  15:  57% | abe: 3.806 | eve: 9.936 | bob: 3.790Epoch  15:  58% | abe: 3.806 | eve: 9.936 | bob: 3.790Epoch  15:  59% | abe: 3.806 | eve: 9.936 | bob: 3.790Epoch  15:  60% | abe: 3.806 | eve: 9.936 | bob: 3.790Epoch  15:  60% | abe: 3.806 | eve: 9.936 | bob: 3.789Epoch  15:  61% | abe: 3.805 | eve: 9.936 | bob: 3.789Epoch  15:  62% | abe: 3.805 | eve: 9.935 | bob: 3.789Epoch  15:  63% | abe: 3.805 | eve: 9.936 | bob: 3.788Epoch  15:  64% | abe: 3.804 | eve: 9.935 | bob: 3.788Epoch  15:  64% | abe: 3.804 | eve: 9.936 | bob: 3.788Epoch  15:  65% | abe: 3.804 | eve: 9.936 | bob: 3.788Epoch  15:  66% | abe: 3.804 | eve: 9.936 | bob: 3.787Epoch  15:  67% | abe: 3.804 | eve: 9.935 | bob: 3.787Epoch  15:  67% | abe: 3.804 | eve: 9.935 | bob: 3.787Epoch  15:  68% | abe: 3.803 | eve: 9.935 | bob: 3.787Epoch  15:  69% | abe: 3.803 | eve: 9.935 | bob: 3.787Epoch  15:  70% | abe: 3.803 | eve: 9.935 | bob: 3.786Epoch  15:  71% | abe: 3.803 | eve: 9.934 | bob: 3.786Epoch  15:  71% | abe: 3.802 | eve: 9.935 | bob: 3.785Epoch  15:  72% | abe: 3.802 | eve: 9.935 | bob: 3.785Epoch  15:  73% | abe: 3.802 | eve: 9.936 | bob: 3.785Epoch  15:  74% | abe: 3.802 | eve: 9.935 | bob: 3.785Epoch  15:  75% | abe: 3.801 | eve: 9.935 | bob: 3.785Epoch  15:  75% | abe: 3.801 | eve: 9.936 | bob: 3.784Epoch  15:  76% | abe: 3.801 | eve: 9.936 | bob: 3.784Epoch  15:  77% | abe: 3.801 | eve: 9.936 | bob: 3.784Epoch  15:  78% | abe: 3.801 | eve: 9.936 | bob: 3.784Epoch  15:  78% | abe: 3.800 | eve: 9.936 | bob: 3.784Epoch  15:  79% | abe: 3.800 | eve: 9.937 | bob: 3.783Epoch  15:  80% | abe: 3.800 | eve: 9.937 | bob: 3.783Epoch  15:  81% | abe: 3.799 | eve: 9.938 | bob: 3.782Epoch  15:  82% | abe: 3.799 | eve: 9.938 | bob: 3.782Epoch  15:  82% | abe: 3.799 | eve: 9.938 | bob: 3.782Epoch  15:  83% | abe: 3.799 | eve: 9.938 | bob: 3.782Epoch  15:  84% | abe: 3.799 | eve: 9.938 | bob: 3.781Epoch  15:  85% | abe: 3.798 | eve: 9.938 | bob: 3.781Epoch  15:  85% | abe: 3.798 | eve: 9.938 | bob: 3.781Epoch  15:  86% | abe: 3.798 | eve: 9.938 | bob: 3.781Epoch  15:  87% | abe: 3.798 | eve: 9.938 | bob: 3.781Epoch  15:  88% | abe: 3.798 | eve: 9.939 | bob: 3.781Epoch  15:  89% | abe: 3.798 | eve: 9.939 | bob: 3.781Epoch  15:  89% | abe: 3.797 | eve: 9.938 | bob: 3.780Epoch  15:  90% | abe: 3.797 | eve: 9.939 | bob: 3.780Epoch  15:  91% | abe: 3.797 | eve: 9.939 | bob: 3.780Epoch  15:  92% | abe: 3.797 | eve: 9.939 | bob: 3.780Epoch  15:  92% | abe: 3.797 | eve: 9.938 | bob: 3.779Epoch  15:  93% | abe: 3.797 | eve: 9.939 | bob: 3.779Epoch  15:  94% | abe: 3.796 | eve: 9.939 | bob: 3.779Epoch  15:  95% | abe: 3.796 | eve: 9.939 | bob: 3.779Epoch  15:  96% | abe: 3.796 | eve: 9.939 | bob: 3.779Epoch  15:  96% | abe: 3.796 | eve: 9.940 | bob: 3.778Epoch  15:  97% | abe: 3.796 | eve: 9.940 | bob: 3.778Epoch  15:  98% | abe: 3.796 | eve: 9.939 | bob: 3.778Epoch  15:  99% | abe: 3.795 | eve: 9.939 | bob: 3.778
New best Bob loss 3.7778005661695033 at epoch 15
Epoch  16:   0% | abe: 3.760 | eve: 9.923 | bob: 3.731Epoch  16:   0% | abe: 3.760 | eve: 9.920 | bob: 3.737Epoch  16:   1% | abe: 3.759 | eve: 9.949 | bob: 3.739Epoch  16:   2% | abe: 3.762 | eve: 9.940 | bob: 3.742Epoch  16:   3% | abe: 3.762 | eve: 9.952 | bob: 3.743Epoch  16:   3% | abe: 3.763 | eve: 9.946 | bob: 3.744Epoch  16:   4% | abe: 3.763 | eve: 9.941 | bob: 3.743Epoch  16:   5% | abe: 3.762 | eve: 9.947 | bob: 3.742Epoch  16:   6% | abe: 3.763 | eve: 9.940 | bob: 3.742Epoch  16:   7% | abe: 3.764 | eve: 9.944 | bob: 3.744Epoch  16:   7% | abe: 3.764 | eve: 9.946 | bob: 3.743Epoch  16:   8% | abe: 3.764 | eve: 9.941 | bob: 3.743Epoch  16:   9% | abe: 3.765 | eve: 9.942 | bob: 3.744Epoch  16:  10% | abe: 3.764 | eve: 9.941 | bob: 3.743Epoch  16:  10% | abe: 3.766 | eve: 9.942 | bob: 3.745Epoch  16:  11% | abe: 3.765 | eve: 9.942 | bob: 3.744Epoch  16:  12% | abe: 3.765 | eve: 9.944 | bob: 3.744Epoch  16:  13% | abe: 3.765 | eve: 9.944 | bob: 3.744Epoch  16:  14% | abe: 3.765 | eve: 9.943 | bob: 3.745Epoch  16:  14% | abe: 3.766 | eve: 9.945 | bob: 3.745Epoch  16:  15% | abe: 3.765 | eve: 9.945 | bob: 3.744Epoch  16:  16% | abe: 3.765 | eve: 9.944 | bob: 3.744Epoch  16:  17% | abe: 3.765 | eve: 9.944 | bob: 3.744Epoch  16:  17% | abe: 3.765 | eve: 9.944 | bob: 3.744Epoch  16:  18% | abe: 3.765 | eve: 9.942 | bob: 3.744Epoch  16:  19% | abe: 3.765 | eve: 9.940 | bob: 3.744Epoch  16:  20% | abe: 3.764 | eve: 9.940 | bob: 3.743Epoch  16:  21% | abe: 3.765 | eve: 9.944 | bob: 3.743Epoch  16:  21% | abe: 3.765 | eve: 9.944 | bob: 3.743Epoch  16:  22% | abe: 3.765 | eve: 9.944 | bob: 3.743Epoch  16:  23% | abe: 3.765 | eve: 9.945 | bob: 3.742Epoch  16:  24% | abe: 3.765 | eve: 9.945 | bob: 3.742Epoch  16:  25% | abe: 3.765 | eve: 9.946 | bob: 3.742Epoch  16:  25% | abe: 3.765 | eve: 9.944 | bob: 3.742Epoch  16:  26% | abe: 3.765 | eve: 9.944 | bob: 3.742Epoch  16:  27% | abe: 3.764 | eve: 9.945 | bob: 3.741Epoch  16:  28% | abe: 3.764 | eve: 9.947 | bob: 3.741Epoch  16:  28% | abe: 3.763 | eve: 9.947 | bob: 3.741Epoch  16:  29% | abe: 3.763 | eve: 9.945 | bob: 3.741Epoch  16:  30% | abe: 3.763 | eve: 9.946 | bob: 3.740Epoch  16:  31% | abe: 3.763 | eve: 9.945 | bob: 3.740Epoch  16:  32% | abe: 3.762 | eve: 9.944 | bob: 3.740Epoch  16:  32% | abe: 3.762 | eve: 9.943 | bob: 3.740Epoch  16:  33% | abe: 3.762 | eve: 9.943 | bob: 3.739Epoch  16:  34% | abe: 3.762 | eve: 9.943 | bob: 3.739Epoch  16:  35% | abe: 3.762 | eve: 9.944 | bob: 3.739Epoch  16:  35% | abe: 3.762 | eve: 9.944 | bob: 3.739Epoch  16:  36% | abe: 3.762 | eve: 9.944 | bob: 3.739Epoch  16:  37% | abe: 3.762 | eve: 9.944 | bob: 3.739Epoch  16:  38% | abe: 3.762 | eve: 9.943 | bob: 3.739Epoch  16:  39% | abe: 3.762 | eve: 9.944 | bob: 3.739Epoch  16:  39% | abe: 3.761 | eve: 9.944 | bob: 3.738Epoch  16:  40% | abe: 3.761 | eve: 9.944 | bob: 3.738Epoch  16:  41% | abe: 3.761 | eve: 9.944 | bob: 3.738Epoch  16:  42% | abe: 3.761 | eve: 9.945 | bob: 3.737Epoch  16:  42% | abe: 3.760 | eve: 9.945 | bob: 3.737Epoch  16:  43% | abe: 3.760 | eve: 9.944 | bob: 3.736Epoch  16:  44% | abe: 3.759 | eve: 9.943 | bob: 3.736Epoch  16:  45% | abe: 3.759 | eve: 9.943 | bob: 3.736Epoch  16:  46% | abe: 3.759 | eve: 9.943 | bob: 3.736Epoch  16:  46% | abe: 3.759 | eve: 9.943 | bob: 3.735Epoch  16:  47% | abe: 3.759 | eve: 9.944 | bob: 3.735Epoch  16:  48% | abe: 3.759 | eve: 9.944 | bob: 3.735Epoch  16:  49% | abe: 3.759 | eve: 9.945 | bob: 3.735Epoch  16:  50% | abe: 3.759 | eve: 9.945 | bob: 3.735Epoch  16:  50% | abe: 3.758 | eve: 9.945 | bob: 3.735Epoch  16:  51% | abe: 3.758 | eve: 9.944 | bob: 3.735Epoch  16:  52% | abe: 3.758 | eve: 9.944 | bob: 3.734Epoch  16:  53% | abe: 3.758 | eve: 9.945 | bob: 3.734Epoch  16:  53% | abe: 3.757 | eve: 9.944 | bob: 3.733Epoch  16:  54% | abe: 3.757 | eve: 9.945 | bob: 3.733Epoch  16:  55% | abe: 3.757 | eve: 9.945 | bob: 3.733Epoch  16:  56% | abe: 3.757 | eve: 9.945 | bob: 3.733Epoch  16:  57% | abe: 3.757 | eve: 9.945 | bob: 3.733Epoch  16:  57% | abe: 3.757 | eve: 9.945 | bob: 3.733Epoch  16:  58% | abe: 3.757 | eve: 9.945 | bob: 3.733Epoch  16:  59% | abe: 3.757 | eve: 9.945 | bob: 3.733Epoch  16:  60% | abe: 3.757 | eve: 9.945 | bob: 3.733Epoch  16:  60% | abe: 3.756 | eve: 9.945 | bob: 3.732Epoch  16:  61% | abe: 3.756 | eve: 9.946 | bob: 3.732Epoch  16:  62% | abe: 3.756 | eve: 9.947 | bob: 3.732Epoch  16:  63% | abe: 3.756 | eve: 9.948 | bob: 3.731Epoch  16:  64% | abe: 3.756 | eve: 9.948 | bob: 3.732Epoch  16:  64% | abe: 3.756 | eve: 9.948 | bob: 3.731Epoch  16:  65% | abe: 3.756 | eve: 9.948 | bob: 3.731Epoch  16:  66% | abe: 3.756 | eve: 9.948 | bob: 3.731Epoch  16:  67% | abe: 3.755 | eve: 9.947 | bob: 3.731Epoch  16:  67% | abe: 3.755 | eve: 9.947 | bob: 3.731Epoch  16:  68% | abe: 3.755 | eve: 9.947 | bob: 3.730Epoch  16:  69% | abe: 3.754 | eve: 9.947 | bob: 3.730Epoch  16:  70% | abe: 3.754 | eve: 9.947 | bob: 3.729Epoch  16:  71% | abe: 3.754 | eve: 9.947 | bob: 3.729Epoch  16:  71% | abe: 3.753 | eve: 9.948 | bob: 3.729Epoch  16:  72% | abe: 3.753 | eve: 9.948 | bob: 3.729Epoch  16:  73% | abe: 3.753 | eve: 9.948 | bob: 3.729Epoch  16:  74% | abe: 3.753 | eve: 9.948 | bob: 3.728Epoch  16:  75% | abe: 3.753 | eve: 9.948 | bob: 3.728Epoch  16:  75% | abe: 3.753 | eve: 9.949 | bob: 3.728Epoch  16:  76% | abe: 3.753 | eve: 9.948 | bob: 3.728Epoch  16:  77% | abe: 3.753 | eve: 9.948 | bob: 3.728Epoch  16:  78% | abe: 3.753 | eve: 9.949 | bob: 3.728Epoch  16:  78% | abe: 3.752 | eve: 9.948 | bob: 3.727Epoch  16:  79% | abe: 3.752 | eve: 9.948 | bob: 3.727Epoch  16:  80% | abe: 3.752 | eve: 9.948 | bob: 3.727Epoch  16:  81% | abe: 3.752 | eve: 9.948 | bob: 3.727Epoch  16:  82% | abe: 3.752 | eve: 9.948 | bob: 3.727Epoch  16:  82% | abe: 3.752 | eve: 9.948 | bob: 3.727Epoch  16:  83% | abe: 3.752 | eve: 9.948 | bob: 3.726Epoch  16:  84% | abe: 3.751 | eve: 9.947 | bob: 3.726Epoch  16:  85% | abe: 3.751 | eve: 9.948 | bob: 3.726Epoch  16:  85% | abe: 3.751 | eve: 9.948 | bob: 3.726Epoch  16:  86% | abe: 3.750 | eve: 9.948 | bob: 3.725Epoch  16:  87% | abe: 3.750 | eve: 9.948 | bob: 3.725Epoch  16:  88% | abe: 3.750 | eve: 9.948 | bob: 3.725Epoch  16:  89% | abe: 3.750 | eve: 9.948 | bob: 3.725Epoch  16:  89% | abe: 3.750 | eve: 9.948 | bob: 3.725Epoch  16:  90% | abe: 3.750 | eve: 9.948 | bob: 3.725Epoch  16:  91% | abe: 3.750 | eve: 9.948 | bob: 3.724Epoch  16:  92% | abe: 3.750 | eve: 9.948 | bob: 3.724Epoch  16:  92% | abe: 3.750 | eve: 9.948 | bob: 3.724Epoch  16:  93% | abe: 3.749 | eve: 9.947 | bob: 3.724Epoch  16:  94% | abe: 3.749 | eve: 9.948 | bob: 3.724Epoch  16:  95% | abe: 3.749 | eve: 9.948 | bob: 3.723Epoch  16:  96% | abe: 3.749 | eve: 9.947 | bob: 3.723Epoch  16:  96% | abe: 3.749 | eve: 9.948 | bob: 3.723Epoch  16:  97% | abe: 3.749 | eve: 9.947 | bob: 3.723Epoch  16:  98% | abe: 3.748 | eve: 9.947 | bob: 3.722Epoch  16:  99% | abe: 3.748 | eve: 9.947 | bob: 3.722
New best Bob loss 3.7223599445550235 at epoch 16
Epoch  17:   0% | abe: 3.713 | eve: 9.938 | bob: 3.679Epoch  17:   0% | abe: 3.718 | eve: 9.936 | bob: 3.684Epoch  17:   1% | abe: 3.717 | eve: 9.942 | bob: 3.684Epoch  17:   2% | abe: 3.720 | eve: 9.935 | bob: 3.687Epoch  17:   3% | abe: 3.722 | eve: 9.938 | bob: 3.689Epoch  17:   3% | abe: 3.719 | eve: 9.945 | bob: 3.688Epoch  17:   4% | abe: 3.722 | eve: 9.944 | bob: 3.689Epoch  17:   5% | abe: 3.722 | eve: 9.935 | bob: 3.689Epoch  17:   6% | abe: 3.724 | eve: 9.934 | bob: 3.691Epoch  17:   7% | abe: 3.723 | eve: 9.937 | bob: 3.691Epoch  17:   7% | abe: 3.723 | eve: 9.937 | bob: 3.690Epoch  17:   8% | abe: 3.722 | eve: 9.938 | bob: 3.689Epoch  17:   9% | abe: 3.723 | eve: 9.932 | bob: 3.689Epoch  17:  10% | abe: 3.723 | eve: 9.936 | bob: 3.691Epoch  17:  10% | abe: 3.724 | eve: 9.932 | bob: 3.691Epoch  17:  11% | abe: 3.723 | eve: 9.932 | bob: 3.691Epoch  17:  12% | abe: 3.723 | eve: 9.932 | bob: 3.691Epoch  17:  13% | abe: 3.723 | eve: 9.932 | bob: 3.691Epoch  17:  14% | abe: 3.723 | eve: 9.932 | bob: 3.691Epoch  17:  14% | abe: 3.723 | eve: 9.933 | bob: 3.692Epoch  17:  15% | abe: 3.724 | eve: 9.933 | bob: 3.692Epoch  17:  16% | abe: 3.723 | eve: 9.933 | bob: 3.692Epoch  17:  17% | abe: 3.723 | eve: 9.933 | bob: 3.692Epoch  17:  17% | abe: 3.723 | eve: 9.934 | bob: 3.692Epoch  17:  18% | abe: 3.723 | eve: 9.936 | bob: 3.692Epoch  17:  19% | abe: 3.724 | eve: 9.936 | bob: 3.693Epoch  17:  20% | abe: 3.723 | eve: 9.934 | bob: 3.692Epoch  17:  21% | abe: 3.723 | eve: 9.935 | bob: 3.692Epoch  17:  21% | abe: 3.722 | eve: 9.934 | bob: 3.691Epoch  17:  22% | abe: 3.721 | eve: 9.934 | bob: 3.690Epoch  17:  23% | abe: 3.721 | eve: 9.935 | bob: 3.690Epoch  17:  24% | abe: 3.721 | eve: 9.937 | bob: 3.690Epoch  17:  25% | abe: 3.721 | eve: 9.936 | bob: 3.689Epoch  17:  25% | abe: 3.720 | eve: 9.935 | bob: 3.689Epoch  17:  26% | abe: 3.720 | eve: 9.936 | bob: 3.689Epoch  17:  27% | abe: 3.720 | eve: 9.937 | bob: 3.688Epoch  17:  28% | abe: 3.720 | eve: 9.938 | bob: 3.688Epoch  17:  28% | abe: 3.719 | eve: 9.938 | bob: 3.688Epoch  17:  29% | abe: 3.719 | eve: 9.940 | bob: 3.688Epoch  17:  30% | abe: 3.719 | eve: 9.939 | bob: 3.687Epoch  17:  31% | abe: 3.719 | eve: 9.940 | bob: 3.687Epoch  17:  32% | abe: 3.719 | eve: 9.939 | bob: 3.688Epoch  17:  32% | abe: 3.719 | eve: 9.938 | bob: 3.688Epoch  17:  33% | abe: 3.718 | eve: 9.938 | bob: 3.687Epoch  17:  34% | abe: 3.718 | eve: 9.938 | bob: 3.687Epoch  17:  35% | abe: 3.718 | eve: 9.938 | bob: 3.687Epoch  17:  35% | abe: 3.718 | eve: 9.938 | bob: 3.687Epoch  17:  36% | abe: 3.718 | eve: 9.939 | bob: 3.686Epoch  17:  37% | abe: 3.718 | eve: 9.938 | bob: 3.686Epoch  17:  38% | abe: 3.718 | eve: 9.938 | bob: 3.686Epoch  17:  39% | abe: 3.717 | eve: 9.938 | bob: 3.686Epoch  17:  39% | abe: 3.717 | eve: 9.937 | bob: 3.685Epoch  17:  40% | abe: 3.717 | eve: 9.938 | bob: 3.685Epoch  17:  41% | abe: 3.718 | eve: 9.938 | bob: 3.685Epoch  17:  42% | abe: 3.717 | eve: 9.938 | bob: 3.685Epoch  17:  42% | abe: 3.717 | eve: 9.938 | bob: 3.685Epoch  17:  43% | abe: 3.717 | eve: 9.939 | bob: 3.684Epoch  17:  44% | abe: 3.717 | eve: 9.938 | bob: 3.684Epoch  17:  45% | abe: 3.716 | eve: 9.938 | bob: 3.684Epoch  17:  46% | abe: 3.717 | eve: 9.938 | bob: 3.684Epoch  17:  46% | abe: 3.716 | eve: 9.938 | bob: 3.684Epoch  17:  47% | abe: 3.716 | eve: 9.938 | bob: 3.684Epoch  17:  48% | abe: 3.716 | eve: 9.938 | bob: 3.684Epoch  17:  49% | abe: 3.716 | eve: 9.936 | bob: 3.683Epoch  17:  50% | abe: 3.716 | eve: 9.936 | bob: 3.683Epoch  17:  50% | abe: 3.716 | eve: 9.937 | bob: 3.683Epoch  17:  51% | abe: 3.716 | eve: 9.938 | bob: 3.683Epoch  17:  52% | abe: 3.716 | eve: 9.938 | bob: 3.683Epoch  17:  53% | abe: 3.716 | eve: 9.937 | bob: 3.683Epoch  17:  53% | abe: 3.716 | eve: 9.938 | bob: 3.683Epoch  17:  54% | abe: 3.715 | eve: 9.938 | bob: 3.682Epoch  17:  55% | abe: 3.715 | eve: 9.938 | bob: 3.682Epoch  17:  56% | abe: 3.715 | eve: 9.939 | bob: 3.682Epoch  17:  57% | abe: 3.715 | eve: 9.938 | bob: 3.682Epoch  17:  57% | abe: 3.715 | eve: 9.938 | bob: 3.681Epoch  17:  58% | abe: 3.714 | eve: 9.939 | bob: 3.681Epoch  17:  59% | abe: 3.715 | eve: 9.939 | bob: 3.681Epoch  17:  60% | abe: 3.715 | eve: 9.940 | bob: 3.681Epoch  17:  60% | abe: 3.715 | eve: 9.940 | bob: 3.681Epoch  17:  61% | abe: 3.714 | eve: 9.940 | bob: 3.681Epoch  17:  62% | abe: 3.714 | eve: 9.940 | bob: 3.681Epoch  17:  63% | abe: 3.714 | eve: 9.939 | bob: 3.681Epoch  17:  64% | abe: 3.714 | eve: 9.940 | bob: 3.680Epoch  17:  64% | abe: 3.713 | eve: 9.940 | bob: 3.680Epoch  17:  65% | abe: 3.713 | eve: 9.940 | bob: 3.680Epoch  17:  66% | abe: 3.713 | eve: 9.940 | bob: 3.680Epoch  17:  67% | abe: 3.713 | eve: 9.940 | bob: 3.680Epoch  17:  67% | abe: 3.713 | eve: 9.940 | bob: 3.680Epoch  17:  68% | abe: 3.713 | eve: 9.941 | bob: 3.679Epoch  17:  69% | abe: 3.712 | eve: 9.941 | bob: 3.679Epoch  17:  70% | abe: 3.712 | eve: 9.941 | bob: 3.679Epoch  17:  71% | abe: 3.712 | eve: 9.941 | bob: 3.679Epoch  17:  71% | abe: 3.712 | eve: 9.941 | bob: 3.678Epoch  17:  72% | abe: 3.712 | eve: 9.941 | bob: 3.678Epoch  17:  73% | abe: 3.711 | eve: 9.942 | bob: 3.678Epoch  17:  74% | abe: 3.711 | eve: 9.942 | bob: 3.678Epoch  17:  75% | abe: 3.711 | eve: 9.943 | bob: 3.677Epoch  17:  75% | abe: 3.711 | eve: 9.942 | bob: 3.677Epoch  17:  76% | abe: 3.711 | eve: 9.943 | bob: 3.677Epoch  17:  77% | abe: 3.711 | eve: 9.943 | bob: 3.677Epoch  17:  78% | abe: 3.710 | eve: 9.943 | bob: 3.677Epoch  17:  78% | abe: 3.710 | eve: 9.943 | bob: 3.676Epoch  17:  79% | abe: 3.710 | eve: 9.942 | bob: 3.676Epoch  17:  80% | abe: 3.710 | eve: 9.942 | bob: 3.676Epoch  17:  81% | abe: 3.710 | eve: 9.942 | bob: 3.676Epoch  17:  82% | abe: 3.710 | eve: 9.942 | bob: 3.676Epoch  17:  82% | abe: 3.710 | eve: 9.942 | bob: 3.676Epoch  17:  83% | abe: 3.709 | eve: 9.942 | bob: 3.675Epoch  17:  84% | abe: 3.709 | eve: 9.943 | bob: 3.675Epoch  17:  85% | abe: 3.709 | eve: 9.943 | bob: 3.675Epoch  17:  85% | abe: 3.709 | eve: 9.943 | bob: 3.675Epoch  17:  86% | abe: 3.709 | eve: 9.943 | bob: 3.674Epoch  17:  87% | abe: 3.709 | eve: 9.943 | bob: 3.674Epoch  17:  88% | abe: 3.709 | eve: 9.943 | bob: 3.674Epoch  17:  89% | abe: 3.708 | eve: 9.943 | bob: 3.674Epoch  17:  89% | abe: 3.708 | eve: 9.943 | bob: 3.674Epoch  17:  90% | abe: 3.708 | eve: 9.943 | bob: 3.673Epoch  17:  91% | abe: 3.708 | eve: 9.943 | bob: 3.673Epoch  17:  92% | abe: 3.707 | eve: 9.943 | bob: 3.673Epoch  17:  92% | abe: 3.707 | eve: 9.943 | bob: 3.673Epoch  17:  93% | abe: 3.707 | eve: 9.943 | bob: 3.672Epoch  17:  94% | abe: 3.707 | eve: 9.943 | bob: 3.672Epoch  17:  95% | abe: 3.707 | eve: 9.943 | bob: 3.672Epoch  17:  96% | abe: 3.706 | eve: 9.942 | bob: 3.672Epoch  17:  96% | abe: 3.706 | eve: 9.942 | bob: 3.672Epoch  17:  97% | abe: 3.706 | eve: 9.941 | bob: 3.671Epoch  17:  98% | abe: 3.706 | eve: 9.942 | bob: 3.671Epoch  17:  99% | abe: 3.706 | eve: 9.942 | bob: 3.671
New best Bob loss 3.6708074346904596 at epoch 17
Epoch  18:   0% | abe: 3.687 | eve: 9.971 | bob: 3.642Epoch  18:   0% | abe: 3.689 | eve: 9.937 | bob: 3.644Epoch  18:   1% | abe: 3.683 | eve: 9.939 | bob: 3.643Epoch  18:   2% | abe: 3.682 | eve: 9.943 | bob: 3.641Epoch  18:   3% | abe: 3.684 | eve: 9.943 | bob: 3.643Epoch  18:   3% | abe: 3.684 | eve: 9.940 | bob: 3.643Epoch  18:   4% | abe: 3.681 | eve: 9.942 | bob: 3.642Epoch  18:   5% | abe: 3.682 | eve: 9.945 | bob: 3.644Epoch  18:   6% | abe: 3.682 | eve: 9.947 | bob: 3.643Epoch  18:   7% | abe: 3.680 | eve: 9.944 | bob: 3.642Epoch  18:   7% | abe: 3.680 | eve: 9.945 | bob: 3.642Epoch  18:   8% | abe: 3.680 | eve: 9.945 | bob: 3.641Epoch  18:   9% | abe: 3.678 | eve: 9.943 | bob: 3.640Epoch  18:  10% | abe: 3.679 | eve: 9.945 | bob: 3.641Epoch  18:  10% | abe: 3.678 | eve: 9.944 | bob: 3.640Epoch  18:  11% | abe: 3.678 | eve: 9.947 | bob: 3.640Epoch  18:  12% | abe: 3.677 | eve: 9.948 | bob: 3.639Epoch  18:  13% | abe: 3.678 | eve: 9.949 | bob: 3.640Epoch  18:  14% | abe: 3.678 | eve: 9.950 | bob: 3.640Epoch  18:  14% | abe: 3.678 | eve: 9.951 | bob: 3.639Epoch  18:  15% | abe: 3.678 | eve: 9.950 | bob: 3.640Epoch  18:  16% | abe: 3.677 | eve: 9.946 | bob: 3.639Epoch  18:  17% | abe: 3.677 | eve: 9.944 | bob: 3.640Epoch  18:  17% | abe: 3.678 | eve: 9.944 | bob: 3.640Epoch  18:  18% | abe: 3.678 | eve: 9.944 | bob: 3.640Epoch  18:  19% | abe: 3.678 | eve: 9.944 | bob: 3.639Epoch  18:  20% | abe: 3.678 | eve: 9.944 | bob: 3.639Epoch  18:  21% | abe: 3.678 | eve: 9.946 | bob: 3.639Epoch  18:  21% | abe: 3.678 | eve: 9.949 | bob: 3.639Epoch  18:  22% | abe: 3.678 | eve: 9.948 | bob: 3.639Epoch  18:  23% | abe: 3.677 | eve: 9.950 | bob: 3.639Epoch  18:  24% | abe: 3.677 | eve: 9.951 | bob: 3.639Epoch  18:  25% | abe: 3.677 | eve: 9.951 | bob: 3.639Epoch  18:  25% | abe: 3.677 | eve: 9.952 | bob: 3.639Epoch  18:  26% | abe: 3.677 | eve: 9.951 | bob: 3.639Epoch  18:  27% | abe: 3.678 | eve: 9.951 | bob: 3.639Epoch  18:  28% | abe: 3.678 | eve: 9.951 | bob: 3.638Epoch  18:  28% | abe: 3.677 | eve: 9.950 | bob: 3.638Epoch  18:  29% | abe: 3.677 | eve: 9.950 | bob: 3.638Epoch  18:  30% | abe: 3.677 | eve: 9.948 | bob: 3.638Epoch  18:  31% | abe: 3.677 | eve: 9.947 | bob: 3.638Epoch  18:  32% | abe: 3.677 | eve: 9.947 | bob: 3.637Epoch  18:  32% | abe: 3.676 | eve: 9.947 | bob: 3.637Epoch  18:  33% | abe: 3.676 | eve: 9.947 | bob: 3.637Epoch  18:  34% | abe: 3.676 | eve: 9.947 | bob: 3.637Epoch  18:  35% | abe: 3.676 | eve: 9.946 | bob: 3.636Epoch  18:  35% | abe: 3.676 | eve: 9.946 | bob: 3.636Epoch  18:  36% | abe: 3.676 | eve: 9.945 | bob: 3.637Epoch  18:  37% | abe: 3.676 | eve: 9.945 | bob: 3.637Epoch  18:  38% | abe: 3.676 | eve: 9.945 | bob: 3.637Epoch  18:  39% | abe: 3.676 | eve: 9.946 | bob: 3.637Epoch  18:  39% | abe: 3.676 | eve: 9.947 | bob: 3.636Epoch  18:  40% | abe: 3.676 | eve: 9.946 | bob: 3.636Epoch  18:  41% | abe: 3.676 | eve: 9.947 | bob: 3.636Epoch  18:  42% | abe: 3.676 | eve: 9.946 | bob: 3.636Epoch  18:  42% | abe: 3.676 | eve: 9.947 | bob: 3.636Epoch  18:  43% | abe: 3.676 | eve: 9.947 | bob: 3.636Epoch  18:  44% | abe: 3.676 | eve: 9.948 | bob: 3.636Epoch  18:  45% | abe: 3.675 | eve: 9.949 | bob: 3.636Epoch  18:  46% | abe: 3.675 | eve: 9.948 | bob: 3.636Epoch  18:  46% | abe: 3.675 | eve: 9.948 | bob: 3.635Epoch  18:  47% | abe: 3.674 | eve: 9.948 | bob: 3.635Epoch  18:  48% | abe: 3.674 | eve: 9.948 | bob: 3.635Epoch  18:  49% | abe: 3.674 | eve: 9.948 | bob: 3.634Epoch  18:  50% | abe: 3.674 | eve: 9.948 | bob: 3.634Epoch  18:  50% | abe: 3.674 | eve: 9.949 | bob: 3.634Epoch  18:  51% | abe: 3.674 | eve: 9.950 | bob: 3.634Epoch  18:  52% | abe: 3.674 | eve: 9.950 | bob: 3.634Epoch  18:  53% | abe: 3.674 | eve: 9.950 | bob: 3.634Epoch  18:  53% | abe: 3.674 | eve: 9.951 | bob: 3.634Epoch  18:  54% | abe: 3.674 | eve: 9.950 | bob: 3.634Epoch  18:  55% | abe: 3.674 | eve: 9.950 | bob: 3.634Epoch  18:  56% | abe: 3.673 | eve: 9.950 | bob: 3.634Epoch  18:  57% | abe: 3.673 | eve: 9.950 | bob: 3.633Epoch  18:  57% | abe: 3.673 | eve: 9.950 | bob: 3.633Epoch  18:  58% | abe: 3.673 | eve: 9.950 | bob: 3.633Epoch  18:  59% | abe: 3.673 | eve: 9.949 | bob: 3.633Epoch  18:  60% | abe: 3.673 | eve: 9.949 | bob: 3.633Epoch  18:  60% | abe: 3.673 | eve: 9.949 | bob: 3.633Epoch  18:  61% | abe: 3.672 | eve: 9.950 | bob: 3.632Epoch  18:  62% | abe: 3.672 | eve: 9.949 | bob: 3.632Epoch  18:  63% | abe: 3.672 | eve: 9.949 | bob: 3.632Epoch  18:  64% | abe: 3.672 | eve: 9.949 | bob: 3.632Epoch  18:  64% | abe: 3.672 | eve: 9.949 | bob: 3.632Epoch  18:  65% | abe: 3.672 | eve: 9.949 | bob: 3.631Epoch  18:  66% | abe: 3.672 | eve: 9.950 | bob: 3.631Epoch  18:  67% | abe: 3.671 | eve: 9.949 | bob: 3.631Epoch  18:  67% | abe: 3.671 | eve: 9.949 | bob: 3.631Epoch  18:  68% | abe: 3.671 | eve: 9.950 | bob: 3.631Epoch  18:  69% | abe: 3.671 | eve: 9.949 | bob: 3.631Epoch  18:  70% | abe: 3.671 | eve: 9.949 | bob: 3.630Epoch  18:  71% | abe: 3.671 | eve: 9.949 | bob: 3.630Epoch  18:  71% | abe: 3.671 | eve: 9.948 | bob: 3.630Epoch  18:  72% | abe: 3.670 | eve: 9.949 | bob: 3.630Epoch  18:  73% | abe: 3.670 | eve: 9.949 | bob: 3.629Epoch  18:  74% | abe: 3.670 | eve: 9.949 | bob: 3.629Epoch  18:  75% | abe: 3.670 | eve: 9.950 | bob: 3.629Epoch  18:  75% | abe: 3.670 | eve: 9.949 | bob: 3.629Epoch  18:  76% | abe: 3.670 | eve: 9.950 | bob: 3.629Epoch  18:  77% | abe: 3.670 | eve: 9.950 | bob: 3.629Epoch  18:  78% | abe: 3.670 | eve: 9.949 | bob: 3.628Epoch  18:  78% | abe: 3.669 | eve: 9.949 | bob: 3.628Epoch  18:  79% | abe: 3.669 | eve: 9.950 | bob: 3.628Epoch  18:  80% | abe: 3.669 | eve: 9.950 | bob: 3.628Epoch  18:  81% | abe: 3.669 | eve: 9.949 | bob: 3.628Epoch  18:  82% | abe: 3.668 | eve: 9.949 | bob: 3.627Epoch  18:  82% | abe: 3.668 | eve: 9.949 | bob: 3.627Epoch  18:  83% | abe: 3.668 | eve: 9.949 | bob: 3.627Epoch  18:  84% | abe: 3.668 | eve: 9.948 | bob: 3.627Epoch  18:  85% | abe: 3.668 | eve: 9.948 | bob: 3.627Epoch  18:  85% | abe: 3.668 | eve: 9.948 | bob: 3.627Epoch  18:  86% | abe: 3.668 | eve: 9.947 | bob: 3.626Epoch  18:  87% | abe: 3.667 | eve: 9.948 | bob: 3.626Epoch  18:  88% | abe: 3.667 | eve: 9.947 | bob: 3.626Epoch  18:  89% | abe: 3.667 | eve: 9.948 | bob: 3.626Epoch  18:  89% | abe: 3.667 | eve: 9.947 | bob: 3.626Epoch  18:  90% | abe: 3.667 | eve: 9.948 | bob: 3.625Epoch  18:  91% | abe: 3.667 | eve: 9.947 | bob: 3.625Epoch  18:  92% | abe: 3.666 | eve: 9.947 | bob: 3.625Epoch  18:  92% | abe: 3.666 | eve: 9.947 | bob: 3.625Epoch  18:  93% | abe: 3.666 | eve: 9.947 | bob: 3.625Epoch  18:  94% | abe: 3.666 | eve: 9.948 | bob: 3.625Epoch  18:  95% | abe: 3.666 | eve: 9.947 | bob: 3.624Epoch  18:  96% | abe: 3.666 | eve: 9.948 | bob: 3.624Epoch  18:  96% | abe: 3.665 | eve: 9.947 | bob: 3.624Epoch  18:  97% | abe: 3.665 | eve: 9.947 | bob: 3.624Epoch  18:  98% | abe: 3.665 | eve: 9.948 | bob: 3.624Epoch  18:  99% | abe: 3.665 | eve: 9.948 | bob: 3.623
New best Bob loss 3.6232779520505574 at epoch 18
Epoch  19:   0% | abe: 3.637 | eve: 9.981 | bob: 3.597Epoch  19:   0% | abe: 3.643 | eve: 9.971 | bob: 3.601Epoch  19:   1% | abe: 3.643 | eve: 9.974 | bob: 3.599Epoch  19:   2% | abe: 3.639 | eve: 9.966 | bob: 3.596Epoch  19:   3% | abe: 3.645 | eve: 9.967 | bob: 3.598Epoch  19:   3% | abe: 3.644 | eve: 9.968 | bob: 3.598Epoch  19:   4% | abe: 3.643 | eve: 9.954 | bob: 3.597Epoch  19:   5% | abe: 3.643 | eve: 9.957 | bob: 3.596Epoch  19:   6% | abe: 3.645 | eve: 9.956 | bob: 3.598Epoch  19:   7% | abe: 3.645 | eve: 9.954 | bob: 3.599Epoch  19:   7% | abe: 3.646 | eve: 9.956 | bob: 3.600Epoch  19:   8% | abe: 3.644 | eve: 9.956 | bob: 3.598Epoch  19:   9% | abe: 3.645 | eve: 9.953 | bob: 3.599Epoch  19:  10% | abe: 3.642 | eve: 9.956 | bob: 3.596Epoch  19:  10% | abe: 3.642 | eve: 9.958 | bob: 3.597Epoch  19:  11% | abe: 3.642 | eve: 9.953 | bob: 3.597Epoch  19:  12% | abe: 3.642 | eve: 9.957 | bob: 3.596Epoch  19:  13% | abe: 3.641 | eve: 9.957 | bob: 3.596Epoch  19:  14% | abe: 3.642 | eve: 9.956 | bob: 3.596Epoch  19:  14% | abe: 3.642 | eve: 9.954 | bob: 3.596Epoch  19:  15% | abe: 3.641 | eve: 9.953 | bob: 3.595Epoch  19:  16% | abe: 3.641 | eve: 9.954 | bob: 3.595Epoch  19:  17% | abe: 3.640 | eve: 9.952 | bob: 3.595Epoch  19:  17% | abe: 3.640 | eve: 9.953 | bob: 3.595Epoch  19:  18% | abe: 3.640 | eve: 9.954 | bob: 3.594Epoch  19:  19% | abe: 3.639 | eve: 9.953 | bob: 3.593Epoch  19:  20% | abe: 3.639 | eve: 9.953 | bob: 3.593Epoch  19:  21% | abe: 3.639 | eve: 9.952 | bob: 3.593Epoch  19:  21% | abe: 3.639 | eve: 9.953 | bob: 3.593Epoch  19:  22% | abe: 3.639 | eve: 9.952 | bob: 3.593Epoch  19:  23% | abe: 3.638 | eve: 9.949 | bob: 3.593Epoch  19:  24% | abe: 3.638 | eve: 9.949 | bob: 3.592Epoch  19:  25% | abe: 3.638 | eve: 9.948 | bob: 3.592Epoch  19:  25% | abe: 3.638 | eve: 9.948 | bob: 3.593Epoch  19:  26% | abe: 3.638 | eve: 9.950 | bob: 3.592Epoch  19:  27% | abe: 3.638 | eve: 9.951 | bob: 3.593Epoch  19:  28% | abe: 3.638 | eve: 9.950 | bob: 3.593Epoch  19:  28% | abe: 3.638 | eve: 9.950 | bob: 3.593Epoch  19:  29% | abe: 3.638 | eve: 9.949 | bob: 3.593Epoch  19:  30% | abe: 3.638 | eve: 9.950 | bob: 3.593Epoch  19:  31% | abe: 3.638 | eve: 9.949 | bob: 3.593Epoch  19:  32% | abe: 3.638 | eve: 9.949 | bob: 3.593Epoch  19:  32% | abe: 3.638 | eve: 9.950 | bob: 3.593Epoch  19:  33% | abe: 3.638 | eve: 9.949 | bob: 3.593Epoch  19:  34% | abe: 3.638 | eve: 9.951 | bob: 3.593Epoch  19:  35% | abe: 3.638 | eve: 9.951 | bob: 3.592Epoch  19:  35% | abe: 3.638 | eve: 9.951 | bob: 3.592Epoch  19:  36% | abe: 3.638 | eve: 9.951 | bob: 3.592Epoch  19:  37% | abe: 3.638 | eve: 9.951 | bob: 3.592Epoch  19:  38% | abe: 3.637 | eve: 9.952 | bob: 3.592Epoch  19:  39% | abe: 3.637 | eve: 9.952 | bob: 3.592Epoch  19:  39% | abe: 3.637 | eve: 9.952 | bob: 3.592Epoch  19:  40% | abe: 3.637 | eve: 9.952 | bob: 3.592Epoch  19:  41% | abe: 3.637 | eve: 9.952 | bob: 3.592Epoch  19:  42% | abe: 3.637 | eve: 9.952 | bob: 3.592Epoch  19:  42% | abe: 3.637 | eve: 9.952 | bob: 3.592Epoch  19:  43% | abe: 3.637 | eve: 9.951 | bob: 3.592Epoch  19:  44% | abe: 3.637 | eve: 9.951 | bob: 3.592Epoch  19:  45% | abe: 3.637 | eve: 9.951 | bob: 3.592Epoch  19:  46% | abe: 3.637 | eve: 9.951 | bob: 3.592Epoch  19:  46% | abe: 3.637 | eve: 9.951 | bob: 3.592Epoch  19:  47% | abe: 3.637 | eve: 9.951 | bob: 3.591Epoch  19:  48% | abe: 3.637 | eve: 9.951 | bob: 3.591Epoch  19:  49% | abe: 3.636 | eve: 9.950 | bob: 3.591Epoch  19:  50% | abe: 3.636 | eve: 9.950 | bob: 3.591Epoch  19:  50% | abe: 3.636 | eve: 9.950 | bob: 3.591Epoch  19:  51% | abe: 3.636 | eve: 9.950 | bob: 3.591Epoch  19:  52% | abe: 3.636 | eve: 9.951 | bob: 3.591Epoch  19:  53% | abe: 3.636 | eve: 9.950 | bob: 3.591Epoch  19:  53% | abe: 3.636 | eve: 9.950 | bob: 3.590Epoch  19:  54% | abe: 3.635 | eve: 9.950 | bob: 3.590Epoch  19:  55% | abe: 3.635 | eve: 9.950 | bob: 3.590Epoch  19:  56% | abe: 3.635 | eve: 9.950 | bob: 3.590Epoch  19:  57% | abe: 3.635 | eve: 9.949 | bob: 3.590Epoch  19:  57% | abe: 3.635 | eve: 9.949 | bob: 3.589Epoch  19:  58% | abe: 3.635 | eve: 9.948 | bob: 3.589Epoch  19:  59% | abe: 3.635 | eve: 9.949 | bob: 3.589Epoch  19:  60% | abe: 3.635 | eve: 9.948 | bob: 3.589Epoch  19:  60% | abe: 3.635 | eve: 9.948 | bob: 3.589Epoch  19:  61% | abe: 3.634 | eve: 9.948 | bob: 3.589Epoch  19:  62% | abe: 3.634 | eve: 9.947 | bob: 3.589Epoch  19:  63% | abe: 3.634 | eve: 9.947 | bob: 3.589Epoch  19:  64% | abe: 3.634 | eve: 9.947 | bob: 3.589Epoch  19:  64% | abe: 3.634 | eve: 9.947 | bob: 3.588Epoch  19:  65% | abe: 3.634 | eve: 9.947 | bob: 3.588Epoch  19:  66% | abe: 3.634 | eve: 9.947 | bob: 3.588Epoch  19:  67% | abe: 3.633 | eve: 9.947 | bob: 3.588Epoch  19:  67% | abe: 3.633 | eve: 9.947 | bob: 3.588Epoch  19:  68% | abe: 3.633 | eve: 9.947 | bob: 3.588Epoch  19:  69% | abe: 3.633 | eve: 9.947 | bob: 3.588Epoch  19:  70% | abe: 3.633 | eve: 9.948 | bob: 3.587Epoch  19:  71% | abe: 3.633 | eve: 9.947 | bob: 3.587Epoch  19:  71% | abe: 3.633 | eve: 9.948 | bob: 3.587Epoch  19:  72% | abe: 3.633 | eve: 9.947 | bob: 3.587Epoch  19:  73% | abe: 3.632 | eve: 9.947 | bob: 3.587Epoch  19:  74% | abe: 3.632 | eve: 9.947 | bob: 3.587Epoch  19:  75% | abe: 3.632 | eve: 9.946 | bob: 3.586Epoch  19:  75% | abe: 3.632 | eve: 9.947 | bob: 3.586Epoch  19:  76% | abe: 3.632 | eve: 9.947 | bob: 3.586Epoch  19:  77% | abe: 3.632 | eve: 9.947 | bob: 3.586Epoch  19:  78% | abe: 3.632 | eve: 9.947 | bob: 3.586Epoch  19:  78% | abe: 3.632 | eve: 9.947 | bob: 3.586Epoch  19:  79% | abe: 3.631 | eve: 9.946 | bob: 3.585Epoch  19:  80% | abe: 3.631 | eve: 9.946 | bob: 3.585Epoch  19:  81% | abe: 3.631 | eve: 9.946 | bob: 3.585Epoch  19:  82% | abe: 3.631 | eve: 9.946 | bob: 3.585Epoch  19:  82% | abe: 3.631 | eve: 9.945 | bob: 3.585Epoch  19:  83% | abe: 3.630 | eve: 9.945 | bob: 3.585Epoch  19:  84% | abe: 3.630 | eve: 9.945 | bob: 3.584Epoch  19:  85% | abe: 3.630 | eve: 9.944 | bob: 3.584Epoch  19:  85% | abe: 3.630 | eve: 9.944 | bob: 3.584Epoch  19:  86% | abe: 3.630 | eve: 9.945 | bob: 3.584Epoch  19:  87% | abe: 3.630 | eve: 9.945 | bob: 3.584Epoch  19:  88% | abe: 3.630 | eve: 9.945 | bob: 3.584Epoch  19:  89% | abe: 3.630 | eve: 9.945 | bob: 3.584Epoch  19:  89% | abe: 3.629 | eve: 9.945 | bob: 3.584Epoch  19:  90% | abe: 3.629 | eve: 9.945 | bob: 3.584Epoch  19:  91% | abe: 3.629 | eve: 9.946 | bob: 3.584Epoch  19:  92% | abe: 3.629 | eve: 9.945 | bob: 3.583Epoch  19:  92% | abe: 3.629 | eve: 9.945 | bob: 3.583Epoch  19:  93% | abe: 3.629 | eve: 9.946 | bob: 3.583Epoch  19:  94% | abe: 3.629 | eve: 9.946 | bob: 3.583Epoch  19:  95% | abe: 3.629 | eve: 9.946 | bob: 3.583Epoch  19:  96% | abe: 3.629 | eve: 9.946 | bob: 3.583Epoch  19:  96% | abe: 3.628 | eve: 9.946 | bob: 3.583Epoch  19:  97% | abe: 3.628 | eve: 9.947 | bob: 3.582Epoch  19:  98% | abe: 3.628 | eve: 9.946 | bob: 3.582Epoch  19:  99% | abe: 3.628 | eve: 9.946 | bob: 3.582
New best Bob loss 3.5821870840844667 at epoch 19
Epoch  20:   0% | abe: 3.607 | eve: 9.969 | bob: 3.557Epoch  20:   0% | abe: 3.606 | eve: 9.959 | bob: 3.555Epoch  20:   1% | abe: 3.602 | eve: 9.963 | bob: 3.555Epoch  20:   2% | abe: 3.605 | eve: 9.968 | bob: 3.560Epoch  20:   3% | abe: 3.608 | eve: 9.955 | bob: 3.566Epoch  20:   3% | abe: 3.609 | eve: 9.947 | bob: 3.565Epoch  20:   4% | abe: 3.611 | eve: 9.955 | bob: 3.567Epoch  20:   5% | abe: 3.609 | eve: 9.953 | bob: 3.564Epoch  20:   6% | abe: 3.608 | eve: 9.955 | bob: 3.563Epoch  20:   7% | abe: 3.608 | eve: 9.958 | bob: 3.562Epoch  20:   7% | abe: 3.608 | eve: 9.954 | bob: 3.562Epoch  20:   8% | abe: 3.608 | eve: 9.953 | bob: 3.561Epoch  20:   9% | abe: 3.609 | eve: 9.954 | bob: 3.562Epoch  20:  10% | abe: 3.609 | eve: 9.956 | bob: 3.562Epoch  20:  10% | abe: 3.608 | eve: 9.951 | bob: 3.561Epoch  20:  11% | abe: 3.608 | eve: 9.951 | bob: 3.561Epoch  20:  12% | abe: 3.609 | eve: 9.952 | bob: 3.562Epoch  20:  13% | abe: 3.609 | eve: 9.951 | bob: 3.561Epoch  20:  14% | abe: 3.609 | eve: 9.948 | bob: 3.561Epoch  20:  14% | abe: 3.608 | eve: 9.950 | bob: 3.560Epoch  20:  15% | abe: 3.609 | eve: 9.952 | bob: 3.560Epoch  20:  16% | abe: 3.608 | eve: 9.954 | bob: 3.559Epoch  20:  17% | abe: 3.608 | eve: 9.955 | bob: 3.559Epoch  20:  17% | abe: 3.607 | eve: 9.957 | bob: 3.558Epoch  20:  18% | abe: 3.607 | eve: 9.957 | bob: 3.558Epoch  20:  19% | abe: 3.606 | eve: 9.956 | bob: 3.558Epoch  20:  20% | abe: 3.606 | eve: 9.957 | bob: 3.558Epoch  20:  21% | abe: 3.607 | eve: 9.957 | bob: 3.558Epoch  20:  21% | abe: 3.607 | eve: 9.959 | bob: 3.558Epoch  20:  22% | abe: 3.607 | eve: 9.957 | bob: 3.558Epoch  20:  23% | abe: 3.606 | eve: 9.956 | bob: 3.557Epoch  20:  24% | abe: 3.606 | eve: 9.954 | bob: 3.557Epoch  20:  25% | abe: 3.605 | eve: 9.954 | bob: 3.556Epoch  20:  25% | abe: 3.605 | eve: 9.953 | bob: 3.556Epoch  20:  26% | abe: 3.605 | eve: 9.952 | bob: 3.556Epoch  20:  27% | abe: 3.605 | eve: 9.952 | bob: 3.556Epoch  20:  28% | abe: 3.605 | eve: 9.952 | bob: 3.556Epoch  20:  28% | abe: 3.605 | eve: 9.952 | bob: 3.556Epoch  20:  29% | abe: 3.605 | eve: 9.953 | bob: 3.555Epoch  20:  30% | abe: 3.605 | eve: 9.952 | bob: 3.555Epoch  20:  31% | abe: 3.605 | eve: 9.952 | bob: 3.555Epoch  20:  32% | abe: 3.605 | eve: 9.953 | bob: 3.555Epoch  20:  32% | abe: 3.605 | eve: 9.953 | bob: 3.555Epoch  20:  33% | abe: 3.605 | eve: 9.952 | bob: 3.555Epoch  20:  34% | abe: 3.604 | eve: 9.951 | bob: 3.555Epoch  20:  35% | abe: 3.604 | eve: 9.951 | bob: 3.554Epoch  20:  35% | abe: 3.604 | eve: 9.952 | bob: 3.554Epoch  20:  36% | abe: 3.603 | eve: 9.951 | bob: 3.554Epoch  20:  37% | abe: 3.604 | eve: 9.950 | bob: 3.554Epoch  20:  38% | abe: 3.603 | eve: 9.950 | bob: 3.554Epoch  20:  39% | abe: 3.603 | eve: 9.949 | bob: 3.554Epoch  20:  39% | abe: 3.603 | eve: 9.948 | bob: 3.554Epoch  20:  40% | abe: 3.603 | eve: 9.947 | bob: 3.554Epoch  20:  41% | abe: 3.603 | eve: 9.948 | bob: 3.553Epoch  20:  42% | abe: 3.603 | eve: 9.949 | bob: 3.553Epoch  20:  42% | abe: 3.603 | eve: 9.949 | bob: 3.553Epoch  20:  43% | abe: 3.603 | eve: 9.949 | bob: 3.553Epoch  20:  44% | abe: 3.603 | eve: 9.949 | bob: 3.553Epoch  20:  45% | abe: 3.602 | eve: 9.949 | bob: 3.553Epoch  20:  46% | abe: 3.602 | eve: 9.948 | bob: 3.552Epoch  20:  46% | abe: 3.602 | eve: 9.947 | bob: 3.553Epoch  20:  47% | abe: 3.602 | eve: 9.947 | bob: 3.553Epoch  20:  48% | abe: 3.602 | eve: 9.947 | bob: 3.552Epoch  20:  49% | abe: 3.602 | eve: 9.947 | bob: 3.552Epoch  20:  50% | abe: 3.602 | eve: 9.947 | bob: 3.552Epoch  20:  50% | abe: 3.601 | eve: 9.948 | bob: 3.551Epoch  20:  51% | abe: 3.601 | eve: 9.947 | bob: 3.551Epoch  20:  52% | abe: 3.601 | eve: 9.947 | bob: 3.551Epoch  20:  53% | abe: 3.601 | eve: 9.948 | bob: 3.551Epoch  20:  53% | abe: 3.600 | eve: 9.948 | bob: 3.550Epoch  20:  54% | abe: 3.600 | eve: 9.948 | bob: 3.550Epoch  20:  55% | abe: 3.600 | eve: 9.948 | bob: 3.550Epoch  20:  56% | abe: 3.600 | eve: 9.948 | bob: 3.550Epoch  20:  57% | abe: 3.600 | eve: 9.948 | bob: 3.550Epoch  20:  57% | abe: 3.600 | eve: 9.948 | bob: 3.550Epoch  20:  58% | abe: 3.600 | eve: 9.947 | bob: 3.549Epoch  20:  59% | abe: 3.599 | eve: 9.947 | bob: 3.549Epoch  20:  60% | abe: 3.599 | eve: 9.947 | bob: 3.549Epoch  20:  60% | abe: 3.599 | eve: 9.947 | bob: 3.549Epoch  20:  61% | abe: 3.599 | eve: 9.947 | bob: 3.550Epoch  20:  62% | abe: 3.599 | eve: 9.948 | bob: 3.549Epoch  20:  63% | abe: 3.599 | eve: 9.948 | bob: 3.549Epoch  20:  64% | abe: 3.599 | eve: 9.948 | bob: 3.549Epoch  20:  64% | abe: 3.599 | eve: 9.948 | bob: 3.549Epoch  20:  65% | abe: 3.599 | eve: 9.948 | bob: 3.549Epoch  20:  66% | abe: 3.598 | eve: 9.947 | bob: 3.549Epoch  20:  67% | abe: 3.598 | eve: 9.948 | bob: 3.548Epoch  20:  67% | abe: 3.598 | eve: 9.948 | bob: 3.548Epoch  20:  68% | abe: 3.598 | eve: 9.948 | bob: 3.548Epoch  20:  69% | abe: 3.598 | eve: 9.948 | bob: 3.548Epoch  20:  70% | abe: 3.597 | eve: 9.948 | bob: 3.548Epoch  20:  71% | abe: 3.597 | eve: 9.948 | bob: 3.547Epoch  20:  71% | abe: 3.597 | eve: 9.948 | bob: 3.547Epoch  20:  72% | abe: 3.597 | eve: 9.949 | bob: 3.547Epoch  20:  73% | abe: 3.597 | eve: 9.949 | bob: 3.547Epoch  20:  74% | abe: 3.597 | eve: 9.949 | bob: 3.547Epoch  20:  75% | abe: 3.597 | eve: 9.949 | bob: 3.547Epoch  20:  75% | abe: 3.596 | eve: 9.949 | bob: 3.547Epoch  20:  76% | abe: 3.596 | eve: 9.948 | bob: 3.547Epoch  20:  77% | abe: 3.596 | eve: 9.948 | bob: 3.547Epoch  20:  78% | abe: 3.596 | eve: 9.948 | bob: 3.547Epoch  20:  78% | abe: 3.596 | eve: 9.948 | bob: 3.546Epoch  20:  79% | abe: 3.596 | eve: 9.948 | bob: 3.546Epoch  20:  80% | abe: 3.596 | eve: 9.948 | bob: 3.546Epoch  20:  81% | abe: 3.596 | eve: 9.947 | bob: 3.546Epoch  20:  82% | abe: 3.596 | eve: 9.947 | bob: 3.546Epoch  20:  82% | abe: 3.595 | eve: 9.948 | bob: 3.546Epoch  20:  83% | abe: 3.595 | eve: 9.948 | bob: 3.545Epoch  20:  84% | abe: 3.595 | eve: 9.948 | bob: 3.545Epoch  20:  85% | abe: 3.595 | eve: 9.947 | bob: 3.545Epoch  20:  85% | abe: 3.595 | eve: 9.948 | bob: 3.545Epoch  20:  86% | abe: 3.595 | eve: 9.947 | bob: 3.545Epoch  20:  87% | abe: 3.594 | eve: 9.947 | bob: 3.544Epoch  20:  88% | abe: 3.594 | eve: 9.948 | bob: 3.544Epoch  20:  89% | abe: 3.594 | eve: 9.947 | bob: 3.544Epoch  20:  89% | abe: 3.594 | eve: 9.947 | bob: 3.544Epoch  20:  90% | abe: 3.594 | eve: 9.947 | bob: 3.544Epoch  20:  91% | abe: 3.594 | eve: 9.947 | bob: 3.544Epoch  20:  92% | abe: 3.594 | eve: 9.947 | bob: 3.544Epoch  20:  92% | abe: 3.594 | eve: 9.947 | bob: 3.544Epoch  20:  93% | abe: 3.594 | eve: 9.947 | bob: 3.544Epoch  20:  94% | abe: 3.594 | eve: 9.947 | bob: 3.543Epoch  20:  95% | abe: 3.593 | eve: 9.947 | bob: 3.543Epoch  20:  96% | abe: 3.593 | eve: 9.948 | bob: 3.543Epoch  20:  96% | abe: 3.593 | eve: 9.947 | bob: 3.543Epoch  20:  97% | abe: 3.593 | eve: 9.947 | bob: 3.543Epoch  20:  98% | abe: 3.593 | eve: 9.947 | bob: 3.543Epoch  20:  99% | abe: 3.593 | eve: 9.947 | bob: 3.543
New best Bob loss 3.542532826961178 at epoch 20
Epoch  21:   0% | abe: 3.575 | eve: 10.002 | bob: 3.531Epoch  21:   0% | abe: 3.585 | eve: 9.962 | bob: 3.537Epoch  21:   1% | abe: 3.584 | eve: 9.936 | bob: 3.536Epoch  21:   2% | abe: 3.580 | eve: 9.944 | bob: 3.532Epoch  21:   3% | abe: 3.581 | eve: 9.941 | bob: 3.533Epoch  21:   3% | abe: 3.578 | eve: 9.939 | bob: 3.530Epoch  21:   4% | abe: 3.578 | eve: 9.946 | bob: 3.529Epoch  21:   5% | abe: 3.576 | eve: 9.948 | bob: 3.528Epoch  21:   6% | abe: 3.576 | eve: 9.953 | bob: 3.527Epoch  21:   7% | abe: 3.576 | eve: 9.958 | bob: 3.527Epoch  21:   7% | abe: 3.574 | eve: 9.952 | bob: 3.525Epoch  21:   8% | abe: 3.573 | eve: 9.954 | bob: 3.523Epoch  21:   9% | abe: 3.574 | eve: 9.953 | bob: 3.524Epoch  21:  10% | abe: 3.573 | eve: 9.956 | bob: 3.522Epoch  21:  10% | abe: 3.574 | eve: 9.952 | bob: 3.523Epoch  21:  11% | abe: 3.572 | eve: 9.952 | bob: 3.522Epoch  21:  12% | abe: 3.572 | eve: 9.953 | bob: 3.522Epoch  21:  13% | abe: 3.572 | eve: 9.953 | bob: 3.521Epoch  21:  14% | abe: 3.571 | eve: 9.955 | bob: 3.520Epoch  21:  14% | abe: 3.572 | eve: 9.953 | bob: 3.521Epoch  21:  15% | abe: 3.571 | eve: 9.954 | bob: 3.520Epoch  21:  16% | abe: 3.571 | eve: 9.954 | bob: 3.520Epoch  21:  17% | abe: 3.570 | eve: 9.954 | bob: 3.520Epoch  21:  17% | abe: 3.571 | eve: 9.952 | bob: 3.520Epoch  21:  18% | abe: 3.570 | eve: 9.952 | bob: 3.520Epoch  21:  19% | abe: 3.570 | eve: 9.952 | bob: 3.520Epoch  21:  20% | abe: 3.570 | eve: 9.952 | bob: 3.520Epoch  21:  21% | abe: 3.571 | eve: 9.951 | bob: 3.520Epoch  21:  21% | abe: 3.570 | eve: 9.952 | bob: 3.519Epoch  21:  22% | abe: 3.570 | eve: 9.952 | bob: 3.519Epoch  21:  23% | abe: 3.570 | eve: 9.951 | bob: 3.519Epoch  21:  24% | abe: 3.570 | eve: 9.951 | bob: 3.519Epoch  21:  25% | abe: 3.569 | eve: 9.949 | bob: 3.519Epoch  21:  25% | abe: 3.569 | eve: 9.948 | bob: 3.519Epoch  21:  26% | abe: 3.569 | eve: 9.950 | bob: 3.519Epoch  21:  27% | abe: 3.569 | eve: 9.951 | bob: 3.519Epoch  21:  28% | abe: 3.569 | eve: 9.952 | bob: 3.519Epoch  21:  28% | abe: 3.569 | eve: 9.953 | bob: 3.519Epoch  21:  29% | abe: 3.569 | eve: 9.951 | bob: 3.519Epoch  21:  30% | abe: 3.568 | eve: 9.951 | bob: 3.519Epoch  21:  31% | abe: 3.568 | eve: 9.951 | bob: 3.518Epoch  21:  32% | abe: 3.568 | eve: 9.951 | bob: 3.518Epoch  21:  32% | abe: 3.568 | eve: 9.952 | bob: 3.518Epoch  21:  33% | abe: 3.568 | eve: 9.952 | bob: 3.518Epoch  21:  34% | abe: 3.568 | eve: 9.952 | bob: 3.518Epoch  21:  35% | abe: 3.568 | eve: 9.952 | bob: 3.518Epoch  21:  35% | abe: 3.568 | eve: 9.952 | bob: 3.518Epoch  21:  36% | abe: 3.568 | eve: 9.952 | bob: 3.518Epoch  21:  37% | abe: 3.567 | eve: 9.952 | bob: 3.518Epoch  21:  38% | abe: 3.568 | eve: 9.952 | bob: 3.518Epoch  21:  39% | abe: 3.568 | eve: 9.953 | bob: 3.518Epoch  21:  39% | abe: 3.568 | eve: 9.953 | bob: 3.518Epoch  21:  40% | abe: 3.568 | eve: 9.953 | bob: 3.518Epoch  21:  41% | abe: 3.567 | eve: 9.954 | bob: 3.518Epoch  21:  42% | abe: 3.568 | eve: 9.954 | bob: 3.518Epoch  21:  42% | abe: 3.567 | eve: 9.954 | bob: 3.518Epoch  21:  43% | abe: 3.567 | eve: 9.954 | bob: 3.518Epoch  21:  44% | abe: 3.567 | eve: 9.955 | bob: 3.518Epoch  21:  45% | abe: 3.567 | eve: 9.955 | bob: 3.518Epoch  21:  46% | abe: 3.567 | eve: 9.954 | bob: 3.517Epoch  21:  46% | abe: 3.567 | eve: 9.955 | bob: 3.517Epoch  21:  47% | abe: 3.567 | eve: 9.954 | bob: 3.517Epoch  21:  48% | abe: 3.567 | eve: 9.954 | bob: 3.517Epoch  21:  49% | abe: 3.567 | eve: 9.953 | bob: 3.517Epoch  21:  50% | abe: 3.567 | eve: 9.953 | bob: 3.517Epoch  21:  50% | abe: 3.567 | eve: 9.953 | bob: 3.517Epoch  21:  51% | abe: 3.567 | eve: 9.952 | bob: 3.517Epoch  21:  52% | abe: 3.566 | eve: 9.952 | bob: 3.516Epoch  21:  53% | abe: 3.566 | eve: 9.951 | bob: 3.516Epoch  21:  53% | abe: 3.566 | eve: 9.952 | bob: 3.516Epoch  21:  54% | abe: 3.566 | eve: 9.951 | bob: 3.516Epoch  21:  55% | abe: 3.566 | eve: 9.952 | bob: 3.516Epoch  21:  56% | abe: 3.565 | eve: 9.952 | bob: 3.515Epoch  21:  57% | abe: 3.565 | eve: 9.952 | bob: 3.515Epoch  21:  57% | abe: 3.565 | eve: 9.952 | bob: 3.515Epoch  21:  58% | abe: 3.565 | eve: 9.952 | bob: 3.515Epoch  21:  59% | abe: 3.565 | eve: 9.951 | bob: 3.515Epoch  21:  60% | abe: 3.565 | eve: 9.951 | bob: 3.515Epoch  21:  60% | abe: 3.565 | eve: 9.950 | bob: 3.515Epoch  21:  61% | abe: 3.564 | eve: 9.950 | bob: 3.514Epoch  21:  62% | abe: 3.564 | eve: 9.949 | bob: 3.514Epoch  21:  63% | abe: 3.564 | eve: 9.949 | bob: 3.515Epoch  21:  64% | abe: 3.564 | eve: 9.949 | bob: 3.514Epoch  21:  64% | abe: 3.564 | eve: 9.949 | bob: 3.514Epoch  21:  65% | abe: 3.564 | eve: 9.949 | bob: 3.514Epoch  21:  66% | abe: 3.564 | eve: 9.950 | bob: 3.514Epoch  21:  67% | abe: 3.564 | eve: 9.950 | bob: 3.514Epoch  21:  67% | abe: 3.563 | eve: 9.950 | bob: 3.514Epoch  21:  68% | abe: 3.563 | eve: 9.950 | bob: 3.514Epoch  21:  69% | abe: 3.563 | eve: 9.950 | bob: 3.514Epoch  21:  70% | abe: 3.563 | eve: 9.950 | bob: 3.514Epoch  21:  71% | abe: 3.563 | eve: 9.950 | bob: 3.514Epoch  21:  71% | abe: 3.563 | eve: 9.951 | bob: 3.513Epoch  21:  72% | abe: 3.563 | eve: 9.950 | bob: 3.513Epoch  21:  73% | abe: 3.563 | eve: 9.950 | bob: 3.513Epoch  21:  74% | abe: 3.563 | eve: 9.950 | bob: 3.513Epoch  21:  75% | abe: 3.563 | eve: 9.950 | bob: 3.513Epoch  21:  75% | abe: 3.563 | eve: 9.951 | bob: 3.513Epoch  21:  76% | abe: 3.563 | eve: 9.951 | bob: 3.513Epoch  21:  77% | abe: 3.563 | eve: 9.950 | bob: 3.513Epoch  21:  78% | abe: 3.563 | eve: 9.951 | bob: 3.513Epoch  21:  78% | abe: 3.563 | eve: 9.950 | bob: 3.513Epoch  21:  79% | abe: 3.563 | eve: 9.950 | bob: 3.513Epoch  21:  80% | abe: 3.562 | eve: 9.950 | bob: 3.512Epoch  21:  81% | abe: 3.562 | eve: 9.950 | bob: 3.512Epoch  21:  82% | abe: 3.562 | eve: 9.950 | bob: 3.512Epoch  21:  82% | abe: 3.562 | eve: 9.950 | bob: 3.512Epoch  21:  83% | abe: 3.562 | eve: 9.951 | bob: 3.512Epoch  21:  84% | abe: 3.562 | eve: 9.951 | bob: 3.512Epoch  21:  85% | abe: 3.561 | eve: 9.951 | bob: 3.512Epoch  21:  85% | abe: 3.561 | eve: 9.951 | bob: 3.511Epoch  21:  86% | abe: 3.561 | eve: 9.950 | bob: 3.511Epoch  21:  87% | abe: 3.561 | eve: 9.950 | bob: 3.511Epoch  21:  88% | abe: 3.561 | eve: 9.950 | bob: 3.511Epoch  21:  89% | abe: 3.561 | eve: 9.950 | bob: 3.511Epoch  21:  89% | abe: 3.561 | eve: 9.949 | bob: 3.511Epoch  21:  90% | abe: 3.561 | eve: 9.949 | bob: 3.511Epoch  21:  91% | abe: 3.560 | eve: 9.949 | bob: 3.511Epoch  21:  92% | abe: 3.560 | eve: 9.949 | bob: 3.511Epoch  21:  92% | abe: 3.560 | eve: 9.948 | bob: 3.511Epoch  21:  93% | abe: 3.560 | eve: 9.948 | bob: 3.510Epoch  21:  94% | abe: 3.560 | eve: 9.948 | bob: 3.511Epoch  21:  95% | abe: 3.560 | eve: 9.949 | bob: 3.510Epoch  21:  96% | abe: 3.560 | eve: 9.949 | bob: 3.510Epoch  21:  96% | abe: 3.560 | eve: 9.949 | bob: 3.510Epoch  21:  97% | abe: 3.560 | eve: 9.949 | bob: 3.510Epoch  21:  98% | abe: 3.560 | eve: 9.949 | bob: 3.510Epoch  21:  99% | abe: 3.559 | eve: 9.949 | bob: 3.510
New best Bob loss 3.509590699203841 at epoch 21
Epoch  22:   0% | abe: 3.530 | eve: 9.908 | bob: 3.478Epoch  22:   0% | abe: 3.537 | eve: 9.909 | bob: 3.491Epoch  22:   1% | abe: 3.541 | eve: 9.936 | bob: 3.495Epoch  22:   2% | abe: 3.542 | eve: 9.950 | bob: 3.494Epoch  22:   3% | abe: 3.541 | eve: 9.941 | bob: 3.493Epoch  22:   3% | abe: 3.543 | eve: 9.939 | bob: 3.496Epoch  22:   4% | abe: 3.545 | eve: 9.938 | bob: 3.499Epoch  22:   5% | abe: 3.545 | eve: 9.936 | bob: 3.500Epoch  22:   6% | abe: 3.543 | eve: 9.937 | bob: 3.498Epoch  22:   7% | abe: 3.543 | eve: 9.942 | bob: 3.497Epoch  22:   7% | abe: 3.543 | eve: 9.944 | bob: 3.497Epoch  22:   8% | abe: 3.544 | eve: 9.945 | bob: 3.498Epoch  22:   9% | abe: 3.544 | eve: 9.937 | bob: 3.499Epoch  22:  10% | abe: 3.543 | eve: 9.938 | bob: 3.498Epoch  22:  10% | abe: 3.543 | eve: 9.935 | bob: 3.498Epoch  22:  11% | abe: 3.543 | eve: 9.934 | bob: 3.497Epoch  22:  12% | abe: 3.543 | eve: 9.938 | bob: 3.498Epoch  22:  13% | abe: 3.544 | eve: 9.936 | bob: 3.498Epoch  22:  14% | abe: 3.542 | eve: 9.936 | bob: 3.496Epoch  22:  14% | abe: 3.543 | eve: 9.936 | bob: 3.497Epoch  22:  15% | abe: 3.543 | eve: 9.933 | bob: 3.497Epoch  22:  16% | abe: 3.543 | eve: 9.932 | bob: 3.497Epoch  22:  17% | abe: 3.542 | eve: 9.931 | bob: 3.495Epoch  22:  17% | abe: 3.542 | eve: 9.933 | bob: 3.496Epoch  22:  18% | abe: 3.542 | eve: 9.935 | bob: 3.496Epoch  22:  19% | abe: 3.542 | eve: 9.937 | bob: 3.495Epoch  22:  20% | abe: 3.542 | eve: 9.939 | bob: 3.495Epoch  22:  21% | abe: 3.542 | eve: 9.940 | bob: 3.495Epoch  22:  21% | abe: 3.542 | eve: 9.943 | bob: 3.494Epoch  22:  22% | abe: 3.542 | eve: 9.940 | bob: 3.494Epoch  22:  23% | abe: 3.542 | eve: 9.940 | bob: 3.495Epoch  22:  24% | abe: 3.542 | eve: 9.939 | bob: 3.495Epoch  22:  25% | abe: 3.542 | eve: 9.941 | bob: 3.495Epoch  22:  25% | abe: 3.542 | eve: 9.940 | bob: 3.494Epoch  22:  26% | abe: 3.542 | eve: 9.939 | bob: 3.494Epoch  22:  27% | abe: 3.542 | eve: 9.941 | bob: 3.494Epoch  22:  28% | abe: 3.541 | eve: 9.942 | bob: 3.494Epoch  22:  28% | abe: 3.542 | eve: 9.942 | bob: 3.494Epoch  22:  29% | abe: 3.542 | eve: 9.942 | bob: 3.494Epoch  22:  30% | abe: 3.542 | eve: 9.942 | bob: 3.494Epoch  22:  31% | abe: 3.541 | eve: 9.941 | bob: 3.494Epoch  22:  32% | abe: 3.541 | eve: 9.941 | bob: 3.494Epoch  22:  32% | abe: 3.541 | eve: 9.941 | bob: 3.494Epoch  22:  33% | abe: 3.541 | eve: 9.940 | bob: 3.494Epoch  22:  34% | abe: 3.541 | eve: 9.940 | bob: 3.493Epoch  22:  35% | abe: 3.540 | eve: 9.941 | bob: 3.493Epoch  22:  35% | abe: 3.540 | eve: 9.941 | bob: 3.493Epoch  22:  36% | abe: 3.540 | eve: 9.942 | bob: 3.493Epoch  22:  37% | abe: 3.540 | eve: 9.942 | bob: 3.494Epoch  22:  38% | abe: 3.540 | eve: 9.941 | bob: 3.494Epoch  22:  39% | abe: 3.540 | eve: 9.942 | bob: 3.493Epoch  22:  39% | abe: 3.540 | eve: 9.942 | bob: 3.493Epoch  22:  40% | abe: 3.540 | eve: 9.941 | bob: 3.493Epoch  22:  41% | abe: 3.540 | eve: 9.941 | bob: 3.493Epoch  22:  42% | abe: 3.540 | eve: 9.941 | bob: 3.493Epoch  22:  42% | abe: 3.539 | eve: 9.941 | bob: 3.493Epoch  22:  43% | abe: 3.539 | eve: 9.942 | bob: 3.493Epoch  22:  44% | abe: 3.539 | eve: 9.942 | bob: 3.492Epoch  22:  45% | abe: 3.539 | eve: 9.942 | bob: 3.492Epoch  22:  46% | abe: 3.538 | eve: 9.942 | bob: 3.492Epoch  22:  46% | abe: 3.538 | eve: 9.942 | bob: 3.492Epoch  22:  47% | abe: 3.538 | eve: 9.942 | bob: 3.492Epoch  22:  48% | abe: 3.538 | eve: 9.941 | bob: 3.492Epoch  22:  49% | abe: 3.539 | eve: 9.942 | bob: 3.492Epoch  22:  50% | abe: 3.538 | eve: 9.941 | bob: 3.491Epoch  22:  50% | abe: 3.538 | eve: 9.941 | bob: 3.491Epoch  22:  51% | abe: 3.538 | eve: 9.941 | bob: 3.491Epoch  22:  52% | abe: 3.538 | eve: 9.940 | bob: 3.491Epoch  22:  53% | abe: 3.538 | eve: 9.940 | bob: 3.491Epoch  22:  53% | abe: 3.538 | eve: 9.940 | bob: 3.491Epoch  22:  54% | abe: 3.538 | eve: 9.940 | bob: 3.490Epoch  22:  55% | abe: 3.537 | eve: 9.940 | bob: 3.490Epoch  22:  56% | abe: 3.537 | eve: 9.940 | bob: 3.490Epoch  22:  57% | abe: 3.537 | eve: 9.940 | bob: 3.490Epoch  22:  57% | abe: 3.537 | eve: 9.940 | bob: 3.490Epoch  22:  58% | abe: 3.537 | eve: 9.940 | bob: 3.490Epoch  22:  59% | abe: 3.537 | eve: 9.940 | bob: 3.490Epoch  22:  60% | abe: 3.537 | eve: 9.940 | bob: 3.489Epoch  22:  60% | abe: 3.536 | eve: 9.939 | bob: 3.489Epoch  22:  61% | abe: 3.536 | eve: 9.939 | bob: 3.489Epoch  22:  62% | abe: 3.536 | eve: 9.939 | bob: 3.489Epoch  22:  63% | abe: 3.536 | eve: 9.939 | bob: 3.489Epoch  22:  64% | abe: 3.536 | eve: 9.939 | bob: 3.489Epoch  22:  64% | abe: 3.536 | eve: 9.939 | bob: 3.489Epoch  22:  65% | abe: 3.536 | eve: 9.939 | bob: 3.489Epoch  22:  66% | abe: 3.535 | eve: 9.939 | bob: 3.489Epoch  22:  67% | abe: 3.535 | eve: 9.939 | bob: 3.489Epoch  22:  67% | abe: 3.535 | eve: 9.940 | bob: 3.489Epoch  22:  68% | abe: 3.535 | eve: 9.940 | bob: 3.488Epoch  22:  69% | abe: 3.535 | eve: 9.940 | bob: 3.488Epoch  22:  70% | abe: 3.535 | eve: 9.941 | bob: 3.488Epoch  22:  71% | abe: 3.535 | eve: 9.940 | bob: 3.488Epoch  22:  71% | abe: 3.535 | eve: 9.940 | bob: 3.488Epoch  22:  72% | abe: 3.535 | eve: 9.941 | bob: 3.488Epoch  22:  73% | abe: 3.534 | eve: 9.942 | bob: 3.488Epoch  22:  74% | abe: 3.534 | eve: 9.941 | bob: 3.487Epoch  22:  75% | abe: 3.534 | eve: 9.941 | bob: 3.487Epoch  22:  75% | abe: 3.534 | eve: 9.941 | bob: 3.487Epoch  22:  76% | abe: 3.534 | eve: 9.941 | bob: 3.487Epoch  22:  77% | abe: 3.534 | eve: 9.942 | bob: 3.487Epoch  22:  78% | abe: 3.534 | eve: 9.941 | bob: 3.487Epoch  22:  78% | abe: 3.534 | eve: 9.941 | bob: 3.487Epoch  22:  79% | abe: 3.534 | eve: 9.941 | bob: 3.487Epoch  22:  80% | abe: 3.533 | eve: 9.942 | bob: 3.487Epoch  22:  81% | abe: 3.533 | eve: 9.942 | bob: 3.487Epoch  22:  82% | abe: 3.533 | eve: 9.942 | bob: 3.487Epoch  22:  82% | abe: 3.533 | eve: 9.942 | bob: 3.486Epoch  22:  83% | abe: 3.533 | eve: 9.942 | bob: 3.486Epoch  22:  84% | abe: 3.533 | eve: 9.942 | bob: 3.486Epoch  22:  85% | abe: 3.533 | eve: 9.942 | bob: 3.486Epoch  22:  85% | abe: 3.533 | eve: 9.941 | bob: 3.486Epoch  22:  86% | abe: 3.533 | eve: 9.942 | bob: 3.486Epoch  22:  87% | abe: 3.532 | eve: 9.942 | bob: 3.486Epoch  22:  88% | abe: 3.532 | eve: 9.942 | bob: 3.486Epoch  22:  89% | abe: 3.532 | eve: 9.942 | bob: 3.485Epoch  22:  89% | abe: 3.532 | eve: 9.942 | bob: 3.485Epoch  22:  90% | abe: 3.532 | eve: 9.941 | bob: 3.485Epoch  22:  91% | abe: 3.532 | eve: 9.941 | bob: 3.485Epoch  22:  92% | abe: 3.532 | eve: 9.942 | bob: 3.485Epoch  22:  92% | abe: 3.532 | eve: 9.942 | bob: 3.485Epoch  22:  93% | abe: 3.531 | eve: 9.942 | bob: 3.485Epoch  22:  94% | abe: 3.531 | eve: 9.942 | bob: 3.485Epoch  22:  95% | abe: 3.531 | eve: 9.942 | bob: 3.485Epoch  22:  96% | abe: 3.531 | eve: 9.943 | bob: 3.485Epoch  22:  96% | abe: 3.531 | eve: 9.943 | bob: 3.485Epoch  22:  97% | abe: 3.531 | eve: 9.943 | bob: 3.484Epoch  22:  98% | abe: 3.531 | eve: 9.943 | bob: 3.484Epoch  22:  99% | abe: 3.531 | eve: 9.943 | bob: 3.484
New best Bob loss 3.4841535268005828 at epoch 22
Epoch  23:   0% | abe: 3.533 | eve: 9.906 | bob: 3.480Epoch  23:   0% | abe: 3.510 | eve: 9.930 | bob: 3.461Epoch  23:   1% | abe: 3.510 | eve: 9.944 | bob: 3.463Epoch  23:   2% | abe: 3.510 | eve: 9.952 | bob: 3.464Epoch  23:   3% | abe: 3.511 | eve: 9.955 | bob: 3.466Epoch  23:   3% | abe: 3.511 | eve: 9.961 | bob: 3.466Epoch  23:   4% | abe: 3.511 | eve: 9.962 | bob: 3.464Epoch  23:   5% | abe: 3.510 | eve: 9.952 | bob: 3.463Epoch  23:   6% | abe: 3.510 | eve: 9.949 | bob: 3.463Epoch  23:   7% | abe: 3.509 | eve: 9.949 | bob: 3.463Epoch  23:   7% | abe: 3.508 | eve: 9.954 | bob: 3.462Epoch  23:   8% | abe: 3.509 | eve: 9.950 | bob: 3.462Epoch  23:   9% | abe: 3.509 | eve: 9.953 | bob: 3.462Epoch  23:  10% | abe: 3.509 | eve: 9.953 | bob: 3.462Epoch  23:  10% | abe: 3.510 | eve: 9.952 | bob: 3.464Epoch  23:  11% | abe: 3.511 | eve: 9.950 | bob: 3.464Epoch  23:  12% | abe: 3.510 | eve: 9.947 | bob: 3.465Epoch  23:  13% | abe: 3.511 | eve: 9.945 | bob: 3.465Epoch  23:  14% | abe: 3.511 | eve: 9.945 | bob: 3.466Epoch  23:  14% | abe: 3.511 | eve: 9.944 | bob: 3.466Epoch  23:  15% | abe: 3.511 | eve: 9.945 | bob: 3.466Epoch  23:  16% | abe: 3.511 | eve: 9.946 | bob: 3.466Epoch  23:  17% | abe: 3.511 | eve: 9.946 | bob: 3.466Epoch  23:  17% | abe: 3.511 | eve: 9.943 | bob: 3.467Epoch  23:  18% | abe: 3.511 | eve: 9.942 | bob: 3.467Epoch  23:  19% | abe: 3.512 | eve: 9.942 | bob: 3.467Epoch  23:  20% | abe: 3.511 | eve: 9.943 | bob: 3.467Epoch  23:  21% | abe: 3.511 | eve: 9.944 | bob: 3.467Epoch  23:  21% | abe: 3.511 | eve: 9.943 | bob: 3.467Epoch  23:  22% | abe: 3.511 | eve: 9.943 | bob: 3.468Epoch  23:  23% | abe: 3.511 | eve: 9.942 | bob: 3.467Epoch  23:  24% | abe: 3.510 | eve: 9.941 | bob: 3.466Epoch  23:  25% | abe: 3.509 | eve: 9.942 | bob: 3.465Epoch  23:  25% | abe: 3.510 | eve: 9.943 | bob: 3.466Epoch  23:  26% | abe: 3.510 | eve: 9.944 | bob: 3.466Epoch  23:  27% | abe: 3.510 | eve: 9.945 | bob: 3.466Epoch  23:  28% | abe: 3.509 | eve: 9.946 | bob: 3.465Epoch  23:  28% | abe: 3.509 | eve: 9.946 | bob: 3.465Epoch  23:  29% | abe: 3.509 | eve: 9.947 | bob: 3.465Epoch  23:  30% | abe: 3.509 | eve: 9.946 | bob: 3.465Epoch  23:  31% | abe: 3.509 | eve: 9.946 | bob: 3.465Epoch  23:  32% | abe: 3.509 | eve: 9.947 | bob: 3.465Epoch  23:  32% | abe: 3.508 | eve: 9.948 | bob: 3.465Epoch  23:  33% | abe: 3.508 | eve: 9.948 | bob: 3.465Epoch  23:  34% | abe: 3.508 | eve: 9.948 | bob: 3.465Epoch  23:  35% | abe: 3.508 | eve: 9.947 | bob: 3.465Epoch  23:  35% | abe: 3.508 | eve: 9.949 | bob: 3.465Epoch  23:  36% | abe: 3.508 | eve: 9.949 | bob: 3.464Epoch  23:  37% | abe: 3.508 | eve: 9.950 | bob: 3.464Epoch  23:  38% | abe: 3.507 | eve: 9.950 | bob: 3.464Epoch  23:  39% | abe: 3.507 | eve: 9.949 | bob: 3.463Epoch  23:  39% | abe: 3.507 | eve: 9.949 | bob: 3.464Epoch  23:  40% | abe: 3.507 | eve: 9.948 | bob: 3.464Epoch  23:  41% | abe: 3.507 | eve: 9.948 | bob: 3.463Epoch  23:  42% | abe: 3.507 | eve: 9.948 | bob: 3.463Epoch  23:  42% | abe: 3.507 | eve: 9.948 | bob: 3.463Epoch  23:  43% | abe: 3.507 | eve: 9.949 | bob: 3.463Epoch  23:  44% | abe: 3.507 | eve: 9.950 | bob: 3.463Epoch  23:  45% | abe: 3.507 | eve: 9.950 | bob: 3.463Epoch  23:  46% | abe: 3.507 | eve: 9.950 | bob: 3.463Epoch  23:  46% | abe: 3.507 | eve: 9.950 | bob: 3.463Epoch  23:  47% | abe: 3.506 | eve: 9.950 | bob: 3.463Epoch  23:  48% | abe: 3.506 | eve: 9.950 | bob: 3.463Epoch  23:  49% | abe: 3.507 | eve: 9.950 | bob: 3.463Epoch  23:  50% | abe: 3.507 | eve: 9.950 | bob: 3.463Epoch  23:  50% | abe: 3.506 | eve: 9.950 | bob: 3.463Epoch  23:  51% | abe: 3.506 | eve: 9.949 | bob: 3.463Epoch  23:  52% | abe: 3.506 | eve: 9.949 | bob: 3.462Epoch  23:  53% | abe: 3.506 | eve: 9.949 | bob: 3.462Epoch  23:  53% | abe: 3.506 | eve: 9.949 | bob: 3.462Epoch  23:  54% | abe: 3.506 | eve: 9.949 | bob: 3.462Epoch  23:  55% | abe: 3.506 | eve: 9.949 | bob: 3.462Epoch  23:  56% | abe: 3.506 | eve: 9.949 | bob: 3.462Epoch  23:  57% | abe: 3.506 | eve: 9.950 | bob: 3.462Epoch  23:  57% | abe: 3.506 | eve: 9.949 | bob: 3.462Epoch  23:  58% | abe: 3.505 | eve: 9.948 | bob: 3.462Epoch  23:  59% | abe: 3.505 | eve: 9.949 | bob: 3.462Epoch  23:  60% | abe: 3.505 | eve: 9.949 | bob: 3.462Epoch  23:  60% | abe: 3.505 | eve: 9.949 | bob: 3.461Epoch  23:  61% | abe: 3.505 | eve: 9.949 | bob: 3.461Epoch  23:  62% | abe: 3.505 | eve: 9.948 | bob: 3.461Epoch  23:  63% | abe: 3.505 | eve: 9.948 | bob: 3.461Epoch  23:  64% | abe: 3.505 | eve: 9.947 | bob: 3.461Epoch  23:  64% | abe: 3.504 | eve: 9.948 | bob: 3.461Epoch  23:  65% | abe: 3.504 | eve: 9.948 | bob: 3.461Epoch  23:  66% | abe: 3.504 | eve: 9.948 | bob: 3.461Epoch  23:  67% | abe: 3.504 | eve: 9.948 | bob: 3.461Epoch  23:  67% | abe: 3.504 | eve: 9.948 | bob: 3.461Epoch  23:  68% | abe: 3.504 | eve: 9.948 | bob: 3.461Epoch  23:  69% | abe: 3.504 | eve: 9.948 | bob: 3.461Epoch  23:  70% | abe: 3.504 | eve: 9.948 | bob: 3.461Epoch  23:  71% | abe: 3.503 | eve: 9.948 | bob: 3.461Epoch  23:  71% | abe: 3.503 | eve: 9.948 | bob: 3.460Epoch  23:  72% | abe: 3.503 | eve: 9.949 | bob: 3.460Epoch  23:  73% | abe: 3.503 | eve: 9.949 | bob: 3.460Epoch  23:  74% | abe: 3.503 | eve: 9.949 | bob: 3.460Epoch  23:  75% | abe: 3.503 | eve: 9.949 | bob: 3.460Epoch  23:  75% | abe: 3.503 | eve: 9.949 | bob: 3.460Epoch  23:  76% | abe: 3.503 | eve: 9.949 | bob: 3.460Epoch  23:  77% | abe: 3.502 | eve: 9.950 | bob: 3.459Epoch  23:  78% | abe: 3.502 | eve: 9.950 | bob: 3.459Epoch  23:  78% | abe: 3.502 | eve: 9.950 | bob: 3.459Epoch  23:  79% | abe: 3.502 | eve: 9.949 | bob: 3.459Epoch  23:  80% | abe: 3.502 | eve: 9.949 | bob: 3.459Epoch  23:  81% | abe: 3.502 | eve: 9.949 | bob: 3.459Epoch  23:  82% | abe: 3.502 | eve: 9.949 | bob: 3.458Epoch  23:  82% | abe: 3.501 | eve: 9.949 | bob: 3.458Epoch  23:  83% | abe: 3.502 | eve: 9.950 | bob: 3.459Epoch  23:  84% | abe: 3.501 | eve: 9.950 | bob: 3.458Epoch  23:  85% | abe: 3.501 | eve: 9.949 | bob: 3.458Epoch  23:  85% | abe: 3.501 | eve: 9.949 | bob: 3.458Epoch  23:  86% | abe: 3.501 | eve: 9.949 | bob: 3.458Epoch  23:  87% | abe: 3.501 | eve: 9.949 | bob: 3.458Epoch  23:  88% | abe: 3.501 | eve: 9.949 | bob: 3.458Epoch  23:  89% | abe: 3.500 | eve: 9.949 | bob: 3.457Epoch  23:  89% | abe: 3.500 | eve: 9.949 | bob: 3.457Epoch  23:  90% | abe: 3.500 | eve: 9.949 | bob: 3.457Epoch  23:  91% | abe: 3.500 | eve: 9.949 | bob: 3.457Epoch  23:  92% | abe: 3.500 | eve: 9.949 | bob: 3.457Epoch  23:  92% | abe: 3.500 | eve: 9.949 | bob: 3.456Epoch  23:  93% | abe: 3.500 | eve: 9.949 | bob: 3.456Epoch  23:  94% | abe: 3.500 | eve: 9.949 | bob: 3.456Epoch  23:  95% | abe: 3.499 | eve: 9.949 | bob: 3.456Epoch  23:  96% | abe: 3.499 | eve: 9.949 | bob: 3.456Epoch  23:  96% | abe: 3.499 | eve: 9.949 | bob: 3.456Epoch  23:  97% | abe: 3.499 | eve: 9.949 | bob: 3.456Epoch  23:  98% | abe: 3.499 | eve: 9.949 | bob: 3.456Epoch  23:  99% | abe: 3.499 | eve: 9.950 | bob: 3.456
New best Bob loss 3.455687735009519 at epoch 23
Epoch  24:   0% | abe: 3.492 | eve: 9.880 | bob: 3.454Epoch  24:   0% | abe: 3.490 | eve: 9.925 | bob: 3.450Epoch  24:   1% | abe: 3.483 | eve: 9.934 | bob: 3.439Epoch  24:   2% | abe: 3.486 | eve: 9.927 | bob: 3.443Epoch  24:   3% | abe: 3.484 | eve: 9.933 | bob: 3.439Epoch  24:   3% | abe: 3.486 | eve: 9.923 | bob: 3.441Epoch  24:   4% | abe: 3.488 | eve: 9.923 | bob: 3.442Epoch  24:   5% | abe: 3.487 | eve: 9.924 | bob: 3.443Epoch  24:   6% | abe: 3.487 | eve: 9.923 | bob: 3.443Epoch  24:   7% | abe: 3.484 | eve: 9.927 | bob: 3.441Epoch  24:   7% | abe: 3.485 | eve: 9.927 | bob: 3.444Epoch  24:   8% | abe: 3.485 | eve: 9.926 | bob: 3.444Epoch  24:   9% | abe: 3.484 | eve: 9.927 | bob: 3.444Epoch  24:  10% | abe: 3.484 | eve: 9.922 | bob: 3.443Epoch  24:  10% | abe: 3.484 | eve: 9.922 | bob: 3.443Epoch  24:  11% | abe: 3.483 | eve: 9.924 | bob: 3.444Epoch  24:  12% | abe: 3.484 | eve: 9.927 | bob: 3.444Epoch  24:  13% | abe: 3.483 | eve: 9.927 | bob: 3.443Epoch  24:  14% | abe: 3.482 | eve: 9.930 | bob: 3.442Epoch  24:  14% | abe: 3.483 | eve: 9.931 | bob: 3.442Epoch  24:  15% | abe: 3.483 | eve: 9.930 | bob: 3.443Epoch  24:  16% | abe: 3.484 | eve: 9.932 | bob: 3.444Epoch  24:  17% | abe: 3.482 | eve: 9.933 | bob: 3.443Epoch  24:  17% | abe: 3.483 | eve: 9.933 | bob: 3.443Epoch  24:  18% | abe: 3.482 | eve: 9.935 | bob: 3.442Epoch  24:  19% | abe: 3.482 | eve: 9.937 | bob: 3.441Epoch  24:  20% | abe: 3.482 | eve: 9.939 | bob: 3.441Epoch  24:  21% | abe: 3.482 | eve: 9.940 | bob: 3.442Epoch  24:  21% | abe: 3.482 | eve: 9.939 | bob: 3.442Epoch  24:  22% | abe: 3.482 | eve: 9.940 | bob: 3.442Epoch  24:  23% | abe: 3.481 | eve: 9.939 | bob: 3.441Epoch  24:  24% | abe: 3.481 | eve: 9.942 | bob: 3.441Epoch  24:  25% | abe: 3.481 | eve: 9.944 | bob: 3.441Epoch  24:  25% | abe: 3.480 | eve: 9.947 | bob: 3.441Epoch  24:  26% | abe: 3.479 | eve: 9.947 | bob: 3.440Epoch  24:  27% | abe: 3.479 | eve: 9.948 | bob: 3.440Epoch  24:  28% | abe: 3.479 | eve: 9.947 | bob: 3.439Epoch  24:  28% | abe: 3.479 | eve: 9.945 | bob: 3.439Epoch  24:  29% | abe: 3.478 | eve: 9.946 | bob: 3.439Epoch  24:  30% | abe: 3.478 | eve: 9.947 | bob: 3.438Epoch  24:  31% | abe: 3.478 | eve: 9.945 | bob: 3.438Epoch  24:  32% | abe: 3.478 | eve: 9.945 | bob: 3.439Epoch  24:  32% | abe: 3.478 | eve: 9.945 | bob: 3.438Epoch  24:  33% | abe: 3.478 | eve: 9.944 | bob: 3.439Epoch  24:  34% | abe: 3.478 | eve: 9.944 | bob: 3.438Epoch  24:  35% | abe: 3.478 | eve: 9.945 | bob: 3.438Epoch  24:  35% | abe: 3.478 | eve: 9.945 | bob: 3.438Epoch  24:  36% | abe: 3.478 | eve: 9.944 | bob: 3.438Epoch  24:  37% | abe: 3.478 | eve: 9.944 | bob: 3.439Epoch  24:  38% | abe: 3.478 | eve: 9.945 | bob: 3.438Epoch  24:  39% | abe: 3.477 | eve: 9.945 | bob: 3.438Epoch  24:  39% | abe: 3.478 | eve: 9.945 | bob: 3.439Epoch  24:  40% | abe: 3.477 | eve: 9.946 | bob: 3.438Epoch  24:  41% | abe: 3.477 | eve: 9.945 | bob: 3.438Epoch  24:  42% | abe: 3.477 | eve: 9.946 | bob: 3.438Epoch  24:  42% | abe: 3.477 | eve: 9.947 | bob: 3.438Epoch  24:  43% | abe: 3.477 | eve: 9.946 | bob: 3.439Epoch  24:  44% | abe: 3.477 | eve: 9.945 | bob: 3.438Epoch  24:  45% | abe: 3.477 | eve: 9.945 | bob: 3.438Epoch  24:  46% | abe: 3.477 | eve: 9.946 | bob: 3.438Epoch  24:  46% | abe: 3.477 | eve: 9.946 | bob: 3.438Epoch  24:  47% | abe: 3.476 | eve: 9.946 | bob: 3.437Epoch  24:  48% | abe: 3.476 | eve: 9.945 | bob: 3.437Epoch  24:  49% | abe: 3.476 | eve: 9.945 | bob: 3.437Epoch  24:  50% | abe: 3.477 | eve: 9.944 | bob: 3.437Epoch  24:  50% | abe: 3.477 | eve: 9.945 | bob: 3.438Epoch  24:  51% | abe: 3.477 | eve: 9.945 | bob: 3.438Epoch  24:  52% | abe: 3.477 | eve: 9.947 | bob: 3.438Epoch  24:  53% | abe: 3.477 | eve: 9.946 | bob: 3.438Epoch  24:  53% | abe: 3.477 | eve: 9.947 | bob: 3.437Epoch  24:  54% | abe: 3.477 | eve: 9.947 | bob: 3.437Epoch  24:  55% | abe: 3.477 | eve: 9.946 | bob: 3.437Epoch  24:  56% | abe: 3.477 | eve: 9.946 | bob: 3.437Epoch  24:  57% | abe: 3.476 | eve: 9.947 | bob: 3.437Epoch  24:  57% | abe: 3.476 | eve: 9.947 | bob: 3.437Epoch  24:  58% | abe: 3.476 | eve: 9.947 | bob: 3.437Epoch  24:  59% | abe: 3.476 | eve: 9.947 | bob: 3.437Epoch  24:  60% | abe: 3.476 | eve: 9.947 | bob: 3.437Epoch  24:  60% | abe: 3.476 | eve: 9.946 | bob: 3.437Epoch  24:  61% | abe: 3.476 | eve: 9.945 | bob: 3.437Epoch  24:  62% | abe: 3.476 | eve: 9.945 | bob: 3.436Epoch  24:  63% | abe: 3.476 | eve: 9.945 | bob: 3.436Epoch  24:  64% | abe: 3.475 | eve: 9.945 | bob: 3.436Epoch  24:  64% | abe: 3.475 | eve: 9.944 | bob: 3.436Epoch  24:  65% | abe: 3.475 | eve: 9.945 | bob: 3.435Epoch  24:  66% | abe: 3.475 | eve: 9.946 | bob: 3.435Epoch  24:  67% | abe: 3.474 | eve: 9.945 | bob: 3.435Epoch  24:  67% | abe: 3.474 | eve: 9.945 | bob: 3.435Epoch  24:  68% | abe: 3.474 | eve: 9.945 | bob: 3.435Epoch  24:  69% | abe: 3.474 | eve: 9.945 | bob: 3.435Epoch  24:  70% | abe: 3.474 | eve: 9.946 | bob: 3.435Epoch  24:  71% | abe: 3.474 | eve: 9.945 | bob: 3.435Epoch  24:  71% | abe: 3.474 | eve: 9.946 | bob: 3.434Epoch  24:  72% | abe: 3.473 | eve: 9.946 | bob: 3.434Epoch  24:  73% | abe: 3.473 | eve: 9.946 | bob: 3.434Epoch  24:  74% | abe: 3.473 | eve: 9.946 | bob: 3.434Epoch  24:  75% | abe: 3.473 | eve: 9.946 | bob: 3.434Epoch  24:  75% | abe: 3.473 | eve: 9.946 | bob: 3.434Epoch  24:  76% | abe: 3.473 | eve: 9.946 | bob: 3.434Epoch  24:  77% | abe: 3.472 | eve: 9.947 | bob: 3.433Epoch  24:  78% | abe: 3.472 | eve: 9.947 | bob: 3.433Epoch  24:  78% | abe: 3.472 | eve: 9.947 | bob: 3.433Epoch  24:  79% | abe: 3.472 | eve: 9.947 | bob: 3.433Epoch  24:  80% | abe: 3.472 | eve: 9.947 | bob: 3.433Epoch  24:  81% | abe: 3.471 | eve: 9.947 | bob: 3.432Epoch  24:  82% | abe: 3.471 | eve: 9.947 | bob: 3.432Epoch  24:  82% | abe: 3.471 | eve: 9.947 | bob: 3.432Epoch  24:  83% | abe: 3.471 | eve: 9.947 | bob: 3.432Epoch  24:  84% | abe: 3.471 | eve: 9.947 | bob: 3.432Epoch  24:  85% | abe: 3.471 | eve: 9.947 | bob: 3.432Epoch  24:  85% | abe: 3.471 | eve: 9.947 | bob: 3.432Epoch  24:  86% | abe: 3.471 | eve: 9.946 | bob: 3.432Epoch  24:  87% | abe: 3.471 | eve: 9.946 | bob: 3.432Epoch  24:  88% | abe: 3.471 | eve: 9.946 | bob: 3.432Epoch  24:  89% | abe: 3.471 | eve: 9.947 | bob: 3.432Epoch  24:  89% | abe: 3.471 | eve: 9.947 | bob: 3.432Epoch  24:  90% | abe: 3.471 | eve: 9.947 | bob: 3.432Epoch  24:  91% | abe: 3.471 | eve: 9.948 | bob: 3.432Epoch  24:  92% | abe: 3.471 | eve: 9.948 | bob: 3.432Epoch  24:  92% | abe: 3.471 | eve: 9.948 | bob: 3.432Epoch  24:  93% | abe: 3.470 | eve: 9.947 | bob: 3.432Epoch  24:  94% | abe: 3.470 | eve: 9.947 | bob: 3.431Epoch  24:  95% | abe: 3.470 | eve: 9.947 | bob: 3.431Epoch  24:  96% | abe: 3.470 | eve: 9.947 | bob: 3.431Epoch  24:  96% | abe: 3.470 | eve: 9.947 | bob: 3.431Epoch  24:  97% | abe: 3.470 | eve: 9.947 | bob: 3.431Epoch  24:  98% | abe: 3.470 | eve: 9.947 | bob: 3.431Epoch  24:  99% | abe: 3.470 | eve: 9.946 | bob: 3.431
New best Bob loss 3.431079248121364 at epoch 24
Epoch  25:   0% | abe: 3.474 | eve: 9.949 | bob: 3.441Epoch  25:   0% | abe: 3.472 | eve: 9.960 | bob: 3.440Epoch  25:   1% | abe: 3.468 | eve: 9.951 | bob: 3.437Epoch  25:   2% | abe: 3.467 | eve: 9.950 | bob: 3.437Epoch  25:   3% | abe: 3.466 | eve: 9.946 | bob: 3.434Epoch  25:   3% | abe: 3.465 | eve: 9.943 | bob: 3.434Epoch  25:   4% | abe: 3.462 | eve: 9.946 | bob: 3.431Epoch  25:   5% | abe: 3.462 | eve: 9.946 | bob: 3.431Epoch  25:   6% | abe: 3.461 | eve: 9.952 | bob: 3.430Epoch  25:   7% | abe: 3.461 | eve: 9.947 | bob: 3.430Epoch  25:   7% | abe: 3.461 | eve: 9.944 | bob: 3.429Epoch  25:   8% | abe: 3.460 | eve: 9.946 | bob: 3.428Epoch  25:   9% | abe: 3.459 | eve: 9.944 | bob: 3.427Epoch  25:  10% | abe: 3.458 | eve: 9.946 | bob: 3.427Epoch  25:  10% | abe: 3.459 | eve: 9.947 | bob: 3.428Epoch  25:  11% | abe: 3.459 | eve: 9.946 | bob: 3.428Epoch  25:  12% | abe: 3.459 | eve: 9.945 | bob: 3.428Epoch  25:  13% | abe: 3.458 | eve: 9.948 | bob: 3.426Epoch  25:  14% | abe: 3.457 | eve: 9.947 | bob: 3.425Epoch  25:  14% | abe: 3.457 | eve: 9.950 | bob: 3.424Epoch  25:  15% | abe: 3.457 | eve: 9.947 | bob: 3.424Epoch  25:  16% | abe: 3.457 | eve: 9.948 | bob: 3.425Epoch  25:  17% | abe: 3.458 | eve: 9.950 | bob: 3.425Epoch  25:  17% | abe: 3.458 | eve: 9.950 | bob: 3.425Epoch  25:  18% | abe: 3.458 | eve: 9.949 | bob: 3.425Epoch  25:  19% | abe: 3.459 | eve: 9.948 | bob: 3.425Epoch  25:  20% | abe: 3.459 | eve: 9.951 | bob: 3.427Epoch  25:  21% | abe: 3.460 | eve: 9.949 | bob: 3.427Epoch  25:  21% | abe: 3.459 | eve: 9.950 | bob: 3.427Epoch  25:  22% | abe: 3.459 | eve: 9.949 | bob: 3.427Epoch  25:  23% | abe: 3.459 | eve: 9.949 | bob: 3.427Epoch  25:  24% | abe: 3.459 | eve: 9.950 | bob: 3.426Epoch  25:  25% | abe: 3.459 | eve: 9.949 | bob: 3.426Epoch  25:  25% | abe: 3.458 | eve: 9.949 | bob: 3.426Epoch  25:  26% | abe: 3.458 | eve: 9.950 | bob: 3.425Epoch  25:  27% | abe: 3.458 | eve: 9.951 | bob: 3.425Epoch  25:  28% | abe: 3.458 | eve: 9.950 | bob: 3.425Epoch  25:  28% | abe: 3.457 | eve: 9.950 | bob: 3.424Epoch  25:  29% | abe: 3.457 | eve: 9.951 | bob: 3.424Epoch  25:  30% | abe: 3.457 | eve: 9.951 | bob: 3.424Epoch  25:  31% | abe: 3.457 | eve: 9.952 | bob: 3.424Epoch  25:  32% | abe: 3.456 | eve: 9.952 | bob: 3.424Epoch  25:  32% | abe: 3.456 | eve: 9.953 | bob: 3.424Epoch  25:  33% | abe: 3.456 | eve: 9.952 | bob: 3.424Epoch  25:  34% | abe: 3.456 | eve: 9.951 | bob: 3.423Epoch  25:  35% | abe: 3.456 | eve: 9.951 | bob: 3.423Epoch  25:  35% | abe: 3.456 | eve: 9.950 | bob: 3.423Epoch  25:  36% | abe: 3.456 | eve: 9.950 | bob: 3.423Epoch  25:  37% | abe: 3.456 | eve: 9.949 | bob: 3.423Epoch  25:  38% | abe: 3.455 | eve: 9.949 | bob: 3.423Epoch  25:  39% | abe: 3.455 | eve: 9.949 | bob: 3.422Epoch  25:  39% | abe: 3.455 | eve: 9.949 | bob: 3.423Epoch  25:  40% | abe: 3.455 | eve: 9.950 | bob: 3.422Epoch  25:  41% | abe: 3.454 | eve: 9.950 | bob: 3.422Epoch  25:  42% | abe: 3.455 | eve: 9.951 | bob: 3.422Epoch  25:  42% | abe: 3.455 | eve: 9.950 | bob: 3.422Epoch  25:  43% | abe: 3.454 | eve: 9.951 | bob: 3.422Epoch  25:  44% | abe: 3.455 | eve: 9.950 | bob: 3.422Epoch  25:  45% | abe: 3.454 | eve: 9.950 | bob: 3.422Epoch  25:  46% | abe: 3.454 | eve: 9.950 | bob: 3.421Epoch  25:  46% | abe: 3.453 | eve: 9.951 | bob: 3.421Epoch  25:  47% | abe: 3.453 | eve: 9.950 | bob: 3.421Epoch  25:  48% | abe: 3.453 | eve: 9.951 | bob: 3.421Epoch  25:  49% | abe: 3.453 | eve: 9.950 | bob: 3.421Epoch  25:  50% | abe: 3.453 | eve: 9.951 | bob: 3.421Epoch  25:  50% | abe: 3.453 | eve: 9.951 | bob: 3.420Epoch  25:  51% | abe: 3.453 | eve: 9.950 | bob: 3.420Epoch  25:  52% | abe: 3.453 | eve: 9.950 | bob: 3.420Epoch  25:  53% | abe: 3.452 | eve: 9.950 | bob: 3.420Epoch  25:  53% | abe: 3.452 | eve: 9.950 | bob: 3.420Epoch  25:  54% | abe: 3.452 | eve: 9.949 | bob: 3.420Epoch  25:  55% | abe: 3.452 | eve: 9.950 | bob: 3.419Epoch  25:  56% | abe: 3.452 | eve: 9.951 | bob: 3.419Epoch  25:  57% | abe: 3.452 | eve: 9.950 | bob: 3.419Epoch  25:  57% | abe: 3.452 | eve: 9.950 | bob: 3.419Epoch  25:  58% | abe: 3.452 | eve: 9.950 | bob: 3.419Epoch  25:  59% | abe: 3.452 | eve: 9.951 | bob: 3.419Epoch  25:  60% | abe: 3.452 | eve: 9.951 | bob: 3.419Epoch  25:  60% | abe: 3.452 | eve: 9.950 | bob: 3.419Epoch  25:  61% | abe: 3.452 | eve: 9.950 | bob: 3.419Epoch  25:  62% | abe: 3.451 | eve: 9.949 | bob: 3.419Epoch  25:  63% | abe: 3.451 | eve: 9.949 | bob: 3.419Epoch  25:  64% | abe: 3.451 | eve: 9.950 | bob: 3.419Epoch  25:  64% | abe: 3.451 | eve: 9.949 | bob: 3.419Epoch  25:  65% | abe: 3.451 | eve: 9.949 | bob: 3.419Epoch  25:  66% | abe: 3.451 | eve: 9.949 | bob: 3.419Epoch  25:  67% | abe: 3.451 | eve: 9.949 | bob: 3.419Epoch  25:  67% | abe: 3.451 | eve: 9.949 | bob: 3.419Epoch  25:  68% | abe: 3.451 | eve: 9.949 | bob: 3.419Epoch  25:  69% | abe: 3.451 | eve: 9.949 | bob: 3.419Epoch  25:  70% | abe: 3.450 | eve: 9.949 | bob: 3.419Epoch  25:  71% | abe: 3.450 | eve: 9.949 | bob: 3.419Epoch  25:  71% | abe: 3.450 | eve: 9.949 | bob: 3.419Epoch  25:  72% | abe: 3.450 | eve: 9.950 | bob: 3.419Epoch  25:  73% | abe: 3.450 | eve: 9.950 | bob: 3.419Epoch  25:  74% | abe: 3.450 | eve: 9.949 | bob: 3.419Epoch  25:  75% | abe: 3.450 | eve: 9.949 | bob: 3.419Epoch  25:  75% | abe: 3.450 | eve: 9.949 | bob: 3.419Epoch  25:  76% | abe: 3.450 | eve: 9.949 | bob: 3.418Epoch  25:  77% | abe: 3.449 | eve: 9.949 | bob: 3.418Epoch  25:  78% | abe: 3.449 | eve: 9.949 | bob: 3.418Epoch  25:  78% | abe: 3.449 | eve: 9.950 | bob: 3.418Epoch  25:  79% | abe: 3.449 | eve: 9.950 | bob: 3.418Epoch  25:  80% | abe: 3.449 | eve: 9.949 | bob: 3.417Epoch  25:  81% | abe: 3.448 | eve: 9.950 | bob: 3.417Epoch  25:  82% | abe: 3.449 | eve: 9.949 | bob: 3.417Epoch  25:  82% | abe: 3.448 | eve: 9.950 | bob: 3.417Epoch  25:  83% | abe: 3.448 | eve: 9.949 | bob: 3.417Epoch  25:  84% | abe: 3.448 | eve: 9.950 | bob: 3.417Epoch  25:  85% | abe: 3.448 | eve: 9.949 | bob: 3.417Epoch  25:  85% | abe: 3.448 | eve: 9.949 | bob: 3.417Epoch  25:  86% | abe: 3.448 | eve: 9.949 | bob: 3.416Epoch  25:  87% | abe: 3.447 | eve: 9.949 | bob: 3.416Epoch  25:  88% | abe: 3.447 | eve: 9.949 | bob: 3.416Epoch  25:  89% | abe: 3.447 | eve: 9.949 | bob: 3.416Epoch  25:  89% | abe: 3.447 | eve: 9.949 | bob: 3.416Epoch  25:  90% | abe: 3.447 | eve: 9.949 | bob: 3.416Epoch  25:  91% | abe: 3.447 | eve: 9.949 | bob: 3.416Epoch  25:  92% | abe: 3.447 | eve: 9.950 | bob: 3.416Epoch  25:  92% | abe: 3.447 | eve: 9.950 | bob: 3.416Epoch  25:  93% | abe: 3.447 | eve: 9.950 | bob: 3.416Epoch  25:  94% | abe: 3.447 | eve: 9.950 | bob: 3.416Epoch  25:  95% | abe: 3.447 | eve: 9.950 | bob: 3.416Epoch  25:  96% | abe: 3.447 | eve: 9.950 | bob: 3.416Epoch  25:  96% | abe: 3.447 | eve: 9.951 | bob: 3.416Epoch  25:  97% | abe: 3.447 | eve: 9.951 | bob: 3.416Epoch  25:  98% | abe: 3.446 | eve: 9.951 | bob: 3.416Epoch  25:  99% | abe: 3.446 | eve: 9.951 | bob: 3.416
New best Bob loss 3.415774399080078 at epoch 25
Epoch  26:   0% | abe: 3.420 | eve: 9.940 | bob: 3.395Epoch  26:   0% | abe: 3.437 | eve: 9.954 | bob: 3.413Epoch  26:   1% | abe: 3.436 | eve: 9.959 | bob: 3.409Epoch  26:   2% | abe: 3.432 | eve: 9.967 | bob: 3.405Epoch  26:   3% | abe: 3.432 | eve: 9.961 | bob: 3.405Epoch  26:   3% | abe: 3.432 | eve: 9.958 | bob: 3.405Epoch  26:   4% | abe: 3.433 | eve: 9.948 | bob: 3.407Epoch  26:   5% | abe: 3.433 | eve: 9.942 | bob: 3.406Epoch  26:   6% | abe: 3.431 | eve: 9.944 | bob: 3.405Epoch  26:   7% | abe: 3.429 | eve: 9.946 | bob: 3.402Epoch  26:   7% | abe: 3.428 | eve: 9.947 | bob: 3.403Epoch  26:   8% | abe: 3.429 | eve: 9.947 | bob: 3.403Epoch  26:   9% | abe: 3.429 | eve: 9.950 | bob: 3.403Epoch  26:  10% | abe: 3.429 | eve: 9.950 | bob: 3.402Epoch  26:  10% | abe: 3.431 | eve: 9.950 | bob: 3.404Epoch  26:  11% | abe: 3.432 | eve: 9.946 | bob: 3.405Epoch  26:  12% | abe: 3.432 | eve: 9.946 | bob: 3.406Epoch  26:  13% | abe: 3.432 | eve: 9.946 | bob: 3.406Epoch  26:  14% | abe: 3.432 | eve: 9.947 | bob: 3.405Epoch  26:  14% | abe: 3.432 | eve: 9.947 | bob: 3.405Epoch  26:  15% | abe: 3.431 | eve: 9.945 | bob: 3.405Epoch  26:  16% | abe: 3.431 | eve: 9.945 | bob: 3.405Epoch  26:  17% | abe: 3.431 | eve: 9.947 | bob: 3.404Epoch  26:  17% | abe: 3.431 | eve: 9.949 | bob: 3.405Epoch  26:  18% | abe: 3.431 | eve: 9.950 | bob: 3.405Epoch  26:  19% | abe: 3.431 | eve: 9.947 | bob: 3.405Epoch  26:  20% | abe: 3.431 | eve: 9.946 | bob: 3.405Epoch  26:  21% | abe: 3.432 | eve: 9.946 | bob: 3.406Epoch  26:  21% | abe: 3.431 | eve: 9.946 | bob: 3.405Epoch  26:  22% | abe: 3.432 | eve: 9.948 | bob: 3.405Epoch  26:  23% | abe: 3.432 | eve: 9.946 | bob: 3.405Epoch  26:  24% | abe: 3.432 | eve: 9.945 | bob: 3.405Epoch  26:  25% | abe: 3.432 | eve: 9.943 | bob: 3.405Epoch  26:  25% | abe: 3.432 | eve: 9.945 | bob: 3.405Epoch  26:  26% | abe: 3.432 | eve: 9.945 | bob: 3.405Epoch  26:  27% | abe: 3.432 | eve: 9.945 | bob: 3.405Epoch  26:  28% | abe: 3.433 | eve: 9.945 | bob: 3.405Epoch  26:  28% | abe: 3.433 | eve: 9.943 | bob: 3.405Epoch  26:  29% | abe: 3.433 | eve: 9.944 | bob: 3.405Epoch  26:  30% | abe: 3.432 | eve: 9.944 | bob: 3.405Epoch  26:  31% | abe: 3.432 | eve: 9.943 | bob: 3.404Epoch  26:  32% | abe: 3.432 | eve: 9.944 | bob: 3.404Epoch  26:  32% | abe: 3.432 | eve: 9.944 | bob: 3.403Epoch  26:  33% | abe: 3.432 | eve: 9.944 | bob: 3.404Epoch  26:  34% | abe: 3.432 | eve: 9.944 | bob: 3.404Epoch  26:  35% | abe: 3.431 | eve: 9.944 | bob: 3.404Epoch  26:  35% | abe: 3.432 | eve: 9.945 | bob: 3.404Epoch  26:  36% | abe: 3.431 | eve: 9.944 | bob: 3.404Epoch  26:  37% | abe: 3.431 | eve: 9.944 | bob: 3.404Epoch  26:  38% | abe: 3.432 | eve: 9.944 | bob: 3.404Epoch  26:  39% | abe: 3.432 | eve: 9.942 | bob: 3.404Epoch  26:  39% | abe: 3.432 | eve: 9.942 | bob: 3.404Epoch  26:  40% | abe: 3.431 | eve: 9.942 | bob: 3.404Epoch  26:  41% | abe: 3.430 | eve: 9.943 | bob: 3.403Epoch  26:  42% | abe: 3.430 | eve: 9.944 | bob: 3.403Epoch  26:  42% | abe: 3.431 | eve: 9.944 | bob: 3.403Epoch  26:  43% | abe: 3.430 | eve: 9.944 | bob: 3.403Epoch  26:  44% | abe: 3.430 | eve: 9.943 | bob: 3.403Epoch  26:  45% | abe: 3.430 | eve: 9.944 | bob: 3.403Epoch  26:  46% | abe: 3.430 | eve: 9.944 | bob: 3.403Epoch  26:  46% | abe: 3.430 | eve: 9.945 | bob: 3.403Epoch  26:  47% | abe: 3.429 | eve: 9.944 | bob: 3.402Epoch  26:  48% | abe: 3.430 | eve: 9.944 | bob: 3.403Epoch  26:  49% | abe: 3.430 | eve: 9.945 | bob: 3.402Epoch  26:  50% | abe: 3.429 | eve: 9.945 | bob: 3.402Epoch  26:  50% | abe: 3.429 | eve: 9.945 | bob: 3.402Epoch  26:  51% | abe: 3.429 | eve: 9.945 | bob: 3.402Epoch  26:  52% | abe: 3.429 | eve: 9.945 | bob: 3.402Epoch  26:  53% | abe: 3.429 | eve: 9.945 | bob: 3.402Epoch  26:  53% | abe: 3.428 | eve: 9.945 | bob: 3.402Epoch  26:  54% | abe: 3.428 | eve: 9.945 | bob: 3.401Epoch  26:  55% | abe: 3.428 | eve: 9.945 | bob: 3.401Epoch  26:  56% | abe: 3.428 | eve: 9.946 | bob: 3.401Epoch  26:  57% | abe: 3.428 | eve: 9.946 | bob: 3.401Epoch  26:  57% | abe: 3.428 | eve: 9.947 | bob: 3.401Epoch  26:  58% | abe: 3.428 | eve: 9.946 | bob: 3.401Epoch  26:  59% | abe: 3.428 | eve: 9.947 | bob: 3.401Epoch  26:  60% | abe: 3.428 | eve: 9.946 | bob: 3.401Epoch  26:  60% | abe: 3.428 | eve: 9.946 | bob: 3.401Epoch  26:  61% | abe: 3.428 | eve: 9.946 | bob: 3.401Epoch  26:  62% | abe: 3.428 | eve: 9.947 | bob: 3.401Epoch  26:  63% | abe: 3.428 | eve: 9.946 | bob: 3.401Epoch  26:  64% | abe: 3.427 | eve: 9.946 | bob: 3.400Epoch  26:  64% | abe: 3.427 | eve: 9.946 | bob: 3.400Epoch  26:  65% | abe: 3.428 | eve: 9.946 | bob: 3.400Epoch  26:  66% | abe: 3.428 | eve: 9.947 | bob: 3.400Epoch  26:  67% | abe: 3.428 | eve: 9.947 | bob: 3.401Epoch  26:  67% | abe: 3.428 | eve: 9.946 | bob: 3.400Epoch  26:  68% | abe: 3.428 | eve: 9.946 | bob: 3.400Epoch  26:  69% | abe: 3.428 | eve: 9.946 | bob: 3.400Epoch  26:  70% | abe: 3.428 | eve: 9.946 | bob: 3.400Epoch  26:  71% | abe: 3.428 | eve: 9.946 | bob: 3.400Epoch  26:  71% | abe: 3.428 | eve: 9.947 | bob: 3.400Epoch  26:  72% | abe: 3.427 | eve: 9.947 | bob: 3.400Epoch  26:  73% | abe: 3.427 | eve: 9.947 | bob: 3.400Epoch  26:  74% | abe: 3.427 | eve: 9.947 | bob: 3.400Epoch  26:  75% | abe: 3.427 | eve: 9.947 | bob: 3.399Epoch  26:  75% | abe: 3.427 | eve: 9.947 | bob: 3.399Epoch  26:  76% | abe: 3.427 | eve: 9.947 | bob: 3.399Epoch  26:  77% | abe: 3.427 | eve: 9.947 | bob: 3.399Epoch  26:  78% | abe: 3.427 | eve: 9.946 | bob: 3.399Epoch  26:  78% | abe: 3.427 | eve: 9.946 | bob: 3.399Epoch  26:  79% | abe: 3.426 | eve: 9.946 | bob: 3.399Epoch  26:  80% | abe: 3.426 | eve: 9.946 | bob: 3.399Epoch  26:  81% | abe: 3.426 | eve: 9.946 | bob: 3.399Epoch  26:  82% | abe: 3.426 | eve: 9.946 | bob: 3.398Epoch  26:  82% | abe: 3.426 | eve: 9.946 | bob: 3.398Epoch  26:  83% | abe: 3.426 | eve: 9.946 | bob: 3.398Epoch  26:  84% | abe: 3.425 | eve: 9.945 | bob: 3.399Epoch  26:  85% | abe: 3.425 | eve: 9.945 | bob: 3.398Epoch  26:  85% | abe: 3.425 | eve: 9.945 | bob: 3.398Epoch  26:  86% | abe: 3.425 | eve: 9.945 | bob: 3.398Epoch  26:  87% | abe: 3.425 | eve: 9.946 | bob: 3.398Epoch  26:  88% | abe: 3.425 | eve: 9.946 | bob: 3.398Epoch  26:  89% | abe: 3.425 | eve: 9.946 | bob: 3.398Epoch  26:  89% | abe: 3.425 | eve: 9.946 | bob: 3.398Epoch  26:  90% | abe: 3.425 | eve: 9.946 | bob: 3.398Epoch  26:  91% | abe: 3.425 | eve: 9.945 | bob: 3.398Epoch  26:  92% | abe: 3.425 | eve: 9.945 | bob: 3.398Epoch  26:  92% | abe: 3.424 | eve: 9.946 | bob: 3.398Epoch  26:  93% | abe: 3.424 | eve: 9.946 | bob: 3.398Epoch  26:  94% | abe: 3.424 | eve: 9.946 | bob: 3.398Epoch  26:  95% | abe: 3.424 | eve: 9.947 | bob: 3.398Epoch  26:  96% | abe: 3.424 | eve: 9.947 | bob: 3.398Epoch  26:  96% | abe: 3.424 | eve: 9.947 | bob: 3.398Epoch  26:  97% | abe: 3.424 | eve: 9.947 | bob: 3.398Epoch  26:  98% | abe: 3.424 | eve: 9.947 | bob: 3.398Epoch  26:  99% | abe: 3.424 | eve: 9.947 | bob: 3.398
New best Bob loss 3.3975549557568456 at epoch 26
Epoch  27:   0% | abe: 3.413 | eve: 9.907 | bob: 3.402Epoch  27:   0% | abe: 3.413 | eve: 9.927 | bob: 3.398Epoch  27:   1% | abe: 3.411 | eve: 9.927 | bob: 3.393Epoch  27:   2% | abe: 3.413 | eve: 9.919 | bob: 3.393Epoch  27:   3% | abe: 3.409 | eve: 9.927 | bob: 3.390Epoch  27:   3% | abe: 3.413 | eve: 9.936 | bob: 3.395Epoch  27:   4% | abe: 3.412 | eve: 9.931 | bob: 3.395Epoch  27:   5% | abe: 3.411 | eve: 9.938 | bob: 3.392Epoch  27:   6% | abe: 3.412 | eve: 9.938 | bob: 3.395Epoch  27:   7% | abe: 3.413 | eve: 9.941 | bob: 3.395Epoch  27:   7% | abe: 3.413 | eve: 9.936 | bob: 3.395Epoch  27:   8% | abe: 3.413 | eve: 9.940 | bob: 3.395Epoch  27:   9% | abe: 3.411 | eve: 9.945 | bob: 3.394Epoch  27:  10% | abe: 3.410 | eve: 9.943 | bob: 3.393Epoch  27:  10% | abe: 3.409 | eve: 9.942 | bob: 3.392Epoch  27:  11% | abe: 3.409 | eve: 9.945 | bob: 3.392Epoch  27:  12% | abe: 3.410 | eve: 9.947 | bob: 3.392Epoch  27:  13% | abe: 3.409 | eve: 9.946 | bob: 3.391Epoch  27:  14% | abe: 3.408 | eve: 9.945 | bob: 3.391Epoch  27:  14% | abe: 3.409 | eve: 9.947 | bob: 3.391Epoch  27:  15% | abe: 3.409 | eve: 9.945 | bob: 3.391Epoch  27:  16% | abe: 3.408 | eve: 9.942 | bob: 3.390Epoch  27:  17% | abe: 3.407 | eve: 9.944 | bob: 3.390Epoch  27:  17% | abe: 3.407 | eve: 9.945 | bob: 3.389Epoch  27:  18% | abe: 3.407 | eve: 9.946 | bob: 3.389Epoch  27:  19% | abe: 3.408 | eve: 9.948 | bob: 3.390Epoch  27:  20% | abe: 3.408 | eve: 9.947 | bob: 3.390Epoch  27:  21% | abe: 3.407 | eve: 9.947 | bob: 3.390Epoch  27:  21% | abe: 3.407 | eve: 9.947 | bob: 3.390Epoch  27:  22% | abe: 3.407 | eve: 9.946 | bob: 3.390Epoch  27:  23% | abe: 3.407 | eve: 9.946 | bob: 3.390Epoch  27:  24% | abe: 3.407 | eve: 9.944 | bob: 3.390Epoch  27:  25% | abe: 3.407 | eve: 9.944 | bob: 3.390Epoch  27:  25% | abe: 3.408 | eve: 9.944 | bob: 3.390Epoch  27:  26% | abe: 3.408 | eve: 9.945 | bob: 3.390Epoch  27:  27% | abe: 3.408 | eve: 9.948 | bob: 3.390Epoch  27:  28% | abe: 3.407 | eve: 9.947 | bob: 3.389Epoch  27:  28% | abe: 3.407 | eve: 9.946 | bob: 3.389Epoch  27:  29% | abe: 3.407 | eve: 9.946 | bob: 3.389Epoch  27:  30% | abe: 3.407 | eve: 9.947 | bob: 3.389Epoch  27:  31% | abe: 3.407 | eve: 9.946 | bob: 3.389Epoch  27:  32% | abe: 3.408 | eve: 9.946 | bob: 3.389Epoch  27:  32% | abe: 3.408 | eve: 9.947 | bob: 3.390Epoch  27:  33% | abe: 3.408 | eve: 9.947 | bob: 3.390Epoch  27:  34% | abe: 3.408 | eve: 9.948 | bob: 3.390Epoch  27:  35% | abe: 3.408 | eve: 9.947 | bob: 3.390Epoch  27:  35% | abe: 3.408 | eve: 9.947 | bob: 3.390Epoch  27:  36% | abe: 3.408 | eve: 9.948 | bob: 3.390Epoch  27:  37% | abe: 3.409 | eve: 9.950 | bob: 3.391Epoch  27:  38% | abe: 3.409 | eve: 9.949 | bob: 3.391Epoch  27:  39% | abe: 3.409 | eve: 9.949 | bob: 3.391Epoch  27:  39% | abe: 3.409 | eve: 9.949 | bob: 3.391Epoch  27:  40% | abe: 3.408 | eve: 9.949 | bob: 3.390Epoch  27:  41% | abe: 3.408 | eve: 9.950 | bob: 3.390Epoch  27:  42% | abe: 3.409 | eve: 9.950 | bob: 3.390Epoch  27:  42% | abe: 3.408 | eve: 9.950 | bob: 3.390Epoch  27:  43% | abe: 3.408 | eve: 9.950 | bob: 3.390Epoch  27:  44% | abe: 3.408 | eve: 9.951 | bob: 3.390Epoch  27:  45% | abe: 3.408 | eve: 9.951 | bob: 3.390Epoch  27:  46% | abe: 3.408 | eve: 9.950 | bob: 3.390Epoch  27:  46% | abe: 3.407 | eve: 9.949 | bob: 3.389Epoch  27:  47% | abe: 3.407 | eve: 9.949 | bob: 3.389Epoch  27:  48% | abe: 3.407 | eve: 9.949 | bob: 3.389Epoch  27:  49% | abe: 3.407 | eve: 9.949 | bob: 3.389Epoch  27:  50% | abe: 3.407 | eve: 9.949 | bob: 3.389Epoch  27:  50% | abe: 3.407 | eve: 9.949 | bob: 3.388Epoch  27:  51% | abe: 3.407 | eve: 9.948 | bob: 3.388Epoch  27:  52% | abe: 3.407 | eve: 9.949 | bob: 3.389Epoch  27:  53% | abe: 3.407 | eve: 9.950 | bob: 3.388Epoch  27:  53% | abe: 3.407 | eve: 9.950 | bob: 3.388Epoch  27:  54% | abe: 3.407 | eve: 9.951 | bob: 3.388Epoch  27:  55% | abe: 3.407 | eve: 9.951 | bob: 3.388Epoch  27:  56% | abe: 3.406 | eve: 9.950 | bob: 3.388Epoch  27:  57% | abe: 3.406 | eve: 9.950 | bob: 3.387Epoch  27:  57% | abe: 3.406 | eve: 9.950 | bob: 3.387Epoch  27:  58% | abe: 3.406 | eve: 9.950 | bob: 3.387Epoch  27:  59% | abe: 3.406 | eve: 9.950 | bob: 3.387Epoch  27:  60% | abe: 3.406 | eve: 9.949 | bob: 3.387Epoch  27:  60% | abe: 3.406 | eve: 9.950 | bob: 3.387Epoch  27:  61% | abe: 3.406 | eve: 9.950 | bob: 3.387Epoch  27:  62% | abe: 3.406 | eve: 9.950 | bob: 3.387Epoch  27:  63% | abe: 3.406 | eve: 9.950 | bob: 3.387Epoch  27:  64% | abe: 3.406 | eve: 9.950 | bob: 3.387Epoch  27:  64% | abe: 3.406 | eve: 9.950 | bob: 3.387Epoch  27:  65% | abe: 3.406 | eve: 9.950 | bob: 3.387Epoch  27:  66% | abe: 3.406 | eve: 9.949 | bob: 3.387Epoch  27:  67% | abe: 3.406 | eve: 9.949 | bob: 3.387Epoch  27:  67% | abe: 3.406 | eve: 9.949 | bob: 3.388Epoch  27:  68% | abe: 3.405 | eve: 9.950 | bob: 3.387Epoch  27:  69% | abe: 3.405 | eve: 9.950 | bob: 3.388Epoch  27:  70% | abe: 3.405 | eve: 9.949 | bob: 3.387Epoch  27:  71% | abe: 3.405 | eve: 9.949 | bob: 3.387Epoch  27:  71% | abe: 3.405 | eve: 9.949 | bob: 3.387Epoch  27:  72% | abe: 3.405 | eve: 9.950 | bob: 3.387Epoch  27:  73% | abe: 3.405 | eve: 9.950 | bob: 3.387Epoch  27:  74% | abe: 3.405 | eve: 9.950 | bob: 3.387Epoch  27:  75% | abe: 3.405 | eve: 9.950 | bob: 3.387Epoch  27:  75% | abe: 3.405 | eve: 9.950 | bob: 3.387Epoch  27:  76% | abe: 3.405 | eve: 9.950 | bob: 3.387Epoch  27:  77% | abe: 3.405 | eve: 9.950 | bob: 3.387Epoch  27:  78% | abe: 3.405 | eve: 9.950 | bob: 3.387Epoch  27:  78% | abe: 3.404 | eve: 9.950 | bob: 3.387Epoch  27:  79% | abe: 3.404 | eve: 9.951 | bob: 3.387Epoch  27:  80% | abe: 3.404 | eve: 9.951 | bob: 3.387Epoch  27:  81% | abe: 3.404 | eve: 9.951 | bob: 3.387Epoch  27:  82% | abe: 3.404 | eve: 9.951 | bob: 3.386Epoch  27:  82% | abe: 3.404 | eve: 9.951 | bob: 3.386Epoch  27:  83% | abe: 3.404 | eve: 9.950 | bob: 3.386Epoch  27:  84% | abe: 3.403 | eve: 9.951 | bob: 3.386Epoch  27:  85% | abe: 3.403 | eve: 9.951 | bob: 3.386Epoch  27:  85% | abe: 3.403 | eve: 9.951 | bob: 3.385Epoch  27:  86% | abe: 3.403 | eve: 9.951 | bob: 3.385Epoch  27:  87% | abe: 3.403 | eve: 9.952 | bob: 3.385Epoch  27:  88% | abe: 3.403 | eve: 9.952 | bob: 3.385Epoch  27:  89% | abe: 3.403 | eve: 9.952 | bob: 3.385Epoch  27:  89% | abe: 3.403 | eve: 9.952 | bob: 3.385Epoch  27:  90% | abe: 3.403 | eve: 9.952 | bob: 3.385Epoch  27:  91% | abe: 3.402 | eve: 9.951 | bob: 3.385Epoch  27:  92% | abe: 3.402 | eve: 9.951 | bob: 3.385Epoch  27:  92% | abe: 3.402 | eve: 9.951 | bob: 3.385Epoch  27:  93% | abe: 3.402 | eve: 9.952 | bob: 3.385Epoch  27:  94% | abe: 3.402 | eve: 9.952 | bob: 3.385Epoch  27:  95% | abe: 3.402 | eve: 9.952 | bob: 3.385Epoch  27:  96% | abe: 3.402 | eve: 9.952 | bob: 3.384Epoch  27:  96% | abe: 3.401 | eve: 9.952 | bob: 3.384Epoch  27:  97% | abe: 3.401 | eve: 9.952 | bob: 3.384Epoch  27:  98% | abe: 3.401 | eve: 9.952 | bob: 3.384Epoch  27:  99% | abe: 3.401 | eve: 9.952 | bob: 3.384
New best Bob loss 3.3843897422630107 at epoch 27
Epoch  28:   0% | abe: 3.398 | eve: 9.910 | bob: 3.398Epoch  28:   0% | abe: 3.398 | eve: 9.929 | bob: 3.388Epoch  28:   1% | abe: 3.395 | eve: 9.924 | bob: 3.384Epoch  28:   2% | abe: 3.397 | eve: 9.935 | bob: 3.386Epoch  28:   3% | abe: 3.393 | eve: 9.941 | bob: 3.378Epoch  28:   3% | abe: 3.392 | eve: 9.938 | bob: 3.377Epoch  28:   4% | abe: 3.394 | eve: 9.941 | bob: 3.379Epoch  28:   5% | abe: 3.396 | eve: 9.939 | bob: 3.384Epoch  28:   6% | abe: 3.396 | eve: 9.934 | bob: 3.384Epoch  28:   7% | abe: 3.395 | eve: 9.931 | bob: 3.382Epoch  28:   7% | abe: 3.394 | eve: 9.927 | bob: 3.381Epoch  28:   8% | abe: 3.394 | eve: 9.930 | bob: 3.380Epoch  28:   9% | abe: 3.393 | eve: 9.932 | bob: 3.379Epoch  28:  10% | abe: 3.392 | eve: 9.932 | bob: 3.379Epoch  28:  10% | abe: 3.392 | eve: 9.932 | bob: 3.380Epoch  28:  11% | abe: 3.392 | eve: 9.931 | bob: 3.381Epoch  28:  12% | abe: 3.392 | eve: 9.930 | bob: 3.381Epoch  28:  13% | abe: 3.393 | eve: 9.930 | bob: 3.381Epoch  28:  14% | abe: 3.393 | eve: 9.931 | bob: 3.382Epoch  28:  14% | abe: 3.393 | eve: 9.933 | bob: 3.382Epoch  28:  15% | abe: 3.393 | eve: 9.933 | bob: 3.382Epoch  28:  16% | abe: 3.393 | eve: 9.934 | bob: 3.382Epoch  28:  17% | abe: 3.392 | eve: 9.935 | bob: 3.382Epoch  28:  17% | abe: 3.391 | eve: 9.937 | bob: 3.381Epoch  28:  18% | abe: 3.391 | eve: 9.939 | bob: 3.381Epoch  28:  19% | abe: 3.390 | eve: 9.938 | bob: 3.380Epoch  28:  20% | abe: 3.390 | eve: 9.937 | bob: 3.380Epoch  28:  21% | abe: 3.389 | eve: 9.936 | bob: 3.379Epoch  28:  21% | abe: 3.389 | eve: 9.939 | bob: 3.379Epoch  28:  22% | abe: 3.389 | eve: 9.937 | bob: 3.379Epoch  28:  23% | abe: 3.389 | eve: 9.938 | bob: 3.379Epoch  28:  24% | abe: 3.389 | eve: 9.939 | bob: 3.378Epoch  28:  25% | abe: 3.388 | eve: 9.938 | bob: 3.378Epoch  28:  25% | abe: 3.388 | eve: 9.938 | bob: 3.378Epoch  28:  26% | abe: 3.388 | eve: 9.937 | bob: 3.378Epoch  28:  27% | abe: 3.388 | eve: 9.938 | bob: 3.378Epoch  28:  28% | abe: 3.388 | eve: 9.940 | bob: 3.379Epoch  28:  28% | abe: 3.389 | eve: 9.942 | bob: 3.379Epoch  28:  29% | abe: 3.388 | eve: 9.941 | bob: 3.379Epoch  28:  30% | abe: 3.388 | eve: 9.943 | bob: 3.379Epoch  28:  31% | abe: 3.388 | eve: 9.944 | bob: 3.379Epoch  28:  32% | abe: 3.388 | eve: 9.945 | bob: 3.379Epoch  28:  32% | abe: 3.388 | eve: 9.946 | bob: 3.379Epoch  28:  33% | abe: 3.388 | eve: 9.947 | bob: 3.379Epoch  28:  34% | abe: 3.388 | eve: 9.947 | bob: 3.379Epoch  28:  35% | abe: 3.388 | eve: 9.946 | bob: 3.379Epoch  28:  35% | abe: 3.388 | eve: 9.946 | bob: 3.379Epoch  28:  36% | abe: 3.388 | eve: 9.947 | bob: 3.379Epoch  28:  37% | abe: 3.388 | eve: 9.947 | bob: 3.379Epoch  28:  38% | abe: 3.388 | eve: 9.947 | bob: 3.379Epoch  28:  39% | abe: 3.387 | eve: 9.948 | bob: 3.379Epoch  28:  39% | abe: 3.387 | eve: 9.948 | bob: 3.378Epoch  28:  40% | abe: 3.387 | eve: 9.948 | bob: 3.379Epoch  28:  41% | abe: 3.387 | eve: 9.949 | bob: 3.379Epoch  28:  42% | abe: 3.387 | eve: 9.949 | bob: 3.379Epoch  28:  42% | abe: 3.388 | eve: 9.949 | bob: 3.379Epoch  28:  43% | abe: 3.387 | eve: 9.948 | bob: 3.379Epoch  28:  44% | abe: 3.387 | eve: 9.949 | bob: 3.379Epoch  28:  45% | abe: 3.387 | eve: 9.949 | bob: 3.379Epoch  28:  46% | abe: 3.387 | eve: 9.948 | bob: 3.379Epoch  28:  46% | abe: 3.386 | eve: 9.949 | bob: 3.378Epoch  28:  47% | abe: 3.387 | eve: 9.950 | bob: 3.378Epoch  28:  48% | abe: 3.386 | eve: 9.950 | bob: 3.378Epoch  28:  49% | abe: 3.386 | eve: 9.949 | bob: 3.378Epoch  28:  50% | abe: 3.386 | eve: 9.950 | bob: 3.378Epoch  28:  50% | abe: 3.386 | eve: 9.951 | bob: 3.378Epoch  28:  51% | abe: 3.386 | eve: 9.951 | bob: 3.378Epoch  28:  52% | abe: 3.386 | eve: 9.952 | bob: 3.377Epoch  28:  53% | abe: 3.386 | eve: 9.952 | bob: 3.377Epoch  28:  53% | abe: 3.386 | eve: 9.952 | bob: 3.378Epoch  28:  54% | abe: 3.385 | eve: 9.952 | bob: 3.377Epoch  28:  55% | abe: 3.385 | eve: 9.952 | bob: 3.377Epoch  28:  56% | abe: 3.385 | eve: 9.953 | bob: 3.377Epoch  28:  57% | abe: 3.385 | eve: 9.953 | bob: 3.377Epoch  28:  57% | abe: 3.385 | eve: 9.953 | bob: 3.377Epoch  28:  58% | abe: 3.385 | eve: 9.952 | bob: 3.377Epoch  28:  59% | abe: 3.385 | eve: 9.952 | bob: 3.377Epoch  28:  60% | abe: 3.385 | eve: 9.951 | bob: 3.377Epoch  28:  60% | abe: 3.385 | eve: 9.951 | bob: 3.377Epoch  28:  61% | abe: 3.385 | eve: 9.952 | bob: 3.377Epoch  28:  62% | abe: 3.385 | eve: 9.952 | bob: 3.377Epoch  28:  63% | abe: 3.385 | eve: 9.951 | bob: 3.378Epoch  28:  64% | abe: 3.385 | eve: 9.951 | bob: 3.378Epoch  28:  64% | abe: 3.385 | eve: 9.952 | bob: 3.378Epoch  28:  65% | abe: 3.385 | eve: 9.951 | bob: 3.377Epoch  28:  66% | abe: 3.385 | eve: 9.951 | bob: 3.377Epoch  28:  67% | abe: 3.385 | eve: 9.951 | bob: 3.377Epoch  28:  67% | abe: 3.385 | eve: 9.951 | bob: 3.377Epoch  28:  68% | abe: 3.385 | eve: 9.950 | bob: 3.377Epoch  28:  69% | abe: 3.385 | eve: 9.951 | bob: 3.377Epoch  28:  70% | abe: 3.385 | eve: 9.950 | bob: 3.377Epoch  28:  71% | abe: 3.385 | eve: 9.949 | bob: 3.377Epoch  28:  71% | abe: 3.385 | eve: 9.949 | bob: 3.377Epoch  28:  72% | abe: 3.384 | eve: 9.949 | bob: 3.377Epoch  28:  73% | abe: 3.384 | eve: 9.949 | bob: 3.377Epoch  28:  74% | abe: 3.384 | eve: 9.949 | bob: 3.377Epoch  28:  75% | abe: 3.384 | eve: 9.948 | bob: 3.377Epoch  28:  75% | abe: 3.384 | eve: 9.948 | bob: 3.377Epoch  28:  76% | abe: 3.384 | eve: 9.948 | bob: 3.377Epoch  28:  77% | abe: 3.384 | eve: 9.947 | bob: 3.376Epoch  28:  78% | abe: 3.384 | eve: 9.948 | bob: 3.376Epoch  28:  78% | abe: 3.384 | eve: 9.948 | bob: 3.376Epoch  28:  79% | abe: 3.384 | eve: 9.948 | bob: 3.376Epoch  28:  80% | abe: 3.384 | eve: 9.949 | bob: 3.376Epoch  28:  81% | abe: 3.384 | eve: 9.948 | bob: 3.376Epoch  28:  82% | abe: 3.384 | eve: 9.948 | bob: 3.376Epoch  28:  82% | abe: 3.384 | eve: 9.948 | bob: 3.376Epoch  28:  83% | abe: 3.384 | eve: 9.948 | bob: 3.376Epoch  28:  84% | abe: 3.384 | eve: 9.949 | bob: 3.376Epoch  28:  85% | abe: 3.384 | eve: 9.949 | bob: 3.376Epoch  28:  85% | abe: 3.384 | eve: 9.949 | bob: 3.376Epoch  28:  86% | abe: 3.384 | eve: 9.949 | bob: 3.376Epoch  28:  87% | abe: 3.384 | eve: 9.949 | bob: 3.376Epoch  28:  88% | abe: 3.384 | eve: 9.949 | bob: 3.376Epoch  28:  89% | abe: 3.384 | eve: 9.948 | bob: 3.376Epoch  28:  89% | abe: 3.383 | eve: 9.948 | bob: 3.376Epoch  28:  90% | abe: 3.383 | eve: 9.948 | bob: 3.376Epoch  28:  91% | abe: 3.383 | eve: 9.949 | bob: 3.376Epoch  28:  92% | abe: 3.383 | eve: 9.949 | bob: 3.376Epoch  28:  92% | abe: 3.383 | eve: 9.949 | bob: 3.376Epoch  28:  93% | abe: 3.383 | eve: 9.950 | bob: 3.376Epoch  28:  94% | abe: 3.383 | eve: 9.950 | bob: 3.376Epoch  28:  95% | abe: 3.383 | eve: 9.950 | bob: 3.376Epoch  28:  96% | abe: 3.383 | eve: 9.950 | bob: 3.376Epoch  28:  96% | abe: 3.383 | eve: 9.951 | bob: 3.376Epoch  28:  97% | abe: 3.383 | eve: 9.951 | bob: 3.376Epoch  28:  98% | abe: 3.383 | eve: 9.951 | bob: 3.376Epoch  28:  99% | abe: 3.383 | eve: 9.952 | bob: 3.376
New best Bob loss 3.3758132632748357 at epoch 28
Epoch  29:   0% | abe: 3.375 | eve: 9.960 | bob: 3.378Epoch  29:   0% | abe: 3.381 | eve: 9.937 | bob: 3.377Epoch  29:   1% | abe: 3.381 | eve: 9.930 | bob: 3.375Epoch  29:   2% | abe: 3.379 | eve: 9.933 | bob: 3.371Epoch  29:   3% | abe: 3.373 | eve: 9.934 | bob: 3.369Epoch  29:   3% | abe: 3.370 | eve: 9.944 | bob: 3.363Epoch  29:   4% | abe: 3.370 | eve: 9.945 | bob: 3.364Epoch  29:   5% | abe: 3.369 | eve: 9.945 | bob: 3.363Epoch  29:   6% | abe: 3.369 | eve: 9.955 | bob: 3.364Epoch  29:   7% | abe: 3.368 | eve: 9.960 | bob: 3.363Epoch  29:   7% | abe: 3.368 | eve: 9.961 | bob: 3.364Epoch  29:   8% | abe: 3.366 | eve: 9.959 | bob: 3.362Epoch  29:   9% | abe: 3.367 | eve: 9.958 | bob: 3.362Epoch  29:  10% | abe: 3.368 | eve: 9.954 | bob: 3.363Epoch  29:  10% | abe: 3.368 | eve: 9.961 | bob: 3.364Epoch  29:  11% | abe: 3.368 | eve: 9.958 | bob: 3.363Epoch  29:  12% | abe: 3.368 | eve: 9.957 | bob: 3.364Epoch  29:  13% | abe: 3.367 | eve: 9.955 | bob: 3.364Epoch  29:  14% | abe: 3.368 | eve: 9.958 | bob: 3.364Epoch  29:  14% | abe: 3.369 | eve: 9.955 | bob: 3.365Epoch  29:  15% | abe: 3.369 | eve: 9.954 | bob: 3.364Epoch  29:  16% | abe: 3.369 | eve: 9.955 | bob: 3.365Epoch  29:  17% | abe: 3.369 | eve: 9.956 | bob: 3.365Epoch  29:  17% | abe: 3.370 | eve: 9.956 | bob: 3.366Epoch  29:  18% | abe: 3.369 | eve: 9.958 | bob: 3.365Epoch  29:  19% | abe: 3.370 | eve: 9.958 | bob: 3.365Epoch  29:  20% | abe: 3.370 | eve: 9.956 | bob: 3.366Epoch  29:  21% | abe: 3.369 | eve: 9.957 | bob: 3.366Epoch  29:  21% | abe: 3.370 | eve: 9.957 | bob: 3.366Epoch  29:  22% | abe: 3.370 | eve: 9.957 | bob: 3.367Epoch  29:  23% | abe: 3.370 | eve: 9.956 | bob: 3.367Epoch  29:  24% | abe: 3.370 | eve: 9.957 | bob: 3.367Epoch  29:  25% | abe: 3.370 | eve: 9.957 | bob: 3.368Epoch  29:  25% | abe: 3.370 | eve: 9.957 | bob: 3.367Epoch  29:  26% | abe: 3.369 | eve: 9.960 | bob: 3.367Epoch  29:  27% | abe: 3.369 | eve: 9.961 | bob: 3.367Epoch  29:  28% | abe: 3.369 | eve: 9.962 | bob: 3.367Epoch  29:  28% | abe: 3.369 | eve: 9.962 | bob: 3.368Epoch  29:  29% | abe: 3.369 | eve: 9.961 | bob: 3.368Epoch  29:  30% | abe: 3.369 | eve: 9.961 | bob: 3.368Epoch  29:  31% | abe: 3.369 | eve: 9.962 | bob: 3.368Epoch  29:  32% | abe: 3.369 | eve: 9.961 | bob: 3.367Epoch  29:  32% | abe: 3.368 | eve: 9.961 | bob: 3.367Epoch  29:  33% | abe: 3.368 | eve: 9.960 | bob: 3.367Epoch  29:  34% | abe: 3.368 | eve: 9.960 | bob: 3.367Epoch  29:  35% | abe: 3.367 | eve: 9.960 | bob: 3.366Epoch  29:  35% | abe: 3.367 | eve: 9.960 | bob: 3.366Epoch  29:  36% | abe: 3.367 | eve: 9.961 | bob: 3.366Epoch  29:  37% | abe: 3.367 | eve: 9.960 | bob: 3.365Epoch  29:  38% | abe: 3.368 | eve: 9.962 | bob: 3.366Epoch  29:  39% | abe: 3.368 | eve: 9.962 | bob: 3.366Epoch  29:  39% | abe: 3.368 | eve: 9.962 | bob: 3.366Epoch  29:  40% | abe: 3.368 | eve: 9.963 | bob: 3.367Epoch  29:  41% | abe: 3.368 | eve: 9.963 | bob: 3.366Epoch  29:  42% | abe: 3.368 | eve: 9.963 | bob: 3.366Epoch  29:  42% | abe: 3.368 | eve: 9.962 | bob: 3.366Epoch  29:  43% | abe: 3.367 | eve: 9.961 | bob: 3.366Epoch  29:  44% | abe: 3.368 | eve: 9.962 | bob: 3.366Epoch  29:  45% | abe: 3.368 | eve: 9.962 | bob: 3.366Epoch  29:  46% | abe: 3.368 | eve: 9.962 | bob: 3.367Epoch  29:  46% | abe: 3.368 | eve: 9.962 | bob: 3.367Epoch  29:  47% | abe: 3.368 | eve: 9.962 | bob: 3.367Epoch  29:  48% | abe: 3.367 | eve: 9.963 | bob: 3.366Epoch  29:  49% | abe: 3.367 | eve: 9.963 | bob: 3.366Epoch  29:  50% | abe: 3.367 | eve: 9.963 | bob: 3.366Epoch  29:  50% | abe: 3.367 | eve: 9.962 | bob: 3.366Epoch  29:  51% | abe: 3.367 | eve: 9.962 | bob: 3.366Epoch  29:  52% | abe: 3.367 | eve: 9.962 | bob: 3.365Epoch  29:  53% | abe: 3.366 | eve: 9.962 | bob: 3.365Epoch  29:  53% | abe: 3.366 | eve: 9.962 | bob: 3.365Epoch  29:  54% | abe: 3.366 | eve: 9.963 | bob: 3.365Epoch  29:  55% | abe: 3.366 | eve: 9.963 | bob: 3.364Epoch  29:  56% | abe: 3.366 | eve: 9.963 | bob: 3.364Epoch  29:  57% | abe: 3.366 | eve: 9.963 | bob: 3.365Epoch  29:  57% | abe: 3.366 | eve: 9.963 | bob: 3.365Epoch  29:  58% | abe: 3.366 | eve: 9.963 | bob: 3.365Epoch  29:  59% | abe: 3.366 | eve: 9.963 | bob: 3.365Epoch  29:  60% | abe: 3.366 | eve: 9.962 | bob: 3.365Epoch  29:  60% | abe: 3.366 | eve: 9.962 | bob: 3.365Epoch  29:  61% | abe: 3.366 | eve: 9.962 | bob: 3.365Epoch  29:  62% | abe: 3.366 | eve: 9.963 | bob: 3.365Epoch  29:  63% | abe: 3.366 | eve: 9.962 | bob: 3.365Epoch  29:  64% | abe: 3.365 | eve: 9.961 | bob: 3.365Epoch  29:  64% | abe: 3.365 | eve: 9.962 | bob: 3.365Epoch  29:  65% | abe: 3.365 | eve: 9.962 | bob: 3.365Epoch  29:  66% | abe: 3.365 | eve: 9.962 | bob: 3.364Epoch  29:  67% | abe: 3.365 | eve: 9.962 | bob: 3.364Epoch  29:  67% | abe: 3.365 | eve: 9.962 | bob: 3.364Epoch  29:  68% | abe: 3.365 | eve: 9.963 | bob: 3.364Epoch  29:  69% | abe: 3.365 | eve: 9.962 | bob: 3.364Epoch  29:  70% | abe: 3.365 | eve: 9.963 | bob: 3.364Epoch  29:  71% | abe: 3.365 | eve: 9.962 | bob: 3.364Epoch  29:  71% | abe: 3.365 | eve: 9.963 | bob: 3.363Epoch  29:  72% | abe: 3.364 | eve: 9.962 | bob: 3.363Epoch  29:  73% | abe: 3.364 | eve: 9.962 | bob: 3.363Epoch  29:  74% | abe: 3.364 | eve: 9.963 | bob: 3.363Epoch  29:  75% | abe: 3.364 | eve: 9.963 | bob: 3.363Epoch  29:  75% | abe: 3.364 | eve: 9.963 | bob: 3.363Epoch  29:  76% | abe: 3.364 | eve: 9.963 | bob: 3.363Epoch  29:  77% | abe: 3.364 | eve: 9.963 | bob: 3.363Epoch  29:  78% | abe: 3.364 | eve: 9.963 | bob: 3.363Epoch  29:  78% | abe: 3.364 | eve: 9.963 | bob: 3.363Epoch  29:  79% | abe: 3.364 | eve: 9.963 | bob: 3.363Epoch  29:  80% | abe: 3.364 | eve: 9.963 | bob: 3.363Epoch  29:  81% | abe: 3.364 | eve: 9.962 | bob: 3.363Epoch  29:  82% | abe: 3.364 | eve: 9.962 | bob: 3.363Epoch  29:  82% | abe: 3.364 | eve: 9.962 | bob: 3.363Epoch  29:  83% | abe: 3.363 | eve: 9.961 | bob: 3.363Epoch  29:  84% | abe: 3.363 | eve: 9.961 | bob: 3.363Epoch  29:  85% | abe: 3.363 | eve: 9.961 | bob: 3.363Epoch  29:  85% | abe: 3.363 | eve: 9.960 | bob: 3.363Epoch  29:  86% | abe: 3.363 | eve: 9.960 | bob: 3.362Epoch  29:  87% | abe: 3.363 | eve: 9.960 | bob: 3.362Epoch  29:  88% | abe: 3.363 | eve: 9.960 | bob: 3.362Epoch  29:  89% | abe: 3.363 | eve: 9.960 | bob: 3.362Epoch  29:  89% | abe: 3.363 | eve: 9.960 | bob: 3.362Epoch  29:  90% | abe: 3.362 | eve: 9.960 | bob: 3.362Epoch  29:  91% | abe: 3.362 | eve: 9.960 | bob: 3.362Epoch  29:  92% | abe: 3.362 | eve: 9.960 | bob: 3.362Epoch  29:  92% | abe: 3.362 | eve: 9.960 | bob: 3.362Epoch  29:  93% | abe: 3.362 | eve: 9.961 | bob: 3.362Epoch  29:  94% | abe: 3.362 | eve: 9.961 | bob: 3.361Epoch  29:  95% | abe: 3.362 | eve: 9.961 | bob: 3.361Epoch  29:  96% | abe: 3.362 | eve: 9.961 | bob: 3.361Epoch  29:  96% | abe: 3.362 | eve: 9.961 | bob: 3.361Epoch  29:  97% | abe: 3.362 | eve: 9.961 | bob: 3.361Epoch  29:  98% | abe: 3.362 | eve: 9.961 | bob: 3.361Epoch  29:  99% | abe: 3.361 | eve: 9.961 | bob: 3.361
New best Bob loss 3.360617586299554 at epoch 29
Epoch  30:   0% | abe: 3.350 | eve: 9.978 | bob: 3.350Epoch  30:   0% | abe: 3.359 | eve: 9.970 | bob: 3.361Epoch  30:   1% | abe: 3.356 | eve: 9.962 | bob: 3.360Epoch  30:   2% | abe: 3.355 | eve: 9.951 | bob: 3.358Epoch  30:   3% | abe: 3.357 | eve: 9.952 | bob: 3.361Epoch  30:   3% | abe: 3.352 | eve: 9.955 | bob: 3.356Epoch  30:   4% | abe: 3.352 | eve: 9.952 | bob: 3.356Epoch  30:   5% | abe: 3.351 | eve: 9.957 | bob: 3.355Epoch  30:   6% | abe: 3.350 | eve: 9.958 | bob: 3.354Epoch  30:   7% | abe: 3.350 | eve: 9.961 | bob: 3.353Epoch  30:   7% | abe: 3.349 | eve: 9.957 | bob: 3.353Epoch  30:   8% | abe: 3.348 | eve: 9.954 | bob: 3.351Epoch  30:   9% | abe: 3.349 | eve: 9.952 | bob: 3.351Epoch  30:  10% | abe: 3.349 | eve: 9.953 | bob: 3.350Epoch  30:  10% | abe: 3.348 | eve: 9.953 | bob: 3.349Epoch  30:  11% | abe: 3.348 | eve: 9.954 | bob: 3.349Epoch  30:  12% | abe: 3.348 | eve: 9.953 | bob: 3.350Epoch  30:  13% | abe: 3.348 | eve: 9.952 | bob: 3.351Epoch  30:  14% | abe: 3.348 | eve: 9.952 | bob: 3.352Epoch  30:  14% | abe: 3.348 | eve: 9.953 | bob: 3.352Epoch  30:  15% | abe: 3.348 | eve: 9.953 | bob: 3.352Epoch  30:  16% | abe: 3.348 | eve: 9.955 | bob: 3.352Epoch  30:  17% | abe: 3.349 | eve: 9.956 | bob: 3.352Epoch  30:  17% | abe: 3.349 | eve: 9.956 | bob: 3.351Epoch  30:  18% | abe: 3.348 | eve: 9.954 | bob: 3.351Epoch  30:  19% | abe: 3.347 | eve: 9.954 | bob: 3.349Epoch  30:  20% | abe: 3.348 | eve: 9.950 | bob: 3.350Epoch  30:  21% | abe: 3.348 | eve: 9.951 | bob: 3.350Epoch  30:  21% | abe: 3.348 | eve: 9.951 | bob: 3.350Epoch  30:  22% | abe: 3.348 | eve: 9.953 | bob: 3.350Epoch  30:  23% | abe: 3.347 | eve: 9.955 | bob: 3.349Epoch  30:  24% | abe: 3.347 | eve: 9.955 | bob: 3.349Epoch  30:  25% | abe: 3.348 | eve: 9.954 | bob: 3.349Epoch  30:  25% | abe: 3.348 | eve: 9.954 | bob: 3.349Epoch  30:  26% | abe: 3.348 | eve: 9.954 | bob: 3.349Epoch  30:  27% | abe: 3.347 | eve: 9.955 | bob: 3.349Epoch  30:  28% | abe: 3.347 | eve: 9.955 | bob: 3.348Epoch  30:  28% | abe: 3.347 | eve: 9.955 | bob: 3.348Epoch  30:  29% | abe: 3.347 | eve: 9.955 | bob: 3.348Epoch  30:  30% | abe: 3.347 | eve: 9.956 | bob: 3.348Epoch  30:  31% | abe: 3.347 | eve: 9.954 | bob: 3.349Epoch  30:  32% | abe: 3.347 | eve: 9.953 | bob: 3.349Epoch  30:  32% | abe: 3.347 | eve: 9.954 | bob: 3.349Epoch  30:  33% | abe: 3.347 | eve: 9.955 | bob: 3.349Epoch  30:  34% | abe: 3.347 | eve: 9.956 | bob: 3.349Epoch  30:  35% | abe: 3.346 | eve: 9.956 | bob: 3.349Epoch  30:  35% | abe: 3.346 | eve: 9.957 | bob: 3.349Epoch  30:  36% | abe: 3.346 | eve: 9.957 | bob: 3.349Epoch  30:  37% | abe: 3.346 | eve: 9.956 | bob: 3.349Epoch  30:  38% | abe: 3.347 | eve: 9.957 | bob: 3.349Epoch  30:  39% | abe: 3.347 | eve: 9.957 | bob: 3.350Epoch  30:  39% | abe: 3.347 | eve: 9.958 | bob: 3.350Epoch  30:  40% | abe: 3.347 | eve: 9.957 | bob: 3.350Epoch  30:  41% | abe: 3.346 | eve: 9.958 | bob: 3.350Epoch  30:  42% | abe: 3.346 | eve: 9.959 | bob: 3.350Epoch  30:  42% | abe: 3.346 | eve: 9.959 | bob: 3.350Epoch  30:  43% | abe: 3.346 | eve: 9.959 | bob: 3.350Epoch  30:  44% | abe: 3.346 | eve: 9.959 | bob: 3.350Epoch  30:  45% | abe: 3.346 | eve: 9.958 | bob: 3.350Epoch  30:  46% | abe: 3.346 | eve: 9.958 | bob: 3.350Epoch  30:  46% | abe: 3.346 | eve: 9.957 | bob: 3.351Epoch  30:  47% | abe: 3.346 | eve: 9.957 | bob: 3.350Epoch  30:  48% | abe: 3.346 | eve: 9.957 | bob: 3.350Epoch  30:  49% | abe: 3.347 | eve: 9.956 | bob: 3.350Epoch  30:  50% | abe: 3.347 | eve: 9.957 | bob: 3.350Epoch  30:  50% | abe: 3.347 | eve: 9.957 | bob: 3.351Epoch  30:  51% | abe: 3.346 | eve: 9.957 | bob: 3.351Epoch  30:  52% | abe: 3.347 | eve: 9.958 | bob: 3.350Epoch  30:  53% | abe: 3.347 | eve: 9.958 | bob: 3.350Epoch  30:  53% | abe: 3.347 | eve: 9.957 | bob: 3.350Epoch  30:  54% | abe: 3.347 | eve: 9.957 | bob: 3.350Epoch  30:  55% | abe: 3.346 | eve: 9.957 | bob: 3.350Epoch  30:  56% | abe: 3.346 | eve: 9.957 | bob: 3.350Epoch  30:  57% | abe: 3.346 | eve: 9.957 | bob: 3.350Epoch  30:  57% | abe: 3.346 | eve: 9.958 | bob: 3.350Epoch  30:  58% | abe: 3.346 | eve: 9.959 | bob: 3.350Epoch  30:  59% | abe: 3.346 | eve: 9.958 | bob: 3.350Epoch  30:  60% | abe: 3.346 | eve: 9.957 | bob: 3.350Epoch  30:  60% | abe: 3.346 | eve: 9.957 | bob: 3.350Epoch  30:  61% | abe: 3.346 | eve: 9.957 | bob: 3.350Epoch  30:  62% | abe: 3.346 | eve: 9.956 | bob: 3.351Epoch  30:  63% | abe: 3.346 | eve: 9.956 | bob: 3.350Epoch  30:  64% | abe: 3.346 | eve: 9.956 | bob: 3.350Epoch  30:  64% | abe: 3.346 | eve: 9.956 | bob: 3.350Epoch  30:  65% | abe: 3.346 | eve: 9.956 | bob: 3.350Epoch  30:  66% | abe: 3.346 | eve: 9.955 | bob: 3.350Epoch  30:  67% | abe: 3.346 | eve: 9.954 | bob: 3.350Epoch  30:  67% | abe: 3.345 | eve: 9.955 | bob: 3.350Epoch  30:  68% | abe: 3.345 | eve: 9.955 | bob: 3.350Epoch  30:  69% | abe: 3.345 | eve: 9.955 | bob: 3.350Epoch  30:  70% | abe: 3.345 | eve: 9.955 | bob: 3.350Epoch  30:  71% | abe: 3.345 | eve: 9.955 | bob: 3.350Epoch  30:  71% | abe: 3.344 | eve: 9.955 | bob: 3.349Epoch  30:  72% | abe: 3.344 | eve: 9.955 | bob: 3.349Epoch  30:  73% | abe: 3.344 | eve: 9.954 | bob: 3.349Epoch  30:  74% | abe: 3.344 | eve: 9.955 | bob: 3.349Epoch  30:  75% | abe: 3.344 | eve: 9.954 | bob: 3.349Epoch  30:  75% | abe: 3.344 | eve: 9.954 | bob: 3.349Epoch  30:  76% | abe: 3.344 | eve: 9.954 | bob: 3.349Epoch  30:  77% | abe: 3.344 | eve: 9.954 | bob: 3.349Epoch  30:  78% | abe: 3.344 | eve: 9.954 | bob: 3.349Epoch  30:  78% | abe: 3.344 | eve: 9.954 | bob: 3.349Epoch  30:  79% | abe: 3.343 | eve: 9.953 | bob: 3.349Epoch  30:  80% | abe: 3.344 | eve: 9.953 | bob: 3.349Epoch  30:  81% | abe: 3.343 | eve: 9.954 | bob: 3.349Epoch  30:  82% | abe: 3.343 | eve: 9.954 | bob: 3.349Epoch  30:  82% | abe: 3.343 | eve: 9.953 | bob: 3.349Epoch  30:  83% | abe: 3.343 | eve: 9.953 | bob: 3.349Epoch  30:  84% | abe: 3.344 | eve: 9.953 | bob: 3.349Epoch  30:  85% | abe: 3.344 | eve: 9.953 | bob: 3.349Epoch  30:  85% | abe: 3.344 | eve: 9.953 | bob: 3.349Epoch  30:  86% | abe: 3.343 | eve: 9.953 | bob: 3.349Epoch  30:  87% | abe: 3.343 | eve: 9.953 | bob: 3.349Epoch  30:  88% | abe: 3.343 | eve: 9.953 | bob: 3.349Epoch  30:  89% | abe: 3.343 | eve: 9.952 | bob: 3.349Epoch  30:  89% | abe: 3.343 | eve: 9.953 | bob: 3.349Epoch  30:  90% | abe: 3.343 | eve: 9.952 | bob: 3.349Epoch  30:  91% | abe: 3.343 | eve: 9.952 | bob: 3.349Epoch  30:  92% | abe: 3.343 | eve: 9.953 | bob: 3.349Epoch  30:  92% | abe: 3.343 | eve: 9.952 | bob: 3.349Epoch  30:  93% | abe: 3.343 | eve: 9.953 | bob: 3.349Epoch  30:  94% | abe: 3.343 | eve: 9.953 | bob: 3.349Epoch  30:  95% | abe: 3.343 | eve: 9.953 | bob: 3.348Epoch  30:  96% | abe: 3.343 | eve: 9.953 | bob: 3.348Epoch  30:  96% | abe: 3.343 | eve: 9.953 | bob: 3.348Epoch  30:  97% | abe: 3.343 | eve: 9.953 | bob: 3.348Epoch  30:  98% | abe: 3.343 | eve: 9.953 | bob: 3.348Epoch  30:  99% | abe: 3.343 | eve: 9.953 | bob: 3.349
New best Bob loss 3.34859341217566 at epoch 30
Epoch  31:   0% | abe: 3.338 | eve: 9.943 | bob: 3.340Epoch  31:   0% | abe: 3.335 | eve: 9.916 | bob: 3.335Epoch  31:   1% | abe: 3.334 | eve: 9.942 | bob: 3.334Epoch  31:   2% | abe: 3.332 | eve: 9.942 | bob: 3.338Epoch  31:   3% | abe: 3.333 | eve: 9.926 | bob: 3.339Epoch  31:   3% | abe: 3.333 | eve: 9.923 | bob: 3.340Epoch  31:   4% | abe: 3.331 | eve: 9.931 | bob: 3.339Epoch  31:   5% | abe: 3.333 | eve: 9.927 | bob: 3.339Epoch  31:   6% | abe: 3.332 | eve: 9.931 | bob: 3.338Epoch  31:   7% | abe: 3.332 | eve: 9.934 | bob: 3.339Epoch  31:   7% | abe: 3.330 | eve: 9.936 | bob: 3.338Epoch  31:   8% | abe: 3.329 | eve: 9.938 | bob: 3.337Epoch  31:   9% | abe: 3.330 | eve: 9.946 | bob: 3.339Epoch  31:  10% | abe: 3.332 | eve: 9.948 | bob: 3.341Epoch  31:  10% | abe: 3.332 | eve: 9.949 | bob: 3.341Epoch  31:  11% | abe: 3.332 | eve: 9.948 | bob: 3.342Epoch  31:  12% | abe: 3.332 | eve: 9.949 | bob: 3.342Epoch  31:  13% | abe: 3.331 | eve: 9.947 | bob: 3.342Epoch  31:  14% | abe: 3.331 | eve: 9.947 | bob: 3.342Epoch  31:  14% | abe: 3.331 | eve: 9.949 | bob: 3.342Epoch  31:  15% | abe: 3.331 | eve: 9.947 | bob: 3.342Epoch  31:  16% | abe: 3.331 | eve: 9.944 | bob: 3.341Epoch  31:  17% | abe: 3.331 | eve: 9.942 | bob: 3.342Epoch  31:  17% | abe: 3.331 | eve: 9.943 | bob: 3.342Epoch  31:  18% | abe: 3.331 | eve: 9.941 | bob: 3.342Epoch  31:  19% | abe: 3.332 | eve: 9.943 | bob: 3.343Epoch  31:  20% | abe: 3.331 | eve: 9.945 | bob: 3.342Epoch  31:  21% | abe: 3.331 | eve: 9.944 | bob: 3.343Epoch  31:  21% | abe: 3.331 | eve: 9.945 | bob: 3.342Epoch  31:  22% | abe: 3.331 | eve: 9.945 | bob: 3.342Epoch  31:  23% | abe: 3.331 | eve: 9.944 | bob: 3.342Epoch  31:  24% | abe: 3.331 | eve: 9.943 | bob: 3.342Epoch  31:  25% | abe: 3.330 | eve: 9.944 | bob: 3.342Epoch  31:  25% | abe: 3.330 | eve: 9.943 | bob: 3.342Epoch  31:  26% | abe: 3.330 | eve: 9.943 | bob: 3.342Epoch  31:  27% | abe: 3.330 | eve: 9.944 | bob: 3.342Epoch  31:  28% | abe: 3.330 | eve: 9.945 | bob: 3.342Epoch  31:  28% | abe: 3.330 | eve: 9.945 | bob: 3.342Epoch  31:  29% | abe: 3.330 | eve: 9.944 | bob: 3.343Epoch  31:  30% | abe: 3.330 | eve: 9.945 | bob: 3.343Epoch  31:  31% | abe: 3.330 | eve: 9.945 | bob: 3.342Epoch  31:  32% | abe: 3.330 | eve: 9.945 | bob: 3.342Epoch  31:  32% | abe: 3.330 | eve: 9.945 | bob: 3.342Epoch  31:  33% | abe: 3.330 | eve: 9.946 | bob: 3.342Epoch  31:  34% | abe: 3.330 | eve: 9.946 | bob: 3.343Epoch  31:  35% | abe: 3.330 | eve: 9.947 | bob: 3.343Epoch  31:  35% | abe: 3.330 | eve: 9.945 | bob: 3.343Epoch  31:  36% | abe: 3.330 | eve: 9.945 | bob: 3.343Epoch  31:  37% | abe: 3.330 | eve: 9.946 | bob: 3.343Epoch  31:  38% | abe: 3.330 | eve: 9.947 | bob: 3.343Epoch  31:  39% | abe: 3.330 | eve: 9.947 | bob: 3.343Epoch  31:  39% | abe: 3.330 | eve: 9.948 | bob: 3.343Epoch  31:  40% | abe: 3.330 | eve: 9.948 | bob: 3.343Epoch  31:  41% | abe: 3.330 | eve: 9.949 | bob: 3.343Epoch  31:  42% | abe: 3.330 | eve: 9.950 | bob: 3.343Epoch  31:  42% | abe: 3.330 | eve: 9.950 | bob: 3.343Epoch  31:  43% | abe: 3.330 | eve: 9.951 | bob: 3.343Epoch  31:  44% | abe: 3.330 | eve: 9.951 | bob: 3.343Epoch  31:  45% | abe: 3.330 | eve: 9.952 | bob: 3.343Epoch  31:  46% | abe: 3.330 | eve: 9.952 | bob: 3.342Epoch  31:  46% | abe: 3.330 | eve: 9.951 | bob: 3.343Epoch  31:  47% | abe: 3.330 | eve: 9.951 | bob: 3.343Epoch  31:  48% | abe: 3.330 | eve: 9.952 | bob: 3.343Epoch  31:  49% | abe: 3.330 | eve: 9.951 | bob: 3.343Epoch  31:  50% | abe: 3.330 | eve: 9.951 | bob: 3.344Epoch  31:  50% | abe: 3.330 | eve: 9.951 | bob: 3.343Epoch  31:  51% | abe: 3.330 | eve: 9.951 | bob: 3.343Epoch  31:  52% | abe: 3.330 | eve: 9.951 | bob: 3.343Epoch  31:  53% | abe: 3.330 | eve: 9.951 | bob: 3.343Epoch  31:  53% | abe: 3.330 | eve: 9.952 | bob: 3.343Epoch  31:  54% | abe: 3.330 | eve: 9.952 | bob: 3.343Epoch  31:  55% | abe: 3.330 | eve: 9.953 | bob: 3.343Epoch  31:  56% | abe: 3.330 | eve: 9.954 | bob: 3.343Epoch  31:  57% | abe: 3.329 | eve: 9.954 | bob: 3.343Epoch  31:  57% | abe: 3.329 | eve: 9.955 | bob: 3.342Epoch  31:  58% | abe: 3.329 | eve: 9.954 | bob: 3.342Epoch  31:  59% | abe: 3.329 | eve: 9.955 | bob: 3.342Epoch  31:  60% | abe: 3.329 | eve: 9.955 | bob: 3.342Epoch  31:  60% | abe: 3.328 | eve: 9.954 | bob: 3.342Epoch  31:  61% | abe: 3.328 | eve: 9.955 | bob: 3.342Epoch  31:  62% | abe: 3.328 | eve: 9.955 | bob: 3.341Epoch  31:  63% | abe: 3.328 | eve: 9.955 | bob: 3.341Epoch  31:  64% | abe: 3.328 | eve: 9.955 | bob: 3.341Epoch  31:  64% | abe: 3.327 | eve: 9.954 | bob: 3.341Epoch  31:  65% | abe: 3.327 | eve: 9.954 | bob: 3.341Epoch  31:  66% | abe: 3.327 | eve: 9.954 | bob: 3.341Epoch  31:  67% | abe: 3.327 | eve: 9.953 | bob: 3.341Epoch  31:  67% | abe: 3.327 | eve: 9.953 | bob: 3.341Epoch  31:  68% | abe: 3.327 | eve: 9.952 | bob: 3.341Epoch  31:  69% | abe: 3.327 | eve: 9.952 | bob: 3.341Epoch  31:  70% | abe: 3.327 | eve: 9.952 | bob: 3.341Epoch  31:  71% | abe: 3.327 | eve: 9.952 | bob: 3.341Epoch  31:  71% | abe: 3.327 | eve: 9.952 | bob: 3.341Epoch  31:  72% | abe: 3.326 | eve: 9.952 | bob: 3.341Epoch  31:  73% | abe: 3.326 | eve: 9.952 | bob: 3.341Epoch  31:  74% | abe: 3.326 | eve: 9.952 | bob: 3.341Epoch  31:  75% | abe: 3.326 | eve: 9.952 | bob: 3.340Epoch  31:  75% | abe: 3.326 | eve: 9.953 | bob: 3.340Epoch  31:  76% | abe: 3.326 | eve: 9.952 | bob: 3.340Epoch  31:  77% | abe: 3.326 | eve: 9.953 | bob: 3.340Epoch  31:  78% | abe: 3.325 | eve: 9.953 | bob: 3.340Epoch  31:  78% | abe: 3.325 | eve: 9.953 | bob: 3.340Epoch  31:  79% | abe: 3.325 | eve: 9.953 | bob: 3.340Epoch  31:  80% | abe: 3.325 | eve: 9.953 | bob: 3.340Epoch  31:  81% | abe: 3.325 | eve: 9.954 | bob: 3.340Epoch  31:  82% | abe: 3.325 | eve: 9.954 | bob: 3.340Epoch  31:  82% | abe: 3.325 | eve: 9.953 | bob: 3.340Epoch  31:  83% | abe: 3.325 | eve: 9.953 | bob: 3.340Epoch  31:  84% | abe: 3.325 | eve: 9.954 | bob: 3.340Epoch  31:  85% | abe: 3.325 | eve: 9.953 | bob: 3.340Epoch  31:  85% | abe: 3.325 | eve: 9.953 | bob: 3.340Epoch  31:  86% | abe: 3.325 | eve: 9.954 | bob: 3.340Epoch  31:  87% | abe: 3.325 | eve: 9.954 | bob: 3.339Epoch  31:  88% | abe: 3.325 | eve: 9.954 | bob: 3.339Epoch  31:  89% | abe: 3.325 | eve: 9.954 | bob: 3.340Epoch  31:  89% | abe: 3.325 | eve: 9.954 | bob: 3.340Epoch  31:  90% | abe: 3.325 | eve: 9.954 | bob: 3.339Epoch  31:  91% | abe: 3.325 | eve: 9.953 | bob: 3.339Epoch  31:  92% | abe: 3.325 | eve: 9.953 | bob: 3.339Epoch  31:  92% | abe: 3.325 | eve: 9.953 | bob: 3.339Epoch  31:  93% | abe: 3.325 | eve: 9.954 | bob: 3.340Epoch  31:  94% | abe: 3.325 | eve: 9.954 | bob: 3.340Epoch  31:  95% | abe: 3.325 | eve: 9.954 | bob: 3.339Epoch  31:  96% | abe: 3.325 | eve: 9.953 | bob: 3.339Epoch  31:  96% | abe: 3.325 | eve: 9.953 | bob: 3.339Epoch  31:  97% | abe: 3.325 | eve: 9.953 | bob: 3.339Epoch  31:  98% | abe: 3.325 | eve: 9.953 | bob: 3.340Epoch  31:  99% | abe: 3.325 | eve: 9.953 | bob: 3.340
New best Bob loss 3.3396958628130733 at epoch 31
Epoch  32:   0% | abe: 3.322 | eve: 9.985 | bob: 3.333Epoch  32:   0% | abe: 3.312 | eve: 9.972 | bob: 3.323Epoch  32:   1% | abe: 3.317 | eve: 9.951 | bob: 3.327Epoch  32:   2% | abe: 3.314 | eve: 9.961 | bob: 3.330Epoch  32:   3% | abe: 3.317 | eve: 9.956 | bob: 3.333Epoch  32:   3% | abe: 3.319 | eve: 9.953 | bob: 3.336Epoch  32:   4% | abe: 3.318 | eve: 9.954 | bob: 3.335Epoch  32:   5% | abe: 3.317 | eve: 9.958 | bob: 3.335Epoch  32:   6% | abe: 3.316 | eve: 9.960 | bob: 3.334Epoch  32:   7% | abe: 3.316 | eve: 9.959 | bob: 3.336Epoch  32:   7% | abe: 3.317 | eve: 9.964 | bob: 3.337Epoch  32:   8% | abe: 3.315 | eve: 9.964 | bob: 3.335Epoch  32:   9% | abe: 3.316 | eve: 9.969 | bob: 3.336Epoch  32:  10% | abe: 3.315 | eve: 9.969 | bob: 3.337Epoch  32:  10% | abe: 3.314 | eve: 9.968 | bob: 3.335Epoch  32:  11% | abe: 3.315 | eve: 9.969 | bob: 3.336Epoch  32:  12% | abe: 3.315 | eve: 9.972 | bob: 3.336Epoch  32:  13% | abe: 3.315 | eve: 9.971 | bob: 3.336Epoch  32:  14% | abe: 3.315 | eve: 9.971 | bob: 3.338Epoch  32:  14% | abe: 3.314 | eve: 9.969 | bob: 3.337Epoch  32:  15% | abe: 3.314 | eve: 9.971 | bob: 3.337Epoch  32:  16% | abe: 3.314 | eve: 9.968 | bob: 3.337Epoch  32:  17% | abe: 3.313 | eve: 9.967 | bob: 3.336Epoch  32:  17% | abe: 3.314 | eve: 9.967 | bob: 3.337Epoch  32:  18% | abe: 3.314 | eve: 9.967 | bob: 3.337Epoch  32:  19% | abe: 3.314 | eve: 9.968 | bob: 3.337Epoch  32:  20% | abe: 3.314 | eve: 9.968 | bob: 3.337Epoch  32:  21% | abe: 3.315 | eve: 9.965 | bob: 3.338Epoch  32:  21% | abe: 3.315 | eve: 9.966 | bob: 3.338Epoch  32:  22% | abe: 3.315 | eve: 9.966 | bob: 3.338Epoch  32:  23% | abe: 3.315 | eve: 9.967 | bob: 3.339Epoch  32:  24% | abe: 3.316 | eve: 9.967 | bob: 3.339Epoch  32:  25% | abe: 3.315 | eve: 9.968 | bob: 3.339Epoch  32:  25% | abe: 3.315 | eve: 9.968 | bob: 3.339Epoch  32:  26% | abe: 3.315 | eve: 9.968 | bob: 3.339Epoch  32:  27% | abe: 3.315 | eve: 9.968 | bob: 3.339Epoch  32:  28% | abe: 3.315 | eve: 9.968 | bob: 3.339Epoch  32:  28% | abe: 3.315 | eve: 9.967 | bob: 3.338Epoch  32:  29% | abe: 3.315 | eve: 9.967 | bob: 3.339Epoch  32:  30% | abe: 3.315 | eve: 9.967 | bob: 3.339Epoch  32:  31% | abe: 3.315 | eve: 9.966 | bob: 3.339Epoch  32:  32% | abe: 3.315 | eve: 9.966 | bob: 3.339Epoch  32:  32% | abe: 3.315 | eve: 9.965 | bob: 3.339Epoch  32:  33% | abe: 3.314 | eve: 9.964 | bob: 3.338Epoch  32:  34% | abe: 3.314 | eve: 9.964 | bob: 3.338Epoch  32:  35% | abe: 3.314 | eve: 9.964 | bob: 3.338Epoch  32:  35% | abe: 3.314 | eve: 9.963 | bob: 3.338Epoch  32:  36% | abe: 3.314 | eve: 9.963 | bob: 3.338Epoch  32:  37% | abe: 3.314 | eve: 9.964 | bob: 3.339Epoch  32:  38% | abe: 3.314 | eve: 9.964 | bob: 3.339Epoch  32:  39% | abe: 3.314 | eve: 9.963 | bob: 3.339Epoch  32:  39% | abe: 3.314 | eve: 9.963 | bob: 3.339Epoch  32:  40% | abe: 3.314 | eve: 9.963 | bob: 3.339Epoch  32:  41% | abe: 3.314 | eve: 9.962 | bob: 3.339Epoch  32:  42% | abe: 3.314 | eve: 9.962 | bob: 3.339Epoch  32:  42% | abe: 3.314 | eve: 9.962 | bob: 3.339Epoch  32:  43% | abe: 3.314 | eve: 9.962 | bob: 3.339Epoch  32:  44% | abe: 3.314 | eve: 9.961 | bob: 3.339Epoch  32:  45% | abe: 3.314 | eve: 9.961 | bob: 3.339Epoch  32:  46% | abe: 3.314 | eve: 9.961 | bob: 3.339Epoch  32:  46% | abe: 3.314 | eve: 9.961 | bob: 3.339Epoch  32:  47% | abe: 3.314 | eve: 9.960 | bob: 3.339Epoch  32:  48% | abe: 3.314 | eve: 9.960 | bob: 3.339Epoch  32:  49% | abe: 3.313 | eve: 9.960 | bob: 3.339Epoch  32:  50% | abe: 3.313 | eve: 9.959 | bob: 3.339Epoch  32:  50% | abe: 3.313 | eve: 9.959 | bob: 3.339Epoch  32:  51% | abe: 3.313 | eve: 9.959 | bob: 3.339Epoch  32:  52% | abe: 3.313 | eve: 9.958 | bob: 3.338Epoch  32:  53% | abe: 3.313 | eve: 9.958 | bob: 3.338Epoch  32:  53% | abe: 3.313 | eve: 9.958 | bob: 3.338Epoch  32:  54% | abe: 3.312 | eve: 9.959 | bob: 3.338Epoch  32:  55% | abe: 3.312 | eve: 9.959 | bob: 3.338Epoch  32:  56% | abe: 3.312 | eve: 9.958 | bob: 3.337Epoch  32:  57% | abe: 3.312 | eve: 9.958 | bob: 3.337Epoch  32:  57% | abe: 3.312 | eve: 9.959 | bob: 3.337Epoch  32:  58% | abe: 3.312 | eve: 9.959 | bob: 3.337Epoch  32:  59% | abe: 3.312 | eve: 9.959 | bob: 3.337Epoch  32:  60% | abe: 3.311 | eve: 9.958 | bob: 3.337Epoch  32:  60% | abe: 3.311 | eve: 9.959 | bob: 3.337Epoch  32:  61% | abe: 3.311 | eve: 9.959 | bob: 3.337Epoch  32:  62% | abe: 3.311 | eve: 9.959 | bob: 3.337Epoch  32:  63% | abe: 3.311 | eve: 9.959 | bob: 3.337Epoch  32:  64% | abe: 3.311 | eve: 9.959 | bob: 3.337Epoch  32:  64% | abe: 3.311 | eve: 9.959 | bob: 3.337Epoch  32:  65% | abe: 3.311 | eve: 9.959 | bob: 3.337Epoch  32:  66% | abe: 3.311 | eve: 9.959 | bob: 3.337Epoch  32:  67% | abe: 3.311 | eve: 9.959 | bob: 3.337Epoch  32:  67% | abe: 3.311 | eve: 9.959 | bob: 3.337Epoch  32:  68% | abe: 3.311 | eve: 9.959 | bob: 3.337Epoch  32:  69% | abe: 3.311 | eve: 9.959 | bob: 3.337Epoch  32:  70% | abe: 3.311 | eve: 9.958 | bob: 3.337Epoch  32:  71% | abe: 3.311 | eve: 9.959 | bob: 3.337Epoch  32:  71% | abe: 3.311 | eve: 9.958 | bob: 3.337Epoch  32:  72% | abe: 3.311 | eve: 9.958 | bob: 3.337Epoch  32:  73% | abe: 3.311 | eve: 9.958 | bob: 3.337Epoch  32:  74% | abe: 3.310 | eve: 9.959 | bob: 3.337Epoch  32:  75% | abe: 3.310 | eve: 9.959 | bob: 3.337Epoch  32:  75% | abe: 3.310 | eve: 9.959 | bob: 3.337Epoch  32:  76% | abe: 3.310 | eve: 9.959 | bob: 3.337Epoch  32:  77% | abe: 3.310 | eve: 9.958 | bob: 3.337Epoch  32:  78% | abe: 3.310 | eve: 9.959 | bob: 3.336Epoch  32:  78% | abe: 3.310 | eve: 9.959 | bob: 3.336Epoch  32:  79% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  80% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  81% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  82% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  82% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  83% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  84% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  85% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  85% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  86% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  87% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  88% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  89% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  89% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  90% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  91% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  92% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  92% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  93% | abe: 3.309 | eve: 9.958 | bob: 3.336Epoch  32:  94% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  95% | abe: 3.309 | eve: 9.959 | bob: 3.336Epoch  32:  96% | abe: 3.308 | eve: 9.959 | bob: 3.336Epoch  32:  96% | abe: 3.308 | eve: 9.959 | bob: 3.336Epoch  32:  97% | abe: 3.308 | eve: 9.959 | bob: 3.336Epoch  32:  98% | abe: 3.308 | eve: 9.959 | bob: 3.336Epoch  32:  99% | abe: 3.308 | eve: 9.959 | bob: 3.336
New best Bob loss 3.3357495844577443 at epoch 32
Epoch  33:   0% | abe: 3.301 | eve: 9.969 | bob: 3.332Epoch  33:   0% | abe: 3.294 | eve: 9.947 | bob: 3.324Epoch  33:   1% | abe: 3.296 | eve: 9.957 | bob: 3.328Epoch  33:   2% | abe: 3.302 | eve: 9.951 | bob: 3.333Epoch  33:   3% | abe: 3.302 | eve: 9.959 | bob: 3.332Epoch  33:   3% | abe: 3.304 | eve: 9.964 | bob: 3.333Epoch  33:   4% | abe: 3.302 | eve: 9.953 | bob: 3.333Epoch  33:   5% | abe: 3.302 | eve: 9.954 | bob: 3.333Epoch  33:   6% | abe: 3.303 | eve: 9.953 | bob: 3.334Epoch  33:   7% | abe: 3.302 | eve: 9.953 | bob: 3.332Epoch  33:   7% | abe: 3.302 | eve: 9.954 | bob: 3.333Epoch  33:   8% | abe: 3.301 | eve: 9.951 | bob: 3.333Epoch  33:   9% | abe: 3.300 | eve: 9.951 | bob: 3.332Epoch  33:  10% | abe: 3.300 | eve: 9.952 | bob: 3.332Epoch  33:  10% | abe: 3.299 | eve: 9.955 | bob: 3.331Epoch  33:  11% | abe: 3.298 | eve: 9.953 | bob: 3.330Epoch  33:  12% | abe: 3.299 | eve: 9.956 | bob: 3.331Epoch  33:  13% | abe: 3.299 | eve: 9.957 | bob: 3.332Epoch  33:  14% | abe: 3.300 | eve: 9.958 | bob: 3.334Epoch  33:  14% | abe: 3.300 | eve: 9.958 | bob: 3.333Epoch  33:  15% | abe: 3.300 | eve: 9.958 | bob: 3.334Epoch  33:  16% | abe: 3.300 | eve: 9.960 | bob: 3.335Epoch  33:  17% | abe: 3.301 | eve: 9.961 | bob: 3.335Epoch  33:  17% | abe: 3.301 | eve: 9.960 | bob: 3.336Epoch  33:  18% | abe: 3.300 | eve: 9.961 | bob: 3.335Epoch  33:  19% | abe: 3.300 | eve: 9.963 | bob: 3.335Epoch  33:  20% | abe: 3.300 | eve: 9.961 | bob: 3.334Epoch  33:  21% | abe: 3.300 | eve: 9.959 | bob: 3.334Epoch  33:  21% | abe: 3.299 | eve: 9.959 | bob: 3.334Epoch  33:  22% | abe: 3.299 | eve: 9.960 | bob: 3.334Epoch  33:  23% | abe: 3.299 | eve: 9.963 | bob: 3.334Epoch  33:  24% | abe: 3.299 | eve: 9.963 | bob: 3.334Epoch  33:  25% | abe: 3.299 | eve: 9.963 | bob: 3.335Epoch  33:  25% | abe: 3.299 | eve: 9.964 | bob: 3.335Epoch  33:  26% | abe: 3.299 | eve: 9.965 | bob: 3.335Epoch  33:  27% | abe: 3.298 | eve: 9.965 | bob: 3.334Epoch  33:  28% | abe: 3.299 | eve: 9.966 | bob: 3.335Epoch  33:  28% | abe: 3.299 | eve: 9.966 | bob: 3.335Epoch  33:  29% | abe: 3.298 | eve: 9.967 | bob: 3.334Epoch  33:  30% | abe: 3.298 | eve: 9.965 | bob: 3.334Epoch  33:  31% | abe: 3.298 | eve: 9.966 | bob: 3.335Epoch  33:  32% | abe: 3.298 | eve: 9.967 | bob: 3.335Epoch  33:  32% | abe: 3.298 | eve: 9.968 | bob: 3.335Epoch  33:  33% | abe: 3.298 | eve: 9.970 | bob: 3.334Epoch  33:  34% | abe: 3.298 | eve: 9.969 | bob: 3.335Epoch  33:  35% | abe: 3.297 | eve: 9.971 | bob: 3.335Epoch  33:  35% | abe: 3.297 | eve: 9.971 | bob: 3.334Epoch  33:  36% | abe: 3.297 | eve: 9.971 | bob: 3.335Epoch  33:  37% | abe: 3.297 | eve: 9.970 | bob: 3.335Epoch  33:  38% | abe: 3.297 | eve: 9.969 | bob: 3.335Epoch  33:  39% | abe: 3.297 | eve: 9.970 | bob: 3.335Epoch  33:  39% | abe: 3.298 | eve: 9.970 | bob: 3.335Epoch  33:  40% | abe: 3.297 | eve: 9.970 | bob: 3.335Epoch  33:  41% | abe: 3.297 | eve: 9.968 | bob: 3.335Epoch  33:  42% | abe: 3.298 | eve: 9.968 | bob: 3.335Epoch  33:  42% | abe: 3.298 | eve: 9.968 | bob: 3.335Epoch  33:  43% | abe: 3.297 | eve: 9.968 | bob: 3.335Epoch  33:  44% | abe: 3.297 | eve: 9.968 | bob: 3.336Epoch  33:  45% | abe: 3.298 | eve: 9.968 | bob: 3.336Epoch  33:  46% | abe: 3.298 | eve: 9.967 | bob: 3.337Epoch  33:  46% | abe: 3.298 | eve: 9.968 | bob: 3.337Epoch  33:  47% | abe: 3.298 | eve: 9.967 | bob: 3.336Epoch  33:  48% | abe: 3.298 | eve: 9.966 | bob: 3.336Epoch  33:  49% | abe: 3.298 | eve: 9.966 | bob: 3.336Epoch  33:  50% | abe: 3.298 | eve: 9.965 | bob: 3.336Epoch  33:  50% | abe: 3.297 | eve: 9.964 | bob: 3.336Epoch  33:  51% | abe: 3.298 | eve: 9.965 | bob: 3.337Epoch  33:  52% | abe: 3.297 | eve: 9.966 | bob: 3.337Epoch  33:  53% | abe: 3.297 | eve: 9.966 | bob: 3.337Epoch  33:  53% | abe: 3.297 | eve: 9.966 | bob: 3.337Epoch  33:  54% | abe: 3.297 | eve: 9.965 | bob: 3.337Epoch  33:  55% | abe: 3.297 | eve: 9.966 | bob: 3.337Epoch  33:  56% | abe: 3.297 | eve: 9.966 | bob: 3.337Epoch  33:  57% | abe: 3.297 | eve: 9.967 | bob: 3.337Epoch  33:  57% | abe: 3.297 | eve: 9.966 | bob: 3.337Epoch  33:  58% | abe: 3.297 | eve: 9.966 | bob: 3.337Epoch  33:  59% | abe: 3.297 | eve: 9.967 | bob: 3.337Epoch  33:  60% | abe: 3.297 | eve: 9.967 | bob: 3.337Epoch  33:  60% | abe: 3.297 | eve: 9.968 | bob: 3.337Epoch  33:  61% | abe: 3.297 | eve: 9.969 | bob: 3.337Epoch  33:  62% | abe: 3.297 | eve: 9.969 | bob: 3.337Epoch  33:  63% | abe: 3.297 | eve: 9.969 | bob: 3.337Epoch  33:  64% | abe: 3.297 | eve: 9.969 | bob: 3.337Epoch  33:  64% | abe: 3.296 | eve: 9.969 | bob: 3.337Epoch  33:  65% | abe: 3.296 | eve: 9.968 | bob: 3.337Epoch  33:  66% | abe: 3.296 | eve: 9.968 | bob: 3.337Epoch  33:  67% | abe: 3.296 | eve: 9.969 | bob: 3.337Epoch  33:  67% | abe: 3.296 | eve: 9.969 | bob: 3.337Epoch  33:  68% | abe: 3.296 | eve: 9.969 | bob: 3.337Epoch  33:  69% | abe: 3.296 | eve: 9.969 | bob: 3.337Epoch  33:  70% | abe: 3.296 | eve: 9.969 | bob: 3.337Epoch  33:  71% | abe: 3.296 | eve: 9.969 | bob: 3.337Epoch  33:  71% | abe: 3.296 | eve: 9.969 | bob: 3.337Epoch  33:  72% | abe: 3.296 | eve: 9.969 | bob: 3.337Epoch  33:  73% | abe: 3.296 | eve: 9.968 | bob: 3.337Epoch  33:  74% | abe: 3.296 | eve: 9.968 | bob: 3.337Epoch  33:  75% | abe: 3.296 | eve: 9.968 | bob: 3.337Epoch  33:  75% | abe: 3.296 | eve: 9.967 | bob: 3.337Epoch  33:  76% | abe: 3.296 | eve: 9.968 | bob: 3.337Epoch  33:  77% | abe: 3.295 | eve: 9.968 | bob: 3.337Epoch  33:  78% | abe: 3.295 | eve: 9.968 | bob: 3.337Epoch  33:  78% | abe: 3.295 | eve: 9.969 | bob: 3.337Epoch  33:  79% | abe: 3.295 | eve: 9.970 | bob: 3.337Epoch  33:  80% | abe: 3.295 | eve: 9.970 | bob: 3.337Epoch  33:  81% | abe: 3.295 | eve: 9.970 | bob: 3.337Epoch  33:  82% | abe: 3.295 | eve: 9.970 | bob: 3.337Epoch  33:  82% | abe: 3.295 | eve: 9.970 | bob: 3.337Epoch  33:  83% | abe: 3.295 | eve: 9.970 | bob: 3.337Epoch  33:  84% | abe: 3.295 | eve: 9.970 | bob: 3.337Epoch  33:  85% | abe: 3.295 | eve: 9.970 | bob: 3.337Epoch  33:  85% | abe: 3.295 | eve: 9.970 | bob: 3.337Epoch  33:  86% | abe: 3.295 | eve: 9.970 | bob: 3.337Epoch  33:  87% | abe: 3.295 | eve: 9.970 | bob: 3.337Epoch  33:  88% | abe: 3.295 | eve: 9.970 | bob: 3.337Epoch  33:  89% | abe: 3.295 | eve: 9.970 | bob: 3.337Epoch  33:  89% | abe: 3.295 | eve: 9.970 | bob: 3.337Epoch  33:  90% | abe: 3.295 | eve: 9.970 | bob: 3.337Epoch  33:  91% | abe: 3.294 | eve: 9.970 | bob: 3.337Epoch  33:  92% | abe: 3.294 | eve: 9.970 | bob: 3.337Epoch  33:  92% | abe: 3.294 | eve: 9.970 | bob: 3.337Epoch  33:  93% | abe: 3.294 | eve: 9.970 | bob: 3.337Epoch  33:  94% | abe: 3.294 | eve: 9.970 | bob: 3.337Epoch  33:  95% | abe: 3.294 | eve: 9.970 | bob: 3.337Epoch  33:  96% | abe: 3.294 | eve: 9.969 | bob: 3.337Epoch  33:  96% | abe: 3.294 | eve: 9.970 | bob: 3.337Epoch  33:  97% | abe: 3.294 | eve: 9.969 | bob: 3.337Epoch  33:  98% | abe: 3.293 | eve: 9.970 | bob: 3.337Epoch  33:  99% | abe: 3.293 | eve: 9.969 | bob: 3.337Epoch  34:   0% | abe: 3.293 | eve: 9.871 | bob: 3.354Epoch  34:   0% | abe: 3.285 | eve: 9.933 | bob: 3.343Epoch  34:   1% | abe: 3.290 | eve: 9.951 | bob: 3.346Epoch  34:   2% | abe: 3.290 | eve: 9.957 | bob: 3.342Epoch  34:   3% | abe: 3.287 | eve: 9.964 | bob: 3.338Epoch  34:   3% | abe: 3.285 | eve: 9.962 | bob: 3.336Epoch  34:   4% | abe: 3.285 | eve: 9.957 | bob: 3.338Epoch  34:   5% | abe: 3.282 | eve: 9.955 | bob: 3.335Epoch  34:   6% | abe: 3.282 | eve: 9.959 | bob: 3.335Epoch  34:   7% | abe: 3.281 | eve: 9.965 | bob: 3.334Epoch  34:   7% | abe: 3.282 | eve: 9.969 | bob: 3.335Epoch  34:   8% | abe: 3.283 | eve: 9.968 | bob: 3.336Epoch  34:   9% | abe: 3.282 | eve: 9.971 | bob: 3.335Epoch  34:  10% | abe: 3.282 | eve: 9.975 | bob: 3.336Epoch  34:  10% | abe: 3.282 | eve: 9.974 | bob: 3.335Epoch  34:  11% | abe: 3.281 | eve: 9.972 | bob: 3.335Epoch  34:  12% | abe: 3.280 | eve: 9.971 | bob: 3.335Epoch  34:  13% | abe: 3.281 | eve: 9.971 | bob: 3.336Epoch  34:  14% | abe: 3.281 | eve: 9.972 | bob: 3.337Epoch  34:  14% | abe: 3.281 | eve: 9.971 | bob: 3.336Epoch  34:  15% | abe: 3.281 | eve: 9.970 | bob: 3.336Epoch  34:  16% | abe: 3.281 | eve: 9.969 | bob: 3.336Epoch  34:  17% | abe: 3.280 | eve: 9.970 | bob: 3.335Epoch  34:  17% | abe: 3.281 | eve: 9.971 | bob: 3.336Epoch  34:  18% | abe: 3.281 | eve: 9.971 | bob: 3.336Epoch  34:  19% | abe: 3.281 | eve: 9.971 | bob: 3.336Epoch  34:  20% | abe: 3.281 | eve: 9.973 | bob: 3.337Epoch  34:  21% | abe: 3.281 | eve: 9.971 | bob: 3.337Epoch  34:  21% | abe: 3.282 | eve: 9.969 | bob: 3.338Epoch  34:  22% | abe: 3.282 | eve: 9.968 | bob: 3.339Epoch  34:  23% | abe: 3.282 | eve: 9.968 | bob: 3.338Epoch  34:  24% | abe: 3.282 | eve: 9.967 | bob: 3.338Epoch  34:  25% | abe: 3.281 | eve: 9.970 | bob: 3.337Epoch  34:  25% | abe: 3.281 | eve: 9.969 | bob: 3.337Epoch  34:  26% | abe: 3.280 | eve: 9.969 | bob: 3.336Epoch  34:  27% | abe: 3.281 | eve: 9.969 | bob: 3.337Epoch  34:  28% | abe: 3.281 | eve: 9.971 | bob: 3.337Epoch  34:  28% | abe: 3.280 | eve: 9.971 | bob: 3.336Epoch  34:  29% | abe: 3.280 | eve: 9.972 | bob: 3.337Epoch  34:  30% | abe: 3.281 | eve: 9.972 | bob: 3.337Epoch  34:  31% | abe: 3.281 | eve: 9.973 | bob: 3.337Epoch  34:  32% | abe: 3.280 | eve: 9.973 | bob: 3.336Epoch  34:  32% | abe: 3.281 | eve: 9.971 | bob: 3.337Epoch  34:  33% | abe: 3.280 | eve: 9.972 | bob: 3.337Epoch  34:  34% | abe: 3.280 | eve: 9.970 | bob: 3.337Epoch  34:  35% | abe: 3.281 | eve: 9.969 | bob: 3.337Epoch  34:  35% | abe: 3.281 | eve: 9.968 | bob: 3.338Epoch  34:  36% | abe: 3.281 | eve: 9.968 | bob: 3.338Epoch  34:  37% | abe: 3.281 | eve: 9.968 | bob: 3.337Epoch  34:  38% | abe: 3.281 | eve: 9.967 | bob: 3.337Epoch  34:  39% | abe: 3.280 | eve: 9.967 | bob: 3.337Epoch  34:  39% | abe: 3.280 | eve: 9.967 | bob: 3.337Epoch  34:  40% | abe: 3.280 | eve: 9.967 | bob: 3.337Epoch  34:  41% | abe: 3.280 | eve: 9.967 | bob: 3.337Epoch  34:  42% | abe: 3.280 | eve: 9.966 | bob: 3.337Epoch  34:  42% | abe: 3.280 | eve: 9.966 | bob: 3.337Epoch  34:  43% | abe: 3.280 | eve: 9.966 | bob: 3.337Epoch  34:  44% | abe: 3.280 | eve: 9.966 | bob: 3.337Epoch  34:  45% | abe: 3.280 | eve: 9.965 | bob: 3.337Epoch  34:  46% | abe: 3.280 | eve: 9.965 | bob: 3.337Epoch  34:  46% | abe: 3.280 | eve: 9.964 | bob: 3.337Epoch  34:  47% | abe: 3.280 | eve: 9.964 | bob: 3.338Epoch  34:  48% | abe: 3.280 | eve: 9.964 | bob: 3.338Epoch  34:  49% | abe: 3.280 | eve: 9.964 | bob: 3.338Epoch  34:  50% | abe: 3.280 | eve: 9.963 | bob: 3.337Epoch  34:  50% | abe: 3.280 | eve: 9.963 | bob: 3.337Epoch  34:  51% | abe: 3.279 | eve: 9.963 | bob: 3.337Epoch  34:  52% | abe: 3.279 | eve: 9.963 | bob: 3.337Epoch  34:  53% | abe: 3.279 | eve: 9.963 | bob: 3.337Epoch  34:  53% | abe: 3.279 | eve: 9.963 | bob: 3.336Epoch  34:  54% | abe: 3.279 | eve: 9.963 | bob: 3.337Epoch  34:  55% | abe: 3.279 | eve: 9.962 | bob: 3.337Epoch  34:  56% | abe: 3.279 | eve: 9.962 | bob: 3.336Epoch  34:  57% | abe: 3.279 | eve: 9.963 | bob: 3.337Epoch  34:  57% | abe: 3.279 | eve: 9.963 | bob: 3.337Epoch  34:  58% | abe: 3.279 | eve: 9.963 | bob: 3.337Epoch  34:  59% | abe: 3.279 | eve: 9.962 | bob: 3.337Epoch  34:  60% | abe: 3.279 | eve: 9.962 | bob: 3.337Epoch  34:  60% | abe: 3.279 | eve: 9.962 | bob: 3.337Epoch  34:  61% | abe: 3.279 | eve: 9.962 | bob: 3.337Epoch  34:  62% | abe: 3.279 | eve: 9.962 | bob: 3.337Epoch  34:  63% | abe: 3.278 | eve: 9.963 | bob: 3.337Epoch  34:  64% | abe: 3.278 | eve: 9.963 | bob: 3.337Epoch  34:  64% | abe: 3.279 | eve: 9.963 | bob: 3.337Epoch  34:  65% | abe: 3.279 | eve: 9.963 | bob: 3.338Epoch  34:  66% | abe: 3.279 | eve: 9.963 | bob: 3.337Epoch  34:  67% | abe: 3.279 | eve: 9.963 | bob: 3.337Epoch  34:  67% | abe: 3.278 | eve: 9.963 | bob: 3.337Epoch  34:  68% | abe: 3.278 | eve: 9.963 | bob: 3.337Epoch  34:  69% | abe: 3.278 | eve: 9.962 | bob: 3.337Epoch  34:  70% | abe: 3.278 | eve: 9.963 | bob: 3.337Epoch  34:  71% | abe: 3.278 | eve: 9.962 | bob: 3.337Epoch  34:  71% | abe: 3.278 | eve: 9.962 | bob: 3.337Epoch  34:  72% | abe: 3.278 | eve: 9.961 | bob: 3.337Epoch  34:  73% | abe: 3.278 | eve: 9.962 | bob: 3.337Epoch  34:  74% | abe: 3.278 | eve: 9.962 | bob: 3.337Epoch  34:  75% | abe: 3.278 | eve: 9.961 | bob: 3.337Epoch  34:  75% | abe: 3.278 | eve: 9.962 | bob: 3.337Epoch  34:  76% | abe: 3.278 | eve: 9.962 | bob: 3.337Epoch  34:  77% | abe: 3.278 | eve: 9.962 | bob: 3.337Epoch  34:  78% | abe: 3.278 | eve: 9.962 | bob: 3.337Epoch  34:  78% | abe: 3.278 | eve: 9.962 | bob: 3.337Epoch  34:  79% | abe: 3.278 | eve: 9.962 | bob: 3.337Epoch  34:  80% | abe: 3.277 | eve: 9.962 | bob: 3.337Epoch  34:  81% | abe: 3.278 | eve: 9.962 | bob: 3.337Epoch  34:  82% | abe: 3.278 | eve: 9.961 | bob: 3.337Epoch  34:  82% | abe: 3.278 | eve: 9.961 | bob: 3.337Epoch  34:  83% | abe: 3.277 | eve: 9.961 | bob: 3.337Epoch  34:  84% | abe: 3.277 | eve: 9.961 | bob: 3.337Epoch  34:  85% | abe: 3.277 | eve: 9.962 | bob: 3.337Epoch  34:  85% | abe: 3.277 | eve: 9.962 | bob: 3.337Epoch  34:  86% | abe: 3.277 | eve: 9.961 | bob: 3.337Epoch  34:  87% | abe: 3.277 | eve: 9.961 | bob: 3.337Epoch  34:  88% | abe: 3.277 | eve: 9.962 | bob: 3.337Epoch  34:  89% | abe: 3.277 | eve: 9.962 | bob: 3.337Epoch  34:  89% | abe: 3.277 | eve: 9.962 | bob: 3.338Epoch  34:  90% | abe: 3.277 | eve: 9.962 | bob: 3.337Epoch  34:  91% | abe: 3.277 | eve: 9.962 | bob: 3.338Epoch  34:  92% | abe: 3.277 | eve: 9.962 | bob: 3.338Epoch  34:  92% | abe: 3.277 | eve: 9.962 | bob: 3.338Epoch  34:  93% | abe: 3.277 | eve: 9.962 | bob: 3.338Epoch  34:  94% | abe: 3.277 | eve: 9.961 | bob: 3.338Epoch  34:  95% | abe: 3.277 | eve: 9.961 | bob: 3.338Epoch  34:  96% | abe: 3.277 | eve: 9.961 | bob: 3.338Epoch  34:  96% | abe: 3.276 | eve: 9.961 | bob: 3.338Epoch  34:  97% | abe: 3.276 | eve: 9.961 | bob: 3.338Epoch  34:  98% | abe: 3.276 | eve: 9.961 | bob: 3.337Epoch  34:  99% | abe: 3.276 | eve: 9.960 | bob: 3.338Epoch  35:   0% | abe: 3.270 | eve: 9.981 | bob: 3.344Epoch  35:   0% | abe: 3.266 | eve: 9.951 | bob: 3.340Epoch  35:   1% | abe: 3.264 | eve: 9.945 | bob: 3.338Epoch  35:   2% | abe: 3.264 | eve: 9.931 | bob: 3.337Epoch  35:   3% | abe: 3.264 | eve: 9.943 | bob: 3.341Epoch  35:   3% | abe: 3.265 | eve: 9.942 | bob: 3.340Epoch  35:   4% | abe: 3.264 | eve: 9.946 | bob: 3.340Epoch  35:   5% | abe: 3.262 | eve: 9.951 | bob: 3.338Epoch  35:   6% | abe: 3.262 | eve: 9.953 | bob: 3.337Epoch  35:   7% | abe: 3.263 | eve: 9.956 | bob: 3.336Epoch  35:   7% | abe: 3.262 | eve: 9.958 | bob: 3.336Epoch  35:   8% | abe: 3.263 | eve: 9.962 | bob: 3.336Epoch  35:   9% | abe: 3.263 | eve: 9.960 | bob: 3.335Epoch  35:  10% | abe: 3.264 | eve: 9.961 | bob: 3.336Epoch  35:  10% | abe: 3.263 | eve: 9.961 | bob: 3.334Epoch  35:  11% | abe: 3.263 | eve: 9.959 | bob: 3.334Epoch  35:  12% | abe: 3.263 | eve: 9.960 | bob: 3.334Epoch  35:  13% | abe: 3.263 | eve: 9.958 | bob: 3.333Epoch  35:  14% | abe: 3.263 | eve: 9.961 | bob: 3.334Epoch  35:  14% | abe: 3.264 | eve: 9.961 | bob: 3.335Epoch  35:  15% | abe: 3.264 | eve: 9.963 | bob: 3.335Epoch  35:  16% | abe: 3.264 | eve: 9.962 | bob: 3.335Epoch  35:  17% | abe: 3.265 | eve: 9.964 | bob: 3.335Epoch  35:  17% | abe: 3.265 | eve: 9.966 | bob: 3.336Epoch  35:  18% | abe: 3.265 | eve: 9.964 | bob: 3.337Epoch  35:  19% | abe: 3.265 | eve: 9.963 | bob: 3.337Epoch  35:  20% | abe: 3.266 | eve: 9.964 | bob: 3.336Epoch  35:  21% | abe: 3.266 | eve: 9.964 | bob: 3.337Epoch  35:  21% | abe: 3.267 | eve: 9.965 | bob: 3.337Epoch  35:  22% | abe: 3.267 | eve: 9.966 | bob: 3.337Epoch  35:  23% | abe: 3.266 | eve: 9.966 | bob: 3.336Epoch  35:  24% | abe: 3.266 | eve: 9.963 | bob: 3.336Epoch  35:  25% | abe: 3.266 | eve: 9.965 | bob: 3.337Epoch  35:  25% | abe: 3.266 | eve: 9.966 | bob: 3.337Epoch  35:  26% | abe: 3.266 | eve: 9.965 | bob: 3.336Epoch  35:  27% | abe: 3.265 | eve: 9.965 | bob: 3.336Epoch  35:  28% | abe: 3.265 | eve: 9.965 | bob: 3.336Epoch  35:  28% | abe: 3.265 | eve: 9.965 | bob: 3.336Epoch  35:  29% | abe: 3.265 | eve: 9.967 | bob: 3.336Epoch  35:  30% | abe: 3.265 | eve: 9.968 | bob: 3.336Epoch  35:  31% | abe: 3.265 | eve: 9.968 | bob: 3.336Epoch  35:  32% | abe: 3.265 | eve: 9.968 | bob: 3.336Epoch  35:  32% | abe: 3.265 | eve: 9.968 | bob: 3.336Epoch  35:  33% | abe: 3.265 | eve: 9.969 | bob: 3.336Epoch  35:  34% | abe: 3.265 | eve: 9.970 | bob: 3.336Epoch  35:  35% | abe: 3.265 | eve: 9.969 | bob: 3.336Epoch  35:  35% | abe: 3.265 | eve: 9.970 | bob: 3.336Epoch  35:  36% | abe: 3.265 | eve: 9.967 | bob: 3.336Epoch  35:  37% | abe: 3.264 | eve: 9.968 | bob: 3.336Epoch  35:  38% | abe: 3.264 | eve: 9.968 | bob: 3.336Epoch  35:  39% | abe: 3.264 | eve: 9.967 | bob: 3.336Epoch  35:  39% | abe: 3.264 | eve: 9.967 | bob: 3.336Epoch  35:  40% | abe: 3.264 | eve: 9.968 | bob: 3.336Epoch  35:  41% | abe: 3.264 | eve: 9.967 | bob: 3.335Epoch  35:  42% | abe: 3.264 | eve: 9.966 | bob: 3.336Epoch  35:  42% | abe: 3.264 | eve: 9.966 | bob: 3.335Epoch  35:  43% | abe: 3.264 | eve: 9.966 | bob: 3.336Epoch  35:  44% | abe: 3.264 | eve: 9.965 | bob: 3.336Epoch  35:  45% | abe: 3.264 | eve: 9.965 | bob: 3.336Epoch  35:  46% | abe: 3.264 | eve: 9.965 | bob: 3.336Epoch  35:  46% | abe: 3.263 | eve: 9.965 | bob: 3.336Epoch  35:  47% | abe: 3.264 | eve: 9.965 | bob: 3.336Epoch  35:  48% | abe: 3.263 | eve: 9.965 | bob: 3.336Epoch  35:  49% | abe: 3.263 | eve: 9.965 | bob: 3.336Epoch  35:  50% | abe: 3.263 | eve: 9.964 | bob: 3.336Epoch  35:  50% | abe: 3.264 | eve: 9.965 | bob: 3.336Epoch  35:  51% | abe: 3.264 | eve: 9.965 | bob: 3.337Epoch  35:  52% | abe: 3.264 | eve: 9.965 | bob: 3.337Epoch  35:  53% | abe: 3.264 | eve: 9.966 | bob: 3.337Epoch  35:  53% | abe: 3.264 | eve: 9.965 | bob: 3.337Epoch  35:  54% | abe: 3.264 | eve: 9.965 | bob: 3.337Epoch  35:  55% | abe: 3.264 | eve: 9.965 | bob: 3.337Epoch  35:  56% | abe: 3.264 | eve: 9.966 | bob: 3.337Epoch  35:  57% | abe: 3.264 | eve: 9.966 | bob: 3.337Epoch  35:  57% | abe: 3.264 | eve: 9.966 | bob: 3.337Epoch  35:  58% | abe: 3.263 | eve: 9.966 | bob: 3.337Epoch  35:  59% | abe: 3.263 | eve: 9.966 | bob: 3.337Epoch  35:  60% | abe: 3.263 | eve: 9.966 | bob: 3.337Epoch  35:  60% | abe: 3.263 | eve: 9.967 | bob: 3.337Epoch  35:  61% | abe: 3.263 | eve: 9.967 | bob: 3.337Epoch  35:  62% | abe: 3.263 | eve: 9.967 | bob: 3.337Epoch  35:  63% | abe: 3.263 | eve: 9.967 | bob: 3.337Epoch  35:  64% | abe: 3.263 | eve: 9.967 | bob: 3.337Epoch  35:  64% | abe: 3.263 | eve: 9.967 | bob: 3.337Epoch  35:  65% | abe: 3.263 | eve: 9.966 | bob: 3.338Epoch  35:  66% | abe: 3.263 | eve: 9.967 | bob: 3.338Epoch  35:  67% | abe: 3.263 | eve: 9.967 | bob: 3.338Epoch  35:  67% | abe: 3.263 | eve: 9.966 | bob: 3.338Epoch  35:  68% | abe: 3.263 | eve: 9.967 | bob: 3.338Epoch  35:  69% | abe: 3.263 | eve: 9.967 | bob: 3.338Epoch  35:  70% | abe: 3.263 | eve: 9.966 | bob: 3.338Epoch  35:  71% | abe: 3.263 | eve: 9.966 | bob: 3.338Epoch  35:  71% | abe: 3.263 | eve: 9.966 | bob: 3.338Epoch  35:  72% | abe: 3.264 | eve: 9.966 | bob: 3.338Epoch  35:  73% | abe: 3.263 | eve: 9.966 | bob: 3.338Epoch  35:  74% | abe: 3.263 | eve: 9.965 | bob: 3.338Epoch  35:  75% | abe: 3.263 | eve: 9.965 | bob: 3.338Epoch  35:  75% | abe: 3.263 | eve: 9.965 | bob: 3.338Epoch  35:  76% | abe: 3.263 | eve: 9.965 | bob: 3.338Epoch  35:  77% | abe: 3.263 | eve: 9.965 | bob: 3.338Epoch  35:  78% | abe: 3.263 | eve: 9.966 | bob: 3.338Epoch  35:  78% | abe: 3.263 | eve: 9.966 | bob: 3.338Epoch  35:  79% | abe: 3.262 | eve: 9.966 | bob: 3.338Epoch  35:  80% | abe: 3.263 | eve: 9.966 | bob: 3.339Epoch  35:  81% | abe: 3.263 | eve: 9.966 | bob: 3.339Epoch  35:  82% | abe: 3.263 | eve: 9.966 | bob: 3.339Epoch  35:  82% | abe: 3.263 | eve: 9.966 | bob: 3.339Epoch  35:  83% | abe: 3.263 | eve: 9.966 | bob: 3.339Epoch  35:  84% | abe: 3.263 | eve: 9.966 | bob: 3.339Epoch  35:  85% | abe: 3.263 | eve: 9.966 | bob: 3.339Epoch  35:  85% | abe: 3.263 | eve: 9.967 | bob: 3.339Epoch  35:  86% | abe: 3.263 | eve: 9.966 | bob: 3.339Epoch  35:  87% | abe: 3.263 | eve: 9.966 | bob: 3.339Epoch  35:  88% | abe: 3.263 | eve: 9.966 | bob: 3.339Epoch  35:  89% | abe: 3.263 | eve: 9.966 | bob: 3.339Epoch  35:  89% | abe: 3.263 | eve: 9.966 | bob: 3.339Epoch  35:  90% | abe: 3.263 | eve: 9.966 | bob: 3.340Epoch  35:  91% | abe: 3.263 | eve: 9.966 | bob: 3.340Epoch  35:  92% | abe: 3.263 | eve: 9.967 | bob: 3.340Epoch  35:  92% | abe: 3.263 | eve: 9.967 | bob: 3.339Epoch  35:  93% | abe: 3.263 | eve: 9.967 | bob: 3.339Epoch  35:  94% | abe: 3.263 | eve: 9.967 | bob: 3.339Epoch  35:  95% | abe: 3.263 | eve: 9.967 | bob: 3.340Epoch  35:  96% | abe: 3.262 | eve: 9.968 | bob: 3.339Epoch  35:  96% | abe: 3.262 | eve: 9.967 | bob: 3.339Epoch  35:  97% | abe: 3.262 | eve: 9.967 | bob: 3.339Epoch  35:  98% | abe: 3.262 | eve: 9.967 | bob: 3.339Epoch  35:  99% | abe: 3.262 | eve: 9.967 | bob: 3.340Epoch  36:   0% | abe: 3.253 | eve: 9.952 | bob: 3.331Epoch  36:   0% | abe: 3.264 | eve: 9.974 | bob: 3.343Epoch  36:   1% | abe: 3.268 | eve: 9.997 | bob: 3.350Epoch  36:   2% | abe: 3.262 | eve: 10.003 | bob: 3.345Epoch  36:   3% | abe: 3.261 | eve: 9.996 | bob: 3.344Epoch  36:   3% | abe: 3.260 | eve: 9.996 | bob: 3.343Epoch  36:   4% | abe: 3.259 | eve: 9.985 | bob: 3.342Epoch  36:   5% | abe: 3.256 | eve: 9.988 | bob: 3.340Epoch  36:   6% | abe: 3.253 | eve: 9.992 | bob: 3.335Epoch  36:   7% | abe: 3.254 | eve: 9.989 | bob: 3.336Epoch  36:   7% | abe: 3.253 | eve: 9.988 | bob: 3.335Epoch  36:   8% | abe: 3.252 | eve: 9.987 | bob: 3.335Epoch  36:   9% | abe: 3.252 | eve: 9.983 | bob: 3.335Epoch  36:  10% | abe: 3.252 | eve: 9.978 | bob: 3.334Epoch  36:  10% | abe: 3.251 | eve: 9.980 | bob: 3.334Epoch  36:  11% | abe: 3.252 | eve: 9.981 | bob: 3.336Epoch  36:  12% | abe: 3.252 | eve: 9.984 | bob: 3.338Epoch  36:  13% | abe: 3.252 | eve: 9.981 | bob: 3.337Epoch  36:  14% | abe: 3.251 | eve: 9.978 | bob: 3.337Epoch  36:  14% | abe: 3.251 | eve: 9.978 | bob: 3.337Epoch  36:  15% | abe: 3.251 | eve: 9.977 | bob: 3.338Epoch  36:  16% | abe: 3.251 | eve: 9.977 | bob: 3.338Epoch  36:  17% | abe: 3.252 | eve: 9.978 | bob: 3.338Epoch  36:  17% | abe: 3.252 | eve: 9.980 | bob: 3.338Epoch  36:  18% | abe: 3.252 | eve: 9.978 | bob: 3.338Epoch  36:  19% | abe: 3.251 | eve: 9.978 | bob: 3.337Epoch  36:  20% | abe: 3.251 | eve: 9.980 | bob: 3.337Epoch  36:  21% | abe: 3.251 | eve: 9.977 | bob: 3.336Epoch  36:  21% | abe: 3.251 | eve: 9.976 | bob: 3.336Epoch  36:  22% | abe: 3.251 | eve: 9.976 | bob: 3.336Epoch  36:  23% | abe: 3.250 | eve: 9.974 | bob: 3.335Epoch  36:  24% | abe: 3.250 | eve: 9.972 | bob: 3.336Epoch  36:  25% | abe: 3.250 | eve: 9.972 | bob: 3.336Epoch  36:  25% | abe: 3.250 | eve: 9.972 | bob: 3.336Epoch  36:  26% | abe: 3.250 | eve: 9.972 | bob: 3.337Epoch  36:  27% | abe: 3.250 | eve: 9.972 | bob: 3.336Epoch  36:  28% | abe: 3.249 | eve: 9.971 | bob: 3.336Epoch  36:  28% | abe: 3.249 | eve: 9.972 | bob: 3.336Epoch  36:  29% | abe: 3.249 | eve: 9.973 | bob: 3.336Epoch  36:  30% | abe: 3.249 | eve: 9.971 | bob: 3.336Epoch  36:  31% | abe: 3.250 | eve: 9.970 | bob: 3.336Epoch  36:  32% | abe: 3.249 | eve: 9.971 | bob: 3.335Epoch  36:  32% | abe: 3.249 | eve: 9.970 | bob: 3.335Epoch  36:  33% | abe: 3.249 | eve: 9.970 | bob: 3.336Epoch  36:  34% | abe: 3.249 | eve: 9.971 | bob: 3.336Epoch  36:  35% | abe: 3.249 | eve: 9.971 | bob: 3.335Epoch  36:  35% | abe: 3.249 | eve: 9.970 | bob: 3.336Epoch  36:  36% | abe: 3.249 | eve: 9.970 | bob: 3.336Epoch  36:  37% | abe: 3.249 | eve: 9.969 | bob: 3.336Epoch  36:  38% | abe: 3.249 | eve: 9.969 | bob: 3.336Epoch  36:  39% | abe: 3.249 | eve: 9.969 | bob: 3.336Epoch  36:  39% | abe: 3.249 | eve: 9.971 | bob: 3.336Epoch  36:  40% | abe: 3.249 | eve: 9.970 | bob: 3.336Epoch  36:  41% | abe: 3.249 | eve: 9.970 | bob: 3.336Epoch  36:  42% | abe: 3.249 | eve: 9.970 | bob: 3.336Epoch  36:  42% | abe: 3.249 | eve: 9.970 | bob: 3.335Epoch  36:  43% | abe: 3.248 | eve: 9.969 | bob: 3.335Epoch  36:  44% | abe: 3.249 | eve: 9.969 | bob: 3.336Epoch  36:  45% | abe: 3.249 | eve: 9.970 | bob: 3.335Epoch  36:  46% | abe: 3.249 | eve: 9.970 | bob: 3.336Epoch  36:  46% | abe: 3.249 | eve: 9.971 | bob: 3.336Epoch  36:  47% | abe: 3.249 | eve: 9.970 | bob: 3.336Epoch  36:  48% | abe: 3.249 | eve: 9.971 | bob: 3.336Epoch  36:  49% | abe: 3.249 | eve: 9.972 | bob: 3.336Epoch  36:  50% | abe: 3.249 | eve: 9.972 | bob: 3.336Epoch  36:  50% | abe: 3.249 | eve: 9.973 | bob: 3.336Epoch  36:  51% | abe: 3.249 | eve: 9.974 | bob: 3.336Epoch  36:  52% | abe: 3.248 | eve: 9.973 | bob: 3.335Epoch  36:  53% | abe: 3.248 | eve: 9.973 | bob: 3.335Epoch  36:  53% | abe: 3.248 | eve: 9.973 | bob: 3.335Epoch  36:  54% | abe: 3.248 | eve: 9.973 | bob: 3.335Epoch  36:  55% | abe: 3.248 | eve: 9.973 | bob: 3.335Epoch  36:  56% | abe: 3.248 | eve: 9.972 | bob: 3.335Epoch  36:  57% | abe: 3.249 | eve: 9.973 | bob: 3.335Epoch  36:  57% | abe: 3.249 | eve: 9.974 | bob: 3.336Epoch  36:  58% | abe: 3.249 | eve: 9.975 | bob: 3.335Epoch  36:  59% | abe: 3.248 | eve: 9.975 | bob: 3.336Epoch  36:  60% | abe: 3.248 | eve: 9.975 | bob: 3.336Epoch  36:  60% | abe: 3.248 | eve: 9.976 | bob: 3.336Epoch  36:  61% | abe: 3.249 | eve: 9.975 | bob: 3.336Epoch  36:  62% | abe: 3.249 | eve: 9.975 | bob: 3.336Epoch  36:  63% | abe: 3.249 | eve: 9.975 | bob: 3.336Epoch  36:  64% | abe: 3.249 | eve: 9.974 | bob: 3.336Epoch  36:  64% | abe: 3.248 | eve: 9.975 | bob: 3.336Epoch  36:  65% | abe: 3.248 | eve: 9.975 | bob: 3.336Epoch  36:  66% | abe: 3.248 | eve: 9.975 | bob: 3.336Epoch  36:  67% | abe: 3.248 | eve: 9.975 | bob: 3.336Epoch  36:  67% | abe: 3.248 | eve: 9.976 | bob: 3.336Epoch  36:  68% | abe: 3.248 | eve: 9.976 | bob: 3.336Epoch  36:  69% | abe: 3.248 | eve: 9.976 | bob: 3.336Epoch  36:  70% | abe: 3.248 | eve: 9.977 | bob: 3.336Epoch  36:  71% | abe: 3.248 | eve: 9.977 | bob: 3.336Epoch  36:  71% | abe: 3.248 | eve: 9.977 | bob: 3.336Epoch  36:  72% | abe: 3.248 | eve: 9.978 | bob: 3.336Epoch  36:  73% | abe: 3.248 | eve: 9.978 | bob: 3.336Epoch  36:  74% | abe: 3.248 | eve: 9.978 | bob: 3.336Epoch  36:  75% | abe: 3.248 | eve: 9.978 | bob: 3.337Epoch  36:  75% | abe: 3.248 | eve: 9.978 | bob: 3.337Epoch  36:  76% | abe: 3.248 | eve: 9.979 | bob: 3.337Epoch  36:  77% | abe: 3.247 | eve: 9.978 | bob: 3.336Epoch  36:  78% | abe: 3.247 | eve: 9.978 | bob: 3.336Epoch  36:  78% | abe: 3.247 | eve: 9.978 | bob: 3.336Epoch  36:  79% | abe: 3.247 | eve: 9.979 | bob: 3.337Epoch  36:  80% | abe: 3.247 | eve: 9.979 | bob: 3.336Epoch  36:  81% | abe: 3.247 | eve: 9.978 | bob: 3.337Epoch  36:  82% | abe: 3.247 | eve: 9.978 | bob: 3.337Epoch  36:  82% | abe: 3.247 | eve: 9.978 | bob: 3.337Epoch  36:  83% | abe: 3.247 | eve: 9.978 | bob: 3.337Epoch  36:  84% | abe: 3.247 | eve: 9.979 | bob: 3.337Epoch  36:  85% | abe: 3.247 | eve: 9.979 | bob: 3.337Epoch  36:  85% | abe: 3.247 | eve: 9.978 | bob: 3.337Epoch  36:  86% | abe: 3.247 | eve: 9.978 | bob: 3.337Epoch  36:  87% | abe: 3.247 | eve: 9.978 | bob: 3.337Epoch  36:  88% | abe: 3.247 | eve: 9.978 | bob: 3.337Epoch  36:  89% | abe: 3.247 | eve: 9.978 | bob: 3.337Epoch  36:  89% | abe: 3.247 | eve: 9.979 | bob: 3.338Epoch  36:  90% | abe: 3.247 | eve: 9.979 | bob: 3.338Epoch  36:  91% | abe: 3.247 | eve: 9.979 | bob: 3.338Epoch  36:  92% | abe: 3.247 | eve: 9.979 | bob: 3.337Epoch  36:  92% | abe: 3.247 | eve: 9.979 | bob: 3.337Epoch  36:  93% | abe: 3.247 | eve: 9.979 | bob: 3.337Epoch  36:  94% | abe: 3.247 | eve: 9.979 | bob: 3.337Epoch  36:  95% | abe: 3.246 | eve: 9.979 | bob: 3.337Epoch  36:  96% | abe: 3.246 | eve: 9.979 | bob: 3.337Epoch  36:  96% | abe: 3.246 | eve: 9.979 | bob: 3.337Epoch  36:  97% | abe: 3.246 | eve: 9.979 | bob: 3.337Epoch  36:  98% | abe: 3.246 | eve: 9.979 | bob: 3.337Epoch  36:  99% | abe: 3.246 | eve: 9.979 | bob: 3.337Epoch  37:   0% | abe: 3.251 | eve: 10.049 | bob: 3.363Epoch  37:   0% | abe: 3.249 | eve: 10.017 | bob: 3.350Epoch  37:   1% | abe: 3.246 | eve: 10.006 | bob: 3.346Epoch  37:   2% | abe: 3.240 | eve: 9.994 | bob: 3.338Epoch  37:   3% | abe: 3.240 | eve: 9.999 | bob: 3.335Epoch  37:   3% | abe: 3.239 | eve: 9.996 | bob: 3.334Epoch  37:   4% | abe: 3.239 | eve: 9.997 | bob: 3.338Epoch  37:   5% | abe: 3.236 | eve: 9.999 | bob: 3.335Epoch  37:   6% | abe: 3.237 | eve: 9.995 | bob: 3.338Epoch  37:   7% | abe: 3.239 | eve: 9.998 | bob: 3.338Epoch  37:   7% | abe: 3.239 | eve: 9.997 | bob: 3.338Epoch  37:   8% | abe: 3.240 | eve: 9.997 | bob: 3.337Epoch  37:   9% | abe: 3.239 | eve: 9.993 | bob: 3.337Epoch  37:  10% | abe: 3.239 | eve: 9.994 | bob: 3.337Epoch  37:  10% | abe: 3.238 | eve: 9.996 | bob: 3.336Epoch  37:  11% | abe: 3.239 | eve: 9.993 | bob: 3.337Epoch  37:  12% | abe: 3.239 | eve: 9.993 | bob: 3.337Epoch  37:  13% | abe: 3.238 | eve: 9.990 | bob: 3.336Epoch  37:  14% | abe: 3.237 | eve: 9.991 | bob: 3.335Epoch  37:  14% | abe: 3.237 | eve: 9.990 | bob: 3.334Epoch  37:  15% | abe: 3.238 | eve: 9.990 | bob: 3.335Epoch  37:  16% | abe: 3.237 | eve: 9.990 | bob: 3.335Epoch  37:  17% | abe: 3.237 | eve: 9.989 | bob: 3.335Epoch  37:  17% | abe: 3.236 | eve: 9.987 | bob: 3.335Epoch  37:  18% | abe: 3.237 | eve: 9.988 | bob: 3.335Epoch  37:  19% | abe: 3.236 | eve: 9.986 | bob: 3.335Epoch  37:  20% | abe: 3.236 | eve: 9.985 | bob: 3.334Epoch  37:  21% | abe: 3.236 | eve: 9.985 | bob: 3.335Epoch  37:  21% | abe: 3.236 | eve: 9.986 | bob: 3.335Epoch  37:  22% | abe: 3.236 | eve: 9.987 | bob: 3.335Epoch  37:  23% | abe: 3.236 | eve: 9.988 | bob: 3.335Epoch  37:  24% | abe: 3.236 | eve: 9.989 | bob: 3.335Epoch  37:  25% | abe: 3.236 | eve: 9.988 | bob: 3.335Epoch  37:  25% | abe: 3.237 | eve: 9.988 | bob: 3.336Epoch  37:  26% | abe: 3.236 | eve: 9.989 | bob: 3.337Epoch  37:  27% | abe: 3.237 | eve: 9.987 | bob: 3.338Epoch  37:  28% | abe: 3.237 | eve: 9.988 | bob: 3.337Epoch  37:  28% | abe: 3.237 | eve: 9.989 | bob: 3.337Epoch  37:  29% | abe: 3.236 | eve: 9.990 | bob: 3.337Epoch  37:  30% | abe: 3.236 | eve: 9.991 | bob: 3.336Epoch  37:  31% | abe: 3.236 | eve: 9.989 | bob: 3.336Epoch  37:  32% | abe: 3.236 | eve: 9.991 | bob: 3.336Epoch  37:  32% | abe: 3.236 | eve: 9.990 | bob: 3.336Epoch  37:  33% | abe: 3.236 | eve: 9.990 | bob: 3.336Epoch  37:  34% | abe: 3.236 | eve: 9.988 | bob: 3.337Epoch  37:  35% | abe: 3.236 | eve: 9.989 | bob: 3.336Epoch  37:  35% | abe: 3.236 | eve: 9.990 | bob: 3.337Epoch  37:  36% | abe: 3.236 | eve: 9.989 | bob: 3.337Epoch  37:  37% | abe: 3.236 | eve: 9.988 | bob: 3.337Epoch  37:  38% | abe: 3.236 | eve: 9.989 | bob: 3.336Epoch  37:  39% | abe: 3.236 | eve: 9.989 | bob: 3.336Epoch  37:  39% | abe: 3.236 | eve: 9.990 | bob: 3.337Epoch  37:  40% | abe: 3.236 | eve: 9.990 | bob: 3.337Epoch  37:  41% | abe: 3.236 | eve: 9.989 | bob: 3.337Epoch  37:  42% | abe: 3.236 | eve: 9.989 | bob: 3.337Epoch  37:  42% | abe: 3.236 | eve: 9.990 | bob: 3.337Epoch  37:  43% | abe: 3.236 | eve: 9.991 | bob: 3.337Epoch  37:  44% | abe: 3.236 | eve: 9.991 | bob: 3.337Epoch  37:  45% | abe: 3.235 | eve: 9.991 | bob: 3.337Epoch  37:  46% | abe: 3.235 | eve: 9.991 | bob: 3.337Epoch  37:  46% | abe: 3.236 | eve: 9.991 | bob: 3.337Epoch  37:  47% | abe: 3.235 | eve: 9.990 | bob: 3.337Epoch  37:  48% | abe: 3.235 | eve: 9.990 | bob: 3.337Epoch  37:  49% | abe: 3.235 | eve: 9.990 | bob: 3.337Epoch  37:  50% | abe: 3.235 | eve: 9.990 | bob: 3.337Epoch  37:  50% | abe: 3.235 | eve: 9.991 | bob: 3.337Epoch  37:  51% | abe: 3.235 | eve: 9.991 | bob: 3.337Epoch  37:  52% | abe: 3.235 | eve: 9.991 | bob: 3.337Epoch  37:  53% | abe: 3.235 | eve: 9.991 | bob: 3.337Epoch  37:  53% | abe: 3.235 | eve: 9.990 | bob: 3.337Epoch  37:  54% | abe: 3.235 | eve: 9.990 | bob: 3.337Epoch  37:  55% | abe: 3.235 | eve: 9.989 | bob: 3.337Epoch  37:  56% | abe: 3.235 | eve: 9.989 | bob: 3.337Epoch  37:  57% | abe: 3.235 | eve: 9.989 | bob: 3.337Epoch  37:  57% | abe: 3.235 | eve: 9.989 | bob: 3.337Epoch  37:  58% | abe: 3.235 | eve: 9.989 | bob: 3.337Epoch  37:  59% | abe: 3.235 | eve: 9.989 | bob: 3.337Epoch  37:  60% | abe: 3.235 | eve: 9.989 | bob: 3.337Epoch  37:  60% | abe: 3.234 | eve: 9.989 | bob: 3.337Epoch  37:  61% | abe: 3.234 | eve: 9.989 | bob: 3.337Epoch  37:  62% | abe: 3.234 | eve: 9.990 | bob: 3.337Epoch  37:  63% | abe: 3.234 | eve: 9.990 | bob: 3.337Epoch  37:  64% | abe: 3.235 | eve: 9.991 | bob: 3.338Epoch  37:  64% | abe: 3.235 | eve: 9.990 | bob: 3.338Epoch  37:  65% | abe: 3.235 | eve: 9.990 | bob: 3.338Epoch  37:  66% | abe: 3.235 | eve: 9.990 | bob: 3.338Epoch  37:  67% | abe: 3.235 | eve: 9.990 | bob: 3.338Epoch  37:  67% | abe: 3.234 | eve: 9.989 | bob: 3.338Epoch  37:  68% | abe: 3.234 | eve: 9.989 | bob: 3.338Epoch  37:  69% | abe: 3.234 | eve: 9.989 | bob: 3.338Epoch  37:  70% | abe: 3.234 | eve: 9.989 | bob: 3.338Epoch  37:  71% | abe: 3.234 | eve: 9.989 | bob: 3.338Epoch  37:  71% | abe: 3.234 | eve: 9.988 | bob: 3.338Epoch  37:  72% | abe: 3.234 | eve: 9.989 | bob: 3.337Epoch  37:  73% | abe: 3.234 | eve: 9.988 | bob: 3.337Epoch  37:  74% | abe: 3.234 | eve: 9.989 | bob: 3.338Epoch  37:  75% | abe: 3.234 | eve: 9.988 | bob: 3.338Epoch  37:  75% | abe: 3.234 | eve: 9.988 | bob: 3.338Epoch  37:  76% | abe: 3.234 | eve: 9.988 | bob: 3.338Epoch  37:  77% | abe: 3.234 | eve: 9.988 | bob: 3.338Epoch  37:  78% | abe: 3.234 | eve: 9.988 | bob: 3.338Epoch  37:  78% | abe: 3.234 | eve: 9.988 | bob: 3.338Epoch  37:  79% | abe: 3.234 | eve: 9.988 | bob: 3.338Epoch  37:  80% | abe: 3.234 | eve: 9.988 | bob: 3.338Epoch  37:  81% | abe: 3.234 | eve: 9.988 | bob: 3.339Epoch  37:  82% | abe: 3.234 | eve: 9.989 | bob: 3.339Epoch  37:  82% | abe: 3.234 | eve: 9.989 | bob: 3.339Epoch  37:  83% | abe: 3.233 | eve: 9.989 | bob: 3.339Epoch  37:  84% | abe: 3.233 | eve: 9.989 | bob: 3.338Epoch  37:  85% | abe: 3.233 | eve: 9.989 | bob: 3.338Epoch  37:  85% | abe: 3.233 | eve: 9.990 | bob: 3.339Epoch  37:  86% | abe: 3.233 | eve: 9.990 | bob: 3.339Epoch  37:  87% | abe: 3.233 | eve: 9.991 | bob: 3.339Epoch  37:  88% | abe: 3.233 | eve: 9.991 | bob: 3.339Epoch  37:  89% | abe: 3.233 | eve: 9.990 | bob: 3.339Epoch  37:  89% | abe: 3.233 | eve: 9.990 | bob: 3.339Epoch  37:  90% | abe: 3.233 | eve: 9.991 | bob: 3.339Epoch  37:  91% | abe: 3.233 | eve: 9.991 | bob: 3.338Epoch  37:  92% | abe: 3.233 | eve: 9.991 | bob: 3.338Epoch  37:  92% | abe: 3.233 | eve: 9.992 | bob: 3.338Epoch  37:  93% | abe: 3.233 | eve: 9.992 | bob: 3.339Epoch  37:  94% | abe: 3.233 | eve: 9.992 | bob: 3.338Epoch  37:  95% | abe: 3.233 | eve: 9.992 | bob: 3.338Epoch  37:  96% | abe: 3.233 | eve: 9.992 | bob: 3.339Epoch  37:  96% | abe: 3.233 | eve: 9.993 | bob: 3.338Epoch  37:  97% | abe: 3.233 | eve: 9.993 | bob: 3.338Epoch  37:  98% | abe: 3.233 | eve: 9.993 | bob: 3.339Epoch  37:  99% | abe: 3.233 | eve: 9.993 | bob: 3.339Epoch  38:   0% | abe: 3.238 | eve: 10.036 | bob: 3.361Epoch  38:   0% | abe: 3.232 | eve: 10.016 | bob: 3.347Epoch  38:   1% | abe: 3.230 | eve: 10.004 | bob: 3.353Epoch  38:   2% | abe: 3.230 | eve: 10.006 | bob: 3.350Epoch  38:   3% | abe: 3.232 | eve: 10.010 | bob: 3.346Epoch  38:   3% | abe: 3.232 | eve: 10.009 | bob: 3.345Epoch  38:   4% | abe: 3.231 | eve: 10.011 | bob: 3.345Epoch  38:   5% | abe: 3.232 | eve: 10.014 | bob: 3.346Epoch  38:   6% | abe: 3.232 | eve: 10.016 | bob: 3.344Epoch  38:   7% | abe: 3.232 | eve: 10.012 | bob: 3.343Epoch  38:   7% | abe: 3.231 | eve: 10.018 | bob: 3.343Epoch  38:   8% | abe: 3.229 | eve: 10.024 | bob: 3.341Epoch  38:   9% | abe: 3.229 | eve: 10.020 | bob: 3.341Epoch  38:  10% | abe: 3.229 | eve: 10.018 | bob: 3.342Epoch  38:  10% | abe: 3.229 | eve: 10.020 | bob: 3.343Epoch  38:  11% | abe: 3.228 | eve: 10.020 | bob: 3.343Epoch  38:  12% | abe: 3.228 | eve: 10.018 | bob: 3.344Epoch  38:  13% | abe: 3.229 | eve: 10.016 | bob: 3.343Epoch  38:  14% | abe: 3.230 | eve: 10.014 | bob: 3.345Epoch  38:  14% | abe: 3.230 | eve: 10.011 | bob: 3.346Epoch  38:  15% | abe: 3.230 | eve: 10.013 | bob: 3.346Epoch  38:  16% | abe: 3.230 | eve: 10.013 | bob: 3.347Epoch  38:  17% | abe: 3.231 | eve: 10.011 | bob: 3.348Epoch  38:  17% | abe: 3.230 | eve: 10.011 | bob: 3.347Epoch  38:  18% | abe: 3.230 | eve: 10.008 | bob: 3.347Epoch  38:  19% | abe: 3.229 | eve: 10.011 | bob: 3.347Epoch  38:  20% | abe: 3.229 | eve: 10.011 | bob: 3.347Epoch  38:  21% | abe: 3.229 | eve: 10.010 | bob: 3.347Epoch  38:  21% | abe: 3.229 | eve: 10.010 | bob: 3.347Epoch  38:  22% | abe: 3.229 | eve: 10.009 | bob: 3.348Epoch  38:  23% | abe: 3.229 | eve: 10.009 | bob: 3.348Epoch  38:  24% | abe: 3.229 | eve: 10.007 | bob: 3.349Epoch  38:  25% | abe: 3.228 | eve: 10.008 | bob: 3.348Epoch  38:  25% | abe: 3.228 | eve: 10.010 | bob: 3.348Epoch  38:  26% | abe: 3.228 | eve: 10.010 | bob: 3.348Epoch  38:  27% | abe: 3.229 | eve: 10.008 | bob: 3.348Epoch  38:  28% | abe: 3.228 | eve: 10.010 | bob: 3.348Epoch  38:  28% | abe: 3.228 | eve: 10.009 | bob: 3.348Epoch  38:  29% | abe: 3.227 | eve: 10.010 | bob: 3.347Epoch  38:  30% | abe: 3.227 | eve: 10.008 | bob: 3.348Epoch  38:  31% | abe: 3.227 | eve: 10.008 | bob: 3.347Epoch  38:  32% | abe: 3.227 | eve: 10.008 | bob: 3.347Epoch  38:  32% | abe: 3.227 | eve: 10.008 | bob: 3.347Epoch  38:  33% | abe: 3.227 | eve: 10.008 | bob: 3.346Epoch  38:  34% | abe: 3.227 | eve: 10.007 | bob: 3.346Epoch  38:  35% | abe: 3.227 | eve: 10.006 | bob: 3.346Epoch  38:  35% | abe: 3.226 | eve: 10.005 | bob: 3.346Epoch  38:  36% | abe: 3.226 | eve: 10.006 | bob: 3.346Epoch  38:  37% | abe: 3.226 | eve: 10.006 | bob: 3.346Epoch  38:  38% | abe: 3.226 | eve: 10.005 | bob: 3.346Epoch  38:  39% | abe: 3.226 | eve: 10.005 | bob: 3.345Epoch  38:  39% | abe: 3.226 | eve: 10.005 | bob: 3.345Epoch  38:  40% | abe: 3.226 | eve: 10.005 | bob: 3.345Epoch  38:  41% | abe: 3.226 | eve: 10.004 | bob: 3.345Epoch  38:  42% | abe: 3.226 | eve: 10.004 | bob: 3.345Epoch  38:  42% | abe: 3.226 | eve: 10.004 | bob: 3.346Epoch  38:  43% | abe: 3.226 | eve: 10.004 | bob: 3.346Epoch  38:  44% | abe: 3.225 | eve: 10.005 | bob: 3.345Epoch  38:  45% | abe: 3.226 | eve: 10.004 | bob: 3.346Epoch  38:  46% | abe: 3.225 | eve: 10.005 | bob: 3.345Epoch  38:  46% | abe: 3.225 | eve: 10.005 | bob: 3.346Epoch  38:  47% | abe: 3.225 | eve: 10.004 | bob: 3.345Epoch  38:  48% | abe: 3.225 | eve: 10.004 | bob: 3.345Epoch  38:  49% | abe: 3.225 | eve: 10.003 | bob: 3.345Epoch  38:  50% | abe: 3.225 | eve: 10.002 | bob: 3.345Epoch  38:  50% | abe: 3.225 | eve: 10.002 | bob: 3.345Epoch  38:  51% | abe: 3.225 | eve: 10.002 | bob: 3.346Epoch  38:  52% | abe: 3.225 | eve: 10.002 | bob: 3.346Epoch  38:  53% | abe: 3.225 | eve: 10.003 | bob: 3.346Epoch  38:  53% | abe: 3.225 | eve: 10.003 | bob: 3.345Epoch  38:  54% | abe: 3.225 | eve: 10.003 | bob: 3.346Epoch  38:  55% | abe: 3.225 | eve: 10.003 | bob: 3.346Epoch  38:  56% | abe: 3.225 | eve: 10.003 | bob: 3.346Epoch  38:  57% | abe: 3.225 | eve: 10.003 | bob: 3.346Epoch  38:  57% | abe: 3.225 | eve: 10.002 | bob: 3.346Epoch  38:  58% | abe: 3.224 | eve: 10.001 | bob: 3.346Epoch  38:  59% | abe: 3.224 | eve: 10.002 | bob: 3.345Epoch  38:  60% | abe: 3.224 | eve: 10.002 | bob: 3.346Epoch  38:  60% | abe: 3.224 | eve: 10.001 | bob: 3.346Epoch  38:  61% | abe: 3.224 | eve: 10.002 | bob: 3.346Epoch  38:  62% | abe: 3.224 | eve: 10.002 | bob: 3.346Epoch  38:  63% | abe: 3.224 | eve: 10.001 | bob: 3.346Epoch  38:  64% | abe: 3.224 | eve: 10.000 | bob: 3.346Epoch  38:  64% | abe: 3.224 | eve: 10.000 | bob: 3.346Epoch  38:  65% | abe: 3.224 | eve: 10.000 | bob: 3.346Epoch  38:  66% | abe: 3.224 | eve: 10.000 | bob: 3.346Epoch  38:  67% | abe: 3.224 | eve: 9.999 | bob: 3.346Epoch  38:  67% | abe: 3.224 | eve: 10.000 | bob: 3.347Epoch  38:  68% | abe: 3.224 | eve: 9.999 | bob: 3.347Epoch  38:  69% | abe: 3.224 | eve: 9.999 | bob: 3.347Epoch  38:  70% | abe: 3.224 | eve: 10.000 | bob: 3.347Epoch  38:  71% | abe: 3.223 | eve: 9.999 | bob: 3.347Epoch  38:  71% | abe: 3.223 | eve: 9.999 | bob: 3.346Epoch  38:  72% | abe: 3.223 | eve: 9.998 | bob: 3.346Epoch  38:  73% | abe: 3.223 | eve: 9.998 | bob: 3.346Epoch  38:  74% | abe: 3.223 | eve: 9.998 | bob: 3.346Epoch  38:  75% | abe: 3.223 | eve: 9.999 | bob: 3.346Epoch  38:  75% | abe: 3.223 | eve: 9.998 | bob: 3.346Epoch  38:  76% | abe: 3.223 | eve: 9.998 | bob: 3.346Epoch  38:  77% | abe: 3.222 | eve: 9.999 | bob: 3.346Epoch  38:  78% | abe: 3.222 | eve: 9.998 | bob: 3.346Epoch  38:  78% | abe: 3.223 | eve: 9.998 | bob: 3.346Epoch  38:  79% | abe: 3.223 | eve: 9.999 | bob: 3.346Epoch  38:  80% | abe: 3.223 | eve: 9.998 | bob: 3.347Epoch  38:  81% | abe: 3.223 | eve: 9.998 | bob: 3.346Epoch  38:  82% | abe: 3.223 | eve: 9.998 | bob: 3.346Epoch  38:  82% | abe: 3.222 | eve: 9.998 | bob: 3.346Epoch  38:  83% | abe: 3.222 | eve: 9.998 | bob: 3.346Epoch  38:  84% | abe: 3.222 | eve: 9.999 | bob: 3.347Epoch  38:  85% | abe: 3.222 | eve: 9.999 | bob: 3.347Epoch  38:  85% | abe: 3.222 | eve: 9.999 | bob: 3.347Epoch  38:  86% | abe: 3.222 | eve: 9.999 | bob: 3.347Epoch  38:  87% | abe: 3.222 | eve: 9.999 | bob: 3.347Epoch  38:  88% | abe: 3.222 | eve: 9.999 | bob: 3.347Epoch  38:  89% | abe: 3.222 | eve: 9.999 | bob: 3.347Epoch  38:  89% | abe: 3.222 | eve: 9.999 | bob: 3.346Epoch  38:  90% | abe: 3.222 | eve: 9.999 | bob: 3.346Epoch  38:  91% | abe: 3.222 | eve: 9.999 | bob: 3.346Epoch  38:  92% | abe: 3.222 | eve: 9.999 | bob: 3.346Epoch  38:  92% | abe: 3.222 | eve: 9.999 | bob: 3.347Epoch  38:  93% | abe: 3.222 | eve: 9.999 | bob: 3.347Epoch  38:  94% | abe: 3.222 | eve: 9.999 | bob: 3.347Epoch  38:  95% | abe: 3.221 | eve: 9.999 | bob: 3.347Epoch  38:  96% | abe: 3.221 | eve: 9.998 | bob: 3.347Epoch  38:  96% | abe: 3.221 | eve: 9.998 | bob: 3.347Epoch  38:  97% | abe: 3.221 | eve: 9.998 | bob: 3.347Epoch  38:  98% | abe: 3.221 | eve: 9.998 | bob: 3.347Epoch  38:  99% | abe: 3.221 | eve: 9.997 | bob: 3.347
Early stopping: No improvement after 5 epochs since epoch 32. Best Bob loss: 3.3357495844577443
Training complete.
cipher1 + cipher2
[[1.4459565  0.7892276  1.0435972  ... 1.4729962  0.93917274 0.9912237 ]
 [1.685696   1.6050247  1.3547413  ... 1.1874256  1.0947728  1.2577436 ]
 [1.2222884  1.244842   0.60848457 ... 0.9259155  0.47663158 0.9580529 ]
 ...
 [1.5773597  1.6696669  1.1135632  ... 1.252677   1.1100862  0.7880171 ]
 [1.4190726  0.93632257 0.7401936  ... 0.821975   1.132328   1.3227673 ]
 [1.1093998  0.8183663  1.1645722  ... 1.3381875  1.2439148  1.5257044 ]]
HO addition:
[[1.400068   0.7829696  1.0183412  ... 1.4255037  0.91577196 0.97269917]
 [1.6279573  1.5510654  1.3126659  ... 1.1532744  1.0644258  1.2200845 ]
 [1.1895381  1.2102228  0.60479486 ... 0.91153026 0.48323756 0.93899727]
 ...
 [1.5246059  1.6126677  1.0876011  ... 1.2162317  1.0811548  0.7713347 ]
 [1.3737216  0.9151962  0.7358601  ... 0.8044048  1.1014081  1.2839273 ]
 [1.0807314  0.80111814 1.132268   ... 1.2982097  1.2077793  1.47558   ]]
cipher1 * cipher2
[[0.5173586  0.15539476 0.25195986 ... 0.5424186  0.09101251 0.22939292]
 [0.71019864 0.63271624 0.4388412  ... 0.25728413 0.23749089 0.35580373]
 [0.362972   0.35619435 0.07655148 ... 0.21423435 0.05136497 0.21916223]
 ...
 [0.6146431  0.69594276 0.17710607 ... 0.3781297  0.2001542  0.09759201]
 [0.47339594 0.12608516 0.13643144 ... 0.12403886 0.28957412 0.42811477]
 [0.19807951 0.09598416 0.3137156  ... 0.4475304  0.36964723 0.5766462 ]]
HO multiplication
[[0.5248596  0.16204667 0.26051688 ... 0.5499386  0.09539993 0.23698525]
 [0.71531045 0.63950086 0.44775787 ... 0.26686785 0.2463481  0.36508358]
 [0.37124193 0.36421826 0.08095983 ... 0.22194532 0.0542354  0.22721992]
 ...
 [0.6216085  0.7013794  0.1857563  ... 0.38714734 0.2093639  0.10331015]
 [0.482225   0.13305798 0.14269881 ... 0.13066685 0.29853937 0.4362069 ]
 [0.20726071 0.10162454 0.3227586  ... 0.45583126 0.37871006 0.58346677]]
HO model Accuracy Percentage Addition: 2.07%
HO model Accuracy Percentage Multiplication: 1.02%
Bob decrypted addition: [[1.0308111  1.0322915  1.0188539  ... 0.5051342  0.86811936 0.0221619 ]
 [0.01865435 1.0637958  0.20162094 ... 0.01869124 1.0185513  1.0047868 ]
 [0.01859516 1.0603704  0.24350011 ... 0.01794928 0.84082407 0.81966305]
 ...
 [0.01770711 0.20759028 0.30698454 ... 0.5132365  0.88182735 0.02279639]
 [0.05455071 0.11569303 0.2459091  ... 0.27030545 0.7282396  1.0336121 ]
 [1.0255609  0.01810735 0.12340647 ... 0.33319318 0.01931852 0.9870877 ]]
Bob decrypted bits addition: [[1 1 1 ... 1 1 0]
 [0 1 0 ... 0 1 1]
 [0 1 0 ... 0 1 1]
 ...
 [0 0 0 ... 1 1 0]
 [0 0 0 ... 0 1 1]
 [1 0 0 ... 0 0 1]]
Number of correctly decrypted bits addition: 3083
Total number of bits addition: 8192
Decryption accuracy addition: 37.63427734375%
Bob decrypted multiplication: [[0.99757046 1.0231005  1.0094378  ... 0.55433416 0.4349277  0.0219509 ]
 [0.0200659  1.055821   0.2368998  ... 0.01932144 1.005929   0.9969513 ]
 [0.01952225 1.0419853  0.51127684 ... 0.01910603 0.6293348  0.6847249 ]
 ...
 [0.01948071 0.30611986 0.52627146 ... 0.7052697  0.56224257 0.02256399]
 [0.12331772 0.20357424 0.3380859  ... 0.6625796  0.487342   1.0022484 ]
 [1.0131264  0.01892453 0.17621487 ... 0.31788647 0.02026993 0.9818319 ]]
Bob decrypted bits multiplication: [[1 1 1 ... 1 0 0]
 [0 1 0 ... 0 1 1]
 [0 1 1 ... 0 1 1]
 ...
 [0 0 1 ... 1 1 0]
 [0 0 0 ... 1 0 1]
 [1 0 0 ... 0 0 1]]
Number of correctly decrypted bits multiplication: 6543
Total number of bits multiplication: 8192
Decryption accuracy multiplication: 79.87060546875%
Eve decrypted addition: [[1.1891109  0.9001645  1.1916378  ... 1.146124   0.91490847 0.91383153]
 [1.1958282  0.9500037  1.1873767  ... 1.1139911  0.9412854  0.9179613 ]
 [1.1904596  0.92109615 1.1911371  ... 1.150375   0.9086606  0.91450375]
 ...
 [1.1917429  0.9345405  1.1906797  ... 1.1527582  0.9172964  0.91445124]
 [1.1927072  0.9100129  1.1919066  ... 1.1483175  0.93441945 0.91352   ]
 [1.1922609  0.8853462  1.19214    ... 1.1502296  0.89024997 0.9156076 ]]
Eve decrypted bits addition: [[1 1 1 ... 1 1 1]
 [1 1 1 ... 1 1 1]
 [1 1 1 ... 1 1 1]
 ...
 [1 1 1 ... 1 1 1]
 [1 1 1 ... 1 1 1]
 [1 1 1 ... 1 1 1]]
Number of correctly decrypted bits by Eve addition: 4067
Total number of bits addition: 8192
Decryption accuracy by Eve addition: 49.64599609375%
Eve decrypted mulitplication: [[1.2178885  0.9433059  1.1838102  ... 1.1386278  0.97321975 0.948422  ]
 [1.21921    1.0299718  1.1732935  ... 1.082774   1.0343096  0.95893186]
 [1.2122717  1.0005178  1.1812987  ... 1.1387296  0.95318264 0.9531727 ]
 ...
 [1.2115649  1.0229744  1.1822348  ... 1.1419662  0.982304   0.9516323 ]
 [1.2104043  1.0072855  1.1815536  ... 1.1140468  1.0395743  0.94169426]
 [1.2224433  0.9324772  1.1827672  ... 1.1447217  0.9437254  0.9545208 ]]
Eve decrypted bits mulitplication: [[1 1 1 ... 1 1 1]
 [1 1 1 ... 1 1 1]
 [1 1 1 ... 1 1 1]
 ...
 [1 1 1 ... 1 1 1]
 [1 1 1 ... 1 1 1]
 [1 1 1 ... 1 1 1]]
Number of correctly decrypted bits by Eve mulitplication: 2074
Total number of bits mulitplication: 8192
Decryption accuracy by Eve mulitplication: 25.3173828125%
Bob decrypted P1: [[0.9997079  1.0186362  0.9992989  ... 0.01979899 1.007068   0.02619946]
 [0.01966643 1.0085822  0.9993676  ... 0.01946807 0.9998892  0.99544364]
 [0.01960659 1.0121474  0.02244192 ... 0.01929075 1.0036165  0.02598393]
 ...
 [0.02021974 0.98739976 0.01942533 ... 0.02067816 0.02297008 0.02285862]
 [1.0024749  0.01969045 0.9952694  ... 0.02440107 0.02109736 0.9922525 ]
 [0.9991518  0.01942497 0.9957158  ... 1.0097266  0.02332032 0.98057926]]
Bob decrypted bits P1: [[1 1 1 ... 0 1 0]
 [0 1 1 ... 0 1 1]
 [0 1 0 ... 0 1 0]
 ...
 [0 1 0 ... 0 0 0]
 [1 0 1 ... 0 0 1]
 [1 0 1 ... 1 0 1]]
Number of correctly decrypted bits P1: 8192
Total number of bits P1: 8192
Decryption accuracy P1: 100.0%
Bob decrypted P2: [[0.9975595  1.0140853  1.004271   ... 1.0041865  0.02201998 0.02317536]
 [0.02017385 1.017039   0.02249467 ... 0.01977348 1.0049177  0.9987017 ]
 [0.01956636 1.0030619  0.99375904 ... 0.02450919 0.02059519 0.9921031 ]
 ...
 [0.02238858 0.01984459 1.0016068  ... 0.9967619  1.0049156  0.02654892]
 [0.01915747 0.979953   0.01970917 ... 0.9949283  1.0128399  0.9957938 ]
 [1.0025029  0.02007663 0.02100879 ... 0.02431101 0.02177572 0.9986308 ]]
Bob decrypted bits P2: [[1 1 1 ... 1 0 0]
 [0 1 0 ... 0 1 1]
 [0 1 1 ... 0 0 1]
 ...
 [0 0 1 ... 1 1 0]
 [0 1 0 ... 1 1 1]
 [1 0 0 ... 0 0 1]]
Number of correctly decrypted bits P2: 8192
Total number of bits P2: 8192
Decryption accuracy P2: 100.0%
